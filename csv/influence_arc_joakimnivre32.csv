2020.acl-main.375,W19-4820,0,0.0199654,"e training objective. Probing approaches applied to models like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have demonstrated that one can decode various linguistic properties such as part-of-speech categories, dependency relations, and named-entity types directly from the internal hidden states of a pretrained model (Tenney et al., 2019b,b; Peters et al., 2018b). Another line of work has tried to tie cognitive measurements or theories of human linguistic processing to the machinations of language models, often establishing strong parallels between the two (Prasad et al., 2019; Abnar et al., 2019; Gauthier and Levy, 2019). As is the case for NLP in general, English has served as the de facto testing ground for much of this work, with other languages often appearing as an afterthought. However, despite its ubiquity in the NLP literature, English is generally considered to be atypical across many typological dimensions. Furthermore, the tendency of interpreting NLP models with respect to existing, canonical datasets often comes with the danger of conflating the theory-driven annotation therein with scientific fact. One can observe this to an extent with the Universal Dependencies (UD) p"
2020.acl-main.375,P17-1080,0,0.047016,"rithm for deriving directed trees from the disjoint distance and depth probes introduced by Hewitt and Manning (2019). 2. A multilingual analysis of the probe’s performance across 13 different treebanks. 3. An analysis showing that the syntactic information encoded by BERT and ELMo fit UD better than SUD for most languages. 2 Related Work There has been a considerable amount of recent work attempting to understand what aspects of natural language pre-trained encoders learn. The classic formulation of these probing experiments is in the form of diagnostic classification (Ettinger et al., 2016; Belinkov et al., 2017; Hupkes et al., 2018; Conneau et al., 2018), which attempts to unearth underlying linguistic properties by fitting relatively underparameterised linear models over representations generated by an encoder. These methods have also faced recent critique, for example, concerning the lack of transparency in the classifers’ ability to extract meaningful information, as opposed to learning it. Alternative paradigms for interpretability have therefore been proposed, such as correlation-based methods (Raghu et al., 2017; Saphra and Lopez, 2018; Kornblith et al., 2019; Chrupała and Alishahi, 2019). How"
2020.acl-main.375,P18-2003,0,0.0192335,"e, concerning the lack of transparency in the classifers’ ability to extract meaningful information, as opposed to learning it. Alternative paradigms for interpretability have therefore been proposed, such as correlation-based methods (Raghu et al., 2017; Saphra and Lopez, 2018; Kornblith et al., 2019; Chrupała and Alishahi, 2019). However, this critique does not invalidate diagnostic classification: indeed, more recent work (Hewitt and Liang, 2019) describes methods to show the empirical validity of certain probes, via control tasks. Among probing studies specifically pertinent to our paper, Blevins et al. (2018) demonstrate that deep RNNs are capable of encoding syntax given a variety of pre-training tasks, including language modeling. Peters et al. (2018b) demonstrate that, regardless of encoder (recurrent, convolutional, or self-attentive), biLM-based pre-training results in similar high-quality representations that implicitly encode a variety of linguistic phenomena, layer by layer. Similarly, Tenney et al. (2019a) employ the ‘edge probing’ approach of Tenney et al. (2019b) to demonstrate that BERT implicitly learns the ‘classical NLP pipeline’, with lower-level linguistic tasks encoded in lower l"
2020.acl-main.375,K18-2005,0,0.0295262,"y length (DepLen) and lower average tree height (Height). However, the magnitude of the difference varies greatly across languages.5 Models We evaluate two pretrained language models: BERT (Devlin et al., 2019) and ELMo (Peters et al., 2018a). For BERT, we use the pretrained multilingual-bert-cased model provided by Google.6 The model is trained on the concatenation of WikiDumps for the top 104 languages with the largest Wikipedias and features a 12-layer Transformer with 768 hidden units and 12 self-attention heads. For ELMo, we make use of the pretrained monolingual models made available by Che et al. (2018). These models are trained on 20 million words randomly sampled from the concatenation of WikiDump and CommonCrawl datasets for 44 different languages, including our 13 languages. Each model features a characterbased word embedding layer, as well as 2 bi-LSTM layers, each of which is 1024-dimensions wide. Though we fit the probe on all layers of each model separately, we also learn a weighted average over each full model: modeli “ L ÿ sj hi,j j“0 where sj is a learned parameter, hi,j is the encoding of word i at layer j, and L is the number of 5 For Chinese, UD actually has slightly lower aver"
2020.acl-main.375,P19-1283,0,0.0226265,"al., 2016; Belinkov et al., 2017; Hupkes et al., 2018; Conneau et al., 2018), which attempts to unearth underlying linguistic properties by fitting relatively underparameterised linear models over representations generated by an encoder. These methods have also faced recent critique, for example, concerning the lack of transparency in the classifers’ ability to extract meaningful information, as opposed to learning it. Alternative paradigms for interpretability have therefore been proposed, such as correlation-based methods (Raghu et al., 2017; Saphra and Lopez, 2018; Kornblith et al., 2019; Chrupała and Alishahi, 2019). However, this critique does not invalidate diagnostic classification: indeed, more recent work (Hewitt and Liang, 2019) describes methods to show the empirical validity of certain probes, via control tasks. Among probing studies specifically pertinent to our paper, Blevins et al. (2018) demonstrate that deep RNNs are capable of encoding syntax given a variety of pre-training tasks, including language modeling. Peters et al. (2018b) demonstrate that, regardless of encoder (recurrent, convolutional, or self-attentive), biLM-based pre-training results in similar high-quality representations tha"
2020.acl-main.375,P18-1198,0,0.024011,"isjoint distance and depth probes introduced by Hewitt and Manning (2019). 2. A multilingual analysis of the probe’s performance across 13 different treebanks. 3. An analysis showing that the syntactic information encoded by BERT and ELMo fit UD better than SUD for most languages. 2 Related Work There has been a considerable amount of recent work attempting to understand what aspects of natural language pre-trained encoders learn. The classic formulation of these probing experiments is in the form of diagnostic classification (Ettinger et al., 2016; Belinkov et al., 2017; Hupkes et al., 2018; Conneau et al., 2018), which attempts to unearth underlying linguistic properties by fitting relatively underparameterised linear models over representations generated by an encoder. These methods have also faced recent critique, for example, concerning the lack of transparency in the classifers’ ability to extract meaningful information, as opposed to learning it. Alternative paradigms for interpretability have therefore been proposed, such as correlation-based methods (Raghu et al., 2017; Saphra and Lopez, 2018; Kornblith et al., 2019; Chrupała and Alishahi, 2019). However, this critique does not invalidate diag"
2020.acl-main.375,N19-1423,0,0.218829,"ace-Syntactic Universal Dependencies (SUD), focusing on surface structure. We find that both models exhibit a preference for UD over SUD — with interesting variations across languages and layers — and that the strength of this preference is correlated with differences in tree shape. 1 Introduction Recent work on interpretability in NLP has led to the consensus that deep neural language models trained on large, unannotated datasets manage to encode various aspects of syntax as a byproduct of the training objective. Probing approaches applied to models like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have demonstrated that one can decode various linguistic properties such as part-of-speech categories, dependency relations, and named-entity types directly from the internal hidden states of a pretrained model (Tenney et al., 2019b,b; Peters et al., 2018b). Another line of work has tried to tie cognitive measurements or theories of human linguistic processing to the machinations of language models, often establishing strong parallels between the two (Prasad et al., 2019; Abnar et al., 2019; Gauthier and Levy, 2019). As is the case for NLP in general, English has served as the de facto testin"
2020.acl-main.375,P81-1022,0,0.432938,"Missing"
2020.acl-main.375,W16-2524,0,0.0258273,"istics 1. A simple algorithm for deriving directed trees from the disjoint distance and depth probes introduced by Hewitt and Manning (2019). 2. A multilingual analysis of the probe’s performance across 13 different treebanks. 3. An analysis showing that the syntactic information encoded by BERT and ELMo fit UD better than SUD for most languages. 2 Related Work There has been a considerable amount of recent work attempting to understand what aspects of natural language pre-trained encoders learn. The classic formulation of these probing experiments is in the form of diagnostic classification (Ettinger et al., 2016; Belinkov et al., 2017; Hupkes et al., 2018; Conneau et al., 2018), which attempts to unearth underlying linguistic properties by fitting relatively underparameterised linear models over representations generated by an encoder. These methods have also faced recent critique, for example, concerning the lack of transparency in the classifers’ ability to extract meaningful information, as opposed to learning it. Alternative paradigms for interpretability have therefore been proposed, such as correlation-based methods (Raghu et al., 2017; Saphra and Lopez, 2018; Kornblith et al., 2019; Chrupała a"
2020.acl-main.375,D19-1050,0,0.018535,". Probing approaches applied to models like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have demonstrated that one can decode various linguistic properties such as part-of-speech categories, dependency relations, and named-entity types directly from the internal hidden states of a pretrained model (Tenney et al., 2019b,b; Peters et al., 2018b). Another line of work has tried to tie cognitive measurements or theories of human linguistic processing to the machinations of language models, often establishing strong parallels between the two (Prasad et al., 2019; Abnar et al., 2019; Gauthier and Levy, 2019). As is the case for NLP in general, English has served as the de facto testing ground for much of this work, with other languages often appearing as an afterthought. However, despite its ubiquity in the NLP literature, English is generally considered to be atypical across many typological dimensions. Furthermore, the tendency of interpreting NLP models with respect to existing, canonical datasets often comes with the danger of conflating the theory-driven annotation therein with scientific fact. One can observe this to an extent with the Universal Dependencies (UD) project (Nivre et al., 2016"
2020.acl-main.375,W18-6008,0,0.165754,"training and evaluating probes, but often fail to mention that UD, like all annotation schemes, is built upon specific theoretical assumptions, which may not be universally accepted. Our research questions start from these concerns. When probing language models for syntactic dependency structure, is UD — with its emphasis on syntactic relations between content words — really the best fit? Or is the representational structure of such models better explained by a scheme that is more oriented towards surface structure, such as the recently proposed Surface-Syntactic Universal Dependencies (SUD) (Gerdes et al., 2018)? And are these patterns consistent across typologically different languages? To explore these questions, we fit the structural probe of Hewitt and Manning (2019) on pretrained BERT and ELMo representations, supervised by UD/SUD treebanks for 13 languages, and extract directed dependency trees. We then conduct an extensive error analysis of the resulting probed parses, in an attempt to qualify our findings. Our main contributions are the following: 4077 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4077–4091 c July 5 - 10, 2020. 2020 Association"
2020.acl-main.375,D19-1275,0,0.0583952,"properties by fitting relatively underparameterised linear models over representations generated by an encoder. These methods have also faced recent critique, for example, concerning the lack of transparency in the classifers’ ability to extract meaningful information, as opposed to learning it. Alternative paradigms for interpretability have therefore been proposed, such as correlation-based methods (Raghu et al., 2017; Saphra and Lopez, 2018; Kornblith et al., 2019; Chrupała and Alishahi, 2019). However, this critique does not invalidate diagnostic classification: indeed, more recent work (Hewitt and Liang, 2019) describes methods to show the empirical validity of certain probes, via control tasks. Among probing studies specifically pertinent to our paper, Blevins et al. (2018) demonstrate that deep RNNs are capable of encoding syntax given a variety of pre-training tasks, including language modeling. Peters et al. (2018b) demonstrate that, regardless of encoder (recurrent, convolutional, or self-attentive), biLM-based pre-training results in similar high-quality representations that implicitly encode a variety of linguistic phenomena, layer by layer. Similarly, Tenney et al. (2019a) employ the ‘edge"
2020.acl-main.375,N19-1419,0,0.39168,"be universally accepted. Our research questions start from these concerns. When probing language models for syntactic dependency structure, is UD — with its emphasis on syntactic relations between content words — really the best fit? Or is the representational structure of such models better explained by a scheme that is more oriented towards surface structure, such as the recently proposed Surface-Syntactic Universal Dependencies (SUD) (Gerdes et al., 2018)? And are these patterns consistent across typologically different languages? To explore these questions, we fit the structural probe of Hewitt and Manning (2019) on pretrained BERT and ELMo representations, supervised by UD/SUD treebanks for 13 languages, and extract directed dependency trees. We then conduct an extensive error analysis of the resulting probed parses, in an attempt to qualify our findings. Our main contributions are the following: 4077 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4077–4091 c July 5 - 10, 2020. 2020 Association for Computational Linguistics 1. A simple algorithm for deriving directed trees from the disjoint distance and depth probes introduced by Hewitt and Manning (201"
2020.acl-main.375,D19-1279,0,0.0657046,"Missing"
2020.acl-main.375,D19-1277,1,0.902162,"Missing"
2020.acl-main.375,H05-1066,0,0.338745,"Missing"
2020.acl-main.375,P19-1452,0,0.306087,"ence is correlated with differences in tree shape. 1 Introduction Recent work on interpretability in NLP has led to the consensus that deep neural language models trained on large, unannotated datasets manage to encode various aspects of syntax as a byproduct of the training objective. Probing approaches applied to models like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have demonstrated that one can decode various linguistic properties such as part-of-speech categories, dependency relations, and named-entity types directly from the internal hidden states of a pretrained model (Tenney et al., 2019b,b; Peters et al., 2018b). Another line of work has tried to tie cognitive measurements or theories of human linguistic processing to the machinations of language models, often establishing strong parallels between the two (Prasad et al., 2019; Abnar et al., 2019; Gauthier and Levy, 2019). As is the case for NLP in general, English has served as the de facto testing ground for much of this work, with other languages often appearing as an afterthought. However, despite its ubiquity in the NLP literature, English is generally considered to be atypical across many typological dimensions. Further"
2020.acl-main.375,L16-1262,1,0.872984,"Missing"
2020.acl-main.375,N18-1202,0,0.804865,"ep syntactic relations, and Surface-Syntactic Universal Dependencies (SUD), focusing on surface structure. We find that both models exhibit a preference for UD over SUD — with interesting variations across languages and layers — and that the strength of this preference is correlated with differences in tree shape. 1 Introduction Recent work on interpretability in NLP has led to the consensus that deep neural language models trained on large, unannotated datasets manage to encode various aspects of syntax as a byproduct of the training objective. Probing approaches applied to models like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have demonstrated that one can decode various linguistic properties such as part-of-speech categories, dependency relations, and named-entity types directly from the internal hidden states of a pretrained model (Tenney et al., 2019b,b; Peters et al., 2018b). Another line of work has tried to tie cognitive measurements or theories of human linguistic processing to the machinations of language models, often establishing strong parallels between the two (Prasad et al., 2019; Abnar et al., 2019; Gauthier and Levy, 2019). As is the case for NLP in general, English"
2020.acl-main.375,D18-1179,0,0.29335,"ep syntactic relations, and Surface-Syntactic Universal Dependencies (SUD), focusing on surface structure. We find that both models exhibit a preference for UD over SUD — with interesting variations across languages and layers — and that the strength of this preference is correlated with differences in tree shape. 1 Introduction Recent work on interpretability in NLP has led to the consensus that deep neural language models trained on large, unannotated datasets manage to encode various aspects of syntax as a byproduct of the training objective. Probing approaches applied to models like ELMo (Peters et al., 2018a) and BERT (Devlin et al., 2019) have demonstrated that one can decode various linguistic properties such as part-of-speech categories, dependency relations, and named-entity types directly from the internal hidden states of a pretrained model (Tenney et al., 2019b,b; Peters et al., 2018b). Another line of work has tried to tie cognitive measurements or theories of human linguistic processing to the machinations of language models, often establishing strong parallels between the two (Prasad et al., 2019; Abnar et al., 2019; Gauthier and Levy, 2019). As is the case for NLP in general, English"
2020.acl-main.375,K19-1007,0,0.0506583,"Missing"
2020.cl-4.3,P18-2003,0,0.0404026,"Missing"
2020.cl-4.3,P15-1033,0,0.456325,"re are more labels than these two and labels do not encode information about whether they are dependency or transfer relations. 765 Computational Linguistics Volume 46, Number 4 However, this notion has not been made explicit when training parsers. In pre-neural transition-based parsers as in Nivre, Hall, and Nilsson (2006), when a dependent gets attached to its head, features of the head are still used for further parsing but features of the dependent are usually discarded.2 In neural parsers, it is less clear what information is used by parsers. Current stateof-the-art models use (Bi)LSTMs (Dyer et al. 2015; Kiperwasser and Goldberg 2016; Dozat and Manning 2017), and LSTMs make it possible to encode information about the surrounding context of words in an unbounded window (which is usually limited to a sentence in practice). In this article, we take a step in finding out what neural parsers learn by testing if they capture the notion of dissociated nuclei. We do this by looking in detail at what a BiLSTM-based parser learns about a specific type of dissociated nucleus: auxiliary verb constructions. We focus on AVCs as they are a typical example of dissociated nucleus and are well attested typolo"
2020.cl-4.3,N18-1108,0,0.0769137,"icle, we use this method to investigate whether or not a specific aspect of linguistic theory is learned, the notion of dissociated nucleus from dependency grammar (explained in §2.1), as a byproduct of learning the task of dependency parsing for several languages. For this, we focus on auxiliary verb constructions (AVCs). A prominent question in neural modeling of syntax is whether or not it is necessary to model hierarchical structure. Sequential models (long short-term memory networks [LSTMs]) have shown surprising capability for learning syntactic tasks (Linzen, Dupoux, and Goldberg 2016; Gulordava et al. 2018), and models of dependency parsing using sequential models are very accurate (Kiperwasser and Goldberg 2016). Although recursive neural networks surpass the abilities of sequential models for learning syntactic tasks (Kuncoro et al. 2018), their use in dependency parsing seems superfluous compared to using sequential models when looking at parsing accuracy (de Lhoneux, Ballesteros, and Nivre 2019). However, there may be benefits to using recursive neural networks in parsing that are not reflected in parsing accuracy. In particular, for reasons outlined in §2.2, they may be useful when it comes"
2020.cl-4.3,Q16-1023,0,0.575166,"rned, the notion of dissociated nucleus from dependency grammar (explained in §2.1), as a byproduct of learning the task of dependency parsing for several languages. For this, we focus on auxiliary verb constructions (AVCs). A prominent question in neural modeling of syntax is whether or not it is necessary to model hierarchical structure. Sequential models (long short-term memory networks [LSTMs]) have shown surprising capability for learning syntactic tasks (Linzen, Dupoux, and Goldberg 2016; Gulordava et al. 2018), and models of dependency parsing using sequential models are very accurate (Kiperwasser and Goldberg 2016). Although recursive neural networks surpass the abilities of sequential models for learning syntactic tasks (Kuncoro et al. 2018), their use in dependency parsing seems superfluous compared to using sequential models when looking at parsing accuracy (de Lhoneux, Ballesteros, and Nivre 2019). However, there may be benefits to using recursive neural networks in parsing that are not reflected in parsing accuracy. In particular, for reasons outlined in §2.2, they may be useful when it comes to learning the notion of dissociated nucleus. In this article, we evaluate the usefulness of recursive neu"
2020.cl-4.3,P11-1068,0,0.51359,"Missing"
2020.cl-4.3,P18-1132,0,0.110018,"ng for several languages. For this, we focus on auxiliary verb constructions (AVCs). A prominent question in neural modeling of syntax is whether or not it is necessary to model hierarchical structure. Sequential models (long short-term memory networks [LSTMs]) have shown surprising capability for learning syntactic tasks (Linzen, Dupoux, and Goldberg 2016; Gulordava et al. 2018), and models of dependency parsing using sequential models are very accurate (Kiperwasser and Goldberg 2016). Although recursive neural networks surpass the abilities of sequential models for learning syntactic tasks (Kuncoro et al. 2018), their use in dependency parsing seems superfluous compared to using sequential models when looking at parsing accuracy (de Lhoneux, Ballesteros, and Nivre 2019). However, there may be benefits to using recursive neural networks in parsing that are not reflected in parsing accuracy. In particular, for reasons outlined in §2.2, they may be useful when it comes to learning the notion of dissociated nucleus. In this article, we evaluate the usefulness of recursive neural networks when it comes to learning the notion of dissociated nucleus. The goals of this article are thus threefold. First, we"
2020.cl-4.3,Q16-1037,0,0.06206,"Missing"
2020.cl-4.3,J08-4003,1,0.594581,"ry in case of AVCs) and concatenate the features Person and Number. The possible values are therefore all possible combinations of 1st, 2nd, and 3rd person with plural and singular. There are cases where this information is not available, in which case the agreement task is undefined for the AVC. The code to reproduce our experiments is available at https://github.com /mdelhoneux/avc analyser, including the modifications we made to the parser to freeze the vector representations at the different layers in the network. 3.2 BiLSTM-based Parsing We use UUParser, a greedy transition-based parser (Nivre 2008) based on the framework of Kiperwasser and Goldberg (2016) where BiLSTMs (Hochreiter and Schmidhuber 7 We experimented with a harder task: predicting the number of objects. In the example in Figure 3, that number would be 1. In case of intransitive use of verbs, it would be 0, and with a ditransitive use of a verb, it would be 2. We observed the same trends and therefore do not report these results. 770 de Lhoneux et al. What Should/Do/Can LSTMs Learn When Parsing Auxiliary Verb Constructions? 1997; Graves 2008) learn representations of tokens in context, and are trained together with a multil"
2020.cl-4.3,L16-1262,1,0.850608,"Missing"
2020.cl-4.3,N18-1202,0,0.0470304,"ed by the parser, it is useful for the task of parsing, since the representations are obtained from a model that is trained end-to-end without explicit supervision about the prediction tasks. Recent research has cast some doubt on this: As discussed by Belinkov (2018), it is not impossible that the information is in the network activations but is not used by the network. In any case, we are not interested in improving the parser here but in finding out what it learns. 9 Note that for this kind of experiment, training language models that learn contextual representations of words such as ELMo (Peters et al. 2018) or BERT (Devlin et al. 2019) and compare these representations to our token vectors would be more appropriate. However, these models are typically trained on very large data sets and it is unclear how well they perform when trained on just treebank data. We leave doing this to future work. 773 Computational Linguistics Volume 46, Number 4 3.4 Vectors We train parsers for 30 epochs for all these treebanks and pick the model of the best epoch based on LAS score on the development set. We report parsing results in Table 2. We train the parser with the same hyperparameters as in Smith et al. (201"
2020.cl-4.3,N19-1000,0,0.0979021,"Missing"
2020.cl-4.3,K18-2011,1,0.868896,"Missing"
2020.cl-4.3,Q18-1019,0,0.0530749,"Missing"
2020.coling-main.375,P17-1080,0,0.0801062,"odels have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representations, which are also studied in Belinkov et al. (2020). We apply more composition methods to explore how CHAR models learn linguistic knowledge and how attention extracts features directly"
2020.coling-main.375,I17-1001,0,0.0436194,"Missing"
2020.coling-main.375,D18-1461,0,0.248477,"e translation significantly in recent years (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gehring et al., 2017; Vaswani et al., 2017). However, it is still unclear how NMT models work due to the black-box nature of neural networks. Better understandings of NMT models could guide us in improving NMT systems. Currently most of the studies towards understanding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al"
2020.coling-main.375,D14-1179,0,0.0633082,"Missing"
2020.coling-main.375,W19-4828,0,0.0391358,"Missing"
2020.coling-main.375,N19-1423,0,0.0464375,"Missing"
2020.coling-main.375,P17-1106,0,0.0173559,"BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representations, which are also studied in Belinkov et al. (2020). We apply more composition methods to explore how CHAR models learn linguistic kn"
2020.coling-main.375,N19-1154,0,0.0364743,"Missing"
2020.coling-main.375,I17-1004,0,0.0171175,"tandings of NMT models could guide us in improving NMT systems. Currently most of the studies towards understanding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fu"
2020.coling-main.375,W19-6611,0,0.0171359,"sm of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representations, which are also studied in Belinkov et al. (2020). We apply more composition methods to explore how CHAR models learn linguistic knowledge and how attention extracts features directly from characters. Probing classification tasks (Belinkov et al., 2017a) have emerged as a popular method to interpret the internal representat"
2020.coling-main.375,D19-1088,0,0.0187335,"anding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representations, which are also studied in Belinkov et al. (2020). We apply more com"
2020.coling-main.375,2020.eamt-1.50,0,0.0534137,"Missing"
2020.coling-main.375,D13-1176,0,0.0535546,"ning linguistic knowledge. In addition, character-based models need more layers to encode word senses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop. 1 Introduction Neural machine translation (NMT) has boosted machine translation significantly in recent years (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gehring et al., 2017; Vaswani et al., 2017). However, it is still unclear how NMT models work due to the black-box nature of neural networks. Better understandings of NMT models could guide us in improving NMT systems. Currently most of the studies towards understanding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mech"
2020.coling-main.375,D15-1166,0,0.411527,"nses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop. 1 Introduction Neural machine translation (NMT) has boosted machine translation significantly in recent years (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Gehring et al., 2017; Vaswani et al., 2017). However, it is still unclear how NMT models work due to the black-box nature of neural networks. Better understandings of NMT models could guide us in improving NMT systems. Currently most of the studies towards understanding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and"
2020.coling-main.375,P02-1040,0,0.10895,"tag. The detailed statistics are provided in Table 1. 2.2 Experimental Settings NMT models We use the Sockeye (Hieber et al., 2017) toolkit to train NMT models. The encoder is a stack of 1 bidirectional RNN and 6 unidirectional RNNs, and the decoder has 8 unidirectional RNNs. We choose long short-term memory (LSTM) RNN unit (Hochreiter and Schmidhuber, 1997). The size of embeddings and hidden units is 512. We tie the source, target, and output embeddings. The beam size is 8 during inference. We employ the models that have the best perplexity on the validation set for evaluation. BLEU scores (Papineni et al., 2002) are computed by sacrebleu (Post, 2018). For CHAR models, we add separators between any two tokens including punctuation marks, and input character sequences to the model directly. The character vocabulary size is 379. For the BPE-based model, we learn a joint BPE model with 32K subwords (Sennrich et al., 2016). As Cherry et al. (2018) have shown that the depth is crucial to the success of CHAR models, we train a 4-layer CHAR model to study the effect of depth. Probing classifiers These probing classifiers are feed-forward neural networks with only one hidden layer, using ReLU non-linear activ"
2020.coling-main.375,N18-2082,0,0.0505931,"Missing"
2020.coling-main.375,W18-6319,0,0.0115204,"e 1. 2.2 Experimental Settings NMT models We use the Sockeye (Hieber et al., 2017) toolkit to train NMT models. The encoder is a stack of 1 bidirectional RNN and 6 unidirectional RNNs, and the decoder has 8 unidirectional RNNs. We choose long short-term memory (LSTM) RNN unit (Hochreiter and Schmidhuber, 1997). The size of embeddings and hidden units is 512. We tie the source, target, and output embeddings. The beam size is 8 during inference. We employ the models that have the best perplexity on the validation set for evaluation. BLEU scores (Papineni et al., 2002) are computed by sacrebleu (Post, 2018). For CHAR models, we add separators between any two tokens including punctuation marks, and input character sequences to the model directly. The character vocabulary size is 379. For the BPE-based model, we learn a joint BPE model with 32K subwords (Sennrich et al., 2016). As Cherry et al. (2018) have shown that the depth is crucial to the success of CHAR models, we train a 4-layer CHAR model to study the effect of depth. Probing classifiers These probing classifiers are feed-forward neural networks with only one hidden layer, using ReLU non-linear activation. The size of the hidden layer is"
2020.coling-main.375,W18-5431,0,0.0167659,"could guide us in improving NMT systems. Currently most of the studies towards understanding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representa"
2020.coling-main.375,W19-5354,0,0.049152,"to the classifier and the output are different from the classifiers in the morphological probing tasks. Instead, the representations of an ambiguous word and its candidate translation are both fed into the classifier and then the classifier predicts whether the candidate translation is correct or not. 2.1 Data We train NMT models on the WMT15 shared task data (Bojar et al., 2015) for FI→EN to be able to compare with Cherry et al. (2018). There are about 2.1M sentence pairs in the training set after preprocessing with Moses scripts. For the WSD probing task, we use the FI–EN part of the MuCoW (Raganato et al., 2019) test set, which is a multilingual test suite for WSD in the WMT19 shared task. It has 2,117 annotated sentences. Each annotation provides the ambiguous Finnish word, the domain of the sentence, and a set of translation candidates of the ambiguous word including both correct and incorrect translations. For each ambiguous word from an annotation, we generate multiple instances that are labeled with one translation candidate and a binary value indicating whether it corresponds to the correct sense. 1,000/1,000 instances are randomly selected as the development/test sets, and the remaining 6,325"
2020.coling-main.375,P16-1162,1,0.45213,"LSTM) RNN unit (Hochreiter and Schmidhuber, 1997). The size of embeddings and hidden units is 512. We tie the source, target, and output embeddings. The beam size is 8 during inference. We employ the models that have the best perplexity on the validation set for evaluation. BLEU scores (Papineni et al., 2002) are computed by sacrebleu (Post, 2018). For CHAR models, we add separators between any two tokens including punctuation marks, and input character sequences to the model directly. The character vocabulary size is 379. For the BPE-based model, we learn a joint BPE model with 32K subwords (Sennrich et al., 2016). As Cherry et al. (2018) have shown that the depth is crucial to the success of CHAR models, we train a 4-layer CHAR model to study the effect of depth. Probing classifiers These probing classifiers are feed-forward neural networks with only one hidden layer, using ReLU non-linear activation. The size of the hidden layer is set to 512. We use the Adam learning algorithm (Kingma and Ba, 2015). The classifiers are trained using a cross-entropy loss. Each classifier is trained for 180/100 epochs in the WSD/morphological probing tasks and the one that performs best on the development set is selec"
2020.coling-main.375,W18-6304,1,0.813362,"T systems. Currently most of the studies towards understanding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representations, which are al"
2020.coling-main.375,D19-1149,1,0.827874,"y most of the studies towards understanding NMT models only take into account subword-based (e.g. BPE-based) models. Deeper character-based (CHAR) models have been shown to perform better than BPE-based models (Cherry et al., 2018). In this paper, we try to investigate the working mechanism of CHAR models. We explore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representations, which are also studied in Belink"
2020.coling-main.375,D19-1448,1,0.842371,"xplore the ability of CHAR models to learn word senses and morphological inflections and the attention mechanism. Previous studies have tried to interpret and understand NMT models by interpreting attention weights (Ghader and Monz, 2017; Raganato and Tiedemann, 2018; Tang et al., 2018; Tang et al., 2019), using gradients (He et al., 2019), applying layer-wise relevance propagation (Ding et al., 2017), probing classification tasks (Belinkov et al., 2017b; Belinkov et al., 2017a; Belinkov et al., 2020; Poliak et al., 2018; Tang et al., 2019), and more intrinsic analysis (Ghader and Monz, 2019; Voita et al., 2019). However, only Belinkov et al. (2017a; Belinkov et al. (2020) have probed character-based representations. Belinkov et al. (2017a) have only explored character-aware word-level representations, while we investigate fully character-level representations, which are also studied in Belinkov et al. (2020). We apply more composition methods to explore how CHAR models learn linguistic knowledge and how attention extracts features directly from characters. Probing classification tasks (Belinkov et al., 2017a) have emerged as a popular method to interpret the internal representations from neural netw"
2020.iwpt-1.25,P13-1023,0,0.0148612,"due to conjunction, control, raising and relative clauses (see Figures 1 and 2). In Universal Dependencies v2 (UD; Nivre et al., 2020), enhanced dependencies (ED) are a separate dependency graph than the basic dependency tree (BD). However, ED is almost a super-set of BD,1 and so most previous approaches (Schuster and Manning, 2016; Nivre et al., 2018) have attempted to recover ED from BD using languagespecific rules. On the other hand, Hershcovich ∗ xcomp aux:pass et al. (2018) experimented with TUPA, a transitionbased directed acyclic graph (DAG) parser originally designed for parsing UCCA (Abend and Rappoport, 2013), for supervised ED parsing. They converted ED to UCCA-like graphs and did not use pre-trained contextualized embeddings, yielding sub-optimal results. Taking a similar approach, we adapt a transition-based graph parser (Che et al., 2019) designed for Meaning Representation Parsing (Oepen et al., 2019), but parse ED directly and use BERT embeddings (Devlin et al., 2019). The main contribution of our work is a transition system supporting the graph structures exhibited by ED, including null nodes (meaning this is not a strictly bilexical formalism), cycles and non-crossing graphs (§3.1), as Fig"
2020.iwpt-1.25,P17-1112,0,0.0183963,"essor, see §2) and a stack (originally containing the root, i.e., word at index 0), to incrementally create the output dependency graph. At each point in the parsing process, a tran237 sition is selected out of a pre-defined set of possible transitions. A classifier is trained to predict the best transition to apply at each step, by mimicking an oracle during training (see §3.1). HIT-SCIR used a different transition system per framework (AMR, EDS, UCCA; and one system for DM and PSD), according to the graph properties of each and based on existing framework-specific parsers (Liu et al., 2018; Buys and Blunsom, 2017; Hershcovich et al., 2017; Wang et al., 2018). We construct a transition system for ED using subsets of transitions from two of the HIT-SCIR systems: their system for DM and PSD, as well as their system for UCCA, with some further adaptations specific to ED graphs. Language 3.1 S WEDISH A RABIC B ULGARIAN C ZECH D UTCH E NGLISH E STONIAN F INNISH F RENCH I TALIAN L ATVIAN L ITHUANIAN P OLISH RUSSIAN S LOVAK Transition System TAMIL Our system contains the following transitions: {S HIFT, L EFT-E DGEl , R IGHT-E DGEl , R EDUCE 0, R EDUCE -1, N ODE, S WAP and F INISH}. The S HIFT transition pops"
2020.iwpt-1.25,K19-2007,0,0.237588,"almost a super-set of BD,1 and so most previous approaches (Schuster and Manning, 2016; Nivre et al., 2018) have attempted to recover ED from BD using languagespecific rules. On the other hand, Hershcovich ∗ xcomp aux:pass et al. (2018) experimented with TUPA, a transitionbased directed acyclic graph (DAG) parser originally designed for parsing UCCA (Abend and Rappoport, 2013), for supervised ED parsing. They converted ED to UCCA-like graphs and did not use pre-trained contextualized embeddings, yielding sub-optimal results. Taking a similar approach, we adapt a transition-based graph parser (Che et al., 2019) designed for Meaning Representation Parsing (Oepen et al., 2019), but parse ED directly and use BERT embeddings (Devlin et al., 2019). The main contribution of our work is a transition system supporting the graph structures exhibited by ED, including null nodes (meaning this is not a strictly bilexical formalism), cycles and non-crossing graphs (§3.1), as Figure 4 demonstrates for the sentence from Figure 2. We parse ED completely separately from BD, demonstrating the applicability of a full graph parser, starting from only segmented and tokenized text, to ED. Our code is available at https:/"
2020.iwpt-1.25,N19-1423,0,0.434286,"er ED from BD using languagespecific rules. On the other hand, Hershcovich ∗ xcomp aux:pass et al. (2018) experimented with TUPA, a transitionbased directed acyclic graph (DAG) parser originally designed for parsing UCCA (Abend and Rappoport, 2013), for supervised ED parsing. They converted ED to UCCA-like graphs and did not use pre-trained contextualized embeddings, yielding sub-optimal results. Taking a similar approach, we adapt a transition-based graph parser (Che et al., 2019) designed for Meaning Representation Parsing (Oepen et al., 2019), but parse ED directly and use BERT embeddings (Devlin et al., 2019). The main contribution of our work is a transition system supporting the graph structures exhibited by ED, including null nodes (meaning this is not a strictly bilexical formalism), cycles and non-crossing graphs (§3.1), as Figure 4 demonstrates for the sentence from Figure 2. We parse ED completely separately from BD, demonstrating the applicability of a full graph parser, starting from only segmented and tokenized text, to ED. Our code is available at https://github.com/ coastalcph/koepsala-parser. Introduction 1 punct 2 Preprocessing As the focus of this shared task is ED parsing, we rely"
2020.iwpt-1.25,P15-1033,0,0.173167,"ed training treebanks and the models trained on the language’s largest treebank. No consistent trend is observed. treebank-specific preprocessing models henceforth. 3 Transition-Based Enhanced Dependency Parser Our system is a transition-based graph parser, based on the HIT-SCIR system (Che et al., 2019), which achieved the highest average score across frameworks (AMR, EDS, UCCA, DM and PSD) in the CoNLL 2019 shared task on Meaning Representation Parsing (MRP; Oepen et al., 2019). It is written in the AllenNLP (Gardner et al., 2018) framework. For training efficiently, it employs stack LSTMs (Dyer et al., 2015), batching operations across sentences. For better encoding, HIT-SCIR fine-tuned BERT (Devlin et al., 2019) while training the parser. A transition-based parser operates by manipulating a buffer (originally containing the input words provided by the preprocessor, see §2) and a stack (originally containing the root, i.e., word at index 0), to incrementally create the output dependency graph. At each point in the parsing process, a tran237 sition is selected out of a pre-defined set of possible transitions. A classifier is trained to predict the best transition to apply at each step, by mimickin"
2020.iwpt-1.25,P17-1104,1,0.936758,"ck (originally containing the root, i.e., word at index 0), to incrementally create the output dependency graph. At each point in the parsing process, a tran237 sition is selected out of a pre-defined set of possible transitions. A classifier is trained to predict the best transition to apply at each step, by mimicking an oracle during training (see §3.1). HIT-SCIR used a different transition system per framework (AMR, EDS, UCCA; and one system for DM and PSD), according to the graph properties of each and based on existing framework-specific parsers (Liu et al., 2018; Buys and Blunsom, 2017; Hershcovich et al., 2017; Wang et al., 2018). We construct a transition system for ED using subsets of transitions from two of the HIT-SCIR systems: their system for DM and PSD, as well as their system for UCCA, with some further adaptations specific to ED graphs. Language 3.1 S WEDISH A RABIC B ULGARIAN C ZECH D UTCH E NGLISH E STONIAN F INNISH F RENCH I TALIAN L ATVIAN L ITHUANIAN P OLISH RUSSIAN S LOVAK Transition System TAMIL Our system contains the following transitions: {S HIFT, L EFT-E DGEl , R IGHT-E DGEl , R EDUCE 0, R EDUCE -1, N ODE, S WAP and F INISH}. The S HIFT transition pops the first element of the b"
2020.iwpt-1.25,K18-2010,1,0.866037,"Missing"
2020.iwpt-1.25,D18-1264,0,0.0269028,"ded by the preprocessor, see §2) and a stack (originally containing the root, i.e., word at index 0), to incrementally create the output dependency graph. At each point in the parsing process, a tran237 sition is selected out of a pre-defined set of possible transitions. A classifier is trained to predict the best transition to apply at each step, by mimicking an oracle during training (see §3.1). HIT-SCIR used a different transition system per framework (AMR, EDS, UCCA; and one system for DM and PSD), according to the graph properties of each and based on existing framework-specific parsers (Liu et al., 2018; Buys and Blunsom, 2017; Hershcovich et al., 2017; Wang et al., 2018). We construct a transition system for ED using subsets of transitions from two of the HIT-SCIR systems: their system for DM and PSD, as well as their system for UCCA, with some further adaptations specific to ED graphs. Language 3.1 S WEDISH A RABIC B ULGARIAN C ZECH D UTCH E NGLISH E STONIAN F INNISH F RENCH I TALIAN L ATVIAN L ITHUANIAN P OLISH RUSSIAN S LOVAK Transition System TAMIL Our system contains the following transitions: {S HIFT, L EFT-E DGEl , R IGHT-E DGEl , R EDUCE 0, R EDUCE -1, N ODE, S WAP and F INISH}. The"
2020.iwpt-1.25,W03-3017,1,0.501286,"terminates the transition sequence. A formal definition of the transition set is shown in Figure 3. Separate E DGE transitions exist for each edge label. Labels containing coordination or case suffixes (such as nmod:van) are treated as any other label and are not split, resulting in a large number of transitions for some languages, shown in Table 2. N ODE transitions, on the other hand, do not se6 For consistency, we keep the transition nomenclature using “E DGE”, although they create directed dependency arcs. Note that in analogous transitions in some transition systems, such as A RC E AGER (Nivre, 2003), the dependent of the transition is also popped out of the stack as part of either of these two transitions. Here, since dependents can have multiple heads and can have arcs with multiple labels, we stick to the E DGE action and use our two R EDUCE transitions to pop elements of the stack when necessary. U KRAINIAN Total E DGE w/ suffix 402 197 768 393 300 445 266 112 281 238 323 676 944 266 209 146 290 395 191 761 386 293 438 259 106 274 232 317 669 938 259 202 140 283 345 137 702 336 232 381 210 59 216 161 263 615 861 204 153 103 225 Table 2: Number of transitions for each language. lect an"
2020.iwpt-1.25,W18-6012,1,0.857933,"nce segmentation, tokenization, lemmatization, part-of-speech tagging, morphological analysis, basic dependency parsing, and finally (for the first time) enhanced dependency parsing. The enhancements encode case information, elided predicates, and shared arguments due to conjunction, control, raising and relative clauses (see Figures 1 and 2). In Universal Dependencies v2 (UD; Nivre et al., 2020), enhanced dependencies (ED) are a separate dependency graph than the basic dependency tree (BD). However, ED is almost a super-set of BD,1 and so most previous approaches (Schuster and Manning, 2016; Nivre et al., 2018) have attempted to recover ED from BD using languagespecific rules. On the other hand, Hershcovich ∗ xcomp aux:pass et al. (2018) experimented with TUPA, a transitionbased directed acyclic graph (DAG) parser originally designed for parsing UCCA (Abend and Rappoport, 2013), for supervised ED parsing. They converted ED to UCCA-like graphs and did not use pre-trained contextualized embeddings, yielding sub-optimal results. Taking a similar approach, we adapt a transition-based graph parser (Che et al., 2019) designed for Meaning Representation Parsing (Oepen et al., 2019), but parse ED directly a"
2020.iwpt-1.25,K19-2001,1,0.902269,"Missing"
2020.iwpt-1.25,2020.acl-demos.14,0,0.0151677,"stics root nsubj punct cop conj det punct nmod obl:aan cc conj:en case nmod:van cc acl:relcl case det det nsubj amod Deze is de modernste en grootste hal van Belgi¨e , en NULL de enige die voldoet aan de Olympische normen . nmod cc det nmod ref nsubj:relsubj conj:en acl:relcl Figure 2: wiki-3745.p.38.s.5 from UD Dutch-LassySmall, containing a null node NULL, not in the original sentence, coordination and case suffixes (:en, :van, :aan), and propagation of conjuncts (hal → grootste). The dashed edges are deleted in ED, and the edges below the sentence are added. Note the cycle NULL ↔ voldoet. (Qi et al., 2020)2 and UDPIPE 1.2 (Straka and Strakov´a, 2017; Straka et al., 2016),3 both of which have models pre-trained on UD v2.5 treebanks. We experiment with either pipeline during prediction to process the raw text files for the dev and test sets, eventually selecting UDPIPE for our primary submission. This process entails sentence segmentation, tokenization, lemmatization, part-of-speech tagging, morphological feature tagging, and BD parsing.4 For training our ED parser (§3), however, we use gold inputs for simplicity. We use the conllu Python package5 to read CoNLL-U files. Preprocessing model select"
2020.iwpt-1.25,L16-1376,0,0.0318393,"et al., 2020) involves sentence segmentation, tokenization, lemmatization, part-of-speech tagging, morphological analysis, basic dependency parsing, and finally (for the first time) enhanced dependency parsing. The enhancements encode case information, elided predicates, and shared arguments due to conjunction, control, raising and relative clauses (see Figures 1 and 2). In Universal Dependencies v2 (UD; Nivre et al., 2020), enhanced dependencies (ED) are a separate dependency graph than the basic dependency tree (BD). However, ED is almost a super-set of BD,1 and so most previous approaches (Schuster and Manning, 2016; Nivre et al., 2018) have attempted to recover ED from BD using languagespecific rules. On the other hand, Hershcovich ∗ xcomp aux:pass et al. (2018) experimented with TUPA, a transitionbased directed acyclic graph (DAG) parser originally designed for parsing UCCA (Abend and Rappoport, 2013), for supervised ED parsing. They converted ED to UCCA-like graphs and did not use pre-trained contextualized embeddings, yielding sub-optimal results. Taking a similar approach, we adapt a transition-based graph parser (Che et al., 2019) designed for Meaning Representation Parsing (Oepen et al., 2019), bu"
2020.iwpt-1.25,L16-1680,0,0.0340407,"Missing"
2020.iwpt-1.25,K17-3009,0,0.0511472,"Missing"
2020.iwpt-1.25,C18-1124,0,0.0160239,"the root, i.e., word at index 0), to incrementally create the output dependency graph. At each point in the parsing process, a tran237 sition is selected out of a pre-defined set of possible transitions. A classifier is trained to predict the best transition to apply at each step, by mimicking an oracle during training (see §3.1). HIT-SCIR used a different transition system per framework (AMR, EDS, UCCA; and one system for DM and PSD), according to the graph properties of each and based on existing framework-specific parsers (Liu et al., 2018; Buys and Blunsom, 2017; Hershcovich et al., 2017; Wang et al., 2018). We construct a transition system for ED using subsets of transitions from two of the HIT-SCIR systems: their system for DM and PSD, as well as their system for UCCA, with some further adaptations specific to ED graphs. Language 3.1 S WEDISH A RABIC B ULGARIAN C ZECH D UTCH E NGLISH E STONIAN F INNISH F RENCH I TALIAN L ATVIAN L ITHUANIAN P OLISH RUSSIAN S LOVAK Transition System TAMIL Our system contains the following transitions: {S HIFT, L EFT-E DGEl , R IGHT-E DGEl , R EDUCE 0, R EDUCE -1, N ODE, S WAP and F INISH}. The S HIFT transition pops the first element of the buffer and pushes it"
2020.iwpt-1.25,2020.lrec-1.497,1,\N,Missing
2020.lrec-1.234,W13-2322,0,0.0891257,"tically vacuous surface tokens). DM and PSD nodes are labeled with lemmas, parts of speech, and (for verbs only, in the PSD case) frame or sense identifiers; jointly, these properties define a semantic predicate. Edges represent semantic argument roles: DM mostly uses overtly order-coded labels, e.g. ARG1, ARG2, etc. Abstractly similar, PSD labels like ACT(or), PAT(ient), or ADDR(essee) indicate ‘participant’ positions in an underlying valency frame. Regarding lexical anchoring, on the opposite end of the range of frameworks in the MRP 2019 shared task is Abstract Meaning Representation (AMR; Banarescu et al. (2013)), which by design does not spell out how nodes relate to sub-strings of the underlying parser input; Figure 2 shows the same example sentence in AMR. Without an explicit relation to the surface string, several of the ‘querying’ possible-01 polarity ARG1 apply-02 ARG1 technique almost ARG2 crop (ARG1)-of resemble-01 mod (domain) mod (domain) other (ARG1)-of exemplify-01 ARG0 and op1 cotton soybean op2 op3 rice op4 et-cetera Figure 2: Sample unanchored Abstract Meaning Representation (AMR) graph for the same sentence as in Figure 1. 1903 dimensions of McDonald and Nivre (2011) will need to eith"
2020.lrec-1.234,W06-2920,0,0.111386,"tly top-performing semantic parsers. Finally, § 5. concludes the paper and discusses avenues for future research. 2. Background The following paragraphs establish relevant methodological and technological context for our work, out of necessity summarizing prior efforts in rather broad strokes. A Tale of Two Parsers One inspiration for this study is the contrastive error analysis of graph-based vs. transitionbased syntactic dependency parsers carried out by McDonald and Nivre (2007) and McDonald and Nivre (2011). Based on data from the CoNLL 2006 shared task on multilingual dependency parsing (Buchholz and Marsi, 2006), they analyzed the performance of the two parser types in relation to a number of structural factors, such as sentence length, dependency length, and tree depth, as well as linguistic categories, notably parts of speech and dependency types. The analysis showed that, although the best graphbased and transition-based syntactic dependency parsers at the time achieved very similar accuracy on average, they had quite distinctive error profiles. Moreover, these differences could be explained by inherent strengths and weaknesses of the two algorithmic approaches. Thus, for exam1902 top ARG2 BV ARG1"
2020.lrec-1.234,K19-2007,0,0.338406,"these, the first two abstractly parallel the two families represented in the studies by McDonald and Nivre (2011), whereas composition-based parsing approaches are not found in syntactic parsing. We consider participating systems in the MRP 2019 competition, and, within each family of approaches, choose the top-performing systems for the PSD 1 See https://github.com/cfmrp/mtool for details. Figure 3: Distribution of sentences by length (node count), binned to ten aggregates. and DM frameworks.2 Among the transition-based systems in MRP 2019, the best-performing parser is the HIT-SCIR parser (Che et al., 2019), which is also the top-performing overall parser; in the factorisation-based family, the SJTU-NICT system (Li et al., 2019) performs best on DM; and among the composition-based submissions, the Saarland system (Donatelli et al., 2019) obtains the best PSD results. Table 1 shows the absolute output quality (in terms of MRP precision, recall, and F1 ) and the rankings of these systems on the PSD evaluation data, reproducing the official shared task results presented by Oepen et al. (2019). The Saarland parser, an extension of Lindemann et al. (2019), uses a compositional approach, employing the"
2020.lrec-1.234,N19-1423,0,0.087353,"l, but degraded more because of error propagation in greedy decoding. Conversely, graph-based parsers showed a more graceful degradation thanks to global optimization and exact decoding, but had a disadvantage for local structures because of a more restricted feature model. More recently, Kulmizev et al. (2019) replicated this analysis for neural graph-based and transition-based parsers and showed that, although the distinct error profiles are still discernible, the differences are now much smaller and are further reduced by the use of deep contextualized word embeddings (Peters et al., 2018; Devlin et al., 2019). MRP 2019 The 2019 Shared Task at the Conference for Computational Language Learning (CoNLL) was devoted to Meaning Representation Parsing (MRP) across frameworks (Oepen et al., 2019). For the first time, this task combined formally and linguistically different approaches to meaning representation in graph form in a uniform training and evaluation setup. The training and evaluation data for the task comprised five distinct approaches— which all encode core predicate–argument structure, among other things—to the representation of sentence meaning in the form of directed graphs, packaged in a u"
2020.lrec-1.234,K19-2006,0,0.286659,"s in the MRP 2019 competition, and, within each family of approaches, choose the top-performing systems for the PSD 1 See https://github.com/cfmrp/mtool for details. Figure 3: Distribution of sentences by length (node count), binned to ten aggregates. and DM frameworks.2 Among the transition-based systems in MRP 2019, the best-performing parser is the HIT-SCIR parser (Che et al., 2019), which is also the top-performing overall parser; in the factorisation-based family, the SJTU-NICT system (Li et al., 2019) performs best on DM; and among the composition-based submissions, the Saarland system (Donatelli et al., 2019) obtains the best PSD results. Table 1 shows the absolute output quality (in terms of MRP precision, recall, and F1 ) and the rankings of these systems on the PSD evaluation data, reproducing the official shared task results presented by Oepen et al. (2019). The Saarland parser, an extension of Lindemann et al. (2019), uses a compositional approach, employing the Apply–Modify Algebra of Groschwitz et al. (2017) to build semantic graphs through highly constrained combinations of smaller graph fragments. A BiLSTM sequence labeling model is used for semantic tagging of word tokens, and the BiLSTM"
2020.lrec-1.234,W17-6810,0,0.0189096,"erforming overall parser; in the factorisation-based family, the SJTU-NICT system (Li et al., 2019) performs best on DM; and among the composition-based submissions, the Saarland system (Donatelli et al., 2019) obtains the best PSD results. Table 1 shows the absolute output quality (in terms of MRP precision, recall, and F1 ) and the rankings of these systems on the PSD evaluation data, reproducing the official shared task results presented by Oepen et al. (2019). The Saarland parser, an extension of Lindemann et al. (2019), uses a compositional approach, employing the Apply–Modify Algebra of Groschwitz et al. (2017) to build semantic graphs through highly constrained combinations of smaller graph fragments. A BiLSTM sequence labeling model is used for semantic tagging of word tokens, and the BiLSTM ‘feature extractor’ architecture of Kiperwasser and Goldberg (2016) is employed for predicting dependency trees, with input representations combining ELMo 2 We use framework-specific performance on PSD and DM, rather than the overall ranking across frameworks within the shared task, as the selection criterion, given that this pilot study is focused on comparing and analysing the results of parsing into these p"
2020.lrec-1.234,hajic-etal-2012-announcing,0,0.0969522,"Missing"
2020.lrec-1.234,W12-3602,1,0.781193,"niform abstract structure and serialization. This task design seeks to enable cross-framework comparison of different parsing approaches and to advance learning from complementary knowledge sources (e.g. via parameter sharing). The MRP 2019 competition received submissions from eighteen teams, and there will be a follow-up shared task, again hosted by CoNLL, in 2020. Figure 1 shows two example graphs for one sentence from the venerable Wall Street Journal (WSJ) corpus in the two bi-lexical MRP frameworks (of five total), DELPHIN MRS Bi-Lexical Dependencies (DM) of Oepen and Lønning (2006) and Ivanova et al. (2012), and Prague Semantic Dependencies (PSD) by Hajiˇc et al. (2012) and Miyao et al. (2014). The DM and PSD frameworks are bi-lexical in the MRP collection, characterized by a one-toone relation between graph nodes and surface tokens. But even within this limiting assumption, which makes these graphs formally somewhat similar to standard syntactic dependency trees, the examples in Figure 1 exhibit all the nontree properties sketched in § 1. above (reentrancies, multiple roots, and semantically vacuous surface tokens). DM and PSD nodes are labeled with lemmas, parts of speech, and (for verbs only,"
2020.lrec-1.234,Q16-1023,0,0.0230753,"1 shows the absolute output quality (in terms of MRP precision, recall, and F1 ) and the rankings of these systems on the PSD evaluation data, reproducing the official shared task results presented by Oepen et al. (2019). The Saarland parser, an extension of Lindemann et al. (2019), uses a compositional approach, employing the Apply–Modify Algebra of Groschwitz et al. (2017) to build semantic graphs through highly constrained combinations of smaller graph fragments. A BiLSTM sequence labeling model is used for semantic tagging of word tokens, and the BiLSTM ‘feature extractor’ architecture of Kiperwasser and Goldberg (2016) is employed for predicting dependency trees, with input representations combining ELMo 2 We use framework-specific performance on PSD and DM, rather than the overall ranking across frameworks within the shared task, as the selection criterion, given that this pilot study is focused on comparing and analysing the results of parsing into these particular frameworks. 1905 Figure 4: Overall MRP precision, recall, and F1 by sentence length for DM (left) and PSD (right). (Peters et al., 2018), and BERT (Devlin et al., 2019) contextualised word embeddings. Additionally, a decomposition step into sub"
2020.lrec-1.234,P19-4002,1,0.844548,"eworks) their evaluation data is publicly available (Oepen et al., 2016). All statistics in this section are against the standard 3,359-sentence PSD and DM test set, comprising gold-standard graphs drawn from the WSJ and Brown corpora. Overall and component-wise MRP evaluation scores were computed using an instrumented version of the official scorer, the mtool Swiss Army knife of meaning representation.1 4.2. Parsing Systems Our choice of models for contrastive evaluation was motivated by the characterisation of systems into three broad families of approaches, as presented, amongst others, by Koller et al. (2019) and Oepen et al. (2019): transition-, factorisation-, and composition-based parsers. Of these, the first two abstractly parallel the two families represented in the studies by McDonald and Nivre (2011), whereas composition-based parsing approaches are not found in syntactic parsing. We consider participating systems in the MRP 2019 competition, and, within each family of approaches, choose the top-performing systems for the PSD 1 See https://github.com/cfmrp/mtool for details. Figure 3: Distribution of sentences by length (node count), binned to ten aggregates. and DM frameworks.2 Among the t"
2020.lrec-1.234,J16-4009,1,0.939361,"Missing"
2020.lrec-1.234,D19-1277,1,0.894859,"Missing"
2020.lrec-1.234,K19-2004,0,0.0119447,"omposition-based parsing approaches are not found in syntactic parsing. We consider participating systems in the MRP 2019 competition, and, within each family of approaches, choose the top-performing systems for the PSD 1 See https://github.com/cfmrp/mtool for details. Figure 3: Distribution of sentences by length (node count), binned to ten aggregates. and DM frameworks.2 Among the transition-based systems in MRP 2019, the best-performing parser is the HIT-SCIR parser (Che et al., 2019), which is also the top-performing overall parser; in the factorisation-based family, the SJTU-NICT system (Li et al., 2019) performs best on DM; and among the composition-based submissions, the Saarland system (Donatelli et al., 2019) obtains the best PSD results. Table 1 shows the absolute output quality (in terms of MRP precision, recall, and F1 ) and the rankings of these systems on the PSD evaluation data, reproducing the official shared task results presented by Oepen et al. (2019). The Saarland parser, an extension of Lindemann et al. (2019), uses a compositional approach, employing the Apply–Modify Algebra of Groschwitz et al. (2017) to build semantic graphs through highly constrained combinations of smalle"
2020.lrec-1.234,P19-1450,0,0.120028,"the best-performing parser is the HIT-SCIR parser (Che et al., 2019), which is also the top-performing overall parser; in the factorisation-based family, the SJTU-NICT system (Li et al., 2019) performs best on DM; and among the composition-based submissions, the Saarland system (Donatelli et al., 2019) obtains the best PSD results. Table 1 shows the absolute output quality (in terms of MRP precision, recall, and F1 ) and the rankings of these systems on the PSD evaluation data, reproducing the official shared task results presented by Oepen et al. (2019). The Saarland parser, an extension of Lindemann et al. (2019), uses a compositional approach, employing the Apply–Modify Algebra of Groschwitz et al. (2017) to build semantic graphs through highly constrained combinations of smaller graph fragments. A BiLSTM sequence labeling model is used for semantic tagging of word tokens, and the BiLSTM ‘feature extractor’ architecture of Kiperwasser and Goldberg (2016) is employed for predicting dependency trees, with input representations combining ELMo 2 We use framework-specific performance on PSD and DM, rather than the overall ranking across frameworks within the shared task, as the selection criterion, given"
2020.lrec-1.234,D07-1013,1,0.852393,"structures make the parsing task much more complex—often moving from techniques with polynomial worst-case complexity to problems that are in principle NP-hard. Among other things, meaning representations transcend syntactic trees in allowing nodes with in-degree greater than one (‘reentrancies’), multiple roots, and ignoring semantically ‘vacuous’ parts of the parser input. Besides greatly increased modeling and algorithmic complexity, meaning representation parsing also poses its own set of methodological challenges for parser evaluation and diagnostics. The contrastive studies initiated by McDonald and Nivre (2007) and McDonald and Nivre (2011) have been influential in comparing the performance of two core types of approaches to syntactic dependency parsing, i.e. different families of parsing approaches. In this work, we investigate to what degree these techniques can be transferred to meaning representation parsing, and how they can be adapted and extended to reflect the formal and linguistic † We acknowledge and thank (Zhang and Clark, 2008) for inspiring our title. differences in the nature of target representations. We develop the blueprint of a general framework for quantitative diagnostic evaluati"
2020.lrec-1.234,J11-1007,1,0.442505,"sk much more complex—often moving from techniques with polynomial worst-case complexity to problems that are in principle NP-hard. Among other things, meaning representations transcend syntactic trees in allowing nodes with in-degree greater than one (‘reentrancies’), multiple roots, and ignoring semantically ‘vacuous’ parts of the parser input. Besides greatly increased modeling and algorithmic complexity, meaning representation parsing also poses its own set of methodological challenges for parser evaluation and diagnostics. The contrastive studies initiated by McDonald and Nivre (2007) and McDonald and Nivre (2011) have been influential in comparing the performance of two core types of approaches to syntactic dependency parsing, i.e. different families of parsing approaches. In this work, we investigate to what degree these techniques can be transferred to meaning representation parsing, and how they can be adapted and extended to reflect the formal and linguistic † We acknowledge and thank (Zhang and Clark, 2008) for inspiring our title. differences in the nature of target representations. We develop the blueprint of a general framework for quantitative diagnostic evaluation and experimentally seek to"
2020.lrec-1.234,S14-2056,1,0.833406,"ork comparison of different parsing approaches and to advance learning from complementary knowledge sources (e.g. via parameter sharing). The MRP 2019 competition received submissions from eighteen teams, and there will be a follow-up shared task, again hosted by CoNLL, in 2020. Figure 1 shows two example graphs for one sentence from the venerable Wall Street Journal (WSJ) corpus in the two bi-lexical MRP frameworks (of five total), DELPHIN MRS Bi-Lexical Dependencies (DM) of Oepen and Lønning (2006) and Ivanova et al. (2012), and Prague Semantic Dependencies (PSD) by Hajiˇc et al. (2012) and Miyao et al. (2014). The DM and PSD frameworks are bi-lexical in the MRP collection, characterized by a one-toone relation between graph nodes and surface tokens. But even within this limiting assumption, which makes these graphs formally somewhat similar to standard syntactic dependency trees, the examples in Figure 1 exhibit all the nontree properties sketched in § 1. above (reentrancies, multiple roots, and semantically vacuous surface tokens). DM and PSD nodes are labeled with lemmas, parts of speech, and (for verbs only, in the PSD case) frame or sense identifiers; jointly, these properties define a semanti"
2020.lrec-1.234,oepen-lonning-2006-discriminant,1,0.643309,"ected graphs, packaged in a uniform abstract structure and serialization. This task design seeks to enable cross-framework comparison of different parsing approaches and to advance learning from complementary knowledge sources (e.g. via parameter sharing). The MRP 2019 competition received submissions from eighteen teams, and there will be a follow-up shared task, again hosted by CoNLL, in 2020. Figure 1 shows two example graphs for one sentence from the venerable Wall Street Journal (WSJ) corpus in the two bi-lexical MRP frameworks (of five total), DELPHIN MRS Bi-Lexical Dependencies (DM) of Oepen and Lønning (2006) and Ivanova et al. (2012), and Prague Semantic Dependencies (PSD) by Hajiˇc et al. (2012) and Miyao et al. (2014). The DM and PSD frameworks are bi-lexical in the MRP collection, characterized by a one-toone relation between graph nodes and surface tokens. But even within this limiting assumption, which makes these graphs formally somewhat similar to standard syntactic dependency trees, the examples in Figure 1 exhibit all the nontree properties sketched in § 1. above (reentrancies, multiple roots, and semantically vacuous surface tokens). DM and PSD nodes are labeled with lemmas, parts of sp"
2020.lrec-1.234,S14-2008,1,0.942226,"Missing"
2020.lrec-1.234,L16-1630,1,0.874805,"Missing"
2020.lrec-1.234,K19-2001,1,0.908652,"Missing"
2020.lrec-1.234,N18-1202,0,0.219124,"a richer feature model, but degraded more because of error propagation in greedy decoding. Conversely, graph-based parsers showed a more graceful degradation thanks to global optimization and exact decoding, but had a disadvantage for local structures because of a more restricted feature model. More recently, Kulmizev et al. (2019) replicated this analysis for neural graph-based and transition-based parsers and showed that, although the distinct error profiles are still discernible, the differences are now much smaller and are further reduced by the use of deep contextualized word embeddings (Peters et al., 2018; Devlin et al., 2019). MRP 2019 The 2019 Shared Task at the Conference for Computational Language Learning (CoNLL) was devoted to Meaning Representation Parsing (MRP) across frameworks (Oepen et al., 2019). For the first time, this task combined formally and linguistically different approaches to meaning representation in graph form in a uniform training and evaluation setup. The training and evaluation data for the task comprised five distinct approaches— which all encode core predicate–argument structure, among other things—to the representation of sentence meaning in the form of directed g"
2020.lrec-1.234,D08-1059,0,0.0609159,"meaning representation parsing also poses its own set of methodological challenges for parser evaluation and diagnostics. The contrastive studies initiated by McDonald and Nivre (2007) and McDonald and Nivre (2011) have been influential in comparing the performance of two core types of approaches to syntactic dependency parsing, i.e. different families of parsing approaches. In this work, we investigate to what degree these techniques can be transferred to meaning representation parsing, and how they can be adapted and extended to reflect the formal and linguistic † We acknowledge and thank (Zhang and Clark, 2008) for inspiring our title. differences in the nature of target representations. We develop the blueprint of a general framework for quantitative diagnostic evaluation and experimentally seek to validate this proposal through a small-scale pilot study. The remainder of the paper is structured as follows: In § 2., we present the relevant background, including previous studies in syntactic parsing that provide our point of departure and the 2019 shared task on meaning representation parsing. § 3. gives a review of established dimensions of contrastive diagnostic evaluation for syntactic dependency"
2020.lrec-1.497,de-marneffe-etal-2006-generating,1,\N,Missing
2020.lrec-1.497,zeman-2008-reusable,1,\N,Missing
2020.lrec-1.497,de-marneffe-etal-2014-universal,1,\N,Missing
2020.lrec-1.497,W08-1301,1,\N,Missing
2020.lrec-1.497,petrov-etal-2012-universal,0,\N,Missing
2020.lrec-1.497,P13-1051,1,\N,Missing
2020.lrec-1.497,P15-2111,0,\N,Missing
2020.lrec-1.497,L16-1376,1,\N,Missing
2020.lrec-1.497,L16-1262,1,\N,Missing
2020.lrec-1.497,W18-6012,1,\N,Missing
2020.udw-1.20,L16-1682,0,0.0310118,"Missing"
2020.udw-1.20,L18-1412,0,0.0278535,"Missing"
2020.udw-1.20,W19-7713,1,0.839127,"ebank with full syntactic annotation, which means that it is hard to develop language technology applications that require both tagging and parsing. It is in this context that we have developed the first Universal Dependencies (UD) treebank for Albanian, called UD Albanian-TSA.2 Although still very limited in size, it constitutes a first step towards developing a large-scale treebank within the UD scheme, enabling NLP research as well as comparative studies involving other languages, and there is also research showing that even a few annotated sentences can contribute to good parsing results (Meechan-Maddon and Nivre, 2019). In the following sections we introduce some of the key features of the Albanian language (Section 2), provide a brief summary of related work with regard to NLP for Albanian (Section 3), and describe the steps taken to develop the treebank (Section 4). We then discuss in some detail a selection of linguistic constructions in Albanian that pose challenges for the UD annotation framework and that are interesting from a cross-linguistic perspective (Section 5). 2 The Albanian Language Albanian belongs to the Indo-European family of languages, but it constitutes its own branch within the family."
2020.udw-1.20,L16-1262,1,0.874517,"Missing"
2020.udw-1.20,2020.lrec-1.497,1,0.864352,"Missing"
2020.udw-1.20,W17-0413,0,0.0191849,"m with the analysis of English ought, which combines with a to-infinitive, and is analyzed with the same syntactic structure that we propose for the Albanian modal verbs. xcomp mark (23) duhet të shkoj must.3SG to go.1SG VERB PART VERB ‘I must go’ This analysis is parallel to constructions of modal-like verbs with verbal complements, e.g., shpresoj të kthehem (I hope to return) and therefore ensures a uniform analysis for all subjunctive constructions introduced by të. However, we note that similar constructions are not annotated consistently in all UD treebanks. For example, in Modern Greek (Prokopidis and Papageorgiou, 2017), the analysis of a construction with πρέπει prépei (must), which also takes the form of a subjunctive with a particle (να na), treats the second verb as the head and assigns the relation aux to both the modal verb and the particle. On the other hand, a drawback of the analysis that we propose for Albanian is that it calls for a different treatment of duhet in impersonal constructions, where duhet takes a past participle instead of a verb in subjunctive as a complement.17 An example of this is illustrated in (24). aux (24) duhet folur must.3SG spoken.PAST.PTCPL AUX VERB ‘it must be spoken’ The"
2020.udw-1.20,trommer-kallulli-2004-morphological,0,0.212581,"Missing"
2020.udw-1.20,W17-7604,0,0.0161685,"s, we have observed that the corpus of Kote et al. (2019) shows some variation in the tagging of ambiguous word forms. For example, the word të (to/of) appears both with PART and DET when occurring in verb groups, while our treebank only uses PART in this position.10 Similarly, the word që (that) appears with CCONJ, SCONJ and PRON when introducing relative clauses, while our treebank only uses PRON in this position. Most of these differences should be relatively easy to harmonize. 4.5 Syntactic Annotation The syntactic annotation was performed manually using the annotation tool UD Annotatrix (Tyers et al., 2017), a browser-based tool customized for manual annotation of dependency trees in UD. Applying the UD guidelines to Albanian turned out to be relatively straightforward for the majority of syntactic constructions. In the next section, we discuss some phenomena that gave rise to questions that may be of more general interest to the community. 5 Challenging Constructions 5.1 Core Arguments One of the fundamental questions when annotating a new language in UD is to determine criteria for distinguishing core arguments from oblique modifiers, including deciding whether there are more than two core arg"
2021.eacl-main.117,J13-1002,1,0.787985,"ive dependencies.9 Our implementation of this transition-based parsing model is based on the influential architecture of Kiperwasser and Goldberg (2016), which takes as input a sequence of vectors x1 , . . . , xn representing the input words w1 , . . . , wn and feeds these vectors through a BiLSTM that outputs contextu7 The English sentence in Figure 1 thus becomes: the dogthe chased the cat-the from the room-the-from. 8 Positioning the artificial root node at the end of the buffer is a modification of the original system by Kiperwasser and Goldberg (2016), inspired by the results reported in Ballesteros and Nivre (2013). 9 This extension of the arc-hybrid system was proposed by de Lhoneux et al. (2017b), inspired by the corresponding extension of the arc-standard system by Nivre (2009). alized word vectors v1 , . . . , vn , which are stored in the buffer B. Parsing is then performed by iteratively applying the transition predicted by an MLP taking as input a small number of contextualized word vectors from the stack S and the buffer B. More precisely, in the experiments reported in this paper, the predictions are based on the two top items s0 and s1 in S and the first item b0 in B. In a historical perspectiv"
2021.eacl-main.117,W07-2404,0,0.160395,"Missing"
2021.eacl-main.117,P93-1015,0,0.712824,"ion. As an alternative to the rule-based approach of J¨arvinen and Tapanainen (1998), Samuelsson (2000) defined a generative statistical model for nucleus-based dependency parsing, which however was never implemented. The nucleus concept has affinities with the chunk concept found in many approaches to parsing, starting with Abney (1991), who proposed to first find chunks and then dependencies between chunks, an idea that was generalized into cascaded parsing by Buchholz et al. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhone"
2021.eacl-main.117,W09-3812,0,0.052392,"the rule-based approach of J¨arvinen and Tapanainen (1998), Samuelsson (2000) defined a generative statistical model for nucleus-based dependency parsing, which however was never implemented. The nucleus concept has affinities with the chunk concept found in many approaches to parsing, starting with Abney (1991), who proposed to first find chunks and then dependencies between chunks, an idea that was generalized into cascaded parsing by Buchholz et al. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhoneux et al. (2019b) inves"
2021.eacl-main.117,W99-0629,0,0.195276,"iteria for headedness and that it is not only a syntactic primitive but also the smallest semantic unit in a lexicographical description. As an alternative to the rule-based approach of J¨arvinen and Tapanainen (1998), Samuelsson (2000) defined a generative statistical model for nucleus-based dependency parsing, which however was never implemented. The nucleus concept has affinities with the chunk concept found in many approaches to parsing, starting with Abney (1991), who proposed to first find chunks and then dependencies between chunks, an idea that was generalized into cascaded parsing by Buchholz et al. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix ("
2021.eacl-main.117,W16-6313,0,0.0174525,"chunks and then dependencies between chunks, an idea that was generalized into cascaded parsing by Buchholz et al. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhoneux et al. (2019b) investigate whether the hidden representations of a neural transition-based dependency parser encodes information about syntactic nuclei, with special reference to verb groups. They find some evidence that this is the case, especially if the parser is equipped with a mechanism for recursive subtree composition of the type first proposed by S"
2021.eacl-main.117,K17-3022,1,0.889015,"Missing"
2021.eacl-main.117,W17-6314,1,0.880405,"Missing"
2021.eacl-main.117,N19-1159,1,0.88763,"Missing"
2021.eacl-main.117,2020.cl-4.3,1,0.852174,"Missing"
2021.eacl-main.117,W14-6108,0,0.0166603,"many approaches to parsing, starting with Abney (1991), who proposed to first find chunks and then dependencies between chunks, an idea that was generalized into cascaded parsing by Buchholz et al. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhoneux et al. (2019b) investigate whether the hidden representations of a neural transition-based dependency parser encodes information about syntactic nuclei, with special reference to verb groups. They find some evidence that this is the case, especially if the parser is equipped with"
2021.eacl-main.117,P15-1033,0,0.0196639,"e transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhoneux et al. (2019b) investigate whether the hidden representations of a neural transition-based dependency parser encodes information about syntactic nuclei, with special reference to verb groups. They find some evidence that this is the case, especially if the parser is equipped with a mechanism for recursive subtree composition of the type first proposed by Stenetorp (2013) and later developed by Dyer et al. (2015) and de Lhoneux et al. (2019a). The idea is to use a composition operator that recursively combines information from subtrees connected by a dependency relation into a representation of the new larger subtree. In this paper, we will exploit variations of this technique to create parser-internal representations of syntactic nuclei, as discussed in Section 4. However, first we need to discuss how to identify nuclei in UD treebanks. 3 Syntactic Nuclei in UD UD1 (Nivre et al., 2016, 2020) is an ongoing project aiming to provide cross-linguistically consistent morphosyntactic annotation of many lan"
2021.eacl-main.117,P19-1012,0,0.0126487,", . . . , vn , which are stored in the buffer B. Parsing is then performed by iteratively applying the transition predicted by an MLP taking as input a small number of contextualized word vectors from the stack S and the buffer B. More precisely, in the experiments reported in this paper, the predictions are based on the two top items s0 and s1 in S and the first item b0 in B. In a historical perspective, this may seem like an overly simplistic prediction model, but recent work has shown that more complex feature vectors are largely superfluous thanks to the BiLSTM encoder (Shi et al., 2017; Falenska and Kuhn, 2019). The transition-based parser as described so far does not provide any mechanism for modeling the nucleus concept. It is a purely word-based model, where any more complex syntactic structure is represented internally by the contextualized vector of its head word. Specifically, when two substructures h and d are combined in a Left-Arc or Right-Arc transition, only the vector vh representing the syntactic head is retained in S or B, while the vector vd representing the syntactic dependent is removed from S. In order to make the parser sensitive to (dissociated) nuclei in its internal representat"
2021.eacl-main.117,W98-0501,0,0.634769,"Missing"
2021.eacl-main.117,Q16-1023,0,0.0825492,"configuration has all words w1 , . . . , wn plus an artificial root node r in B, while S and A are empty.8 There are four transitions: Shift, Left-Arc, Right-Arc and Swap. Shift pushes the first word b0 in B onto S (and is not permissible if b0 = r). Left-Arc attaches the top word s0 in S to b0 and removes s0 from S, while Right-Arc attaches s0 to the next word s1 in S and removes s0 from S. Swap, finally, moves s1 back to B in order to allow the construction of non-projective dependencies.9 Our implementation of this transition-based parsing model is based on the influential architecture of Kiperwasser and Goldberg (2016), which takes as input a sequence of vectors x1 , . . . , xn representing the input words w1 , . . . , wn and feeds these vectors through a BiLSTM that outputs contextu7 The English sentence in Figure 1 thus becomes: the dogthe chased the cat-the from the room-the-from. 8 Positioning the artificial root node at the end of the buffer is a modification of the original system by Kiperwasser and Goldberg (2016), inspired by the results reported in Ballesteros and Nivre (2013). 9 This extension of the arc-hybrid system was proposed by de Lhoneux et al. (2017b), inspired by the corresponding extensi"
2021.eacl-main.117,W02-2016,0,0.0366944,"apanainen (1998), Samuelsson (2000) defined a generative statistical model for nucleus-based dependency parsing, which however was never implemented. The nucleus concept has affinities with the chunk concept found in many approaches to parsing, starting with Abney (1991), who proposed to first find chunks and then dependencies between chunks, an idea that was generalized into cascaded parsing by Buchholz et al. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhoneux et al. (2019b) investigate whether the hidden representations of a"
2021.eacl-main.117,P11-1068,0,0.0858722,"Missing"
2021.eacl-main.117,W18-6010,0,0.0174896,"l. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhoneux et al. (2019b) investigate whether the hidden representations of a neural transition-based dependency parser encodes information about syntactic nuclei, with special reference to verb groups. They find some evidence that this is the case, especially if the parser is equipped with a mechanism for recursive subtree composition of the type first proposed by Stenetorp (2013) and later developed by Dyer et al. (2015) and de Lhoneux et al. (2019a). The idea is to use a"
2021.eacl-main.117,W03-3017,1,0.582299,"n the evaluation, whereas Nivre and Fang (2017) excluded it. tree, but where nuclei are explicitly represented by letting the word form for each nucleus core be a concatenation of all the word forms that are part of the nucleus.7 We call this oracle parsing to emphasize that the parser has oracle information about the nuclei of a sentence, although it still has to predict all the syntactic relations. 4 Syntactic Nuclei in Transition-Based Dependency Parsing A transition-based dependency parser derives a dependency tree from the sequence of words forming a sentence (Yamada and Matsumoto, 2003; Nivre, 2003, 2004). The parser constructs the tree incrementally by applying transitions, or parsing actions, to configurations consisting of a stack S of partially processed words, a buffer B of remaining input words, and a set of dependency arcs A representing the partially constructed dependency tree. The process of parsing starts from an initial configuration and ends when the parser reaches a terminal configuration. The transitions between configurations are predicted by a history-based model that combines information from S, B and A. For the experiments in this paper, we use a version of the arc-hy"
2021.eacl-main.117,W04-0308,1,0.598609,"Missing"
2021.eacl-main.117,P09-1040,1,0.600916,"of vectors x1 , . . . , xn representing the input words w1 , . . . , wn and feeds these vectors through a BiLSTM that outputs contextu7 The English sentence in Figure 1 thus becomes: the dogthe chased the cat-the from the room-the-from. 8 Positioning the artificial root node at the end of the buffer is a modification of the original system by Kiperwasser and Goldberg (2016), inspired by the results reported in Ballesteros and Nivre (2013). 9 This extension of the arc-hybrid system was proposed by de Lhoneux et al. (2017b), inspired by the corresponding extension of the arc-standard system by Nivre (2009). alized word vectors v1 , . . . , vn , which are stored in the buffer B. Parsing is then performed by iteratively applying the transition predicted by an MLP taking as input a small number of contextualized word vectors from the stack S and the buffer B. More precisely, in the experiments reported in this paper, the predictions are based on the two top items s0 and s1 in S and the first item b0 in B. In a historical perspective, this may seem like an overly simplistic prediction model, but recent work has shown that more complex feature vectors are largely superfluous thanks to the BiLSTM enc"
2021.eacl-main.117,W17-0411,1,0.82491,"t can deal with nucleus recognition, either in a preprocessing step or integrated with the construction of dependency trees, and such parsers are not (yet) available. Moreover, evaluation results would not be comparable to previous research. Therefore, we will make use of the nucleus concept in UD in three more indirect ways: • Evaluation: Even if a parser outputs a wordbased dependency tree in UD format, we can evaluate its accuracy on nucleus-based parsing by simply not scoring the functional relations. This is equivalent to the Content Labeled Attachment Score (CLAS) previously proposed by Nivre and Fang (2017), and we will use this score as a complement to the standard Labeled Attachment Score (LAS) in our experiments.6 • Nucleus Composition: Given our definition of nucleus-internal relations, we can make parsers aware of the nucleus concept by differentiating the way they predict and represent dissociated nuclei and dependency structures, respectively. More precisely, we will make use of composition operations to create internal representations of (dissociated) nuclei, as discussed in detail in Section 4 below. • Oracle Parsing: To establish an upper bound on what a nucleus-aware parser can achiev"
2021.eacl-main.117,L16-1262,1,0.868618,"Missing"
2021.eacl-main.117,2020.lrec-1.497,1,0.886405,"Missing"
2021.eacl-main.117,C00-2099,0,0.555749,"of Tesni`ere’s notion of nucleus, from the point of view of accuracy, interpretability and evaluation. We do this from a multilingual perspective, because it is likely that the effects of introducing nuclei will be different in different languages, and we strongly believe that a comparison between different languages is necessary in order to assess the potential usefulness of this notion. We are certainly not the first to propose that Tesni`ere’s notion of nucleus can be useful in parsing. One of the earliest formalizations of dependency grammar for the purpose of statistical parsing, that of Samuelsson (2000), had this notion at its core, and Sangati and Mazza (2009) presented a conversion of the Penn Treebank of English to Tesni`ere style obl obj det the DET nsubj dog NOUN Case=Nom NOUN koira case det chased VERB the DET VERB jahtasi nsubj det cat NOUN Case=Acc NOUN kissan from ADP the DET room NOUN Case=Ela NOUN huoneesta obj obl Figure 1: Word-based dependency trees for equivalent sentences from English (top) and Finnish (bottom). obl nsubj obj the dog chased the cat from the room koira jahtasi kissan huoneesta nsubj obj obl Figure 2: Nucleus-based dependency trees for equivalent sentences from"
2021.eacl-main.117,D17-1002,0,0.0121902,"ed word vectors v1 , . . . , vn , which are stored in the buffer B. Parsing is then performed by iteratively applying the transition predicted by an MLP taking as input a small number of contextualized word vectors from the stack S and the buffer B. More precisely, in the experiments reported in this paper, the predictions are based on the two top items s0 and s1 in S and the first item b0 in B. In a historical perspective, this may seem like an overly simplistic prediction model, but recent work has shown that more complex feature vectors are largely superfluous thanks to the BiLSTM encoder (Shi et al., 2017; Falenska and Kuhn, 2019). The transition-based parser as described so far does not provide any mechanism for modeling the nucleus concept. It is a purely word-based model, where any more complex syntactic structure is represented internally by the contextualized vector of its head word. Specifically, when two substructures h and d are combined in a Left-Arc or Right-Arc transition, only the vector vh representing the syntactic head is retained in S or B, while the vector vd representing the syntactic dependent is removed from S. In order to make the parser sensitive to (dissociated) nuclei i"
2021.eacl-main.117,K18-2011,1,0.866766,"Missing"
2021.eacl-main.117,C08-2031,0,0.0609421,"us-based dependency parsing, which however was never implemented. The nucleus concept has affinities with the chunk concept found in many approaches to parsing, starting with Abney (1991), who proposed to first find chunks and then dependencies between chunks, an idea that was generalized into cascaded parsing by Buchholz et al. (1999) among others. It is also clearly related to the vibhakti level in the Paninian computation grammar framework (Bharati and Sangal, 1993; Bharati et al., 2009). In a similar vein, Kudo and Matsumoto (2002) use cascaded chunking for dependency parsing of Japanese, Tongchim et al. (2008) show that base-NP chunking can significantly improve the accuracy of dependency parsing for Thai, and Durgar El-Kahlout et al. (2014) show that chunking improves dependency parsing of Turkish. Das et al. (2016) study the importance of chunking in the transfer parsing model between Hindi and Bengali, and Lacroix (2018) show that NP chunks are informative for universal part-of-speech tagging and dependency parsing. In a more recent study, de Lhoneux et al. (2019b) investigate whether the hidden representations of a neural transition-based dependency parser encodes information about syntactic nu"
2021.eacl-main.117,W03-3023,0,0.107359,"hat we include punctuation in the evaluation, whereas Nivre and Fang (2017) excluded it. tree, but where nuclei are explicitly represented by letting the word form for each nucleus core be a concatenation of all the word forms that are part of the nucleus.7 We call this oracle parsing to emphasize that the parser has oracle information about the nuclei of a sentence, although it still has to predict all the syntactic relations. 4 Syntactic Nuclei in Transition-Based Dependency Parsing A transition-based dependency parser derives a dependency tree from the sequence of words forming a sentence (Yamada and Matsumoto, 2003; Nivre, 2003, 2004). The parser constructs the tree incrementally by applying transitions, or parsing actions, to configurations consisting of a stack S of partially processed words, a buffer B of remaining input words, and a set of dependency arcs A representing the partially constructed dependency tree. The process of parsing starts from an initial configuration and ends when the parser reaches a terminal configuration. The transitions between configurations are predicted by a history-based model that combines information from S, B and A. For the experiments in this paper, we use a version"
2021.eacl-main.264,Q19-1004,0,0.0209175,"O:   Hi = Attention QWiQ , KWiK , V WiV (2) MHA(Q, K, V ) = concat(H1 , H2 , ..., Hk )W O (3) Every layer also consists of a feed-forward network (FFN), consisting of two Dense layers with ReLU activation functions. For each layer, therefore, the output of MHA is passed through a LayerNorm with residual connections, passed through FFN, and then through another LayerNorm with residual connections. Searching for structure Often, the line of inquiry regarding interpretability in NLP has been concerned with extracting and analyzing linguistic information from neural network models of language (Belinkov and Glass, 2019). Recently, such investigations have targeted Transformer models (Hewitt and Manning, 2019; Rosa and Mareˇcek, 2019; Tenney et al., 2019), at least in part because the self-attention mechanism employed by these models offers a possible window into their inner workings. With large-scale machine translation and language models being openly distributed for experimentation, several researchers have wondered if self-attention is capable of representing syntactic structure, despite not being trained with any overt parsing objective. In pursuit of this question, Raganato et al. (2018) applied a maxim"
2021.eacl-main.264,2020.acl-main.493,0,0.0162277,"Design To examine the extent to which we can decode dependency trees from attention patterns, we run a tree decoding algorithm over mBERT’s attention heads — before and after fine-tuning via a parsing objective. We surmise that doing so will enable us to determine if attention can be interpreted as a reliable mechanism for capturing linguistic structure. 3.1 Model We employ mBERT1 in our experiments, which has been shown to perform well across a variety of NLP tasks (Hu et al., 2020; Kondratyuk and Straka, 2019a) and capture aspects of syntactic structure cross-lingually (Pires et al., 2019; Chi et al., 2020). mBERT features 12 layers with 768 hidden units and 12 attention heads, with a joint WordPiece sub-word vocabulary across languages. The model was trained on the concatenation of WikiDumps for the top 104 languages with the largest Wikipedias,where principled sampling was employed to enforce a balance between high- and 1 https://github.com/google-research/ bert 3033 low-resource languages. 3.2 Decoding Algorithm For decoding dependency trees, we follow Raganato et al. (2018) in applying the Chu-LiuEdmonds maximum spanning tree algorithm (Chu, 1965) to every layer/head combination available in"
2021.eacl-main.264,W19-4828,0,0.35935,"such attention matrices to the score matrices employed in arc-factored dependency parsing (McDonald et al., 2005a,b), a salient question concerning interpretability becomes: Can we expect some combination of these parameters to capture linguistic structure in the form of a dependency tree, especially if the model performs well on NLP tasks? If not, can we relax the expectation and examine the extent to which subcomponents of the linguistic structure, such as subject-verb relations, are represented? This prospect was first posed by Raganato et al. (2018) for MT encoders, and later explored by Clark et al. (2019) for BERT. Ultimately, the consensus of these and other studies (Voita et al., 2019; Htut et al., 2019; Limisiewicz et al., 2020) was that, while there appears to exist no “generalist” head responsible for extracting full dependency structures, standalone heads often specialize in capturing individual grammatical relations. Unfortunately, most of such studies focused their 3031 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 3031–3045 April 19 - 23, 2021. ©2021 Association for Computational Linguistics experiments entirely on E"
2021.eacl-main.264,N19-1423,0,0.0343978,"tions track the same relations across languages? 3. How do attention patterns change after finetuning with explicit syntactic annotation? 4. Which components of the model are involved in these changes? In answering these questions, we believe we can shed further light on the (cross-)linguistic properties of Transformer-based language models, as well as address the question of attention patterns being a reliable representation of linguistic structure. 2 Attention as Structure Transformers The focus of the present study is mBERT, a multilingual variant of the exceedingly popular language model (Devlin et al., 2019). BERT is built upon the Transformer architecture (Vaswani et al., 2017b), which is a self-attentionbased encoder-decoder model (though only the encoder is relevant to our purposes). A Transformer takes a sequence of vectors x = [x1 , x2 , ...xn ] as input and applies a positional encoding to them, in order to retain the order of words in a sentence. These inputs are then transformed into query (Q), key (K), and value (V ) vectors via three separate linear transformations and passed to an attention mechanism. A single attention head computes scaled dot-product attention between K and Q, output"
2021.eacl-main.264,P81-1022,0,0.634003,"Missing"
2021.eacl-main.264,N19-1419,0,0.0240634,"O (3) Every layer also consists of a feed-forward network (FFN), consisting of two Dense layers with ReLU activation functions. For each layer, therefore, the output of MHA is passed through a LayerNorm with residual connections, passed through FFN, and then through another LayerNorm with residual connections. Searching for structure Often, the line of inquiry regarding interpretability in NLP has been concerned with extracting and analyzing linguistic information from neural network models of language (Belinkov and Glass, 2019). Recently, such investigations have targeted Transformer models (Hewitt and Manning, 2019; Rosa and Mareˇcek, 2019; Tenney et al., 2019), at least in part because the self-attention mechanism employed by these models offers a possible window into their inner workings. With large-scale machine translation and language models being openly distributed for experimentation, several researchers have wondered if self-attention is capable of representing syntactic structure, despite not being trained with any overt parsing objective. In pursuit of this question, Raganato et al. (2018) applied a maximum-spanning-tree algorithm over the attention weights of several trained MT models, compar"
2021.eacl-main.264,N19-1357,0,0.153929,"s entirely on English, which is typologically favored to succeed in such scenarios due to its rigid word order and lack of inflectional morphology. It remains to be seen whether the attention patterns of such models can capture structural features across typologically diverse languages, or if the reported experiments on English are a misrepresentation of local positional heuristics as such. Furthermore, though previous work has investigated how attention patterns might change after fine-tuning on different tasks (Htut et al., 2019), a recent debate about attention as an explanatory mechanism (Jain and Wallace, 2019; Wiegreffe and Pinter, 2019) has cast the entire enterprise in doubt. Indeed, it remains to be seen whether fine-tuning on an explicit structured prediction task, e.g. dependency parsing, can force attention to represent the structure being learned, or if the patterns observed in pretrained models are not altered in any meaningful way. To address these issues, we investigate the prospect of extracting linguistic structure from the attention weights of multilingual Transformerbased language models. In light of the surveyed literature, our research questions are as follows: 1. Can we decode dep"
2021.eacl-main.264,P04-1061,0,0.0967521,"input to be the element-wise product of a given attention matrix and its transpose (A ◦ A&gt; ). We liken this to the joint probability of a head attending to its dependent and a dependent attending to its head, similarly to Limisiewicz et al. (2020). Per this point, we also follow Htut et al. (2019) in evaluating the decoded trees via Undirected Unlabeled Attachment Score (UUAS) — the percentage of undirected edges recovered correctly. Since we discount directionality, this is effectively a less strict measure than UAS, but one that has a long tradition in unsupervised dependency parsing since Klein and Manning (2004). 3.3 Data For our data, we employ the Parallel Universal Dependencies (PUD) treebanks, as collected in UD v2.4 (Nivre et al., 2019). PUD was first released as part of the CONLL 2017 shared task (Zeman et al., 2018), containing 1000 parallel sentences, which were (professionally) translated from English, German, French, Italian, and Spanish to 14 other languages. The sentences are taken from two domains, news and wikipedia, the latter implying some overlap with mBERT’s training data (though we did not investigate this). We include all PUD treebanks except Thai.2 3.4 the exact tree structure we"
2021.eacl-main.264,D19-1279,0,0.380977,"hat attention weights cannot provide even a plausible explanation for models relying on syntax. 3 Experimental Design To examine the extent to which we can decode dependency trees from attention patterns, we run a tree decoding algorithm over mBERT’s attention heads — before and after fine-tuning via a parsing objective. We surmise that doing so will enable us to determine if attention can be interpreted as a reliable mechanism for capturing linguistic structure. 3.1 Model We employ mBERT1 in our experiments, which has been shown to perform well across a variety of NLP tasks (Hu et al., 2020; Kondratyuk and Straka, 2019a) and capture aspects of syntactic structure cross-lingually (Pires et al., 2019; Chi et al., 2020). mBERT features 12 layers with 768 hidden units and 12 attention heads, with a joint WordPiece sub-word vocabulary across languages. The model was trained on the concatenation of WikiDumps for the top 104 languages with the largest Wikipedias,where principled sampling was employed to enforce a balance between high- and 1 https://github.com/google-research/ bert 3033 low-resource languages. 3.2 Decoding Algorithm For decoding dependency trees, we follow Raganato et al. (2018) in applying the Chu"
2021.eacl-main.264,D19-1445,0,0.0224834,"e-tuning the entire mBERT network, we conducted a series of experiments, wherein we updated only select components of model and left the remainder frozen. Most surprisingly, we observed that the Transformer parameters designed for composing the attention matrix, K and Q, were only modestly capable of guiding the attention towards resembling the dependency structure. In contrast, it was the Value (V ) parameters, which are used for computing a weighted sum over the KQproduced attention, that yielded the most faithful representations of the linguistic structure via attention. Though prior work (Kovaleva et al., 2019; Zhao and Bethard, 2020) seems to indicate that there is a lack of a substantial change in attention patterns after fine-tuning on syntax- and semantics-oriented classification tasks, the opposite effect has been observed with fine-tuning on negation scope resolution, where a more explanatory attention mechanism can be induced (Htut et al., 2019). Our results are similar to the latter, and we demonstrate that given explicit syntactic annotation, attention weights do end up storing more transparently decodable structure. It is, however, still unclear which sets of transformer parameters are be"
2021.eacl-main.264,2020.acl-main.375,1,0.840291,"to training on concatenated PUD sets, however, our results are not directly comparable/ 3038 mBERT’s internal representations may play a role. Indeed, as we hypothesized in Section 3.2, it could be the case that the composition of CJK characters into gold tokens for Chinese and Japanese may degrade the representations (and their corresponding attention) therein. Furthermore, for Japanese and Korean specifically, it has been observed that tokenization strategies employed by different treebanks could drastically influence the conclusions one may draw about their inherent hierarchical structure (Kulmizev et al., 2020). Turkish and French are admittedly more difficult to diagnose. Note, however, that we fine-tuned our model on a concatenation of all PUD treebanks. As such, any deviation from PUD’s annotation norms is therefore likely to be heavily penalised, by virtue of signal from other languages drowning out these differences. 6 Conclusion In this study, we revisited the prospect of decoding dependency trees from the self-attention patterns of Transformer-based language models. We elected to extend our experiments to 18 languages in order to gain better insight about how tree decoding accuracy might be a"
2021.eacl-main.264,2020.emnlp-main.363,1,0.839093,"UERY, now seems to show a UUAS drop almost uniformly. This is also true for the completely unfrozen encoder. Supervised Parsing In addition to decoding trees from attention matrices, we also measure supervised UAS/LAS on a held-out test set.5 Based on Figure 4, it is apparent that all settings result 4 The inner average is over all heads; the outer is over all languages. 5 Note that the test set in our scenario is from the actual, non-parallel language treebank; as such, we left Korean out of this comparison due to annotation differences. in generally the same UAS. This is somewhat expected; Lauscher et al. (2020) see better results on parsing with the entire encoder frozen, implying that the task is easy enough for a biaffine parser to learn, given frozen mBERT representations.6 The LAS distinction is, however, rather interesting: there is a marked difference between how important the dense layers are, as opposed to the attentive components. This is likely not reflected in our UUAS probe as, strictly speaking, labelling arcs is not equivalent to searching for structure in sentences, but more akin to classifying pre-identified structures. We also note that D ENSE appears to be better than N ONE on aver"
2021.eacl-main.264,2020.findings-emnlp.245,0,0.0378293,"Missing"
2021.eacl-main.264,P05-1012,0,0.234401,"owing that the attention learned by their models reflects expected cross-lingual idiosyncrasies between English and French, e.g., concerning word order. With self-attentive Transformers, interpretation becomes slightly more difficult, as attention is distributed across words within the input itself. This is further compounded by the use of multiple layers and heads, each combination of which yields its own alignment, representing a different (possibly redundant) view of the data. Given the similarity of such attention matrices to the score matrices employed in arc-factored dependency parsing (McDonald et al., 2005a,b), a salient question concerning interpretability becomes: Can we expect some combination of these parameters to capture linguistic structure in the form of a dependency tree, especially if the model performs well on NLP tasks? If not, can we relax the expectation and examine the extent to which subcomponents of the linguistic structure, such as subject-verb relations, are represented? This prospect was first posed by Raganato et al. (2018) for MT encoders, and later explored by Clark et al. (2019) for BERT. Ultimately, the consensus of these and other studies (Voita et al., 2019; Htut et a"
2021.eacl-main.264,H05-1066,0,0.53079,"Missing"
2021.eacl-main.264,2020.lrec-1.497,1,0.867817,"Missing"
2021.eacl-main.264,P19-1493,0,0.0214993,"ntax. 3 Experimental Design To examine the extent to which we can decode dependency trees from attention patterns, we run a tree decoding algorithm over mBERT’s attention heads — before and after fine-tuning via a parsing objective. We surmise that doing so will enable us to determine if attention can be interpreted as a reliable mechanism for capturing linguistic structure. 3.1 Model We employ mBERT1 in our experiments, which has been shown to perform well across a variety of NLP tasks (Hu et al., 2020; Kondratyuk and Straka, 2019a) and capture aspects of syntactic structure cross-lingually (Pires et al., 2019; Chi et al., 2020). mBERT features 12 layers with 768 hidden units and 12 attention heads, with a joint WordPiece sub-word vocabulary across languages. The model was trained on the concatenation of WikiDumps for the top 104 languages with the largest Wikipedias,where principled sampling was employed to enforce a balance between high- and 1 https://github.com/google-research/ bert 3033 low-resource languages. 3.2 Decoding Algorithm For decoding dependency trees, we follow Raganato et al. (2018) in applying the Chu-LiuEdmonds maximum spanning tree algorithm (Chu, 1965) to every layer/head combi"
2021.eacl-main.264,W18-5431,0,0.0260543,"Missing"
2021.eacl-main.264,P19-1282,0,0.0246737,"f whether it can be seen as a “faithful” explanation of model predictions has been subject to much recent debate. For example, Jain and Wallace (2019) present compelling arguments that attention does not offer a faithful explanation of predictions. Primarily, they demonstrate that there is little correlation between standard feature importance measures and attention weights. Furthermore, they contend that there exist counterfactual attention distributions, which are substantially different from learned attention weights but that do not alter a model’s predictions. Using a similar methodology, Serrano and Smith (2019) corroborate that attention does not provide an adequate account of an input component’s importance. In response to these findings, Wiegreffe and Pinter (2019) question the assumptions underlying such claims. Attention, they argue, is not a primitive, i.e., it cannot be detached from the rest of a model’s components as is done in the experiments of Jain and Wallace (2019). They propose a set of four analyses to test whether a given model’s attention mechanism can provide meaningful explanation and demonstrate that the alternative attention distributions found via adversarial training methods d"
2021.eacl-main.264,D18-1548,0,0.0596304,"Missing"
2021.eacl-main.264,K18-2001,1,0.819166,"to Limisiewicz et al. (2020). Per this point, we also follow Htut et al. (2019) in evaluating the decoded trees via Undirected Unlabeled Attachment Score (UUAS) — the percentage of undirected edges recovered correctly. Since we discount directionality, this is effectively a less strict measure than UAS, but one that has a long tradition in unsupervised dependency parsing since Klein and Manning (2004). 3.3 Data For our data, we employ the Parallel Universal Dependencies (PUD) treebanks, as collected in UD v2.4 (Nivre et al., 2019). PUD was first released as part of the CONLL 2017 shared task (Zeman et al., 2018), containing 1000 parallel sentences, which were (professionally) translated from English, German, French, Italian, and Spanish to 14 other languages. The sentences are taken from two domains, news and wikipedia, the latter implying some overlap with mBERT’s training data (though we did not investigate this). We include all PUD treebanks except Thai.2 3.4 the exact tree structure we aim to decode. To this end, we employ the graph-based decoding algorithm of the biaffine parser introduced by Dozat and Manning (2016). We replace the standard BiLSTM encoder for this parser with the entire mBERT n"
2021.eacl-main.264,2020.acl-main.429,0,0.0374127,"RT network, we conducted a series of experiments, wherein we updated only select components of model and left the remainder frozen. Most surprisingly, we observed that the Transformer parameters designed for composing the attention matrix, K and Q, were only modestly capable of guiding the attention towards resembling the dependency structure. In contrast, it was the Value (V ) parameters, which are used for computing a weighted sum over the KQproduced attention, that yielded the most faithful representations of the linguistic structure via attention. Though prior work (Kovaleva et al., 2019; Zhao and Bethard, 2020) seems to indicate that there is a lack of a substantial change in attention patterns after fine-tuning on syntax- and semantics-oriented classification tasks, the opposite effect has been observed with fine-tuning on negation scope resolution, where a more explanatory attention mechanism can be induced (Htut et al., 2019). Our results are similar to the latter, and we demonstrate that given explicit syntactic annotation, attention weights do end up storing more transparently decodable structure. It is, however, still unclear which sets of transformer parameters are best suited for learning th"
2021.eacl-main.264,D18-1412,0,0.0195081,"same fashion as described in Section 3.2. We surmise that, if attention heads are capable of tracking hierarchical relations between words in any capacity, it is precisely in this setting that this ability would be attested. In addition to this, we are interested in what individual components of the mBERT network are capable of steering attention patterns towards syntactic structure. We believe that addressing this question will help us not only in interpreting decisions made by BERT-based neural parsers, but also in aiding us developing syntax-aware models in general (Strubell et al., 2018; Swayamdipta et al., 2018). As such — beyond fine-tuning all parameters of the mBERT network (our basic setting) — we perform a series of ablation experiments wherein we update only one set of parameters per training cycle, e.g. the Query weights WiQ , and leave everything else frozen. This gives us a set of 6 models, which are described below. For each model, all non-BERT parser components are always left unfrozen. Fine-Tuning Details In addition to exploring pretrained mBERT’s attention weights, we are also interested in how attention might be guided by a training objective that learns 2 Thai is the only treebank tha"
2021.eacl-main.264,P19-1452,0,0.0637448,"Missing"
2021.eacl-main.264,P19-1580,0,0.0785703,"arsing (McDonald et al., 2005a,b), a salient question concerning interpretability becomes: Can we expect some combination of these parameters to capture linguistic structure in the form of a dependency tree, especially if the model performs well on NLP tasks? If not, can we relax the expectation and examine the extent to which subcomponents of the linguistic structure, such as subject-verb relations, are represented? This prospect was first posed by Raganato et al. (2018) for MT encoders, and later explored by Clark et al. (2019) for BERT. Ultimately, the consensus of these and other studies (Voita et al., 2019; Htut et al., 2019; Limisiewicz et al., 2020) was that, while there appears to exist no “generalist” head responsible for extracting full dependency structures, standalone heads often specialize in capturing individual grammatical relations. Unfortunately, most of such studies focused their 3031 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 3031–3045 April 19 - 23, 2021. ©2021 Association for Computational Linguistics experiments entirely on English, which is typologically favored to succeed in such scenarios due to its rigi"
2021.eacl-main.264,D19-1002,0,0.112922,"hich is typologically favored to succeed in such scenarios due to its rigid word order and lack of inflectional morphology. It remains to be seen whether the attention patterns of such models can capture structural features across typologically diverse languages, or if the reported experiments on English are a misrepresentation of local positional heuristics as such. Furthermore, though previous work has investigated how attention patterns might change after fine-tuning on different tasks (Htut et al., 2019), a recent debate about attention as an explanatory mechanism (Jain and Wallace, 2019; Wiegreffe and Pinter, 2019) has cast the entire enterprise in doubt. Indeed, it remains to be seen whether fine-tuning on an explicit structured prediction task, e.g. dependency parsing, can force attention to represent the structure being learned, or if the patterns observed in pretrained models are not altered in any meaningful way. To address these issues, we investigate the prospect of extracting linguistic structure from the attention weights of multilingual Transformerbased language models. In light of the surveyed literature, our research questions are as follows: 1. Can we decode dependency trees for some langua"
A97-1040,H92-1022,0,0.0227939,"nowledge"" of the system simply by adding more examples: if they contain ""new"" structures, the knowledge base is extended; if they mirror existing examples, the system still benefits since the evidence for one interpretation or another is thereby strengthened. 4.2 The matching algorithm The matcher, which has been developed from one first used in the MEG project ( S o m e r s e t al., 1994), processes the new text in a linear fashion, having first divided it into manageable portions, on the basis of punctuation, lay-out, formatting and so on. The input is tagged, using a standard tagger, e.g. (Brill, 1992). There is no need to train the tagger on our text type, because the actual tags do not matter, as long as tagging is consistent. The matching process then involves ""sliding"" one phrase past the other, identifying ""strong"" matches (word and tag) or ""weak"" (tag only) matches, and allowing for gaps in the match, in a method not unlike dynamic programming. The matches are then scored accordingly. The result is a set of possible matches linked to correctly filled schemas, so that even previously unseen words can normally be correctly assigned to the appropriate slot. The approach is not without it"
A97-1040,W96-0411,0,0.0264887,"hat cannedtext approaches, template-based approaches and g r a m m a r - b a s e d approaches to natural language generation - while they are often contrasted - m a y in fact be regarded as different points on a scale, from the very specific to the very general. In a sense, templates are just generalized canned texts, and grammars are just generalized templates. Indeed, the possibility of combining these different modes of generation has recently been highlighted as one of the keys to efficient use of natural language generation techniques in practical applications (van Noord & Neumann, 1996; Busemann, 1996). 6.3 high-level text structuring, such as assembling paragraphs into documents. ""The basic idea is to use hypertext mechanisms to enable users to dynamically select the paragraphs they wish to read, and therefore in essence perform their own high-level textplanning"" (P~eiter & Mellish, 1993), p.3. Second, but related to the first point, the hypertext capabilities are also a mild form of tailoring to the needs of different users. Users are expected to explore only links containing information that they need. Hypertext is generated by means of rules t h a t are very similar to the g r a m m a r"
A97-1040,A94-1001,0,0.0684236,"Missing"
A97-1040,1996.amta-1.19,0,0.0174632,"middeling en Beroepsopleiding), Mick Riley (Newcastle upon Tyne City Council), and Teresa Paskiewicz and Mark Stairmand (UMIST). The URL for the project's web site is h t t p ://www.mari. co. u k / t r e e / . 269 T R E E therefore offers two significant services: intelligent search and summarization on the one hand, and these independent of the original language of the job ad on the other. It could be argued that the latter at least could be achieved by hooking a commercial Machine Translation (MT) system up to an Internet employment service. Although MT has had some success on the Internet (Flanagan, 1996), this is with largely sympathetic users who understand well the limitations of MT. Its use for a more delicate task aimed at the general public, especially a public which is not necessarily highly educated, is certainly out of the question, for well known reasons which we need not explore here. Suffice to say that an experiment in Canada using an M T system for precisely this application (Murray, 1989) was far from successful. It is also apparent that for many jobs in a location where a different language is spoken, sufficient linguistic knowledge at least to read an ad for a job in that regi"
A97-1040,X93-1015,0,0.0623927,"Missing"
A97-1040,W98-1400,0,0.212343,"Missing"
A97-1040,C90-1014,0,0.0774551,"Missing"
A97-1040,J96-4008,0,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,N07-1050,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,D07-1013,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,W04-2407,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,D07-1097,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,nivre-etal-2006-maltparser,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,E12-2012,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,W06-2920,0,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,W04-0308,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,W09-3811,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,W02-1002,0,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,J08-4003,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,P05-1012,0,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,C10-1093,0,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,P09-1040,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,P06-1055,0,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,W06-2932,0,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,P05-1013,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,D07-1096,1,\N,Missing
ballesteros-nivre-2012-maltoptimizer-system,W03-3017,1,\N,Missing
bosco-etal-2010-comparing,W06-2920,0,\N,Missing
bosco-etal-2010-comparing,W08-1004,0,\N,Missing
bosco-etal-2010-comparing,P07-1122,1,\N,Missing
bosco-etal-2010-comparing,P09-1008,0,\N,Missing
bosco-etal-2010-comparing,D07-1096,1,\N,Missing
C04-1010,H92-1026,0,0.0190023,"d only if it is connected (Nivre, 2003). Otherwise, it is a set of connected components, each of which is a well-formed dependency graph for a substring of the original input. The transition system defined above is nondeterministic in itself, since several transitions can often be applied in a given configuration. To construct deterministic parsers based on this system, we use classifiers trained on treebank data in order to predict the next transition (and dependency type) given the current configuration of the parser. In this way, our approach can be seen as a form of history-based parsing (Black et al., 1992; Magerman, 1995). In the experiments reported here, we use memory-based learning to train our classifiers. 3 Memory-Based Learning Memory-based learning and problem solving is based on two fundamental principles: learning is the simple storage of experiences in memory, and solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans, 1999). It is inspired by the nearest neighbor approach in statistical pattern recognition and artificial intelligence (Fix and Hodges, 1952), as well as the analogical modeling approach in linguistics (Skousen, 1989; S"
C04-1010,A00-2031,0,0.0159856,"Missing"
C04-1010,A00-2018,0,0.839681,"English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al., 2004). For English, the interest in dependency parsing has been weaker than for other languages. To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank (Marcus et al., 1993), is annotated primarily with constituent analysis. On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) and Charniak (2000), use statistical models for disambiguation that make crucial use of dependency relations. Moreover, the deterministic dependency parser of Yamada and Matsumoto (2003), when trained on the Penn Treebank, gives a dependency accuracy that is almost as good as that of Collins (1997) and Charniak (2000). The parser described in this paper is similar to that of Yamada and Matsumoto (2003) in that it uses a deterministic parsing algorithm in combination with a classifier induced from a treebank. However, there are also important differences between the two approaches. First of all, whereas Yamada an"
C04-1010,P99-1065,0,0.256251,"Missing"
C04-1010,P96-1025,0,0.0517947,"ctions 2–21 3 Given the parsing algorithm, N can never have a head or a right dependent in the current configuration. 4 In TiMBL, the value of k in fact refers to k nearest distances rather than k nearest neighbors, which means that, even with k = 1, the nearest neighbor set can contain several instances that are equally distant to the test instance. This is different from the original IB 1 algorithm, as described in Aha et al. (1991). used for training and section 23 for testing (Collins, 1999; Charniak, 2000). The data has been converted to dependency trees using head rules (Magerman, 1995; Collins, 1996). We are grateful to Yamada and Matsumoto for letting us use their rule set, which is a slight modification of the rules used by Collins (1999). This permits us to make exact comparisons with the parser of Yamada and Matsumoto (2003), but also the parsers of Collins (1997) and Charniak (2000), which are evaluated on the same data set in Yamada and Matsumoto (2003). One problem that we had to face is that the standard conversion of phrase structure trees to dependency trees gives unlabeled dependency trees, whereas our parser requires labeled trees. Since the annotation scheme of the Penn Treeb"
C04-1010,P97-1003,0,0.706973,"Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al., 2004). For English, the interest in dependency parsing has been weaker than for other languages. To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank (Marcus et al., 1993), is annotated primarily with constituent analysis. On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) and Charniak (2000), use statistical models for disambiguation that make crucial use of dependency relations. Moreover, the deterministic dependency parser of Yamada and Matsumoto (2003), when trained on the Penn Treebank, gives a dependency accuracy that is almost as good as that of Collins (1997) and Charniak (2000). The parser described in this paper is similar to that of Yamada and Matsumoto (2003) in that it uses a deterministic parsing algorithm in combination with a classifier induced from a treebank. However, there are also important differences between the two approaches. First of al"
C04-1010,C96-1058,0,0.891701,"complexity of the algorithm used here is linear in the size of the input, while the algorithm of Yamada and Matsumoto is quadratic in the worst case. Another difference is that Yamada and Matsumoto use support vector machines (Vapnik, 1995), while we instead rely on memory-based learning (Daelemans, 1999). Most importantly, however, the parser presented in this paper constructs labeled dependency graphs, i.e. dependency graphs where arcs are labeled with dependency types. As far as we know, this makes it different from all previous systems for dependency parsing applied to the Penn Treebank (Eisner, 1996; Yamada and Matsumoto, 2003), although there are systems that extract labeled grammatical relations based on shallow parsing, e.g. Buchholz (2002). The fact that we are working with labeled dependency graphs is also one of the motivations for choosing memory-based learning over support vector machines, since we require a multi-class classifier. Even though it is possible to use SVM for multi-class classification, this can get cumbersome when the number of classes is large. (For the DEP   VP   DEP ?  ADVP NP - SBJ   ? The finger-pointing ? has already ? ? begun . Figure 1: Dependency"
C04-1010,W00-1303,0,0.0172052,"sis in recent years. One important reason seems to be that dependency parsing offers a good compromise between the conflicting demands of analysis depth, on the one hand, and robustness and efficiency, on the other. Thus, whereas a complete dependency structure provides a fully disambiguated analysis of a sentence, this analysis is typically less complex than in frameworks based on constituent analysis and can therefore often be computed deterministically with reasonable accuracy. Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al., 2004). For English, the interest in dependency parsing has been weaker than for other languages. To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank (Marcus et al., 1993), is annotated primarily with constituent analysis. On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) an"
C04-1010,P95-1037,0,0.620798,"ected (Nivre, 2003). Otherwise, it is a set of connected components, each of which is a well-formed dependency graph for a substring of the original input. The transition system defined above is nondeterministic in itself, since several transitions can often be applied in a given configuration. To construct deterministic parsers based on this system, we use classifiers trained on treebank data in order to predict the next transition (and dependency type) given the current configuration of the parser. In this way, our approach can be seen as a form of history-based parsing (Black et al., 1992; Magerman, 1995). In the experiments reported here, we use memory-based learning to train our classifiers. 3 Memory-Based Learning Memory-based learning and problem solving is based on two fundamental principles: learning is the simple storage of experiences in memory, and solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans, 1999). It is inspired by the nearest neighbor approach in statistical pattern recognition and artificial intelligence (Fix and Hodges, 1952), as well as the analogical modeling approach in linguistics (Skousen, 1989; Skousen, 1992). In"
C04-1010,J93-2004,0,0.038941,"Missing"
C04-1010,W04-2407,1,0.634041,"between the conflicting demands of analysis depth, on the one hand, and robustness and efficiency, on the other. Thus, whereas a complete dependency structure provides a fully disambiguated analysis of a sentence, this analysis is typically less complex than in frameworks based on constituent analysis and can therefore often be computed deterministically with reasonable accuracy. Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al., 2004). For English, the interest in dependency parsing has been weaker than for other languages. To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank (Marcus et al., 1993), is annotated primarily with constituent analysis. On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) and Charniak (2000), use statistical models for disambiguation that make crucial use of dependency"
C04-1010,W03-3017,1,0.944081,"en trained on the Penn Treebank, gives a dependency accuracy that is almost as good as that of Collins (1997) and Charniak (2000). The parser described in this paper is similar to that of Yamada and Matsumoto (2003) in that it uses a deterministic parsing algorithm in combination with a classifier induced from a treebank. However, there are also important differences between the two approaches. First of all, whereas Yamada and Matsumoto employs a strict bottom-up algorithm (essentially shift-reduce parsing) with multiple passes over the input, the present parser uses the algorithm proposed in Nivre (2003), which combines bottomup and top-down processing in a single pass in order to achieve incrementality. This also means that the time complexity of the algorithm used here is linear in the size of the input, while the algorithm of Yamada and Matsumoto is quadratic in the worst case. Another difference is that Yamada and Matsumoto use support vector machines (Vapnik, 1995), while we instead rely on memory-based learning (Daelemans, 1999). Most importantly, however, the parser presented in this paper constructs labeled dependency graphs, i.e. dependency graphs where arcs are labeled with dependen"
C04-1010,J03-4001,0,0.017939,"ing offers a good compromise between the conflicting demands of analysis depth, on the one hand, and robustness and efficiency, on the other. Thus, whereas a complete dependency structure provides a fully disambiguated analysis of a sentence, this analysis is typically less complex than in frameworks based on constituent analysis and can therefore often be computed deterministically with reasonable accuracy. Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al., 2004). For English, the interest in dependency parsing has been weaker than for other languages. To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank (Marcus et al., 1993), is annotated primarily with constituent analysis. On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) and Charniak (2000), use statistical models for disambiguation th"
C04-1010,H92-1086,0,0.0217108,"2; Magerman, 1995). In the experiments reported here, we use memory-based learning to train our classifiers. 3 Memory-Based Learning Memory-based learning and problem solving is based on two fundamental principles: learning is the simple storage of experiences in memory, and solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans, 1999). It is inspired by the nearest neighbor approach in statistical pattern recognition and artificial intelligence (Fix and Hodges, 1952), as well as the analogical modeling approach in linguistics (Skousen, 1989; Skousen, 1992). In machine learning terms, it can be characterized as a lazy learning method, since it defers processing of input until needed and processes input by combining stored data (Aha, 1997). Memory-based learning has been successfully applied to a number of problems in natural language processing, such as grapheme-to-phoneme conversion, part-of-speech tagging, prepositional-phrase attachment, and base noun phrase chunking (Daelemans et al., 2002). Previous work on memory-based learning for deterministic parsing includes Veenstra and Daelemans (2000) and Nivre et al. (2004). For the experiments rep"
C04-1010,W03-3023,0,0.793139,"eason seems to be that dependency parsing offers a good compromise between the conflicting demands of analysis depth, on the one hand, and robustness and efficiency, on the other. Thus, whereas a complete dependency structure provides a fully disambiguated analysis of a sentence, this analysis is typically less complex than in frameworks based on constituent analysis and can therefore often be computed deterministically with reasonable accuracy. Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al., 2004). For English, the interest in dependency parsing has been weaker than for other languages. To some extent, this can probably be explained by the strong tradition of constituent analysis in Anglo-American linguistics, but this trend has been reinforced by the fact that the major treebank of American English, the Penn Treebank (Marcus et al., 1993), is annotated primarily with constituent analysis. On the other hand, the best available parsers trained on the Penn Treebank, those of Collins (1997) and Charniak (2000), use statistical mod"
C04-1010,J03-4003,0,\N,Missing
C04-1010,P93-1005,0,\N,Missing
C08-1081,H92-1026,0,0.105017,"ndency parsing, based on a transition-based parsing model (McDonald and Nivre, 2007). More precisely, the approach is based on four essential components: Parser actions are predicted using a history-based feature model (section 3.2) and SVM classifiers (section 3.3). Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4). 3.2 History-based parsing models rely on features of the derivation history to predict the next parser action (Black et al., 1992). The features used are all symbolic and defined in terms of five different node attributes: • A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time (Nivre, 2003). • History-based feature models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997). • Discriminative classifiers for mapping histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003). • Pseudo-projective parsing for recovering nonprojective structures (Nivre and Nilsson, 2005). In the following subsections, we bri"
C08-1081,C00-2143,1,0.769917,"ndency annotation, but have been obtained through conversion from other kinds of annotation. And the data sets that do come with original dependency annotation are generally fairly small, with less than 100,000 words available for training, the notable exception of course being the Prague Dependency Treebank of Czech (Hajiˇc et al., 2001), which is one of the largest and most widely used treebanks in the field. This paper contributes to the growing literature on dependency parsing for typologically diverse languages by presenting the first results on parsing the Russian treebank S YN TAG RUS (Boguslavsky et al., 2000; Boguslavsky et al., 2002). There are several factors that make this treebank an interesting resource in this context. First of all, it contains a genuine dependency annotation, theoretically grounded in the long tradition of dependency grammar for Slavic languages, represented by the work of Tesni`ere (1959) and Mel’ˇcuk (1988), among others. Secondly, with close to 641 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 641–648 Manchester, August 2008 500,000 tokens, the treebank is larger than most other available dependency treebanks and prov"
C08-1081,boguslavsky-etal-2002-development,1,0.82638,"e been obtained through conversion from other kinds of annotation. And the data sets that do come with original dependency annotation are generally fairly small, with less than 100,000 words available for training, the notable exception of course being the Prague Dependency Treebank of Czech (Hajiˇc et al., 2001), which is one of the largest and most widely used treebanks in the field. This paper contributes to the growing literature on dependency parsing for typologically diverse languages by presenting the first results on parsing the Russian treebank S YN TAG RUS (Boguslavsky et al., 2000; Boguslavsky et al., 2002). There are several factors that make this treebank an interesting resource in this context. First of all, it contains a genuine dependency annotation, theoretically grounded in the long tradition of dependency grammar for Slavic languages, represented by the work of Tesni`ere (1959) and Mel’ˇcuk (1988), among others. Secondly, with close to 641 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 641–648 Manchester, August 2008 500,000 tokens, the treebank is larger than most other available dependency treebanks and provides a good basis for exper"
C08-1081,P05-1013,1,0.832741,"aining phantom nodes and 631 phantom nodes in total. 3 MaltParser MaltParser (Nivre et al., 2007b) is a languageindependent system for data-driven dependency parsing, based on a transition-based parsing model (McDonald and Nivre, 2007). More precisely, the approach is based on four essential components: Parser actions are predicted using a history-based feature model (section 3.2) and SVM classifiers (section 3.3). Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4). 3.2 History-based parsing models rely on features of the derivation history to predict the next parser action (Black et al., 1992). The features used are all symbolic and defined in terms of five different node attributes: • A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time (Nivre, 2003). • History-based feature models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997). • Discriminative classifiers for mapping histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Mat"
C08-1081,W06-2920,0,0.0817321,"e growing interest is apparently the belief that dependencybased representations should be more suitable for languages that exhibit free or flexible word order and where most of the clues to syntactic structure are found in lexical and morphological features, rather than in syntactic categories and word order configurations. Some support for this view can be found in the results from the CoNLL shared tasks on dependency parsing in 2006 and 2007, where a variety of data-driven methods for dependency parsing have been applied with encouraging results to languages of great typological diversity (Buchholz and Marsi, 2006; Nivre et al., 2007a). However, there are still important differences in parsing accuracy for different language types. For © Joakim Nivre, Igor M. Boguslavsky, and Leonid L. Iomdin, 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. example, Nivre et al. (2007a) observe that the languages included in the 2007 CoNLL shared task can be divided into three distinct groups with respect to top accuracy scores, with relatively low accuracy for richly inflected languages like"
C08-1081,W03-3017,1,0.608046,"tion 3.2) and SVM classifiers (section 3.3). Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4). 3.2 History-based parsing models rely on features of the derivation history to predict the next parser action (Black et al., 1992). The features used are all symbolic and defined in terms of five different node attributes: • A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time (Nivre, 2003). • History-based feature models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997). • Discriminative classifiers for mapping histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003). • Pseudo-projective parsing for recovering nonprojective structures (Nivre and Nilsson, 2005). In the following subsections, we briefly describe each of these four components in turn. 3.1 Parsing Algorithm The parser uses the deterministic algorithm for labeled dependency parsing first proposed by Nivre (2003). The algorithm builds a labeled dep"
C08-1081,H05-1100,0,0.115567,"t were correct, while the recall is the percentage of true non-projective dependencies that were correctly predicted by the parser. 646 and Dubey (2003). Summing up, the main result of the experimental evaluation is that both morphological and lexical features are crucial for attaining high accuracy when training and evaluating on the representations found in the S YN TAG RUS treebank of Russian. With regard to morphological features this is in line with a number of recent studies showing the importance of morphology for parsing languages with less rigid word order, including work on Spanish (Cowan and Collins, 2005), Hebrew (Tsarfaty, 2006; Tsarfaty and Sima’an, 2007), Turkish (Eryigit et al., 2006), and Swedish (Øvrelid and Nivre, 2007). With regard to lexical features, the situation is more complex in that there are a number of studies questioning the usefulness of lexical features in statistical parsing and arguing that equivalent or better results can be achieved with unlexicalized models provided that linguistic categories can be split flexibly into more fine-grained categories, either using hand-crafted splits, as in the seminal work of Klein and Manning (2003), or using hidden variables and unsupe"
C08-1081,P03-1055,0,0.0319107,"Missing"
C08-1081,P03-1013,0,0.0103688,"are a number of studies questioning the usefulness of lexical features in statistical parsing and arguing that equivalent or better results can be achieved with unlexicalized models provided that linguistic categories can be split flexibly into more fine-grained categories, either using hand-crafted splits, as in the seminal work of Klein and Manning (2003), or using hidden variables and unsupervised learning, as in the more recent work by Petrov et al. (2006), among others. There are even studies showing that lexicalization can be harmful when parsing richly inflected languages like German (Dubey and Keller, 2003) and Turkish (Eryi˘git and Oflazer, 2006). However, it is worth noting that most of these results have been obtained either for models of constituency-based parsing or for models of dependency parsing suffering from sparse data.4 In the experiments presented here, we have used a transition-based model for dependency parsing that has much fewer parameters than state-of-theart probabilistic models for constituency parsing. Moreover, we have been able to use a relatively large training set, thereby minimizing the effect of sparseness for lexical features. We therefore conjecture that the benefici"
C08-1081,E06-1012,0,0.0260662,"Missing"
C08-1081,P03-1054,0,0.00818323,"ord order, including work on Spanish (Cowan and Collins, 2005), Hebrew (Tsarfaty, 2006; Tsarfaty and Sima’an, 2007), Turkish (Eryigit et al., 2006), and Swedish (Øvrelid and Nivre, 2007). With regard to lexical features, the situation is more complex in that there are a number of studies questioning the usefulness of lexical features in statistical parsing and arguing that equivalent or better results can be achieved with unlexicalized models provided that linguistic categories can be split flexibly into more fine-grained categories, either using hand-crafted splits, as in the seminal work of Klein and Manning (2003), or using hidden variables and unsupervised learning, as in the more recent work by Petrov et al. (2006), among others. There are even studies showing that lexicalization can be harmful when parsing richly inflected languages like German (Dubey and Keller, 2003) and Turkish (Eryi˘git and Oflazer, 2006). However, it is worth noting that most of these results have been obtained either for models of constituency-based parsing or for models of dependency parsing suffering from sparse data.4 In the experiments presented here, we have used a transition-based model for dependency parsing that has mu"
C08-1081,P06-1055,0,0.0113442,"2007), Turkish (Eryigit et al., 2006), and Swedish (Øvrelid and Nivre, 2007). With regard to lexical features, the situation is more complex in that there are a number of studies questioning the usefulness of lexical features in statistical parsing and arguing that equivalent or better results can be achieved with unlexicalized models provided that linguistic categories can be split flexibly into more fine-grained categories, either using hand-crafted splits, as in the seminal work of Klein and Manning (2003), or using hidden variables and unsupervised learning, as in the more recent work by Petrov et al. (2006), among others. There are even studies showing that lexicalization can be harmful when parsing richly inflected languages like German (Dubey and Keller, 2003) and Turkish (Eryi˘git and Oflazer, 2006). However, it is worth noting that most of these results have been obtained either for models of constituency-based parsing or for models of dependency parsing suffering from sparse data.4 In the experiments presented here, we have used a transition-based model for dependency parsing that has much fewer parameters than state-of-theart probabilistic models for constituency parsing. Moreover, we have"
C08-1081,W97-0301,0,0.0442624,"phs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4). 3.2 History-based parsing models rely on features of the derivation history to predict the next parser action (Black et al., 1992). The features used are all symbolic and defined in terms of five different node attributes: • A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time (Nivre, 2003). • History-based feature models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997). • Discriminative classifiers for mapping histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003). • Pseudo-projective parsing for recovering nonprojective structures (Nivre and Nilsson, 2005). In the following subsections, we briefly describe each of these four components in turn. 3.1 Parsing Algorithm The parser uses the deterministic algorithm for labeled dependency parsing first proposed by Nivre (2003). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and History-Based Fe"
C08-1081,W07-2219,0,0.227892,"Missing"
C08-1081,P06-3009,0,0.0272105,"s the percentage of true non-projective dependencies that were correctly predicted by the parser. 646 and Dubey (2003). Summing up, the main result of the experimental evaluation is that both morphological and lexical features are crucial for attaining high accuracy when training and evaluating on the representations found in the S YN TAG RUS treebank of Russian. With regard to morphological features this is in line with a number of recent studies showing the importance of morphology for parsing languages with less rigid word order, including work on Spanish (Cowan and Collins, 2005), Hebrew (Tsarfaty, 2006; Tsarfaty and Sima’an, 2007), Turkish (Eryigit et al., 2006), and Swedish (Øvrelid and Nivre, 2007). With regard to lexical features, the situation is more complex in that there are a number of studies questioning the usefulness of lexical features in statistical parsing and arguing that equivalent or better results can be achieved with unlexicalized models provided that linguistic categories can be split flexibly into more fine-grained categories, either using hand-crafted splits, as in the seminal work of Klein and Manning (2003), or using hidden variables and unsupervised learning, as in t"
C08-1081,W03-3023,0,0.0332917,"Nilsson (2005) (section 3.4). 3.2 History-based parsing models rely on features of the derivation history to predict the next parser action (Black et al., 1992). The features used are all symbolic and defined in terms of five different node attributes: • A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time (Nivre, 2003). • History-based feature models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997). • Discriminative classifiers for mapping histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003). • Pseudo-projective parsing for recovering nonprojective structures (Nivre and Nilsson, 2005). In the following subsections, we briefly describe each of these four components in turn. 3.1 Parsing Algorithm The parser uses the deterministic algorithm for labeled dependency parsing first proposed by Nivre (2003). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and History-Based Feature Models • POS = part of speech (atomic) • DEP = dependency type • MOR = morphological features (set) • LEM = lemma • LEX"
C08-1081,W02-2016,0,0.0103845,"ive approach of Nivre and Nilsson (2005) (section 3.4). 3.2 History-based parsing models rely on features of the derivation history to predict the next parser action (Black et al., 1992). The features used are all symbolic and defined in terms of five different node attributes: • A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time (Nivre, 2003). • History-based feature models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997). • Discriminative classifiers for mapping histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003). • Pseudo-projective parsing for recovering nonprojective structures (Nivre and Nilsson, 2005). In the following subsections, we briefly describe each of these four components in turn. 3.1 Parsing Algorithm The parser uses the deterministic algorithm for labeled dependency parsing first proposed by Nivre (2003). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and History-Based Feature Models • POS = part of speech (atomic) • DEP = dependency type • MOR = morphological featu"
C08-1081,P95-1037,0,0.110237,"t that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4). 3.2 History-based parsing models rely on features of the derivation history to predict the next parser action (Black et al., 1992). The features used are all symbolic and defined in terms of five different node attributes: • A transition-based deterministic algorithm for building labeled projective dependency graphs in linear time (Nivre, 2003). • History-based feature models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997). • Discriminative classifiers for mapping histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003). • Pseudo-projective parsing for recovering nonprojective structures (Nivre and Nilsson, 2005). In the following subsections, we briefly describe each of these four components in turn. 3.1 Parsing Algorithm The parser uses the deterministic algorithm for labeled dependency parsing first proposed by Nivre (2003). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens"
C08-1081,D07-1013,1,0.0710384,"hen they are attached correctly they are are often mislabeled. The remaining parts of speech are too infrequent to warrant any conclusions. Looking specifically at non-projective dependencies, we find that the best model has a labeled precision of 68.8 and a labeled recall of 31.4. The corresponding unlabeled figures are 73.3 and 33.4.3 This confirms the results of previous studies showing that the pseudo-projective parsing technique used by MaltParser tends to give high precision – given that non-projective dependencies are among the most difficult to parse correctly – but rather low recall (McDonald and Nivre, 2007). It is also worth mentioning that phantom tokens, i.e., empty tokens inserted for the analysis of certain elliptical constructions (see section 2), have a labeled precision of 82.4 and a labeled recall of 82.8 (89.2 and 89.6 unlabeled), which is very close to the average accuracy, despite being very infrequent. However, it must be remembered that these tokens were given as part of the input in these experiments. In order to correctly analyse these tokens and their dependencies when parsing raw text, they would have to be recovered in a pre-processing phase along the lines of Dienes 3 The prec"
C08-1081,P93-1005,0,\N,Missing
C08-1081,D07-1096,1,\N,Missing
C10-1094,H91-1060,0,0.288184,"Missing"
C10-1094,P06-4020,0,0.0683923,"Missing"
C10-1094,W06-2920,0,0.0649395,"Missing"
C10-1094,P04-1041,0,0.0138708,"Missing"
C10-1094,W08-2102,0,0.0219878,"Missing"
C10-1094,P05-1022,0,0.052948,"state-of-the-art parsers were evaluated for their recall on the goldstandard dependencies. Three of the parsers were based on grammars automatically extracted from the PTB: the C&C CCG parser (Clark and Curran, 2007), the Enju HPSG parser (Miyao and Tsujii, 2005), and the Stanford parser (Klein and Manning, 2003). The two remaining systems were the 834 RASP parser (Briscoe et al., 2006), using a manually constructed grammar and a statistical parse selection component, and the DCU post-processor of PTB parsers (Cahill et al., 2004) using the output of the Charniak and Johnson reranking parser (Charniak and Johnson, 2005). Because of the wide variation in parser output representations, a mostly manual evaluation was performed to ensure that each parser got credit for the constructions it recovered correctly. The parsers were run essentially “out of the box”, meaning that the development set was used to confirm input and output formats, but no real tuning was performed. In addition, since a separate question model is available for C&C, this was also evaluated on ObQ sentences. The best overall performers were C&C and Enju, which is unsurprising since they are deep parsers based on grammar formalisms designed to"
C10-1094,J07-4004,0,0.224176,"Missing"
C10-1094,de-marneffe-etal-2006-generating,0,0.0641288,"Missing"
C10-1094,gimenez-marquez-2004-svmtool,0,0.0865987,"Missing"
C10-1094,E06-1011,1,0.313697,"-based parsers typically rely on global training and inference algorithms, where the goal is to learn models in which the weight/probability of correct trees is higher than that of incorrect trees. At inference time a global search is run to find the 1 highest weighted dependency tree. Unfortunately, global inference and learning for graph-based dependency parsing is typically NP-hard (McDonald and Satta, 2007). As a result, graph-based parsers (including MSTParser) often limit the scope of their features to a small number of adjacent arcs (usually two) and/or resort to approximate inference (McDonald and Pereira, 2006). MaltParser2 is a freely available implementation of the parsing models described in Nivre et al. (2006a) and Nivre et al. (2006b). MaltParser is categorized as a transition-based parsing system, characterized by parsing algorithms that produce dependency trees by transitioning through abstract state machines (K¨ubler et al., 2008). Transitionbased parsers learn models that predict the next state given the current state of the system as well as features over the history of parsing decisions and the input sentence. At inference time, the parser starts in an initial state, then greedily moves t"
C10-1094,W07-2216,1,0.608607,"graph-based parsing system in that core parsing algorithms can be equated to finding directed maximum spanning trees (either projective or non-projective) from a dense graph representation of the sentence. Graph-based parsers typically rely on global training and inference algorithms, where the goal is to learn models in which the weight/probability of correct trees is higher than that of incorrect trees. At inference time a global search is run to find the 1 highest weighted dependency tree. Unfortunately, global inference and learning for graph-based dependency parsing is typically NP-hard (McDonald and Satta, 2007). As a result, graph-based parsers (including MSTParser) often limit the scope of their features to a small number of adjacent arcs (usually two) and/or resort to approximate inference (McDonald and Pereira, 2006). MaltParser2 is a freely available implementation of the parsing models described in Nivre et al. (2006a) and Nivre et al. (2006b). MaltParser is categorized as a transition-based parsing system, characterized by parsing algorithms that produce dependency trees by transitioning through abstract state machines (K¨ubler et al., 2008). Transitionbased parsers learn models that predict t"
C10-1094,P05-1012,1,0.0924636,"Missing"
C10-1094,W06-2932,1,0.848475,"r the evaluation, including parser training, post-processing, and evaluation.3 4.1 Parser Training One important difference between MSTParser and MaltParser, on the one hand, and the best performing parsers evaluated in Rimell et al. (2009), on the other, is that the former were never developed specifically as parsers for English. Instead, they are best understood as data-driven parser generators, that is, tools for generating a parser given a training set of sentences annotated with dependency structures. Over the years, both systems have been applied to a wide range of languages (see, e.g., McDonald et al. (2006), McDonald (2006), Nivre et al. (2006b), Hall et al. (2007), Nivre et al. (2007)), but they come with no language-specific enhancements and are not equipped specifically to deal with unbounded dependencies. Since the dependency representation used in the evaluation corpus is based on the Stanford typed dependency scheme (de Marneffe et al., 2006), we opted for using the WSJ section of the PTB, converted to Stanford dependencies, as our primary source of training data. Thus, both parsers were trained on section 2–21 of the WSJ data, which we converted to Stanford dependencies using the Stanford"
C10-1094,P05-1011,0,0.0881372,"Missing"
C10-1094,nivre-etal-2006-maltparser,1,0.308576,"hich the weight/probability of correct trees is higher than that of incorrect trees. At inference time a global search is run to find the 1 highest weighted dependency tree. Unfortunately, global inference and learning for graph-based dependency parsing is typically NP-hard (McDonald and Satta, 2007). As a result, graph-based parsers (including MSTParser) often limit the scope of their features to a small number of adjacent arcs (usually two) and/or resort to approximate inference (McDonald and Pereira, 2006). MaltParser2 is a freely available implementation of the parsing models described in Nivre et al. (2006a) and Nivre et al. (2006b). MaltParser is categorized as a transition-based parsing system, characterized by parsing algorithms that produce dependency trees by transitioning through abstract state machines (K¨ubler et al., 2008). Transitionbased parsers learn models that predict the next state given the current state of the system as well as features over the history of parsing decisions and the input sentence. At inference time, the parser starts in an initial state, then greedily moves to subsequent states – based on the predictions of the model – until a termination state is reached. Tran"
C10-1094,W06-2933,1,0.871166,"Missing"
C10-1094,P06-2041,1,0.881979,"Missing"
C10-1094,D07-1097,1,0.623321,"Missing"
C10-1094,P09-1040,1,0.856395,"ntially produces the same kind of dependency structures as output but uses the original phrase structure trees from the PTB as input to training. For our experiments we used MSTParser with the same parsing algorithms and features as reported in McDonald et al. (2006). However, unlike that work we used an atomic maximum entropy model as the second stage arc predictor as opposed to the more time consuming sequence labeler. McDonald et al. (2006) showed that there is negligible accuracy loss when using atomic rather than structured labeling. For MaltParser we used the projective Stack algorithm (Nivre, 2009) with default settings and a slightly enriched feature model. All parsing was projective because the Stanford dependency trees are strictly projective. 4 QB contains 4000 questions, but we removed all questions that also occurred in the test or development set of Rimell et al. (2009), who sampled their questions from the same TREC QA test sets. 836 4.2 Post-Processing All the development and test sets in the corpus of Rimell et al. (2009) were parsed using MSTParser and MaltParser after part-of-speech tagging the input using SVMTool (Gim´enez and M`arquez, 2004) trained on section 2–21 of the"
C10-1094,P08-1067,0,0.062612,"Missing"
C10-1094,D09-1085,1,0.255417,"Sagae and Lavie, 2006; Huang, 2008; Carreras et al., 2008), broad-coverage parsing is still far from being a solved problem. In particular, metrics like attachment score for dependency parsers (Buchholz and Marsi, 2006) and Parseval for constituency parsers (Black et al., 1991) suffer from being an average over a highly skewed distribution of different grammatical constructions. As a result, infrequent yet semantically important construction types could be parsed with accuracies far below what one might expect. This shortcoming of aggregate parsing metrics was highlighted in a recent study by Rimell et al. (2009), introducing a new parser evaluation corpus containing around 700 sentences annotated with unbounded dependencies in seven different grammatical constructions. This corpus was used to evaluate five state-of-the-art parsers cgomezr@udc.es for English, focusing on grammar-based and statistical phrase structure parsers. For example, in the sentence By Monday, they hope to have a sheaf of documents both sides can trust., parsers should recognize that there is a dependency between trust and documents, an instance of object extraction out of a (reduced) relative clause. In the evaluation, the recal"
C10-1094,P06-1063,0,0.0324415,"Missing"
C10-1094,N06-2033,0,0.0764608,"Missing"
C10-1094,P03-1054,0,0.00493055,"d (2006), Nivre et al. (2006b), Hall et al. (2007), Nivre et al. (2007)), but they come with no language-specific enhancements and are not equipped specifically to deal with unbounded dependencies. Since the dependency representation used in the evaluation corpus is based on the Stanford typed dependency scheme (de Marneffe et al., 2006), we opted for using the WSJ section of the PTB, converted to Stanford dependencies, as our primary source of training data. Thus, both parsers were trained on section 2–21 of the WSJ data, which we converted to Stanford dependencies using the Stanford parser (Klein and Manning, 2003). The Stanford scheme comes in several varieties, but because both parsers require the dependency structure for each sentence to be a tree, we had to use the so-called basic variety (de Marneffe et al., 2006). It is well known that questions are very rare in the WSJ data, and Rimell et al. (2009) found that parsers trained only on WSJ data generally performed badly on the questions included in the 3 To ensure replicability, we provide all experimental settings, post-processing scripts and additional information about the evaluation at http://stp.ling.uu.se/∼nivre/exp/. evaluation corpus, while"
C10-1094,D07-1013,1,0.699906,"bounded dependency constructions (a–g). Arcs drawn below each sentence represent the dependencies scored in the evaluation, while the tree above each sentence is the Stanford basic dependency representation, with solid arcs indicating crucial dependencies (cf. Section 4). All examples are from the development sets. (2009) and considerably better than the other statistical parsers in that evaluation. Interestingly, though the two systems have similar accuracies overall, there is a clear distinction between the kinds of errors each system makes, which we argue is consistent with observations by McDonald and Nivre (2007). 2 Unbounded Dependency Evaluation An unbounded dependency involves a word or phrase interpreted at a distance from its surface position, where an unlimited number of clause boundaries may in principle intervene. The unbounded dependency corpus of Rimell et al. (2009) includes seven grammatical constructions: object extraction from a relative clause (ObRC), object extraction from a reduced relative clause (ObRed), subject extraction from a relative clause (SbRC), free relatives (Free), object questions (ObQ), right node raising (RNR), and subject extraction from an embedded clause (SbEm), all"
C10-2013,abeille-barrier-2004-enriching,0,0.0620534,"A syntactic analysis in terms of typed grammatical relations, whether encoded as functional annotations in syntagmatic trees or in labeled dependency trees, appears to be useful for many NLP tasks including question answering, information extraction, and lexical acquisition tasks like collocation extraction. This usefulness holds particularly for French, a language for which bare syntagmatic trees are often syntactically underspecied because of a rather free order of post-verbal complements/adjuncts and the possibility of subject inversion. Thus, the annotation scheme of the French Treebank (Abeillé and Barrier, 2004) makes use of at syntagmatic trees without VP joakim.nivre@lingl.uu.se nodes, with no structural distinction between complements, adjuncts or post-verbal subjects, but with additional functional annotations on dependents of verbs. Parsing is commonly enhanced by using more abstract lexical information, in the form of morphological features (Tsarfaty, 2006), lemmas (Seddah et al., 2010), or various forms of clusters (see (Candito and Seddah, 2010) for references). In this paper, we explore the integration of morphological features, lemmas, and linear context clusters. Typed dependencies can b"
C10-2013,J92-4003,0,0.152406,"Missing"
C10-2013,W06-2920,0,0.00795066,"e dominant paradigm for English has been to use constituency-based parsers, the output of which can be converted to typed dependencies using well-proven conversion procedures, as in the Stanford parser (Klein and Manning, 2003). In recent years, it has also become popular to use statistical dependency parsers, which are trained directly on labeled dependency trees and output such trees directly, such as MSTParser (McDonald, 2006) and MaltParser (Nivre et al., 2006). Dependency parsing has been applied to a fairly broad range of languages, especially in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006; Nivre et al., 2007). We present a comparison of three statistical parsing architectures that output typed dependencies for French: one constituency-based architecture featuring the Berkeley parser (Petrov et al., 2006), and two dependency-based systems using radically different parsing methods, MSTParser (McDonald et al., 2006) and MaltParser (Nivre et al., 2006). These three systems are compared both in terms of parsing accuracy and parsing times, in realistic settings that only use predicted information. By using freely available software packages that implement language-independent approa"
C10-2013,W09-3821,1,0.178099,"Missing"
C10-2013,W10-1409,1,0.292957,"ather free order of post-verbal complements/adjuncts and the possibility of subject inversion. Thus, the annotation scheme of the French Treebank (Abeillé and Barrier, 2004) makes use of at syntagmatic trees without VP joakim.nivre@lingl.uu.se nodes, with no structural distinction between complements, adjuncts or post-verbal subjects, but with additional functional annotations on dependents of verbs. Parsing is commonly enhanced by using more abstract lexical information, in the form of morphological features (Tsarfaty, 2006), lemmas (Seddah et al., 2010), or various forms of clusters (see (Candito and Seddah, 2010) for references). In this paper, we explore the integration of morphological features, lemmas, and linear context clusters. Typed dependencies can be derived using many different parsing architectures. As far as statistical approaches are concerned, the dominant paradigm for English has been to use constituency-based parsers, the output of which can be converted to typed dependencies using well-proven conversion procedures, as in the Stanford parser (Klein and Manning, 2003). In recent years, it has also become popular to use statistical dependency parsers, which are trained directly on labele"
C10-2013,candito-etal-2010-statistical,1,0.637544,"nks For training and testing the statistical parsers, we use treebanks that are automatically converted from the French Treebank (Abeillé and Barrier, 2004) (hereafter F TB), a constituency-based treebank made up of 12, 531 sentences from the Le Monde newspaper. Each sentence is annotated with a constituent structure and words bear the following features: gender, number, mood, tense, person, deniteness, wh-feature, and clitic case. Nodes representing dependents of a verb are labeled with one of 8 grammatical functions.1 We use two treebanks automatically obtained from F TB, both described in Candito et al. (2010). F TB - UC is a modied version of the original constituency-based treebank, where the rich morphological annotation has been mapped to a simple tagset of 28 part-of-speech tags, and where compounds with regular syntax are broken down into phrases containing several simple words while remaining sequences annotated as compounds in F TB are merged into a single token. Function labels are appended to syntactic category symbols and are either used or ignored, depending on the task. F TB - UC -D EP is a dependency treebank derived from F TB - UC using the classic technique of head propagation rule"
C10-2013,cer-etal-2010-parsing,0,0.0356489,"Missing"
C10-2013,A00-2018,0,0.108329,"Missing"
C10-2013,W06-2932,0,0.0627677,"ectly on labeled dependency trees and output such trees directly, such as MSTParser (McDonald, 2006) and MaltParser (Nivre et al., 2006). Dependency parsing has been applied to a fairly broad range of languages, especially in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006; Nivre et al., 2007). We present a comparison of three statistical parsing architectures that output typed dependencies for French: one constituency-based architecture featuring the Berkeley parser (Petrov et al., 2006), and two dependency-based systems using radically different parsing methods, MSTParser (McDonald et al., 2006) and MaltParser (Nivre et al., 2006). These three systems are compared both in terms of parsing accuracy and parsing times, in realistic settings that only use predicted information. By using freely available software packages that implement language-independent approaches 108 Coling 2010: Poster Volume, pages 108–116, Beijing, August 2010 and applying them to a language different from English, we also hope to shed some light on the capacity of different methods to cope with the challenges posed by different languages. Comparative evaluation of constituency-based and dependency-based parsers w"
C10-2013,de-marneffe-etal-2006-generating,0,0.00964342,"Missing"
C10-2013,Y09-1013,1,0.190601,"ed global inference for graph-based dependency parsing is NP-hard, and graph-based parsers like MSTParser therefore limit the scope of their features to a small number of adjacent arcs (usually two) and/or resort to approximate inference (McDonald and Pereira, 2006). For our experiments, we use MSTParser 0.4.3b4 with 1-best projective decoding, using the algorithm of Eisner (1996), and second order features. The labeling of dependencies is performed as a separate sequence classication step, following McDonald et al. (2006). To provide part-of-speech tags to MSTParser, we use the MElt tagger (Denis and Sagot, 2009), a Maximum Entropy Markov Model tagger enriched with information from a large-scale dictionary.5 The tagger was trained on the training set to provide POS tags for the dev and test sets, and we used 10-way jackkning to generate tags for the training set. 3.3 MaltParser MaltParser6 is a freely available implementation of the parsing models described in (Nivre, 2006) and (Nivre, 2008). These models are often characterized as transition-based, because they reduce the problem of parsing a sentence to the problem of nding an optimal path through an abstract transition system, or state machine. T"
C10-2013,C96-1058,0,0.154658,"arsers typically use global training algorithms, where the goal is to learn to score correct trees higher than incorrect trees. At parsing time a global search is run to nd the highest scoring dependency tree. However, unrestricted global inference for graph-based dependency parsing is NP-hard, and graph-based parsers like MSTParser therefore limit the scope of their features to a small number of adjacent arcs (usually two) and/or resort to approximate inference (McDonald and Pereira, 2006). For our experiments, we use MSTParser 0.4.3b4 with 1-best projective decoding, using the algorithm of Eisner (1996), and second order features. The labeling of dependencies is performed as a separate sequence classication step, following McDonald et al. (2006). To provide part-of-speech tags to MSTParser, we use the MElt tagger (Denis and Sagot, 2009), a Maximum Entropy Markov Model tagger enriched with information from a large-scale dictionary.5 The tagger was trained on the training set to provide POS tags for the dev and test sets, and we used 10-way jackkning to generate tags for the training set. 3.3 MaltParser MaltParser6 is a freely available implementation of the parsing models described in (Nivr"
C10-2013,P98-1106,0,0.0427852,"Missing"
C10-2013,P03-1054,0,0.00198719,"n the form of morphological features (Tsarfaty, 2006), lemmas (Seddah et al., 2010), or various forms of clusters (see (Candito and Seddah, 2010) for references). In this paper, we explore the integration of morphological features, lemmas, and linear context clusters. Typed dependencies can be derived using many different parsing architectures. As far as statistical approaches are concerned, the dominant paradigm for English has been to use constituency-based parsers, the output of which can be converted to typed dependencies using well-proven conversion procedures, as in the Stanford parser (Klein and Manning, 2003). In recent years, it has also become popular to use statistical dependency parsers, which are trained directly on labeled dependency trees and output such trees directly, such as MSTParser (McDonald, 2006) and MaltParser (Nivre et al., 2006). Dependency parsing has been applied to a fairly broad range of languages, especially in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006; Nivre et al., 2007). We present a comparison of three statistical parsing architectures that output typed dependencies for French: one constituency-based architecture featuring the Berkeley parser (Pet"
C10-2013,P08-1068,0,0.546912,"POS tags. Motivations for these features are rooted in the fact that French has a rather rich inectional morphology. The intuition behind using morphological features like tense, mood, gender, number, and person is that some of these are likely to provide additional cues for syntactic attachment or function type. This is especially true given that the 29 tags used by the MElt tagger are rather coarse-grained. The use of lemmas and word clusters, on the other hand, is motivated by data sparseness considerations: these provide various degrees of generalization over word forms. As suggested by Koo et al. (2008), the use of word clusters may also reduce the need for annotated data. All our features are automatically produced: no features except word forms originate from the treebank. Our aim was to assess the performance currently available for French in a realistic setting. Lemmas Lemmatized forms are extracted using Lefff (Sagot, 2010), a large-coverage morphosyntactic lexicon for French, and a set of heuristics for unknown words. More specically, Lefff is queried for each (word, pos), where pos is the tag predicted by the MElt tagger. If the pair is found, we use the longest lemma associated with"
C10-2013,P95-1037,0,0.137856,"Missing"
C10-2013,P05-1010,0,0.033322,"Missing"
C10-2013,D07-1013,1,0.235204,"Missing"
C10-2013,E06-1011,0,0.0377804,"a sentence to the problem of nding a directed maximum spanning tree in a dense graph representation of the sentence. Graph-based parsers typically use global training algorithms, where the goal is to learn to score correct trees higher than incorrect trees. At parsing time a global search is run to nd the highest scoring dependency tree. However, unrestricted global inference for graph-based dependency parsing is NP-hard, and graph-based parsers like MSTParser therefore limit the scope of their features to a small number of adjacent arcs (usually two) and/or resort to approximate inference (McDonald and Pereira, 2006). For our experiments, we use MSTParser 0.4.3b4 with 1-best projective decoding, using the algorithm of Eisner (1996), and second order features. The labeling of dependencies is performed as a separate sequence classication step, following McDonald et al. (2006). To provide part-of-speech tags to MSTParser, we use the MElt tagger (Denis and Sagot, 2009), a Maximum Entropy Markov Model tagger enriched with information from a large-scale dictionary.5 The tagger was trained on the training set to provide POS tags for the dev and test sets, and we used 10-way jackkning to generate tags for the t"
C10-2013,nivre-etal-2006-maltparser,1,0.27488,"ear context clusters. Typed dependencies can be derived using many different parsing architectures. As far as statistical approaches are concerned, the dominant paradigm for English has been to use constituency-based parsers, the output of which can be converted to typed dependencies using well-proven conversion procedures, as in the Stanford parser (Klein and Manning, 2003). In recent years, it has also become popular to use statistical dependency parsers, which are trained directly on labeled dependency trees and output such trees directly, such as MSTParser (McDonald, 2006) and MaltParser (Nivre et al., 2006). Dependency parsing has been applied to a fairly broad range of languages, especially in the CoNLL shared tasks in 2006 and 2007 (Buchholz and Marsi, 2006; Nivre et al., 2007). We present a comparison of three statistical parsing architectures that output typed dependencies for French: one constituency-based architecture featuring the Berkeley parser (Petrov et al., 2006), and two dependency-based systems using radically different parsing methods, MSTParser (McDonald et al., 2006) and MaltParser (Nivre et al., 2006). These three systems are compared both in terms of parsing accuracy and parsi"
C10-2013,J08-4003,1,0.445253,"rder features. The labeling of dependencies is performed as a separate sequence classication step, following McDonald et al. (2006). To provide part-of-speech tags to MSTParser, we use the MElt tagger (Denis and Sagot, 2009), a Maximum Entropy Markov Model tagger enriched with information from a large-scale dictionary.5 The tagger was trained on the training set to provide POS tags for the dev and test sets, and we used 10-way jackkning to generate tags for the training set. 3.3 MaltParser MaltParser6 is a freely available implementation of the parsing models described in (Nivre, 2006) and (Nivre, 2008). These models are often characterized as transition-based, because they reduce the problem of parsing a sentence to the problem of nding an optimal path through an abstract transition system, or state machine. This is sometimes equated with shift-reduce parsing, but in fact includes a much broader range of transition systems (Nivre, 2008). Transition-based parsers learn models that predict the next state given the current state of the system, including features over the history of parsing decisions and the input sentence. At parsing time, the parser starts in an initial state and greedily mo"
C10-2013,N07-1051,0,0.0285364,"Missing"
C10-2013,P06-1055,0,0.0252933,"three architectures in more detail.2 3 The Berkeley parser is a freely available implementation of the statistical training and parsing algorithms described in (Petrov et al., 2006) and (Petrov and Klein, 2007). It exploits the fact that PCFG learning can be improved by splitting symbols according to structural and/or lexical properties (Klein and Manning, 2003). Following Matsuzaki et al. (2005), the Berkeley learning algorithm uses EM to estimate probabilities on symbols that are automatically augmented with latent annotations, a process that can be viewed as symbol splitting. Petrov et al. (2006) proposed to score the splits in order to retain only the most benecial ones, and keep the grammar size manageable: the splits that induce the smallest losses in the likelihood of the treebank are merged back. The algorithm starts with a very general treebank-induced binarized PCFG, with order h horizontal markovisation. created, where at each level a symbol appears without track of its original siblings. Then the Berkeley algorithm performs split/merge/smooth cycles that iteratively rene the binarized grammar: it adds two latent annotations on each symbol, learns probabilities for the rene"
C10-2013,sagot-2010-lefff,0,0.0338599,"Missing"
C10-2013,W10-1410,1,0.880622,"Missing"
C10-2013,P06-3009,0,0.0189149,"which bare syntagmatic trees are often syntactically underspecied because of a rather free order of post-verbal complements/adjuncts and the possibility of subject inversion. Thus, the annotation scheme of the French Treebank (Abeillé and Barrier, 2004) makes use of at syntagmatic trees without VP joakim.nivre@lingl.uu.se nodes, with no structural distinction between complements, adjuncts or post-verbal subjects, but with additional functional annotations on dependents of verbs. Parsing is commonly enhanced by using more abstract lexical information, in the form of morphological features (Tsarfaty, 2006), lemmas (Seddah et al., 2010), or various forms of clusters (see (Candito and Seddah, 2010) for references). In this paper, we explore the integration of morphological features, lemmas, and linear context clusters. Typed dependencies can be derived using many different parsing architectures. As far as statistical approaches are concerned, the dominant paradigm for English has been to use constituency-based parsers, the output of which can be converted to typed dependencies using well-proven conversion procedures, as in the Stanford parser (Klein and Manning, 2003). In recent years, it has als"
C10-2013,W03-3023,0,0.125602,"ijing, August 2010 and applying them to a language different from English, we also hope to shed some light on the capacity of different methods to cope with the challenges posed by different languages. Comparative evaluation of constituency-based and dependency-based parsers with respect to labeled accuracy is rare, despite the fact that parser evaluation on typed dependencies has been advocated for a long time (Lin, 1995; Carroll et al., 1998). Early work on statistical dependency parsing often compared constituency-based and dependency-based methods with respect to their unlabeled accuracy (Yamada and Matsumoto, 2003), but comparison of different approaches with respect to labeled accuracy is more recent. Cer et al. (2010) present a thorough analysis of the best trade-off between speed and accuracy in deriving Stanford typed dependencies for English (de Marneffe et al., 2006), comparing a number of constituency-based and dependency-based parsers on data from the Wall Street Journal. They conclude that the highest accuracy is obtained using constituency-based parsers, although some of the dependency-based parsers are more efcient. For German, the 2008 ACL workshop on parsing German (Kübler, 2008) featured"
C10-2013,W08-1008,0,\N,Missing
C10-2013,C98-1102,0,\N,Missing
C10-2013,D07-1096,1,\N,Missing
C12-1059,W06-2922,0,0.0162269,"bsolute for Czech. The main difference compared to our approach, except for the fact that they use a different transition system, is that their method for finding the optimal transition after the first training round is heuristic and does not guarantee that the best parse is still reachable. Finally, Cohen et al. (2012) tackle the problem of spurious ambiguity for static oracles by eliminating ambiguity from the underlying transition system instead of modifying the oracle. They show how this can be achieved for the arc-standard system of Nivre (2004) as well as the non-projective extension by Attardi (2006). It is still an open question whether their technique can also be applied to the arc-eager system targeted in this paper. 7 Conclusion We have highlighted the shortcoming of traditional static oracles used to train transition-based dependency parsers, and instead proposed the notion of a dynamic oracle, which allows more than one correct transition sequence in the case of spurious ambiguity, and which can predict an optimal transition also for non-optimal configurations. We have defined a concrete dynamic oracle for the arc-eager transition system and showed how it can be used in online train"
C12-1059,E12-1009,0,0.0144274,"ively long time to train. We instead use a simpler online algorithm which can be viewed as a stochastic approximation of the DAgger algorithm, which is itself heavily inspired by the Searn algorithm. Recent work on beam search and structured prediction for transition-based dependency parsing has shown that parsing accuracy can be improved considerably if models are trained to perform beam search instead of greedy one-best search, and if training is done using a global structured learning objective instead of local learning of individual decisions (Zhang and Clark, 2008; Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Huang et al., 2012). Like our method, beam search with global structured learning mitigates the effects of error propagation by exploring non-canonical configurations at training time, but the use of a beam reduces parsing speed by a factor that is roughly proportional to the size of the beam, making parsing less efficient. Our method in contrast still trains classifiers to perform local decisions, and thus incurs no efficiency penalty at parsing time, but each local decision is trained to take into account the consequences of previous, possibly erroneous, decisions. Although we may not be a"
C12-1059,P11-2121,0,0.0226701,"vious, possibly erroneous, decisions. Although we may not be able to reach the accuracy level of a beam-search parser, we show that a substantial improvement in accuracy is possible also for a purely deterministic classifier-based parser, making our method suitable for training accurate parsers in situations where maximum efficiency is needed, e.g., when there is a need to process very large corpora. Integrating our dynamic oracle in the training procedure for a transition-based parser with beam search is an interesting question for future work. The work that probably comes closest to ours is Choi and Palmer (2011), who improve the accuracy of a greedy transition-based dependency parser through an iterative training procedure that they call bootstrapping. They start by training a classifier using a standard static oracle for a hybrid transition system combining elements of the arc-eager system and the algorithm of 11 Stacked learning has been explored to some extent in the context of parsing for integrating approximate higher order features as well as for combining the predictions of different parsers (Nivre and McDonald, 2008; Martins et al., 2008). 971 Covington (2001). In a second step, they then use"
C12-1059,de-marneffe-etal-2006-generating,0,0.122602,"Missing"
C12-1059,W11-2925,0,0.0524953,"Missing"
C12-1059,foster-van-genabith-2008-parser,0,0.0369631,"Missing"
C12-1059,N10-1115,1,0.570932,"t for all configurations, including configurations which are not a part of a gold derivation. For configurations which are not part of a gold derivation (and from which the gold tree is not reachable), the dynamic oracle permits all transitions that can lead to a tree with minimum loss compared to the gold tree. In this paper, we provide a provably correct dynamic oracle for the arc-eager transition system of Nivre (2003, 2008). One important use for a dynamic oracle is in training a parser that (a) is not restricted to a 1 This is similar to the parsing oracle used in the EasyFirst parser of Goldberg and Elhadad (2010). 960 ✞ ROOT 0 PRD ✞ P ☎✞ ✞ SBJ ☎ ✞IOBJ ☎ ❄ ❄ ❄ He1 her3 wrote2 DOBJ ☎ ✞ DET ☎ ❄ ❄ a4 letter5 ☎ ❄ .6 Figure 1: Projective dependency tree particular canonical order of transitions and (b) can handle configurations that are not part of any gold sequence, thus mitigating the effect of error propagation. To this end, we provide an online training procedure based on the dynamic oracle that deals with spurious ambiguity by treating all sequences leading to a gold tree as correct, and with error-propagation by exploring transition sequences that are not optimal in the sense that they do not derive t"
C12-1059,D07-1097,1,0.25501,"re thus artificially lower than they could be. We could get better scores for these data sets for all training conditions by training on the Ontonotes corpora instead, but as our main concern is not in achieving the best scores, we opted for the simpler experimental setup. 10 Language-specific tuning is likely to improve results for the other languages as well – we did not perform any language-specific tuning, and it is well established that individual languages parsing accuracies can greatly benefit from tuning of the feature set, the transition system being used and the learning parameters (Hall et al., 2007). 970 6 Related Work Deterministic classifier-based dependency parsing is an instance of independent sequential classification-based structured prediction. In sequential classification models, such as MaximumEntropy Markov Models (McCallum et al., 2000), a structured output is produced by repeated application of a locally trained classifier, where each classification decision is conditioned on the structure created by previous decisions. Several methods have been developed to cope with error propagation in sequential classification, including stacked sequential learning (Cohen and Carvalho, 20"
C12-1059,N12-1015,0,0.0476937,"n. We instead use a simpler online algorithm which can be viewed as a stochastic approximation of the DAgger algorithm, which is itself heavily inspired by the Searn algorithm. Recent work on beam search and structured prediction for transition-based dependency parsing has shown that parsing accuracy can be improved considerably if models are trained to perform beam search instead of greedy one-best search, and if training is done using a global structured learning objective instead of local learning of individual decisions (Zhang and Clark, 2008; Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Huang et al., 2012). Like our method, beam search with global structured learning mitigates the effects of error propagation by exploring non-canonical configurations at training time, but the use of a beam reduces parsing speed by a factor that is roughly proportional to the size of the beam, making parsing less efficient. Our method in contrast still trains classifiers to perform local decisions, and thus incurs no efficiency penalty at parsing time, but each local decision is trained to take into account the consequences of previous, possibly erroneous, decisions. Although we may not be able to reach the accu"
C12-1059,P06-1063,0,0.0119919,"Missing"
C12-1059,J93-2004,0,0.0424806,"eech tags in both cases. Since the arc-eager parser can only handle projective dependency trees, all trees in the training set are projectivized before training, using the baseline pseudo-projective transformation in Nivre and Nilsson (2005). However, non-projective trees are kept intact in the test sets for evaluation. We include all ten languages from the CoNLL 2007 shared task: • ARA: Arabic (Hajiˇc et al., 2004) • BAS: Basque (Aduriz et al., 2003) • CAT: Catalan (Martí et al., 2007) • CHI: Chinese (Chen et al., 2003) • CZE: Czech (Hajiˇc et al., 2001; Böhmová et al., 2003) • ENG: English (Marcus et al., 1993) • GRE: Greek (Prokopidis et al., 2005) • HUN: Hungarian (Czendes et al., 2005) 969 ARA BAS Static Dynamic-ambiguity Dynamic-explore 80.60 80.72 83.06 74.10 74.90 76.10 Static Dynamic-ambiguity Dynamic-explore 71.04 71.06 73.54 64.42 65.18 66.77 CAT CHI CZE ENG Unlabeled Attachment Scores 91.21 84.13 78.00 86.24 91.09 83.62 78.38 86.83 92.01 84.65 79.54 88.81 Labeled Attachment Scores 85.96 79.75 69.49 84.90 85.73 79.24 69.39 85.56 86.60 80.74 71.32 87.60 GRE HUN ITA TUR 79.16 79.48 80.66 77.75 76.17 77.10 84.11 84.52 84.77 79.02 78.97 78.84 70.94 71.88 73.83 68.10 66.99 68.23 79.93 80.63 81.0"
C12-1059,D08-1017,0,0.00925318,"work. The work that probably comes closest to ours is Choi and Palmer (2011), who improve the accuracy of a greedy transition-based dependency parser through an iterative training procedure that they call bootstrapping. They start by training a classifier using a standard static oracle for a hybrid transition system combining elements of the arc-eager system and the algorithm of 11 Stacked learning has been explored to some extent in the context of parsing for integrating approximate higher order features as well as for combining the predictions of different parsers (Nivre and McDonald, 2008; Martins et al., 2008). 971 Covington (2001). In a second step, they then use this classifier to parse the training corpus, creating one new training instance for every configuration visited during parsing, using an adapted version of the static oracle to predict the optimal transition for each configuration. They iterate this procedure as long as parsing accuracy improves on a held-out development set and report improvements in parsing accuracy of about 0.5 percent absolute for English and almost 2 percent absolute for Czech. The main difference compared to our approach, except for the fact that they use a differe"
C12-1059,D07-1013,1,0.575417,"d tree, because it does not eliminate any gold arc that is still reachable – the cost of the incorrect attachment is already accounted for in the cost of the erroneous SHIFT action. After defining the concept of a dynamic oracle which is correct over the entire configuration space of a transition system and providing a concrete instantiation of it for the arc-eager transition system, we now go on to present one useful application of such an oracle. 4 Training Parsers with the Dynamic Oracle Greedy transition-based parsers trained with static oracles are known to suffer from error propagation (McDonald and Nivre, 2007). We may hope to mitigate the error propagation problem by letting the parser explore larger portions of the configuration space during training and learn how to behave optimally also after committing previous errors. While this is not possible with the usual static oracles, the dynamic oracle defined above allows us to do just that, as it returns a set of optimal transitions for each possible configuration. Algorithm 2 is a standard online training algorithm for transition-based dependency parsers using a static oracle. Given a training sentence x with gold tree Ggold , it starts in the initi"
C12-1059,W03-3017,1,0.615468,"quences from gold parse trees. These sequences can then be used as training data for a classifier that approximates the oracle at parsing time in deterministic classifier-based parsing (Yamada and Matsumoto, 2003; Nivre et al., 2004), or it can be used to determine when to perform updates in online training of a beam search parser (Zhang and Clark, 2008). Currently, such oracles work by translating a given tree to a static sequence of parser transitions which, if run in sequence, will produce the gold tree. Most transition systems, including the arc-eager and arc-standard systems described in Nivre (2003, 2004), exhibit spurious ambiguity and map several sequences to the same gold tree. In such cases, the oracles implicitly define a canonical derivation order. We call such oracles static, because they produce a single static sequence of transitions that is supposed to be followed in its entirety. Static oracles are usually specified as rules over individual parser configurations – if the configuration has properties X and the gold tree is Y , then the correct transition is Z – giving the impression that they define a function from configurations to transitions. However, these rules are only c"
C12-1059,W04-0308,1,0.438224,"0.5 percent absolute for English and almost 2 percent absolute for Czech. The main difference compared to our approach, except for the fact that they use a different transition system, is that their method for finding the optimal transition after the first training round is heuristic and does not guarantee that the best parse is still reachable. Finally, Cohen et al. (2012) tackle the problem of spurious ambiguity for static oracles by eliminating ambiguity from the underlying transition system instead of modifying the oracle. They show how this can be achieved for the arc-standard system of Nivre (2004) as well as the non-projective extension by Attardi (2006). It is still an open question whether their technique can also be applied to the arc-eager system targeted in this paper. 7 Conclusion We have highlighted the shortcoming of traditional static oracles used to train transition-based dependency parsers, and instead proposed the notion of a dynamic oracle, which allows more than one correct transition sequence in the case of spurious ambiguity, and which can predict an optimal transition also for non-optimal configurations. We have defined a concrete dynamic oracle for the arc-eager trans"
C12-1059,J08-4003,1,0.960357,"er outperforms greedy parsers trained using conventional oracles on a range of data sets, with an average improvement of over 1.2 LAS points and up to almost 3 LAS points on some data sets. KEYWORDS: dependency parsing, transition system, oracle. Proceedings of COLING 2012: Technical Papers, pages 959–976, COLING 2012, Mumbai, December 2012. 959 1 Introduction The basic idea in transition-based dependency parsing is to define a nondeterministic transition system for mapping sentences to dependency trees and to perform parsing as search for the optimal transition sequence for a given sentence (Nivre, 2008). A key component in training transition-based parsers is an oracle, which is used to derive optimal transition sequences from gold parse trees. These sequences can then be used as training data for a classifier that approximates the oracle at parsing time in deterministic classifier-based parsing (Yamada and Matsumoto, 2003; Nivre et al., 2004), or it can be used to determine when to perform updates in online training of a beam search parser (Zhang and Clark, 2008). Currently, such oracles work by translating a given tree to a static sequence of parser transitions which, if run in sequence, w"
C12-1059,W04-2407,1,0.239448,"12. 959 1 Introduction The basic idea in transition-based dependency parsing is to define a nondeterministic transition system for mapping sentences to dependency trees and to perform parsing as search for the optimal transition sequence for a given sentence (Nivre, 2008). A key component in training transition-based parsers is an oracle, which is used to derive optimal transition sequences from gold parse trees. These sequences can then be used as training data for a classifier that approximates the oracle at parsing time in deterministic classifier-based parsing (Yamada and Matsumoto, 2003; Nivre et al., 2004), or it can be used to determine when to perform updates in online training of a beam search parser (Zhang and Clark, 2008). Currently, such oracles work by translating a given tree to a static sequence of parser transitions which, if run in sequence, will produce the gold tree. Most transition systems, including the arc-eager and arc-standard systems described in Nivre (2003, 2004), exhibit spurious ambiguity and map several sequences to the same gold tree. In such cases, the oracles implicitly define a canonical derivation order. We call such oracles static, because they produce a single sta"
C12-1059,P08-1108,1,0.681003,"sting question for future work. The work that probably comes closest to ours is Choi and Palmer (2011), who improve the accuracy of a greedy transition-based dependency parser through an iterative training procedure that they call bootstrapping. They start by training a classifier using a standard static oracle for a hybrid transition system combining elements of the arc-eager system and the algorithm of 11 Stacked learning has been explored to some extent in the context of parsing for integrating approximate higher order features as well as for combining the predictions of different parsers (Nivre and McDonald, 2008; Martins et al., 2008). 971 Covington (2001). In a second step, they then use this classifier to parse the training corpus, creating one new training instance for every configuration visited during parsing, using an adapted version of the static oracle to predict the optimal transition for each configuration. They iterate this procedure as long as parsing accuracy improves on a held-out development set and report improvements in parsing accuracy of about 0.5 percent absolute for English and almost 2 percent absolute for Czech. The main difference compared to our approach, except for the fact"
C12-1059,P05-1013,1,0.317118,"entire QuestionBank (Judge et al., 2006). • ANS, EML, GRPS, REVS, BLGS: the question-answers, emails, newsgroups, reviews and weblogs portions of the English Web Treebank (Bies et al., 2012; Petrov and McDonald, 2012). The CoNLL models are trained on the dedicated training set for each of the ten languages and evaluated on the corresponding test set, with gold standard part-of-speech tags in both cases. Since the arc-eager parser can only handle projective dependency trees, all trees in the training set are projectivized before training, using the baseline pseudo-projective transformation in Nivre and Nilsson (2005). However, non-projective trees are kept intact in the test sets for evaluation. We include all ten languages from the CoNLL 2007 shared task: • ARA: Arabic (Hajiˇc et al., 2004) • BAS: Basque (Aduriz et al., 2003) • CAT: Catalan (Martí et al., 2007) • CHI: Chinese (Chen et al., 2003) • CZE: Czech (Hajiˇc et al., 2001; Böhmová et al., 2003) • ENG: English (Marcus et al., 1993) • GRE: Greek (Prokopidis et al., 2005) • HUN: Hungarian (Czendes et al., 2005) 969 ARA BAS Static Dynamic-ambiguity Dynamic-explore 80.60 80.72 83.06 74.10 74.90 76.10 Static Dynamic-ambiguity Dynamic-explore 71.04 71.06"
C12-1059,W03-3023,0,0.170531,"NG 2012, Mumbai, December 2012. 959 1 Introduction The basic idea in transition-based dependency parsing is to define a nondeterministic transition system for mapping sentences to dependency trees and to perform parsing as search for the optimal transition sequence for a given sentence (Nivre, 2008). A key component in training transition-based parsers is an oracle, which is used to derive optimal transition sequences from gold parse trees. These sequences can then be used as training data for a classifier that approximates the oracle at parsing time in deterministic classifier-based parsing (Yamada and Matsumoto, 2003; Nivre et al., 2004), or it can be used to determine when to perform updates in online training of a beam search parser (Zhang and Clark, 2008). Currently, such oracles work by translating a given tree to a static sequence of parser transitions which, if run in sequence, will produce the gold tree. Most transition systems, including the arc-eager and arc-standard systems described in Nivre (2003, 2004), exhibit spurious ambiguity and map several sequences to the same gold tree. In such cases, the oracles implicitly define a canonical derivation order. We call such oracles static, because they"
C12-1059,D08-1059,0,0.782299,"system for mapping sentences to dependency trees and to perform parsing as search for the optimal transition sequence for a given sentence (Nivre, 2008). A key component in training transition-based parsers is an oracle, which is used to derive optimal transition sequences from gold parse trees. These sequences can then be used as training data for a classifier that approximates the oracle at parsing time in deterministic classifier-based parsing (Yamada and Matsumoto, 2003; Nivre et al., 2004), or it can be used to determine when to perform updates in online training of a beam search parser (Zhang and Clark, 2008). Currently, such oracles work by translating a given tree to a static sequence of parser transitions which, if run in sequence, will produce the gold tree. Most transition systems, including the arc-eager and arc-standard systems described in Nivre (2003, 2004), exhibit spurious ambiguity and map several sequences to the same gold tree. In such cases, the oracles implicitly define a canonical derivation order. We call such oracles static, because they produce a single static sequence of transitions that is supposed to be followed in its entirety. Static oracles are usually specified as rules"
C12-1059,P11-2033,1,0.820458,"ta set and take a relatively long time to train. We instead use a simpler online algorithm which can be viewed as a stochastic approximation of the DAgger algorithm, which is itself heavily inspired by the Searn algorithm. Recent work on beam search and structured prediction for transition-based dependency parsing has shown that parsing accuracy can be improved considerably if models are trained to perform beam search instead of greedy one-best search, and if training is done using a global structured learning objective instead of local learning of individual decisions (Zhang and Clark, 2008; Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Huang et al., 2012). Like our method, beam search with global structured learning mitigates the effects of error propagation by exploring non-canonical configurations at training time, but the use of a beam reduces parsing speed by a factor that is roughly proportional to the size of the beam, making parsing less efficient. Our method in contrast still trains classifiers to perform local decisions, and thus incurs no efficiency penalty at parsing time, but each local decision is trained to take into account the consequences of previous, possibly erroneous, decisions. A"
C12-1059,D07-1096,1,\N,Missing
C12-2136,E12-1009,0,0.0271337,"RDS IN CHINESE: 依存分析, 错误分析, ZPar, MaltParser, MSTParser Proceedings of COLING 2012: Posters, pages 1391–1400, COLING 2012, Mumbai, December 2012. 1391 1 Introduction Beam-search has been applied to transition-based dependency parsing in recent studies (Zhang and Clark, 2008; Huang and Sagae, 2010; Hatori et al., 2011). In addition to reducing search errors compared to greedy search, it also enables the use of global models that accommodate richer non-local features without overfitting, leading to recent state-of-the-art accuracies of transition-based dependency parsing (Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Bohnet and Nivre, 2012) that are competitive with the best graph-based dependency parsers. It has been known that a transition-based parser using global learning, beam-search and rich features gives significantly higher accuracies than one with local learning and greedy search. However, the effects of global learning, beam-search and rich features have not been separately studied. Apart from the natural conclusion that beam-search reduces error propagation compared to greedy search, exactly how these techniques help to improve parsing has not been discussed, and many interesting questions re"
C12-2136,D12-1133,1,0.756664,"误分析, ZPar, MaltParser, MSTParser Proceedings of COLING 2012: Posters, pages 1391–1400, COLING 2012, Mumbai, December 2012. 1391 1 Introduction Beam-search has been applied to transition-based dependency parsing in recent studies (Zhang and Clark, 2008; Huang and Sagae, 2010; Hatori et al., 2011). In addition to reducing search errors compared to greedy search, it also enables the use of global models that accommodate richer non-local features without overfitting, leading to recent state-of-the-art accuracies of transition-based dependency parsing (Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Bohnet and Nivre, 2012) that are competitive with the best graph-based dependency parsers. It has been known that a transition-based parser using global learning, beam-search and rich features gives significantly higher accuracies than one with local learning and greedy search. However, the effects of global learning, beam-search and rich features have not been separately studied. Apart from the natural conclusion that beam-search reduces error propagation compared to greedy search, exactly how these techniques help to improve parsing has not been discussed, and many interesting questions remain unanswered. For exam"
C12-2136,W06-2920,0,0.435748,"xhaustive parsing than local, greedy parsing in the use of global models and non-greedy search. On the other hand, beam-search does not affect the fundamental transition-based parsing process, which allows the use of rich non-local features, and is very different from graph-based parsing. An interesting question is how such differences in models and algorithms affect empirical errors. McDonald and Nivre (2007) make a comparative analysis of local greedy transition-based MaltParser and global near-exhaustive graph-based MSTParser (McDonald and Pereira, 2006) using the CoNLL-X Shared Task data (Buchholz and Marsi, 2006), showing that the parsers give near identical overall accuracies, but have very different error distributions according to various metrics. While MaltParser is more accurate on frequently occurring short sentences and dependencies, it performs worse on long sentences and dependencies due to search errors. We present empirical studies of the error distribution of global, beam-search transition-based dependency parsing, using ZPar (Zhang and Nivre, 2011) as a representative system. We follow McDonald and Nivre (2007) and perform a comparative error analysis of ZPar, MSTParser and MaltParser usi"
C12-2136,W02-1001,0,0.0497659,"Missing"
C12-2136,P04-1015,0,0.0603703,"Missing"
C12-2136,I11-1136,0,0.0151324,"以取得与最好的基于图的依存分析器 同一水平的精度。我们分析全局学习和柱搜索对基于转移的依存分析器的精度与错误分布 的影响。首先，全局学习和柱搜索需要同时使用才能达到显著优于局部学习和贪婪搜索的 效果。此外，全局学习和柱搜索的联合使用不仅可以减少错误蔓延，还可以支持更为复杂 的模型训练而不过拟合。最后，我们对应用了全局学习和柱搜索的基于转移的依存分析器 进行错误分析，且将此分析与对MaltParser与MSTParser的错误对比相比较。 KEYWORDS: Dependency parsing, error analysis, ZPar, MaltParser, MSTParser. KEYWORDS IN CHINESE: 依存分析, 错误分析, ZPar, MaltParser, MSTParser Proceedings of COLING 2012: Posters, pages 1391–1400, COLING 2012, Mumbai, December 2012. 1391 1 Introduction Beam-search has been applied to transition-based dependency parsing in recent studies (Zhang and Clark, 2008; Huang and Sagae, 2010; Hatori et al., 2011). In addition to reducing search errors compared to greedy search, it also enables the use of global models that accommodate richer non-local features without overfitting, leading to recent state-of-the-art accuracies of transition-based dependency parsing (Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Bohnet and Nivre, 2012) that are competitive with the best graph-based dependency parsers. It has been known that a transition-based parser using global learning, beam-search and rich features gives significantly higher accuracies than one with local learning and greedy search. However, the effe"
C12-2136,P10-1110,0,0.113183,"柱搜索和全局模型被应用于基于转移的依存分析，可以取得与最好的基于图的依存分析器 同一水平的精度。我们分析全局学习和柱搜索对基于转移的依存分析器的精度与错误分布 的影响。首先，全局学习和柱搜索需要同时使用才能达到显著优于局部学习和贪婪搜索的 效果。此外，全局学习和柱搜索的联合使用不仅可以减少错误蔓延，还可以支持更为复杂 的模型训练而不过拟合。最后，我们对应用了全局学习和柱搜索的基于转移的依存分析器 进行错误分析，且将此分析与对MaltParser与MSTParser的错误对比相比较。 KEYWORDS: Dependency parsing, error analysis, ZPar, MaltParser, MSTParser. KEYWORDS IN CHINESE: 依存分析, 错误分析, ZPar, MaltParser, MSTParser Proceedings of COLING 2012: Posters, pages 1391–1400, COLING 2012, Mumbai, December 2012. 1391 1 Introduction Beam-search has been applied to transition-based dependency parsing in recent studies (Zhang and Clark, 2008; Huang and Sagae, 2010; Hatori et al., 2011). In addition to reducing search errors compared to greedy search, it also enables the use of global models that accommodate richer non-local features without overfitting, leading to recent state-of-the-art accuracies of transition-based dependency parsing (Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Bohnet and Nivre, 2012) that are competitive with the best graph-based dependency parsers. It has been known that a transition-based parser using global learning, beam-search and rich features gives significantly higher accuracies than one with local learning and greedy sea"
C12-2136,D07-1013,1,0.950889,"d only when the two are jointly applied. Second, we show that the accuracies of a local, greedy transition-based parser cannot be improved by adding the rich features of Zhang and Nivre (2011). Our result suggests that global learning with beam-search accommodates more complex models with richer features than a local model with greedy search and therefore enables higher accuracies. One interesting aspect of using a global model with beam-search is that it narrows down the contrast between “local, greedy, transition-based parsing” and “global, exhaustive, graph-based parsing” as exemplified by McDonald and Nivre (2007). On the one hand, global beam-search parsing is more similar to global, exhaustive parsing than local, greedy parsing in the use of global models and non-greedy search. On the other hand, beam-search does not affect the fundamental transition-based parsing process, which allows the use of rich non-local features, and is very different from graph-based parsing. An interesting question is how such differences in models and algorithms affect empirical errors. McDonald and Nivre (2007) make a comparative analysis of local greedy transition-based MaltParser and global near-exhaustive graph-based M"
C12-2136,E06-1011,0,0.083071,"ne hand, global beam-search parsing is more similar to global, exhaustive parsing than local, greedy parsing in the use of global models and non-greedy search. On the other hand, beam-search does not affect the fundamental transition-based parsing process, which allows the use of rich non-local features, and is very different from graph-based parsing. An interesting question is how such differences in models and algorithms affect empirical errors. McDonald and Nivre (2007) make a comparative analysis of local greedy transition-based MaltParser and global near-exhaustive graph-based MSTParser (McDonald and Pereira, 2006) using the CoNLL-X Shared Task data (Buchholz and Marsi, 2006), showing that the parsers give near identical overall accuracies, but have very different error distributions according to various metrics. While MaltParser is more accurate on frequently occurring short sentences and dependencies, it performs worse on long sentences and dependencies due to search errors. We present empirical studies of the error distribution of global, beam-search transition-based dependency parsing, using ZPar (Zhang and Nivre, 2011) as a representative system. We follow McDonald and Nivre (2007) and perform a co"
C12-2136,P09-1040,1,0.894307,"Missing"
C12-2136,W06-2933,1,0.812759,"tion compared to greedy search, exactly how these techniques help to improve parsing has not been discussed, and many interesting questions remain unanswered. For example, the contribution of global learning in improving the accuracies has not been separately studied. It has not been shown how global learning affects the accuracies, or whether it is important at all. For another example, it would be interesting to know whether a local, greedy, transition-based parser can be equipped with the rich features of Zhang and Nivre (2011) to improve its accuracy, and in particular whether MaltParser (Nivre et al., 2006) can achieve the same level of accuracies as ZPar (Zhang and Nivre, 2011) by using the same range of rich feature definitions. In this paper, we answer the above questions empirically. First, we separate out global learning and beam-search, and study the effect of each technique by comparison with a local greedy baseline. Our results show that significant improvements are achieved only when the two are jointly applied. Second, we show that the accuracies of a local, greedy transition-based parser cannot be improved by adding the rich features of Zhang and Nivre (2011). Our result suggests that"
C12-2136,P05-1013,1,0.492204,"we evaluate the parsers on the CoNLL-X Shared Task data (Buchholz and Marsi, 2006), which include training and test sentences for 13 different languages. For each parser, we conjoin the outputs for all 13 languages in the same way as McDonald and Nivre (2007), and calculate error distributions over the aggregated output. Accuracies are measured using the labeled attached score (LAS) evaluation metric, which is defined as the percentage of words (excluding punctuation) that are assigned both the correct head word and the correct arc label. To handle non-projectivity, pseudo-projective parsing (Nivre and Nilsson, 2005) is applied to ZPar and MaltParser, transforming non-projective trees into pseudo-projective trees in the training data, and post-processing pseudo-projective outputs by the parser to transform them into non-projective trees. MSTParser produces non-projective trees from projective trees by scorebased rearrangements of arcs. 3.2 Error distributions We take a range of different perspectives to characterize the errors of ZPar, comparing them with those of MaltParser and MSTParser by measuring the accuracies against various types of metrics, including the size of the sentences and dependency arcs,"
C12-2136,D08-1059,1,0.893122,"析全局模型和柱搜索对基于转移依存分析器的影响 柱搜索和全局模型被应用于基于转移的依存分析，可以取得与最好的基于图的依存分析器 同一水平的精度。我们分析全局学习和柱搜索对基于转移的依存分析器的精度与错误分布 的影响。首先，全局学习和柱搜索需要同时使用才能达到显著优于局部学习和贪婪搜索的 效果。此外，全局学习和柱搜索的联合使用不仅可以减少错误蔓延，还可以支持更为复杂 的模型训练而不过拟合。最后，我们对应用了全局学习和柱搜索的基于转移的依存分析器 进行错误分析，且将此分析与对MaltParser与MSTParser的错误对比相比较。 KEYWORDS: Dependency parsing, error analysis, ZPar, MaltParser, MSTParser. KEYWORDS IN CHINESE: 依存分析, 错误分析, ZPar, MaltParser, MSTParser Proceedings of COLING 2012: Posters, pages 1391–1400, COLING 2012, Mumbai, December 2012. 1391 1 Introduction Beam-search has been applied to transition-based dependency parsing in recent studies (Zhang and Clark, 2008; Huang and Sagae, 2010; Hatori et al., 2011). In addition to reducing search errors compared to greedy search, it also enables the use of global models that accommodate richer non-local features without overfitting, leading to recent state-of-the-art accuracies of transition-based dependency parsing (Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Bohnet and Nivre, 2012) that are competitive with the best graph-based dependency parsers. It has been known that a transition-based parser using global learning, beam-search and rich features gives significantly higher accuracies than one with local"
C12-2136,J11-1005,1,0.498712,"sing the shift-reduce process than a global tree search. 4 Conclusion We studied empirically the effect of global learning and beam-search on the overall accuracies and error distributions of transition-based dependency parsing. We first analyzed the ways in which global learning and beam-search improved parsing accuracies over local learning and greedy search, showing that they allow more complex parsing models without overfitting, including the use of rich non-local features and online reordering for non-projective parsing, which result in state-of-the-art accuracies (Zhang and Nivre, 2011; Zhang and Clark, 2011; Bohnet and Nivre, 2012). We also showed that the effects result from the interaction between global learning and beam-search, and that applying either of the techniques by itself does not lead to improvements over local learning and greedy search. We then performed a detailed error analysis of a global, beam-search transition-based dependency parser, relating it to the classic comparison of local greedy transition-based and global near-exhaustive graph-based parsing (McDonald and Nivre, 2007). Our results might serve to inspire further parser developments by providing more insights into thes"
C12-2136,P11-2033,1,0.525544,"arser, MSTParser. KEYWORDS IN CHINESE: 依存分析, 错误分析, ZPar, MaltParser, MSTParser Proceedings of COLING 2012: Posters, pages 1391–1400, COLING 2012, Mumbai, December 2012. 1391 1 Introduction Beam-search has been applied to transition-based dependency parsing in recent studies (Zhang and Clark, 2008; Huang and Sagae, 2010; Hatori et al., 2011). In addition to reducing search errors compared to greedy search, it also enables the use of global models that accommodate richer non-local features without overfitting, leading to recent state-of-the-art accuracies of transition-based dependency parsing (Zhang and Nivre, 2011; Bohnet and Kuhn, 2012; Bohnet and Nivre, 2012) that are competitive with the best graph-based dependency parsers. It has been known that a transition-based parser using global learning, beam-search and rich features gives significantly higher accuracies than one with local learning and greedy search. However, the effects of global learning, beam-search and rich features have not been separately studied. Apart from the natural conclusion that beam-search reduces error propagation compared to greedy search, exactly how these techniques help to improve parsing has not been discussed, and many i"
C16-1325,W03-2405,0,0.250537,"me the first Turkish treebank to be included in a UD release. The treebank was created by automatic conversion of the IMST This work is licenced under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 1 http://universaldependencies.org/ License details: http:// 3444 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 3444–3454, Osaka, Japan, December 11-17 2016. Treebank (Sulubacak et al., 2016), which is itself a reannotation of the METU-Sabancı Turkish Treebank (Oflazer et al., 2003; Atalay et al., 2003). Although the annotation framework of the IMST Treebank was revised, it is still fundamentally similar to that of the METU-Sabancı Treebank and radically different from the UD framework in both morphology and syntax. In this paper, we describe the procedures employed in converting the annotation schemes of the IMST Treebank to the corresponding UD-compliant schemes. We also provide comparative statistics on the composition of the IMST Treebank before and after the conversion. Afterwards, we report our initial parsing results on the new IMST-UD Treebank in comparison with the original IMST Tre"
C16-1325,de-marneffe-etal-2006-generating,0,0.185725,"Missing"
C16-1325,de-marneffe-etal-2014-universal,1,0.918476,"Missing"
C16-1325,E06-1012,0,0.552875,"Missing"
C16-1325,J08-3003,1,0.900686,"Missing"
C16-1325,W11-3806,1,0.873339,"Missing"
C16-1325,P99-1033,0,0.107905,"word has a separate row, each containing a tabdelimited array of morphosyntactic data pertaining to the word. In compliance with the UD standard, the converted sentences were output in the CoNLL-U format.2 The sections to follow present explanations and discussions on the procedures of mapping morphological and syntactic data, as well as some idiosyncratic linguistic phenomena. Quick reference tables were also provided where applicable, showing what conditions on the source unit are required to assign which properties to the target unit. 2.1 Segmentation The inflectional group (IG) formalism (Oflazer, 1999; Hakkani-T¨ur et al., 2002) was designed to make the highly agglutinative typology of Turkish tractable for language processing. Since then, it has seen usage in many influential works (Oflazer, 2003; Eryi˘git and Oflazer, 2006) and has become the de facto standard in parsing Turkish. According to the formalism, orthographic tokens are divided into morphosyntactic words from derivational boundaries.3 These units are called the inflectional groups (IGs) of the token. The IG formalism establishes these, rather than orthographic tokens, as the syntactic units of the sentence. The original IMST t"
C16-1325,J03-4001,0,0.0451041,"mat.2 The sections to follow present explanations and discussions on the procedures of mapping morphological and syntactic data, as well as some idiosyncratic linguistic phenomena. Quick reference tables were also provided where applicable, showing what conditions on the source unit are required to assign which properties to the target unit. 2.1 Segmentation The inflectional group (IG) formalism (Oflazer, 1999; Hakkani-T¨ur et al., 2002) was designed to make the highly agglutinative typology of Turkish tractable for language processing. Since then, it has seen usage in many influential works (Oflazer, 2003; Eryi˘git and Oflazer, 2006) and has become the de facto standard in parsing Turkish. According to the formalism, orthographic tokens are divided into morphosyntactic words from derivational boundaries.3 These units are called the inflectional groups (IGs) of the token. The IG formalism establishes these, rather than orthographic tokens, as the syntactic units of the sentence. The original IMST treebank also follows its predecessors in using the IG formalism. The rightmost IG governs the word, while every other IG depends on the next one in line with the exclusive relation DERIV. Though a com"
C16-1325,petrov-etal-2012-universal,0,0.0603661,"the UD framework is at least as viable for Turkish as the original annotation framework of the IMST Treebank. 1 Introduction The Universal Dependencies (UD)1 project is an international collaborative project to make cross-linguistically consistent treebanks available for a wide variety of languages. Currently in version 1.3, the UD project covers 40 languages, including two Turkic languages: Kazakh, which was annotated from scratch, and Turkish, the creation of which is described in this paper. The universal annotation guidelines of UD are based on the Google Universal Part-of-Speech Tagset (Petrov et al., 2012) for parts of speech, the Interset framework (Zeman, 2008) for morphological features, and Stanford Dependencies (De Marneffe et al., 2006; Tsarfaty, 2013; De Marneffe et al., 2014) for dependency relations. The objective of harmonizing annotation guidelines as far as possible is to make comparison of parsing results and investigating cross-linguistic methods across languages easier. This is achieved by a number of principles, including the primacy of content words, distinguishing core arguments from modifiers and distinguishing clausal constituents from nominals. The IMST-UD Treebank was firs"
C16-1325,W13-4915,1,0.888478,"Missing"
C16-1325,P13-2103,0,0.0332315,"roject is an international collaborative project to make cross-linguistically consistent treebanks available for a wide variety of languages. Currently in version 1.3, the UD project covers 40 languages, including two Turkic languages: Kazakh, which was annotated from scratch, and Turkish, the creation of which is described in this paper. The universal annotation guidelines of UD are based on the Google Universal Part-of-Speech Tagset (Petrov et al., 2012) for parts of speech, the Interset framework (Zeman, 2008) for morphological features, and Stanford Dependencies (De Marneffe et al., 2006; Tsarfaty, 2013; De Marneffe et al., 2014) for dependency relations. The objective of harmonizing annotation guidelines as far as possible is to make comparison of parsing results and investigating cross-linguistic methods across languages easier. This is achieved by a number of principles, including the primacy of content words, distinguishing core arguments from modifiers and distinguishing clausal constituents from nominals. The IMST-UD Treebank was first released in UD version 1.3 and became the first Turkish treebank to be included in a UD release. The treebank was created by automatic conversion of the"
C16-1325,zeman-2008-reusable,0,0.0261613,"l annotation framework of the IMST Treebank. 1 Introduction The Universal Dependencies (UD)1 project is an international collaborative project to make cross-linguistically consistent treebanks available for a wide variety of languages. Currently in version 1.3, the UD project covers 40 languages, including two Turkic languages: Kazakh, which was annotated from scratch, and Turkish, the creation of which is described in this paper. The universal annotation guidelines of UD are based on the Google Universal Part-of-Speech Tagset (Petrov et al., 2012) for parts of speech, the Interset framework (Zeman, 2008) for morphological features, and Stanford Dependencies (De Marneffe et al., 2006; Tsarfaty, 2013; De Marneffe et al., 2014) for dependency relations. The objective of harmonizing annotation guidelines as far as possible is to make comparison of parsing results and investigating cross-linguistic methods across languages easier. This is achieved by a number of principles, including the primacy of content words, distinguishing core arguments from modifiers and distinguishing clausal constituents from nominals. The IMST-UD Treebank was first released in UD version 1.3 and became the first Turkish"
C16-1325,J08-4010,1,\N,Missing
C18-1112,P17-1183,0,0.0252668,"elopment of general NMT systems, especially for low-resource languages. Since NMT models are more likely to generate incorrect normalizations of unchanged spellings, we propose a hybrid method using both NMT-based methods and dictionary-based method which improves the performance further. In the future, we could 1) explore some hard-attention-based models, 2) introduce phoneme knowledge into NMT models, and 3) use sentence pairs for spelling normalization. Compared to soft attention, 1328 hard attention (Xu et al., 2015) only pays attention to one or several specified source word annotations. Aharoni and Goldberg (2017) employ hard monotonic attention for a morphological inflection generation task. The variation between historical spelling and modern spelling is usually monotonic, which is similar to morphological inflection. Thus, hard attention should work well in historical spelling normalization as well. Many words have changed their spellings, but they keep the same pronunciation. Thus, Bollmann et al. (2017) use an additional grapheme-to-phoneme dictionary in a multi-task learning setting. We can add the phonetic dictionaries as additional training data to improve the performance. In addition to token-"
C18-1112,C16-1013,0,0.253116,"ethods, and SMT methods on five different historical languages. The results show that the character-level SMT model performs best on four out of five historical languages. With the development of deep learning, various neural networks have been applied to many tasks. In recent years, NMT models (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) have outperformed SMT models (Koehn et al., 2003) distinctly in various translation tasks. We hypothesize that NMT models also perform better than SMT models for the historical spelling normalization task. Bollmann and Søgaard (2016) view the spelling normalization as a character-level sequence labeling task, and utilize a bi-directional LSTM for this task, which is better than a conditional random field (CRF) model. They also use additional data with similar but not the same historical spelling for a multi-task learning model, and gain further improvement. Korchagina (2017) applies a character-level NMT model to medieval German text, and finds that the NMT models can only outperform the SMT models with a larger training set. Bollmann et al. (2017) test attentionbased NMT models, and multi-task learning models which learn"
C18-1112,W11-4106,0,0.0914496,"T models considering character error rate (CER). We show that vanilla RNNs are competitive to GRUs/LSTMs. We demonstrate that transformer models perform better when provided with more training data. We reveal that models with a small subword vocabulary are better than character-level models. Related Work Historical Spelling Normalization Various methods have been employed for historical spelling normalization. Rayson et al. (2005) use a dictionary to map tokens to their modernized spellings, and many different edit-distance-based methods have been proposed to deal with spelling normalization (Bollmann et al., 2011; Pettersson et al., 2013a). In addition, character-level SMT models have been applied to spelling normalization, where models are trained on token pairs instead of sentence pairs (Pettersson et al., 2013b; Scherrer and Erjavec, 2013; Sánchez-Martínez et al., 2013). Each character of a token is viewed as a word of a sentence. The language models are trained on character N-grams instead of word N-grams. Pettersson et al. (2014) evaluate dictionary-based methods, edit distance-based methods, and SMT methods on five different historical languages. The results show that the character-level SMT mod"
C18-1112,P17-1031,0,0.22794,"used for these historical texts directly. Spelling normalization is the task of mapping a historical spelling to its modern spelling. It is usually used as a preprocessing step before feeding the historical text into modern NLP tools (Pettersson et al., 2013b; Bollmann, 2013; Sánchez-Martínez et al., 2013), which leads to much better results compared to analyzing unnormalized historical texts. There are some papers in which neural machine translation (NMT) models are employed for the spelling normalization task. Korchagina (2017) utilizes a character-level NMT model for medieval German texts. Bollmann et al. (2017) apply an attention-based NMT model to historical German texts. The evidence so far is too incomplete to draw any general conclusions about the utility of different NMT models for historical spelling normalization. We are interested in exploring how different properties of NMT models interact with different aspects of the spelling normalization problem and find some generalizations about the use of NMT models for this task. In this paper, we apply different NMT models to the spelling normalization task for historical stages of five languages, English, German, Hungarian, Icelandic, and Swedish."
C18-1112,W13-2302,0,0.0253538,"model, which leads to data sparsity issues when using statistical methods, similar to the situation for low-resource languages. Second, there are a lot of variations in historical texts from different time periods, not only in spelling but also in lexical semantics and syntax. Therefore, the NLP tools developed for modern text cannot be used for these historical texts directly. Spelling normalization is the task of mapping a historical spelling to its modern spelling. It is usually used as a preprocessing step before feeding the historical text into modern NLP tools (Pettersson et al., 2013b; Bollmann, 2013; Sánchez-Martínez et al., 2013), which leads to much better results compared to analyzing unnormalized historical texts. There are some papers in which neural machine translation (NMT) models are employed for the spelling normalization task. Korchagina (2017) utilizes a character-level NMT model for medieval German texts. Bollmann et al. (2017) apply an attention-based NMT model to historical German texts. The evidence so far is too incomplete to draw any general conclusions about the utility of different NMT models for historical spelling normalization. We are interested in exploring how dif"
C18-1112,D17-1151,0,0.0215861,"ted. It should be noted that we compare the gap to the gap in NMT (Bahdanau et al., 2015)1 . Hypothesis 2 The gap between NMT models with attention and without attention is also small. Since the average token length is only around five, additionally paying attention to all the tokens in the source sentence may be unnecessary. Thus, we hypothesize that the decoder in the vanilla Encoder-Decoder model can predict most of the targets correctly with only one fixed-size vector from the encoder, even without any attention mechanisms. It should be mentioned that we compare the gap to the gap in NMT (Britz et al., 2017)2 . Hypothesis 3 Transformer models perform better than soft-attention-based models. Transformer models have more advanced self-attention networks and more fine-grained multi-head attention mechanisms compared to RNN-based models with soft-attention. Thus, transformer models have better performance in conventional translation tasks. We hypothesize that it is the same in the spelling normalization task. Hypothesis 4 Subword-level NMT models perform better than character-level NMT models. Character-level and subword-level models are proposed to deal with the problem of out-of-vocabulary words ma"
C18-1112,D14-1179,0,0.074642,"Missing"
C18-1112,P16-1160,0,0.0220523,"distance dependencies. To deal with these problems, Cho et al. (2014) propose GRUs, while Sutskever et al. (2014) use LSTMs (Hochreiter and Schmidhuber, 1997) to replace the vanilla RNNs. However, any two tokens in RNNs still have a linear distance. Thus, Vaswani et al. (2017) replace RNNs with self-attention networks which connect any two tokens in a sentence directly. Due to the expensive computation of NMT models, the vocabulary size is usually very limited, which causes a lot of out-of-vocabulary (OOV) words. Character-level models (Ling et al., 2015; Costa-jussà 1321 and Fonollosa, 2016; Chung et al., 2016) and subword-level models (Sennrich et al., 2016; Wu et al., 2016) are widely used to deal with OOV problems. These two kinds of models need additional segmentation compared to word-level models. For character-level models, we just need to separate each character by space. But we need more complicated segmentation methods for subword-level models. Sennrich et al. (2016) utilize character n-grams and a byte pair encoding (BPE) algorithm (Gage, 1994) for segmentation. Wu et al. (2016) apply the wordpiece model (Schuster and Nakajima, 2012) to segmentation. Based on their experiments, subword-lev"
C18-1112,P16-2058,0,0.0486212,"Missing"
C18-1112,D13-1176,0,0.544035,"tersson et al., 2013b; Scherrer and Erjavec, 2013; Sánchez-Martínez et al., 2013). Each character of a token is viewed as a word of a sentence. The language models are trained on character N-grams instead of word N-grams. Pettersson et al. (2014) evaluate dictionary-based methods, edit distance-based methods, and SMT methods on five different historical languages. The results show that the character-level SMT model performs best on four out of five historical languages. With the development of deep learning, various neural networks have been applied to many tasks. In recent years, NMT models (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) have outperformed SMT models (Koehn et al., 2003) distinctly in various translation tasks. We hypothesize that NMT models also perform better than SMT models for the historical spelling normalization task. Bollmann and Søgaard (2016) view the spelling normalization as a character-level sequence labeling task, and utilize a bi-directional LSTM for this task, which is better than a conditional random field (CRF) model. They also use additional data with similar but not the same historical spelling for a multi-task learning model,"
C18-1112,N03-1017,0,0.0471731,"d of a sentence. The language models are trained on character N-grams instead of word N-grams. Pettersson et al. (2014) evaluate dictionary-based methods, edit distance-based methods, and SMT methods on five different historical languages. The results show that the character-level SMT model performs best on four out of five historical languages. With the development of deep learning, various neural networks have been applied to many tasks. In recent years, NMT models (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015) have outperformed SMT models (Koehn et al., 2003) distinctly in various translation tasks. We hypothesize that NMT models also perform better than SMT models for the historical spelling normalization task. Bollmann and Søgaard (2016) view the spelling normalization as a character-level sequence labeling task, and utilize a bi-directional LSTM for this task, which is better than a conditional random field (CRF) model. They also use additional data with similar but not the same historical spelling for a multi-task learning model, and gain further improvement. Korchagina (2017) applies a character-level NMT model to medieval German text, and fi"
C18-1112,W17-0504,0,0.853352,"emantics and syntax. Therefore, the NLP tools developed for modern text cannot be used for these historical texts directly. Spelling normalization is the task of mapping a historical spelling to its modern spelling. It is usually used as a preprocessing step before feeding the historical text into modern NLP tools (Pettersson et al., 2013b; Bollmann, 2013; Sánchez-Martínez et al., 2013), which leads to much better results compared to analyzing unnormalized historical texts. There are some papers in which neural machine translation (NMT) models are employed for the spelling normalization task. Korchagina (2017) utilizes a character-level NMT model for medieval German texts. Bollmann et al. (2017) apply an attention-based NMT model to historical German texts. The evidence so far is too incomplete to draw any general conclusions about the utility of different NMT models for historical spelling normalization. We are interested in exploring how different properties of NMT models interact with different aspects of the spelling normalization problem and find some generalizations about the use of NMT models for this task. In this paper, we apply different NMT models to the spelling normalization task for h"
C18-1112,P02-1040,0,0.1012,"Missing"
C18-1112,W13-5617,1,0.933746,"tated data for training a model, which leads to data sparsity issues when using statistical methods, similar to the situation for low-resource languages. Second, there are a lot of variations in historical texts from different time periods, not only in spelling but also in lexical semantics and syntax. Therefore, the NLP tools developed for modern text cannot be used for these historical texts directly. Spelling normalization is the task of mapping a historical spelling to its modern spelling. It is usually used as a preprocessing step before feeding the historical text into modern NLP tools (Pettersson et al., 2013b; Bollmann, 2013; Sánchez-Martínez et al., 2013), which leads to much better results compared to analyzing unnormalized historical texts. There are some papers in which neural machine translation (NMT) models are employed for the spelling normalization task. Korchagina (2017) utilizes a character-level NMT model for medieval German texts. Bollmann et al. (2017) apply an attention-based NMT model to historical German texts. The evidence so far is too incomplete to draw any general conclusions about the utility of different NMT models for historical spelling normalization. We are interested in"
C18-1112,W14-0605,1,0.945031,"to historical German texts. The evidence so far is too incomplete to draw any general conclusions about the utility of different NMT models for historical spelling normalization. We are interested in exploring how different properties of NMT models interact with different aspects of the spelling normalization problem and find some generalizations about the use of NMT models for this task. In this paper, we apply different NMT models to the spelling normalization task for historical stages of five languages, English, German, Hungarian, Icelandic, and Swedish. We compare our result to those of Pettersson et al. (2014), which are obtained with statistical machine translation (SMT) models. We investigate whether NMT models outperform SMT models in general, and explore which properties of NMT models are suitable for spelling normalization. Compared to the conventional machine translation (MT) tasks, we train models on token pairs instead of sentence pairs. Token length is usually shorter than sentence length. After reviewing related work in Section 2, we give our hypotheses about utilizing NMT models for the spelling normalization task and select different NMT models based on our hypotheses in Section 3. The"
C18-1112,rognvaldsson-etal-2012-icelandic,0,0.124786,"Missing"
C18-1112,W11-0415,0,0.0802436,"Missing"
C18-1112,W13-2409,0,0.0481456,"small subword vocabulary are better than character-level models. Related Work Historical Spelling Normalization Various methods have been employed for historical spelling normalization. Rayson et al. (2005) use a dictionary to map tokens to their modernized spellings, and many different edit-distance-based methods have been proposed to deal with spelling normalization (Bollmann et al., 2011; Pettersson et al., 2013a). In addition, character-level SMT models have been applied to spelling normalization, where models are trained on token pairs instead of sentence pairs (Pettersson et al., 2013b; Scherrer and Erjavec, 2013; Sánchez-Martínez et al., 2013). Each character of a token is viewed as a word of a sentence. The language models are trained on character N-grams instead of word N-grams. Pettersson et al. (2014) evaluate dictionary-based methods, edit distance-based methods, and SMT methods on five different historical languages. The results show that the character-level SMT model performs best on four out of five historical languages. With the development of deep learning, various neural networks have been applied to many tasks. In recent years, NMT models (Kalchbrenner and Blunsom, 2013; Sutskever et al.,"
C18-1112,P16-1162,0,0.362497,"lems, Cho et al. (2014) propose GRUs, while Sutskever et al. (2014) use LSTMs (Hochreiter and Schmidhuber, 1997) to replace the vanilla RNNs. However, any two tokens in RNNs still have a linear distance. Thus, Vaswani et al. (2017) replace RNNs with self-attention networks which connect any two tokens in a sentence directly. Due to the expensive computation of NMT models, the vocabulary size is usually very limited, which causes a lot of out-of-vocabulary (OOV) words. Character-level models (Ling et al., 2015; Costa-jussà 1321 and Fonollosa, 2016; Chung et al., 2016) and subword-level models (Sennrich et al., 2016; Wu et al., 2016) are widely used to deal with OOV problems. These two kinds of models need additional segmentation compared to word-level models. For character-level models, we just need to separate each character by space. But we need more complicated segmentation methods for subword-level models. Sennrich et al. (2016) utilize character n-grams and a byte pair encoding (BPE) algorithm (Gage, 1994) for segmentation. Wu et al. (2016) apply the wordpiece model (Schuster and Nakajima, 2012) to segmentation. Based on their experiments, subword-level models outperform word-level and character-le"
C18-1112,P18-4020,0,\N,Missing
C96-2192,A92-1018,0,0.0543266,"Missing"
C96-2192,J88-1003,0,\N,Missing
C96-2192,W95-0201,0,\N,Missing
C96-2192,E93-1064,0,\N,Missing
C96-2192,C90-2040,0,\N,Missing
C96-2192,C90-3030,0,\N,Missing
C96-2192,J94-2001,0,\N,Missing
C96-2192,E95-1021,0,\N,Missing
D07-1013,W06-2920,0,0.779687,"mputational linguistics community and have been successfully employed for many problems ranging from machine translation (Ding and Palmer, 2004) to ontology construction (Snow et al., 2004). In this work we focus on a common parsing paradigm called datadriven dependency parsing. Unlike grammar-based parsing, data-driven approaches learn to produce dependency graphs for sentences solely from an annotated corpus. The advantage of such models is that they are easily ported to any domain or language in which annotated resources exist. As evident from the CoNLL-X shared task on dependency parsing (Buchholz and Marsi, 2006), there are currently two dominant models for data-driven dependency parsing. The first is what Buchholz and Marsi (2006) call the “all-pairs” approach, where every possible arc is considered in the construction of the optimal parse. The second is the “stepwise” approach, where the optimal parse is built stepwise and where the subset of possible arcs considered depend on previous decisions. Theoretically, these models are extremely different. The all-pairs models are globally trained, use exact (or near exact) inference algorithms, and define features over a limited history of parsing decision"
D07-1013,W04-1513,0,0.0175923,"ough labeled directed arcs, as shown in Figure 1, taken from the Prague Dependency Treebank (B¨ohmov´a et al., 2003). A primary advantage of dependency representations is that they have a natural mechanism for representing discontinuous constructions, arising from long distance dependencies or free word order, through non-projective dependency arcs, exemplified by the arc from jedna to Z in Figure 1. Syntactic dependency graphs have recently gained a wide interest in the computational linguistics community and have been successfully employed for many problems ranging from machine translation (Ding and Palmer, 2004) to ontology construction (Snow et al., 2004). In this work we focus on a common parsing paradigm called datadriven dependency parsing. Unlike grammar-based parsing, data-driven approaches learn to produce dependency graphs for sentences solely from an annotated corpus. The advantage of such models is that they are easily ported to any domain or language in which annotated resources exist. As evident from the CoNLL-X shared task on dependency parsing (Buchholz and Marsi, 2006), there are currently two dominant models for data-driven dependency parsing. The first is what Buchholz and Marsi (200"
D07-1013,P90-1005,0,0.260126,"tadriven dependency parsing: global, exhaustive, graph-based models, and local, greedy, transition-based models. We show that, in spite of similar performance overall, the two models produce different types of errors, in a way that can be explained by theoretical properties of the two models. This analysis leads to new directions for parser development. 1 Figure 1: Example dependency graph. Introduction Syntactic dependency representations have a long history in descriptive and theoretical linguistics and many formal models have been advanced (Hudson, 1984; Mel’ˇcuk, 1988; Sgall et al., 1986; Maruyama, 1990). A dependency graph of a sentence represents each word and its syntactic modifiers through labeled directed arcs, as shown in Figure 1, taken from the Prague Dependency Treebank (B¨ohmov´a et al., 2003). A primary advantage of dependency representations is that they have a natural mechanism for representing discontinuous constructions, arising from long distance dependencies or free word order, through non-projective dependency arcs, exemplified by the arc from jedna to Z in Figure 1. Syntactic dependency graphs have recently gained a wide interest in the computational linguistics community a"
D07-1013,P05-1012,1,0.15271,"e, define the score of a graph as the sum of its arc scores, X s(G = (V, A)) = s(i, j, l) (i,j,l)∈A The score of a dependency arc, s(i, j, l) represents the likelihood of creating a dependency from word wi to word wj with the label l. If the arc score function is known a priori, then the parsing problem can be stated as, G = arg max s(G) = arg max G∈D(Gx ) X s(i, j, l) G∈D(Gx ) (i,j,l)∈A This problem is equivalent to finding the highest scoring directed spanning tree in the graph Gx originating out of the root node 0, which can be solved for both the labeled and unlabeled case in O(n2 ) time (McDonald et al., 2005b). In this approach, nonprojective arcs are produced naturally through the inference algorithm that searches over all possible directed trees, whether projective or not. The parsing models of McDonald work primarily in this framework. To learn arc scores, these models use large-margin structured learning algorithms (McDonald et al., 2005a), which optimize the parameters of the model to maximize the score margin between the correct dependency graph and all incorrect dependency graphs for every sentence in a training set. The learning procedure is global since model parameters are set relative"
D07-1013,H05-1066,1,0.202859,"Missing"
D07-1013,W06-2932,1,0.71883,"85.82 91.65 87.60 70.30 81.29 84.58 65.68 80.75 1. V = {0, 1, . . . , n} 2. If (i, j, l) ∈ A, then j 6= 0. 3. If (i, j, l) ∈ A, then for all i0 ∈ V − {i} and l0 ∈ L, (i0 , j, l0 ) ∈ / A. 4. For all j ∈ V − {0}, there is a (possibly empty) sequence of nodes i1 , . . . , im ∈V and labels l1 , . . . , lm , l∈L such that (0, i1 , l1 ),(i1 , i2 , l2 ), . . . , (im , j, l)∈A. Table 1: Labeled parsing accuracy for top scoring systems at CoNLL-X (Buchholz and Marsi, 2006). on a variety of languages, as seen in Table 1, which shows results for the two top performing systems in the CoNLL-X shared task, McDonald et al. (2006) (“all-pairs”) and Nivre et al. (2006) (“stepwise”). Despite the similar performance in terms of overall accuracy, there are indications that the two types of models exhibit different behaviour. For example, Sagae and Lavie (2006) displayed that combining the predictions of both parsing models can lead to significantly improved accuracies. In order to pave the way for new and better methods, a much more detailed error analysis is needed to understand the strengths and weaknesses of different approaches. In this work we set out to do just that, focusing on the two top performing systems from th"
D07-1013,P05-1013,1,0.620556,"systems for data-driven dependency parsing are inspired by shift-reduce parsing, where configurations contain a stack for storing partially processed nodes. Transitions in such systems add arcs to the dependency graph and/or manipulate the stack. One example is the transition system defined by Nivre (2003), which parses a sentence x = w0 , w1 , . . . , wn in O(n) time, producing a projective dependency graph satisfying conditions 1–4 in section 2.1, possibly after adding arcs (0, i, lr ) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers). Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing. To learn transition scores, these systems use discriminative learning methods, e.g., memory-based learning or support vector machines. The learning procedure is local since only single transitions are scored, not entire transition sequences. The primary advantage of these models is that features are not restricted to a limited number of graph arcs but can take into account the entire"
D07-1013,W06-2933,1,0.80114,"80.75 1. V = {0, 1, . . . , n} 2. If (i, j, l) ∈ A, then j 6= 0. 3. If (i, j, l) ∈ A, then for all i0 ∈ V − {i} and l0 ∈ L, (i0 , j, l0 ) ∈ / A. 4. For all j ∈ V − {0}, there is a (possibly empty) sequence of nodes i1 , . . . , im ∈V and labels l1 , . . . , lm , l∈L such that (0, i1 , l1 ),(i1 , i2 , l2 ), . . . , (im , j, l)∈A. Table 1: Labeled parsing accuracy for top scoring systems at CoNLL-X (Buchholz and Marsi, 2006). on a variety of languages, as seen in Table 1, which shows results for the two top performing systems in the CoNLL-X shared task, McDonald et al. (2006) (“all-pairs”) and Nivre et al. (2006) (“stepwise”). Despite the similar performance in terms of overall accuracy, there are indications that the two types of models exhibit different behaviour. For example, Sagae and Lavie (2006) displayed that combining the predictions of both parsing models can lead to significantly improved accuracies. In order to pave the way for new and better methods, a much more detailed error analysis is needed to understand the strengths and weaknesses of different approaches. In this work we set out to do just that, focusing on the two top performing systems from the CoNLL-X shared task as representativ"
D07-1013,W03-3017,1,0.186877,"x , starting from the initial configuration cx and taking the optimal transition t∗ = arg maxt∈T s(c, t) out of every configuration c. This can be seen as a greedy search for the optimal dependency graph, based on a sequence of locally optimal decisions in terms of the transition system. Many transition systems for data-driven dependency parsing are inspired by shift-reduce parsing, where configurations contain a stack for storing partially processed nodes. Transitions in such systems add arcs to the dependency graph and/or manipulate the stack. One example is the transition system defined by Nivre (2003), which parses a sentence x = w0 , w1 , . . . , wn in O(n) time, producing a projective dependency graph satisfying conditions 1–4 in section 2.1, possibly after adding arcs (0, i, lr ) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers). Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing. To learn transition scores, these systems use discriminative learning"
D07-1013,E06-1010,1,0.29887,"ween the parsers on this metric. MSTParser is slightly more precise for arcs that are predicted with more siblings, whereas MaltParser has slightly higher recall on arcs that have more siblings in the gold standard tree. Arcs closer to the root tend to have more siblings, which ties this result to the previous ones. The final graph property we wish to look at is the degree of non-projectivity. The degree of a dependency arc from word w to word u is defined here as the number of words occurring between w and u that are not descendants of w and modify a word that does not occur between w and u (Nivre, 2006). In the example from Figure 1, the arc from jedna to Z has a degree of one, and all other arcs have a degree of zero. Figure 6 plots dependency arc precision and recall relative to arc degree in predicted and gold standard dependency graphs. MSTParser is more 127 precise when predicting arcs with high degree and MaltParser vice-versa. Again, this can be explained by the fact that there is a tight correlation between a high degree of non-projectivity, dependency length, distance to root and number of siblings. 4.3 Linguistic Factors It is important to relate each system’s accuracy to a set of"
D07-1013,N06-2033,0,0.632561,"y empty) sequence of nodes i1 , . . . , im ∈V and labels l1 , . . . , lm , l∈L such that (0, i1 , l1 ),(i1 , i2 , l2 ), . . . , (im , j, l)∈A. Table 1: Labeled parsing accuracy for top scoring systems at CoNLL-X (Buchholz and Marsi, 2006). on a variety of languages, as seen in Table 1, which shows results for the two top performing systems in the CoNLL-X shared task, McDonald et al. (2006) (“all-pairs”) and Nivre et al. (2006) (“stepwise”). Despite the similar performance in terms of overall accuracy, there are indications that the two types of models exhibit different behaviour. For example, Sagae and Lavie (2006) displayed that combining the predictions of both parsing models can lead to significantly improved accuracies. In order to pave the way for new and better methods, a much more detailed error analysis is needed to understand the strengths and weaknesses of different approaches. In this work we set out to do just that, focusing on the two top performing systems from the CoNLL-X shared task as representatives of the two dominant models in data-driven dependency parsing. 2 2.1 Two Models for Dependency Parsing Preliminaries Let L = {l1 , . . . , l|L |} be a set of permissible arc labels. Let x ="
D07-1096,D07-1119,0,0.635846,"Missing"
D07-1096,D07-1120,0,0.0179351,"Missing"
D07-1096,W06-1615,1,0.130888,"d annotated resources available in the target domain, and many studies have shown that this may lead to substantial improvements. This includes the work of Roark and Bacchiani (2003), Florian et al. (2004), Chelba and Acero (2004), Daum´e and Marcu (2006), and Titov and Henderson (2006). Of these, Roark and Bacchiani (2003) and Titov and Henderson (2006) deal specifically with syntactic parsing. The second scenario assumes that there are no annotated resources in the target domain. This is a more realistic situation and is considerably more difficult. Recent work by McClosky et al. (2006) and Blitzer et al. (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation. For this shared-task, we are assuming the latter setting – no annotated resources in the target domain. Obtaining adequate annotated syntactic resources for multiple languages is already a challenging problem, which is only exacerbated when these resources must be drawn from multiple and diverse domains. As a result, the only language that could be feasibly tested in the domain adaptation track was English. The setup for the domain adaptation track was as follows. Participants were prov"
D07-1096,W06-2920,0,0.770442,"d provide a first analysis of these results. 1 Introduction Previous shared tasks of the Conference on Computational Natural Language Learning (CoNLL) have been devoted to chunking (1999, 2000), clause identification (2001), named entity recognition (2002, 2003), and semantic role labeling (2004, 2005). In 2006 the shared task was multilingual dependency parsing, where participants had to train a single parser on data from thirteen different languages, which enabled a comparison not only of parsing and learning methods, but also of the performance that can be achieved for different languages (Buchholz and Marsi, 2006). In dependency-based syntactic parsing, the task is to derive a syntactic structure for an input sentence by identifying the syntactic head of each word in the sentence. This defines a dependency graph, where In this year’s shared task, we continue to explore data-driven methods for multilingual dependency parsing, but we add a new dimension by also introducing the problem of domain adaptation. The way this was done was by having two separate tracks: a multilingual track using essentially the same setup as last year, but with partly different languages, and a domain adaptation track, where th"
D07-1096,D07-1121,0,0.0305771,"Missing"
D07-1096,D07-1101,0,0.829681,"Missing"
D07-1096,W01-0521,0,0.119247,"and Turkish. The treebanks from 2 The reason for having an upper bound on the training set size was the fact that, in 2006, some participants could not train on all the data for some languages because of time limitations. Similar considerations also led to the decision to have a smaller number of languages this year (ten, as opposed to thirteen). 917 which the data sets were extracted are described in section 3. 2.3 Domain Adaptation Track One well known characteristic of data-driven parsing systems is that they typically perform much worse on data that does not come from the training domain (Gildea, 2001). Due to the large overhead in annotating text with deep syntactic parse trees, the need to adapt parsers from domains with plentiful resources (e.g., news) to domains with little resources is an important problem. This problem is commonly referred to as domain adaptation, where the goal is to adapt annotated resources from a source domain to a target domain of interest. Almost all prior work on domain adaptation assumes one of two scenarios. In the first scenario, there are limited annotated resources available in the target domain, and many studies have shown that this may lead to substantia"
D07-1096,A00-2018,0,0.0790907,"test data, and to handle multiple languages, possibly by adjusting a number of hyper-parameters. Participants in the multilingual track were expected to submit parsing results for all languages involved. 1 http://depparse.uvt.nl/depparse-wiki/SoftwarePage One of the claimed advantages of dependency parsing, as opposed to parsing based on constituent analysis, is that it extends naturally to languages with free or flexible word order. This explains the interest in recent years for multilingual evaluation of dependency parsers. Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English. The parser of McDonald and Pereira (2006) had been applied to English, Czech and Danish, and the parser of Nivre et al. (2007) to ten different languages. But by far the largest evaluation of multilingual dependency parsing systems so far was the 2006 shared task, where nineteen systems were evaluated on data from thirteen languages (Buchholz and Marsi, 2006). One"
D07-1096,W04-3237,0,0.0190919,"dapt parsers from domains with plentiful resources (e.g., news) to domains with little resources is an important problem. This problem is commonly referred to as domain adaptation, where the goal is to adapt annotated resources from a source domain to a target domain of interest. Almost all prior work on domain adaptation assumes one of two scenarios. In the first scenario, there are limited annotated resources available in the target domain, and many studies have shown that this may lead to substantial improvements. This includes the work of Roark and Bacchiani (2003), Florian et al. (2004), Chelba and Acero (2004), Daum´e and Marcu (2006), and Titov and Henderson (2006). Of these, Roark and Bacchiani (2003) and Titov and Henderson (2006) deal specifically with syntactic parsing. The second scenario assumes that there are no annotated resources in the target domain. This is a more realistic situation and is considerably more difficult. Recent work by McClosky et al. (2006) and Blitzer et al. (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation. For this shared-task, we are assuming the latter setting – no annotated resources in the target doma"
D07-1096,D07-1097,1,0.748997,"Missing"
D07-1096,D07-1122,0,0.0269928,"Missing"
D07-1096,P97-1003,0,0.129198,"neralize to unseen test data, and to handle multiple languages, possibly by adjusting a number of hyper-parameters. Participants in the multilingual track were expected to submit parsing results for all languages involved. 1 http://depparse.uvt.nl/depparse-wiki/SoftwarePage One of the claimed advantages of dependency parsing, as opposed to parsing based on constituent analysis, is that it extends naturally to languages with free or flexible word order. This explains the interest in recent years for multilingual evaluation of dependency parsers. Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English. The parser of McDonald and Pereira (2006) had been applied to English, Czech and Danish, and the parser of Nivre et al. (2007) to ten different languages. But by far the largest evaluation of multilingual dependency parsing systems so far was the 2006 shared task, where nineteen systems were evaluated on data from thirteen languages (Buchholz an"
D07-1096,D07-1112,0,0.583145,"Missing"
D07-1096,D07-1102,0,0.0310581,"Missing"
D07-1096,W07-2416,0,0.767751,"he test data is a small subset of the development test set of PDT. English For English we used the Wall Street Journal section of the Penn Treebank (Marcus et al., 1993). In particular, we used sections 2-11 for training and a subset of section 23 for testing. As a preprocessing stage we removed many functions tags from the non-terminals in the phrase structure representation to make the representations more uniform with out-of-domain test sets for the domain adaptation track (see section 3.2). The resulting data set was then converted to dependency structures using the procedure described in Johansson and Nugues (2007a). This work was done by Ryan McDonald. all the approximately 65,000 tokens of the original treebank for training. The rich morphology of Turkish requires the basic tokens in parsing to be inflectional groups (IGs) rather than words. IGs of a single word are connected to each other deterministically using dependency links labeled DERIV, referred to as word-internal dependencies in the following, and the FORM and the LEMMA fields may be empty (they contain underscore characters in the data files). Sentences do not necessarily have a unique root; most internal punctuation and a few foreign word"
D07-1096,D07-1123,0,0.0858787,"he test data is a small subset of the development test set of PDT. English For English we used the Wall Street Journal section of the Penn Treebank (Marcus et al., 1993). In particular, we used sections 2-11 for training and a subset of section 23 for testing. As a preprocessing stage we removed many functions tags from the non-terminals in the phrase structure representation to make the representations more uniform with out-of-domain test sets for the domain adaptation track (see section 3.2). The resulting data set was then converted to dependency structures using the procedure described in Johansson and Nugues (2007a). This work was done by Ryan McDonald. all the approximately 65,000 tokens of the original treebank for training. The rich morphology of Turkish requires the basic tokens in parsing to be inflectional groups (IGs) rather than words. IGs of a single word are connected to each other deterministically using dependency links labeled DERIV, referred to as word-internal dependencies in the following, and the FORM and the LEMMA fields may be empty (they contain underscore characters in the data files). Sentences do not necessarily have a unique root; most internal punctuation and a few foreign word"
D07-1096,W02-2016,0,0.338207,"expected to submit parsing results for all languages involved. 1 http://depparse.uvt.nl/depparse-wiki/SoftwarePage One of the claimed advantages of dependency parsing, as opposed to parsing based on constituent analysis, is that it extends naturally to languages with free or flexible word order. This explains the interest in recent years for multilingual evaluation of dependency parsers. Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English. The parser of McDonald and Pereira (2006) had been applied to English, Czech and Danish, and the parser of Nivre et al. (2007) to ten different languages. But by far the largest evaluation of multilingual dependency parsing systems so far was the 2006 shared task, where nineteen systems were evaluated on data from thirteen languages (Buchholz and Marsi, 2006). One of the conclusions from the 2006 shared task was that parsing accuracy differed greatly between languages and that a deeper analysis of the factors inv"
D07-1096,W04-3111,1,0.307142,"task. A new test set of about 9,000 tokens was provided by G¨uls¸en Eryi˘git (Eryi˘git, 2007), who also handled the conversion to the CoNLL format, which means that we could use 919 Domain Adaptation Track As mentioned previously, the source data is drawn from a corpus of news, specifically the Wall Street Journal section of the Penn Treebank (Marcus et al., 1993). This data set is identical to the English training set from the multilingual track (see section 3.1). For the target domains we used three different labeled data sets. The first two were annotated as part of the PennBioIE project (Kulick et al., 2004) and consist of sentences drawn from either biomedical or chemical research abstracts. Like the source WSJ corpus, this data is annotated using the Penn Treebank phrase structure scheme. To convert these sets to dependency structures we used the same procedure as before (Johansson and Nugues, 2007a). Additional care was taken to remove sentences that contained non-WSJ part-of-speech tags or non-terminals (e.g., HYPH part-of-speech tag indicating a hyphen). Furthermore, the annotation scheme for gaps and traces was made consistent with the Penn Treebank wherever possible. As already mentioned,"
D07-1096,D07-1098,0,0.0447748,"Missing"
D07-1096,D07-1124,0,0.0197253,"Missing"
D07-1096,J93-2004,0,0.0597121,"dependency annotation, just as for PADT. It was also used in the shared task 2006, but there are two important changes compared to last year. First, version 2.0 of PDT was used instead of version 1.0, and a conversion script was created by Zdenek Zabokrtsky, using the new XMLbased format of PDT 2.0. Secondly, due to the upper bound on training set size, only sections 1–3 of PDT constitute the training data, which amounts to some 450,000 tokens. The test data is a small subset of the development test set of PDT. English For English we used the Wall Street Journal section of the Penn Treebank (Marcus et al., 1993). In particular, we used sections 2-11 for training and a subset of section 23 for testing. As a preprocessing stage we removed many functions tags from the non-terminals in the phrase structure representation to make the representations more uniform with out-of-domain test sets for the domain adaptation track (see section 3.2). The resulting data set was then converted to dependency structures using the procedure described in Johansson and Nugues (2007a). This work was done by Ryan McDonald. all the approximately 65,000 tokens of the original treebank for training. The rich morphology of Turk"
D07-1096,N04-1001,0,0.244784,"se trees, the need to adapt parsers from domains with plentiful resources (e.g., news) to domains with little resources is an important problem. This problem is commonly referred to as domain adaptation, where the goal is to adapt annotated resources from a source domain to a target domain of interest. Almost all prior work on domain adaptation assumes one of two scenarios. In the first scenario, there are limited annotated resources available in the target domain, and many studies have shown that this may lead to substantial improvements. This includes the work of Roark and Bacchiani (2003), Florian et al. (2004), Chelba and Acero (2004), Daum´e and Marcu (2006), and Titov and Henderson (2006). Of these, Roark and Bacchiani (2003) and Titov and Henderson (2006) deal specifically with syntactic parsing. The second scenario assumes that there are no annotated resources in the target domain. This is a more realistic situation and is considerably more difficult. Recent work by McClosky et al. (2006) and Blitzer et al. (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation. For this shared-task, we are assuming the latter setting – no annotated res"
D07-1096,D07-1125,0,0.020143,"Missing"
D07-1096,P06-1043,0,0.463102,"scenario, there are limited annotated resources available in the target domain, and many studies have shown that this may lead to substantial improvements. This includes the work of Roark and Bacchiani (2003), Florian et al. (2004), Chelba and Acero (2004), Daum´e and Marcu (2006), and Titov and Henderson (2006). Of these, Roark and Bacchiani (2003) and Titov and Henderson (2006) deal specifically with syntactic parsing. The second scenario assumes that there are no annotated resources in the target domain. This is a more realistic situation and is considerably more difficult. Recent work by McClosky et al. (2006) and Blitzer et al. (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation. For this shared-task, we are assuming the latter setting – no annotated resources in the target domain. Obtaining adequate annotated syntactic resources for multiple languages is already a challenging problem, which is only exacerbated when these resources must be drawn from multiple and diverse domains. As a result, the only language that could be feasibly tested in the domain adaptation track was English. The setup for the domain adaptation track was as follo"
D07-1096,N03-1027,0,0.115089,"text with deep syntactic parse trees, the need to adapt parsers from domains with plentiful resources (e.g., news) to domains with little resources is an important problem. This problem is commonly referred to as domain adaptation, where the goal is to adapt annotated resources from a source domain to a target domain of interest. Almost all prior work on domain adaptation assumes one of two scenarios. In the first scenario, there are limited annotated resources available in the target domain, and many studies have shown that this may lead to substantial improvements. This includes the work of Roark and Bacchiani (2003), Florian et al. (2004), Chelba and Acero (2004), Daum´e and Marcu (2006), and Titov and Henderson (2006). Of these, Roark and Bacchiani (2003) and Titov and Henderson (2006) deal specifically with syntactic parsing. The second scenario assumes that there are no annotated resources in the target domain. This is a more realistic situation and is considerably more difficult. Recent work by McClosky et al. (2006) and Blitzer et al. (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation. For this shared-task, we are assuming the latter set"
D07-1096,D07-1013,1,0.545996,"Missing"
D07-1096,N06-2033,0,0.645238,"Missing"
D07-1096,E06-1011,1,0.349109,"the claimed advantages of dependency parsing, as opposed to parsing based on constituent analysis, is that it extends naturally to languages with free or flexible word order. This explains the interest in recent years for multilingual evaluation of dependency parsers. Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English. The parser of McDonald and Pereira (2006) had been applied to English, Czech and Danish, and the parser of Nivre et al. (2007) to ten different languages. But by far the largest evaluation of multilingual dependency parsing systems so far was the 2006 shared task, where nineteen systems were evaluated on data from thirteen languages (Buchholz and Marsi, 2006). One of the conclusions from the 2006 shared task was that parsing accuracy differed greatly between languages and that a deeper analysis of the factors involved in this variation was an important problem for future research. In order to provide an extended empirical foundation"
D07-1096,D07-1111,0,0.734777,"Missing"
D07-1096,H05-1066,1,0.508532,"Missing"
D07-1096,D07-1126,0,0.0372423,"Missing"
D07-1096,W06-2934,1,0.278986,"Missing"
D07-1096,D07-1128,0,0.0204553,"Missing"
D07-1096,D07-1129,0,0.0286186,"Missing"
D07-1096,W06-2902,0,0.016467,"g., news) to domains with little resources is an important problem. This problem is commonly referred to as domain adaptation, where the goal is to adapt annotated resources from a source domain to a target domain of interest. Almost all prior work on domain adaptation assumes one of two scenarios. In the first scenario, there are limited annotated resources available in the target domain, and many studies have shown that this may lead to substantial improvements. This includes the work of Roark and Bacchiani (2003), Florian et al. (2004), Chelba and Acero (2004), Daum´e and Marcu (2006), and Titov and Henderson (2006). Of these, Roark and Bacchiani (2003) and Titov and Henderson (2006) deal specifically with syntactic parsing. The second scenario assumes that there are no annotated resources in the target domain. This is a more realistic situation and is considerably more difficult. Recent work by McClosky et al. (2006) and Blitzer et al. (2006) have shown that the existence of a large unlabeled corpus in the new domain can be leveraged in adaptation. For this shared-task, we are assuming the latter setting – no annotated resources in the target domain. Obtaining adequate annotated syntactic resources for"
D07-1096,D07-1099,0,0.322183,"Missing"
D07-1096,D07-1130,0,0.0262275,"Missing"
D07-1096,D07-1131,0,0.0212092,"Missing"
D07-1096,W03-3023,0,0.882665,"ults for all languages involved. 1 http://depparse.uvt.nl/depparse-wiki/SoftwarePage One of the claimed advantages of dependency parsing, as opposed to parsing based on constituent analysis, is that it extends naturally to languages with free or flexible word order. This explains the interest in recent years for multilingual evaluation of dependency parsers. Even before the 2006 shared task, the parsers of Collins (1997) and Charniak (2000), originally developed for English, had been adapted for dependency parsing of Czech, and the parsing methodology proposed by Kudo and Matsumoto (2002) and Yamada and Matsumoto (2003) had been evaluated on both Japanese and English. The parser of McDonald and Pereira (2006) had been applied to English, Czech and Danish, and the parser of Nivre et al. (2007) to ten different languages. But by far the largest evaluation of multilingual dependency parsing systems so far was the 2006 shared task, where nineteen systems were evaluated on data from thirteen languages (Buchholz and Marsi, 2006). One of the conclusions from the 2006 shared task was that parsing accuracy differed greatly between languages and that a deeper analysis of the factors involved in this variation was an i"
D07-1096,P06-1085,0,\N,Missing
D07-1096,D07-1127,0,\N,Missing
D07-1097,W07-2416,0,0.0143741,"es, extrapolating from the optimal parameters settings for each language. When evaluated on the official test sets, the ensemble system significantly outperforms the single-parser system and achieves the highest average labeled attachment score. 1 Introduction In the multilingual track of the CoNLL 2007 shared task on dependency parsing, a single parser must be trained to handle data from ten different languages: Arabic (Hajiˇc et al., 2004), Basque (Aduriz et al., 2003), Catalan, (Mart´ı et al., 2007), Chinese (Chen et al., 2003), Czech (B¨ohmov´a et al., 2003), English (Marcus et al., 1993; Johansson and Nugues, 2007), Greek (Prokopidis et al., 2005), Hungarian (Csendes et al., 2005), Italian (Montemagni et al., 2003), and Turkish (Oflazer et al., 2003).1 Our contribution is a study in multilingual parser optimization using the freely available MaltParser system, which performs 1 For more information about the task and the data sets, see Nivre et al. (2007). deterministic, classifier-based parsing with historybased feature models and discriminative learning, and which was one of the top performing systems in the CoNLL 2006 shared task (Nivre et al., 2006). In order to maximize parsing accuracy, optimizatio"
D07-1097,J93-2004,0,0.0418663,"rent parsing strategies, extrapolating from the optimal parameters settings for each language. When evaluated on the official test sets, the ensemble system significantly outperforms the single-parser system and achieves the highest average labeled attachment score. 1 Introduction In the multilingual track of the CoNLL 2007 shared task on dependency parsing, a single parser must be trained to handle data from ten different languages: Arabic (Hajiˇc et al., 2004), Basque (Aduriz et al., 2003), Catalan, (Mart´ı et al., 2007), Chinese (Chen et al., 2003), Czech (B¨ohmov´a et al., 2003), English (Marcus et al., 1993; Johansson and Nugues, 2007), Greek (Prokopidis et al., 2005), Hungarian (Csendes et al., 2005), Italian (Montemagni et al., 2003), and Turkish (Oflazer et al., 2003).1 Our contribution is a study in multilingual parser optimization using the freely available MaltParser system, which performs 1 For more information about the task and the data sets, see Nivre et al. (2007). deterministic, classifier-based parsing with historybased feature models and discriminative learning, and which was one of the top performing systems in the CoNLL 2006 shared task (Nivre et al., 2006). In order to maximize"
D07-1097,N06-2033,0,0.410516,"the defining feature for the split (instead of POSTAG). With respect to the SVM parameters (γ, r, C, and ), Arabic, Basque, Catalan, Greek and Hungarian retain the baseline settings, while the other languages have slightly different values for some parameters. The cumulative improvement after optimization of feature model and learning algorithm parameters was 1.71 percentage points on average over all ten languages, with a minimum of 0.69 (Turkish) and a maximum of 3.25 (Chinese) (cf. table 1). 3 The Blended Parser The Blended parser is an ensemble system based on the methodology proposed by Sagae and Lavie (2006). Given the output dependency graphs Gi (1 ≤ i ≤ m) of m different parsers for an input sentence x, we construct a new graph containing all the labeled dependency arcs proposed by some parser and weight each arc a by a score s(a) reflecting its popularity among the m parsers. The output of the ensemble system for x is the maximum spanning tree of this graph (rooted at the node 0), which can be extracted using the Chu-Liu-Edmonds algorithm, as shown by McDonald et al. (2005). Following 936 c Sagae and Lavie (2006), we let s(a) = m i=1 wi ai , where wic is the average labeled attachment score of"
D07-1097,D07-1013,1,0.840676,"Missing"
D07-1097,W03-3023,0,0.235532,"Missing"
D07-1097,H05-1066,0,0.562194,"Missing"
D07-1097,P05-1013,1,0.292258,"Missing"
D07-1097,W06-2933,1,0.445728,"Missing"
D07-1097,N07-1050,1,0.691603,"ai , where wic is the average labeled attachment score of parser i for the word class c8 of the dependent of a, and ai is 1 if a ∈ Gi and 0 otherwise. The Blended parser uses six component parsers, with three different parsing algorithms, each of which is used to construct one left-to-right parser and one right-to-left parser. The parsing algorithms used are the arc-eager baseline algorithm, the arcstandard variant of the baseline algorithm, and the incremental, non-projective parsing algorithm first described by Covington (2001) and recently used for deterministic classifier-based parsing by Nivre (2007), all of which are available in MaltParser. Thus, the six component parsers for each language were instances of the following: P 1. Arc-eager projective left-to-right 2. Arc-eager projective right-to-left 3. Arc-standard projective left-to-right 4. Arc-standard projective right-to-left 5. Covington non-projective left-to-right 6. Covington non-projective right-to-left 8 We use CPOSTAG to determine the part of speech. root 1 2 3–6 7+ Parser R P R P R P R P R P Single Malt 87.01 80.36 95.08 94.87 86.28 86.67 77.97 80.23 68.98 71.06 Blended 92.09 74.20 95.71 94.92 87.55 88.12 78.66 83.02 65.29 78"
D07-1097,W07-2201,0,\N,Missing
D07-1097,W02-2016,0,\N,Missing
D07-1097,W06-2920,0,\N,Missing
D07-1097,H92-1026,0,\N,Missing
D07-1097,W07-2207,0,\N,Missing
D07-1097,W07-2202,0,\N,Missing
D07-1097,W05-1518,0,\N,Missing
D07-1097,P95-1037,0,\N,Missing
D07-1097,P06-2041,1,\N,Missing
D07-1097,D07-1096,1,\N,Missing
D07-1097,W03-3017,1,\N,Missing
D11-1002,W04-3240,0,0.462342,"Missing"
D11-1002,D09-1047,0,0.0158785,"on dialogue act boundaries were fed into an n-gram language model, which was used for the joint segmentation and classification of dialogue acts. Sutton and McCallum (2005) performed joint parsing and semantic role labelling (SRL), using the results of a probabilistic SRL system to improve the accuracy of a probabilistic parser. Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles i"
D11-1002,P08-1081,0,0.0130061,"ove the classification accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiation– response pair identification has been explored as a pairwise ranking problem (Wang and Ros´e, 2010), question–answer pair identification has been approached via the two separate sub-tasks of question classification and answer detection (Cong et al., 2008; Ding et al., 2008; Cao et al., 2009). Our thread discourse structure prediction task includes joint classification of post roles (i.e. dialogue acts) and links, and could potentially be performed at the sub-post sentence level to extract initiation–response pairs. 3 Task Description and Data Set The main task performed in this research is joint classification of inter-post links (Link) and dialogue acts (DA) within forum threads. In this, we assume that a post can only link to an earlier post (or a virtual root node), and that dialogue acts are labels on edges. It is possible for there to be multiple edges fro"
D11-1002,W05-1504,0,0.0477988,"Missing"
D11-1002,P08-1095,0,0.0229703,"010a), demonstrating the generalisability of the original method. In both cases, however, we tackled only a single task, either link classification (optionally given dialogue act tags) or dialogue act classification, but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of c"
D11-1002,N09-1037,0,0.0208178,"different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their approach, the predictions of a multi-layer perceptron classifier on dialogue act boundaries were fed into an n-gram language model, which was used for the joint segmentation and classification of dialogue acts. Sutton and McCallum (2005) performed joint parsing and semantic role labelling (SRL), using the results of a probabilistic SRL system to improve the accuracy of a probabilistic parser. Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-"
D11-1002,J86-3001,0,0.379024,", but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivan"
D11-1002,D10-1084,1,0.517285,"assessment (Lui and Baldwin, 2009). We aim to move beyond simple threading, to predict not only the links between posts, but also show the manner of each link, in the form of the discourse structure of the thread. In doing so, we hope to be able to perform richer visualisation of thread structure (e.g. highlighting the key posts which appear to have led to a successful resolution to a problem), and more finegrained weighting of posts in threads for search purposes. To illustrate the task, we use an example thread, made up of 5 posts from 4 distinct participants, from the CNET forum dataset of Kim et al. (2010b), as shown in Figure 1. The discourse structure of the thread is modelled as a rooted directed acyclic graph 13 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 13–25, c Edinburgh, Scotland, UK, July 27–31, 2011. 2011 Association for Computational Linguistics full threads, indicating that the method is applicable to in-situ thread classification. Finally, we investigate the role of user-level features in discourse structure analysis. Ø 0+Question-Question User A Post 1 HTML Input Code ...Please can someone tell me how to create an input box that a"
D11-1002,W10-2923,1,0.839716,"Missing"
D11-1002,W10-1915,0,0.0189845,"Missing"
D11-1002,W02-0216,0,0.0351975,"neralisability of the original method. In both cases, however, we tackled only a single task, either link classification (optionally given dialogue act tags) or dialogue act classification, but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication includin"
D11-1002,U10-1009,1,0.684369,"tion (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results su"
D11-1002,D07-1013,1,0.806323,"the joint classification predictions, and performed a similar breakdown of posts 20 for Link and DA; the results are presented in Figure 3. It is clear that the anomaly for CRFSGD comes from the DA component, due to there being greater predictability in the dialogue for final posts in a thread (users tend to confirm a successful resolution of the problem, or report on successful external reproduction of the solution). MaltParser seems less adept at identifying that a post is at the end of a thread, and predicting the dialogue act accordingly. This observation is congruous with the findings of McDonald and Nivre (2007) that errors propagate, due to MaltParser’s greedy inference strategy. The higher results for Link are to be expected, as throughout the thread, most posts tend to link locally. XXX B/down XXX XXX Test [1, 2] [1, 4] [1, 6] [1, 8] [All] [1, 2] [1, 4] [1, 6] [1, 8] [All] .947/.947 .946/.947 .946/.947 .946/.947 .946/.946 — .836/.841 .840/.841 .840/.841 .840/.838 — — .800/.794 .800/.794 .800/.791 — — — .780/.769 .776/.767 — — — .756/.738 Table 5: Post-level Link-DA F-score for CRFSGD/MaltParser, based on in situ classification over sub-threads of different lengths (indicated in the rows), broken d"
D11-1002,E06-1011,0,0.053421,"Missing"
D11-1002,H05-1066,0,0.17872,"Missing"
D11-1002,N06-1047,0,0.022453,"-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 2004; Weinberger and Fischer, 2006; Wang et al., 2007; Fortuna et al., 2007; Kim et al., 2010b). For a more complete review of models for discourse disentanglement and dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interactions between different su"
D11-1002,W03-3017,1,0.730692,". One feature of MaltParser that makes it well suited to our task is that it is possible to define feature models of arbitrary complexity for each token. In presenting the thread data to MaltParser, we represent the nulllink from the initial post of each thread, as well as any disconnected posts, as the root. To the best of our knowledge, there is no past work on using dependency parsing to learn thread discourse structure. Based on extensive experimentation, we determined that the MaltParser configuration that obtains the best results for our task is the Nivre algorithm in arc-standard mode (Nivre, 2003; Nivre, 2004), using LIBSVM (Chang and Lin, 2011) with a linear kernel as the learner, and a feature model with exhaustive combinations of features relating to the features and predictions of the first/top 17 three tokens from both “Input” and “Stack”.3 As such, MaltParser is actually unable to predict any non-projective structures, as experiments with algorithms supporting non-projective structures invariably led to lower results. In our choice of parsing algorithm, we are also unable to detect posts with multiple heads, but can potentially detect disconnected sub-graphs. 4.2 Features The fe"
D11-1002,W04-0308,1,0.0531983,"of MaltParser that makes it well suited to our task is that it is possible to define feature models of arbitrary complexity for each token. In presenting the thread data to MaltParser, we represent the nulllink from the initial post of each thread, as well as any disconnected posts, as the root. To the best of our knowledge, there is no past work on using dependency parsing to learn thread discourse structure. Based on extensive experimentation, we determined that the MaltParser configuration that obtains the best results for our task is the Nivre algorithm in arc-standard mode (Nivre, 2003; Nivre, 2004), using LIBSVM (Chang and Lin, 2011) with a linear kernel as the learner, and a feature model with exhaustive combinations of features relating to the features and predictions of the first/top 17 three tokens from both “Input” and “Stack”.3 As such, MaltParser is actually unable to predict any non-projective structures, as experiments with algorithms supporting non-projective structures invariably led to lower results. In our choice of parsing algorithm, we are also unable to detect posts with multiple heads, but can potentially detect disconnected sub-graphs. 4.2 Features The features used in"
D11-1002,P95-1005,0,0.304332,"Missing"
D11-1002,C08-1095,0,0.0412607,"Missing"
D11-1002,W09-3813,0,0.0170508,"et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 2004; Weinberger and Fischer, 2006; Wang et al., 2007; Fortuna et al., 2007; Kim et al., 2010b). For a more complete review of models for discourse disentanglement and dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interactions between different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their approach, the p"
D11-1002,W04-2319,0,0.0142908,"o a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 2004; Weinberger and Fischer, 2006; Wang et al., 2007; Fortuna et al., 2007; Kim et al., 2010b). For a more complete review of models for discourse disentanglement and dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interaction"
D11-1002,C10-2133,0,0.0513622,"ies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking struc15 ture and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007; Wanas et al., 2008; Lui and Baldwin, 2009), and post descriptiveness in particular domains (e.g. medical forums: Leaman et al. (2010))"
D11-1002,N03-1030,0,0.021924,"c graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 2004; Weinberger and Fischer, 2006; Wang et al., 2007; Fortuna et al., 2007; Kim et al., 2010b). For a more complete review of models for discourse disentanglement and dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interactions between different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their a"
D11-1002,J00-3003,0,0.332415,"Missing"
D11-1002,W05-0636,0,0.0238895,"nd dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interactions between different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their approach, the predictions of a multi-layer perceptron classifier on dialogue act boundaries were fed into an n-gram language model, which was used for the joint segmentation and classification of dialogue acts. Sutton and McCallum (2005) performed joint parsing and semantic role labelling (SRL), using the results of a probabilistic SRL system to improve the accuracy of a probabilistic parser. Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-o"
D11-1002,A97-1011,0,0.0698392,"Missing"
D11-1002,N10-1097,0,0.161975,"Missing"
D11-1002,P07-2019,0,0.0814572,"ation predictions, and performed a similar breakdown of posts 20 for Link and DA; the results are presented in Figure 3. It is clear that the anomaly for CRFSGD comes from the DA component, due to there being greater predictability in the dialogue for final posts in a thread (users tend to confirm a successful resolution of the problem, or report on successful external reproduction of the solution). MaltParser seems less adept at identifying that a post is at the end of a thread, and predicting the dialogue act accordingly. This observation is congruous with the findings of McDonald and Nivre (2007) that errors propagate, due to MaltParser’s greedy inference strategy. The higher results for Link are to be expected, as throughout the thread, most posts tend to link locally. XXX B/down XXX XXX Test [1, 2] [1, 4] [1, 6] [1, 8] [All] [1, 2] [1, 4] [1, 6] [1, 8] [All] .947/.947 .946/.947 .946/.947 .946/.947 .946/.946 — .836/.841 .840/.841 .840/.841 .840/.838 — — .800/.794 .800/.794 .800/.791 — — — .780/.769 .776/.767 — — — .756/.738 Table 5: Post-level Link-DA F-score for CRFSGD/MaltParser, based on in situ classification over sub-threads of different lengths (indicated in the rows), broken d"
D11-1002,P07-2032,0,0.0159489,"Missing"
D11-1002,J05-2005,0,0.0318554,"n both cases, however, we tackled only a single task, either link classification (optionally given dialogue act tags) or dialogue act classification, but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 20"
D11-1002,C00-2137,0,0.0329904,"Missing"
D11-1036,H91-1060,0,0.0649648,"y other structure. For (6a)–(6b), for instance, we get that (6a)t (6b) is a flat tree over pre-terminals where “would” and “have” are labeled with ‘vg’ and “worked” is the head, labeled with ‘*’. The generalization of two functional trees provides us with one structure that reflects the common and consistent content of the two trees. These structures thus provide us with a formally well-defined gold standard for cross-treebank evaluation. Step 3: Measuring Distances. Our functional trees superficially look like constituency-based trees, so a simple proposal would be to use Parseval measures (Black et al., 1991) for comparing the parsed trees against the new generalized gold trees. Parseval scores, however, have two significant drawbacks. First, they are known to be too restrictive with respect to some errors and too permissive with respect to others (Carroll et al., 1998; K¨ubler and Telljohann, 2002; Roark, 2002; Rehbein and van Genabith, 2007). Secondly, F1 scores would still penalize structures that are correct with respect to the original gold, but are not there in the generalized structure. Here we propose to adopt measures that are based on tree edit distance (TED) instead. TEDbased measures a"
D11-1036,W06-2920,0,0.320185,"normalized and brought into the same common ground. 1 Introduction Data-driven dependency parsing has seen a considerable surge of interest in recent years. Dependency parsers have been tested on parsing sentences in English (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; McDonald et al., 2005) as well as many other languages (Nivre et al., 2007a). The evaluation metric traditionally associated with dependency parsing is based on scoring labeled or unlabeled attachment decisions, whereby each correctly identified pair of head-dependent words is counted towards the success of the parser (Buchholz and Marsi, 2006). As it turns out, however, such evaluation procedures are sensitive to the annotation choices in the data on which the parser was trained. 385 Evelina Andersson Uppsala University Sweden Different annotation schemes often make different assumptions with respect to how linguistic content is represented in a treebank (Rambow, 2010). The consequence of such annotation discrepancies is that when we compare parsing results across different experiments, even ones that use the same parser and the same set of sentences, the gap between results in different experiments may not reflect a true gap in pe"
D11-1036,D10-1096,0,0.0623753,"ones that use the same parser and the same set of sentences, the gap between results in different experiments may not reflect a true gap in performance, but rather a difference in the annotation decisions made in the respective treebanks. Different methods have been proposed for making dependency parsing results comparable across experiments. These methods include picking a single gold standard for all experiments to which the parser output should be converted (Carroll et al., 1998; Cer et al., 2010), evaluating parsers by comparing their performance in an embedding task (Miyao et al., 2008; Buyko and Hahn, 2010), or neutralizing the arc direction in the native representation of dependency trees (Schwartz et al., 2011). Each of these methods has its own drawbacks. Picking a single gold standard skews the results in favor of parsers which were trained on it. Transforming dependency trees to a set of pre-defined labeled dependencies, or into task-based features, requires the use of heuristic rules that run the risk of distorting correct information and introducing noise of their own. Neutralizing the direction of arcs is limited to unlabeled evaluation and local context, and thus may not cover all possi"
D11-1036,cer-etal-2010-parsing,0,0.0712638,"Missing"
D11-1036,de-marneffe-etal-2006-generating,0,0.0629635,"Missing"
D11-1036,emms-2008-tree,0,0.0227087,"y trees is simply the cost of all edit operations that are required to turn a parse tree into its gold standard, normalized with respect to the overall size of the dependency tree and subtracted from a unity.3 Here we apply the idea of defining scores by TED costs normalized relative to the size of the tree and substracted from a unity, and extend it from fixed-size dependency trees to ordered trees of arbitrary size. 3 The size of a dependency tree, either parse or gold, is always fixed by the number of terminals. 390 Our formalization follows closely the formulation of the T-Dice measure of Emms (2008), building on his thorough investigation of the formal and empirical differences between TED-based measures and Parseval. We first define for any ordered and labeled tree π the following operations. relabel-node change the label of node v in π delete-node delete a non-root node v in π with parent u, making the children of v the children of u, inserted in the place of v as a subsequence in the left-to-right order of the children of u. insert-node insert a node v as a child of u in π making it the parent of a consecutive subsequence of the children of u. An edit script ES(π1 , π2 ) = {e0 , e1 .."
D11-1036,W07-2416,0,0.532412,"a dependency treebank is well-defined according to current standards (K¨ubler et al., 2009), there are different ways in which the trees can be used to express syntactic content (Rambow, 2010). Consider, for instance, algorithms for converting the phrase-structure trees in the Penn Treebank (Marcus et al., 1993) into dependency structures. Different conversion algorithms implicitly make different assumptions about how to represent linguistic content in the data. When multiple conversion algorithms are applied to the same data, we end up with different dependency trees for the same sentences (Johansson and Nugues, 2007; Choi and Palmer, 2010; de Marneffe et al., 2006). Some common cases of discrepancies are as follows. 386 Lexical vs. Functional Head Choice. In linguistics, there is a distinction between lexical heads and functional heads. A lexical head carries the semantic gist of a phrase while a functional one marks its relation to other parts of the sentence. The two kinds of heads may or may not coincide in a single word form (Zwicky, 1993). Common examples refer to prepositional phrases, such as the phrase “on Sunday”. This phrase has two possible analyses, one selects a lexical head (1a) and the oth"
D11-1036,J93-2004,0,0.0481286,"gh endeavor, and suggest ways to extend the protocol to additional evaluation scenarios. 2 The Challenge: Treebank Theories Dependency treebanks contain information about the grammatically meaningful elements in the utterance and the grammatical relations between them. Even if the formal representation in a dependency treebank is well-defined according to current standards (K¨ubler et al., 2009), there are different ways in which the trees can be used to express syntactic content (Rambow, 2010). Consider, for instance, algorithms for converting the phrase-structure trees in the Penn Treebank (Marcus et al., 1993) into dependency structures. Different conversion algorithms implicitly make different assumptions about how to represent linguistic content in the data. When multiple conversion algorithms are applied to the same data, we end up with different dependency trees for the same sentences (Johansson and Nugues, 2007; Choi and Palmer, 2010; de Marneffe et al., 2006). Some common cases of discrepancies are as follows. 386 Lexical vs. Functional Head Choice. In linguistics, there is a distinction between lexical heads and functional heads. A lexical head carries the semantic gist of a phrase while a f"
D11-1036,E06-1011,0,0.0210463,"ed in the supplementary material. 392 The Default, OldLTH and CoNLL schemes mainly differ in their coordination structure, and the Functional and Lexical schemes differ in their selection of a functional and a lexical head, respectively. All schemes use the same inventory of labels.7 The LTH parameter settings for the different schemes are elaborated in the supplementary material. The Setup We use two different parsers: (i) MaltParser (Nivre et al., 2007b) with the arc eager algorithm as optimized for English in (Nivre et al., 2010) and (ii) MSTParser with the second-order projective model of McDonald and Pereira (2006). Both parsers were trained on the different instances of sections 2-21 of the PTB obeying the different annotation schemes in Table 3. Each trained model was used to parse section 23. All non-projective dependencies in the training and gold sets were projectivized prior to training and parsing using the algorithm of Nivre and Nilsson (2005). A more principled treatment of non-projective dependency trees is an important topic for future research. We evaluated the parses using labeled and unlabeled attachment scores, and using our TEDEVAL software package. Evaluation Our TEDEVAL software packag"
D11-1036,P05-1012,0,0.0298235,"a refined notion of tree edit distance for evaluating parse hypotheses relative to multiple gold standards. We demonstrate that, for different conversions of the Penn Treebank into dependencies, performance trends that are observed for parsing results in isolation change or dissolve completely when parse hypotheses are normalized and brought into the same common ground. 1 Introduction Data-driven dependency parsing has seen a considerable surge of interest in recent years. Dependency parsers have been tested on parsing sentences in English (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; McDonald et al., 2005) as well as many other languages (Nivre et al., 2007a). The evaluation metric traditionally associated with dependency parsing is based on scoring labeled or unlabeled attachment decisions, whereby each correctly identified pair of head-dependent words is counted towards the success of the parser (Buchholz and Marsi, 2006). As it turns out, however, such evaluation procedures are sensitive to the annotation choices in the data on which the parser was trained. 385 Evelina Andersson Uppsala University Sweden Different annotation schemes often make different assumptions with respect to how lingui"
D11-1036,P08-1006,0,0.0911077,"nt experiments, even ones that use the same parser and the same set of sentences, the gap between results in different experiments may not reflect a true gap in performance, but rather a difference in the annotation decisions made in the respective treebanks. Different methods have been proposed for making dependency parsing results comparable across experiments. These methods include picking a single gold standard for all experiments to which the parser output should be converted (Carroll et al., 1998; Cer et al., 2010), evaluating parsers by comparing their performance in an embedding task (Miyao et al., 2008; Buyko and Hahn, 2010), or neutralizing the arc direction in the native representation of dependency trees (Schwartz et al., 2011). Each of these methods has its own drawbacks. Picking a single gold standard skews the results in favor of parsers which were trained on it. Transforming dependency trees to a set of pre-defined labeled dependencies, or into task-based features, requires the use of heuristic rules that run the risk of distorting correct information and introducing noise of their own. Neutralizing the direction of arcs is limited to unlabeled evaluation and local context, and thus"
D11-1036,P05-1013,1,0.901195,"orated in the supplementary material. The Setup We use two different parsers: (i) MaltParser (Nivre et al., 2007b) with the arc eager algorithm as optimized for English in (Nivre et al., 2010) and (ii) MSTParser with the second-order projective model of McDonald and Pereira (2006). Both parsers were trained on the different instances of sections 2-21 of the PTB obeying the different annotation schemes in Table 3. Each trained model was used to parse section 23. All non-projective dependencies in the training and gold sets were projectivized prior to training and parsing using the algorithm of Nivre and Nilsson (2005). A more principled treatment of non-projective dependency trees is an important topic for future research. We evaluated the parses using labeled and unlabeled attachment scores, and using our TEDEVAL software package. Evaluation Our TEDEVAL software package implements the pipeline described in Section 3. We convert all parse and gold trees into functional trees using the algorithm defined in Section 3, and for each pair of parsing experiments we calculate a shared gold standard using generalization determined through a chart-based greedy algorithm.8 Our scoring procedure uses the TED algorith"
D11-1036,C04-1010,1,0.779898,"rent representations and a refined notion of tree edit distance for evaluating parse hypotheses relative to multiple gold standards. We demonstrate that, for different conversions of the Penn Treebank into dependencies, performance trends that are observed for parsing results in isolation change or dissolve completely when parse hypotheses are normalized and brought into the same common ground. 1 Introduction Data-driven dependency parsing has seen a considerable surge of interest in recent years. Dependency parsers have been tested on parsing sentences in English (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; McDonald et al., 2005) as well as many other languages (Nivre et al., 2007a). The evaluation metric traditionally associated with dependency parsing is based on scoring labeled or unlabeled attachment decisions, whereby each correctly identified pair of head-dependent words is counted towards the success of the parser (Buchholz and Marsi, 2006). As it turns out, however, such evaluation procedures are sensitive to the annotation choices in the data on which the parser was trained. 385 Evelina Andersson Uppsala University Sweden Different annotation schemes often make different assumptions wi"
D11-1036,C10-1094,1,0.913352,"Missing"
D11-1036,N10-1049,0,0.239506,"al., 2007a). The evaluation metric traditionally associated with dependency parsing is based on scoring labeled or unlabeled attachment decisions, whereby each correctly identified pair of head-dependent words is counted towards the success of the parser (Buchholz and Marsi, 2006). As it turns out, however, such evaluation procedures are sensitive to the annotation choices in the data on which the parser was trained. 385 Evelina Andersson Uppsala University Sweden Different annotation schemes often make different assumptions with respect to how linguistic content is represented in a treebank (Rambow, 2010). The consequence of such annotation discrepancies is that when we compare parsing results across different experiments, even ones that use the same parser and the same set of sentences, the gap between results in different experiments may not reflect a true gap in performance, but rather a difference in the annotation decisions made in the respective treebanks. Different methods have been proposed for making dependency parsing results comparable across experiments. These methods include picking a single gold standard for all experiments to which the parser output should be converted (Carroll"
D11-1036,P11-1067,0,0.251711,"nts may not reflect a true gap in performance, but rather a difference in the annotation decisions made in the respective treebanks. Different methods have been proposed for making dependency parsing results comparable across experiments. These methods include picking a single gold standard for all experiments to which the parser output should be converted (Carroll et al., 1998; Cer et al., 2010), evaluating parsers by comparing their performance in an embedding task (Miyao et al., 2008; Buyko and Hahn, 2010), or neutralizing the arc direction in the native representation of dependency trees (Schwartz et al., 2011). Each of these methods has its own drawbacks. Picking a single gold standard skews the results in favor of parsers which were trained on it. Transforming dependency trees to a set of pre-defined labeled dependencies, or into task-based features, requires the use of heuristic rules that run the risk of distorting correct information and introducing noise of their own. Neutralizing the direction of arcs is limited to unlabeled evaluation and local context, and thus may not cover all possible discrepancies. This paper proposes a new three-step protocol for cross-experiment parser evaluation, and"
D11-1036,A97-1014,0,0.192686,". In the future we plan to use this procedure for comparing constituency and dependency parsers. A conversion from constituency-based trees into functional trees 394 is straightforward to define: simply replace the node labels with the grammatical function of their dominating arc – and the rest of the pipeline follows. A pre-condition for cross-framework evaluation is that all representations encode the same set of grammatical relations by, e.g., annotating arcs in dependency trees or decorating nodes in constituency trees. For some treebanks this is already the case (Nivre and Megyesi, 2007; Skut et al., 1997; Hinrichs et al., 2004) while for others this is still lacking. Recent studies (Briscoe et al., 2002; de Marneffe et al., 2006) suggest that evaluation through a single set of grammatical relations as the common denominator is a linguistically sound and practically useful way to go. To guarantee extensions for crossframework evaluation it would be fruitful to make sure that resources use the same set of grammatical relation labels across different formal representation types. Moreover, we further aim to inquire whether we can find a single set of grammatical relation labels that can be used a"
D11-1036,W03-3023,0,0.160471,"ations for harmonizing different representations and a refined notion of tree edit distance for evaluating parse hypotheses relative to multiple gold standards. We demonstrate that, for different conversions of the Penn Treebank into dependencies, performance trends that are observed for parsing results in isolation change or dissolve completely when parse hypotheses are normalized and brought into the same common ground. 1 Introduction Data-driven dependency parsing has seen a considerable surge of interest in recent years. Dependency parsers have been tested on parsing sentences in English (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; McDonald et al., 2005) as well as many other languages (Nivre et al., 2007a). The evaluation metric traditionally associated with dependency parsing is based on scoring labeled or unlabeled attachment decisions, whereby each correctly identified pair of head-dependent words is counted towards the success of the parser (Buchholz and Marsi, 2006). As it turns out, however, such evaluation procedures are sensitive to the annotation choices in the data on which the parser was trained. 385 Evelina Andersson Uppsala University Sweden Different annotation schemes often make"
D11-1036,C10-2013,1,\N,Missing
D11-1036,D07-1096,1,\N,Missing
D12-1108,W09-1114,0,0.0292868,"t promising step. Our main contribution with respect to the work by Langlais et al. (2007) is the introduction of the possibility of handling document-level models by lifting the assumption of sentence independence. As a consequence, enumerating the entire neighbourhood becomes too expensive, which is why we resort to a “first-choice” strategy that non-deterministically generates states and accepts the first one encountered that meets the acceptance criterion. More recently, Gibbs sampling was proposed as a way to generate samples from the posterior distribution of a phrase-based SMT decoder (Arun et al., 2009; Arun et al., 2010), a process that resembles local search in its use of a set of state-modifying operators to generate a sequence of decoder states. Where local search seeks for the best state attainable from a given initial state, Gibbs sampling produces a representative sample from the posterior. Like all work on SMT decoding that we know of, the Gibbs sampler presented by Arun et al. (2010) assumes independence of sentences and considers the complete neighbourhood of each state before taking a sample. 6 Conclusion In the last twenty years of SMT research, there has been a strong assumptio"
D12-1108,W11-1014,0,0.00662194,"Missing"
D12-1108,P01-1030,0,0.0117476,"d to realise higher gains from cross-sentence semantic information. They support our claim that crosssentence models should be examined more closely and that existing methods should be adapted to deal with them, a problem addressed by our main contribution, the local search document decoder. 5 Related Work Even though DP beam search (Koehn et al., 2003) has been the dominant approach to SMT decoding in recent years, methods based on local search have been explored at various times. For word-based SMT, greedy hill-climbing techniques were advo1187 cated as a faster replacement for beam search (Germann et al., 2001; Germann, 2003; Germann et al., 2004), and a problem formulation specifically targeting word reordering with an efficient word reordering algorithm has been proposed (Eisner and Tromble, 2006). A local search decoder has been advanced as a faster alternative to beam search also for phrasebased SMT (Langlais et al., 2007; Langlais et al., 2008). That work anticipates many of the features found in our decoder, including the use of local search to refine an initial hypothesis produced by DP beam search. The possibility of using models that do not fit well into the beam search paradigm is mention"
D12-1108,N03-1010,0,0.0154231,"ins from cross-sentence semantic information. They support our claim that crosssentence models should be examined more closely and that existing methods should be adapted to deal with them, a problem addressed by our main contribution, the local search document decoder. 5 Related Work Even though DP beam search (Koehn et al., 2003) has been the dominant approach to SMT decoding in recent years, methods based on local search have been explored at various times. For word-based SMT, greedy hill-climbing techniques were advo1187 cated as a faster replacement for beam search (Germann et al., 2001; Germann, 2003; Germann et al., 2004), and a problem formulation specifically targeting word reordering with an efficient word reordering algorithm has been proposed (Eisner and Tromble, 2006). A local search decoder has been advanced as a faster alternative to beam search also for phrasebased SMT (Langlais et al., 2007; Langlais et al., 2008). That work anticipates many of the features found in our decoder, including the use of local search to refine an initial hypothesis produced by DP beam search. The possibility of using models that do not fit well into the beam search paradigm is mentioned and illustra"
D12-1108,D11-1084,0,0.369773,"guage Learning, pages 1179–1190, Jeju Island, Korea, 12–14 July 2012. 2012 Association for Computational Linguistics any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required. Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems. Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (2011), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences. In this paper, we present a method for decoding complete documents in phrase-based SMT. Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by the application of a s"
D12-1108,2010.iwslt-papers.10,1,0.837142,"ocument is required. Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems. Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (2011), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences. In this paper, we present a method for decoding complete documents in phrase-based SMT. Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by the application of a series of operations using a hill climbing strategy to find a (local) maximum of the score function. This setup gives us complete freedom to define scoring functions over the entire document. Moreover, by optionally initialising the st"
D12-1108,W11-2123,0,0.0368737,"is important to keep 1180 The problem addressed by the decoder is the search for the state Sˆ with maximal score, such that Sˆ = arg max f (S). S (5) The feature functions implemented in our baseline system are identical to the ones found in the popular Moses SMT system (Koehn et al., 2007). In particular, our decoder has the following feature functions: 1. phrase translation scores provided by the phrase table including forward and backward conditional probabilities, lexical weights and a phrase penalty (Koehn et al., 2003), 2. n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3. a word penalty score, 4. a distortion model with geometric decay (Koehn et al., 2003), and 5. a feature indicating the number of times a given distortion limit is exceeded in the current state. In our experiments, the last feature is used with a fixed weight of negative infinity in order to limit the gaps between the coverage sets of adjacent anchored phrase pairs to a maximum value. In DP search, the distortion limit is usually enforced directly by the search algorithm and is not added as a feature. In our decoder, however, this restriction is not required to limit complexity, so we deci"
D12-1108,D07-1103,0,0.0127504,"left to right until the whole range [p; q] is covered. 4 goal of our experiments is to demonstrate the behaviour of the decoder and characterise its response to changes in the fundamental search parameters. The SMT models for our experiments were created with a subset of the training data for the English-French shared task at the WMT 2011 workshop (Callison-Burch et al., 2011). The phrase table was trained on Europarl, news-commentary and UN data. To reduce the training data to a manageable size, singleton phrase pairs were removed before the phrase scoring step. Significance-based filtering (Johnson et al., 2007) was applied to the resulting phrase table. The language model was a 5gram model with Kneser-Ney smoothing trained on the monolingual News corpus with IRSTLM (Federico et al., 2008). Feature weights were trained with Minimum Error-Rate Training (MERT) (Och, 2003) on the news-test2008 development set using the DP beam search decoder and the MERT implementation of the Moses toolkit (Koehn et al., 2007). Experimental results are reported for the newstest2009 test set, a corpus of 111 newswire documents totalling 2,525 sentences or 65,595 English input tokens. Experimental Results In this section,"
D12-1108,P10-4006,0,0.0117936,"Missing"
D12-1108,N03-1017,0,0.283168,"tic phenomena such as pronominal anaphora cannot be translated correctly without referring to extra-sentential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001; Tillmann and Ney, 2003). This algorithm constructs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elim"
D12-1108,P07-2045,0,0.0678837,"to a linear combination of K feature functions hk (S), each with a constant weight λk , so K f (S) = SMT Model (1) ∑ λk hk (S). (4) k=1 Our decoder is based on local search, so its state at any time is a representation of a complete translation of the entire document. Even though the decoder operates at the document level, it is important to keep 1180 The problem addressed by the decoder is the search for the state Sˆ with maximal score, such that Sˆ = arg max f (S). S (5) The feature functions implemented in our baseline system are identical to the ones found in the popular Moses SMT system (Koehn et al., 2007). In particular, our decoder has the following feature functions: 1. phrase translation scores provided by the phrase table including forward and backward conditional probabilities, lexical weights and a phrase penalty (Koehn et al., 2003), 2. n-gram language model scores implemented with the KenLM toolkit (Heafield, 2011), 3. a word penalty score, 4. a distortion model with geometric decay (Koehn et al., 2003), and 5. a feature indicating the number of times a given distortion limit is exceeded in the current state. In our experiments, the last feature is used with a fixed weight of negative"
D12-1108,2007.tmi-papers.13,0,0.889821,"oves are rejected in a row (rejection limit). Algorithm 1 Decoding algorithm Input: an initial document state S; search parameters maxsteps and maxrejected Output: a modified document state 1: nsteps ← 0 2: nrejected ← 0 3: while nsteps < maxsteps and nrejected < maxrejected do 4: S0 ← Neighbour(S) 5: if Accept( f (S0 ), f (S)) then 6: S ← S0 7: nrejected ← 0 8: else 9: nrejected ← nrejected + 1 10: end if 11: nsteps ← nsteps + 1 12: end while 13: return S A notable difference between this algorithm and other hill climbing algorithms that have been used for SMT decoding (Germann et al., 2004; Langlais et al., 2007) is its non-determinism. Previous work for sentence-level decoding employed a steepest ascent strategy which amounts to enumerating the complete neighbourhood of the current state as defined by the state operations and selecting the next state to be the best state found in the neighbourhood of the current one. Enumerating all neighbours of a given state, costly as it is, has the advantage that it makes it easy to prove local optimality of a state by recognising that all possible successor states have lower scores. It can be rather inefficient, since at every step only one modification will be"
D12-1108,2008.jeptalnrecital-long.12,0,0.0149019,"al., 2003) has been the dominant approach to SMT decoding in recent years, methods based on local search have been explored at various times. For word-based SMT, greedy hill-climbing techniques were advo1187 cated as a faster replacement for beam search (Germann et al., 2001; Germann, 2003; Germann et al., 2004), and a problem formulation specifically targeting word reordering with an efficient word reordering algorithm has been proposed (Eisner and Tromble, 2006). A local search decoder has been advanced as a faster alternative to beam search also for phrasebased SMT (Langlais et al., 2007; Langlais et al., 2008). That work anticipates many of the features found in our decoder, including the use of local search to refine an initial hypothesis produced by DP beam search. The possibility of using models that do not fit well into the beam search paradigm is mentioned and illustrated with the example of a reversed n-gram language model, which the authors claim would be difficult to implement in a beam search decoder. Similarly to the work by Germann et al. (2001), their decoder is deterministic and explores the entire neighbourhood of a state in order to identify the most promising step. Our main contribu"
D12-1108,W10-1737,0,0.219847,"Missing"
D12-1108,W01-1408,0,0.0825319,"ring to extra-sentential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001; Tillmann and Ney, 2003). This algorithm constructs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elimination of hypotheses from the search space if they coincide in a certain number of"
D12-1108,P03-1021,0,0.0172753,"e training data for the English-French shared task at the WMT 2011 workshop (Callison-Burch et al., 2011). The phrase table was trained on Europarl, news-commentary and UN data. To reduce the training data to a manageable size, singleton phrase pairs were removed before the phrase scoring step. Significance-based filtering (Johnson et al., 2007) was applied to the resulting phrase table. The language model was a 5gram model with Kneser-Ney smoothing trained on the monolingual News corpus with IRSTLM (Federico et al., 2008). Feature weights were trained with Minimum Error-Rate Training (MERT) (Och, 2003) on the news-test2008 development set using the DP beam search decoder and the MERT implementation of the Moses toolkit (Koehn et al., 2007). Experimental results are reported for the newstest2009 test set, a corpus of 111 newswire documents totalling 2,525 sentences or 65,595 English input tokens. Experimental Results In this section, we present the results of a series of experiments with our document decoder. The 1184 Stability An important difference between our decoder and the classical DP decoder as well as previous work in SMT decoding with local search is that our decoder is inherently"
D12-1108,P02-1040,0,0.105323,"se in scores for all three test sets demonstrates that the hill climbing decoder manages to fix some of the search errors made by the DP search. The last row contains the scores obtained by adding in the semantic language model. Scores are presented for three publicly available test sets from recent WMT Machine Translation shared tasks, of which one (newstest2009) was used to monitor progress during development and select the final model. Adding the semantic language model results in a small increase in NIST scores (Doddington, 2002) for all three test sets as well as a small BLEU score gain (Papineni et al., 2002) for two out of three corpora. We note that the NIST score turned out to react more sensitively to improvements due to the semantic LM in all our experiments, which is reasonable because the model specifically targets content words, which benefit from the information weighting done by the NIST score. While the results we present do not constitute compelling evidence in favour of our semantic LM in its current form, they do suggest that this model could be improved to realise higher gains from cross-sentence semantic information. They support our claim that crosssentence models should be examin"
D12-1108,W10-1728,1,0.859272,"ational Natural c Language Learning, pages 1179–1190, Jeju Island, Korea, 12–14 July 2012. 2012 Association for Computational Linguistics any obvious way, especially if joint optimisation of a number of interdependent decisions over an entire document is required. Research into models with a more varied, non-local dependency structure is to some extent stifled by the difficulty of decoding such models effectively, as can be seen by the problems some researchers encountered when they attempted to solve discourse-level problems. Consider, for instance, the work on cache-based language models by Tiedemann (2010) and Gong et al. (2011), where error propagation was a serious issue, or the works on pronominal anaphora by Le Nagard and Koehn (2010), who implemented cross-sentence dependencies with an ad-hoc two-pass decoding strategy, and Hardmeier and Federico (2010) with the use of an external decoder driver to manage backward-only dependencies between sentences. In this paper, we present a method for decoding complete documents in phrase-based SMT. Our decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by"
D12-1108,J03-1005,0,0.0104688,"ential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001; Tillmann and Ney, 2003). This algorithm constructs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elimination of hypotheses from the search space if they coincide in a certain number of final words with a bette"
D12-1108,P97-1037,0,0.0171941,"correctly without referring to extra-sentential context. This is true both for the phrase-based and the syntaxbased approach to SMT. In the rest of this paper, we shall concentrate on phrase-based SMT. One reason why it is difficult to experiment with document-wide models for phrase-based SMT is that the dynamic programming (DP) algorithm which has been used almost exclusively for decoding SMT models in the recent literature has very strong assumptions of locality built into it. DP beam search for phrase-based SMT was described by Koehn et al. (2003), extending earlier work on word-based SMT (Tillmann et al., 1997; Och et al., 2001; Tillmann and Ney, 2003). This algorithm constructs output sentences by starting with an empty hypothesis and adding output words at the end until translations for all source words have been generated. The core models of phrase-based SMT, in particular the n-gram language model (LM), only depend on a constant number of output words to the left of the word being generated. This fact is exploited by the search algorithm with a DP technique called hypothesis recombination (Och et al., 2001), which permits the elimination of hypotheses from the search space if they coincide in a"
D12-1108,D07-1053,0,0.0691649,"Missing"
D12-1133,W06-2922,0,0.0120535,"re et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech tags and a set D of dependency labels, a tagged dependency tree for a sentence x = w1 , . . . , wn is a directed tree T = (Vx , A) with labeling functions π and δ such that: 1. Vx = {0, 1, . . . ,"
D12-1133,E12-1009,1,0.548119,"on) in combination with neighboring words, word prefixes, word suffixes, score differences and tag rank. Finally, in some experiments, we make use of two additional feature sets, which we call graph features (G) and cluster features (C), respectively. Graph features are defined over the factors of a graph-based dependency parser, which was shown to improve the accuracy of a transition-based parser by Zhang and Clark (2008). However, while their features were 1459 limited to certain first- and second-order factors, we use features over second- and third-order factors as found in the parsers of Bohnet and Kuhn (2012). These features are scored as soon as the factors are completed, using a technique that is similar to what Hatori et al. (2011) call delayed features, although they use it for part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector"
D12-1133,C10-1011,1,0.712467,"ccuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and"
D12-1133,W08-2102,0,0.0226881,"Missing"
D12-1133,D07-1101,0,0.0656566,"rovements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimizat"
D12-1133,P05-1022,0,0.0491642,"search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other."
D12-1133,A00-2018,0,0.172564,"Missing"
D12-1133,D07-1022,0,0.0449469,"Missing"
D12-1133,P04-1015,0,0.203067,"ary experiments. One final thing to note about the inference algorithm is that the notion of permissibility for a transition t out of a configuration c can be used to capture not only formal constraints on transitions – such as the fact that it is impossible to perform a S HIFTp transition with an empty buffer or illegal to perform a L EFT-A RCd transition with the special root node on top of the stack – but also to filter out unlike1458 τ= f(xj , yj ) − f(xj , y ∗ ) ||f(xj , yj ) − f(xj , y ∗ )||2 We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010), which means that, during learning, we terminate the beam search as soon as the hypothesis corresponding to the gold parse yj falls out of the beam and update with respect to the partial transition sequence constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors, as originally proposed by Collins (2002). 2.3 Feature Representations As already noted, the feature representation f(x, y) of an input sentence x with parse y decomposes into feature representations f(c, t) for the transitions t(c) needed"
D12-1133,P97-1003,0,0.137903,"Missing"
D12-1133,W02-1001,0,0.469906,"so that S HIFTp is permissible only if p is one of the k best part-of-speech tags with a score no more than α below the score of the 1-best tag, as determined by a preprocessing tagger. We also filter out instances of L EFT-A RCd and R IGHT-A RCd , where d does not occur in the training data for the predicted part-ofspeech tag combination of the head and dependent. This procedure leads to a significant speed up. In order to learn a weight vector w from a training set {(xj , yj )}Tj=1 of sentences with their tagged dependency trees, we use a variant of the structured perceptron, introduced by Collins (2002), which makes N iterations over the training data and updates the weight vector for every sentence xj where the highest scoring parse y ∗ is different from yj . More precisely, we use the passive-aggressive update of Crammer et al. (2006): wi+1 = wi + τ (f(xj , yj ) − f(xj , y ∗ )) (c,t)∈C0,m s(x, y) = X f(c, t) · w where (c,t)∈C0,m Finally, the configuration of the new hypothesis is obtained by evaluating t(h.c) (line 11). The new hypothesis is then inserted into T MP in score-sorted order (line 12). The pruning parameters b1 and b2 determine the number of hypotheses allowed in the beam and a"
D12-1133,W09-1205,0,0.0189706,"Missing"
D12-1133,P08-1043,0,0.0681111,"Missing"
D12-1133,I11-1136,0,0.819459,"or tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian. However, Li et al. (2011) and Hatori et al. (2011) report improvements with a joint model also for Chinese, which is not a richly inflected language but is nevertheless rich in part-of-speech ambiguities. In this paper, we present a transition-based model for joint part-of-speech tagging and labeled dependency parsing with non-projective trees. Exper1455 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural c Language Learning, pages 1455–1465, Jeju Island, Korea, 12–14 July 2012. 2012 Association for Computational Linguistics iments show that joint modeling improves both taggin"
D12-1133,P10-1110,0,0.394881,"led dependency parsing. It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representati"
D12-1133,W06-2930,0,0.0370504,"Missing"
D12-1133,P10-1001,0,0.127268,"h tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2"
D12-1133,P08-1068,0,0.208457,"racy of a transition-based parser by Zhang and Clark (2008). However, while their features were 1459 limited to certain first- and second-order factors, we use features over second- and third-order factors as found in the parsers of Bohnet and Kuhn (2012). These features are scored as soon as the factors are completed, using a technique that is similar to what Hatori et al. (2011) call delayed features, although they use it for part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector (Bohnet, 2010). This is usually done via a hash table, but significant speedups can be achieved by using a hash kernel, which simply replaces table lookup by a hash function (Bloom, 1970; Shi et al., 2009; Bohnet, 2010). The price to pay for these speedups is that there may be collisions, so that different features are mapped to the same index, but this is of"
D12-1133,D10-1125,0,0.0155999,"arch efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a pa"
D12-1133,P11-1089,0,0.0147608,"he Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian. However, Li et al. (2011) and Hatori et al. (2011) report improvements with a joint model also for Chinese, which is not a richly inflected language but is nevertheless rich in part-of-speech ambiguities. In this paper, we present a transition-based model for joint part-of-speech tagging and labeled dependency parsing with non-projective trees. Exper1455 Proceedings of the 2012 Joint Conference on Empirical Met"
D12-1133,D11-1109,0,0.358563,"s that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian. However, Li et al. (2011) and Hatori et al. (2011) report improvements with a joint model also for Chinese, which is not a richly inflected language but is nevertheless rich in part-of-speech ambiguities. In this paper, we present a transition-based model for joint part-of-speech tagging and labeled dependency parsing with non-projective trees. Exper1455 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural c Language Learning, pages 1455–1465, Jeju Island, Korea, 12–14 July 2012. 2012 Association for Computational Linguistics iments show that joint mode"
D12-1133,P09-1039,0,0.0147995,"c parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologi"
D12-1133,D10-1004,0,0.0861162,"focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated us"
D12-1133,E06-1011,0,0.209765,"German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selecti"
D12-1133,P05-1012,0,0.455901,"ese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy"
D12-1133,W04-2407,1,0.409781,"ciation for Computational Linguistics iments show that joint modeling improves both tagging and parsing accuracy, leading to state-of-the-art accuracy for richly inflected languages like Czech and German as well as more configurational languages like Chinese and English. To our knowledge, this is the first joint system that performs labeled dependency parsing. It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; N"
D12-1133,N07-1050,1,0.825999,"), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech tags and a set D of dependency labels, a tagged dependency tree for a sentence x = w1 , . . . , wn is a directed tree T = (Vx , A) with labeling functions π and δ such that: 1. Vx = {0, 1, . . . , n} is a set o"
D12-1133,J08-4003,1,0.798923,"the tree. The set Vx of nodes is the set of positive integers up to and including n, each corresponding to the linear position of a word in the sentence, plus an extra 1456 artificial root node 0. The set A of arcs is a set of pairs (i, j), where i is the head node and j is the dependent node. The functions π and δ assign a unique part-of-speech label to each node/word and a unique dependency label to each arc, respectively. This notion of dependency tree differs from the standard definition only by including part-of-speech labels as well as dependency labels (K¨ubler et al., 2009). Following Nivre (2008), we define a transition system for dependency parsing as a quadruple S = (C, T, cs , Ct ), where 1. C is a set of configurations, 2. T is a set of transitions, each of which is a (partial) function t : C → C, 3. cs is an initialization function, mapping a sentence x to a configuration c ∈ C, 4. Ct ⊆ C is a set of terminal configurations. A transition sequence for a sentence x in S is a sequence of configuration-transition pairs C0,m = [(c0 , t0 ), (c1 , t1 ), . . . , (cm , tm )] where c0 = cs (x), tm (cm ) ∈ Ct and ti (ci ) = ci+1 (0 ≤ i < m).1 In this paper, we take the set C of configuratio"
D12-1133,P09-1040,1,0.809231,"lassifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech tags and a set D of dependency labels, a tagged dependency tree for a sentence x = w1 , . . . , wn is a directed tree T = (Vx , A) with labeling functions π and δ such that: 1. Vx = {0, 1, . . . , n} is a set of nodes, 2. A"
D12-1133,N07-1051,0,0.0174838,"2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint mor"
D12-1133,P06-1055,0,0.0905061,"008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discrimin"
D12-1133,W06-1616,0,0.00579486,"nguages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the w"
D12-1133,C08-1098,0,0.037857,"Missing"
D12-1133,D08-1016,0,0.00900578,"ependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentenc"
D12-1133,P11-2009,0,0.0602517,"Missing"
D12-1133,D09-1058,0,0.0481609,"Missing"
D12-1133,W07-2218,0,0.100716,"uced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and t"
D12-1133,N03-1033,0,0.143986,"onverted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006).4 In order to assign k-best part-of-speech tags and scores to words in the training set, we used a perceptron tagger with 10-fold jack-knifing. The same type of tagger was trained on the entire training set in order to supply tags for the development and test sets. The feature set of the tagger was optimized for English and German and provides state-of-theart accuracy for these two languages. The 1-best tagging accuracy for section 23 of the Penn Treebank is 97.28, which is on a par with Toutanova et al. (2003). For German, we obtain a tagging accuracy of 97.24, which is close to the 97.39 achieved by the RF-Tagger (Schmid and Laws, 2008), which to our knowledge is the best tagger for German.5 The results are not directly comparable to the RF-Tagger as it was evaluated on a different part of the Tiger Treebank and trained on a larger part of the Treebank. We could not use the larger training set as it contains the test set of the CoNLL 2009 data that we use to evaluate the joint model. For Czech, the 1best tagging accuracy is 99.11 and for Chinese 92.65 on the CoNLL 2009 test set. We trained parsers"
D12-1133,P06-3009,0,0.198008,"Missing"
D12-1133,W03-3023,0,0.916128,"orea, 12–14 July 2012. 2012 Association for Computational Linguistics iments show that joint modeling improves both tagging and parsing accuracy, leading to state-of-the-art accuracy for richly inflected languages like Czech and German as well as more configurational languages like Chinese and English. To our knowledge, this is the first joint system that performs labeled dependency parsing. It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early s"
D12-1133,D08-1059,0,0.814263,"ing. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Pet"
D12-1133,J11-1005,0,0.0446316,"parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov"
D12-1133,P11-2033,1,0.842746,"net, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might imp"
D12-1133,W09-1201,1,\N,Missing
D13-1037,S10-1021,0,0.134997,"to interesting insights about anaphora resolution in a multi-lingual context. In particular, we show in this paper that the pronoun prediction task makes it possible to model the resolution of pronominal anaphora as a latent variable and opens up a way to solve a task relying on anaphora resolution without using any data annotated for anaphora. This is what we consider the main contribution of our present work. We start by modelling cross-lingual pronoun prediction as an independent machine learning task after doing anaphora resolution in the source language (English) using the BART software (Broscheit et al., 2010). We show that it is difficult to achieve satisfactory performance with standard maximum380 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 380–391, c Seattle, Washington, USA, 18-21 October 2013. 2013 Association for Computational Linguistics The latest version released in March is equipped with ... It is sold at ... La dernière version lancée en mars est dotée de ... • est vendue ... Figure 1: Task setup entropy classifiers especially for low-frequency pronouns such as the French feminine plural pronoun elles. We propose a neural network classifi"
D13-1037,2012.eamt-1.60,0,0.0357142,"vely. The target words are represented as one-hot vectors with the dimensionality of the target language vocabulary. These vectors are then averaged to yield a single vector per antecedent candidate. Finally, the vectors of all candidates for a given training example are weighted by the probabilities assigned to them by the anaphora resolver (p1 and p2 ) and summed to yield a single vector per training example. 3 Data Sets and External Tools We run experiments with two different test sets. The TED data set consists of around 2.6 million tokens of lecture subtitles released in the WIT3 corpus (Cettolo et al., 2012). The WIT3 training data yields 71,052 examples, which were randomly partitioned into a training set of 63,228 examples and a test set of 7,824 examples. The official WIT3 development and test sets were not used in our experiments. The news-commentary data set is version 6 of the parallel news-commentary corpus released as a part of the WMT 2011 training data1 . It contains around 2.8 million tokens of news text and yields 31,017 data points, 1 http://www.statmt.org/wmt11/translation-task. html (3 July 2013). 382 The feature setup of all our classifiers requires the detection of potential ante"
D13-1037,E09-1018,0,0.0150325,"ignments to project coreference annotations from one language to another with a view to training anaphora resolvers in the target language (Postolache et al., 2006; de Souza and Or˘asan, 2011). Rahman and Ng (2012) instead use machine translation to translate their test 389 data into a language for which they have an anaphora resolver and then project the annotations back to the original language. Completely unsupervised monolingual anaphora resolution has been approached using, e. g., Markov logic (Poon and Domingos, 2008) and the Expectation-Maximisation algorithm (Cherry and Bergsma, 2005; Charniak and Elsner, 2009). To the best of our knowledge, the direct application of machine learning techniques to parallel data in a task related to anaphora resolution is novel in our work. Neural networks and deep learning techniques have recently gained some popularity in natural language processing. They have been applied to tasks such as language modelling (Bengio et al., 2003; Schwenk, 2007), translation modelling in statistical machine translation (Le et al., 2012), but also part-ofspeech tagging, chunking, named entity recognition and semantic role labelling (Collobert et al., 2011). In tasks related to anapho"
D13-1037,W05-0612,0,0.0253418,"ther work has used word alignments to project coreference annotations from one language to another with a view to training anaphora resolvers in the target language (Postolache et al., 2006; de Souza and Or˘asan, 2011). Rahman and Ng (2012) instead use machine translation to translate their test 389 data into a language for which they have an anaphora resolver and then project the annotations back to the original language. Completely unsupervised monolingual anaphora resolution has been approached using, e. g., Markov logic (Poon and Domingos, 2008) and the Expectation-Maximisation algorithm (Cherry and Bergsma, 2005; Charniak and Elsner, 2009). To the best of our knowledge, the direct application of machine learning techniques to parallel data in a task related to anaphora resolution is novel in our work. Neural networks and deep learning techniques have recently gained some popularity in natural language processing. They have been applied to tasks such as language modelling (Bengio et al., 2003; Schwenk, 2007), translation modelling in statistical machine translation (Le et al., 2012), but also part-ofspeech tagging, chunking, named entity recognition and semantic role labelling (Collobert et al., 2011)"
D13-1037,E12-3001,0,0.373892,"with good results to project coreference annotations from one language into another by using word alignments (Postolache et al., 2006; Rahman and Ng, 2012). On the other hand, what is true in general need not be true for all types of linguistic elements. For instance, a substantial percentage of the English thirdperson subject pronouns he, she, it and they does not get realised as pronouns in French translations (Hardmeier, 2012). Moreover, it has been recognised by various authors in the statistical machine translation (SMT) community (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012) that pronoun translation is a difficult problem because, even when a pronoun does get translated as a pronoun, it may require choosing the correct word form based on agreement features that are not easily predictable from the source text. The work presented in this paper investigates the problem of cross-lingual pronoun prediction for English-French. Given an English pronoun and its discourse context as well as a French translation of the same discourse and word alignments between the two languages, we attempt to predict the French word aligned to the English pronoun. As far as we know, this"
D13-1037,2010.iwslt-papers.10,1,0.536436,"this fact has been exploited with good results to project coreference annotations from one language into another by using word alignments (Postolache et al., 2006; Rahman and Ng, 2012). On the other hand, what is true in general need not be true for all types of linguistic elements. For instance, a substantial percentage of the English thirdperson subject pronouns he, she, it and they does not get realised as pronouns in French translations (Hardmeier, 2012). Moreover, it has been recognised by various authors in the statistical machine translation (SMT) community (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012) that pronoun translation is a difficult problem because, even when a pronoun does get translated as a pronoun, it may require choosing the correct word form based on agreement features that are not easily predictable from the source text. The work presented in this paper investigates the problem of cross-lingual pronoun prediction for English-French. Given an English pronoun and its discourse context as well as a French translation of the same discourse and word alignments between the two languages, we attempt to predict the French word aligned to the English pronoun. As far a"
D13-1037,P03-1054,0,0.00907702,"e anaphora resolver BART to generate this information. BART (Broscheit et al., 2010) is an anaphora resolution toolkit consisting of a markable detection and feature extraction pipeline based on a variety of standard natural language processing (NLP) tools and a machine learning component to predict coreference links including both pronominal anaphora and noun-noun coreference. In our experiments, we always use BART’s markable detection and feature extraction machinery. Markable detection is based on the identification of noun phrases in constituency parses generated with the Stanford parser (Klein and Manning, 2003). The set of features extracted by BART is an extension of the widely used mention-pair anaphora resolution feature set by Soon et al. (2001) (see below, Section 6). In the experiments of the next two sections, we also use BART to predict anaphoric links for pronouns. The model used with BART is a maximum entropy ranker trained on the ACE02-npaper corpus (LDC2003T11). In order to obtain a probability distribution over antecedent candidates rather than onebest predictions or coreference sets, we modified the ranking component with which BART resolves pronouns to normalise and output the scores"
D13-1037,N12-1005,0,0.00779725,"been approached using, e. g., Markov logic (Poon and Domingos, 2008) and the Expectation-Maximisation algorithm (Cherry and Bergsma, 2005; Charniak and Elsner, 2009). To the best of our knowledge, the direct application of machine learning techniques to parallel data in a task related to anaphora resolution is novel in our work. Neural networks and deep learning techniques have recently gained some popularity in natural language processing. They have been applied to tasks such as language modelling (Bengio et al., 2003; Schwenk, 2007), translation modelling in statistical machine translation (Le et al., 2012), but also part-ofspeech tagging, chunking, named entity recognition and semantic role labelling (Collobert et al., 2011). In tasks related to anaphora resolution, standard feedforward neural networks have been tested as a classifier in an anaphora resolution system (Stuckardt, 2007), but the network design presented in our work is novel. 9 Conclusion In this paper, we have introduced cross-lingual pronoun prediction as an independent natural language processing task. Even though it is not an end-to-end task, pronoun prediction is interesting for several reasons. It is related to the problem o"
D13-1037,W10-1737,0,0.450652,"Missing"
D13-1037,J03-1002,0,0.00316037,"ference resolution system (BART) to predict anaphoric links. Anaphora resolution is done by our neural network classifier and requires only some quantity of word-aligned parallel data for training, completely obviating the need for a coreference-annotated training set. 2 Task Setup The overall setup of the classification task we address in this paper is shown in Figure 1. We are given an English discourse containing a pronoun along with its French translation and word alignments between the two languages, which in our case were computed automatically using a standard SMT pipeline with GIZA++ (Och and Ney, 2003). We focus on the four English third-person subject pronouns he, she, it and they. The output of the classifier is a multinomial distribution over six classes: the four French subject pronouns il, elle, ils and elles, corresponding to masculine and feminine singular and plural, respectively; the impersonal pronoun ce/c’, which occurs in some very frequent constructions such as c’est (it is); and a sixth class OTHER, which indicates that none of these pronouns was used. In general, a pronoun may be aligned to multiple words; in this case, a training example is counted as a positive example for"
D13-1037,D08-1068,0,0.0258809,"to English-Czech data to resolve different uses of the pronoun it. Other work has used word alignments to project coreference annotations from one language to another with a view to training anaphora resolvers in the target language (Postolache et al., 2006; de Souza and Or˘asan, 2011). Rahman and Ng (2012) instead use machine translation to translate their test 389 data into a language for which they have an anaphora resolver and then project the annotations back to the original language. Completely unsupervised monolingual anaphora resolution has been approached using, e. g., Markov logic (Poon and Domingos, 2008) and the Expectation-Maximisation algorithm (Cherry and Bergsma, 2005; Charniak and Elsner, 2009). To the best of our knowledge, the direct application of machine learning techniques to parallel data in a task related to anaphora resolution is novel in our work. Neural networks and deep learning techniques have recently gained some popularity in natural language processing. They have been applied to tasks such as language modelling (Bengio et al., 2003; Schwenk, 2007), translation modelling in statistical machine translation (Le et al., 2012), but also part-ofspeech tagging, chunking, named en"
D13-1037,postolache-etal-2006-transferring,0,0.0935963,"Missing"
D13-1037,N12-1090,0,0.203502,"tion When texts are translated from one language into another, the translation reconstructs the meaning or function of the source text with the means of the target language. Generally, this has the effect that the entities occurring in the translation and their mutual relations will display similar patterns as the entities in the source text. In particular, coreference patterns tend to be very similar in translations of a text, and this fact has been exploited with good results to project coreference annotations from one language into another by using word alignments (Postolache et al., 2006; Rahman and Ng, 2012). On the other hand, what is true in general need not be true for all types of linguistic elements. For instance, a substantial percentage of the English thirdperson subject pronouns he, she, it and they does not get realised as pronouns in French translations (Hardmeier, 2012). Moreover, it has been recognised by various authors in the statistical machine translation (SMT) community (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012) that pronoun translation is a difficult problem because, even when a pronoun does get translated as a pronoun, it may require choosing the c"
D13-1037,J01-4004,0,0.560755,"ection and feature extraction pipeline based on a variety of standard natural language processing (NLP) tools and a machine learning component to predict coreference links including both pronominal anaphora and noun-noun coreference. In our experiments, we always use BART’s markable detection and feature extraction machinery. Markable detection is based on the identification of noun phrases in constituency parses generated with the Stanford parser (Klein and Manning, 2003). The set of features extracted by BART is an extension of the widely used mention-pair anaphora resolution feature set by Soon et al. (2001) (see below, Section 6). In the experiments of the next two sections, we also use BART to predict anaphoric links for pronouns. The model used with BART is a maximum entropy ranker trained on the ACE02-npaper corpus (LDC2003T11). In order to obtain a probability distribution over antecedent candidates rather than onebest predictions or coreference sets, we modified the ranking component with which BART resolves pronouns to normalise and output the scores assigned by the ranker to all candidates instead of picking the highest-scoring candidate. 4 Baseline Classifiers In order to create a simple"
D13-1037,J03-4003,0,\N,Missing
D13-1037,sagot-etal-2006-lefff,0,\N,Missing
D18-1291,D15-1041,0,0.276216,"rsity Abstract 2017). When task-specific training data is scarce or the morphological complexity of a language leads to sparsity at the word-type level, word embeddings often need to be augmented with sub-word or partof-speech (POS) tag information in order to release their full power (Kim et al., 2016; Sennrich et al., 2016; Chen and Manning, 2014). Initialising vectors with embeddings trained for a different task, typically language modelling, on huge unlabelled corpora has also been shown to improve results significantly (Dhingra et al., 2017a). In dependency parsing, the use of character (Ballesteros et al., 2015) and POS (Dyer et al., 2015) models is widespread, and the majority of parsers make use of pre-trained word embeddings (Zeman et al., 2017). We provide a comprehensive analysis of the interactions between pre-trained word embeddings, character models and POS tags in a transition-based dependency parser. While previous studies have shown POS information to be less important in the presence of character models, we show that in fact there are complex interactions between all three techniques. In isolation each produces large improvements over a baseline system using randomly initialised word embe"
D18-1291,D14-1082,0,0.136168,"s • For all techniques, improvements are largest for low-frequency and open-class words and for morphologically rich languages. • These improvements are largely redundant when the techniques are used together. • Character-based models are the most effective technique for low-frequency words. • Part-of-speech tags are potentially very effective for high-frequency function words, but current state-of-the-art taggers are not accurate enough to take full advantage of this. • Large character embeddings are helpful for morphologically rich languages, regardless of character set size. 2 Related Work Chen and Manning (2014) introduced POS tag embeddings: a learned dense representation of each tag designed to exploit semantic similarities between tags. In their greedy transition-based parser, the inclusion of these POS tag embeddings improved labelled attachment score (LAS) by 1.7 on the English Penn Treebank (ETB) and almost 10 on the Chinese Penn Treebank (CTB). They also tested the use of pre-trained word embeddings for initialisation of word vectors, finding gains of 0.7 for PTB and 1.7 for CTB. Dyer et al. (2015) in their Stack Long ShortTerm Memory (LSTM) dependency parser, show that POS tag embeddings in t"
D18-1291,P17-1168,0,0.121491,"e Joakim Nivre Department of Linguistics and Philology, Uppsala University Abstract 2017). When task-specific training data is scarce or the morphological complexity of a language leads to sparsity at the word-type level, word embeddings often need to be augmented with sub-word or partof-speech (POS) tag information in order to release their full power (Kim et al., 2016; Sennrich et al., 2016; Chen and Manning, 2014). Initialising vectors with embeddings trained for a different task, typically language modelling, on huge unlabelled corpora has also been shown to improve results significantly (Dhingra et al., 2017a). In dependency parsing, the use of character (Ballesteros et al., 2015) and POS (Dyer et al., 2015) models is widespread, and the majority of parsers make use of pre-trained word embeddings (Zeman et al., 2017). We provide a comprehensive analysis of the interactions between pre-trained word embeddings, character models and POS tags in a transition-based dependency parser. While previous studies have shown POS information to be less important in the presence of character models, we show that in fact there are complex interactions between all three techniques. In isolation each produces larg"
D18-1291,K17-3002,0,0.295654,"ng to reading comprehension to machine translation, a unique dense vector is learned for each word type in the training data. These word embeddings have been shown to capture essential semantic and morphological relationships between words (Mikolov et al., 2013), and have precipitated the enormous success of neural network-based architectures across a wide variety of NLP tasks (Plank et al., 2016; Dhingra et al., 2017b; Vaswani et al., While previous research has examined in detail the benefits of character and POS models in dependency parsing and their interactions (Ballesteros et al., 2015; Dozat et al., 2017), there has been no systematic investigation into the way these techniques combine with the use of pretrained embeddings. Our results suggest a large amount of redundancy between all three techniques: in isolation, each gives large improvements over a simple baseline model, but these improvements are not additive. In fact combining any two of the three methods gives similar results, close to the performance of the fully combined system. We set out to systematically investigate the ways in which pre-trained embeddings, character and POS models contribute to improving parser quality. We break do"
D18-1291,P15-1033,0,0.397559,"cific training data is scarce or the morphological complexity of a language leads to sparsity at the word-type level, word embeddings often need to be augmented with sub-word or partof-speech (POS) tag information in order to release their full power (Kim et al., 2016; Sennrich et al., 2016; Chen and Manning, 2014). Initialising vectors with embeddings trained for a different task, typically language modelling, on huge unlabelled corpora has also been shown to improve results significantly (Dhingra et al., 2017a). In dependency parsing, the use of character (Ballesteros et al., 2015) and POS (Dyer et al., 2015) models is widespread, and the majority of parsers make use of pre-trained word embeddings (Zeman et al., 2017). We provide a comprehensive analysis of the interactions between pre-trained word embeddings, character models and POS tags in a transition-based dependency parser. While previous studies have shown POS information to be less important in the presence of character models, we show that in fact there are complex interactions between all three techniques. In isolation each produces large improvements over a baseline system using randomly initialised word embeddings only, but combining t"
D18-1291,Q16-1023,0,0.397497,"vel as a model using a combination of word embeddings and POS tags. Combining character and POS models produced even better results, but they conclude that POS tags are less important for character-based parsers. They also showed that character models are particularly effective for morphologically rich languages, but that performance remains good in languages with little morphology, and that character models help substantially with out-of-vocabulary (OOV) words, but that this does not fully explain the improvements they bring. The use of pretrained embeddings was not considered in their work. Kiperwasser and Goldberg (2016), in the transition-based version of their parser based on BiLSTM feature extractors, found that POS tags improved performance by 0.3 LAS for English and 4.4 LAS for Chinese. Like Dyer et al. (2015), they concatenate a randomly-initialised word embeddings to a pre-trained word vector; however in this case the pre-trained vector is also updated during training. They find that this helps LAS by 0.5–0.7 for English and 0.9–1.2 for Chinese, depending on the specific architecture of their system. Dozat et al. (2017), building on the graph-based version of Kiperwasser and Goldberg (2016), confirmed"
D18-1291,K17-3022,1,0.633554,"Missing"
D18-1291,W17-6314,1,0.693983,"Missing"
D18-1291,K18-2011,1,0.828401,"Missing"
D18-1291,L16-1680,0,0.0506962,"Missing"
D18-1291,K17-3009,0,0.0291312,"Missing"
D18-1291,J08-4003,1,0.758759,"both transition- and graph-based dependency parsing, and has quickly become a de facto standard in the field (Zeman et al., 2017). In a K&G parser, BiLSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2008) are employed to learn useful representations of tokens in context. A multi-layer perceptron (MLP) is trained to predict transitions and possible arc labels, taking as input the BiLSTM vectors of a few tokens at a time. Crucially, the BiLSTMs and MLP are trained together, enabling the parser to learn very effective token representations for parsing. For further details we refer the reader to Nivre (2008) and Kiperwasser and Goldberg (2016), for transition-based parsing and BiLSTM feature extractors, respectively. Our version of the K&G parser is extended with a S WAP transition to facilitate the construction 1 https://github.com/UppsalaNLP/ uuparser 2712 of non-projective dependency trees (Nivre, 2009). We use a static-dynamic oracle to allow the parser to learn from non-optimal configurations at training time in order to recover better from mistakes at test time, as described in de Lhoneux et al. (2017b). In this paper we experiment with a total of eight variations of the parser, where the d"
D18-1291,P09-1040,1,0.827167,"is trained to predict transitions and possible arc labels, taking as input the BiLSTM vectors of a few tokens at a time. Crucially, the BiLSTMs and MLP are trained together, enabling the parser to learn very effective token representations for parsing. For further details we refer the reader to Nivre (2008) and Kiperwasser and Goldberg (2016), for transition-based parsing and BiLSTM feature extractors, respectively. Our version of the K&G parser is extended with a S WAP transition to facilitate the construction 1 https://github.com/UppsalaNLP/ uuparser 2712 of non-projective dependency trees (Nivre, 2009). We use a static-dynamic oracle to allow the parser to learn from non-optimal configurations at training time in order to recover better from mistakes at test time, as described in de Lhoneux et al. (2017b). In this paper we experiment with a total of eight variations of the parser, where the difference between each version resides in the vector representations xi of word types wi before they are passed to the BiLSTM feature extractors (see Section 3 of Kiperwasser and Goldberg (2016)). In the simplest case, we set xi equal to the word embedding er (wi ): xi = er (wi ) The superscript r refer"
D18-1291,K17-3001,1,0.867824,"Missing"
D18-1291,P16-2067,0,0.023463,"y rich languages. 1 Introduction The last few years of research in natural language processing (NLP) have witnessed an explosion in the application of neural networks and word embeddings. In tasks ranging from POS tagging to reading comprehension to machine translation, a unique dense vector is learned for each word type in the training data. These word embeddings have been shown to capture essential semantic and morphological relationships between words (Mikolov et al., 2013), and have precipitated the enormous success of neural network-based architectures across a wide variety of NLP tasks (Plank et al., 2016; Dhingra et al., 2017b; Vaswani et al., While previous research has examined in detail the benefits of character and POS models in dependency parsing and their interactions (Ballesteros et al., 2015; Dozat et al., 2017), there has been no systematic investigation into the way these techniques combine with the use of pretrained embeddings. Our results suggest a large amount of redundancy between all three techniques: in isolation, each gives large improvements over a simple baseline model, but these improvements are not additive. In fact combining any two of the three methods gives similar res"
D18-1291,D17-1035,0,0.0266976,"factors. In the frequency and POS tag cases, we want to examine the overall contribution to LAS of words from each category. We expect changing the representation of a token to affect how likely it is to be assigned the correct head in the dependency tree, but also how likely it is to be assigned correctly as the head of other words. We thus introduce a new metric for this part of the analysis: the head and dependents labelled attachment score, which we refer to as HD3 Changing the random seed has been shown to produce results that appear statistically significant different in neural systems (Reimers and Gurevych, 2017). 4 Available at https://web.stanford.edu/˜tdozat/. LAS. When calculating HDLAS, the dependency analysis for a given token is only considered correct if the token has the correct labelled head and the complete set of correctly labelled dependents. This is a harsher metric than LAS, which only considers whether a token has the correct labelled head. Note that when calculating HDLAS for all tokens in a sentence, each dependency relation is counted twice, once for the head word and once for the dependent. It only makes sense to use this metric when analysing individual tokens in a sentence, or wh"
D18-1291,P16-1162,0,0.060115,"Missing"
D19-1149,P17-1080,0,0.0303653,"18), extracted from ContraWSD (Rios et al., 2017), for both German→English (DE→EN) and German→French (DE→FR). The classifier is fed a representation of ambiguous nouns and a word sense (represented as the embedding of a translation candidate), and has to predict whether the two match. We can learn the role that encoders play in encoding information relevant for WSD by comparing different representations: word embeddings and encoder hidden states at different layers. We extract encoder hidden states from both RNNbased (RNNS2S) (Luong et al., 2015) and Transformer (Vaswani et al., 2017) models. Belinkov et al. (2017a,b) have shown that the higher layers are better at learning semantics. We hypothesize that the hidden states in higher layers incorporate more relevant information for WSD than those in lower layers. In addition to encoders, we also probe how much do decoder hidden states contribute to the WSD classification task. Recently, the distributions of attention mechanisms have been used for interpreting NMT models (Ghader and Monz, 2017; Voita et al., 2018; Tang et al., 2018b; Voita et al., 2019; Tang et al., 2019). We further investigate the attention weights and attention entropy of self-attentio"
D19-1149,I17-1001,0,0.057937,"Missing"
D19-1149,2005.mtsummit-papers.11,0,0.0517875,"ention distributions. We use attention entropy (Ghader and Monz, 2017) to measure the concentration. EAt (xt ) = − |x| X examples are used for training. We train 10 times with different seeds for each classifier and apply average accuracy. Table 1 lists the detailed statistics of the data. More experimental details are provided in the Appendix. At(xi , xt ) log At(xi , xt ) (1) i=1 For NMT models, we use the Sockeye (Hieber et al., 2017) toolkit to train RNNS2Ss and Transformers. DE→EN training data is from the WMT17 shared task (Bojar et al., 2017). DE→FR training data is from Europarl (v7) (Koehn, 2005) and News Commentary (v11) cleaned by Rios et al. (2017).3 In ContraWSD, each ambiguous noun has a small number of translation candidates. The average number of word senses per noun is 2.4 and 2.3 in DE→EN and DE→FR, respectively. We generate instances that are labelled with one candidate and a binary value indicating whether it corresponds to the correct sense. we get 50,792 and 43,268 instances in DE→EN and DE→FR, respectively. 5K/5K examples are randomly selected as the test/development set. The remaining We use TreeTagger (Schmid, 1995) to identify nouns. (1) If a query word is split into"
D19-1149,W17-3204,0,0.0226269,"umber of senses. Lexical ambiguities: number of sentences containing an ambiguous word. Instances: number of instances generated for WSD classification. 3.1 Results Table 2 provides the BLEU scores and the WSD accuracy on test sets, using different representations to represent ambiguous nouns. ENC denotes encoder hidden states; DEC means decoder hidden states. DE→EN Experiments 1 DE→FR NMT training data Here xi denotes the ith source token, xt is the current source token, and At(xi , xt ) represents the attention weight from xt to xi . We merge subwords after encoding, following the method in Koehn and Knowles (2017).2 Each self-attention layer has multiple heads and we average the attention weights from all the heads. In theory, sentential information is more important for ambiguous words that need to be disambiguated than non-ambiguous words. From the perspective of attention weights, for ambiguous words, we hypothesize that self-attention distributes more attention to the context words to capture the relevant sentential information, compared to words in general. From the perspective of attention entropy, we hypothesize that self-attention focuses on the related context words rather than the entire sent"
D19-1149,D15-1166,0,0.47884,"uous noun. We find that encoder hidden states outperform word embeddings significantly which indicates that encoders adequately encode relevant information for disambiguation into hidden states. In contrast to encoders, the effect of decoder is different in models with different architectures. Moreover, the attention weights and attention entropy show that self-attention can detect ambiguous nouns and distribute more attention to the context. 1 Introduction Neural machine translation (NMT) models (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) have access to the whole source sentence for the prediction of each word, which intuitively allows them to perform word sense disambiguation (WSD) better than previous phrase-based methods, and Rios et al. (2018) have confirmed this empirically. However, it is still unclear which component dominates the ability to disambiguate word senses. We explore the ability of NMT encoders and decoders to disambiguate word senses by evaluating hidden states and investigating the self-attention distributions. Marvin and Koehn (2018) find that the hidden states in higher encoder layers do not perform disam"
D19-1149,W18-1812,0,0.168414,"unsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) have access to the whole source sentence for the prediction of each word, which intuitively allows them to perform word sense disambiguation (WSD) better than previous phrase-based methods, and Rios et al. (2018) have confirmed this empirically. However, it is still unclear which component dominates the ability to disambiguate word senses. We explore the ability of NMT encoders and decoders to disambiguate word senses by evaluating hidden states and investigating the self-attention distributions. Marvin and Koehn (2018) find that the hidden states in higher encoder layers do not perform disambiguation better than those in lower layers and conclude that encoders do not encode enough relevant context for disambiguation. However, their results are based on small data sets, and we wish to revisit this question with larger-scale data sets. Tang et al. (2018b) speculate that encoders have encoded the relevant information for WSD into hidden states before decoding but without any experimental tests. In this paper, we first train a classifier for WSD, on a much larger data set than Marvin and Koehn (2018), extracted"
D19-1149,W18-6319,0,0.0622041,"Missing"
D19-1149,D14-1179,0,0.115535,"Missing"
D19-1149,N18-1119,0,0.0178907,"so that ambiguous nouns have different representations in different source sentences. We can learn to what extent relevant information for WSD is encoded by encoders by comparing to the baseline. Decoders To explore the role of decoders, we feed the decoder hidden state at the time step predicting the translation of the ambiguous noun, and the word embedding of the current translate candidate into the classifier. The decoder hidden state is extracted from the last decoder layer. To get these hidden states. we force NMT models to generate the reference translations using constrained decoding (Post and Vilar, 2018). Since decoders are crucial in NMT, we assume that the decoder hidden states incorporate more relevant information for WSD from the decoder side. Thus, we hypothesize that using decoder hidden states can achieve better WSD performance. 2.2 Attention Distribution The attention weights can be viewed as the degree of contribution to the current word representation, which provides a way to interpret NMT models. Tang et al. (2018a) have shown that Transformers with self-attention are better at WSD than RNNs. However, the working mechanism of self-attention has not been explored. We try to use the"
D19-1149,I17-1004,0,0.135022,"hidden states at different layers. We extract encoder hidden states from both RNNbased (RNNS2S) (Luong et al., 2015) and Transformer (Vaswani et al., 2017) models. Belinkov et al. (2017a,b) have shown that the higher layers are better at learning semantics. We hypothesize that the hidden states in higher layers incorporate more relevant information for WSD than those in lower layers. In addition to encoders, we also probe how much do decoder hidden states contribute to the WSD classification task. Recently, the distributions of attention mechanisms have been used for interpreting NMT models (Ghader and Monz, 2017; Voita et al., 2018; Tang et al., 2018b; Voita et al., 2019; Tang et al., 2019). We further investigate the attention weights and attention entropy of self-attention in encoders to explore how self-attention incorporates relevant information for WSD into hidden states. As sentential information is helpful in disambiguating ambiguous words, we hypothesize that self1429 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 1429–1435, c Hong Kong, China, November 3–7, 2019. 2019 Asso"
D19-1149,W17-4702,1,0.83005,"dden states in higher encoder layers do not perform disambiguation better than those in lower layers and conclude that encoders do not encode enough relevant context for disambiguation. However, their results are based on small data sets, and we wish to revisit this question with larger-scale data sets. Tang et al. (2018b) speculate that encoders have encoded the relevant information for WSD into hidden states before decoding but without any experimental tests. In this paper, we first train a classifier for WSD, on a much larger data set than Marvin and Koehn (2018), extracted from ContraWSD (Rios et al., 2017), for both German→English (DE→EN) and German→French (DE→FR). The classifier is fed a representation of ambiguous nouns and a word sense (represented as the embedding of a translation candidate), and has to predict whether the two match. We can learn the role that encoders play in encoding information relevant for WSD by comparing different representations: word embeddings and encoder hidden states at different layers. We extract encoder hidden states from both RNNbased (RNNS2S) (Luong et al., 2015) and Transformer (Vaswani et al., 2017) models. Belinkov et al. (2017a,b) have shown that the hig"
D19-1149,E17-3017,1,0.827005,"e attention distributions of ambiguous nouns to nouns in gen1430 eral1 in two respects. One is the attention weight over the word itself. The other one is the concentration of attention distributions. We use attention entropy (Ghader and Monz, 2017) to measure the concentration. EAt (xt ) = − |x| X examples are used for training. We train 10 times with different seeds for each classifier and apply average accuracy. Table 1 lists the detailed statistics of the data. More experimental details are provided in the Appendix. At(xi , xt ) log At(xi , xt ) (1) i=1 For NMT models, we use the Sockeye (Hieber et al., 2017) toolkit to train RNNS2Ss and Transformers. DE→EN training data is from the WMT17 shared task (Bojar et al., 2017). DE→FR training data is from Europarl (v7) (Koehn, 2005) and News Commentary (v11) cleaned by Rios et al. (2017).3 In ContraWSD, each ambiguous noun has a small number of translation candidates. The average number of word senses per noun is 2.4 and 2.3 in DE→EN and DE→FR, respectively. We generate instances that are labelled with one candidate and a binary value indicating whether it corresponds to the correct sense. we get 50,792 and 43,268 instances in DE→EN and DE→FR, respectiv"
D19-1149,D13-1176,0,0.086378,"ain a classifier to predict whether a translation is correct given the representation of an ambiguous noun. We find that encoder hidden states outperform word embeddings significantly which indicates that encoders adequately encode relevant information for disambiguation into hidden states. In contrast to encoders, the effect of decoder is different in models with different architectures. Moreover, the attention weights and attention entropy show that self-attention can detect ambiguous nouns and distribute more attention to the context. 1 Introduction Neural machine translation (NMT) models (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) have access to the whole source sentence for the prediction of each word, which intuitively allows them to perform word sense disambiguation (WSD) better than previous phrase-based methods, and Rios et al. (2018) have confirmed this empirically. However, it is still unclear which component dominates the ability to disambiguate word senses. We explore the ability of NMT encoders and decoders to disambiguate word senses by evaluating hidden states and investigating the self-attention distributions. Marvin and"
D19-1149,W18-6437,1,0.905897,"Missing"
D19-1149,P16-1162,1,0.680945,"Missing"
D19-1149,D18-1458,1,0.891786,"Missing"
D19-1149,W18-6304,1,0.867723,"owever, it is still unclear which component dominates the ability to disambiguate word senses. We explore the ability of NMT encoders and decoders to disambiguate word senses by evaluating hidden states and investigating the self-attention distributions. Marvin and Koehn (2018) find that the hidden states in higher encoder layers do not perform disambiguation better than those in lower layers and conclude that encoders do not encode enough relevant context for disambiguation. However, their results are based on small data sets, and we wish to revisit this question with larger-scale data sets. Tang et al. (2018b) speculate that encoders have encoded the relevant information for WSD into hidden states before decoding but without any experimental tests. In this paper, we first train a classifier for WSD, on a much larger data set than Marvin and Koehn (2018), extracted from ContraWSD (Rios et al., 2017), for both German→English (DE→EN) and German→French (DE→FR). The classifier is fed a representation of ambiguous nouns and a word sense (represented as the embedding of a translation candidate), and has to predict whether the two match. We can learn the role that encoders play in encoding information re"
D19-1149,R19-1136,1,0.828719,"Missing"
D19-1149,P18-1117,1,0.760909,"rent layers. We extract encoder hidden states from both RNNbased (RNNS2S) (Luong et al., 2015) and Transformer (Vaswani et al., 2017) models. Belinkov et al. (2017a,b) have shown that the higher layers are better at learning semantics. We hypothesize that the hidden states in higher layers incorporate more relevant information for WSD than those in lower layers. In addition to encoders, we also probe how much do decoder hidden states contribute to the WSD classification task. Recently, the distributions of attention mechanisms have been used for interpreting NMT models (Ghader and Monz, 2017; Voita et al., 2018; Tang et al., 2018b; Voita et al., 2019; Tang et al., 2019). We further investigate the attention weights and attention entropy of self-attention in encoders to explore how self-attention incorporates relevant information for WSD into hidden states. As sentential information is helpful in disambiguating ambiguous words, we hypothesize that self1429 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 1429–1435, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computat"
D19-1149,P19-1580,1,0.860242,"tates from both RNNbased (RNNS2S) (Luong et al., 2015) and Transformer (Vaswani et al., 2017) models. Belinkov et al. (2017a,b) have shown that the higher layers are better at learning semantics. We hypothesize that the hidden states in higher layers incorporate more relevant information for WSD than those in lower layers. In addition to encoders, we also probe how much do decoder hidden states contribute to the WSD classification task. Recently, the distributions of attention mechanisms have been used for interpreting NMT models (Ghader and Monz, 2017; Voita et al., 2018; Tang et al., 2018b; Voita et al., 2019; Tang et al., 2019). We further investigate the attention weights and attention entropy of self-attention in encoders to explore how self-attention incorporates relevant information for WSD into hidden states. As sentential information is helpful in disambiguating ambiguous words, we hypothesize that self1429 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 1429–1435, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics Correct or Incorrect a"
D19-1149,W17-4717,0,\N,Missing
D19-1277,N19-1423,0,0.151023,"shown by McDonald and Nivre (2007, 2011). In recent years, dependency parsing, like most of NLP, has shifted from linear models and discrete features to neural networks and continuous representations. This has led to substantial accuracy improvements for both transition-based and graph-based parsers and raises the question whether their complementary strengths and weaknesses are still relevant. In this paper, we replicate the analysis of McDonald and Nivre (2007, 2011) for neural parsers. In addition, we investigate the impact of deep contextualized word representations (Peters et al., 2018; Devlin et al., 2019) for both types of parsers. Based on what we know about the strengths and weaknesses of the two approaches, we hypothesize that deep contextualized word representations will benefit transition-based parsing more than graph-based parsing. The reason is that these representations make information about global sentence structure available locally, thereby helping to prevent search errors in greedy transition-based parsing. The hypothesis is corroborated in experiments on 13 languages, and the error analysis supports our suggested explanation. We also find that deep contextualized word representat"
D19-1277,K17-3002,0,0.0284595,"vectors corresponding to the head and dependent are part of the input (2 words in total). The parser then extracts a maximum spanning tree over the score matrix using the ChuLiu-Edmonds (CLE) algorithm2 (Edmonds, 1967) which allows us to construct non-projective trees. It is important to note that, while we acknowledge the existence of graph-based parsers that outperform the implementation of Kiperwasser and Goldberg (2016), such models do not meet our criteria for systematic comparison. The parser 1 https://github.com/UppsalaNLP/ uuparser 2 We use the implementation from Qi et al. (2018). by Dozat et al. (2017) is very similar, but employs the MLP as a further step in the featurization process prior to scoring via a biaffine classifier. To keep the comparison as exact as possible, we forego comparing our transition-based systems to the Dozat et al. (2017) parser (and its numerous modifications). In addition, preliminary experiments showed that our chosen graph-based parser outperforms its transition-based counterpart, which was itself competitive in the CoNLL 2018 shared task (Zeman et al., 2018). 5.2 Input Representations In our experiments, we evaluate three pairs of systems – differing only in th"
D19-1277,P15-1033,0,0.0566768,"ser using global learning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see Figure 1). Neural networks for dependency parsing, first explored by Titov and Henderson (2007) and Attardi et al. (2009), have come to dominate the field during the last five years. While this has dramatically changed learning architectures and feature representations, most parsing models are still either transition-based (Chen and Manning, 2014; Dyer et al., 2015; Weiss et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016) or graph-based (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2017). However, more accurate feature learning using continuous representations and nonlinear models has allowed parsing architectures to be simplified. Thus, most recent transition-based parsers have moved back to local learning and greedy inference, seemingly without losing accurracy (Chen and Manning, 2014; Dyer et al., 2015; Kiperwasser and Goldberg, 2016). Similarly, graph-based parsers again rely on first-order models and obtain no improvements from"
D19-1277,C96-1058,0,0.31962,"ue if we consider languages other than English, ever since the influ2755 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2755–2768, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics ential CoNLL shared tasks on dependency parsing in 2006 (Buchholz and Marsi, 2006) and 2007 (Nivre et al., 2007) with data from 19 languages. The graph-based approach to dependency parsing was developed by McDonald et al. (2005a,b), building on earlier work by Eisner (1996). The idea is to score dependency trees by a linear combination of scores of local subgraphs, often single arcs, and to implement parsing as exact search for the highest scoring tree under a globally optimized model. These parsers do not suffer from search errors but parsing algorithms are more complex and restrict the scope of features to local subgraphs. The terms transition-based and graph-based were coined by McDonald and Nivre (2007, 2011), who performed a contrastive error analysis of the two top-performing systems in the CoNLL 2006 shared task on multilingual dependency parsing: MaltPar"
D19-1277,P19-1012,0,0.06634,"ally in the form of a BiLSTM, that provides contextualized representations of the input words as input to the scoring of transitions – in transition-based parsers – or of dependency arcs – in graph-based parsers. By making information about the global sentence context available in local word representations, this encoder can be assumed to mitigate error propagation for transition-based parsers and to widen the feature scope beyond individual word pairs for graph-based parsers. For both types of parsers, this also obviates the need for complex structural feature templates, as recently shown by Falenska and Kuhn (2019). We should therefore expect neural transition-based and graph-based parsers to be not only more accurate than their non-neural counterparts but also more similar to each other in their error profiles. 3 Deep Contextualized Word Representations Neural parsers rely on vector representations of words as their primary input, often in the form of pretrained word embeddings such as word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), or fastText (Bojanowski et al., 2016), which are sometimes extended with characterbased representations produced by recurrent neural networks (Ballesteros"
D19-1277,C12-1059,1,0.815023,"transition-based but the graph-based parser that is more accurate on short sentences and degrades faster. In other words, although the transition-based parser still seems to suffer from search errors, as shown by the results on dependency length and distance to the root, it no longer seems to suffer from error propagation in the sense that earlier errors make later errors more probable. The most likely explanation for this is the improved training for transition-based parsers using dynamic oracles and aggressive exploration to learn how to behave optimally also in non-optimal configurations (Goldberg and Nivre, 2012, 2013; Kiperwasser and Goldberg, 2016). Turning to the models with deep contextualized word representations, we find that transitionbased and graph-based parsers behave more similarly, which is in line with our hypotheses. However, the most noteworthy result is that accuracy improves with increasing sentence length. For ELMo this holds only from 1–10 to 11–20, but for BERT it holds up to 21–30, and even sentences of length 31–40 are parsed with higher accuracy than sentences of length 1–10. A closer look at the breakdown per language reveals that this picture is slightly distorted by differen"
D19-1277,Q13-1033,1,0.877926,"Missing"
D19-1277,L18-1550,0,0.0267843,"ems to the Dozat et al. (2017) parser (and its numerous modifications). In addition, preliminary experiments showed that our chosen graph-based parser outperforms its transition-based counterpart, which was itself competitive in the CoNLL 2018 shared task (Zeman et al., 2018). 5.2 Input Representations In our experiments, we evaluate three pairs of systems – differing only in their input representations. The first is a baseline that represents tokens by wk = xk ◦ B I L STM(c1:M ), as described in Section 5.1. The word embeddings xk are initialized via pretrained fastText vectors (xk ∈ R300 ) (Grave et al., 2018), which are updated for the parsing task. We term these transition-based and graphbased baselines TR and GR. For the ELMo experiments, we make use of pretrained models provided by Che et al. (2018), who train ELMo on 20 million words randomly sampled from raw WikiDump and Common Crawl datasets for 44 languages. We encode each goldsegmented sentence in our treebank via the ELMo model for that language, which yields a tensor SELMo = RN ×L×D , where N is the number of words in the sentence, L = 3 is the number of ELMo layers, and D = 1024 is the ELMo vector dimensionality. Following Peters et al."
D19-1277,N19-1419,0,0.0451915,"and global learning and exact search, which give graph-based parsers an advantage with respect to global sentence structure. At the same time, we expect the differences to be less pronounced than they were ten years ago because of the convergence in neural architectures and feature representations. But how will the addition of deep contextualized word representations affect the behavior of the two parsers? Given recent recent work showing that deep contextualized word representations incorporate rich information about syntactic structure (Goldberg, 2019; Liu et al., 2019; Tenney et al., 2019; Hewitt and Manning, 2019), we hypothesize that transition-based parsers have most to gain from these representations because it will improve their capacity to make decisions informed by global sentence structure and therefore reduce the number of search errors. Our main hypothesis can be stated as follows: Deep contextualized word representations are more effective at reducing errors in transitionbased parsing than in graph-based parsing. If this holds true, then the analysis of McDonald and Nivre (2007, 2011) suggests that the differential error reduction should be especially visible on phenomena such as: 2758 1. 2."
D19-1277,P10-1110,0,0.038362,"rops rapidly for arcs with increased orlengths. These ar (Goldberg Nivre, 2012, 2013); it maypropagation. T toacles build, and areand hence more prone to error mean using alternative search strategies, such as slower compared to MaltParser, demonstrating the effect of transition-based parsing with beam search (Joerror propagation. Another important factor is the use of rich hansson and Nugues, 2007; Titov and Henderis a likely reason for its precision to drop slower even than th son, 2007; Zhang and Clark, 2008) or exact search increases from 1 to 8. Interestingly, the precision of ZPar is a (Huang and Sagae, 2010; Kuhlmann et al., 2011) of MaltParser for size 1 arcs (arcs between neighbouring wor or graph-based parsing with heuristic search to ofcope features in ZPar is the of most helpful in arcs that take more with the complexity higher-order models, reduce actions to build. The recall curves of the three pars especially for non-projective parsing (McDonald and Pereira, 2006; Koo et al., 2010; Zhang and McDonald, 2012); or it may mean hybrid or en2756 1397 semble systems (Sagae and Lavie, 2006; Nivre and McDonald, 2008; Zhang and Clark, 2008; Bohnet and Kuhn, 2012). A nice illustration of the impact"
D19-1277,D07-1123,0,0.0956993,"Missing"
D19-1277,Q16-1023,0,0.659905,"learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see Figure 1). Neural networks for dependency parsing, first explored by Titov and Henderson (2007) and Attardi et al. (2009), have come to dominate the field during the last five years. While this has dramatically changed learning architectures and feature representations, most parsing models are still either transition-based (Chen and Manning, 2014; Dyer et al., 2015; Weiss et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016) or graph-based (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2017). However, more accurate feature learning using continuous representations and nonlinear models has allowed parsing architectures to be simplified. Thus, most recent transition-based parsers have moved back to local learning and greedy inference, seemingly without losing accurracy (Chen and Manning, 2014; Dyer et al., 2015; Kiperwasser and Goldberg, 2016). Similarly, graph-based parsers again rely on first-order models and obtain no improvements from using higher-order models (Kiperwasser and Goldberg, 2016; Dozat and Man"
D19-1277,D19-1279,0,0.139001,"abstraction, as captured by the model’s different layers, and are pre-trained on corpora much larger than typical treebanks. Deep contextualized embedding models have proven to be adept at a wide array of NLP tasks, achieving state-of-the-art performance in standard Natural Language Understanding (NLU) benchmarks, such as GLUE (Wang et al., 2019). Though many such models have been proposed, we adopt the two arguably most popular ones for our experiments: ELMo and BERT. Both models have previously been used for dependency parsing (Che et al., 2018; Jawahar et al., 2018; Lim et al., 2018; 2757 Kondratyuk, 2019; Schuster et al., 2019), but there has been no systematic analysis of their impact on transition-based and graph-based parsers. 3.1 ELMo ELMo is a deep contextualized embedding model proposed by Peters et al. (2018), which produces sentence-level representations yielded by a multi-layer BiLSTM language model. ELMo is trained with a standard language-modeling objective, in which a BiLSTM reads a sequence of N learned context-independent embeddings w1 , . . . , wN (obtained via a character-level CNN) and produces a context-dependent representation hj,k = BiLSTM(w1:N , k), where j (1 ≤ j ≤ L) is"
D19-1277,P10-1001,0,0.0446255,"ansition-based and exponentially graph-based parsers decreases less quickly as strengths. the size of This the sentence increases, without sacrificing their may exact inference. Sentences with 50+ words are relatively rar mean evolving the model structure through new transition systems show (Nivre,larger 2008,variance 2009; Kuhlmann The three parsers in performance when et al., 2011) or higher-order models for graphties of the dependency tree. Figure 3 shows the precision and based parsing (McDonald and Pereira, 2006; Carthe arc lengths in the predicted and gold-standard dependen reras, 2007; Koo and Collins, 2010); it may mean is defined as the absolute difference between the indices of exploring alternative learning strategies, in particrepresents the percentage of predicted arcs with a particular ular for transition-based parsing, where improverepresents the percentage of gold arcs of a particular length ments have been achieved thanks to global structure learning (Zhang and precision Clark, 2008; Zhang and MaltParser gives higher than MSTParser for short d Nivre, 2011; Andor et al., 2016) and dynamic cision drops rapidly for arcs with increased orlengths. These ar (Goldberg Nivre, 2012, 2013); it ma"
D19-1277,D10-1125,0,0.0485791,"s, 2007; Titov and Henderis a likely reason for its precision to drop slower even than th son, 2007; Zhang and Clark, 2008) or exact search increases from 1 to 8. Interestingly, the precision of ZPar is a (Huang and Sagae, 2010; Kuhlmann et al., 2011) of MaltParser for size 1 arcs (arcs between neighbouring wor or graph-based parsing with heuristic search to ofcope features in ZPar is the of most helpful in arcs that take more with the complexity higher-order models, reduce actions to build. The recall curves of the three pars especially for non-projective parsing (McDonald and Pereira, 2006; Koo et al., 2010; Zhang and McDonald, 2012); or it may mean hybrid or en2756 1397 semble systems (Sagae and Lavie, 2006; Nivre and McDonald, 2008; Zhang and Clark, 2008; Bohnet and Kuhn, 2012). A nice illustration of the impact of new techniques can be found in Zhang and Nivre (2012), where an error analysis along the lines of McDonald and Nivre (2007, 2011) shows that a transition-based parser using global learning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers"
D19-1277,P11-1068,0,0.0662001,"Missing"
D19-1277,K17-3022,1,0.885339,"Missing"
D19-1277,W17-6314,1,0.90162,"Missing"
D19-1277,K18-2014,0,0.0150781,"over several layers of abstraction, as captured by the model’s different layers, and are pre-trained on corpora much larger than typical treebanks. Deep contextualized embedding models have proven to be adept at a wide array of NLP tasks, achieving state-of-the-art performance in standard Natural Language Understanding (NLU) benchmarks, such as GLUE (Wang et al., 2019). Though many such models have been proposed, we adopt the two arguably most popular ones for our experiments: ELMo and BERT. Both models have previously been used for dependency parsing (Che et al., 2018; Jawahar et al., 2018; Lim et al., 2018; 2757 Kondratyuk, 2019; Schuster et al., 2019), but there has been no systematic analysis of their impact on transition-based and graph-based parsers. 3.1 ELMo ELMo is a deep contextualized embedding model proposed by Peters et al. (2018), which produces sentence-level representations yielded by a multi-layer BiLSTM language model. ELMo is trained with a standard language-modeling objective, in which a BiLSTM reads a sequence of N learned context-independent embeddings w1 , . . . , wN (obtained via a character-level CNN) and produces a context-dependent representation hj,k = BiLSTM(w1:N , k),"
D19-1277,N19-1112,0,0.0174624,"sers to make accurate local decisions, and global learning and exact search, which give graph-based parsers an advantage with respect to global sentence structure. At the same time, we expect the differences to be less pronounced than they were ten years ago because of the convergence in neural architectures and feature representations. But how will the addition of deep contextualized word representations affect the behavior of the two parsers? Given recent recent work showing that deep contextualized word representations incorporate rich information about syntactic structure (Goldberg, 2019; Liu et al., 2019; Tenney et al., 2019; Hewitt and Manning, 2019), we hypothesize that transition-based parsers have most to gain from these representations because it will improve their capacity to make decisions informed by global sentence structure and therefore reduce the number of search errors. Our main hypothesis can be stated as follows: Deep contextualized word representations are more effective at reducing errors in transitionbased parsing than in graph-based parsing. If this holds true, then the analysis of McDonald and Nivre (2007, 2011) suggests that the differential error reduction should be espe"
D19-1277,P05-1012,0,0.123152,"am during the last fifteen years. This is especially true if we consider languages other than English, ever since the influ2755 Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, pages 2755–2768, c Hong Kong, China, November 3–7, 2019. 2019 Association for Computational Linguistics ential CoNLL shared tasks on dependency parsing in 2006 (Buchholz and Marsi, 2006) and 2007 (Nivre et al., 2007) with data from 19 languages. The graph-based approach to dependency parsing was developed by McDonald et al. (2005a,b), building on earlier work by Eisner (1996). The idea is to score dependency trees by a linear combination of scores of local subgraphs, often single arcs, and to implement parsing as exact search for the highest scoring tree under a globally optimized model. These parsers do not suffer from search errors but parsing algorithms are more complex and restrict the scope of features to local subgraphs. The terms transition-based and graph-based were coined by McDonald and Nivre (2007, 2011), who performed a contrastive error analysis of the two top-performing systems in the CoNLL 2006 shared t"
D19-1277,W06-2932,0,0.0724207,"by a linear combination of scores of local subgraphs, often single arcs, and to implement parsing as exact search for the highest scoring tree under a globally optimized model. These parsers do not suffer from search errors but parsing algorithms are more complex and restrict the scope of features to local subgraphs. The terms transition-based and graph-based were coined by McDonald and Nivre (2007, 2011), who performed a contrastive error analysis of the two top-performing systems in the CoNLL 2006 shared task on multilingual dependency parsing: MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2006), which represented the state of the art in transition-based and graph-based parsing, respectively, at the time. Their analysis shows that, despite having almost exactly the same parsing accuracy when averaged over 13 languages, the two parsers have very distinctive error profiles. MaltParser is more accurate on short sentences, on short dependencies, on dependencies near the leaves of the tree, on nouns and prounouns, and on subject and object relations. MSTParser is more accurate on long sentences, on long dependencies, on dependencies near the root of the tree, on verbs, and on coordination"
D19-1277,D07-1013,1,0.137562,"on-based parsers more than graph-based parsers, making the two approaches virtually equivalent in terms of both accuracy and error profile. We argue that the reason is that these representations help prevent search errors and thereby allow transitionbased parsers to better exploit their inherent strength of making accurate local decisions. We support this explanation by an error analysis of parsing experiments on 13 languages. 1 Introduction For more than a decade, research on data-driven dependency parsing has been dominated by two approaches: transition-based parsing and graphbased parsing (McDonald and Nivre, 2007, 2011). Transition-based parsing reduces the parsing task to scoring single parse actions and is often combined with local optimization and greedy search algorithms. Graph-based parsing decomposes parse trees into subgraphs and relies on global optimization and exhaustive (or at least non-greedy) ∗ We gratefully acknowledge the inspiration for our subtitle in the seminal paper by Zhang and Clark (2008). search to find the best tree. These radically different approaches often lead to comparable parsing accuracy, but with distinct error profiles indicative of their respective strengths and weak"
D19-1277,E06-1011,0,0.716649,"t as attempts to mitigate the weaknesses of trapossible trees grows with sentence size ditional parse transition-based and exponentially graph-based parsers decreases less quickly as strengths. the size of This the sentence increases, without sacrificing their may exact inference. Sentences with 50+ words are relatively rar mean evolving the model structure through new transition systems show (Nivre,larger 2008,variance 2009; Kuhlmann The three parsers in performance when et al., 2011) or higher-order models for graphties of the dependency tree. Figure 3 shows the precision and based parsing (McDonald and Pereira, 2006; Carthe arc lengths in the predicted and gold-standard dependen reras, 2007; Koo and Collins, 2010); it may mean is defined as the absolute difference between the indices of exploring alternative learning strategies, in particrepresents the percentage of predicted arcs with a particular ular for transition-based parsing, where improverepresents the percentage of gold arcs of a particular length ments have been achieved thanks to global structure learning (Zhang and precision Clark, 2008; Zhang and MaltParser gives higher than MSTParser for short d Nivre, 2011; Andor et al., 2016) and dynamic"
D19-1277,H05-1066,0,0.624312,"Missing"
D19-1277,W03-3017,1,0.669466,"ths and weaknesses of the systems. The 0.8 Dependency recall Dependency precision 0.9 MSTParser MaltParser ZPar 0.7 0.6 0.5 0.8 0.7 0.6 0.5 0 2 4 6 8 10 12 14 2 Dependency length Figure 1: 3: Labeled precision by length forrelative to pred Figure Dependency arcdependency precision/recall MST (global–exhaustive–graph), Malt (local–greedy– transition) and ZPar (global–beam–transition). From Zhang and Nivre (2012). 0.94 0.9 MSTParser MaltParser ZPar 0.9 Dependency recall 0.92 Dependency precision The transition-based approach to dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre (2003), with inspiration from history-based parsing (Black et al., 1992) and data-driven shift-reduce parsing (Veenstra and Daelemans, 2000). The idea is to reduce the complex parsing task to the simpler task of predicting the next parsing action and to implement parsing as greedy search for the optimal sequence of actions, guided by a simple classifier trained on local parser configurations. This produces parsers that are very efficient, often with linear time complexity, and which can benefit from rich non-local features defined over parser configurations but which may suffer from compounding sear"
D19-1277,J08-4003,1,0.889318,"Missing"
D19-1277,P09-1040,1,0.73304,"tor wk = xk ◦ B I L STM(c1:M ) representing input word wk is the concatenation of a pretrained word embedding xk and a character-based embedding B I L STM(c1:M ) obtained by running a BiLSTM over the character sequence c1:M of wk . Finally, each input element is represented by a BiLSTM vector, hk = B I L STM(w1:N , k). In transition-based parsing, the BiLSTM vectors are input to a multi-layer perceptron (MLP) for scoring transitions, using the arc-hybrid transition system from Kuhlmann et al. (2011) extended with a S WAP transition to allow the construction of non-projective dependency trees (Nivre, 2009; de Lhoneux et al., 2017b). The scoring is based on the top three words on the stack and the first word of the buffer, and the input to the MLP includes the BiLSTM vectors for these words as well as their leftmost and rightmost dependents (up to 12 words in total). In graph-based parsing, the BiLSTM vectors are input to an MLP for scoring all possible dependency relations under an arc-factored model, meaning that only the vectors corresponding to the head and dependent are part of the input (2 words in total). The parser then extracts a maximum spanning tree over the score matrix using the Ch"
D19-1277,W06-2933,1,0.665942,"Missing"
D19-1277,P08-1108,1,0.698764,"8) or exact search increases from 1 to 8. Interestingly, the precision of ZPar is a (Huang and Sagae, 2010; Kuhlmann et al., 2011) of MaltParser for size 1 arcs (arcs between neighbouring wor or graph-based parsing with heuristic search to ofcope features in ZPar is the of most helpful in arcs that take more with the complexity higher-order models, reduce actions to build. The recall curves of the three pars especially for non-projective parsing (McDonald and Pereira, 2006; Koo et al., 2010; Zhang and McDonald, 2012); or it may mean hybrid or en2756 1397 semble systems (Sagae and Lavie, 2006; Nivre and McDonald, 2008; Zhang and Clark, 2008; Bohnet and Kuhn, 2012). A nice illustration of the impact of new techniques can be found in Zhang and Nivre (2012), where an error analysis along the lines of McDonald and Nivre (2007, 2011) shows that a transition-based parser using global learning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see Figure 1). Neural networks for dependency parsing, first explored by Titov and Henderson (2007) and A"
D19-1277,P05-1013,1,0.607233,"the swap transition, but real non-projective dependencies are more likely to be found by the graphbased parser using a spanning tree algorithm. Interestingly, adding deep contextualized word representations has almost no effect on the graphbased parser,10 while especially the ELMo em8 At the very end, the curves appear to diverge again, but the data is very sparse in this part of the plot. 9 Incidentally, the same pattern is reported by McDonald and Nivre (2007, 2011), even though the techniques for processing non-projective dependencies are different in that study: pseudo-projective parsing (Nivre and Nilsson, 2005) for the transition-based parser and approximate second-order non-projective parsing (McDonald and Pereira, 2006) for the graph-based parser. 10 The breakdown per language shows marginal improvements for the enhanced graph-based models on a few lanbeddings improve both precision and recall for the transition-based parser. 6.4 Parts of Speech and Dependency Types Thanks to the cross-linguistically consistent UD annotations, we can relate errors to linguistic categories more systematically than in the old study. The main impression, however, is that there are very few clear differences, which is"
D19-1277,D14-1162,0,0.096618,"l word pairs for graph-based parsers. For both types of parsers, this also obviates the need for complex structural feature templates, as recently shown by Falenska and Kuhn (2019). We should therefore expect neural transition-based and graph-based parsers to be not only more accurate than their non-neural counterparts but also more similar to each other in their error profiles. 3 Deep Contextualized Word Representations Neural parsers rely on vector representations of words as their primary input, often in the form of pretrained word embeddings such as word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), or fastText (Bojanowski et al., 2016), which are sometimes extended with characterbased representations produced by recurrent neural networks (Ballesteros et al., 2015). These techniques assign a single static representation to each word type and therefore cannot capture contextdependent variation in meaning and syntactic behavior. By contrast, deep contextualized word representations encode words with respect to the sentential context in which they appear. Like word embeddings, such models are typically trained with a language-modeling objective, but yield sentence-level tensors as represen"
D19-1277,N18-1202,0,0.788146,"hs and weaknesses, as shown by McDonald and Nivre (2007, 2011). In recent years, dependency parsing, like most of NLP, has shifted from linear models and discrete features to neural networks and continuous representations. This has led to substantial accuracy improvements for both transition-based and graph-based parsers and raises the question whether their complementary strengths and weaknesses are still relevant. In this paper, we replicate the analysis of McDonald and Nivre (2007, 2011) for neural parsers. In addition, we investigate the impact of deep contextualized word representations (Peters et al., 2018; Devlin et al., 2019) for both types of parsers. Based on what we know about the strengths and weaknesses of the two approaches, we hypothesize that deep contextualized word representations will benefit transition-based parsing more than graph-based parsing. The reason is that these representations make information about global sentence structure available locally, thereby helping to prevent search errors in greedy transition-based parsing. The hypothesis is corroborated in experiments on 13 languages, and the error analysis supports our suggested explanation. We also find that deep contextua"
D19-1277,K18-2016,0,0.0438521,"eaning that only the vectors corresponding to the head and dependent are part of the input (2 words in total). The parser then extracts a maximum spanning tree over the score matrix using the ChuLiu-Edmonds (CLE) algorithm2 (Edmonds, 1967) which allows us to construct non-projective trees. It is important to note that, while we acknowledge the existence of graph-based parsers that outperform the implementation of Kiperwasser and Goldberg (2016), such models do not meet our criteria for systematic comparison. The parser 1 https://github.com/UppsalaNLP/ uuparser 2 We use the implementation from Qi et al. (2018). by Dozat et al. (2017) is very similar, but employs the MLP as a further step in the featurization process prior to scoring via a biaffine classifier. To keep the comparison as exact as possible, we forego comparing our transition-based systems to the Dozat et al. (2017) parser (and its numerous modifications). In addition, preliminary experiments showed that our chosen graph-based parser outperforms its transition-based counterpart, which was itself competitive in the CoNLL 2018 shared task (Zeman et al., 2018). 5.2 Input Representations In our experiments, we evaluate three pairs of system"
D19-1277,N06-2033,0,0.061055,"7; Zhang and Clark, 2008) or exact search increases from 1 to 8. Interestingly, the precision of ZPar is a (Huang and Sagae, 2010; Kuhlmann et al., 2011) of MaltParser for size 1 arcs (arcs between neighbouring wor or graph-based parsing with heuristic search to ofcope features in ZPar is the of most helpful in arcs that take more with the complexity higher-order models, reduce actions to build. The recall curves of the three pars especially for non-projective parsing (McDonald and Pereira, 2006; Koo et al., 2010; Zhang and McDonald, 2012); or it may mean hybrid or en2756 1397 semble systems (Sagae and Lavie, 2006; Nivre and McDonald, 2008; Zhang and Clark, 2008; Bohnet and Kuhn, 2012). A nice illustration of the impact of new techniques can be found in Zhang and Nivre (2012), where an error analysis along the lines of McDonald and Nivre (2007, 2011) shows that a transition-based parser using global learning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see Figure 1). Neural networks for dependency parsing, first explored by Titov"
D19-1277,N19-1162,0,0.0206572,"aptured by the model’s different layers, and are pre-trained on corpora much larger than typical treebanks. Deep contextualized embedding models have proven to be adept at a wide array of NLP tasks, achieving state-of-the-art performance in standard Natural Language Understanding (NLU) benchmarks, such as GLUE (Wang et al., 2019). Though many such models have been proposed, we adopt the two arguably most popular ones for our experiments: ELMo and BERT. Both models have previously been used for dependency parsing (Che et al., 2018; Jawahar et al., 2018; Lim et al., 2018; 2757 Kondratyuk, 2019; Schuster et al., 2019), but there has been no systematic analysis of their impact on transition-based and graph-based parsers. 3.1 ELMo ELMo is a deep contextualized embedding model proposed by Peters et al. (2018), which produces sentence-level representations yielded by a multi-layer BiLSTM language model. ELMo is trained with a standard language-modeling objective, in which a BiLSTM reads a sequence of N learned context-independent embeddings w1 , . . . , wN (obtained via a character-level CNN) and produces a context-dependent representation hj,k = BiLSTM(w1:N , k), where j (1 ≤ j ≤ L) is the BiLSTM layer and k"
D19-1277,K18-2011,1,0.902732,"Missing"
D19-1277,D18-1291,1,0.915118,"Missing"
D19-1277,W07-2218,0,0.0409198,", 2006; Nivre and McDonald, 2008; Zhang and Clark, 2008; Bohnet and Kuhn, 2012). A nice illustration of the impact of new techniques can be found in Zhang and Nivre (2012), where an error analysis along the lines of McDonald and Nivre (2007, 2011) shows that a transition-based parser using global learning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see Figure 1). Neural networks for dependency parsing, first explored by Titov and Henderson (2007) and Attardi et al. (2009), have come to dominate the field during the last five years. While this has dramatically changed learning architectures and feature representations, most parsing models are still either transition-based (Chen and Manning, 2014; Dyer et al., 2015; Weiss et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016) or graph-based (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2017). However, more accurate feature learning using continuous representations and nonlinear models has allowed parsing architectures to be simplified. Thus, most recent transition-based"
D19-1277,D18-1503,0,0.0444129,"Missing"
D19-1277,P15-1032,0,0.0216261,"arning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see Figure 1). Neural networks for dependency parsing, first explored by Titov and Henderson (2007) and Attardi et al. (2009), have come to dominate the field during the last five years. While this has dramatically changed learning architectures and feature representations, most parsing models are still either transition-based (Chen and Manning, 2014; Dyer et al., 2015; Weiss et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016) or graph-based (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2017). However, more accurate feature learning using continuous representations and nonlinear models has allowed parsing architectures to be simplified. Thus, most recent transition-based parsers have moved back to local learning and greedy inference, seemingly without losing accurracy (Chen and Manning, 2014; Dyer et al., 2015; Kiperwasser and Goldberg, 2016). Similarly, graph-based parsers again rely on first-order models and obtain no improvements from using higher-order"
D19-1277,1983.tc-1.13,0,0.645557,"Missing"
D19-1277,W03-3023,0,0.3101,"ined by the complementary strengths and weaknesses of the systems. The 0.8 Dependency recall Dependency precision 0.9 MSTParser MaltParser ZPar 0.7 0.6 0.5 0.8 0.7 0.6 0.5 0 2 4 6 8 10 12 14 2 Dependency length Figure 1: 3: Labeled precision by length forrelative to pred Figure Dependency arcdependency precision/recall MST (global–exhaustive–graph), Malt (local–greedy– transition) and ZPar (global–beam–transition). From Zhang and Nivre (2012). 0.94 0.9 MSTParser MaltParser ZPar 0.9 Dependency recall 0.92 Dependency precision The transition-based approach to dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre (2003), with inspiration from history-based parsing (Black et al., 1992) and data-driven shift-reduce parsing (Veenstra and Daelemans, 2000). The idea is to reduce the complex parsing task to the simpler task of predicting the next parsing action and to implement parsing as greedy search for the optimal sequence of actions, guided by a simple classifier trained on local parser configurations. This produces parsers that are very efficient, often with linear time complexity, and which can benefit from rich non-local features defined over parser configurations but which may suffer from"
D19-1277,K18-2001,1,0.888719,"Missing"
D19-1277,D12-1030,0,0.0212426,"Henderis a likely reason for its precision to drop slower even than th son, 2007; Zhang and Clark, 2008) or exact search increases from 1 to 8. Interestingly, the precision of ZPar is a (Huang and Sagae, 2010; Kuhlmann et al., 2011) of MaltParser for size 1 arcs (arcs between neighbouring wor or graph-based parsing with heuristic search to ofcope features in ZPar is the of most helpful in arcs that take more with the complexity higher-order models, reduce actions to build. The recall curves of the three pars especially for non-projective parsing (McDonald and Pereira, 2006; Koo et al., 2010; Zhang and McDonald, 2012); or it may mean hybrid or en2756 1397 semble systems (Sagae and Lavie, 2006; Nivre and McDonald, 2008; Zhang and Clark, 2008; Bohnet and Kuhn, 2012). A nice illustration of the impact of new techniques can be found in Zhang and Nivre (2012), where an error analysis along the lines of McDonald and Nivre (2007, 2011) shows that a transition-based parser using global learning and beam search (instead of local learning and greedy search) performs on par with graph-based parsers for long dependencies, while retaining the advantage of the original transition-based parsers on short dependencies (see"
D19-1277,D08-1059,0,0.266905,"ments on 13 languages. 1 Introduction For more than a decade, research on data-driven dependency parsing has been dominated by two approaches: transition-based parsing and graphbased parsing (McDonald and Nivre, 2007, 2011). Transition-based parsing reduces the parsing task to scoring single parse actions and is often combined with local optimization and greedy search algorithms. Graph-based parsing decomposes parse trees into subgraphs and relies on global optimization and exhaustive (or at least non-greedy) ∗ We gratefully acknowledge the inspiration for our subtitle in the seminal paper by Zhang and Clark (2008). search to find the best tree. These radically different approaches often lead to comparable parsing accuracy, but with distinct error profiles indicative of their respective strengths and weaknesses, as shown by McDonald and Nivre (2007, 2011). In recent years, dependency parsing, like most of NLP, has shifted from linear models and discrete features to neural networks and continuous representations. This has led to substantial accuracy improvements for both transition-based and graph-based parsers and raises the question whether their complementary strengths and weaknesses are still relevan"
D19-1277,P11-2033,1,0.853513,"Missing"
D19-1277,C12-2136,1,0.864886,"Missing"
D19-1277,E12-1009,0,\N,Missing
D19-1277,D15-1041,0,\N,Missing
D19-1277,W06-2920,0,\N,Missing
D19-1277,H92-1026,0,\N,Missing
D19-1277,J11-1007,1,\N,Missing
D19-1277,D14-1082,0,\N,Missing
D19-1277,D07-1096,1,\N,Missing
D19-1277,K18-2023,0,\N,Missing
D19-1277,D07-1101,0,\N,Missing
de-marneffe-etal-2014-universal,de-marneffe-etal-2006-generating,1,\N,Missing
de-marneffe-etal-2014-universal,W09-2307,1,\N,Missing
de-marneffe-etal-2014-universal,J03-4003,0,\N,Missing
de-marneffe-etal-2014-universal,W08-1301,1,\N,Missing
de-marneffe-etal-2014-universal,P03-1054,1,\N,Missing
de-marneffe-etal-2014-universal,P06-1033,1,\N,Missing
de-marneffe-etal-2014-universal,W13-3721,1,\N,Missing
de-marneffe-etal-2014-universal,P08-1109,1,\N,Missing
de-marneffe-etal-2014-universal,P06-1055,0,\N,Missing
de-marneffe-etal-2014-universal,C12-1147,0,\N,Missing
de-marneffe-etal-2014-universal,petrov-etal-2012-universal,0,\N,Missing
de-marneffe-etal-2014-universal,J05-1004,0,\N,Missing
de-marneffe-etal-2014-universal,P05-1013,1,\N,Missing
de-marneffe-etal-2014-universal,N13-1070,0,\N,Missing
de-marneffe-etal-2014-universal,W13-2308,0,\N,Missing
de-marneffe-etal-2014-universal,P13-2103,0,\N,Missing
de-marneffe-etal-2014-universal,P13-2017,1,\N,Missing
E06-1010,P04-1041,0,0.0145598,"Missing"
E06-1010,P04-1042,0,0.0291483,"Missing"
E06-1010,P90-1005,0,0.0848516,"Missing"
E06-1010,P04-1082,0,0.013042,"here it is more common to use a direct encoding of so-called nonprojective dependencies. While this “surface dependency approximation” (Levy and Manning, 2004) may be acceptable for certain applications of syntactic parsing, it is clearly not adequate as a basis for deep semantic interpretation, which explains the growing body of research devoted to different methods for correcting this approximation. Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees (Johnson, 2002; Jijkoun and De Rijke, 2004; Levy and Manning, 2004; Campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al., 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005). By contrast, there is very little work on parsing methods that allow discontinuous constructions to be represented directly in the syntactic structure, whether by discontinuous constituent structures or by non-projective dependency structures. Notable exceptions are Plaehn (2000), where discontinuous phrase structure grammar"
E06-1010,P05-1012,0,0.0812041,"ocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al., 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005). By contrast, there is very little work on parsing methods that allow discontinuous constructions to be represented directly in the syntactic structure, whether by discontinuous constituent structures or by non-projective dependency structures. Notable exceptions are Plaehn (2000), where discontinuous phrase structure grammar parsing is explored, and McDonald et al. (2005b), where nonprojective dependency structures are derived using spanning tree algorithms from graph theory. One question that arises if we want to pursue the structure-based approach is how to constrain the class of permissible structures. On the one hand, we want to capture all the constructions that are found in natural languages, or at least to provide a much better approximation than before. On the other hand, it must still be possible for the parser not only to search the space of permissible structures in an efficient way but also to learn to select the most appropriate structure for a g"
E06-1010,P99-1065,0,0.135095,"Missing"
E06-1010,H05-1066,0,0.235396,"Missing"
E06-1010,P03-1055,0,0.0252944,"ation” (Levy and Manning, 2004) may be acceptable for certain applications of syntactic parsing, it is clearly not adequate as a basis for deep semantic interpretation, which explains the growing body of research devoted to different methods for correcting this approximation. Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees (Johnson, 2002; Jijkoun and De Rijke, 2004; Levy and Manning, 2004; Campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al., 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005). By contrast, there is very little work on parsing methods that allow discontinuous constructions to be represented directly in the syntactic structure, whether by discontinuous constituent structures or by non-projective dependency structures. Notable exceptions are Plaehn (2000), where discontinuous phrase structure grammar parsing is explored, and McDonald et al. (2005b), where nonprojective dependency structures are derived using spanning tree algorithms"
E06-1010,P97-1043,0,0.614729,"Missing"
E06-1010,P05-1013,1,0.699509,"for deep semantic interpretation, which explains the growing body of research devoted to different methods for correcting this approximation. Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees (Johnson, 2002; Jijkoun and De Rijke, 2004; Levy and Manning, 2004; Campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al., 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005). By contrast, there is very little work on parsing methods that allow discontinuous constructions to be represented directly in the syntactic structure, whether by discontinuous constituent structures or by non-projective dependency structures. Notable exceptions are Plaehn (2000), where discontinuous phrase structure grammar parsing is explored, and McDonald et al. (2005b), where nonprojective dependency structures are derived using spanning tree algorithms from graph theory. One question that arises if we want to pursue the structure-based approach is how to constrain the class of permissib"
E06-1010,W04-2407,1,0.856649,"at can define arbitrary non-projective structures is N P complete, but there are no results for systems of intermediate complexity. The pseudo-projective grammar proposed by Kahane et al. (1998) can be parsed in polynomial time and captures non-local dependencies through a form of gap-threading, but the structures generated by the grammar are strictly projective. Moreover, the study of formal grammars is only partially relevant for research on datadriven dependency parsing, where most systems are not grammar-based but rely on inductive inference from treebank data (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a). For example, despite the results of Neuhaus and Br¨oker (1997), McDonald et al. (2005b) perform parsing with arbitrary non-projective dependency structures in O(n2 ) time. In this paper, we will therefore approach the problem from a slightly different angle. Instead of investigating formal dependency grammars and their complexity, we will impose a series of graphtheoretic constraints on dependency structures and see how these constraints affect expressivity and parsing efficiency. The approach is mainly experimental and we evaluate constraints using data from two dep"
E06-1010,2000.iwpt-1.20,0,0.0485959,"and De Rijke, 2004; Levy and Manning, 2004; Campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al., 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005). By contrast, there is very little work on parsing methods that allow discontinuous constructions to be represented directly in the syntactic structure, whether by discontinuous constituent structures or by non-projective dependency structures. Notable exceptions are Plaehn (2000), where discontinuous phrase structure grammar parsing is explored, and McDonald et al. (2005b), where nonprojective dependency structures are derived using spanning tree algorithms from graph theory. One question that arises if we want to pursue the structure-based approach is how to constrain the class of permissible structures. On the one hand, we want to capture all the constructions that are found in natural languages, or at least to provide a much better approximation than before. On the other hand, it must still be possible for the parser not only to search the space of permissible stru"
E06-1010,W03-3023,0,0.0422245,"for a dependency grammar that can define arbitrary non-projective structures is N P complete, but there are no results for systems of intermediate complexity. The pseudo-projective grammar proposed by Kahane et al. (1998) can be parsed in polynomial time and captures non-local dependencies through a form of gap-threading, but the structures generated by the grammar are strictly projective. Moreover, the study of formal grammars is only partially relevant for research on datadriven dependency parsing, where most systems are not grammar-based but rely on inductive inference from treebank data (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a). For example, despite the results of Neuhaus and Br¨oker (1997), McDonald et al. (2005b) perform parsing with arbitrary non-projective dependency structures in O(n2 ) time. In this paper, we will therefore approach the problem from a slightly different angle. Instead of investigating formal dependency grammars and their complexity, we will impose a series of graphtheoretic constraints on dependency structures and see how these constraints affect expressivity and parsing efficiency. The approach is mainly experimental and we evaluate constraints usi"
E06-1010,P04-1040,0,0.0626316,"Missing"
E06-1010,P02-1018,0,0.0298686,"to avoid explicitly discontinuous constituents, or on dependency, where it is more common to use a direct encoding of so-called nonprojective dependencies. While this “surface dependency approximation” (Levy and Manning, 2004) may be acceptable for certain applications of syntactic parsing, it is clearly not adequate as a basis for deep semantic interpretation, which explains the growing body of research devoted to different methods for correcting this approximation. Most of this work has so far focused either on post-processing to recover non-local dependencies from context-free parse trees (Johnson, 2002; Jijkoun and De Rijke, 2004; Levy and Manning, 2004; Campbell, 2004), or on incorporating nonlocal dependency information in nonterminal categories in constituency representations (Dienes and Dubey, 2003; Hockenmaier, 2003; Cahill et al., 2004) or in the categories used to label arcs in dependency representations (Nivre and Nilsson, 2005). By contrast, there is very little work on parsing methods that allow discontinuous constructions to be represented directly in the syntactic structure, whether by discontinuous constituent structures or by non-projective dependency structures. Notable excep"
E06-1010,P98-1106,0,\N,Missing
E06-1010,C98-1102,0,\N,Missing
E12-1006,J93-2004,0,0.058587,"ute the argument structure of natural language sentences. The argument structure encompasses grammatical relationships between elements such as subject, predicate, object, etc., which are useful for further (e.g., semantic) processing. The parses yielded by different parsing frameworks typically obey different formal and theoretical assumptions concerning how to represent the grammatical relationships in the data (Rambow, 2010). For example, grammatical relations may be encoded on top of dependency arcs in a dependency tree (Mel’ˇcuk, 1988), they may decorate nodes in a phrase-structure tree (Marcus et al., 1993; Maamouri et al., 2004; Sima’an et al., 2001), or they may be read off of positions in A popular way to address this has been to pick one of the frameworks and convert all parser outputs to its formal type. When comparing constituency-based and dependency-based parsers, for instance, the output of constituency parsers has often been converted to dependency structures prior to evaluation (Cer et al., 2010; Nivre et al., 2010). This solution has various drawbacks. First, it demands a conversion script that maps one representation type to another when some theoretical assumptions in one framewor"
E12-1006,H05-1066,0,0.266722,"Missing"
E12-1006,W09-4636,0,0.0191592,": 0.9239 L: 0.7946 MF Trees Dep Trees STB ut Dep Dep T ED E VAL T ED E VAL M ULTIPLE S INGLE U: 0.9266 U: 0.9264 L: 0.8225 L: 0.8372 U: 0.9275 U: 0.9272 L: 0.8121 L: 0.8275 U: 0.9281 N/A L: 0.7861 Table 4: Swedish cross-framework evaluation: T ED EVAL scores against the native gold and the generalized gold. Boldface scores are the highest in their column. Table 2: English cross-framework evaluation: T ED EVAL scores against gold and generalized gold. Boldface scores are highest in their column. Italic scores are highest for dependency parsers in their column. parsers, using the HunPoS tagger (Megyesi, 2009), but let the Berkeley parser predict its own tags. We use the same evaluation metrics and procedures as before. Prior to evaluating RR trees using ParsEval we strip off the added function nodes. Prior to evaluating them using TedEval we strip off the phrase-structure nodes. Tables 3 and 4 summarize the parsing results for the different Swedish parsers. In the leftmost column of table 3 we present the constituencybased evaluation measures. Interestingly, the Berkeley RR instantiation performs better than when training the Berkeley parser on PS trees. These constituency-based scores however hav"
E12-1006,H05-1078,0,0.0254613,"ground for the different representation types, (ii) computing the theoretical common ground for each test sentence, and (iii) counting only what counts, that is, measuring the distance between the common ground and the parse tree while discarding annotation-specific edits. A pre-condition for applying our protocol is the availability of a relational interpretation of trees in the different frameworks. For dependency frameworks this is straightforward, as these relations are encoded on top of dependency arcs. For constituency trees with an inherent mapping of nodes onto grammatical relations (Merlo and Musillo, 2005; Gabbard et al., 2006; Tsarfaty and Sima’an, 2008), a procedure for reading relational schemes off of the trees is trivial to implement. For parsers that are trained on and parse into bare-bones phrase-structure trees this is not so. Reading off the relational structure may be more costly and require interjection of additional theoretical assumptions via manually written scripts. Scripts that read off grammatical relations based on tree positions work well for configurational 6 Conclusion We developed a protocol for comparing parsing results across different theories and representation types"
E12-1006,P81-1022,0,0.779636,"Missing"
E12-1006,C10-1094,1,0.906234,"Missing"
E12-1006,P06-1055,0,0.021181,"t set representing sets of constraints on which the different gold theories agree. 2 48 The ordering can be alphabetic, thematic, etc. We can now define δ for the ith framework, as the error of parsei relative to its native gold standard goldi and to the generalized gold gen. This is the edit cost minus the cost of the script turning parsei into gen intersected with the script turning goldi into gen. The underlying intuition is that if an operation that was used to turn parsei into gen is used to discard theory-specific information from goldi , its cost should not be counted as error. parser (Petrov et al., 2006) and the Brown parser (Charniak and Johnson, 2005). All experiments use Penn Treebank (PTB) data. For Swedish, we compare MaltParser and MSTParser with two variants of the Berkeley parser, one trained on phrase structure trees, and one trained on a variant of the Relational-Realizational representation of Tsarfaty and Sima’an (2008). All experiments use the Talbanken Swedish Treebank (STB) data. δ(parsei , goldi , gen) = cost(ES ∗ (parsei , gen)) 4.1 We use sections 02–21 of the WSJ Penn Treebank for training and section 00 for evaluation and analysis. We use two different native gold standard"
E12-1006,N10-1049,0,0.143845,"o make sure that we are not comparing apples and oranges? Introduction The goal of statistical parsers is to recover a formal representation of the grammatical relations that constitute the argument structure of natural language sentences. The argument structure encompasses grammatical relationships between elements such as subject, predicate, object, etc., which are useful for further (e.g., semantic) processing. The parses yielded by different parsing frameworks typically obey different formal and theoretical assumptions concerning how to represent the grammatical relationships in the data (Rambow, 2010). For example, grammatical relations may be encoded on top of dependency arcs in a dependency tree (Mel’ˇcuk, 1988), they may decorate nodes in a phrase-structure tree (Marcus et al., 1993; Maamouri et al., 2004; Sima’an et al., 2001), or they may be read off of positions in A popular way to address this has been to pick one of the frameworks and convert all parser outputs to its formal type. When comparing constituency-based and dependency-based parsers, for instance, the output of constituency parsers has often been converted to dependency structures prior to evaluation (Cer et al., 2010; Ni"
E12-1006,P11-1067,0,0.106813,"rsion of their output into dependencies. The conversion to SD allows one to compare results across formal frameworks, but not without a cost. The conversion introduces a set of annotation specific decisions which may introduce a bias into the evaluation. In the middle column of Table 1 we report the T ED E VAL metrics measured against the generalized gold standard for all parsing frameworks. We can now confirm that the constituency-based parsers significantly outperform the dependency parsers, and that this is not due to specific theoretical decisions which are seen to affect LAS/UAS metrics (Schwartz et al., 2011). For the dependency parsers we now see that Malt outperforms MST on labeled dependencies slightly, but the difference is insignificant. The fact that the discrepancy in theoretical assumptions between different frameworks indeed affects the conversion-based evaluation procedure is reflected in the results we report in Table 2. Here the leftmost and rightmost columns report T ED E VAL scores against the own native gold (S INGLE) and the middle column against the generalized gold (M ULTIPLE). Had the theories for SD and PTBttl SD been identical, T ED E VAL S INGLE and T ED E VAL M ULTIPLE would"
E12-1006,H91-1060,0,0.607655,"e show that our extended protocol, which can handle linearlyordered labeled trees with arbitrary branching, can soundly compare parsing results across frameworks in a representation-independent and language-independent fashion. Preliminaries: Relational Schemes for Cross-Framework Parse Evaluation Traditionally, different statistical parsers have been evaluated using specially designated evaluation measures that are designed to fit their representation types. Dependency trees are evaluated using attachment scores (Buchholz and Marsi, 2006), phrase-structure trees are evaluated using ParsEval (Black et al., 1991), LFG-based parsers postulate an evaluation procedure based on fstructures (Cahill et al., 2008), and so on. From a downstream application point of view, there is no significance as to which formalism was used for generating the representation and which learning methods have been utilized. The bottom line is simply which parsing framework most accurately recovers a useful representation that helps to unravel the human-perceived interpretation. Relational schemes, that is, schemes that encode the set of grammatical relations that constitute the predicate-argument structures of sentences, provid"
E12-1006,W06-2920,0,0.644417,"ncy-based parsing models, all trained on the Swedish treebank data. All in all we show that our extended protocol, which can handle linearlyordered labeled trees with arbitrary branching, can soundly compare parsing results across frameworks in a representation-independent and language-independent fashion. Preliminaries: Relational Schemes for Cross-Framework Parse Evaluation Traditionally, different statistical parsers have been evaluated using specially designated evaluation measures that are designed to fit their representation types. Dependency trees are evaluated using attachment scores (Buchholz and Marsi, 2006), phrase-structure trees are evaluated using ParsEval (Black et al., 1991), LFG-based parsers postulate an evaluation procedure based on fstructures (Cahill et al., 2008), and so on. From a downstream application point of view, there is no significance as to which formalism was used for generating the representation and which learning methods have been utilized. The bottom line is simply which parsing framework most accurately recovers a useful representation that helps to unravel the human-perceived interpretation. Relational schemes, that is, schemes that encode the set of grammatical relati"
E12-1006,J08-1003,0,0.0581572,"Missing"
E12-1006,cer-etal-2010-parsing,0,0.0124214,"Missing"
E12-1006,P05-1022,0,0.0115084,"hich the different gold theories agree. 2 48 The ordering can be alphabetic, thematic, etc. We can now define δ for the ith framework, as the error of parsei relative to its native gold standard goldi and to the generalized gold gen. This is the edit cost minus the cost of the script turning parsei into gen intersected with the script turning goldi into gen. The underlying intuition is that if an operation that was used to turn parsei into gen is used to discard theory-specific information from goldi , its cost should not be counted as error. parser (Petrov et al., 2006) and the Brown parser (Charniak and Johnson, 2005). All experiments use Penn Treebank (PTB) data. For Swedish, we compare MaltParser and MSTParser with two variants of the Berkeley parser, one trained on phrase structure trees, and one trained on a variant of the Relational-Realizational representation of Tsarfaty and Sima’an (2008). All experiments use the Talbanken Swedish Treebank (STB) data. δ(parsei , goldi , gen) = cost(ES ∗ (parsei , gen)) 4.1 We use sections 02–21 of the WSJ Penn Treebank for training and section 00 for evaluation and analysis. We use two different native gold standards subscribing to different theories of encoding gr"
E12-1006,de-marneffe-etal-2006-generating,0,0.00660104,"Missing"
E12-1006,N06-1024,0,0.0162642,"representation types, (ii) computing the theoretical common ground for each test sentence, and (iii) counting only what counts, that is, measuring the distance between the common ground and the parse tree while discarding annotation-specific edits. A pre-condition for applying our protocol is the availability of a relational interpretation of trees in the different frameworks. For dependency frameworks this is straightforward, as these relations are encoded on top of dependency arcs. For constituency trees with an inherent mapping of nodes onto grammatical relations (Merlo and Musillo, 2005; Gabbard et al., 2006; Tsarfaty and Sima’an, 2008), a procedure for reading relational schemes off of the trees is trivial to implement. For parsers that are trained on and parse into bare-bones phrase-structure trees this is not so. Reading off the relational structure may be more costly and require interjection of additional theoretical assumptions via manually written scripts. Scripts that read off grammatical relations based on tree positions work well for configurational 6 Conclusion We developed a protocol for comparing parsing results across different theories and representation types which is framework-ind"
E12-1006,gimenez-marquez-2004-svmtool,0,0.0182849,"Missing"
E12-1006,C08-1112,1,0.919669,"Missing"
E12-1006,D11-1036,1,0.0585547,"ne framework may be incompatible with the other one. In the constituency-to-dependency case, some constituency-based structures (e.g., coordination 44 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 44–54, c Avignon, France, April 23 - 27 2012. 2012 Association for Computational Linguistics 2 and ellipsis) do not comply with the single head assumption of dependency treebanks. Secondly, these scripts may be labor intensive to create, and are available mostly for English. So the evaluation protocol becomes language-dependent. In Tsarfaty et al. (2011) we proposed a general protocol for handling annotation discrepancies when comparing parses across different dependency theories. The protocol consists of three phases: converting all structures into function trees, for each sentence, generalizing the different gold standard function trees to get their common denominator, and employing an evaluation measure based on tree edit distance (TED) which discards edit operations that recover theory-specific structures. Although the protocol is potentially applicable to a wide class of syntactic representation types, formal restrictions in the procedur"
E12-1006,nivre-etal-2006-maltparser,1,\N,Missing
E12-2012,ballesteros-nivre-2012-maltoptimizer-system,1,0.567209,"ation tools for machine learning, such as Paramsearch (Van den Bosch, 2004). In addition, Nilsson and Nugues (2010) has explored automatic feature selection specifically for MaltParser, but MaltOptimizer is the first system that implements a complete customized optimization process for this system. In the rest of the paper, we describe the optimization process implemented in MaltOptimizer (Section 2), report experiments (Section 3), outline the demonstration (Section 4), and conclude (Section 5). A more detailed description of MaltOptimizer with additional experimental results can be found in Ballesteros and Nivre (2012). 2 The MaltOptimizer System MaltOptimizer is written in Java and implements an optimization procedure for MaltParser based on the heuristics described in Nivre and Hall (2010). The system takes as input a training set, consisting of sentences annotated with dependency trees in CoNLL data format,1 and outputs an optimized MaltParser configuration together with an estimate of the final parsing accuracy. The evaluation metric that is used for optimization by default is the labeled attachment score (LAS) excluding punctuation, that is, the percentage of non-punctuation tokens that are assigned th"
E12-2012,W06-2920,0,0.556884,"apted to new settings provided that we can find suitable training data. However, such components may require careful feature selection and parameter tuning in order to Joakim Nivre Uppsala University Sweden joakim.nivre@lingfil.uu.se give optimal performance, a task that can be difficult for application developers without specialized knowledge of each component. A typical example is MaltParser (Nivre et al., 2006), a widely used transition-based dependency parser with state-of-the-art performance for many languages, as demonstrated in the CoNLL shared tasks on multilingual dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). MaltParser is an open-source system that offers a wide range of parameters for optimization. It implements nine different transition-based parsing algorithms, each with its own specific parameters, and it has an expressive specification language that allows the user to define arbitrarily complex feature models. Finally, any combination of parsing algorithm and feature model can be combined with a number of different machine learning algorithms available in LIBSVM (Chang and Lin, 2001) and LIBLINEAR (Fan et al., 2008). Just running the system with default settings when tr"
E12-2012,C10-1093,0,0.35669,"er, who can use the tool for black box optimization, as well as expert users, who can use it interactively to speed up optimization. Experiments on a number of data sets show that using MaltOptimizer for completely automatic optimization gives consistent and often substantial improvements over the default settings for MaltParser. The importance of feature selection and parameter optimization has been demonstrated for many NLP tasks (Kool et al., 2000; Daelemans et al., 2003), and there are general optimization tools for machine learning, such as Paramsearch (Van den Bosch, 2004). In addition, Nilsson and Nugues (2010) has explored automatic feature selection specifically for MaltParser, but MaltOptimizer is the first system that implements a complete customized optimization process for this system. In the rest of the paper, we describe the optimization process implemented in MaltOptimizer (Section 2), report experiments (Section 3), outline the demonstration (Section 4), and conclude (Section 5). A more detailed description of MaltOptimizer with additional experimental results can be found in Ballesteros and Nivre (2012). 2 The MaltOptimizer System MaltOptimizer is written in Java and implements an optimiz"
E12-2012,P05-1013,1,0.72883,"performing algorithm and creates a new option file for the best configuration so far. The user is again given the opportunity to edit the option file (or stop the process) before optimization continues. 2.3 Figure 2: Decision tree for best non-projective algorithm (+PP for pseudo-projective parsing). Stack algorithms (Nivre, 2009; Nivre et al., 2009) Both the Covington group and the Stack group contain algorithms that can handle non-projective dependency trees, and any projective algorithm can be combined with pseudo-projective parsing to recover non-projective dependencies in postprocessing (Nivre and Nilsson, 2005). In phase 2, MaltOptimizer explores the parsing algorithms implemented in MaltParser, based on the data characteristics inferred in the first phase. In particular, if there are no non-projective dependencies in the training set, then only projective algorithms are explored, including the arc-eager and arc-standard versions of Nivre’s algorithm, the projective version of Covington’s projective parsing algorithm and the projective Stack algorithm. The system follows a decision tree considering the characteristics of each algorithm, which is shown in Figure 1. On the other hand, if the training"
E12-2012,P81-1022,0,0.82109,"Missing"
E12-2012,W09-3811,1,0.567952,"st projective algorithm. in Figure 1 and Figure 2 and picking the algorithm that gives the best results after traversing both. Once the system has finished testing each of the algorithms with default settings, MaltOptimizer tunes some specific parameters of the best performing algorithm and creates a new option file for the best configuration so far. The user is again given the opportunity to edit the option file (or stop the process) before optimization continues. 2.3 Figure 2: Decision tree for best non-projective algorithm (+PP for pseudo-projective parsing). Stack algorithms (Nivre, 2009; Nivre et al., 2009) Both the Covington group and the Stack group contain algorithms that can handle non-projective dependency trees, and any projective algorithm can be combined with pseudo-projective parsing to recover non-projective dependencies in postprocessing (Nivre and Nilsson, 2005). In phase 2, MaltOptimizer explores the parsing algorithms implemented in MaltParser, based on the data characteristics inferred in the first phase. In particular, if there are no non-projective dependencies in the training set, then only projective algorithms are explored, including the arc-eager and arc-standard versions of"
E12-2012,W03-3017,1,0.554527,"Missing"
E12-2012,J08-4003,1,0.472223,"Missing"
E12-2012,P09-1040,1,0.686176,"n tree for best projective algorithm. in Figure 1 and Figure 2 and picking the algorithm that gives the best results after traversing both. Once the system has finished testing each of the algorithms with default settings, MaltOptimizer tunes some specific parameters of the best performing algorithm and creates a new option file for the best configuration so far. The user is again given the opportunity to edit the option file (or stop the process) before optimization continues. 2.3 Figure 2: Decision tree for best non-projective algorithm (+PP for pseudo-projective parsing). Stack algorithms (Nivre, 2009; Nivre et al., 2009) Both the Covington group and the Stack group contain algorithms that can handle non-projective dependency trees, and any projective algorithm can be combined with pseudo-projective parsing to recover non-projective dependencies in postprocessing (Nivre and Nilsson, 2005). In phase 2, MaltOptimizer explores the parsing algorithms implemented in MaltParser, based on the data characteristics inferred in the first phase. In particular, if there are no non-projective dependencies in the training set, then only projective algorithms are explored, including the arc-eager and arc"
E12-2012,nivre-etal-2006-maltparser,1,\N,Missing
E12-2012,D07-1096,1,\N,Missing
I11-1100,J04-4004,0,0.077163,"Missing"
I11-1100,cer-etal-2010-parsing,0,0.032005,"Missing"
I11-1100,C08-1071,0,0.0212923,"Missing"
I11-1100,N10-1004,0,0.0312252,"iques such as voting, stacking and product models (Henderson and Brill, 2000; Nivre and McDonald, 2008; Petrov, 2010). An ensemble approach to parsing seems particularly appropriate for the linguistic melting pot of Web 2.0, as does the related idea of selecting a model based on characteristics of the input. For example, a preliminary error analysis of the Malt uptraining results shows that coordination cases in TwitterDev are helped more by grammars trained on FootballTrain than on TwitterTrain, suggesting that sentences containing a conjunction should be directed to a FootballTrain grammar. McClosky et al. (2010) use linear regression to determine the correct mix of training material for a particular document. We intend to experiment with this idea in the context of Web 2.0 parsing. More Parser Evaluation The cross-parser evaluation we have presented in the first half of the paper is by no means exhaustive. For example, to measure the positive effect of discriminative reranking, the first-stage Brown parser should also be included in the evaluation. Other statistical parsers could be evaluated, and it would be interesting to examine the performance of systems which employ hand-crafted grammars and tre"
I11-1100,de-marneffe-etal-2006-generating,0,0.00984564,"Missing"
I11-1100,P05-1012,0,0.0540053,"ers from different geographical and social backgrounds. Foster (2010) carried out a pilot study on this topic by investigating the performance of the Berkeley parser (Petrov et al., 2006) on sentences taken from a sports discussion forum. Each misparsed sentence was examined manually and a list of problematic phenomena identified. We extend this work by looking at a larger dataset consisting not only of discussion forum posts but also microblogs or tweets. We extend the parser evaluation to the Brown reranking parser (Charniak and Johnson, 2005), MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005), and we examine the ability of all four parsers to recover typed Stanford dependencies (de Marneffe et al., 2006). The relative ranking of the four parsers confirms the results of previous Stanford-dependency-based parser evaluations on other datasets (Cer et al., 2010; Petrov et al., 2010). Furthermore, our study shows that the sentences in tweets are harder to parse than the sentences from the discussion forum, despite their shorter length and that a large contributing factor is the high part-of-speech tagging error rate. Foster’s work also included a targeted approach to improving parser p"
I11-1100,N10-1060,1,0.883765,", Joachim Wagner1 , Joseph Le Roux2 Joakim Nivre3 , Deirdre Hogan1 and Josef van Genabith1 1,3 NCLT/CNGL, Dublin City University, Ireland 2 LIF - CNRS UMR 6166, Universit´e Aix-Marseille, France 3 Department of Linguistics and Philology, Uppsala University, Sweden 1 {jfoster,ocetinoglu,jwagner,dhogan,josef}@computing.dcu.ie 2 joseph.le-roux@lif.univ-mrs.fr, 3 joakim.nivre@lingfil.uu.se Abstract social media is particularly challenging since Web 2.0 is not really a domain, consisting, as it does, of utterances from a wide variety of speakers from different geographical and social backgrounds. Foster (2010) carried out a pilot study on this topic by investigating the performance of the Berkeley parser (Petrov et al., 2006) on sentences taken from a sports discussion forum. Each misparsed sentence was examined manually and a list of problematic phenomena identified. We extend this work by looking at a larger dataset consisting not only of discussion forum posts but also microblogs or tweets. We extend the parser evaluation to the Brown reranking parser (Charniak and Johnson, 2005), MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005), and we examine the ability of all four parser"
I11-1100,gimenez-marquez-2004-svmtool,0,0.0101406,"Missing"
I11-1100,P11-2008,0,0.0596175,"Missing"
I11-1100,D09-1087,0,0.0469586,"Missing"
I11-1100,D10-1002,0,0.00568548,"d user-generated content can be used to improve parser accuracy. The reasons for the improvements yielded by the three types of retraining need to be determined.6 The underperformance of the TwitterTrain material in comparison to the FootballTrain material suggests that sample selection involving language and topic identification needs to be applied before parser retraining. We also intend to test the combination of PCFG-LA self-training 6 See Foster et al. (2011) for a preliminary analysis of the effect of Malt uptraining on sentences from TwitterDev. and product grammar parsing described in Huang et al. (2010) on our Web 2.0 dataset. Switchboard, as well as Ontonotes 4.0, which has recently been released and which contains syntactically annotated web text (300k words). Combination Parsing Several successful parsing methods have employed multiple parsing models, combined using techniques such as voting, stacking and product models (Henderson and Brill, 2000; Nivre and McDonald, 2008; Petrov, 2010). An ensemble approach to parsing seems particularly appropriate for the linguistic melting pot of Web 2.0, as does the related idea of selecting a model based on characteristics of the input. For example,"
I11-1100,P06-1063,1,0.829525,"Missing"
I11-1100,H94-1020,0,0.0475196,"Missing"
I11-1100,P06-1043,0,0.281537,"he discussion forum, despite their shorter length and that a large contributing factor is the high part-of-speech tagging error rate. Foster’s work also included a targeted approach to improving parser performance by modifying the Penn Treebank trees to reflect observed differences between Wall Street Journal (WSJ) sentences and discussion forum sentences (subject ellipsis, non-standard capitalisation, etc.). We approach the problem from a different perspective, by seeing how far we can get by exploiting unlabelled target domain data. We employ three types of parser retraining, namely, 1) the McClosky et al. (2006) self-training protocol, 2) uptraining of Malt using dependency trees produced by a slightly more accurate phrase structure parser (Petrov et al., 2010), and 3) PCFG-LA self-training (Huang We investigate the problem of parsing the noisy language of social media. We evaluate four Wall-Street-Journal-trained statistical parsers (Berkeley, Brown, Malt and MST) on a new dataset containing 1,000 phrase structure trees for sentences from microblogs (tweets) and discussion forum posts. We compare the four parsers on their ability to produce Stanford dependencies for these Web 2.0 sentences. We find"
I11-1100,P08-1108,1,0.789006,"ng. We also intend to test the combination of PCFG-LA self-training 6 See Foster et al. (2011) for a preliminary analysis of the effect of Malt uptraining on sentences from TwitterDev. and product grammar parsing described in Huang et al. (2010) on our Web 2.0 dataset. Switchboard, as well as Ontonotes 4.0, which has recently been released and which contains syntactically annotated web text (300k words). Combination Parsing Several successful parsing methods have employed multiple parsing models, combined using techniques such as voting, stacking and product models (Henderson and Brill, 2000; Nivre and McDonald, 2008; Petrov, 2010). An ensemble approach to parsing seems particularly appropriate for the linguistic melting pot of Web 2.0, as does the related idea of selecting a model based on characteristics of the input. For example, a preliminary error analysis of the Malt uptraining results shows that coordination cases in TwitterDev are helped more by grammars trained on FootballTrain than on TwitterTrain, suggesting that sentences containing a conjunction should be directed to a FootballTrain grammar. McClosky et al. (2010) use linear regression to determine the correct mix of training material for a p"
I11-1100,nivre-etal-2006-maltparser,1,0.187118,"rances from a wide variety of speakers from different geographical and social backgrounds. Foster (2010) carried out a pilot study on this topic by investigating the performance of the Berkeley parser (Petrov et al., 2006) on sentences taken from a sports discussion forum. Each misparsed sentence was examined manually and a list of problematic phenomena identified. We extend this work by looking at a larger dataset consisting not only of discussion forum posts but also microblogs or tweets. We extend the parser evaluation to the Brown reranking parser (Charniak and Johnson, 2005), MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005), and we examine the ability of all four parsers to recover typed Stanford dependencies (de Marneffe et al., 2006). The relative ranking of the four parsers confirms the results of previous Stanford-dependency-based parser evaluations on other datasets (Cer et al., 2010; Petrov et al., 2010). Furthermore, our study shows that the sentences in tweets are harder to parse than the sentences from the discussion forum, despite their shorter length and that a large contributing factor is the high part-of-speech tagging error rate. Foster’s work also included a t"
I11-1100,W09-3811,1,0.21318,"ntaining the supplied POS tag for a given word may be removed from the chart during coarse-to-fine pruning.2 3 Baseline Evaluation We first evaluate four widely used WSJ-trained statistical parsers on our new Web 2.0 datasets: Berkeley (Petrov et al., 2006) We train a PCFG-LA using 6 iterations and we run the parser in accurate mode. 3.1 Results Brown (Charniak and Johnson, 2005) We employ this parser in its out-of-the-box settings. Table 2 shows the Parseval f-score and part-ofspeech (POS) tagging accuracy for the Berkeley Malt (Nivre et al., 2006) We use the stacklazy algorithm described in Nivre et al. (2009). We train a linear classifier where the feature interactions are modelled explicitly. 2 In the interest of replicability, detailed information on experimental settings is available at http: //nclt.computing.dcu.ie/publications/ foster_ijcnlp11.html. 895 Parser Berk O Berk P Brown Malt P MST P Berk G Malt G MST G LAS UAS WSJ22 90.5 93.2 89.9 92.5 91.5 94.2 88.0 90.6 88.8 91.3 91.6 93.4 90.0 91.6 90.7 92.3 LAS UAS FootballDev 79.8 84.8 80.1 84.9 82.0 86.3 76.1 81.5 76.4 81.1 83.1 86.4 80.4 83.7 80.8 83.4 LAS UAS TwitterDev 68.9 75.1 68.2 74.2 71.4 77.3 67.3 73.6 68.1 73.8 76.8 80.8 78.3 81.6 78"
I11-1100,C10-1094,1,0.884961,"Missing"
I11-1100,P06-1055,0,0.0152372,"in City University, Ireland 2 LIF - CNRS UMR 6166, Universit´e Aix-Marseille, France 3 Department of Linguistics and Philology, Uppsala University, Sweden 1 {jfoster,ocetinoglu,jwagner,dhogan,josef}@computing.dcu.ie 2 joseph.le-roux@lif.univ-mrs.fr, 3 joakim.nivre@lingfil.uu.se Abstract social media is particularly challenging since Web 2.0 is not really a domain, consisting, as it does, of utterances from a wide variety of speakers from different geographical and social backgrounds. Foster (2010) carried out a pilot study on this topic by investigating the performance of the Berkeley parser (Petrov et al., 2006) on sentences taken from a sports discussion forum. Each misparsed sentence was examined manually and a list of problematic phenomena identified. We extend this work by looking at a larger dataset consisting not only of discussion forum posts but also microblogs or tweets. We extend the parser evaluation to the Brown reranking parser (Charniak and Johnson, 2005), MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005), and we examine the ability of all four parsers to recover typed Stanford dependencies (de Marneffe et al., 2006). The relative ranking of the four parsers confirms"
I11-1100,D10-1069,0,0.0996262,"t of problematic phenomena identified. We extend this work by looking at a larger dataset consisting not only of discussion forum posts but also microblogs or tweets. We extend the parser evaluation to the Brown reranking parser (Charniak and Johnson, 2005), MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005), and we examine the ability of all four parsers to recover typed Stanford dependencies (de Marneffe et al., 2006). The relative ranking of the four parsers confirms the results of previous Stanford-dependency-based parser evaluations on other datasets (Cer et al., 2010; Petrov et al., 2010). Furthermore, our study shows that the sentences in tweets are harder to parse than the sentences from the discussion forum, despite their shorter length and that a large contributing factor is the high part-of-speech tagging error rate. Foster’s work also included a targeted approach to improving parser performance by modifying the Penn Treebank trees to reflect observed differences between Wall Street Journal (WSJ) sentences and discussion forum sentences (subject ellipsis, non-standard capitalisation, etc.). We approach the problem from a different perspective, by seeing how far we can get"
I11-1100,N10-1003,0,0.00470176,"the combination of PCFG-LA self-training 6 See Foster et al. (2011) for a preliminary analysis of the effect of Malt uptraining on sentences from TwitterDev. and product grammar parsing described in Huang et al. (2010) on our Web 2.0 dataset. Switchboard, as well as Ontonotes 4.0, which has recently been released and which contains syntactically annotated web text (300k words). Combination Parsing Several successful parsing methods have employed multiple parsing models, combined using techniques such as voting, stacking and product models (Henderson and Brill, 2000; Nivre and McDonald, 2008; Petrov, 2010). An ensemble approach to parsing seems particularly appropriate for the linguistic melting pot of Web 2.0, as does the related idea of selecting a model based on characteristics of the input. For example, a preliminary error analysis of the Malt uptraining results shows that coordination cases in TwitterDev are helped more by grammars trained on FootballTrain than on TwitterTrain, suggesting that sentences containing a conjunction should be directed to a FootballTrain grammar. McClosky et al. (2010) use linear regression to determine the correct mix of training material for a particular docum"
I11-1100,W10-2105,0,0.0674734,"Missing"
I11-1100,W09-2205,0,0.0221942,"Missing"
I11-1100,P07-1078,0,0.0355222,"Missing"
I11-1100,W10-2606,0,0.0124848,"Missing"
I11-1100,E03-1008,0,0.0496129,"Missing"
I11-1100,W99-0623,0,\N,Missing
I11-1143,W10-1411,1,0.862755,"w that the approach using hard constraints seems most promising and performs significantly better than single-stage parsing. Our best result gives significant increase in LAS and UAS, respectively, over the previous best result using single-stage parsing. 1 Introduction There has been a recent surge in addressing parsing for morphologically rich free word order languages such as Czech, Turkish, Hindi, etc. These languages pose various challenges for the task of parsing mainly because the syntactic cues necessary to identify various relations are complex and distributed (Tsarfaty et al., 2010; Ambati et al., 2010; Nivre and McDonald, 2008; Tsarfaty and Sima'an, 2008; Seddah et al., 2009; Gadde et al., 2010; Husain et al., 2009; Eryigit et al., 2008). There has also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd st"
I11-1143,I08-2099,1,0.940296,"finite verb and its dependents’. More precisely, let T be the complete dependency tree of a sentence, and let G be a clausal subgraph of T. Then an arc x → y in G is a valid arc, if (a) x is a finite verb; (b) y is not a finite verb; (c) there is no z such that y → z, where z is a finite verb and y is a conjunct. 1 The dependency label k1 can be roughly translated to ‘agent’, r6 is a dependency label for genitive relation, ccof is a relation signifying conjunction and nmod-relc is used for relative clause modification. For the complete description of the tagset and the dependency scheme see (Begum et al., 2008). 1280 3 Two-stage parsing 4 Two-stage parsing has been successfully used in a constraint based system for Hindi (Bharati et al., 2009, 2009b). This parser tries to analyze the given input sentence, which has already been POS tagged and chunked, in 2 stages; it first tries to extract intra-clausal dependency relations. In the 2nd stage it then tries to handle more complex relations such as those involved in constructions of coordination and subordination between clauses. (1) mai ghar gayaa kyomki mai ’I’ ’home’ ’went’ ’because’ ’I’ bimaar thaa ’sick’ ‘was’ ‘I went home because I was sick’ The"
I11-1143,W09-3812,1,0.935581,"as also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find out whether this two-stage parsing approach that has earlier been successful in constraint-based systems for parsing Hindi (Bharati et al., 2009) can also benefit data-driven parsing approaches (Nivre et al., 2006), and compare two ways of implementing this idea, one based on hard constraints (similar to the one used in constraint-based parsing), and one based on soft constraints (using a kind of parser stacking; (Nivre and McDonald, 2008). We show that one of the ways in which clausal parsing helps is by better learning of features that leads to improved label accuracy for Hindi. In particular we show that ambiguous case markers (or suffixes) that appear with many relations can be disambiguated successfully. We also show that the setu"
I11-1143,N10-1093,1,0.943463,"r than single-stage parsing. Our best result gives significant increase in LAS and UAS, respectively, over the previous best result using single-stage parsing. 1 Introduction There has been a recent surge in addressing parsing for morphologically rich free word order languages such as Czech, Turkish, Hindi, etc. These languages pose various challenges for the task of parsing mainly because the syntactic cues necessary to identify various relations are complex and distributed (Tsarfaty et al., 2010; Ambati et al., 2010; Nivre and McDonald, 2008; Tsarfaty and Sima'an, 2008; Seddah et al., 2009; Gadde et al., 2010; Husain et al., 2009; Eryigit et al., 2008). There has also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find out whether this two-stage parsing approach that has earlier been succe"
I11-1143,W09-3819,0,0.0325424,"Missing"
I11-1143,D07-1097,1,0.890709,"Missing"
I11-1143,P09-3002,0,0.0655384,"that the output we get after each stage is a tree. Later in the 2nd stage the relationship between the two clauses are identified. The 2nd stage parse for the above sentence is shown in Figure 4b. The 2nd stage does not modify the parse sub-trees obtained from the 1st stage, it only establishes the relations between the clauses. Two-stage data-driven parsing Since the availability of the Hyderabad Dependency Treebank for Hindi (Begum et al., 2008) a considerable amount of work has gone into exploring various data-driven approaches for Hindi parsing (Bharati et al., 2008; Husain et al., 2009; Mannem et al., 2009b; Gadde et al., 2010). The ICON09 and ICON10 tools contests on Indian language parsing (Husain, 2009; Husain et al., 2010) have also showcased various parsing efforts and established the state-of-the-art for Hindi dependency parsing. During both these parsing contest MaltParser was used to achieve the best accuracy for Hindi. Through the experiments described in this paper, we aim to investigate the following questions: - What are the different ways in which one can treat clauses as minimal unit during the parsing process? - Will this help improve parsing accuracy using MaltParser? We now pre"
I11-1143,H05-1066,0,0.323468,"Missing"
I11-1143,D07-1013,1,0.93712,"compare two ways of implementing this idea, one based on hard constraints (similar to the one used in constraint-based parsing), and one based on soft constraints (using a kind of parser stacking; (Nivre and McDonald, 2008). We show that one of the ways in which clausal parsing helps is by better learning of features that leads to improved label accuracy for Hindi. In particular we show that ambiguous case markers (or suffixes) that appear with many relations can be disambiguated successfully. We also show that the setup reduces many of the traditional MaltParser (Nivre et al., 2006) errors (McDonald and Nivre, 2007). Our results show that the approach using hard constraints seems most promising and performs significantly better than single-stage parsing. The paper is arranged as follows. In Section 2, we introduce the clause as a basic parsing unit. Section 3 gives a brief overview of two-stage parsing. In Section 4 we discuss data-driven parsing for Hindi and present two methods for implementing two-stage parsing within this framework. Section 5 explains the experimental setup, and Section 6 discusses the results. We conclude the paper in Section 7. 2 Clauses as minimal parsing units We begin with the o"
I11-1143,nilsson-nivre-2008-malteval,1,0.85221,"Missing"
I11-1143,P09-1040,1,0.890985,"Missing"
I11-1143,P08-1108,1,0.915113,"sing hard constraints seems most promising and performs significantly better than single-stage parsing. Our best result gives significant increase in LAS and UAS, respectively, over the previous best result using single-stage parsing. 1 Introduction There has been a recent surge in addressing parsing for morphologically rich free word order languages such as Czech, Turkish, Hindi, etc. These languages pose various challenges for the task of parsing mainly because the syntactic cues necessary to identify various relations are complex and distributed (Tsarfaty et al., 2010; Ambati et al., 2010; Nivre and McDonald, 2008; Tsarfaty and Sima'an, 2008; Seddah et al., 2009; Gadde et al., 2010; Husain et al., 2009; Eryigit et al., 2008). There has also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find ou"
I11-1143,nivre-etal-2006-maltparser,1,0.817481,"Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find out whether this two-stage parsing approach that has earlier been successful in constraint-based systems for parsing Hindi (Bharati et al., 2009) can also benefit data-driven parsing approaches (Nivre et al., 2006), and compare two ways of implementing this idea, one based on hard constraints (similar to the one used in constraint-based parsing), and one based on soft constraints (using a kind of parser stacking; (Nivre and McDonald, 2008). We show that one of the ways in which clausal parsing helps is by better learning of features that leads to improved label accuracy for Hindi. In particular we show that ambiguous case markers (or suffixes) that appear with many relations can be disambiguated successfully. We also show that the setup reduces many of the traditional MaltParser (Nivre et al., 2006) err"
I11-1143,W03-3017,1,0.815227,"Missing"
I11-1143,W09-3824,0,0.0290121,"s significantly better than single-stage parsing. Our best result gives significant increase in LAS and UAS, respectively, over the previous best result using single-stage parsing. 1 Introduction There has been a recent surge in addressing parsing for morphologically rich free word order languages such as Czech, Turkish, Hindi, etc. These languages pose various challenges for the task of parsing mainly because the syntactic cues necessary to identify various relations are complex and distributed (Tsarfaty et al., 2010; Ambati et al., 2010; Nivre and McDonald, 2008; Tsarfaty and Sima'an, 2008; Seddah et al., 2009; Gadde et al., 2010; Husain et al., 2009; Eryigit et al., 2008). There has also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find out whether this two-stage parsing approach that ha"
I11-1143,N06-2033,0,0.0514118,"1 Introduction There has been a recent surge in addressing parsing for morphologically rich free word order languages such as Czech, Turkish, Hindi, etc. These languages pose various challenges for the task of parsing mainly because the syntactic cues necessary to identify various relations are complex and distributed (Tsarfaty et al., 2010; Ambati et al., 2010; Nivre and McDonald, 2008; Tsarfaty and Sima'an, 2008; Seddah et al., 2009; Gadde et al., 2010; Husain et al., 2009; Eryigit et al., 2008). There has also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find out whether this two-stage parsing approach that has earlier been successful in constraint-based systems for parsing Hindi (Bharati et al., 2009) can also benefit data-driven parsing approaches (Nivre et al., 2006), and compare two way"
I11-1143,C08-1112,0,0.0197131,"s most promising and performs significantly better than single-stage parsing. Our best result gives significant increase in LAS and UAS, respectively, over the previous best result using single-stage parsing. 1 Introduction There has been a recent surge in addressing parsing for morphologically rich free word order languages such as Czech, Turkish, Hindi, etc. These languages pose various challenges for the task of parsing mainly because the syntactic cues necessary to identify various relations are complex and distributed (Tsarfaty et al., 2010; Ambati et al., 2010; Nivre and McDonald, 2008; Tsarfaty and Sima'an, 2008; Seddah et al., 2009; Gadde et al., 2010; Husain et al., 2009; Eryigit et al., 2008). There has also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find out whether this two-stage par"
I11-1143,W05-1518,0,0.029955,"using single-stage parsing. 1 Introduction There has been a recent surge in addressing parsing for morphologically rich free word order languages such as Czech, Turkish, Hindi, etc. These languages pose various challenges for the task of parsing mainly because the syntactic cues necessary to identify various relations are complex and distributed (Tsarfaty et al., 2010; Ambati et al., 2010; Nivre and McDonald, 2008; Tsarfaty and Sima'an, 2008; Seddah et al., 2009; Gadde et al., 2010; Husain et al., 2009; Eryigit et al., 2008). There has also been a lot of interest in building ensemble systems (Zeman and Zabokrtsky, 2005; Sagae and Lavie, 2006) and parser stacking (Nivre and McDonald, 2008; Martins et al., 2009) to improve the overall parsing accuracy by combining the strengths of multiple parsers. In this paper, we formulate clausal parsing as a two-stage setup where intra-clausal relations are identified in the 1st stage and inter-clausal relations are identified in the 2nd stage. We attempt to find out whether this two-stage parsing approach that has earlier been successful in constraint-based systems for parsing Hindi (Bharati et al., 2009) can also benefit data-driven parsing approaches (Nivre et al., 20"
I11-1143,J08-4010,1,\N,Missing
I11-1143,J08-3003,1,\N,Missing
I11-1143,D08-1017,0,\N,Missing
I17-1018,W14-4012,0,0.0792603,"Missing"
I17-1018,P08-1102,0,0.049283,"Missing"
I17-1018,P09-1058,0,0.586714,"tal number of combinatory labels. The efficiency can be improved if we reduce k. For some POS tags, combining them with the full boundary tags is redundant. For instance, only the functional word 的 can be tagged as DEG in Chinese Treebank (Xue et al., 2005). Since it is a single-character word, combinatory tags of B-DEG, I-DEG, and E-DEG never occur in the experimental data and should therefore be pruned to reduce the search space. Similarly, if the maximum length of words under a given POS tag is two in the training data, we prune the corresponding label. Tagging Scheme Following the work of Kruengkrai et al. (2009a), the employed tags indicating the word boundaries are B, I, E, S representing a character at the beginning, inside, end of a word or as a singlecharacter word. The CRF layer models conditional scores over all possible combinatory labels given the input characters. Incorporating the transition scores between the successive labels, the op1 夏 Output Our baseline model is an adaptation of BiRNNCRF. As illustrated in Figure 1, the Chinese characters are represented as vectors and fed into the bidirectional recurrent layers. The character representations will be described in detail in the followi"
I17-1018,D15-1176,0,0.0393132,"n Chinese dictionaries. In our approach, they are retrieved via the unicode representation of Chinese characters as the characters that share the same radical are grouped together. They are organised in consistent with the categorisation in Kangxi Dictionary (康熙字典), in which all the Chinese characters are grouped under 214 different radicals. We only employ the radicals of the common characters in the unicode range of (U+4E00, U+9FFF). For the characters out of the range and the non-Chinese characters, we use a single special vector as their radical representations. where f is usually an RNN (Ling et al., 2015) or a CNN (dos Santos and Zadrozny, 2014). In this paper, instead of completely relying on the BiRNN to extract contextual features from context-free character representations, we encode rich local information in the character vectors via employing the incrementally concatenated n-gram representation as demonstrated in Figure 2. In the example, the vector representation of the pivot character 太 in the given context is the concatenation of the context-free vector representation Vi,i of 太 itself along with Vi−1,i of the bigram 天太 as well as Vi−1,i+1 of the trigram 天太热. Instead of constructing th"
I17-1018,P16-1101,0,0.0838702,"nn@helsinki.fi Abstract joint model which predicts the combinatory labels of segmentation boundaries and POS tags at the character level. Joint segmentation and POS tagging becomes a standard character-based sequence tagging problem and therefore the general machine learning algorithms for structured prediction can be applied. The bidirectional recurrent neural network (RNN) using conditional random fields (CRF) (Lafferty et al., 2001) as the output interface for sentence-level optimisation (BiRNN-CRF) achieves state-of-the-art accuracies on various sequence tagging tasks (Huang et al., 2015; Ma and Hovy, 2016) and outperforms the traditional linear statistical models. RNNs with gated recurrent cells, such as long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) and gated recurrent units (GRU) (Cho et al., 2014) are capable of capturing long dependencies and retrieving rich global information. The sequential CRF on top of the recurrent layers ensures that the optimal sequence of tags over the entire sentence is obtained. In this paper, we model joint segmentation and POS tagging as a fully character-based sequence tagging problem via predicting the combinatory labels. The BiRNN-CRF archit"
I17-1018,W04-3236,0,0.174321,"egmentation and POS tagging. 1 Introduction Word segmentation and part-of-speech (POS) tagging are core steps for higher-level natural language processing (NLP) tasks. Given the raw text, segmentation is applied at the very first step and POS tagging is performed on top afterwards. As by convention the words in Chinese are not delimited by spaces, segmentation is non-trivial, but its accuracy has a significant impact on POS tagging. Moreover, POS tags provide useful information for word segmentation. Thus, modelling word segmentation and POS tagging jointly can outperform the pipeline models (Ng and Low, 2004; Zhang and Clark, 2008). POS tagging is a typical sequence tagging problem over segmented words, while segmentation also can be modelled as a character-level tagging problem via predicting the labels that identify the word boundaries. Ng and Low (2004) propose a 173 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 173–183, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP (summer) (Zhang and Clark, 2010), which is a state-of-theart joint tagger using structured perceptron and beam decoding. According to the experimental results, our pro"
I17-1018,D14-1162,0,0.0852471,"hinese characters are logograms. As opposed to alphabetical languages, there is rich information 175 Char. embedding size n-gram embedding size Radical embedding size Character font Character size GRU state size Conv. filter size Conv. filter number Max pooling size Fully-connected size Optimiser Initial learning rate Decay rate Gradient Clipping Dropout rate Batch size 2.3.3 Pre-trained Character Embeddings The context-free vector representations of single characters introduced in section 2.3.1 can be replaced by pre-trained character embeddings retrieved from large corpora. We employ GloVe (Pennington et al., 2014) to train our character embeddings on Wikipedia2 and the freely available Sogou News Corpora (SogouCS).3 We use randomly initialised vectors as the representations of the characters that are not in the embedding vocabulary. Pre-trained embeddings for higher-order n-grams are not employed in this paper. 2.4 Ensemble Decoding At the final decoding phase, we use ensemble decoding, a simple averaging technique, to mitigate the deviations led by random weight initialisation of the neural network. For the chain CRF decoder, the final sequence of the combinatory tags y is obtained via the conditional"
I17-1018,P14-2042,0,0.164784,"Missing"
I17-1018,P11-1139,0,0.136417,"Missing"
I17-1018,D16-1157,0,0.0159777,"training algorithm is employed for sentence level optimisation, which is the same as the training algorithm of the BiRNNCRF model. Their proposed model is not evaluated on CTB5 and therefore difficult to be compared with our system. Kong et al. (2015) apply segmental recurrent neural networks to joint segmentation and POS tagging but the evaluation results are substantially below the state-of-the-art on CTB5. Bojanowski et al. (2016) retrieve word embeddings via representing words as a bag of character n-grams for morphologically rich languages. A similar character n-gram model is proposed by Wieting et al. (2016). Sun et al. (2014) attempt to encode radical information into the conventional character embeddings. The radicalenhanced embeddings are employed and evaluated for Chinese segmentation. The results show that radical-enhanced embeddings outperform both skip-ngram and continues bag-of-word (Mikolov et al., 2013) in word2vec. Table 8: Result comparisions on CTB5 in F1scores. used for processing very large files. The memory demand of decoding is drastically milder compared to training, a large batch size therefore can be employed. The tagger takes constant time to build the sub-computational graph"
I17-1018,P16-1040,0,0.0693485,"e are in comparison to Single (** p &lt; 0.01, * p &lt; 0.05) performs very well despite being fully character based. Moreover, it has clear advantages when applied to smaller datasets like UD Chinese, while the prevalence is much smaller on CTB5. Both our model and ZPar segment OOV words in UD Chinese with higher accuracies than the ones in CTBs despite that UD Chinese is notably smaller and the overall OOV rate is higher. Compared to CTB, the words in UD Chinese are more fine-grained and the average word length is shorter, which makes it easier for the tagger to correctly segment the OOV words as Zhang et al. (2016) show that the longer words are more difficult to be segmented correctly. For joint POS tagging for OOV words, the two systems both perform significantly better on CTB5 as it is only composed of news text. BN CS FM MG NS SM SP WB Ensemble Seg Seg&Tag 97.89* 94.48** 96.67** 91.78** 96.54** 91.92** 94.54** 89.23** 97.56 93.92** 96.43** 91.78** 97.29** 93.93** 94.27** 88.44** Seg 97.68 95.61 96.30 94.22 97.49 96.13 96.69 93.38 ZPar Seg&Tag 94.22 90.15 91.51 88.60 93.70 90.32 93.35 86.88 Table 7: Evaluation on Broadcast News (BN), Conversations (CS), Forum (FM), Magazine (MG), News (NS), Short Mes"
I17-1018,P08-1101,0,0.127339,"S tagging. 1 Introduction Word segmentation and part-of-speech (POS) tagging are core steps for higher-level natural language processing (NLP) tasks. Given the raw text, segmentation is applied at the very first step and POS tagging is performed on top afterwards. As by convention the words in Chinese are not delimited by spaces, segmentation is non-trivial, but its accuracy has a significant impact on POS tagging. Moreover, POS tags provide useful information for word segmentation. Thus, modelling word segmentation and POS tagging jointly can outperform the pipeline models (Ng and Low, 2004; Zhang and Clark, 2008). POS tagging is a typical sequence tagging problem over segmented words, while segmentation also can be modelled as a character-level tagging problem via predicting the labels that identify the word boundaries. Ng and Low (2004) propose a 173 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 173–183, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP (summer) (Zhang and Clark, 2010), which is a state-of-theart joint tagger using structured perceptron and beam decoding. According to the experimental results, our proposed model outperforms"
I17-1018,D10-1082,0,0.638575,"vide useful information for word segmentation. Thus, modelling word segmentation and POS tagging jointly can outperform the pipeline models (Ng and Low, 2004; Zhang and Clark, 2008). POS tagging is a typical sequence tagging problem over segmented words, while segmentation also can be modelled as a character-level tagging problem via predicting the labels that identify the word boundaries. Ng and Low (2004) propose a 173 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 173–183, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP (summer) (Zhang and Clark, 2010), which is a state-of-theart joint tagger using structured perceptron and beam decoding. According to the experimental results, our proposed model outperforms ZPar on all the datasets in terms of accuracy. The main contributions of this work include: 1. We apply the BiRNN-CRF model for general sequence tagging to joint segmentation and POS tagging for Chinese and achieve state-of-the-art accuracy. The experimental results show that our tagger is robust and accurate across datasets of different sizes, genres and annotation schemes. 2. We propose a novel approach for vector representations of ch"
I17-1018,D13-1061,0,0.225031,"Missing"
I17-1018,I11-1035,0,\N,Missing
I17-1018,L16-1262,1,\N,Missing
I17-2015,W14-4012,0,0.0329254,"Missing"
I17-2015,Y11-1011,0,0.0254307,"substantially higher scores as it returns much fewer PP. Referring to the trivial examples as well as the fact that only TP are meaningful to higher-level applications, S1 and S2 perform equally poorly, which is consistent with recall but not precision. Furthermore, a segmenter with less TP may achieve higher precision if it is drastically under-segmenting, as demonstrated by the comparison between S1 and S3. 2.2 True Negative Rate Neither recall nor precision measure how well the system rejects the negatives. True negative rate (TNR) is therefore proposed by Powers (2011) as the complement. Jiang et al. (2011) show that segmenters measured by TNR are better correlated than precision and recall with their actual performances within IR systems. For WS, it is not straightforward to compute TNR by directly normalising the true negatives (TN) by the real negatives (RN). However, it can be indirectly computed via TP, PP, RP and the total number of possible output TW given a sentence. Regarding the input characters as a string, TW is equal to the number )N , where N is the number of of substrings as (1+N 2 the characters. RN can then be computed by subtracting RP, the number of words in reference. The fal"
I17-2015,I17-1018,1,0.841883,"ation (Palmer and Burger, 1997). The drawback is that incorrectly segmented words that are not interesting to higherlevel applications still contribute to the scores as long as one of the two associated boundaries is correctly detected. 1 Score 0.8 0.6 0.4 3 Experiments 0.2 To further investigate the correlations and drawbacks of the metrics discussed in the previous section experimentally, we employ a neural-based word segmenter to see how they measure the segmentation performance in a real scenario. The segmenter is a simplified version of the joint segmentation and POS tagger introduced in Shao et al. (2017). It is fully character-based. The vector representations of input characters are passed to the prevalent bidirectional recurrent neural network equipped with gated recurrent unit (GRU) (Cho et al., 2014) as the basic cell. A time-wise softmax layer is added as the inference for the recurrent layers to obtain probability distribution of binary tags that indicate the boundaries of the words. Cross-entropy with respect to time step is applied as the loss function. We train the segmenter for 30 epochs and pick the weights of the best epoch that minimises the loss on the development set. The Chine"
I17-2015,W03-1719,0,0.0553146,"n characters (Goldwater et al., 2007). It is the initial step for most higher level natural language processing tasks, such as part-of-speech tagging, syntactic analysis, information retrieval and machine translation. Thus, correct segmentation is crucial as segmentation errors propagate to higher level tasks. Because only correctly segmented words are meaningful to higher level tasks, word level precision, recall and their evenly-weighted average F1-score that are customised from information retrieval (IR) (Kent et al., 1955) are conventionally used as the standard evaluation metrics for WS (Sproat and Emerson, 2003; Qiu et al., 2015). In this paper, we thoroughly investigate precision and recall in addition to true negative rate in the scope of WS, with a special focus on the drawbacks of precision. Precision and F1-score can be misleading as an under-splitting system may obtain higher precision despite having fewer cor∀ip ∈ RP , ∀in ∈ RN , ∃I, {ip , in } ⊂ I Precision and recall are thus not directly correlated. For IR, system performance is well measured only if both precision and recall are used as it is trivial to optimise with respect to either precision or recall, but difficult to improve both. Th"
J01-1008,P90-1001,0,\N,Missing
J08-3003,P05-1038,0,0.0440134,"and Oﬂazer 2006). In this article, we units of syntactic structure (Eryigit corroborate this claim showing that it holds in both approaches we explore. We also study the impact of different morphological feature representations on parsing accuracy. The second set of issues concerns lexicalization, a topic that has been very prominent in the parsing literature lately. Whereas the best performing parsers for English all make use of lexical information, the real beneﬁts of lexicalization for English as well as other languages remains controversial (Dubey and Keller, 2003; Klein and Manning 2003; Arun and Keller 2005). The third set concerns the basic parsing methodology, including both parsing algorithms and learning algorithms. We ﬁrst introduce a statistical parser using a conditional probabilistic model which is very sensitive to the selected representational features and thus clearly exposes the ones ˘ Nivre, and Oﬂazer Eryigit, Dependency Parsing of Turkish with crucial importance for parsing Turkish. We then implement our models on a deterministic classiﬁer-based parser using discriminative learning, which is one of the best performing dependency parsers evaluated on a wide range of different langua"
J08-3003,W06-2922,0,0.0105271,"Missing"
J08-3003,W06-2923,0,0.0538957,"Missing"
J08-3003,W04-3224,0,0.00686561,"rtainly improves parsing accuracy for Turkish, only the lexicalization of conjunctions and nouns together has an impact on accuracy. Similarly to the experiments on inﬂectional features, we again see that the classiﬁer-based parser has no sparse data problem even if we use a totally lexicalized model. Although the effect of lexicalization has been discussed in several studies recently (Dubey and Keller 2003; Klein and Manning 2003; Arun and Keller 2005), it is often investigated as an all-or-nothing affair, except for a few studies that analyze the distributions of lexical items, for example, Bikel (2004) and Gildea (2001). The results for 25 IGs with a noun part-of-speech tag other than common nouns are marked with an additional minor part of speech that indicates whether the nominal is a proper noun or a derived form—one of future participle, past participle, inﬁnitive, or a form involving a zero-morpheme derivation. These latter four do not contain any root information. 377 Computational Linguistics Volume 34, Number 3 Figure 8 Unlabeled and labeled attachment scores for incrementally extended lexicalization for the classiﬁer-based parser. Turkish clearly show that the effect of lexicalizat"
J08-3003,W00-1201,0,0.0282273,"Linguistics Computational Linguistics Volume 34, Number 3 An important issue in this context is to what extent our models and algorithms are tailored to properties of speciﬁc languages or language groups. This issue is especially pertinent for data-driven approaches, where one of the claimed advantages is portability to new languages. The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (Collins 1997, 1999), is applied to a new language, which often leads to a signiﬁcant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004). However, it is often quite difﬁcult to tease apart the inﬂuence of different features of the parsing methodology in the observed degradation of performance. A related issue concerns the suitability of different kinds of syntactic representation for different types of languages. Whereas most of the work on English has been based on constituency-based representations, partly inﬂuenced by the availability of data resources such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), it has been argued that free consti"
J08-3003,H92-1026,0,0.0499667,"Missing"
J08-3003,J02-2002,0,0.0452358,"Missing"
J08-3003,W06-2920,0,0.34395,"been based on constituency-based representations, partly inﬂuenced by the availability of data resources such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), it has been argued that free constituent order languages can be analyzed more adequately using dependency-based representations, which is also the kind of annotation found, for example, in the Prague Dependency Treebank of Czech (Hajiˇc et al. 2001). Recently, dependency-based parsing has been applied to 13 different languages in the shared task of the 2006 Conference on Computational Natural Language Learning (CoNLL) (Buchholz and Marsi 2006). In this article, we focus on dependency-based parsing of Turkish, a language that is characterized by rich agglutinative morphology, free constituent order, and predominantly head-ﬁnal syntactic constructions. Thus, Turkish can be viewed as the representative of a class of languages that are very different from English and most other languages that have been studied in the parsing literature. Using data from the recently released Turkish Treebank (Oﬂazer et al. 2003), we investigate the impact of different design choices in developing data-driven parsers. There are essentially three sets of"
J08-3003,W06-2925,0,0.0251147,"Missing"
J08-3003,W06-2926,0,0.0329291,"Missing"
J08-3003,W06-2927,0,0.0366282,"Missing"
J08-3003,P96-1025,0,0.197624,"the relatively naive simpler baseline parsers which cannot recover headinitial dependencies. 4. Probabilistic Dependency Parser A well-studied approach to dependency parsing is a statistical approach where the parser takes a morphologically tagged and disambiguated sentence as input, and outputs the most probable dependency tree by using probabilities induced from the training data. Such an approach comprises three components: 1. A parsing algorithm for building the dependency analyses (Eisner 1996; Sekine, Uchimoto, and Isahara 2000) 2. A conditional probability model to score the analyses (Collins 1996) Table 1 Unlabeled attachment scores and unlabeled word-to-word scores for the baseline parsers. Parsing Model ASU WWU Attach-to-next (ﬁrst IG) Attach-to-next (last IG) Rule-based 56.0 54.1 70.5 63.3 63.3 79.3 363 Computational Linguistics 3. Volume 34, Number 3 Maximum likelihood estimation to make inferences about the underlying probability models (Collins 1996; Chung and Rim 2004) 4.1 Methodology The aim of our probabilistic model is to assign a probability to each candidate dependency link by using the frequencies of similar dependencies computed from a training set. The aim of the parsing"
J08-3003,P97-1003,0,0.0192592,"eived: 5 October 2006; revised submission received: 3 April 2007; accepted for publication: 16 May 2007. © 2008 Association for Computational Linguistics Computational Linguistics Volume 34, Number 3 An important issue in this context is to what extent our models and algorithms are tailored to properties of speciﬁc languages or language groups. This issue is especially pertinent for data-driven approaches, where one of the claimed advantages is portability to new languages. The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (Collins 1997, 1999), is applied to a new language, which often leads to a signiﬁcant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004). However, it is often quite difﬁcult to tease apart the inﬂuence of different features of the parsing methodology in the observed degradation of performance. A related issue concerns the suitability of different kinds of syntactic representation for different types of languages. Whereas most of the work on English has been based on constituency-based representations, partly inﬂu"
J08-3003,P99-1065,0,0.0474825,"ion for Computational Linguistics Computational Linguistics Volume 34, Number 3 An important issue in this context is to what extent our models and algorithms are tailored to properties of speciﬁc languages or language groups. This issue is especially pertinent for data-driven approaches, where one of the claimed advantages is portability to new languages. The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (Collins 1997, 1999), is applied to a new language, which often leads to a signiﬁcant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004). However, it is often quite difﬁcult to tease apart the inﬂuence of different features of the parsing methodology in the observed degradation of performance. A related issue concerns the suitability of different kinds of syntactic representation for different types of languages. Whereas most of the work on English has been based on constituency-based representations, partly inﬂuenced by the availability of data resources such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), it has been"
J08-3003,W06-2928,0,0.0384986,"Missing"
J08-3003,W06-2929,0,0.0193811,"Missing"
J08-3003,P03-1013,0,0.066789,"nal Linguistics Volume 34, Number 3 An important issue in this context is to what extent our models and algorithms are tailored to properties of speciﬁc languages or language groups. This issue is especially pertinent for data-driven approaches, where one of the claimed advantages is portability to new languages. The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (Collins 1997, 1999), is applied to a new language, which often leads to a signiﬁcant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004). However, it is often quite difﬁcult to tease apart the inﬂuence of different features of the parsing methodology in the observed degradation of performance. A related issue concerns the suitability of different kinds of syntactic representation for different types of languages. Whereas most of the work on English has been based on constituency-based representations, partly inﬂuenced by the availability of data resources such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), it has been argued that free constituent order languages c"
J08-3003,C96-1058,0,0.0606541,"Missing"
J08-3003,E06-1012,1,0.909481,"Missing"
J08-3003,W01-0521,0,0.0119816,"parsing accuracy for Turkish, only the lexicalization of conjunctions and nouns together has an impact on accuracy. Similarly to the experiments on inﬂectional features, we again see that the classiﬁer-based parser has no sparse data problem even if we use a totally lexicalized model. Although the effect of lexicalization has been discussed in several studies recently (Dubey and Keller 2003; Klein and Manning 2003; Arun and Keller 2005), it is often investigated as an all-or-nothing affair, except for a few studies that analyze the distributions of lexical items, for example, Bikel (2004) and Gildea (2001). The results for 25 IGs with a noun part-of-speech tag other than common nouns are marked with an additional minor part of speech that indicates whether the nominal is a proper noun or a derived form—one of future participle, past participle, inﬁnitive, or a form involving a zero-morpheme derivation. These latter four do not contain any root information. 377 Computational Linguistics Volume 34, Number 3 Figure 8 Unlabeled and labeled attachment scores for incrementally extended lexicalization for the classiﬁer-based parser. Turkish clearly show that the effect of lexicalization is not uniform"
J08-3003,W94-0314,0,0.0808522,"nclusions from our study. 2. Turkish: Morphology and Dependency Relations Turkish displays rather different characteristics compared to the more well-studied languages in the parsing literature. Most of these characteristics are also found in many agglutinative languages such as Basque, Estonian, Finnish, Hungarian, Japanese, and Korean.1 Turkish is a ﬂexible constituent order language. Even though in written texts the constituent order predominantly conforms to the SOV order, constituents may freely change their position depending on the requirements of the discourse context (Erguvanlı 1979; Hoffman 1994). However, from a dependency structure point of view, Turkish is predominantly (but not exclusively) head ﬁnal. Turkish has a very rich agglutinative morphological structure. Nouns can give rise to about 100 inﬂected forms and verbs to many more. Furthermore, Turkish words may be formed through very productive derivations, increasing substantially the number of possible word forms that can be generated from a root word. It is not uncommon to ﬁnd up to four or ﬁve derivations in a single word. Previous work on Turkish (Hakkani¨ Oﬂazer, and Tur ¨ 2002; Oﬂazer 2003; Oﬂazer et al. 2003; Eryigit ˘"
J08-3003,W06-2930,0,0.0358618,"Missing"
J08-3003,P03-1054,0,0.0188546,"rd forms as the basic ˘ and Oﬂazer 2006). In this article, we units of syntactic structure (Eryigit corroborate this claim showing that it holds in both approaches we explore. We also study the impact of different morphological feature representations on parsing accuracy. The second set of issues concerns lexicalization, a topic that has been very prominent in the parsing literature lately. Whereas the best performing parsers for English all make use of lexical information, the real beneﬁts of lexicalization for English as well as other languages remains controversial (Dubey and Keller, 2003; Klein and Manning 2003; Arun and Keller 2005). The third set concerns the basic parsing methodology, including both parsing algorithms and learning algorithms. We ﬁrst introduce a statistical parser using a conditional probabilistic model which is very sensitive to the selected representational features and thus clearly exposes the ones ˘ Nivre, and Oﬂazer Eryigit, Dependency Parsing of Turkish with crucial importance for parsing Turkish. We then implement our models on a deterministic classiﬁer-based parser using discriminative learning, which is one of the best performing dependency parsers evaluated on a wide ra"
J08-3003,W02-2016,0,0.0945693,".1±0.3 77.1±0.7 77.6±0.5 79.0±0.7 results than using root information (#5). Also, dynamic selection of tags seems to help performance (#3) but using all available inﬂectional information performs signiﬁcantly worse possibly due to data sparseness. 5. Classiﬁer-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (Nivre et al. 2006, 2007). This strategy consists of the combination of the following three techniques: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto 2002; Nivre 2003; Yamada and Matsumoto 2003) Table 3 Unlabeled attachment scores for different choices for morphological features. Model ASU IG-based model # (Dl =1, Dr =1, Hl =0, Hr =1) 72.1±0.3 1 Using major part of speech instead of minor part of speech 71.2±0.2 2 Using only minor part of speech and no other inﬂectional features 68.3±0.2 3 Using minor part of speech for all types of IGs together with case and possessive markers for nominals and possessive marker for adjectives (but no dynamic selection) 71.0±0.3 4 Using all inﬂectional features in addition to minor part of speech 46.5±0.4 5 Add"
J08-3003,P03-1056,0,0.0147149,"34, Number 3 An important issue in this context is to what extent our models and algorithms are tailored to properties of speciﬁc languages or language groups. This issue is especially pertinent for data-driven approaches, where one of the claimed advantages is portability to new languages. The results so far mainly come from studies where a parser originally developed for English, such as the Collins parser (Collins 1997, 1999), is applied to a new language, which often leads to a signiﬁcant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004). However, it is often quite difﬁcult to tease apart the inﬂuence of different features of the parsing methodology in the observed degradation of performance. A related issue concerns the suitability of different kinds of syntactic representation for different types of languages. Whereas most of the work on English has been based on constituency-based representations, partly inﬂuenced by the availability of data resources such as the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993), it has been argued that free constituent order languages can be analyzed more ade"
J08-3003,W06-2931,0,0.0266142,"Missing"
J08-3003,P95-1037,0,0.0314318,"Missing"
J08-3003,J93-2004,0,0.0418254,"Missing"
J08-3003,W06-2932,0,0.10732,"Missing"
J08-3003,W03-3017,1,0.658285,"e an analysis for an input sentence, and efﬁcient, typically deriving this analysis in time that is linear in the length of the sentence. In the following sections, we will ﬁrst present the parsing methodology and then results that show that the IG-based model again outperforms the word-based model. We will then explore how we can further improve the accuracy by exploiting the advantages of this parser. All experiments are performed using the freely available implementation MaltParser.18 5.1 Methodology For the experiments in this article, we use a variant of the parsing algorithm proposed by Nivre (2003, 2006), a linear-time algorithm that derives a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and a list to store remaining input tokens. However, in contrast to the original arc-eager parsing strategy, we use an arc-standard bottom-up algorithm, as described in Nivre (2004). Like many algorithms used for dependency parsing, this algorithm is restricted to projective dependency graphs. The parser uses two elementary data structures, a stack σ of partially analyzed tokens and an input list τ of remaining input tokens. The pa"
J08-3003,W04-0308,1,0.769162,"ove the accuracy by exploiting the advantages of this parser. All experiments are performed using the freely available implementation MaltParser.18 5.1 Methodology For the experiments in this article, we use a variant of the parsing algorithm proposed by Nivre (2003, 2006), a linear-time algorithm that derives a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and a list to store remaining input tokens. However, in contrast to the original arc-eager parsing strategy, we use an arc-standard bottom-up algorithm, as described in Nivre (2004). Like many algorithms used for dependency parsing, this algorithm is restricted to projective dependency graphs. The parser uses two elementary data structures, a stack σ of partially analyzed tokens and an input list τ of remaining input tokens. The parser is initialized with an empty stack and with all the tokens of a sentence in the input list; it terminates as soon as the input list is empty. In the following, we use subscripted indices, starting from 0, to refer to particular tokens in σ and τ. Thus, σ0 is the token on top of the stack σ (the top token) and τ0 is the ﬁrst token in the in"
J08-3003,W04-2407,1,0.787512,"Missing"
J08-3003,W06-2933,1,0.422301,"Missing"
J08-3003,P05-1013,1,0.627689,"siﬁer-based parser not only builds dependency structures but also assigns dependency labels, we give ASL scores as well as ASU scores. 19 Experiments have also been performed using memory-based learning (Daelemans and Bosch 2005). They were found to give lower parsing accuracy. 20 Because the frequency of non-projective dependencies in the Turkish Treebank is not high enough to learn such dependencies and mostly due to the unconnected punctuations with which we are dealing by adding an extra dependency label, we did not observe any improvement when applying the pseudo-projective processing of Nivre and Nilsson (2005), which is reported to improve accuracy for other languages. 372 ˘ Nivre, and Oﬂazer Eryigit, Dependency Parsing of Turkish 5.2 Experimental Results In this section, our ﬁrst aim is to conﬁrm the claim that using IGs as the units in parsing improves performance. For this purpose, we start by using models similar to those described in the previous section. We use an unlexicalized feature model where the parser uses only the minor POS and the DEP of tokens and compare the results with the probabilistic parser. We then show in the second part how we can improve accuracy by exploiting the morpholo"
J08-3003,nivre-etal-2006-talbanken05,1,0.930024,"Word-based model #1 (Dl =1, Dr =1, Hl =1, Hr =1) Word-based model #2 (Dl =1, Dr =1, Hl =1, Hr =1) IG-based model (Dl =1, Dr =1, Hl =0, Hr =1) ASU WWU 68.1±0.4 68.3±0.3 72.1±0.3 77.1±0.7 77.6±0.5 79.0±0.7 results than using root information (#5). Also, dynamic selection of tags seems to help performance (#3) but using all available inﬂectional information performs signiﬁcantly worse possibly due to data sparseness. 5. Classiﬁer-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (Nivre et al. 2006, 2007). This strategy consists of the combination of the following three techniques: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto 2002; Nivre 2003; Yamada and Matsumoto 2003) Table 3 Unlabeled attachment scores for different choices for morphological features. Model ASU IG-based model # (Dl =1, Dr =1, Hl =0, Hr =1) 72.1±0.3 1 Using major part of speech instead of minor part of speech 71.2±0.2 2 Using only minor part of speech and no other inﬂectional features 68.3±0.2 3 Using minor part of speech for all types of IGs together with case and possessive"
J08-3003,J03-4001,1,0.916091,"Missing"
J08-3003,W97-0301,0,0.106603,"Missing"
J08-3003,W06-2934,0,0.0278293,"Missing"
J08-3003,W05-1513,0,0.0207132,"Missing"
J08-3003,W06-2935,0,0.019617,"Missing"
J08-3003,C00-2109,0,0.0590108,"Missing"
J08-3003,W06-2936,0,0.0257373,"Missing"
J08-3003,W06-2937,0,0.0258319,"Missing"
J08-3003,W03-3023,0,0.46816,"ults than using root information (#5). Also, dynamic selection of tags seems to help performance (#3) but using all available inﬂectional information performs signiﬁcantly worse possibly due to data sparseness. 5. Classiﬁer-Based Dependency Parser Our second data-driven parser is based on a parsing strategy that has achieved a high parsing accuracy across a variety of different languages (Nivre et al. 2006, 2007). This strategy consists of the combination of the following three techniques: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto 2002; Nivre 2003; Yamada and Matsumoto 2003) Table 3 Unlabeled attachment scores for different choices for morphological features. Model ASU IG-based model # (Dl =1, Dr =1, Hl =0, Hr =1) 72.1±0.3 1 Using major part of speech instead of minor part of speech 71.2±0.2 2 Using only minor part of speech and no other inﬂectional features 68.3±0.2 3 Using minor part of speech for all types of IGs together with case and possessive markers for nominals and possessive marker for adjectives (but no dynamic selection) 71.0±0.3 4 Using all inﬂectional features in addition to minor part of speech 46.5±0.4 5 Adding root information to the best perform"
J08-3003,W06-2938,0,0.0546519,"Missing"
J08-3003,megyesi-etal-2008-swedish,1,\N,Missing
J08-3003,E06-1011,0,\N,Missing
J08-3003,N06-1042,0,\N,Missing
J08-3003,J03-4003,0,\N,Missing
J08-3003,P05-1012,0,\N,Missing
J08-3003,C04-1010,1,\N,Missing
J08-3003,P09-1039,0,\N,Missing
J08-3003,P83-1017,0,\N,Missing
J08-3003,W06-2924,0,\N,Missing
J08-3003,W07-2420,0,\N,Missing
J08-3003,P93-1005,0,\N,Missing
J08-4003,W06-2922,0,0.526833,"ms with deterministic search. In data-driven dependency parsing, oracles normally take the form of classiﬁers, trained on treebank data, but they can also be deﬁned in terms of grammars and heuristic disambiguation rules (Nivre 2003). The main reason for introducing this framework is to allow us to characterize algorithms that have previously been described in different traditions and to compare their formal properties within a single uniﬁed framework. In particular, whereas this type of framework has previously been used to characterize algorithms in the stackbased family (Nivre 2003, 2006b; Attardi 2006), it is here being used also for the listbased algorithms ﬁrst discussed by Covington (2001). Deﬁnition 4 A transition system for dependency parsing is a quadruple S = (C, T, cs , Ct ), where 1. C is a set of conﬁgurations, each of which contains a buffer β of (remaining) nodes and a set A of dependency arcs, 2. T is a set of transitions, each of which is a (partial) function t : C → C, 3. cs is an initialization function, mapping a sentence x = (w0 , w1 , . . . , wn ) to a conﬁguration with β = [1, . . . , n], 4. Ct ⊆ C is a set of terminal conﬁgurations. A conﬁguration is required to contain"
J08-4003,W06-2920,0,0.239111,"dependencies only. The algorithm was generalized to allow both head-ﬁnal and head-initial dependencies by Yamada and Matsumoto (2003), who reported very good parsing accuracy for English, using dependency structures extracted from the Penn Treebank for training and testing. The approach was extended to labeled dependency parsing by Nivre, Hall, and Nilsson (2004) (for Swedish) and Nivre and Scholz (2004) (for English), using a different parsing algorithm ﬁrst presented in Nivre (2003). At a recent evaluation of data-driven systems for dependency parsing with data from 13 different languages (Buchholz and Marsi 2006), the deterministic classiﬁer-based parser of Nivre et al. (2006) reached top performance together with the system of McDonald, Lerman, and Pereira (2006), which is based on a global discriminative model with online learning. These results indicate that, at least for dependency parsing, deterministic parsing is possible without a drastic loss in accuracy. The deterministic classiﬁer-based approach has also been applied to phrase structure parsing (Kalt 2004; Sagae and Lavie 2005), although the accuracy for this type of representation remains a bit below the state of the art. In this setting, m"
J08-4003,C96-1058,0,0.280942,"tric dependency relations holding between the words of a sentence. This basic conception of syntactic structure underlies a variety of different linguistic theories, such as Structural Syntax (Tesni`ere 1959), Functional Generative Description (Sgall, Hajiˇcov´a, and Panevov´a 1986), Meaning-Text Theory (Mel’ˇcuk 1988), and Word Grammar (Hudson 1990). In computational linguistics, dependencybased syntactic representations have in recent years been used primarily in data-driven models, which learn to produce dependency structures for sentences solely from an annotated corpus, as in the work of Eisner (1996), Yamada and Matsumoto (2003), Nivre, Hall, and Nilsson (2004), and McDonald, Crammer, and Pereira (2005), among others. One potential advantage of such models is that they are easily ported to any domain or language in which annotated resources exist. In this kind of framework the syntactic structure of a sentence is modeled by a dependency graph, which represents each word and its syntactic dependents through labeled directed arcs. This is exempliﬁed in Figure 1, for a Czech sentence taken from the Prague 515 Computational Linguistics Volume 34, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  Atr"
J08-4003,D07-1097,1,0.286316,"as ﬁrst proposed for Japanese by Kudo and Matsumoto (2002) and for English by Yamada and Matsumoto (2003). In contrast to spanning tree parsing, this can be characterized as a greedy inference strategy, trying to construct a globally optimal dependency graph by making a sequence of locally optimal decisions. The ﬁrst strictly incremental parser of this kind was described in Nivre (2003) and used for classiﬁer-based parsing of Swedish by Nivre, Hall, and Nilsson (2004) and English by Nivre and Scholz (2004). Altogether it has now been applied to 19 different languages (Nivre et al. 2006, 2007; Hall et al. 2007). Most algorithms in this tradition are restricted to projective dependency graphs, but it is 549 Computational Linguistics Volume 34, Number 4 possible to recover non-projective dependencies using pseudo-projective parsing (Nivre and Nilsson 2005). More recently, algorithms for non-projective classiﬁer-based parsing have been proposed by Attardi (2006) and Nivre (2006a). The strictly deterministic parsing strategy has been relaxed in favor of n-best parsing by Johansson and Nugues (2006), among others. The dominant learning method in this tradition is support vector machines (Kudo and Matsumo"
J08-4003,P06-2041,1,0.34911,"Missing"
J08-4003,W06-2930,0,0.0208137,"h by Nivre and Scholz (2004). Altogether it has now been applied to 19 different languages (Nivre et al. 2006, 2007; Hall et al. 2007). Most algorithms in this tradition are restricted to projective dependency graphs, but it is 549 Computational Linguistics Volume 34, Number 4 possible to recover non-projective dependencies using pseudo-projective parsing (Nivre and Nilsson 2005). More recently, algorithms for non-projective classiﬁer-based parsing have been proposed by Attardi (2006) and Nivre (2006a). The strictly deterministic parsing strategy has been relaxed in favor of n-best parsing by Johansson and Nugues (2006), among others. The dominant learning method in this tradition is support vector machines (Kudo and Matsumoto 2002; Yamada and Matsumoto 2003; Nivre et al. 2006) but memory-based learning has also been used (Nivre, Hall, and Nilsson 2004; Nivre and Scholz 2004; Attardi 2006). Of the algorithms described in this article, the arc-eager stack-based algorithm is essentially the algorithm proposed for unlabeled dependency parsing in Nivre (2003), extended to labeled dependency parsing in Nivre, Hall, and Nilsson (2004), and most fully described in Nivre (2006b). The major difference is that the par"
J08-4003,W04-3203,0,0.0156404,"n Nivre (2003). At a recent evaluation of data-driven systems for dependency parsing with data from 13 different languages (Buchholz and Marsi 2006), the deterministic classiﬁer-based parser of Nivre et al. (2006) reached top performance together with the system of McDonald, Lerman, and Pereira (2006), which is based on a global discriminative model with online learning. These results indicate that, at least for dependency parsing, deterministic parsing is possible without a drastic loss in accuracy. The deterministic classiﬁer-based approach has also been applied to phrase structure parsing (Kalt 2004; Sagae and Lavie 2005), although the accuracy for this type of representation remains a bit below the state of the art. In this setting, more competitive results have been achieved using probabilistic classiﬁers and beam search, rather than strictly deterministic search, as in the work by Ratnaparkhi (1997, 1999) and Sagae and Lavie (2006). A deterministic classiﬁer-based parser consists of three essential components: a parsing algorithm, which deﬁnes the derivation of a syntactic analysis as a sequence 514 Nivre Deterministic Incremental Dependency Parsing of elementary parsing actions; a fe"
J08-4003,W02-2016,0,0.12523,"selection is performed incrementally so that only a single analysis is derived by the parser. This has the advantage of making the parsing process very simple and efﬁcient but the potential disadvantage that overall accuracy suffers because of the early commitment enforced by the greedy search strategy. Somewhat surprisingly, though, research has shown that, with the right choice of parsing algorithm and classiﬁer, this type of parser can achieve state-of-the-art accuracy, especially when used with dependency-based syntactic representations. Classiﬁer-based dependency parsing was pioneered by Kudo and Matsumoto (2002) for unlabeled dependency parsing of Japanese with head-ﬁnal dependencies only. The algorithm was generalized to allow both head-ﬁnal and head-initial dependencies by Yamada and Matsumoto (2003), who reported very good parsing accuracy for English, using dependency structures extracted from the Penn Treebank for training and testing. The approach was extended to labeled dependency parsing by Nivre, Hall, and Nilsson (2004) (for Swedish) and Nivre and Scholz (2004) (for English), using a different parsing algorithm ﬁrst presented in Nivre (2003). At a recent evaluation of data-driven systems fo"
J08-4003,J93-2004,0,0.0387314,"Missing"
J08-4003,H94-1020,0,0.0144533,"SG (“Only one of them concerns quality.”) AuxP ✞ ROOT 0  ✞ Adv  ❄ ❄ na6 kvalitu7 quality to ❄ .8 .) Figure 1 Dependency graph for a Czech sentence from the Prague Dependency Treebank. ✞ ✞ ✞ ROOT ✞ NMOD ROOT 0 ❄ Economic1 ✞SBJ ❄ news2  ❄ had3  P  OBJ ✞NMOD ❄ little4 ✞ NMOD ✞   PMOD ✞ ❄ ❄ ❄ effect5 on6 ﬁnancial7  ❄ ❄ markets8 .9 NMOD Figure 2 Dependency graph for an English sentence from the Penn Treebank. ¨ Dependency Treebank (Hajiˇc et al. 2001; Bohmov´ a et al. 2003), and in Figure 2, for an English sentence taken from the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993; Marcus et al. 1994).1 An artiﬁcial word ROOT has been inserted at the beginning of each sentence, serving as the unique root of the graph. This is a standard device that simpliﬁes both theoretical deﬁnitions and computational implementations. Deﬁnition 1 Given a set L = {l1 , . . . , l|L |} of dependency labels, a dependency graph for a sentence x = (w0 , w1 , . . . , wn ) is a labeled directed graph G = (V, A), where 1. V = {0, 1, . . . , n} is a set of nodes, 2. A ⊆ V × L × V is a set of labeled directed arcs. The set V of nodes (or vertices) is the set of non-negative integers up to and including n, each corr"
J08-4003,D07-1125,0,0.00685747,"of the algorithm of Yamada and Matsumoto (2003), where incrementality is achieved by only allowing one left-toright pass over the input, whereas Yamada and Matsumoto perform several iterations in order to construct the dependency graph bottom-up, breadth-ﬁrst as it were. The list-based algorithms are both inspired by the work of Covington (2001), although the formulations are not equivalent. They have previously been explored for deterministic classiﬁer-based parsing in Nivre (2006a, 2007). A more orthodox implementation of Covington’s algorithms for data-driven dependency parsing is found in Marinov (2007). 8. Conclusion In this article, we have introduced a formal framework for deterministic incremental dependency parsing, where parsing algorithms can be deﬁned in terms of transition systems that are deterministic only together with an oracle for predicting the next transition. We have used this framework to analyze four different algorithms, proving the correctness of each algorithm relative to a relevant class of dependency graphs, and giving complexity results for each algorithm. To complement the formal analysis, we have performed an experimental evaluation of accuracy and efﬁciency, using"
J08-4003,P05-1012,0,0.164211,"e the number of distinct dependency labels and the percentage of non-projective dependencies also play a role. 7. Related Work Data-driven dependency parsing using supervised machine learning was pioneered by Eisner (1996), who showed how traditional chart parsing techniques could be adapted for dependency parsing to give efﬁcient parsing with exact inference over a probabilistic model where the score of a dependency tree is the sum of the scores of individual arcs. This approach has been further developed in particular by Ryan McDonald and his colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006) and is now known as spanning tree parsing, because the problem of ﬁnding the most probable tree under this type of model is equivalent to ﬁnding an optimum spanning tree in a dense graph containing all possible dependency arcs. If we assume that the score of an individual arc is independent of all other arcs, this problem can be solved efﬁciently for arbitrary non-projective dependency trees using the Chu-Liu-Edmonds algorithm, as shown by McDonald et al. (2005). Spanning tree algorithms have so far primarily been combined with online learning methods such as MIRA"
J08-4003,W06-2932,0,0.0141888,"Missing"
J08-4003,D07-1013,1,0.774534,"Missing"
J08-4003,E06-1011,0,0.182911,"ct dependency labels and the percentage of non-projective dependencies also play a role. 7. Related Work Data-driven dependency parsing using supervised machine learning was pioneered by Eisner (1996), who showed how traditional chart parsing techniques could be adapted for dependency parsing to give efﬁcient parsing with exact inference over a probabilistic model where the score of a dependency tree is the sum of the scores of individual arcs. This approach has been further developed in particular by Ryan McDonald and his colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006) and is now known as spanning tree parsing, because the problem of ﬁnding the most probable tree under this type of model is equivalent to ﬁnding an optimum spanning tree in a dense graph containing all possible dependency arcs. If we assume that the score of an individual arc is independent of all other arcs, this problem can be solved efﬁciently for arbitrary non-projective dependency trees using the Chu-Liu-Edmonds algorithm, as shown by McDonald et al. (2005). Spanning tree algorithms have so far primarily been combined with online learning methods such as MIRA (McDonald, Crammer, and Pere"
J08-4003,H05-1066,0,0.279502,"Missing"
J08-4003,P07-1122,1,0.679693,"Missing"
J08-4003,W03-3017,1,0.855189,"dependency parsing was pioneered by Kudo and Matsumoto (2002) for unlabeled dependency parsing of Japanese with head-ﬁnal dependencies only. The algorithm was generalized to allow both head-ﬁnal and head-initial dependencies by Yamada and Matsumoto (2003), who reported very good parsing accuracy for English, using dependency structures extracted from the Penn Treebank for training and testing. The approach was extended to labeled dependency parsing by Nivre, Hall, and Nilsson (2004) (for Swedish) and Nivre and Scholz (2004) (for English), using a different parsing algorithm ﬁrst presented in Nivre (2003). At a recent evaluation of data-driven systems for dependency parsing with data from 13 different languages (Buchholz and Marsi 2006), the deterministic classiﬁer-based parser of Nivre et al. (2006) reached top performance together with the system of McDonald, Lerman, and Pereira (2006), which is based on a global discriminative model with online learning. These results indicate that, at least for dependency parsing, deterministic parsing is possible without a drastic loss in accuracy. The deterministic classiﬁer-based approach has also been applied to phrase structure parsing (Kalt 2004; Sag"
J08-4003,W04-0308,1,0.693108,"o been used (Nivre, Hall, and Nilsson 2004; Nivre and Scholz 2004; Attardi 2006). Of the algorithms described in this article, the arc-eager stack-based algorithm is essentially the algorithm proposed for unlabeled dependency parsing in Nivre (2003), extended to labeled dependency parsing in Nivre, Hall, and Nilsson (2004), and most fully described in Nivre (2006b). The major difference is that the parser is now initialized with the special root node on the stack, whereas earlier formulations had an empty stack at initialization.15 The arc-standard stack-based algorithm is brieﬂy described in Nivre (2004) but can also be seen as an incremental version of the algorithm of Yamada and Matsumoto (2003), where incrementality is achieved by only allowing one left-toright pass over the input, whereas Yamada and Matsumoto perform several iterations in order to construct the dependency graph bottom-up, breadth-ﬁrst as it were. The list-based algorithms are both inspired by the work of Covington (2001), although the formulations are not equivalent. They have previously been explored for deterministic classiﬁer-based parsing in Nivre (2006a, 2007). A more orthodox implementation of Covington’s algorithms"
J08-4003,N07-1050,1,0.568312,"we focus on parsing algorithms. More precisely, we describe two families of algorithms that can be used for deterministic dependency parsing, supported by classiﬁers for predicting the next parsing action. The ﬁrst family uses a stack to store partially processed tokens and is restricted to the derivation of projective dependency structures. The algorithms of Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Nivre (2003, 2006b) all belong to this family. The second family, represented by the algorithms described by Covington (2001) and recently explored for classiﬁerbased parsing in Nivre (2007), instead uses open lists for partially processed tokens, which allows arbitrary dependency structures to be processed (in particular, structures with non-projective dependencies). We provide a detailed analysis of four different algorithms, two from each family, and give proofs of correctness and complexity for each algorithm. In addition, we perform an experimental evaluation of accuracy and efﬁciency for the four algorithms, combined with state-of-the-art classiﬁers, using data from 13 different languages. Although variants of these algorithms have been partially described in the literature"
J08-4003,W04-2407,1,0.62942,"Missing"
J08-4003,W06-2933,1,0.346666,"Missing"
J08-4003,P05-1013,1,0.556589,"fferent languages with considerable typological variation. Table 1 gives an overview of the training data available for each language. For data sets that include a non-negligible proportion of non-projective dependency graphs, it can be expected that the non-projective list-based algorithm will achieve higher accuracy than the strictly projective algorithms. In order to make the comparison more fair, we therefore also evaluate pseudo-projective versions of the latter algorithms, making use of graph transformations in pre- and post-processing to recover nonprojective dependency arcs, following Nivre and Nilsson (2005). For each language, seven different parsers were therefore trained as follows: 1. For the non-projective list-based algorithm, one parser was trained without preprocessing the training data. 2. For the three projective algorithms, two parsers were trained after preprocessing the training data as follows: (a) (b) 538 For the strictly projective parser, non-projective dependency graphs in the training data were transformed by lifting non-projective arcs to the nearest permissible ancestor of the real head. This corresponds to the Baseline condition in Nivre and Nilsson (2005). For the pseudo-pr"
J08-4003,C04-1010,1,0.631712,"curacy, especially when used with dependency-based syntactic representations. Classiﬁer-based dependency parsing was pioneered by Kudo and Matsumoto (2002) for unlabeled dependency parsing of Japanese with head-ﬁnal dependencies only. The algorithm was generalized to allow both head-ﬁnal and head-initial dependencies by Yamada and Matsumoto (2003), who reported very good parsing accuracy for English, using dependency structures extracted from the Penn Treebank for training and testing. The approach was extended to labeled dependency parsing by Nivre, Hall, and Nilsson (2004) (for Swedish) and Nivre and Scholz (2004) (for English), using a different parsing algorithm ﬁrst presented in Nivre (2003). At a recent evaluation of data-driven systems for dependency parsing with data from 13 different languages (Buchholz and Marsi 2006), the deterministic classiﬁer-based parser of Nivre et al. (2006) reached top performance together with the system of McDonald, Lerman, and Pereira (2006), which is based on a global discriminative model with online learning. These results indicate that, at least for dependency parsing, deterministic parsing is possible without a drastic loss in accuracy. The deterministic classiﬁe"
J08-4003,W97-0301,0,0.0609739,"6), which is based on a global discriminative model with online learning. These results indicate that, at least for dependency parsing, deterministic parsing is possible without a drastic loss in accuracy. The deterministic classiﬁer-based approach has also been applied to phrase structure parsing (Kalt 2004; Sagae and Lavie 2005), although the accuracy for this type of representation remains a bit below the state of the art. In this setting, more competitive results have been achieved using probabilistic classiﬁers and beam search, rather than strictly deterministic search, as in the work by Ratnaparkhi (1997, 1999) and Sagae and Lavie (2006). A deterministic classiﬁer-based parser consists of three essential components: a parsing algorithm, which deﬁnes the derivation of a syntactic analysis as a sequence 514 Nivre Deterministic Incremental Dependency Parsing of elementary parsing actions; a feature model, which deﬁnes a feature vector representation of the parser state at any given time; and a classiﬁer, which maps parser states, as represented by the feature model, to parsing actions. Although different types of parsing algorithms, feature models, and classiﬁers have been used for deterministic"
J08-4003,W05-1513,0,0.00591629,"03). At a recent evaluation of data-driven systems for dependency parsing with data from 13 different languages (Buchholz and Marsi 2006), the deterministic classiﬁer-based parser of Nivre et al. (2006) reached top performance together with the system of McDonald, Lerman, and Pereira (2006), which is based on a global discriminative model with online learning. These results indicate that, at least for dependency parsing, deterministic parsing is possible without a drastic loss in accuracy. The deterministic classiﬁer-based approach has also been applied to phrase structure parsing (Kalt 2004; Sagae and Lavie 2005), although the accuracy for this type of representation remains a bit below the state of the art. In this setting, more competitive results have been achieved using probabilistic classiﬁers and beam search, rather than strictly deterministic search, as in the work by Ratnaparkhi (1997, 1999) and Sagae and Lavie (2006). A deterministic classiﬁer-based parser consists of three essential components: a parsing algorithm, which deﬁnes the derivation of a syntactic analysis as a sequence 514 Nivre Deterministic Incremental Dependency Parsing of elementary parsing actions; a feature model, which deﬁn"
J08-4003,P06-2089,0,0.0102116,"l discriminative model with online learning. These results indicate that, at least for dependency parsing, deterministic parsing is possible without a drastic loss in accuracy. The deterministic classiﬁer-based approach has also been applied to phrase structure parsing (Kalt 2004; Sagae and Lavie 2005), although the accuracy for this type of representation remains a bit below the state of the art. In this setting, more competitive results have been achieved using probabilistic classiﬁers and beam search, rather than strictly deterministic search, as in the work by Ratnaparkhi (1997, 1999) and Sagae and Lavie (2006). A deterministic classiﬁer-based parser consists of three essential components: a parsing algorithm, which deﬁnes the derivation of a syntactic analysis as a sequence 514 Nivre Deterministic Incremental Dependency Parsing of elementary parsing actions; a feature model, which deﬁnes a feature vector representation of the parser state at any given time; and a classiﬁer, which maps parser states, as represented by the feature model, to parsing actions. Although different types of parsing algorithms, feature models, and classiﬁers have been used for deterministic dependency parsing, there are ver"
J08-4003,P83-1017,0,0.631027,"eterministic parsing techniques, which are maximally efﬁcient in that they only derive one analysis. This is possible because the formal language can be deﬁned by a non-ambiguous formal grammar that assigns a single canonical derivation to each string in the language, a property that cannot be maintained for any realistically sized natural language grammar. Consequently, these deterministic parsing techniques have been much less popular for natural language parsing, except as a way of modeling human sentence processing, which appears to be at least partly deterministic in nature (Marcus 1980; Shieber 1983). More recently, however, it has been shown that accurate syntactic disambiguation for natural language can be achieved using a pseudo-deterministic approach, where treebank-induced classiﬁers are used to predict the optimal next derivation step when faced with a nondeterministic choice between several possible actions. Compared to the more traditional methods for natural language parsing, this can be seen as a severe form of pruning, where parse selection is performed incrementally so that only a single analysis is derived by the parser. This has the advantage of making the parsing process ve"
J08-4003,W03-3023,0,0.161419,"sadvantage that overall accuracy suffers because of the early commitment enforced by the greedy search strategy. Somewhat surprisingly, though, research has shown that, with the right choice of parsing algorithm and classiﬁer, this type of parser can achieve state-of-the-art accuracy, especially when used with dependency-based syntactic representations. Classiﬁer-based dependency parsing was pioneered by Kudo and Matsumoto (2002) for unlabeled dependency parsing of Japanese with head-ﬁnal dependencies only. The algorithm was generalized to allow both head-ﬁnal and head-initial dependencies by Yamada and Matsumoto (2003), who reported very good parsing accuracy for English, using dependency structures extracted from the Penn Treebank for training and testing. The approach was extended to labeled dependency parsing by Nivre, Hall, and Nilsson (2004) (for Swedish) and Nivre and Scholz (2004) (for English), using a different parsing algorithm ﬁrst presented in Nivre (2003). At a recent evaluation of data-driven systems for dependency parsing with data from 13 different languages (Buchholz and Marsi 2006), the deterministic classiﬁer-based parser of Nivre et al. (2006) reached top performance together with the sy"
J08-4010,W04-2407,1,\N,Missing
J08-4010,megyesi-etal-2008-swedish,1,\N,Missing
J08-4010,nivre-etal-2006-talbanken05,1,\N,Missing
J08-4010,J93-2004,0,\N,Missing
J08-4010,W03-3023,0,\N,Missing
J08-4010,E06-1011,0,\N,Missing
J08-4010,W06-2926,0,\N,Missing
J08-4010,W06-2937,0,\N,Missing
J08-4010,P97-1003,0,\N,Missing
J08-4010,W06-2935,0,\N,Missing
J08-4010,N06-1042,0,\N,Missing
J08-4010,W01-0521,0,\N,Missing
J08-4010,W06-2927,0,\N,Missing
J08-4010,W00-1201,0,\N,Missing
J08-4010,W02-2016,0,\N,Missing
J08-4010,W06-2933,1,\N,Missing
J08-4010,W06-2920,0,\N,Missing
J08-4010,J03-4001,1,\N,Missing
J08-4010,W04-0308,1,\N,Missing
J08-4010,W05-1513,0,\N,Missing
J08-4010,H92-1026,0,\N,Missing
J08-4010,W06-2936,0,\N,Missing
J08-4010,W06-2923,0,\N,Missing
J08-4010,C96-1058,0,\N,Missing
J08-4010,W06-2934,0,\N,Missing
J08-4010,W94-0314,0,\N,Missing
J08-4010,W06-2929,0,\N,Missing
J08-4010,W06-2925,0,\N,Missing
J08-4010,W06-2931,0,\N,Missing
J08-4010,E06-1012,1,\N,Missing
J08-4010,J03-4003,0,\N,Missing
J08-4010,P03-1054,0,\N,Missing
J08-4010,P05-1038,0,\N,Missing
J08-4010,P96-1025,0,\N,Missing
J08-4010,P05-1012,0,\N,Missing
J08-4010,W06-2930,0,\N,Missing
J08-4010,C04-1010,1,\N,Missing
J08-4010,P09-1039,0,\N,Missing
J08-4010,W06-2932,0,\N,Missing
J08-4010,P03-1056,0,\N,Missing
J08-4010,P83-1017,0,\N,Missing
J08-4010,W06-2928,0,\N,Missing
J08-4010,W06-2924,0,\N,Missing
J08-4010,P95-1037,0,\N,Missing
J08-4010,J02-2002,0,\N,Missing
J08-4010,W07-2420,0,\N,Missing
J08-4010,W06-2922,0,\N,Missing
J08-4010,P05-1013,1,\N,Missing
J08-4010,P99-1065,0,\N,Missing
J08-4010,W06-2938,0,\N,Missing
J08-4010,P93-1005,0,\N,Missing
J08-4010,P03-1013,0,\N,Missing
J08-4010,W03-3017,1,\N,Missing
J08-4010,W04-3224,0,\N,Missing
J08-4010,C00-2109,0,\N,Missing
J11-1007,W06-2922,0,0.137103,"state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based parsing models to reﬂect the fact that parameterization is over possible state transitions. Transition-based models have been promoted by the groups of Matsumoto (Kudo and Matsumoto 2002; Yamada and Matsumoto 2003; Cheng, Asahara, and Matsumoto 2006), Nivre (Nivre, Hall, and Nilsson 2004; Nivre and Nilsson 2005; Nivre et al. 2006), and others (Attardi 2006; Attardi and Ciaramita 2007; Johansson and Nugues 2007; Duan, Zhao, and Xu 2007; Titov and Henderson 2007a, 2007b). It is important to note that there is no a priori reason why a graph-based parameterization should require global learning and inference, and a transition-based parameterization would necessitate local learning and greedy inference. Nevertheless, as observed by Buchholz and Marsi (2006), it is striking that recent work on data-driven dependency parsing has been dominated by global, exhaustive, graph-based models, on the one hand, and local, greedy, transition-based models, on th"
J11-1007,N07-1049,0,0.0121055,"Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based parsing models to reﬂect the fact that parameterization is over possible state transitions. Transition-based models have been promoted by the groups of Matsumoto (Kudo and Matsumoto 2002; Yamada and Matsumoto 2003; Cheng, Asahara, and Matsumoto 2006), Nivre (Nivre, Hall, and Nilsson 2004; Nivre and Nilsson 2005; Nivre et al. 2006), and others (Attardi 2006; Attardi and Ciaramita 2007; Johansson and Nugues 2007; Duan, Zhao, and Xu 2007; Titov and Henderson 2007a, 2007b). It is important to note that there is no a priori reason why a graph-based parameterization should require global learning and inference, and a transition-based parameterization would necessitate local learning and greedy inference. Nevertheless, as observed by Buchholz and Marsi (2006), it is striking that recent work on data-driven dependency parsing has been dominated by global, exhaustive, graph-based models, on the one hand, and local, greedy, transition-based models, on the other. Therefore, a carefu"
J11-1007,J96-1002,0,0.058999,"Missing"
J11-1007,W06-2920,0,0.797532,"in the computational linguistics community and have been successfully employed for many problems ranging from machine translation (Ding and Palmer 2004) to ontology construction (Snow, Jurafsky, and Ng 2005). A primary advantage of dependency representations is that they have a natural mechanism for representing discontinuous constructions, which arise due to long-distance dependencies or in languages where grammatical relations are often signaled by morphology instead of word order. This is undoubtedly one of the reasons for the emergence of dependency parsers for a wide range of languages (Buchholz and Marsi 2006; Nivre et al. 2007). Thus, the example in Figure 1 contains an instance of a discontinuous construction through the subgraph rooted at the word hearing. Speciﬁcally, the dependency arc from hearing to on spans the words is and scheduled, which are not nodes in this subgraph. An arc of this kind is said to be non-projective. In this article we focus on a common paradigm called data-driven dependency parsing, which encompasses parsing systems that learn to produce dependency graphs for sentences from a corpus of sentences annotated with dependency graphs. The advantage of such models is that th"
J11-1007,D07-1101,0,0.20937,"learns these parameters to globally score correct graphs above incorrect ones. Inference is also global, in that systems attempt to ﬁnd the highest scoring graph among the set of all graphs. We call such systems graph-based parsing models to reﬂect the fact that parameterization is over the graph. Graph-based models are mainly associated with the pioneering work of Eisner (Eisner 1996), as well as McDonald and colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006; McDonald, Lerman, and Pereira 2006) and others (Riedel, C ¸ akıcı, and Meza-Ruiz 2006; Carreras 2007; Koo et al. 2007; Nakagawa 2007; Smith and Smith 2007). The second category of parsing systems parameterizes models over transitions from one state to another in an abstract state-machine. Parameters in these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems t"
J11-1007,A00-2018,0,0.0385922,"emble systems and voting schemes, which only perform the integration at parsing time. However, given that we are dealing with datadriven models, it should be possible to integrate at learning time, so that the two complementary models can learn from one another. In this article, we propose to do this by letting one model generate features for the other in a stacked learning framework. Feature-based integration in this sense has previously been exploited for dependency parsing by McDonald (2006), who trained an instance of MSTParser using features generated by the parsers of Collins (1999) and Charniak (2000), which improved unlabeled accuracy by 1.7 percentage points on data from the Penn Treebank. In other NLP domains, feature-based integration has been used by Taskar, Lacoste-Julien, and Klein (2005), who trained a discriminative word alignment model using features derived from the IBM models, by Florian et al. (2004), who trained classiﬁers on auxiliary data to guide named entity classiﬁers, and by others. Feature-based integration also has points in common with co-training, which has been applied to syntactic parsing by Sarkar (2001) and Steedman et al. (2003), among others. The difference, o"
J11-1007,W06-2927,0,0.10435,"Missing"
J11-1007,W04-1513,0,0.0105139,"yanmcd@google.com. ∗∗ Department of Linguistics and Philology, Box 635, SE-75126 Uppsala, Sweden. E-mail: joakim.nivre@lingfil.uu.se. Submission received: 25 August 2009; revised submission received: 20 August 2010; accepted for publication: 7 October 2010. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 1 Figure 1 Dependency graph for an English sentence. Syntactic dependency graphs have recently gained a wide interest in the computational linguistics community and have been successfully employed for many problems ranging from machine translation (Ding and Palmer 2004) to ontology construction (Snow, Jurafsky, and Ng 2005). A primary advantage of dependency representations is that they have a natural mechanism for representing discontinuous constructions, which arise due to long-distance dependencies or in languages where grammatical relations are often signaled by morphology instead of word order. This is undoubtedly one of the reasons for the emergence of dependency parsers for a wide range of languages (Buchholz and Marsi 2006; Nivre et al. 2007). Thus, the example in Figure 1 contains an instance of a discontinuous construction through the subgraph root"
J11-1007,D07-1098,0,0.0223986,"Missing"
J11-1007,C96-1058,0,0.0656505,"t that there are currently two dominant approaches for data-driven 198 McDonald and Nivre Analyzing and Integrating Dependency Parsers dependency parsing. The ﬁrst category parameterizes models over dependency subgraphs and learns these parameters to globally score correct graphs above incorrect ones. Inference is also global, in that systems attempt to ﬁnd the highest scoring graph among the set of all graphs. We call such systems graph-based parsing models to reﬂect the fact that parameterization is over the graph. Graph-based models are mainly associated with the pioneering work of Eisner (Eisner 1996), as well as McDonald and colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006; McDonald, Lerman, and Pereira 2006) and others (Riedel, C ¸ akıcı, and Meza-Ruiz 2006; Carreras 2007; Koo et al. 2007; Nakagawa 2007; Smith and Smith 2007). The second category of parsing systems parameterizes models over transitions from one state to another in an abstract state-machine. Parameters in these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history."
J11-1007,N04-1001,0,0.0204938,"one model generate features for the other in a stacked learning framework. Feature-based integration in this sense has previously been exploited for dependency parsing by McDonald (2006), who trained an instance of MSTParser using features generated by the parsers of Collins (1999) and Charniak (2000), which improved unlabeled accuracy by 1.7 percentage points on data from the Penn Treebank. In other NLP domains, feature-based integration has been used by Taskar, Lacoste-Julien, and Klein (2005), who trained a discriminative word alignment model using features derived from the IBM models, by Florian et al. (2004), who trained classiﬁers on auxiliary data to guide named entity classiﬁers, and by others. Feature-based integration also has points in common with co-training, which has been applied to syntactic parsing by Sarkar (2001) and Steedman et al. (2003), among others. The difference, of course, is that standard co-training is a weakly supervised method, where the ﬁrst-stage parser’s predictions replace, rather than complement, the gold standard annotation during training. Feature-based integration is also similar to parse reranking (Collins 2000), where one parser produces a set of candidate parse"
J11-1007,P07-1050,0,0.116397,"Dependency Parsers and transition-based features, that is, features over both sub-graphs and transitions. Huang and Sagae (2010) go even further and show how transition-based parsing can be tabularized to allow for dynamic programming, which in turn permits an exponentially larger search space. Martins et al. (2008) present a method for integrating graph-based and transition-based parsers based on stacking, which is similar to the approach taken in this work. Other studies have tried to overcome the weaknesses of parsing models by changing the underlying model structure directly. For example, Hall (2007), Riedel, C ¸ akıcı, and Meza-Ruiz (2006), Nakagawa (2007), Smith and Eisner (2008), and Martins, Smith, and Xing (2009) attempt to overcome local restrictions in feature scope for graphbased parsers through both approximations and exact solutions with integer linear programming. Our work differs from past studies in that we attempt to quantify exactly the types of errors these parsers make, tie them to their theoretical expectations, and show that integrating graph-based and transition-based parsers not only increases overall accuracy, but does so directly exploiting the strengths of each sys"
J11-1007,D07-1097,1,0.705355,"a system that combines multiple transition-based parsers with a single graph-based parser by weighting each potential dependency relation by the number of parsers that predicted it. A ﬁnal dependency graph is predicted by using spanning tree inference algorithms from the graph-based parsing literature (McDonald et al. 2005). Sagae and Lavie report improvements of up to 1.7 percentage points over the best single parser when combining three transition-based models and one graph-based model for unlabeled dependency parsing, evaluated on data from the Penn Treebank. The same technique was used by Hall et al. (2007) to combine six transition-based parsers in the best performing system in the CoNLL 2007 shared task. Zhang and Clark (2008) propose a parsing system that uses global learning coupled with beam search over a transition-based backbone incorporating both graph-based 200 McDonald and Nivre Analyzing and Integrating Dependency Parsers and transition-based features, that is, features over both sub-graphs and transitions. Huang and Sagae (2010) go even further and show how transition-based parsing can be tabularized to allow for dynamic programming, which in turn permits an exponentially larger sear"
J11-1007,W99-0623,0,0.0431494,"ich is commonly called “classiﬁer stacking.” This method is simple—requiring only the deﬁnition of new features—and robust by allowing a model to learn relative to the predictions of the other. More importantly, we rerun the error analysis and show that the integrated models do indeed take advantage of the complementary strengths of both the graph-based and transition-based parsing systems. Combining the strengths of different machine learning systems, and even parsing systems, is by no means new as there are a number of previous studies that have looked at combining phrase-structure parsers (Henderson and Brill 1999), dependency parsers ˇ (Zeman and Zabokrtsk y` 2005), or both (McDonald 2006). Of particular note is past work on combining graph-based and transition-based dependency parsers. Sagae and Lavie (2006) present a system that combines multiple transition-based parsers with a single graph-based parser by weighting each potential dependency relation by the number of parsers that predicted it. A ﬁnal dependency graph is predicted by using spanning tree inference algorithms from the graph-based parsing literature (McDonald et al. 2005). Sagae and Lavie report improvements of up to 1.7 percentage point"
J11-1007,P07-1120,0,0.0186921,"for all languages except Czech, German, Portuguese, and Slovene. Finally, given that the two base models had the best performance for these data sets at the CoNLL-X shared task, the guided models achieve a substantial improvement of the state of the art.12 Although there is no statistically signiﬁcant difference between the two base models, they are both outperformed by MaltMST (p < 0.0001), which in turn has signiﬁcantly lower accuracy than MSTMalt (p < 0.0005). An extension to the models described so far would be to iteratively integrate the two parsers in the spirit of pipeline iteration (Hollingshead and Roark 2007). For example, one could start with a Malt model, use it to train a guided MSTMalt model, then use that as the guide to train a MaltMSTMalt model, and so forth. We ran such experiments, but found that accuracy did not increase signiﬁcantly and in some cases decreased slightly. This was true regardless of which parser began the iterative process. In retrospect, this result is not surprising. Because the initial integration effectively incorporates knowledge from both parsing systems, there is little to be gained by adding additional parsers in the chain. 6.2 Error Analysis The experimental resu"
J11-1007,W05-1506,0,0.0150967,"her than complement, the gold standard annotation during training. Feature-based integration is also similar to parse reranking (Collins 2000), where one parser produces a set of candidate parses and a second-stage classiﬁer chooses the most likely one. However, feature-based integration is not explicitly constrained to any parse decisions that the ﬁrst-stage parser might make. Furthermore, as only the single most likely parse is used from the ﬁrststage model, it is signiﬁcantly more efﬁcient than reranking, which requires both computationally and conceptually more complex parsing algorithms (Huang and Chiang 2005). 5.1 Parser Stacking with Rich Features As explained in Section 2, both models essentially learn a scoring function s : X → R, where the domain X is different for the two models. For the graph-based model, X is the set of possible dependency arcs (i, j, l); for the transition-based model, X is the set of possible conﬁguration-transition pairs (c, t). But in both cases, the input is represented by a k-dimensional feature vector f : X → Rk . In a stacked parsing system we simply extend the feature vector for one model, called the base model, with a certain number of features generated by the ot"
J11-1007,P10-1110,0,0.0699308,"Missing"
J11-1007,D07-1123,0,0.0625986,"Missing"
J11-1007,P10-1001,0,0.0428804,"the right is the predicted dependency tree based on Equation (1). 203 Computational Linguistics Volume 37, Number 1 over anything larger than arcs (McDonald and Satta 2007). Thus, graph-based parsing systems cannot easily condition on any extended scope of the dependency graph beyond a single arc, which is their primary shortcoming relative to transition-based systems. McDonald, Crammer, and Pereira (2005) show that a rich feature set over the input space, including lexical and surface syntactic features of neighboring words, can partially alleviate this problem, and both Carreras (2007) and Koo et al. (2010) explore higher-order models for projective trees. Additionally, work has been done on approximate non-factored parsing systems (McDonald and Pereira 2006; Hall 2007; Nakagawa 2007; Smith and Eisner 2008) as well as exact solutions through integer linear programming (Riedel, C ¸ akıcı, and Meza-Ruiz 2006; Martins, Smith, and Xing 2009). The speciﬁc graph-based system studied in this work is that presented by McDonald, Lerman, and Pereira (2006), which uses pairwise arc scoring and approximate exhaustive search for unlabeled parsing. A separate arc label classiﬁer is then used to label each arc"
J11-1007,D07-1015,0,0.0355011,"arameters to globally score correct graphs above incorrect ones. Inference is also global, in that systems attempt to ﬁnd the highest scoring graph among the set of all graphs. We call such systems graph-based parsing models to reﬂect the fact that parameterization is over the graph. Graph-based models are mainly associated with the pioneering work of Eisner (Eisner 1996), as well as McDonald and colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006; McDonald, Lerman, and Pereira 2006) and others (Riedel, C ¸ akıcı, and Meza-Ruiz 2006; Carreras 2007; Koo et al. 2007; Nakagawa 2007; Smith and Smith 2007). The second category of parsing systems parameterizes models over transitions from one state to another in an abstract state-machine. Parameters in these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based p"
J11-1007,W02-2016,0,0.026009,"e-machine. Parameters in these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based parsing models to reﬂect the fact that parameterization is over possible state transitions. Transition-based models have been promoted by the groups of Matsumoto (Kudo and Matsumoto 2002; Yamada and Matsumoto 2003; Cheng, Asahara, and Matsumoto 2006), Nivre (Nivre, Hall, and Nilsson 2004; Nivre and Nilsson 2005; Nivre et al. 2006), and others (Attardi 2006; Attardi and Ciaramita 2007; Johansson and Nugues 2007; Duan, Zhao, and Xu 2007; Titov and Henderson 2007a, 2007b). It is important to note that there is no a priori reason why a graph-based parameterization should require global learning and inference, and a transition-based parameterization would necessitate local learning and greedy inference. Nevertheless, as observed by Buchholz and Marsi (2006), it is striking that re"
J11-1007,J93-2004,0,0.0383994,"Missing"
J11-1007,D08-1017,0,0.0807279,"e six transition-based parsers in the best performing system in the CoNLL 2007 shared task. Zhang and Clark (2008) propose a parsing system that uses global learning coupled with beam search over a transition-based backbone incorporating both graph-based 200 McDonald and Nivre Analyzing and Integrating Dependency Parsers and transition-based features, that is, features over both sub-graphs and transitions. Huang and Sagae (2010) go even further and show how transition-based parsing can be tabularized to allow for dynamic programming, which in turn permits an exponentially larger search space. Martins et al. (2008) present a method for integrating graph-based and transition-based parsers based on stacking, which is similar to the approach taken in this work. Other studies have tried to overcome the weaknesses of parsing models by changing the underlying model structure directly. For example, Hall (2007), Riedel, C ¸ akıcı, and Meza-Ruiz (2006), Nakagawa (2007), Smith and Eisner (2008), and Martins, Smith, and Xing (2009) attempt to overcome local restrictions in feature scope for graphbased parsers through both approximations and exact solutions with integer linear programming. Our work differs from pas"
J11-1007,P09-1039,0,0.0517431,"Missing"
J11-1007,P90-1005,0,0.0773187,"er makes and how they relate to theoretical expectations. Using these observations, we present an integrated system based on a stacking learning framework and show that such a system can learn to overcome the shortcomings of each non-integrated system. 1. Introduction Syntactic dependency representations have a long history in descriptive and theoretical linguistics and many formal models have been advanced, most notably Word Grammar (Hudson 1984), Meaning-Text Theory (Mel’ˇcuk 1988), Functional Generative Description (Sgall, Hajiˇcov´a, and Panevov´a 1986), and Constraint Dependency Grammar (Maruyama 1990). Common to all theories is the notion of directed syntactic dependencies between the words of a sentence, an example of which is given in Figure 1 for the sentence A hearing is scheduled on the issue today, which has been extracted from the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993). A dependency graph of a sentence represents each word and its syntactic modiﬁers through labeled directed arcs, where each arc label comes from some ﬁnite set representing possible syntactic roles. Returning to our example in Figure 1, we can see multiple instances of labeled dependency relations s"
J11-1007,P05-1012,1,0.950348,"re Analyzing and Integrating Dependency Parsers dependency parsing. The ﬁrst category parameterizes models over dependency subgraphs and learns these parameters to globally score correct graphs above incorrect ones. Inference is also global, in that systems attempt to ﬁnd the highest scoring graph among the set of all graphs. We call such systems graph-based parsing models to reﬂect the fact that parameterization is over the graph. Graph-based models are mainly associated with the pioneering work of Eisner (Eisner 1996), as well as McDonald and colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006; McDonald, Lerman, and Pereira 2006) and others (Riedel, C ¸ akıcı, and Meza-Ruiz 2006; Carreras 2007; Koo et al. 2007; Nakagawa 2007; Smith and Smith 2007). The second category of parsing systems parameterizes models over transitions from one state to another in an abstract state-machine. Parameters in these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the g"
J11-1007,W06-2932,1,0.926364,"Missing"
J11-1007,D07-1013,1,0.937957,"Missing"
J11-1007,E06-1011,1,0.837671,"rating Dependency Parsers dependency parsing. The ﬁrst category parameterizes models over dependency subgraphs and learns these parameters to globally score correct graphs above incorrect ones. Inference is also global, in that systems attempt to ﬁnd the highest scoring graph among the set of all graphs. We call such systems graph-based parsing models to reﬂect the fact that parameterization is over the graph. Graph-based models are mainly associated with the pioneering work of Eisner (Eisner 1996), as well as McDonald and colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006; McDonald, Lerman, and Pereira 2006) and others (Riedel, C ¸ akıcı, and Meza-Ruiz 2006; Carreras 2007; Koo et al. 2007; Nakagawa 2007; Smith and Smith 2007). The second category of parsing systems parameterizes models over transitions from one state to another in an abstract state-machine. Parameters in these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest"
J11-1007,H05-1066,1,0.85104,"Missing"
J11-1007,W07-2216,1,0.519115,"to exist, but non-projective trees required approximate inference that used an exhaustive projective algorithm followed by transformations to the graph that incrementally introduce non-projectivity. In general, inference and learning for graph-based dependency parsing is NP-hard when the score is factored Figure 2 A graph-based parsing example. A dense graph Gx is shown on the left (arcs into the root are omitted) with corresponding arc scores. On the right is the predicted dependency tree based on Equation (1). 203 Computational Linguistics Volume 37, Number 1 over anything larger than arcs (McDonald and Satta 2007). Thus, graph-based parsing systems cannot easily condition on any extended scope of the dependency graph beyond a single arc, which is their primary shortcoming relative to transition-based systems. McDonald, Crammer, and Pereira (2005) show that a rich feature set over the input space, including lexical and surface syntactic features of neighboring words, can partially alleviate this problem, and both Carreras (2007) and Koo et al. (2010) explore higher-order models for projective trees. Additionally, work has been done on approximate non-factored parsing systems (McDonald and Pereira 2006;"
J11-1007,D07-1100,0,0.205097,"ally score correct graphs above incorrect ones. Inference is also global, in that systems attempt to ﬁnd the highest scoring graph among the set of all graphs. We call such systems graph-based parsing models to reﬂect the fact that parameterization is over the graph. Graph-based models are mainly associated with the pioneering work of Eisner (Eisner 1996), as well as McDonald and colleagues (McDonald, Crammer, and Pereira 2005; McDonald et al. 2005; McDonald and Pereira 2006; McDonald, Lerman, and Pereira 2006) and others (Riedel, C ¸ akıcı, and Meza-Ruiz 2006; Carreras 2007; Koo et al. 2007; Nakagawa 2007; Smith and Smith 2007). The second category of parsing systems parameterizes models over transitions from one state to another in an abstract state-machine. Parameters in these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based parsing models t"
J11-1007,W03-3017,1,0.908431,"tion, s(c, t) = g(f(c), t). Given a transition scoring function, the parsing problem consists in ﬁnding a terminal conﬁguration cm ∈ Cx , starting from the initial conﬁguration cx and taking the optimal transition t∗ out of every conﬁguration c: t∗ = arg max s(c, t) t∈T 2 http://mstparser.sourceforge.net. 204 McDonald and Nivre Analyzing and Integrating Dependency Parsers This can be seen as a greedy search for the optimal dependency graph, based on a sequence of locally optimal decisions in terms of the transition system. By way of example, we consider the transition system ﬁrst presented in Nivre (2003), where a parser conﬁguration is a triple c = (σ, β, A), consisting of a stack σ of partially processed nodes, a buffer β of remaining input nodes, and a set A of labeled dependency arcs. The initial conﬁguration for a sentence x = w0 , w1 , . . . , wn is cx = ([0], [1, . . . , n], ∅ ) and the set of terminal conﬁgurations Cx contains all conﬁgurations of the form c = (σ, [ ], A) (that is, all conﬁgurations with an empty buffer and with arbitrary σ and A). The set T of transitions for this system is speciﬁed in Figure 3. The transitions L EFT-A RCl and R IGHT-A RCl extend the arc set A with an"
J11-1007,N07-1050,1,0.884713,"Missing"
J11-1007,P09-1040,1,0.791945,"Missing"
J11-1007,W04-2407,1,0.801564,"Missing"
J11-1007,W06-2933,1,0.809035,"Missing"
J11-1007,P08-1108,1,0.456224,"G = (V, A) consisting of a set of nodes V and a set of labeled directed arcs A ⊆ V × V × L; that is, if (i, j, l) ∈ A for i, j ∈ V and l ∈ L, then there is an arc from node i to node j with label l in the graph. In terms of standard linguistic dependency theory nomenclature, we say that (i, j, l) ∈ A if there is a dependency with head wi , dependent wj , and syntactic role l. A dependency graph G for sentence x must satisfy the following properties: 1. V = {0, 1, . . . , n}. 2. If (i, j, l) ∈ A, then j = 0. 1 This work has previously been published partially in McDonald and Nivre (2007) and Nivre and McDonald (2008). 201 Computational Linguistics Volume 37, Number 1 3. If (i, j, l) ∈ A, then for all arcs (i , j, l ) ∈ A, i = i and l = l . 4. For all j ∈ V − {0}, either (0, j, l) for some l ∈ L or there is a non-empty sequence of nodes i1 , . . . , im ∈ V and labels l1 , . . . , lm+1 ∈ L such that (0, i1 , l1 ),(i1 , i2 , l2 ), . . . , (im , j, lm+1 )∈A. The ﬁrst constraint states that the dependency graph spans the entire input. The second constraint states that the node 0 is a root. The third constraint states that each node has at most one incoming arc in the graph. The ﬁnal constraint states that"
J11-1007,P05-1013,1,0.940866,"ransition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based parsing models to reﬂect the fact that parameterization is over possible state transitions. Transition-based models have been promoted by the groups of Matsumoto (Kudo and Matsumoto 2002; Yamada and Matsumoto 2003; Cheng, Asahara, and Matsumoto 2006), Nivre (Nivre, Hall, and Nilsson 2004; Nivre and Nilsson 2005; Nivre et al. 2006), and others (Attardi 2006; Attardi and Ciaramita 2007; Johansson and Nugues 2007; Duan, Zhao, and Xu 2007; Titov and Henderson 2007a, 2007b). It is important to note that there is no a priori reason why a graph-based parameterization should require global learning and inference, and a transition-based parameterization would necessitate local learning and greedy inference. Nevertheless, as observed by Buchholz and Marsi (2006), it is striking that recent work on data-driven dependency parsing has been dominated by global, exhaustive, graph-based models, on the one hand, and"
J11-1007,W06-1616,0,0.0475874,"approach could potentially result in substantial improvements. 3. Novel approaches: The theoretical analysis presented in this article reveals that the two dominant approaches are each based on a particular combination of training and inference methods, which raises the question of which other combinations can fruitfully be explored. For example, can we construct globally trained, greedy, transition-based parsers? Or graph-based parsers with global features? To some extent the former characterization ﬁts the approach of Zhang and Clark (2008) and Huang and Sagae (2010), and the latter that of Riedel and Clarke (2006), Nakagawa (2007), and others. The analysis presented in this section explains the relative success of such approaches. In the next two sections we explore a model that falls into category 2. The system we propose uses a two-stage stacking framework, where a second-stage parser conditions on the predictions of a ﬁrst-stage parser during inference. The second-stage parser is also learned with access to the ﬁrst-stage parser’s decisions and thus learns when to trust the ﬁrst-stage parser’s predictions and when to trust its own. The method is not a traditional ensemble, because the parsers are no"
J11-1007,W06-2934,0,0.0234066,"Missing"
J11-1007,N06-2033,0,0.569808,"ortantly, we rerun the error analysis and show that the integrated models do indeed take advantage of the complementary strengths of both the graph-based and transition-based parsing systems. Combining the strengths of different machine learning systems, and even parsing systems, is by no means new as there are a number of previous studies that have looked at combining phrase-structure parsers (Henderson and Brill 1999), dependency parsers ˇ (Zeman and Zabokrtsk y` 2005), or both (McDonald 2006). Of particular note is past work on combining graph-based and transition-based dependency parsers. Sagae and Lavie (2006) present a system that combines multiple transition-based parsers with a single graph-based parser by weighting each potential dependency relation by the number of parsers that predicted it. A ﬁnal dependency graph is predicted by using spanning tree inference algorithms from the graph-based parsing literature (McDonald et al. 2005). Sagae and Lavie report improvements of up to 1.7 percentage points over the best single parser when combining three transition-based models and one graph-based model for unlabeled dependency parsing, evaluated on data from the Penn Treebank. The same technique was"
J11-1007,N01-1023,0,0.0151753,"g features generated by the parsers of Collins (1999) and Charniak (2000), which improved unlabeled accuracy by 1.7 percentage points on data from the Penn Treebank. In other NLP domains, feature-based integration has been used by Taskar, Lacoste-Julien, and Klein (2005), who trained a discriminative word alignment model using features derived from the IBM models, by Florian et al. (2004), who trained classiﬁers on auxiliary data to guide named entity classiﬁers, and by others. Feature-based integration also has points in common with co-training, which has been applied to syntactic parsing by Sarkar (2001) and Steedman et al. (2003), among others. The difference, of course, is that standard co-training is a weakly supervised method, where the ﬁrst-stage parser’s predictions replace, rather than complement, the gold standard annotation during training. Feature-based integration is also similar to parse reranking (Collins 2000), where one parser produces a set of candidate parses and a second-stage classiﬁer chooses the most likely one. However, feature-based integration is not explicitly constrained to any parse decisions that the ﬁrst-stage parser might make. Furthermore, as only the single mos"
J11-1007,D08-1016,0,0.0834247,"r both sub-graphs and transitions. Huang and Sagae (2010) go even further and show how transition-based parsing can be tabularized to allow for dynamic programming, which in turn permits an exponentially larger search space. Martins et al. (2008) present a method for integrating graph-based and transition-based parsers based on stacking, which is similar to the approach taken in this work. Other studies have tried to overcome the weaknesses of parsing models by changing the underlying model structure directly. For example, Hall (2007), Riedel, C ¸ akıcı, and Meza-Ruiz (2006), Nakagawa (2007), Smith and Eisner (2008), and Martins, Smith, and Xing (2009) attempt to overcome local restrictions in feature scope for graphbased parsers through both approximations and exact solutions with integer linear programming. Our work differs from past studies in that we attempt to quantify exactly the types of errors these parsers make, tie them to their theoretical expectations, and show that integrating graph-based and transition-based parsers not only increases overall accuracy, but does so directly exploiting the strengths of each system. Thus, this is the ﬁrst large-scale error analysis of modern data-driven depend"
J11-1007,D07-1014,0,0.0152176,"Missing"
J11-1007,H05-1010,0,0.0185543,"Missing"
J11-1007,D07-1099,0,0.0360841,"Missing"
J11-1007,W07-2218,0,0.156608,"construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based parsing models to reﬂect the fact that parameterization is over possible state transitions. Transition-based models have been promoted by the groups of Matsumoto (Kudo and Matsumoto 2002; Yamada and Matsumoto 2003; Cheng, Asahara, and Matsumoto 2006), Nivre (Nivre, Hall, and Nilsson 2004; Nivre and Nilsson 2005; Nivre et al. 2006), and others (Attardi 2006; Attardi and Ciaramita 2007; Johansson and Nugues 2007; Duan, Zhao, and Xu 2007; Titov and Henderson 2007a, 2007b). It is important to note that there is no a priori reason why a graph-based parameterization should require global learning and inference, and a transition-based parameterization would necessitate local learning and greedy inference. Nevertheless, as observed by Buchholz and Marsi (2006), it is striking that recent work on data-driven dependency parsing has been dominated by global, exhaustive, graph-based models, on the one hand, and local, greedy, transition-based models, on the other. Therefore, a careful comparative analysis of these model types appears highly relevant, and this"
J11-1007,W03-3023,0,0.17081,"these models are typically learned using standard classiﬁcation techniques that learn to predict one transition from a set of permissible transitions given a state history. Inference is local, in that systems start in a ﬁxed initial state and greedily construct the graph by taking the highest scoring transitions at each state entered until a termination condition is met. We call such systems transition-based parsing models to reﬂect the fact that parameterization is over possible state transitions. Transition-based models have been promoted by the groups of Matsumoto (Kudo and Matsumoto 2002; Yamada and Matsumoto 2003; Cheng, Asahara, and Matsumoto 2006), Nivre (Nivre, Hall, and Nilsson 2004; Nivre and Nilsson 2005; Nivre et al. 2006), and others (Attardi 2006; Attardi and Ciaramita 2007; Johansson and Nugues 2007; Duan, Zhao, and Xu 2007; Titov and Henderson 2007a, 2007b). It is important to note that there is no a priori reason why a graph-based parameterization should require global learning and inference, and a transition-based parameterization would necessitate local learning and greedy inference. Nevertheless, as observed by Buchholz and Marsi (2006), it is striking that recent work on data-driven de"
J11-1007,W05-1518,0,0.0840469,"odels, on the other. Therefore, a careful comparative analysis of these model types appears highly relevant, and this is what we will try to provide in this article. For convenience, we will use the shorthand terms “graph-based” and “transition-based” for these models, although both graph-based and transition-based parameterizations can be (and have been) combined with different types of learning and inference. For example, the system described by Zhang and Clark (2008) could be characterized as a transition-based model with global learning, and the ˇ ensemble system of Zeman and Zabokrtsk y` (2005) as a graph-based model with greedy inference. Perhaps the most interesting reason to study the canonical graph-based and transition-based models is that even though they appear to be quite different theoretically (see Section 2), recent empirical studies show that both obtain similar parsing accuracies on a variety of languages. For example, Table 1 shows the results of the two top performing systems in the CoNLL-X shared task, those of McDonald, Lerman, and Pereira (2006) (graph-based) and Nivre et al. (2006) (transition-based), which exhibit no statistically signiﬁcant difference in accurac"
J11-1007,D08-1059,0,0.597677,"data-driven dependency parsing has been dominated by global, exhaustive, graph-based models, on the one hand, and local, greedy, transition-based models, on the other. Therefore, a careful comparative analysis of these model types appears highly relevant, and this is what we will try to provide in this article. For convenience, we will use the shorthand terms “graph-based” and “transition-based” for these models, although both graph-based and transition-based parameterizations can be (and have been) combined with different types of learning and inference. For example, the system described by Zhang and Clark (2008) could be characterized as a transition-based model with global learning, and the ˇ ensemble system of Zeman and Zabokrtsk y` (2005) as a graph-based model with greedy inference. Perhaps the most interesting reason to study the canonical graph-based and transition-based models is that even though they appear to be quite different theoretically (see Section 2), recent empirical studies show that both obtain similar parsing accuracies on a variety of languages. For example, Table 1 shows the results of the two top performing systems in the CoNLL-X shared task, those of McDonald, Lerman, and Pere"
J11-1007,J03-4003,0,\N,Missing
J11-1007,D07-1096,1,\N,Missing
J13-1002,N09-2066,0,0.025541,"Missing"
J13-1002,W06-2920,0,0.118821,"de does not correspond to an input token, it has no welldeﬁned position in the node sequence deﬁned by the word order of a sentence and could in principle be inserted anywhere (or nowhere at all). One option that can be found in the literature is to insert it at the end of this sequence, but the more common convention in contemporary research on dependency parsing is to insert it at the beginning, hence treating it as a dummy word preﬁxed to the sentence. This is also the choice implicitly assumed in the CoNLL data format, used in the CoNLL shared tasks on dependency parsing in 2006 and 2007 (Buchholz and Marsi 2006; Nivre et al. 2007) and the current de facto standard for exchange of dependency annotated data. The question that concerns us here is whether the use of a dummy root node is just a harmless technicality permitting us to treat different dependency theories uniformly, and whether its placement in the input sequence is purely arbitrary, or whether both of these choices may in fact have an impact on the parsing accuracy that can be achieved with a given parsing model. In order to investigate this question empirically, we deﬁne three different types of dependency graphs that differ only with resp"
J13-1002,de-marneffe-etal-2006-generating,0,0.0131845,"type None is not a tree, but a forest, because it consists of two disjoint trees. 3. Experiments In order to test the hypothesis that the existence and placement of the dummy root node can have an impact on parsing accuracy, we performed an experiment using two widely used data-driven dependency parsers, MaltParser (Nivre, Hall, and Nilsson 2006) and MSTParser (McDonald 2006), and all the 13 data sets from the CoNLL 2006 shared task on multilingual dependency parsing (Buchholz and Marsi 2006) as well as the English Penn Treebank converted to Stanford dependencies (de Marneffe, MacCartney, and Manning 2006). We created three different versions of each data set, corresponding to the representation types None, First, and Last, and used them to evaluate MaltParser with two different transition systems—arc-eager (Nivre 2003) and arc-standard (Nivre 2004)—and MSTParser with the arc-factored non-projective algorithm (McDonald et al. 2005). The results are shown in Table 1. When creating the data sets, we took the original version from the CoNLL-X shared task as None, because it does not include the dummy root node as an explicit input token. In this representation, the tokens of a sentence are indexed"
J13-1002,D07-1097,1,0.473771,"rties is clearly outside the scope of this article and has to be left for future research. Another limitation of the current study is that it only examines three different parsers, and although this is clearly sufﬁcient to prove the existence of the phenomenon it will be interesting to see whether the same patterns can be found if we examine more recent state-of-the-art methods, going from deterministic parsing to beam search for transition-based parsing and from arc-factored to higher-order models for graph-based parsing. In this context, it is also relevant to mention previous work, such as Hall et al. (2007) and Attardi and Dell’Orletta (2009), which have tried to improve parsing accuracy by switching or 11 Computational Linguistics Volume 39, Number 1 combining parsing directions, which implicitly has the effect of changing the position of the root node (if present). In conclusion, we believe there may be two methodological lessons to learn from our experiments. The ﬁrst is that, for certain parsing models, the existence and placement of the dummy root node is in fact a parameter worth tuning for best performance. Thus, for the deterministic arc-eager parser, it seems that we can obtain higher p"
J13-1002,J93-2004,0,0.0462133,"Missing"
J13-1002,H05-1066,0,0.0254842,"Missing"
J13-1002,W03-3017,1,0.603484,"acy, we performed an experiment using two widely used data-driven dependency parsers, MaltParser (Nivre, Hall, and Nilsson 2006) and MSTParser (McDonald 2006), and all the 13 data sets from the CoNLL 2006 shared task on multilingual dependency parsing (Buchholz and Marsi 2006) as well as the English Penn Treebank converted to Stanford dependencies (de Marneffe, MacCartney, and Manning 2006). We created three different versions of each data set, corresponding to the representation types None, First, and Last, and used them to evaluate MaltParser with two different transition systems—arc-eager (Nivre 2003) and arc-standard (Nivre 2004)—and MSTParser with the arc-factored non-projective algorithm (McDonald et al. 2005). The results are shown in Table 1. When creating the data sets, we took the original version from the CoNLL-X shared task as None, because it does not include the dummy root node as an explicit input token. In this representation, the tokens of a sentence are indexed from 1 to n and the dependency graph is speciﬁed by giving each word a head index ranging from 0 to n, where 0 signiﬁes that the token is not a dependent on any other token in the sentence. The First version was creat"
J13-1002,W04-0308,1,0.783459,"t using two widely used data-driven dependency parsers, MaltParser (Nivre, Hall, and Nilsson 2006) and MSTParser (McDonald 2006), and all the 13 data sets from the CoNLL 2006 shared task on multilingual dependency parsing (Buchholz and Marsi 2006) as well as the English Penn Treebank converted to Stanford dependencies (de Marneffe, MacCartney, and Manning 2006). We created three different versions of each data set, corresponding to the representation types None, First, and Last, and used them to evaluate MaltParser with two different transition systems—arc-eager (Nivre 2003) and arc-standard (Nivre 2004)—and MSTParser with the arc-factored non-projective algorithm (McDonald et al. 2005). The results are shown in Table 1. When creating the data sets, we took the original version from the CoNLL-X shared task as None, because it does not include the dummy root node as an explicit input token. In this representation, the tokens of a sentence are indexed from 1 to n and the dependency graph is speciﬁed by giving each word a head index ranging from 0 to n, where 0 signiﬁes that the token is not a dependent on any other token in the sentence. The First version was created by adding an extra token at"
J13-1002,nivre-etal-2006-maltparser,1,0.0564195,"Missing"
J13-1002,P05-1013,1,0.0505385,"makes the parser start with an empty stack instead of a stack containing an extra dummy root node.2 For MSTParser, we modiﬁed the parser implementation so that it extracts a maximum spanning tree that is still rooted in an extra dummy root node but where the score of a tree is based only on the scores of arcs connecting real token nodes. Finally, because MaltParser with the arc-eager and arc-standard transition systems can only construct projective dependency graphs, we projectivized all training sets before training the MaltParser models using the baseline pseudo-projective transformation of Nivre and Nilsson (2005).3 Except for these modiﬁcations, all parsers were run with out-of-the-box settings. 3.1 Deterministic Arc-Eager Parsing The arc-eager transition-based parser ﬁrst described in Nivre (2003) parses a sentence in a single pass from left to right, using a stack to store partially processed tokens and greedily choosing the highest-scoring parsing action at each point. The arc-eager property entails that every arc in the output graph is added at the earliest possible opportunity, which means that right-dependents are attached to their head before they have found their own right-dependents. This can"
J13-1002,J14-2001,1,\N,Missing
J13-1002,D07-1096,1,\N,Missing
J13-1003,P05-1038,0,0.0571577,"Missing"
J13-1003,P08-1067,0,0.0549641,"Missing"
J13-1003,P03-1054,0,0.0158058,"odern Standard Arabic (Semitic) and French (Romance), the last article of this special issue, by Green et al., may be seen as an applications paper, treating the task of MWE recognition as a side effect of a joint model for parsing and MWE identiﬁcation. The key problem here is knowing what to consider a minimal unit for parsing, and how to handle parsing in realistic scenarios where MWEs have not yet been identiﬁed. The authors present two parsing models for such a task: a factored model including a factored lexicon that integrates morphological knowledge into the Stanford Parser word model (Klein and Manning 2003), and a Dirichlet Process Tree Substitution Grammar based model (Cohn, Blunsom, and Goldwater 2010). The latter can be roughly described as Data Oriented Parsing (Bod 1992; Bod, Scha, and Sima’an 2003) in a Bayesian framework, extended to include speciﬁc features that ease the extraction of tree fragments matching MWEs. Interestingly, those very different models do provide the same range of performance when confronted with predicted morphology input. Additional important challenges that are exposed in the context of this study concern the design of experiments for cross-linguistic comparison i"
J13-1003,P95-1037,0,0.302286,"Missing"
J13-1003,J93-2004,0,0.0463151,"Missing"
J13-1003,P06-1055,0,0.078628,"een, de Marneffe, and Manning 2013 Kallmeyer and Maier 2013 Fraser et al. 2013 Goldberg and Elhadad 2013 Seeker and Kuhn 2013 Seeker and Kuhn 2013 Tsarfaty et al. Parsing Morphologically Rich Languages: predicate-argument constraints allows the authors to obtain more substantial gains from morphology. Fraser et al. also focus on parsing German, though in a constituency-based setting. They use a PCFG-based unlexicalized chart parser (Schmid 2004) along with a set of manual treebank annotations that bring the treebank grammar performance to the level of automatically predicted states learned by Petrov et al. (2006). As in the previous study, syncretism is shown to cause ambiguity that hurts parsing performance. To combat this added ambiguity, they use external information sources. In particular, they show different ways of using information from monolingual and bilingual data sets in a re-ranking framework for improving parsing accuracy. The bilingual approach is inspired by machine translation studies and exploits the variation in marking the same grammatical functions differently across languages for increasing the conﬁdence of a disambiguation decision in one language by observing a parallel non-ambi"
J13-1003,C04-1024,0,0.0319019,"French German Hebrew Hungarian 18 Constituency-Based Dependency-Based Green, de Marneffe, and Manning 2013 Marton, Habash, and Rambow 2013 Seeker and Kuhn 2013 Green, de Marneffe, and Manning 2013 Kallmeyer and Maier 2013 Fraser et al. 2013 Goldberg and Elhadad 2013 Seeker and Kuhn 2013 Seeker and Kuhn 2013 Tsarfaty et al. Parsing Morphologically Rich Languages: predicate-argument constraints allows the authors to obtain more substantial gains from morphology. Fraser et al. also focus on parsing German, though in a constituency-based setting. They use a PCFG-based unlexicalized chart parser (Schmid 2004) along with a set of manual treebank annotations that bring the treebank grammar performance to the level of automatically predicted states learned by Petrov et al. (2006). As in the previous study, syncretism is shown to cause ambiguity that hurts parsing performance. To combat this added ambiguity, they use external information sources. In particular, they show different ways of using information from monolingual and bilingual data sets in a re-ranking framework for improving parsing accuracy. The bilingual approach is inspired by machine translation studies and exploits the variation in mar"
J13-1003,A97-1014,0,0.288535,"Missing"
J13-1003,W10-1401,1,0.919998,"Missing"
J13-1003,W07-2219,1,0.883448,"Missing"
J13-1003,A00-2018,0,\N,Missing
J13-1003,C10-1011,0,\N,Missing
J13-1003,P97-1003,0,\N,Missing
J13-1003,W06-2920,0,\N,Missing
J13-1003,W08-2102,0,\N,Missing
J13-1003,P05-1022,0,\N,Missing
J13-1003,P08-1109,0,\N,Missing
J13-1003,C92-3126,0,\N,Missing
J13-1003,P99-1065,0,\N,Missing
J13-1003,P03-1013,0,\N,Missing
J13-1003,D07-1096,1,\N,Missing
J13-1003,N10-1115,0,\N,Missing
J13-4002,afonso-etal-2002-floresta,0,0.0174617,"Missing"
J13-4002,W03-2405,0,0.0646346,"Missing"
J13-4002,W06-2922,0,0.0770697,"k ´ Universidade da Coruna, ˜ Facultad de Informtica, Campus de Elvina ˜ ∗ Departamento de Computacion, ˜ Spain. E-mail: cgomezr@udc.es. s/n, 15071 A Coruna, ∗∗ Department of Linguistics and Philology, Uppsala University, Box 635, 75126 Uppsala, Sweden. E-mail: joakim.nivre@lingfil.uu.se. Submission received: 13 October 2011; revised submission received: 29 August 2012; accepted for publication: 7 November 2012. doi:10.1162/COLI a 00150 © 2013 Association for Computational Linguistics Computational Linguistics Volume 39, Number 4 data (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; Attardi 2006; Zhang and Clark 2008). Transition systems for dependency parsing come in many different varieties, and our aim in the first part of this article is to deepen our understanding of these systems by analyzing them in a uniform framework. More precisely, we demonstrate that a number of well-known systems from the literature can all be viewed as variants of a stack-based system with five elementary transitions, where different variants are obtained by composing elementary transitions into complex transitions and by adding restrictions on their applicability. We call such systems divisible transit"
J13-4002,P08-2037,0,0.0214824,"Missing"
J13-4002,W06-2920,0,0.0549636,"related to the three main themes of the article: a formal framework for analyzing and constructing transition systems for dependency parsing (Section 3), a procedure for classifying mildly non-projective dependency structures in terms of multiplanarity (Section 4), and a novel transition-based parser for (a subclass of) non-projective dependency structures (Section 5). 6.1 Frameworks for Dependency Parsing Due to the growing popularity of dependency parsing, several proposals have been made that group and study different dependency parsers under common (more or less formal) frameworks. Thus, Buchholz and Marsi (2006) observed that almost all of the systems participating in the CoNLL-X shared task could be classified as belonging to one of two approaches, which they called the “all pairs” and the “stepwise” approaches. This was taken up by McDonald and Nivre (2007), who called the first approach global exhaustive graph-based parsing and the second approach local greedy transition-based parsing. The terms graph-based and transition-based have become well established, even though there now exist graph-based models that do not perform exhaustive search (McDonald and Pereira 2006; Koo et al. 2010) as well as t"
J13-4002,D10-1096,0,0.0247155,"contributions of this article. 2. Dependency Parsing Dependency parsing is based on the idea that syntactic structure can be analyzed in terms of binary, asymmetric relations between the words of a sentence, an idea that has a long tradition in descriptive and theoretical linguistics (Tesni`ere 1959; Sgall, Hajiˇcov´a, and Panevov´a 1986; Mel’ˇcuk 1988; Hudson 1990). In computational linguistics, dependency structures have become increasingly popular in the interface to downstream applications of parsing, such as information extraction (Culotta and Sorensen 2004; Stevenson and Greenwood 2006; Buyko and Hahn 2010), question answering (Shen and Klakow 2006; Bikel and Castelli 2008), and machine translation (Quirk, Menezes, and Cherry 2005; Xu et al. 2009). And although dependency structures can easily be extracted from other syntactic representations, such as phrase structure trees, this has also led to an increased interest in statistical parsers that specifically produce dependency trees (Eisner 1996; Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005). Current approaches to statistical dependency parsing can be broadly grouped into graph-based and transition"
J13-4002,D07-1101,0,0.0189155,"al parsers that specifically produce dependency trees (Eisner 1996; Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005). Current approaches to statistical dependency parsing can be broadly grouped into graph-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transit"
J13-4002,D11-1114,1,0.919296,"Missing"
J13-4002,E09-1034,1,0.929585,"Missing"
J13-4002,P07-1077,0,0.51504,"of departure for addressing the problem of non-projective dependency parsing. Despite the impressive results obtained with dependency parsers limited to strictly projective dependency trees—that is, trees where every subtree has a contiguous yield—it is clear that most if not all languages have syntactic constructions whose analysis requires nonprojective trees. It is also clear, however, that allowing arbitrary non-projective trees makes parsing computationally hard (McDonald and Satta 2007) and does not seem justified by the data in available treebanks (Kuhlmann and Nivre 2006; Nivre 2006a; Havelka 2007). This suggests that we should try to find a superset of projective trees that is permissive enough to encompass constructions found in natural language yet restricted enough to permit efficient parsing. Proposals for such a set include trees with bounded arc degree (Nivre 2006a, 2007), well-nested trees with bounded gap degree ¨ 2007), as well as trees parsable by a (Kuhlmann and Nivre 2006; Kuhlmann and Mohl particular transition system such as that proposed by Attardi (2006). In the same vein, Yli-Jyr¨a (2003) introduced the concept of multiplanarity, which generalizes the simple notion of"
J13-4002,D09-1127,0,0.0258658,"Missing"
J13-4002,P10-1110,0,0.221086,"d Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only one of them concerns quality.”) AuxP ✞ ROOT 1  ✞ Adv  ❄ ❄ na7 kvalitu8 quality to ❄ .9 .) Figure 1 Dependency graph for a Czech sentence from the Prague Dependency Treebank. greedy, deterministic parsing (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; Attardi 2006; Nivre 2008), but globally trained models and non-greedy parsing methods such as beam search are increasingly used (Johansson and Nugues 2006; Titov and Henderson 2007; Zhang and Clark 2008; Huang, Jiang, and Liu 2009; Huang and Sagae 2010; Zhang and Nivre 2011). In empirical evaluations, the two main approaches to dependency parsing often achieve very similar accuracy, but transition-based parsers tend to be more efficient. In this article, we will be concerned exclusively with transitionbased models. In the remainder of this background section, we first introduce the syntactic representations used by dependency parsers, starting from a general characterization of dependency graphs and discussing a number of different restrictions of this class that will be relevant for the analysis later on. We then go on to review the formal"
J13-4002,W06-2930,0,0.160963,"ied on local optimization and 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only one of them concerns quality.”) AuxP ✞ ROOT 1  ✞ Adv  ❄ ❄ na7 kvalitu8 quality to ❄ .9 .) Figure 1 Dependency graph for a Czech sentence from the Prague Dependency Treebank. greedy, deterministic parsing (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; Attardi 2006; Nivre 2008), but globally trained models and non-greedy parsing methods such as beam search are increasingly used (Johansson and Nugues 2006; Titov and Henderson 2007; Zhang and Clark 2008; Huang, Jiang, and Liu 2009; Huang and Sagae 2010; Zhang and Nivre 2011). In empirical evaluations, the two main approaches to dependency parsing often achieve very similar accuracy, but transition-based parsers tend to be more efficient. In this article, we will be concerned exclusively with transitionbased models. In the remainder of this background section, we first introduce the syntactic representations used by dependency parsers, starting from a general characterization of dependency graphs and discussing a number of different restrictions"
J13-4002,P98-1106,0,0.184386,"Missing"
J13-4002,P10-1001,0,0.0157734,"specifically produce dependency trees (Eisner 1996; Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005). Current approaches to statistical dependency parsing can be broadly grouped into graph-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transition-based parsers have"
J13-4002,D10-1125,0,0.0383413,"Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transition-based parsers have relied on local optimization and 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only one of them concerns quality.”) AuxP ✞ ROOT 1  ✞ Adv  ❄ ❄ na7 kvalitu8"
J13-4002,P11-1068,1,0.869244,"Missing"
J13-4002,P07-1021,0,0.0362611,"Missing"
J13-4002,P06-2066,1,0.714911,"he planar parsing system as our point of departure for addressing the problem of non-projective dependency parsing. Despite the impressive results obtained with dependency parsers limited to strictly projective dependency trees—that is, trees where every subtree has a contiguous yield—it is clear that most if not all languages have syntactic constructions whose analysis requires nonprojective trees. It is also clear, however, that allowing arbitrary non-projective trees makes parsing computationally hard (McDonald and Satta 2007) and does not seem justified by the data in available treebanks (Kuhlmann and Nivre 2006; Nivre 2006a; Havelka 2007). This suggests that we should try to find a superset of projective trees that is permissive enough to encompass constructions found in natural language yet restricted enough to permit efficient parsing. Proposals for such a set include trees with bounded arc degree (Nivre 2006a, 2007), well-nested trees with bounded gap degree ¨ 2007), as well as trees parsable by a (Kuhlmann and Nivre 2006; Kuhlmann and Mohl particular transition system such as that proposed by Attardi (2006). In the same vein, Yli-Jyr¨a (2003) introduced the concept of multiplanarity, which gener"
J13-4002,E09-1055,0,0.015666,".9 4.1 Test for Multiplanarity In order for a constraint on non-projective dependency structures to be useful for practical parsing, it must provide a good balance between parsing efficiency and coverage of non-projective phenomena present in natural language treebanks. For example, Kuhlmann and Nivre (2006) and Havelka (2007) have shown that the vast majority of structures present in existing treebanks are well-nested and have a small gap de¨ 2005), leading to an interest in parsers for these gree (Bodirsky, Kuhlmann, and Mohl ´ kinds of structures (Gomez-Rodr´ ıguez, Weir, and Carroll 2009; Kuhlmann and Satta 2009). No similar analysis has been performed for k-planar structures, however. Yli-Jyr¨a (2003) does provide evidence that all except two structures in the Danish Dependency Treebank (Kromann 2003) are at most 3-planar, but his analysis is based on constraints that restrict the possible ways of assigning planes to dependency arcs, and he is not guaranteed to find the minimal number k for which a given structure is k-planar. Here we provide a procedure for finding the minimal natural number k such that a dependency graph is k-planar and use it to show that the vast majority of sentences in a number"
J13-4002,J93-2004,0,0.0497908,"Missing"
J13-4002,H94-1020,0,0.038301,"existing and novel transitionbased models. Finally, we discuss the implementation of efficient parsers based on these transition systems. 2.1 Dependency Graphs In dependency parsing, the syntactic structure of a sentence is modeled by a dependency graph, which represents each token and its syntactic dependents through labeled, directed arcs. This is exemplified in Figure 1 for a Czech sentence taken from the Prague ¨ Dependency Treebank (Hajiˇc et al. 2001; Bohmov´ a et al. 2003), and in Figure 2 for an English sentence taken from the Penn Treebank (Marcus, Santorini, and Marcinkiewicz 1993; Marcus et al. 1994).1 In the former case, an artificial token ROOT has been inserted at the beginning of the sentence, serving as the unique root of the graph and ensuring that the graph is a tree even if more than one token is independent of all other tokens. In the latter case, no such device has been used, and we will not in general assume the existence of an artificial root node prefixed to the sentence, although all our models will be compatible with such a device. 1 The dependency graph has in this case been derived automatically from the constituency-based annotation in the treebank using standard head-fi"
J13-4002,P09-1039,0,0.038063,"Missing"
J13-4002,D10-1004,0,0.0132273,"hbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transition-based parsers have relied on local optimization and 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only one of them concerns quality.”) AuxP ✞ ROOT 1  ✞ Adv  ❄ ❄ na7 kvalitu8 quality to ❄ .9 .) Fig"
J13-4002,P05-1012,0,0.0950336,"Missing"
J13-4002,D07-1013,1,0.889495,"Missing"
J13-4002,E06-1011,0,0.309445,"to statistical dependency parsing can be broadly grouped into graph-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transition-based parsers have relied on local optimization and 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only"
J13-4002,W07-2216,0,0.352462,"s that are assumed in most existing systems. In the second part of the article, we take the planar parsing system as our point of departure for addressing the problem of non-projective dependency parsing. Despite the impressive results obtained with dependency parsers limited to strictly projective dependency trees—that is, trees where every subtree has a contiguous yield—it is clear that most if not all languages have syntactic constructions whose analysis requires nonprojective trees. It is also clear, however, that allowing arbitrary non-projective trees makes parsing computationally hard (McDonald and Satta 2007) and does not seem justified by the data in available treebanks (Kuhlmann and Nivre 2006; Nivre 2006a; Havelka 2007). This suggests that we should try to find a superset of projective trees that is permissive enough to encompass constructions found in natural language yet restricted enough to permit efficient parsing. Proposals for such a set include trees with bounded arc degree (Nivre 2006a, 2007), well-nested trees with bounded gap degree ¨ 2007), as well as trees parsable by a (Kuhlmann and Nivre 2006; Kuhlmann and Mohl particular transition system such as that proposed by Attardi (2006)."
J13-4002,D07-1100,0,0.014919,"ouped into graph-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transition-based parsers have relied on local optimization and 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only on"
J13-4002,W03-3017,1,0.874328,"its transitions can be written as a composition of restrictions of the elementary transitions S HIFT, U NSHIFT, R EDUCE, L EFT-A RC, and R IGHT-A RC. Note that the definition allows the use of unrestricted elementary transitions in the composition, because for any transition t, we have that t C = t.4 3.1 Examples of Divisible Transition Systems In this section, we show that a number of transition-based parsers from the literature use divisible transition systems that can be defined using only elementary transitions. This includes the arc-eager and arc-standard projective parsers described in Nivre (2003) and Nivre (2008), the arc-eager and arc-standard parsers for directed acyclic graphs from ´ Sagae and Tsujii (2008), the hybrid parser of Kuhlmann, Gomez-Rodr´ ıguez, and Satta (2011), and the easy-first parser of Goldberg and Elhadad (2010). We also give examples of transition systems that are not divisible (Attardi 2006; Nivre 2009). First of all, we define four standard subsets of the configuration set C: Hσ (C) = {(σ|i, β, A) ∈ C |∃j : ( j, i) ∈ A} Hσ (C) = {(σ|i, β, A) ∈ C |¬∃j : ( j, i) ∈ A} Hβ (C) = {(σ, i|β, A) ∈ C |∃j : ( j, i) ∈ A} Hβ (C) = {(σ, i|β, A) ∈ C |¬∃j : ( j, i) ∈ A} The s"
J13-4002,W04-0308,1,0.279576,"left-headed arc, S HIFT and R EDUCE jointly remove the dependent of the new arc from the buffer, and U NSHIFT moves the head of the new arc back to the buffer so that it can find a head to the left. It is worth noting that the arc-standard system for projective trees does not make use of restrictions. Although this description of the arc-standard parser corresponds to its definition in Nivre (2008), where arcs are created involving the topmost stack node and the first buffer node, the system has also been presented in an equivalent form with arcs built between the two top nodes in the stack (Nivre 2004). This variant can also be described as a divisible transition system, with L EFT-A RCAS = U NSHIFT; L EFT-A RC; R EDUCE; S HIFT and R IGHT-A RCAS = U NSHIFT; R IGHT-A RC; S HIFT; R EDUCE.5 Example 4 Nivre’s (2003) arc-eager parser is a parser for projective dependency trees, which adds arcs in a strict left-to-right order using the following transitions: S HIFTAE = S HIFT R EDUCEAE = R EDUCE L EFT-A RCAE = L EFT-A RC R IGHT-A RCAE = R IGHT-A RC; S HIFT Hσ (C) Hσ (C) ; R EDUCE As in the first example, the S HIFTAE transition is equivalent to the elementary S HIFT transition, but the R IGHT-A"
J13-4002,N07-1050,1,0.930228,"lakow 2006; Bikel and Castelli 2008), and machine translation (Quirk, Menezes, and Cherry 2005; Xu et al. 2009). And although dependency structures can easily be extracted from other syntactic representations, such as phrase structure trees, this has also led to an increased interest in statistical parsers that specifically produce dependency trees (Eisner 1996; Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005). Current approaches to statistical dependency parsing can be broadly grouped into graph-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al."
J13-4002,J08-4003,1,0.0530427,"plexity. Finally, we show that the 2-planar parser, when evaluated on data sets with a non-negligible proportion of non-projective trees, gives significant improvements in parsing accuracy over the corresponding 1-planar and projective parsers, and provides comparable accuracy to the widely used arc-eager pseudo-projective parser. 800 ´ Gomez-Rodr´ ıguez and Nivre Divisible Transition Systems and Multiplanarity The remainder of the article is structured as follows. Section 2 reviews basic concepts of dependency parsing and in particular the formalization of stack-based transition systems from Nivre (2008). Section 3 introduces our system of elementary transitions, uses it to analyze a number of parsing algorithms from the literature as divisible transition systems, proves a number of theoretical results about the expressivity and complexity of such systems, and finally introduces a divisible transition system for 1-planar dependency parsing. Section 4 reviews the notion of multiplanarity, introduces an efficient procedure for determining the smallest k for which a dependency tree is k-planar, and uses this procedure in an empirical investigation of available dependency treebanks. Section 5 sho"
J13-4002,P09-1040,1,0.556945,"Missing"
J13-4002,W04-2407,1,0.771115,"Missing"
J13-4002,nivre-etal-2006-maltparser,1,0.817796,"idely used method for nonprojective transition-based parsing and as such a competitive baseline for the 2-planar parser. In order to make the comparison as exact as possible, we have chosen to implement all four systems in the MaltParser framework and use the same type of classifiers and feature models. For the arc-eager baselines, we copy the set-up from the CoNLL-X shared task on dependency parsing, which includes the use of support vector machines with a polynomial kernel, history-based feature models tuned separately for each language, and pseudo-projective parsing with the Head encoding (Nivre et al. 2006). For the 1-planar and 2-planar parsers, we use the same type of classifier but modify the feature model to take into account the following systematic differences between the transition systems: r r In both the 1-planar and 2-planar parser, we need to add features over the arc connecting the top node of the stack and the first node of the buffer (if any). No such arc can exist in the arc-eager system used by the projective and pseudo-projective baseline systems. In the 2-planar parser, we need to add features over the top nodes of the inactive stack. No such nodes exist in the 1-planar and arc"
J13-4002,W06-2933,1,0.732346,"Missing"
J13-4002,P05-1013,1,0.930901,"ich is a planar graph with n nodes. Moreover, if the S INGLE -H EAD and A CYCLICITY constraints are used, the maximum number of arcs is n − 1, because every node can have at most one incoming arc and there must be at least one root. 835 Computational Linguistics Volume 39, Number 4 algorithm in MaltParser (Nivre, Hall, and Nilsson 2006), this system is also the basis of the ISBN Dependency Parser (Titov and Henderson 2007) and ZPar (Zhang and Clark 2008; Zhang and Nivre 2011). In addition to a strictly projective arc-eager parser, we also include a version that uses pseudo-projective parsing (Nivre and Nilsson 2005) to recover non-projective arcs. This is the most widely used method for nonprojective transition-based parsing and as such a competitive baseline for the 2-planar parser. In order to make the comparison as exact as possible, we have chosen to implement all four systems in the MaltParser framework and use the same type of classifiers and feature models. For the arc-eager baselines, we copy the set-up from the CoNLL-X shared task on dependency parsing, which includes the use of support vector machines with a polynomial kernel, history-based feature models tuned separately for each language, and"
J13-4002,P05-1034,0,0.0361201,"Missing"
J13-4002,W06-1616,0,0.0173853,"arsing can be broadly grouped into graph-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transition-based parsers have relied on local optimization and 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM"
J13-4002,C08-1095,0,0.0920755,"NSHIFT, R EDUCE, L EFT-A RC, and R IGHT-A RC. Note that the definition allows the use of unrestricted elementary transitions in the composition, because for any transition t, we have that t C = t.4 3.1 Examples of Divisible Transition Systems In this section, we show that a number of transition-based parsers from the literature use divisible transition systems that can be defined using only elementary transitions. This includes the arc-eager and arc-standard projective parsers described in Nivre (2003) and Nivre (2008), the arc-eager and arc-standard parsers for directed acyclic graphs from ´ Sagae and Tsujii (2008), the hybrid parser of Kuhlmann, Gomez-Rodr´ ıguez, and Satta (2011), and the easy-first parser of Goldberg and Elhadad (2010). We also give examples of transition systems that are not divisible (Attardi 2006; Nivre 2009). First of all, we define four standard subsets of the configuration set C: Hσ (C) = {(σ|i, β, A) ∈ C |∃j : ( j, i) ∈ A} Hσ (C) = {(σ|i, β, A) ∈ C |¬∃j : ( j, i) ∈ A} Hβ (C) = {(σ, i|β, A) ∈ C |∃j : ( j, i) ∈ A} Hβ (C) = {(σ, i|β, A) ∈ C |¬∃j : ( j, i) ∈ A} The set Hσ (C) is the subset of configurations where the node on top of the stack has been assigned a head in A, and Hσ ("
J13-4002,P06-1112,0,0.0307418,"cy Parsing Dependency parsing is based on the idea that syntactic structure can be analyzed in terms of binary, asymmetric relations between the words of a sentence, an idea that has a long tradition in descriptive and theoretical linguistics (Tesni`ere 1959; Sgall, Hajiˇcov´a, and Panevov´a 1986; Mel’ˇcuk 1988; Hudson 1990). In computational linguistics, dependency structures have become increasingly popular in the interface to downstream applications of parsing, such as information extraction (Culotta and Sorensen 2004; Stevenson and Greenwood 2006; Buyko and Hahn 2010), question answering (Shen and Klakow 2006; Bikel and Castelli 2008), and machine translation (Quirk, Menezes, and Cherry 2005; Xu et al. 2009). And although dependency structures can easily be extracted from other syntactic representations, such as phrase structure trees, this has also led to an increased interest in statistical parsers that specifically produce dependency trees (Eisner 1996; Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005). Current approaches to statistical dependency parsing can be broadly grouped into graph-based and transition-based techniques (McDonald and Nivre 2007"
J13-4002,D08-1016,0,0.0112309,"h-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and learn models for scoring entire parse trees for a given sentence. Many of these models permit exact inference using dynamic programming (Eisner 1996; McDonald, Crammer, and Pereira 2005; Carreras 2007; Koo and Collins 2010), but recent work has explored approximate search methods in order to widen the scope of features especially when processing non-projective trees (McDonald and Pereira 2006; Riedel and Clarke 2006; Nakagawa 2007; Smith and Eisner 2008; Martins, Smith, and Xing 2009; Koo et al. 2010; Martins et al. 2010). Transition-based parsers parameterize the parsing problem by the structure of a transition system, or abstract state machine, for mapping sentences to dependency trees and learn models for scoring individual transitions from one state to the other. Traditionally, transition-based parsers have relied on local optimization and 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only one of them concerns qual"
J13-4002,W06-0202,0,0.0235901,"nar parsers, are entirely new contributions of this article. 2. Dependency Parsing Dependency parsing is based on the idea that syntactic structure can be analyzed in terms of binary, asymmetric relations between the words of a sentence, an idea that has a long tradition in descriptive and theoretical linguistics (Tesni`ere 1959; Sgall, Hajiˇcov´a, and Panevov´a 1986; Mel’ˇcuk 1988; Hudson 1990). In computational linguistics, dependency structures have become increasingly popular in the interface to downstream applications of parsing, such as information extraction (Culotta and Sorensen 2004; Stevenson and Greenwood 2006; Buyko and Hahn 2010), question answering (Shen and Klakow 2006; Bikel and Castelli 2008), and machine translation (Quirk, Menezes, and Cherry 2005; Xu et al. 2009). And although dependency structures can easily be extracted from other syntactic representations, such as phrase structure trees, this has also led to an increased interest in statistical parsers that specifically produce dependency trees (Eisner 1996; Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005). Current approaches to statistical dependency parsing can be broadly grouped into grap"
J13-4002,W07-2218,0,0.396405,"nd 801 Computational Linguistics Volume 39, Number 4 ✞  AuxK ✞  AuxP ✞ Pred Sb ✞  ✞ Atr  ✞ AuxZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only one of them concerns quality.”) AuxP ✞ ROOT 1  ✞ Adv  ❄ ❄ na7 kvalitu8 quality to ❄ .9 .) Figure 1 Dependency graph for a Czech sentence from the Prague Dependency Treebank. greedy, deterministic parsing (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; Attardi 2006; Nivre 2008), but globally trained models and non-greedy parsing methods such as beam search are increasingly used (Johansson and Nugues 2006; Titov and Henderson 2007; Zhang and Clark 2008; Huang, Jiang, and Liu 2009; Huang and Sagae 2010; Zhang and Nivre 2011). In empirical evaluations, the two main approaches to dependency parsing often achieve very similar accuracy, but transition-based parsers tend to be more efficient. In this article, we will be concerned exclusively with transitionbased models. In the remainder of this background section, we first introduce the syntactic representations used by dependency parsers, starting from a general characterization of dependency graphs and discussing a number of different restrictions of this class that will b"
J13-4002,D11-1116,0,0.0225824,"Missing"
J13-4002,N09-1028,0,0.013601,"nary, asymmetric relations between the words of a sentence, an idea that has a long tradition in descriptive and theoretical linguistics (Tesni`ere 1959; Sgall, Hajiˇcov´a, and Panevov´a 1986; Mel’ˇcuk 1988; Hudson 1990). In computational linguistics, dependency structures have become increasingly popular in the interface to downstream applications of parsing, such as information extraction (Culotta and Sorensen 2004; Stevenson and Greenwood 2006; Buyko and Hahn 2010), question answering (Shen and Klakow 2006; Bikel and Castelli 2008), and machine translation (Quirk, Menezes, and Cherry 2005; Xu et al. 2009). And although dependency structures can easily be extracted from other syntactic representations, such as phrase structure trees, this has also led to an increased interest in statistical parsers that specifically produce dependency trees (Eisner 1996; Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005). Current approaches to statistical dependency parsing can be broadly grouped into graph-based and transition-based techniques (McDonald and Nivre 2007). Graphbased parsers parameterize the parsing problem by the structure of the dependency trees and l"
J13-4002,W03-3023,0,0.600794,"ncy trees, guided by statistical models trained on treebank ´ Universidade da Coruna, ˜ Facultad de Informtica, Campus de Elvina ˜ ∗ Departamento de Computacion, ˜ Spain. E-mail: cgomezr@udc.es. s/n, 15071 A Coruna, ∗∗ Department of Linguistics and Philology, Uppsala University, Box 635, 75126 Uppsala, Sweden. E-mail: joakim.nivre@lingfil.uu.se. Submission received: 13 October 2011; revised submission received: 29 August 2012; accepted for publication: 7 November 2012. doi:10.1162/COLI a 00150 © 2013 Association for Computational Linguistics Computational Linguistics Volume 39, Number 4 data (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; Attardi 2006; Zhang and Clark 2008). Transition systems for dependency parsing come in many different varieties, and our aim in the first part of this article is to deepen our understanding of these systems by analyzing them in a uniform framework. More precisely, we demonstrate that a number of well-known systems from the literature can all be viewed as variants of a stack-based system with five elementary transitions, where different variants are obtained by composing elementary transitions into complex transitions and by adding restrictions on their applicab"
J13-4002,D08-1059,0,0.178616,"de da Coruna, ˜ Facultad de Informtica, Campus de Elvina ˜ ∗ Departamento de Computacion, ˜ Spain. E-mail: cgomezr@udc.es. s/n, 15071 A Coruna, ∗∗ Department of Linguistics and Philology, Uppsala University, Box 635, 75126 Uppsala, Sweden. E-mail: joakim.nivre@lingfil.uu.se. Submission received: 13 October 2011; revised submission received: 29 August 2012; accepted for publication: 7 November 2012. doi:10.1162/COLI a 00150 © 2013 Association for Computational Linguistics Computational Linguistics Volume 39, Number 4 data (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; Attardi 2006; Zhang and Clark 2008). Transition systems for dependency parsing come in many different varieties, and our aim in the first part of this article is to deepen our understanding of these systems by analyzing them in a uniform framework. More precisely, we demonstrate that a number of well-known systems from the literature can all be viewed as variants of a stack-based system with five elementary transitions, where different variants are obtained by composing elementary transitions into complex transitions and by adding restrictions on their applicability. We call such systems divisible transition systems and prove a"
J13-4002,P11-2033,1,0.790329,"xZ  ❄ ❄ ❄ ❄ ❄ je4 jen5 jedna6 Z2 nich3 only is them (Out-of one-FEM - SG (“Only one of them concerns quality.”) AuxP ✞ ROOT 1  ✞ Adv  ❄ ❄ na7 kvalitu8 quality to ❄ .9 .) Figure 1 Dependency graph for a Czech sentence from the Prague Dependency Treebank. greedy, deterministic parsing (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; Attardi 2006; Nivre 2008), but globally trained models and non-greedy parsing methods such as beam search are increasingly used (Johansson and Nugues 2006; Titov and Henderson 2007; Zhang and Clark 2008; Huang, Jiang, and Liu 2009; Huang and Sagae 2010; Zhang and Nivre 2011). In empirical evaluations, the two main approaches to dependency parsing often achieve very similar accuracy, but transition-based parsers tend to be more efficient. In this article, we will be concerned exclusively with transitionbased models. In the remainder of this background section, we first introduce the syntactic representations used by dependency parsers, starting from a general characterization of dependency graphs and discussing a number of different restrictions of this class that will be relevant for the analysis later on. We then go on to review the formalization of transition s"
J13-4002,J11-3004,1,\N,Missing
J13-4002,C96-1058,0,\N,Missing
J13-4002,P04-1054,0,\N,Missing
J13-4002,C98-1102,0,\N,Missing
J13-4002,P10-1151,1,\N,Missing
J13-4002,N10-1115,0,\N,Missing
J14-2001,P99-1059,0,0.0228125,"and wj inclusive, (ii) G[i,j] is a directed tree, and (iii) it holds for every arc (i, l, j) ∈ G[i,j] that there is a directed path 1 Although span and arc constraints can easily be added to other dependency parsing frameworks, this often affects parsing complexity. For example, in graph-based parsing (McDonald, Crammer, and Pereira 2005) arc constraints can be enforced within the O(n3 ) Eisner algorithm (Eisner 1996) by pruning out inconsistent chart cells, but span constraints require the parser to keep track of full subtree end points, which would necessitate the use of O(n4 ) algorithms (Eisner and Satta 1999). 250 Nivre, Goldberg, and McDonald Constrained Arc-Eager Dependency Parsing from i to every node k such that min(i, j) &lt; k &lt; max(i, j) (projectivity). We now define two constraints on a dependency graph G for a sentence x: r G is a projective dependency tree (PDT) if and only if it is a projective spanning tree over the interval [1, n] rooted at node n. r G is a projective dependency graph (PDG) if and only if it can be extended to a projective dependency tree simply by adding arcs. It is clear from the definitions that every PDT is also a PDG, but not the other way around. Every PDG can be c"
J14-2001,C96-1058,0,0.0699697,"ay that a subgraph G[i,j] = (V[i,j] , A[i,j] ) of G is a projective spanning tree over the interval [i, j] (1 ≤ i ≤ j ≤ n) iff (i) G[i,j] contains all nodes corresponding to words between wi and wj inclusive, (ii) G[i,j] is a directed tree, and (iii) it holds for every arc (i, l, j) ∈ G[i,j] that there is a directed path 1 Although span and arc constraints can easily be added to other dependency parsing frameworks, this often affects parsing complexity. For example, in graph-based parsing (McDonald, Crammer, and Pereira 2005) arc constraints can be enforced within the O(n3 ) Eisner algorithm (Eisner 1996) by pruning out inconsistent chart cells, but span constraints require the parser to keep track of full subtree end points, which would necessitate the use of O(n4 ) algorithms (Eisner and Satta 1999). 250 Nivre, Goldberg, and McDonald Constrained Arc-Eager Dependency Parsing from i to every node k such that min(i, j) &lt; k &lt; max(i, j) (projectivity). We now define two constraints on a dependency graph G for a sentence x: r G is a projective dependency tree (PDT) if and only if it is a projective spanning tree over the interval [1, n] rooted at node n. r G is a projective dependency graph (PDG)"
J14-2001,C12-1059,1,0.847816,"configuration without having to scan the stack and buffer linearly. Because there are at most O(n) arcs in the arc constraint set, the preprocessing will not take more than O(n) time but guarantees that all permissibility checks can be performed in O(1) time. Finally, we note that the arc-constrained system is sound and complete in the sense that it derives all and only PDTs compatible with a given arc constraint set AC for a sentence x. Soundness follows from the fact that, for every arc (i, l, j) ∈ AC , the preconditions 3 For further discussion of reachability in the arc-eager system, see Goldberg and Nivre (2012, 2013). 253 Computational Linguistics Volume 40, Number 2 force the system to reach a configuration of the form (σ |min(i, j), max(i, j)|β, A) in which either L EFT-A RCl (i &gt; j) or R IGHT-A RC l (i &lt; j) will be the only permissible transition. Completeness follows from the observation that every PDT G compatible with AC is also a PDG and can therefore be viewed as a larger constraint set for which every transition sequence (given soundness) derives G exactly. Empirical Case Study: Imperatives. Consider the problem of parsing commands to personal assistants such as Siri or Google Now. In this"
J14-2001,Q13-1033,1,0.843482,"Missing"
J14-2001,I11-1084,0,0.0193491,"transition. Completeness follows from the observation that every PDT G compatible with AC is also a PDG and can therefore be viewed as a larger constraint set for which every transition sequence (given soundness) derives G exactly. Empirical Case Study: Imperatives. Consider the problem of parsing commands to personal assistants such as Siri or Google Now. In this setting, the distribution of utterances is highly skewed towards imperatives making them easy to identify. Unfortunately, parsers trained on treebanks like the Penn Treebank (PTB) typically do a poor job of parsing such utterances (Hara et al. 2011). However, we know that if the first word of a command is a verb, it is likely the root of the sentence. If we take an arc-eager beam search parser (Zhang and Nivre 2011) trained on the PTB, it gets 82.14 labeled attachment score on a set of commands.4 However, if we constrain the same parser so that the first word of the sentence must be the root, accuracy jumps dramatically to 85.56. This is independent of simply knowing that the first word of the sentence is a verb, as both parsers in this experiment had access to gold part-of-speech tags. 4. Parsing with Span Constraints Span Constraints."
J14-2001,P10-1001,0,0.162458,"Missing"
J14-2001,P05-1012,1,0.86983,"Missing"
J14-2001,P13-2017,1,0.886031,"Missing"
J14-2001,W03-3017,1,0.76581,"ce, Ramat-Gan, 5290002, Israel. E-mail: yoav.goldberg@gmail.com. † Google, 76 Buckingham Palace Road, London SW1W9TQ, United Kingdom. E-mail: ryanmcd@google.com. Submission received: 26 June 2013; accepted for publication: 10 October 2013. doi:10.1162/COLI a 00184 © 2014 Association for Computational Linguistics Computational Linguistics Volume 40, Number 2 Figure 1 Span constraint derived from a title assisting parsing. Left: unconstrained. Right: constrained. In this article, we examine the problem of constraining transition-based dependency parsers based on the arc-eager transition system (Nivre 2003, 2008), which perform a single left-to-right pass over the input, eagerly adding dependency arcs at the earliest possible opportunity, resulting in linear time parsing. We consider two types of constraints: span constraints, exemplified earlier, require the output graph to have a single subtree over one or more (non-overlapping) spans of the input; arc constraints instead require specific arcs to be present in the output dependency graph. The main contribution of the article is to show that both span and arc constraints can be implemented as efficiently computed preconditions on parser transi"
J14-2001,J08-4003,1,0.894607,"ad. S HIFT removes the first node in the buffer and pushes it onto the stack, with the precondition that j 6= n. A transition sequence for a sentence x is a sequence C0,m = (c0 , c1 , . . . , cm ) of configurations, such that c0 is the initial configuration cs (x), cm is a terminal configuration, and there is a legal transition t such that ci = t(ci−1 ) for every i, 1 ≤ i ≤ m. The dependency graph derived by C0,m is Gcm = (Vx , Acm ), where Acm is the set of arcs in cm . Complexity and Correctness. For a sentence of length n, the number of transitions in the arc-eager system is bounded by 2n (Nivre 2008). This means that a parser using greedy inference (or constant width beam search) will run in O(n) time provided that transitions plus required precondition checks can be performed in O(1) time. This holds for the arc-eager system and, as we will demonstrate, its constrained variants as well. The arc-eager transition system as presented here is sound and complete for the set of PDTs (Nivre 2008). For a specific sentence x = w1 , . . . , wn , this means that any transition sequence for x produces a PDT (soundness), and that any PDT for x is generated by 251 Computational Linguistics Transition"
J14-2001,W04-2407,1,0.901212,"Missing"
J14-2001,P80-1024,0,0.667437,"Missing"
J14-2001,W03-3023,0,0.309594,"strained to respect two different types of conditions on the output dependency graph: span constraints, which require certain spans to correspond to subtrees of the graph, and arc constraints, which require certain arcs to be present in the graph. The constraints are incorporated into the arc-eager transition system as a set of preconditions for each transition and preserve the linear time complexity of the parser. 1. Introduction Data-driven dependency parsers in general achieve high parsing accuracy without relying on hard constraints to rule out (or prescribe) certain syntactic structures (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005; Zhang and Clark 2008; Koo and Collins 2010). Nevertheless, there are situations where additional information sources, not available at the time of training the parser, may be used to derive hard constraints at parsing time. For example, Figure 1 shows the parse of a greedy arc-eager dependency parser trained on the Wall Street Journal section of the Penn Treebank before (left) and after (right) being constrained to build a single subtree over the span corresponding to the named entity “Cat on a Hot Tin Roof,” which does not"
J14-2001,D08-1059,0,0.0265037,"traints, which require certain spans to correspond to subtrees of the graph, and arc constraints, which require certain arcs to be present in the graph. The constraints are incorporated into the arc-eager transition system as a set of preconditions for each transition and preserve the linear time complexity of the parser. 1. Introduction Data-driven dependency parsers in general achieve high parsing accuracy without relying on hard constraints to rule out (or prescribe) certain syntactic structures (Yamada and Matsumoto 2003; Nivre, Hall, and Nilsson 2004; McDonald, Crammer, and Pereira 2005; Zhang and Clark 2008; Koo and Collins 2010). Nevertheless, there are situations where additional information sources, not available at the time of training the parser, may be used to derive hard constraints at parsing time. For example, Figure 1 shows the parse of a greedy arc-eager dependency parser trained on the Wall Street Journal section of the Penn Treebank before (left) and after (right) being constrained to build a single subtree over the span corresponding to the named entity “Cat on a Hot Tin Roof,” which does not occur in the training set but can easily be found in on-line databases. In this case, addi"
J14-2001,P11-2033,1,0.937551,"ich every transition sequence (given soundness) derives G exactly. Empirical Case Study: Imperatives. Consider the problem of parsing commands to personal assistants such as Siri or Google Now. In this setting, the distribution of utterances is highly skewed towards imperatives making them easy to identify. Unfortunately, parsers trained on treebanks like the Penn Treebank (PTB) typically do a poor job of parsing such utterances (Hara et al. 2011). However, we know that if the first word of a command is a verb, it is likely the root of the sentence. If we take an arc-eager beam search parser (Zhang and Nivre 2011) trained on the PTB, it gets 82.14 labeled attachment score on a set of commands.4 However, if we constrain the same parser so that the first word of the sentence must be the root, accuracy jumps dramatically to 85.56. This is independent of simply knowing that the first word of the sentence is a verb, as both parsers in this experiment had access to gold part-of-speech tags. 4. Parsing with Span Constraints Span Constraints. Given a sentence x = w1 , . . . , wn , we take a span constraint set to be a set SC of non-overlapping spans [i, j] (1 ≤ i &lt; j ≤ n). The task of span-constrained parsing"
J14-2001,J13-1002,1,\N,Missing
J14-2002,W06-2920,0,0.0718961,"l-formed tree, there will be no training instances corresponding to the extended transition sequences in the new system (i.e., sequences containing one or more non-terminal configurations of the form (σ, [ ], A)). However, because the Unshift transition is only used in completely deterministic cases, where the classifier is not called upon to rank alternative transitions, we can make use of exactly the same classifier for both the old and the new system.4 We compare the original and modified arc-eager systems on all 13 data sets from the CoNLL-X shared task on multilingual dependency parsing (Buchholz and Marsi 2006), 3 The number is k − 1, rather than k, because Unshift requires an empty buffer, which together with only one word on the stack would imply a terminal configuration. 4 Although this greatly simplifies the integration of the new system into existing parsing frameworks, it is conceivable that accuracy could be improved further through specialized training methods, for example, using a dynamic oracle along the lines of Goldberg and Nivre (2012). We leave this for future research. 263 Computational Linguistics Volume 40, Number 2 which all assume the existence of a dummy root word prefixed to the"
J14-2002,C12-1059,1,0.876942,"e new system.4 We compare the original and modified arc-eager systems on all 13 data sets from the CoNLL-X shared task on multilingual dependency parsing (Buchholz and Marsi 2006), 3 The number is k − 1, rather than k, because Unshift requires an empty buffer, which together with only one word on the stack would imply a terminal configuration. 4 Although this greatly simplifies the integration of the new system into existing parsing frameworks, it is conceivable that accuracy could be improved further through specialized training methods, for example, using a dynamic oracle along the lines of Goldberg and Nivre (2012). We leave this for future research. 263 Computational Linguistics Volume 40, Number 2 which all assume the existence of a dummy root word prefixed to the sentence. We tune the feature representations separately for each language and projectivize the training data for languages with non-projective dependencies but otherwise use default settings in MaltParser (including the standard heuristic of attaching any unattached tokens to the artificial root node at the end of parsing for the original system). Because we want to perform a detailed error analysis for fragmented parses, we initially avoid"
J14-2002,D07-1013,1,0.91562,"Missing"
J14-2002,D11-1006,0,0.0584966,"Missing"
J14-2002,W03-3017,1,0.475109,"ations, optionally labeled with dependency types (Kubler, ¨ McDonald, and Nivre 2009). In this article, we will furthermore restrict our attention to dependency trees that are projective, meaning that every subtree has a contiguous yield. Figure 1 shows a labeled projective dependency tree. Transition-based dependency parsing views parsing as heuristic search through a non-deterministic transition system for deriving dependency trees, guided by a statistical model for scoring transitions from one configuration to the next. Figure 2 shows the arc-eager transition system for dependency parsing (Nivre 2003, 2008). A parser configuration consists of a stack σ, a buffer β, and a set of arcs A. The initial configuration for parsing a sentence x = w1 , . . . , wn has an empty stack, a buffer containing the words w1 , . . . , wn , and an empty arc set. A terminal configuration is any configuration with an empty buffer. Whatever arcs have then been accumulated in the arc set A defines the output dependency tree. There are four possible transitions from a configuration   P  DOBJ  SBJ  IOBJ  ? ? He1 her3 wrote2   DET  ? ? a4 letter5 ? .6 Figure 1 Projective labeled dependency tree for an Engl"
J14-2002,W04-0308,1,0.904672,"rc from next to top and pops the stack; allowed only if top has no head. The arc-eager system defines an incremental left-to-right parsing order, where left dependents are added bottom–up and right dependents top–down, which is advantageous for postponing certain attachment decisions. However, a fundamental problem with this system is that it does not guarantee that the output parse is a projective dependency tree, only a projective dependency forest, that is, a sequence of adjacent, non-overlapping projective trees (Nivre 2008). This is different from the closely related arc-standard system (Nivre 2004), which constructs all dependencies bottom–up and can easily be constrained to only output trees. The failure to implement the tree constraint may lead to fragmented parses and lower parsing accuracy, especially with respect to the global structure of the sentence. Moreover, even if the loss in accuracy is not substantial, this may be problematic when using the parser in applications where downstream components may not function correctly if the parser output is not a wellformed tree. The standard solution to this problem in practical implementations, such as MaltParser (Nivre, Hall, and Nilsso"
J14-2002,J08-4003,1,0.920465,"from top to next and moves next to the stack. 4. Left-Arc adds a dependency arc from next to top and pops the stack; allowed only if top has no head. The arc-eager system defines an incremental left-to-right parsing order, where left dependents are added bottom–up and right dependents top–down, which is advantageous for postponing certain attachment decisions. However, a fundamental problem with this system is that it does not guarantee that the output parse is a projective dependency tree, only a projective dependency forest, that is, a sequence of adjacent, non-overlapping projective trees (Nivre 2008). This is different from the closely related arc-standard system (Nivre 2004), which constructs all dependencies bottom–up and can easily be constrained to only output trees. The failure to implement the tree constraint may lead to fragmented parses and lower parsing accuracy, especially with respect to the global structure of the sentence. Moreover, even if the loss in accuracy is not substantial, this may be problematic when using the parser in applications where downstream components may not function correctly if the parser output is not a wellformed tree. The standard solution to this prob"
J14-2002,W04-2407,1,0.890355,"Missing"
J14-2002,nivre-etal-2006-maltparser,1,0.882348,"Missing"
J14-2002,W07-2218,0,0.0713223,"Missing"
J14-2002,C00-2137,0,0.170029,"Missing"
J14-2002,D08-1059,0,0.0561987,"Missing"
J14-2002,P11-2033,1,0.928469,"Missing"
K17-3001,K17-3023,0,0.0375672,"Missing"
K17-3001,P16-1231,1,0.301678,"M Table 1: The supporting data overview: the number of words (M = million; K = thousand) for each language. http://commoncrawl.org/ Except for Ancient Greek, which was gathered from the Perseus Digital Library. 3 http://github.com/CLD2Owners/cld2 4 http://unicode.org/reports/tr15/ 3 verted to Unicode character NO-BREAK SPACE (U+00A0).5 The dimensionality of the word embeddings was chosen to be 100 after thorough discussion – more dimensions may yield better results and are commonly used, but even with just 100, the uncompressed word embeddings for the 45 languages take 135 GiB. Also note that Andor et al. (2016) achieved state-of-the-art results with 64 dimensions. The word embeddings were precomputed using word2vec (Mikolov et al., 2013) with the following options: word2vec -min-count 10 -size 100 -window 10 -negative 5 -iter 2 -threads 16 -cbow 0 -binary 0. The precomputed word embeddings are available on-line (Ginter et al., 2017). 2.3 this shared task, i.e., not included in any previous UD release. The PUD treebank consists of 1000 sentences currently in 18 languages (15 K to 27 K words, depending on the language), which were randomly picked from on-line newswire and Wikipedia;7 usually only a fe"
K17-3001,W06-2920,0,0.0145655,"categorization of the different approaches of the participating systems. Introduction Ten years ago, two CoNLL shared tasks were a major milestone for parsing research in general and dependency parsing in particular. For the first time dependency treebanks in more than ten languages were available for learning parsers. Many of them were used in follow-up work, evaluating parsers on multiple languages became standard, and multiple state-of-the-art, open-source parsers became available, facilitating production of dependency structures to be used in downstream applications. While the two tasks (Buchholz and Marsi, 2006; Nivre et al., 2007) were extremely important in setting the scene for the following years, there were also limitations that complicated application of their results: (1) gold-standard to1 Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 1–19, c 2017 Association for Computational Linguistics Vancouver, Canada, August 3-4, 2017. kenization and part-of-speech tags in the test data moved the tasks away from real-world scenarios, and (2) incompatible annotation schemes made cross-linguistic comparison impossible. CoNLL 2017 has picked"
K17-3001,K17-3017,0,0.147208,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3005,0,0.0752704,"Missing"
K17-3001,K17-3026,0,0.0310687,"E 90.88 82.31 82.46 LyS-FASTPARSE 90.88 82.31 79.14 NAIST SATO 90.88 82.31 82.46 Orange – Deski˜n 90.88 38.81 15.38 UALING 90.88 82.31 82.46 UParse 90.88 82.31 82.46 naistCL 90.88 82.31 82.46 Table 5: Universal POS tags, features and lemmas (ordered by UPOS F1 scores). duce suboptimal results when deployed on a machine different from the one where it was trained. Several teams used the library and may have been affected; for the Uppsala team (de Lhoneux et al., 2017) the issue led to official LAS = 65.11 (23rd place) instead of 69.66 (9th place). In the second case, the ParisNLP system (De La Clergerie et al., 2017) used a wrong method of recognizing the input language, which was not supported in the test data (but unfortunately it was possible to get along with it in development and trial data). Simply crashing could mean that the task moderator would show the team their diagnostic output and they would fix the bug; however, the parser was robust enough to switch to a languageagnostic mode and produced results that were not great, but also not so bad to alert the moderator and make him investigate. Thus the official LAS of the system is 60.02 (27th place) while without the bug it could have been 70.35 ("
K17-3001,K17-3021,0,0.0954088,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3022,1,0.891655,"Missing"
K17-3001,K17-3025,0,0.0327614,"Missing"
K17-3001,K17-3024,0,0.050508,"Missing"
K17-3001,K17-3027,0,0.0537913,"Missing"
K17-3001,K17-3014,0,0.0756362,"Missing"
K17-3001,K17-3015,0,0.0745209,"Missing"
K17-3001,K17-3007,0,0.0511894,"Missing"
K17-3001,L16-1262,1,0.869327,"Missing"
K17-3001,W14-6111,0,0.0253686,"Missing"
K17-3001,W17-0411,1,0.831758,"ossible when the system run completed; before that, even the task moderator would not see whether the system was really producing output and not just sitting in an endless loop. Especially given the scale of operations this year, this turned out to be a major obstacle for some participants; TIRA needs to be improved by offering more finegrained process monitoring tools, both for organizers and participants. Content-word Labeled Attachment Score (CLAS) has been proposed as an alternative parsing metric that is tailored to the UD annotation style and more suitable for cross-language comparison (Nivre and Fang, 2017). It differs from LAS in that it only considers relations between content words. Attachment of function words is disregarded because it corresponds to morphological features in other languages (and morphology is not evaluated in this shared task). Furthermore, languages with many function words (e.g., English) have longer sentences than morphologically rich languages (e.g., Finnish), hence a single error in Finnish costs the parser significantly more than an error in English. CLAS also disregards attachment of punctuation. As CLAS is still experimental, we have designated full LAS as our main"
K17-3001,K17-3003,0,0.0845341,"Missing"
K17-3001,W17-0412,1,0.869806,"Missing"
K17-3001,L16-1680,1,0.0475333,"Missing"
K17-3001,K17-3009,1,0.104147,"Missing"
K17-3001,tiedemann-2012-parallel,0,0.0126153,"oses (so that follow-up research is not obstructed). We deliberately did not place upper bounds on data sizes (in contrast to e.g. Nivre et al. (2007)), despite the fact that processing large amounts of data may be difficult for some teams. Our primary objective was to determine the capability of current parsers with the data that is currently available. In practice, the task was formally closed, i.e., we listed the approved data resources so that all participants were aware of their options. However, the selection was rather broad, ranging from Wikipedia dumps over the OPUS parallel corpora (Tiedemann, 2012) to morphological transducers. Some of the resources were proposed by the participating teams. 2.2 Supporting Data To enable the induction of custom embeddings and the use of semi-supervised methods in general, the participants were provided with supporting resources primarily consisting of large text corpora for (nearly) all of the languages in the task, as well as embeddings pre-trained on these corpora. 1 Outside CoNLL, there were several other parsing tasks in the meantime, which naturally also explored previously unadressed aspects—for example SANCL (Petrov and McDonald, 2012) or SPMRL (S"
K17-3001,K17-3016,0,0.0605417,"Missing"
K17-3001,K17-3020,0,0.0375614,"Missing"
K17-3001,K17-3013,0,0.0456211,"Missing"
K17-3001,D07-1096,1,\N,Missing
K17-3001,K17-3002,1,\N,Missing
K17-3001,K17-3019,0,\N,Missing
K17-3001,K17-3012,1,\N,Missing
K17-3001,K17-3006,0,\N,Missing
K17-3001,K17-3010,0,\N,Missing
K17-3001,K17-3018,0,\N,Missing
K17-3001,K17-3028,1,\N,Missing
K17-3001,K17-3011,0,\N,Missing
K17-3022,Q16-1031,0,0.032839,"ce of length n with words w1 , . . . , wn , we create a sequence of vectors x1:n , where the vector xi representing wi is the concatenation of a word embedding, a pretrained embedding, and a character vector. We construct a character vector che (wi ) for each wi by running a BiLSTM over the characters chj (1 ≤ j ≤ m) of wi : 100 50 12 100 100 2 200 / 200 0.25 0.33 0.1 Table 2: Hyper-parameter values for parsing. With the aim of training a multilingual parser, we additionally created a variant of the parser which adds a language embedding to input vectors in a spirit similar to what is done in Ammar et al. (2016). In this setting, the vector for each word xi is the concatenation of a word embedding, a pretrained word embedding, a character vector, and a language embedding li with the language corresponding to the word. As was mentioned in the introduction, our experiments with this model was limited to the languages with little data. Those experiments are described in Section 5. che (wi ) = B I L STM(ch1:m ) As in the original parser, we also concatenate these vectors with pretrained word embeddings pe(wi ). The input vectors xi are therefore: xi = e(wi ) ◦ pe(wi ) ◦ che (wi ) Our pretrained word embe"
K17-3022,D15-1041,0,0.0715977,"holz and Marsi, 2006; Nivre et al., 2007). Even models that perform joint inference, like those of Hatori et al. (2012) and Bohnet et al. (2013), depend heavily on part-of-speech tags, so we were unlikely to reach top scores in the shared task without them. However, from a scientific perspective, we thought it would be interesting to explore how far we can get with a bare-bones system that does not predict redundant linguistic categories. In addition, we take inspiration from recent work showing that character-based representations can at least partly obviate the need for part-of-speech tags (Ballesteros et al., 2015). The Uppsala system is a very simple pipeline consisting of two main components. The first is a model for joint sentence and word segmentation, which uses the BiRNN-CRF framework of Shao et al. (2017) to predict sentence and word boundaries in the raw input and simultaneously marks multiword tokens that need non-segmental analysis. The latter are handled by a simple dictionary lookup or by an encoder-decoder network. We use a single universal model regardless of writing system, but train separate models for each language. The segmentation component is described in more detail in Section 2. Th"
K17-3022,W17-0203,1,0.918606,"der-decoder (Bahdanau et al., 2014) equipped with shared long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) as the basic recurrent cell. At test time, multi-word tokens are first queried in the dictionary. If not found, the segmented words are generated via the encoder-decoder as a sequence-to-sequence transOur original plans included training a single universal model on data from all languages, with cross-lingual word embeddings, but in the limited time available we could only start exploring two simple enhancements. First, we constructed word embeddings based on the RSV model (Basirat and Nivre, 2017), using universal part-of-speech tags as contexts (Section 4). Secondly, we used multilingual training data for languages with little or no training data (Section 5). Our system was trained only on the training sets provided by the organizers (Nivre et al., 2017a). We did not make any use of large unlabeled data sets, parallel data sets, or word embeddings derived from such data. After evaluation on the official test sets (Nivre et al., 2017b), run on the TIRA server (Potthast et al., 2014), the Uppsala system ranked 23 of 33 systems with respect to the main evaluation metric, with a macro-ave"
K17-3022,Q13-1034,1,0.885612,"Missing"
K17-3022,W06-2920,0,0.223232,"ahu Kiperwasser† Sara Stymne∗ Yoav Goldberg† Joakim Nivre∗ ∗ Department of Linguistics and Philology Uppsala University Uppsala, Sweden Abstract Computer Science Department Bar-Ilan University Ramat-Gan, Israel lemmas, despite the fact that these annotations are available in the training and development data. In this way, we go against a strong tradition in dependency parsing, which has generally favored pipeline systems with part-of-speech tagging as a crucial component, a tendency that has probably been reinforced by the widespread use of data sets with gold tags from the early CoNLL tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Even models that perform joint inference, like those of Hatori et al. (2012) and Bohnet et al. (2013), depend heavily on part-of-speech tags, so we were unlikely to reach top scores in the shared task without them. However, from a scientific perspective, we thought it would be interesting to explore how far we can get with a bare-bones system that does not predict redundant linguistic categories. In addition, we take inspiration from recent work showing that character-based representations can at least partly obviate the need for part-of-speech tags (Ballesteros et al.,"
K17-3022,W14-4012,0,0.0702859,"Missing"
K17-3022,L16-1262,1,0.853436,"Missing"
K17-3022,Q13-1033,1,0.85172,"ure over the words of each sentence. In particular, the system makes no use of part-of-speech tags, morphological features, or 207 Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 207–217, c 2017 Association for Computational Linguistics Vancouver, Canada, August 3-4, 2017. 2 informative features of words in context and a feed-forward network for predicting the next parsing transition. The parser uses the arc-hybrid transition system (Kuhlmann et al., 2011) with greedy inference and a dynamic oracle for exploration during training (Goldberg and Nivre, 2013). For the shared task, the parser has been modified to use character-based representations instead of part-ofspeech tags and to use pseudo-projective parsing to capture non-projective dependencies (Nivre and Nilsson, 2005). The parsing component is further described in Section 3. Sentence and Word Segmentation We model joint sentence and word segmentation as a character-level sequence labeling problem in a Bi-RNN-CRF model (Huang et al., 2015; Ma and Hovy, 2016). We simultaneously predict sentence boundaries and word boundaries and identify multi-word tokens that require further transduction."
K17-3022,P12-1110,0,0.0235023,"psala University Uppsala, Sweden Abstract Computer Science Department Bar-Ilan University Ramat-Gan, Israel lemmas, despite the fact that these annotations are available in the training and development data. In this way, we go against a strong tradition in dependency parsing, which has generally favored pipeline systems with part-of-speech tagging as a crucial component, a tendency that has probably been reinforced by the widespread use of data sets with gold tags from the early CoNLL tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). Even models that perform joint inference, like those of Hatori et al. (2012) and Bohnet et al. (2013), depend heavily on part-of-speech tags, so we were unlikely to reach top scores in the shared task without them. However, from a scientific perspective, we thought it would be interesting to explore how far we can get with a bare-bones system that does not predict redundant linguistic categories. In addition, we take inspiration from recent work showing that character-based representations can at least partly obviate the need for part-of-speech tags (Ballesteros et al., 2015). The Uppsala system is a very simple pipeline consisting of two main components. The first is"
K17-3022,P81-1022,0,0.685375,"Missing"
K17-3022,P05-1013,1,0.822588,"ependencies, pages 207–217, c 2017 Association for Computational Linguistics Vancouver, Canada, August 3-4, 2017. 2 informative features of words in context and a feed-forward network for predicting the next parsing transition. The parser uses the arc-hybrid transition system (Kuhlmann et al., 2011) with greedy inference and a dynamic oracle for exploration during training (Goldberg and Nivre, 2013). For the shared task, the parser has been modified to use character-based representations instead of part-ofspeech tags and to use pseudo-projective parsing to capture non-projective dependencies (Nivre and Nilsson, 2005). The parsing component is further described in Section 3. Sentence and Word Segmentation We model joint sentence and word segmentation as a character-level sequence labeling problem in a Bi-RNN-CRF model (Huang et al., 2015; Ma and Hovy, 2016). We simultaneously predict sentence boundaries and word boundaries and identify multi-word tokens that require further transduction. In the BiRNN-CRF architecture, characters – regardless of writing system – are represented as dense vectors and fed into the bidirectional recurrent layers. We employ the gated recurrent unit (GRU) (Cho et al., 2014) as th"
K17-3022,Q16-1032,1,0.762352,"e and word boundaries in the raw input and simultaneously marks multiword tokens that need non-segmental analysis. The latter are handled by a simple dictionary lookup or by an encoder-decoder network. We use a single universal model regardless of writing system, but train separate models for each language. The segmentation component is described in more detail in Section 2. The second main component of our system is a greedy transition-based parser that predicts the dependency tree given the raw words of a sentence. The starting point for this model is the transitionbased parser described in Kiperwasser and Goldberg (2016b), which relies on a BiLSTM to learn We present the Uppsala submission to the CoNLL 2017 shared task on parsing from raw text to universal dependencies. Our system is a simple pipeline consisting of two components. The first performs joint word and sentence segmentation on raw text; the second predicts dependency trees from raw words. The parser bypasses the need for part-of-speech tagging, but uses word embeddings based on universal tag distributions. We achieved a macroaveraged LAS F1 of 65.11 in the official test run and obtained the 2nd best result for sentence segmentation with a score o"
K17-3022,Q16-1023,1,0.778627,"e and word boundaries in the raw input and simultaneously marks multiword tokens that need non-segmental analysis. The latter are handled by a simple dictionary lookup or by an encoder-decoder network. We use a single universal model regardless of writing system, but train separate models for each language. The segmentation component is described in more detail in Section 2. The second main component of our system is a greedy transition-based parser that predicts the dependency tree given the raw words of a sentence. The starting point for this model is the transitionbased parser described in Kiperwasser and Goldberg (2016b), which relies on a BiLSTM to learn We present the Uppsala submission to the CoNLL 2017 shared task on parsing from raw text to universal dependencies. Our system is a simple pipeline consisting of two components. The first performs joint word and sentence segmentation on raw text; the second predicts dependency trees from raw words. The parser bypasses the need for part-of-speech tagging, but uses word embeddings based on universal tag distributions. We achieved a macroaveraged LAS F1 of 65.11 in the official test run and obtained the 2nd best result for sentence segmentation with a score o"
K17-3022,P11-1068,0,0.532177,"Missing"
K17-3022,I17-1018,1,0.927202,"reach top scores in the shared task without them. However, from a scientific perspective, we thought it would be interesting to explore how far we can get with a bare-bones system that does not predict redundant linguistic categories. In addition, we take inspiration from recent work showing that character-based representations can at least partly obviate the need for part-of-speech tags (Ballesteros et al., 2015). The Uppsala system is a very simple pipeline consisting of two main components. The first is a model for joint sentence and word segmentation, which uses the BiRNN-CRF framework of Shao et al. (2017) to predict sentence and word boundaries in the raw input and simultaneously marks multiword tokens that need non-segmental analysis. The latter are handled by a simple dictionary lookup or by an encoder-decoder network. We use a single universal model regardless of writing system, but train separate models for each language. The segmentation component is described in more detail in Section 2. The second main component of our system is a greedy transition-based parser that predicts the dependency tree given the raw words of a sentence. The starting point for this model is the transitionbased p"
K17-3022,P16-1101,0,0.031215,"c-hybrid transition system (Kuhlmann et al., 2011) with greedy inference and a dynamic oracle for exploration during training (Goldberg and Nivre, 2013). For the shared task, the parser has been modified to use character-based representations instead of part-ofspeech tags and to use pseudo-projective parsing to capture non-projective dependencies (Nivre and Nilsson, 2005). The parsing component is further described in Section 3. Sentence and Word Segmentation We model joint sentence and word segmentation as a character-level sequence labeling problem in a Bi-RNN-CRF model (Huang et al., 2015; Ma and Hovy, 2016). We simultaneously predict sentence boundaries and word boundaries and identify multi-word tokens that require further transduction. In the BiRNN-CRF architecture, characters – regardless of writing system – are represented as dense vectors and fed into the bidirectional recurrent layers. We employ the gated recurrent unit (GRU) (Cho et al., 2014) as the basic recurrent cell. Dropout (Srivastava et al., 2014) is applied to the output of the recurrent layers, which are concatenated and passed further to the first order chain CRF layer. The CRF layer models conditional scores over all possible"
K17-3022,L16-1680,0,0.0727605,"Missing"
K18-2001,K18-2015,0,0.053009,"Missing"
K18-2001,Q17-1010,0,0.211935,"Missing"
K18-2001,K18-2010,0,0.0386566,"Missing"
K18-2001,K18-2017,0,0.075361,"Missing"
K18-2001,W06-2920,0,0.453112,"Missing"
K18-2001,K18-2025,0,0.0365994,"Missing"
K18-2001,K18-2005,0,0.120251,"Missing"
K18-2001,K18-2013,1,0.806044,"Missing"
K18-2001,K18-2026,0,0.0321915,"Missing"
K18-2001,K18-2012,0,0.0235436,"above are all intrinsic measures: they evaluate the grammatical analysis task per se, with the hope that better scores correspond to output that is more useful for downstream NLP applications. Nevertheless, such correlations are not automatically granted. We thus seek to complement our task with an extrinsic evaluation, where the output of parsing systems is exploited by applications like biological event extraction, opinion analysis and negation scope resolution. This optional track involves English only. It is organized in collaboration with the EPE initiative;7 for details see Fares et al. (2018). Syntactic Word Alignment The higher segmentation level is based on the notion of syntactic word. Some languages contain multi-word tokens (MWT) that are regarded as contractions of multiple syntactic words. For example, the German token zum is a contraction of the preposition zu “to” and the article dem “the”. Syntactic words constitute independent nodes in dependency trees. As shown by the example, it is not required that the MWT is a pure concatenation of the participating words; the simple token alignment thus does not work when MWTs 4 TIRA: The System Submission Platform Similarly to our"
K18-2001,K18-2003,0,0.040574,"Missing"
K18-2001,K18-2006,0,0.0774162,"Missing"
K18-2001,K18-2014,0,0.0664725,"Missing"
K18-2001,K18-2008,0,0.0697052,"Missing"
K18-2001,L16-1262,1,0.910778,"Missing"
K18-2001,W17-0411,1,0.849881,"and in the system output before comparing them. In the end-to-end evaluation of our task, LAS is re-defined as the harmonic mean (F1 ) of precision P and recall R, where P = #correctRelations #systemNodes (1) R= #correctRelations #goldNodes (2) LAS = 2P R P +R (3) Note that attachment of all nodes including punctuation is evaluated. LAS is computed separately for each of the 82 test files and a macro-average of all these scores is used to rank the systems. 3.2 MLAS: Morphology-Aware Labeled Attachment Score MLAS aims at cross-linguistic comparability of the scores. It is an extension of CLAS (Nivre and Fang, 2017), which was tested experimentally in the 2017 task. CLAS focuses on dependencies between content words and disregards attachment of function words; in MLAS, function words are not ignored, but they are treated as features of content words. In addition, part-of-speech tags and morphological features are evaluated, too. 3.3 BLEX: Bilexical Dependency Score BLEX is similar to MLAS in that it focuses on relations between content words. Instead of morphological features, it incorporates lemmatization in the evaluation. It is thus closer to semantic content and evaluates two aspects of UD annota5 ar"
K18-2001,K18-2022,0,0.0296323,"Missing"
K18-2001,K18-2011,1,0.844373,"Missing"
K18-2001,W17-0412,1,0.901947,"Missing"
K18-2001,L16-1680,1,0.90044,"Missing"
K18-2001,K17-3009,1,0.858784,"Missing"
K18-2001,tiedemann-2012-parallel,0,0.0674866,"at follow-up research is not obstructed). We deliberately did not place upper bounds on data sizes (in contrast to e.g. Nivre et al. (2007)), despite the fact that processing large amounts of data may be difficult for some teams. Our primary objective was to determine the capability of current parsers provided with large amounts of freely available data. In practice, the task was formally closed, i.e., we listed the approved data resources so that all participants were aware of their options. However, the selection was rather broad, ranging from Wikipedia dumps over the OPUS parallel corpora (Tiedemann, 2012) to morphological transducers. Some of the resources were proposed by the participating teams. We provided dependency-annotated training and test data, and also large quantities of crawled raw texts. Other language resources are available from third-party servers and we only referred to the respective download sites. 2.1 Training Data: UD 2.2 Training and development data came from the Universal Dependencies (UD) 2.2 collection (Nivre et al., 2018). This year, the official UD release immediately followed the test phase of the shared task. The training and development data were available to the"
K18-2001,K18-2016,0,0.0988933,"Missing"
K18-2001,K18-2019,0,0.110064,"Missing"
K18-2001,K18-2007,0,0.0602044,"Missing"
K18-2001,K18-2004,0,0.103154,"Missing"
K18-2011,C16-1012,0,0.0132499,"OS tagging and morphological features (UFEATS). Treebanks sharing a parsing model grouped together; substitute and proxy treebanks for segmentation, tagging, parsing far right (SPECIAL models detailed in the text). Confidence intervals for coloring: |< µ−σ < |< µ− SE < µ < µ+ SE < |< µ+σ < |. 119 able method for pooling training data both within and across languages. It is also worth noting that this method is easy to use and does not require extra external resources used in most work on multilingual parsing, like multilingual word embeddings (Ammar et al., 2016) or linguistic re-write rules (Aufrant et al., 2016) to achieve good results. coding. Scores that are significantly higher/lower than the mean score of the 21 systems that successfully parsed all test sets are marked with two shades of green/red. The lighter shade marks differences that are outside the interval defined by √the standard error of the mean (µ ± SE, SE = σ/ N ) but within one standard deviation (std dev) from the mean. The darker shade marks differences that are more than one std dev above/below the mean (µ ± σ). Finally, scores that are no longer valid because of the Thai UPOS tagger are crossed out in yellow cells, and corrected"
K18-2011,P82-1020,0,0.805881,"Missing"
K18-2011,P18-1246,1,0.843945,"(2017a). We use the default parameter settings introduced by Shao et al. (2018) and train a segmentation model for all treebanks with at least 50 sentences of training data. For treebanks with less or no training data (except Thai discussed below), we substitute a model for another treebank/language: • For Japanese Modern, Czech PUD, English PUD and Swedish PUD, we use the model trained on the largest treebank from the same language (Japanese GSD, Czech PDT, English EWT and Swedish Talbanken). 4 Tagging and Morphological Analysis We use two separate instantiations of the tagger6 described in Bohnet et al. (2018) to predict UPOS tags and morphological features, respectively. The tagger uses a Meta-BiLSTM over the output of a sentence-based character model and a word model. There are two features that mainly distinguishes the tagger from previous work. The character BiLSTMs use the full context of the sentence in contrast to most other taggers which use words only as context for the character model. This character model is combined with the word model in the Meta-BiLSTM relatively late, after two layers of BiLSTMs. For both the word and character models, we use two layers of BiLSTMs with 300 LSTM cells"
K18-2011,Q17-1010,0,0.119675,"Missing"
K18-2011,W13-4902,1,0.850186,"ogical Features Having a strong morphological analyzer, we were interested in finding out whether or not we can improve parsing accuracy using predicted morphological information. We conducted several experiments on the development sets for a subset of treebanks. However, no experiment gave us any improvement in terms of LAS and we decided not to use this technique for the shared task. What we tried was to create an embedding representing either the full set of morphological features or a subset of potentially useful features, for example case (which has been shown to be useful for parsing by Kapociute-Dzikiene et al. (2013) and Eryigit et al. (2008)), verb form and a few others. That embedding was concatenated to the word embedding at the input of the BiLSTM. We varied the embedding size (10, 20, 30, 40), tried different subsets of morphological features, and tried with and without using dropout on that embedding. We also tried creating an embedding of a concatenation of the universal POS tag and the Case feature and replace the POS embedding with this one. We are currently unsure why none of these experiments were successful and plan to investigate this 9 https://radimrehurek.com/gensim/ An alternative strategy"
K18-2011,D14-1082,0,0.0860011,"pped to universal POS tags and a few morphological features like person, number and gender. For Thai, we annotated about 33,000 sentences from Wikipedia using PyThaiNLP8 and mapped only to UPOS tags (no features). Unfortunately, we realized only after the test phase that PyThaiNLP was not a permitted resource, which invalidates our UPOS tagging scores for Thai, as well as the LAS and MLAS scores which depend on the tagger. Note, however, that the score for morphological features xi = e(wi ) ◦ e(pi ) ◦ BiLSTM(ch1:m ). Here, e(wi ) represents the word embedding and e(pi ) the POS tag embedding (Chen and Manning, 2014); these are concatenated to a character-based vector, obtained by running a BiLSTM over the characters ch1:m of wi . With the aim of training multi-treebank models, we additionally created a variant of the parser which adds a treebank embedding e(tbi ) to input vectors in a spirit similar to the language embeddings of Ammar et al. (2016) and de Lhoneux et al. (2017a): xi = e(wi ) ◦ e(pi ) ◦ BiLSTM(ch1:m ) ◦ e(tbi ). We have previously shown that treebank embeddings provide an effective way to combine multiple monolingual heterogeneous treebanks (Stymne et al., 2018) and applied them to lowreso"
K18-2011,Q16-1032,0,0.158942,"or the PUD treebanks (except Thai), Japanese Modern and Naija NSC, we use the same model substitutions as for segmentation (see Table 2). is not affected, as we did not predict features at all for Thai. The same goes for sentence and word segmentation, which do not depend on the tagger. Lemmas Due to time constraints we chose not to focus on the BLEX metric in this shared task. In order to avoid zero scores, however, we simply copied a lowercased version of the raw token into the lemma column. 5 Dependency Parsing We use a greedy transition-based parser (Nivre, 2008) based on the framework of Kiperwasser and Goldberg (2016b) where BiLSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2008) learn representations of tokens in context, and are trained together with a multi-layer perceptron that predicts transitions and arc labels based on a few BiLSTM vectors. Our parser is extended with a S WAP transition to allow the construction of nonprojective dependency trees (Nivre, 2009). We also introduce a static-dynamic oracle to allow the parser to learn from non-optimal configurations at training time in order to recover better from mistakes at test time (de Lhoneux et al., 2017b). In our parser, the vector representatio"
K18-2011,K17-3022,1,0.72705,"Missing"
K18-2011,Q16-1023,0,0.434449,"or the PUD treebanks (except Thai), Japanese Modern and Naija NSC, we use the same model substitutions as for segmentation (see Table 2). is not affected, as we did not predict features at all for Thai. The same goes for sentence and word segmentation, which do not depend on the tagger. Lemmas Due to time constraints we chose not to focus on the BLEX metric in this shared task. In order to avoid zero scores, however, we simply copied a lowercased version of the raw token into the lemma column. 5 Dependency Parsing We use a greedy transition-based parser (Nivre, 2008) based on the framework of Kiperwasser and Goldberg (2016b) where BiLSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2008) learn representations of tokens in context, and are trained together with a multi-layer perceptron that predicts transitions and arc labels based on a few BiLSTM vectors. Our parser is extended with a S WAP transition to allow the construction of nonprojective dependency trees (Nivre, 2009). We also introduce a static-dynamic oracle to allow the parser to learn from non-optimal configurations at training time in order to recover better from mistakes at test time (de Lhoneux et al., 2017b). In our parser, the vector representatio"
K18-2011,W17-6314,1,0.712346,"Missing"
K18-2011,K17-3002,0,0.0838483,"ainian IU. All in all, the 2018 edition of the Uppsala parser can be characterized as a system that is strong on segmentation (especially word segmentation) and prediction of UPOS tags and morphological features, and where the dependency parsing component performs well in low-resource scenarios thanks to the use of multi-treebank models, both within and across languages. For what it is worth, we also seem to have the highest ranking singleparser transition-based system in a task that is otherwise dominated by graph-based models, in particular variants of the winning Stanford system from 2017 (Dozat et al., 2017). 8 9 Conclusion We have described the Uppsala submission to the CoNLL 2018 shared task, consisting of a segmenter that jointly extracts words and sentences from a raw text, a tagger that provides UPOS tags and morphological features, and a parser that builds a dependency tree given the words and tags of each sentence. For the parser we applied multi-treebank models both monolingually and multilingually, resulting in only 34 models for 82 treebanks as well as significant improvements in parsing accuracy especially for low-resource languages. We ranked 7th for the official LAS and MLAS scores,"
K18-2011,K18-2002,0,0.0159289,"icial LAS and MLAS scores, and first for the unofficial scores on word segmentation, UPOS tagging and morphological features. Acknowledgments We are grateful to the shared task organizers and to Dan Zeman and Martin Potthast in particular, and we acknowledge the computational resources provided by CSC in Helsinki and Sigma2 in Oslo through NeIC-NLPL (www.nlpl.eu). Aaron Smith was supported by the Swedish Research Council. Extrinsic Parser Evaluation In addition to the official shared task evaluation, we also participated in the 2018 edition of the Extrinsic Parser Evaluation Initiative (EPE) (Fares et al., 2018), where parsers developed for the CoNLL 2018 shared task were evaluated with respect to their contribution to three downstream systems: biological event extraction, fine-grained opinion analysis, and negation resolution. The downstream systems are available for English only, and we participated with our English model trained on English EWT, English LinES and English GUM, using English EWT as the proxy. In the extrinsic evaluation, the Uppsala system ranked second for event extraction, first for opinion analysis, and 16th (out of 16 systems) for negation resolution. Our results for the first tw"
K18-2011,J08-4003,1,0.671677,"e adopt three different strategies: • For the PUD treebanks (except Thai), Japanese Modern and Naija NSC, we use the same model substitutions as for segmentation (see Table 2). is not affected, as we did not predict features at all for Thai. The same goes for sentence and word segmentation, which do not depend on the tagger. Lemmas Due to time constraints we chose not to focus on the BLEX metric in this shared task. In order to avoid zero scores, however, we simply copied a lowercased version of the raw token into the lemma column. 5 Dependency Parsing We use a greedy transition-based parser (Nivre, 2008) based on the framework of Kiperwasser and Goldberg (2016b) where BiLSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2008) learn representations of tokens in context, and are trained together with a multi-layer perceptron that predicts transitions and arc labels based on a few BiLSTM vectors. Our parser is extended with a S WAP transition to allow the construction of nonprojective dependency trees (Nivre, 2009). We also introduce a static-dynamic oracle to allow the parser to learn from non-optimal configurations at training time in order to recover better from mistakes at test time (de Lhoneu"
K18-2011,P09-1040,1,0.839321,"task. In order to avoid zero scores, however, we simply copied a lowercased version of the raw token into the lemma column. 5 Dependency Parsing We use a greedy transition-based parser (Nivre, 2008) based on the framework of Kiperwasser and Goldberg (2016b) where BiLSTMs (Hochreiter and Schmidhuber, 1997; Graves, 2008) learn representations of tokens in context, and are trained together with a multi-layer perceptron that predicts transitions and arc labels based on a few BiLSTM vectors. Our parser is extended with a S WAP transition to allow the construction of nonprojective dependency trees (Nivre, 2009). We also introduce a static-dynamic oracle to allow the parser to learn from non-optimal configurations at training time in order to recover better from mistakes at test time (de Lhoneux et al., 2017b). In our parser, the vector representation xi of a word type wi before it is passed to the BiLSTM feature extractors is given by: • For Faroese we used the model for Norwegian Nynorsk, as we believe this to be the most closely related language. • For treebanks with small training sets we use only the provided training sets for training. Since these treebanks do not have development sets, we use"
K18-2011,J93-1004,0,0.0296153,"Missing"
K18-2011,Q18-1030,1,0.830131,"arginally) higher score with the mono-treebank baseline model: Estonian EDT, Russian SynTagRus, Slovenian SSJ, and Turkish IMST. Looking at the aggregate sets, we see that, as expected, the pooling of resources helps most for LOW- RESOURCE (25.33 vs. 17.72) and SMALL (63.60 vs. 60.06), but even for BIG there is some improvement (80.21 vs. 79.61). We find these results very encouraging, as they indicate that our treebank embedding method is a reliFor word segmentation, we obtained the best results overall, strongly outperforming the mean for all groups except SMALL. We know from previous work (Shao et al., 2018) that our word segmenter performs well on more challenging languages like Arabic, Hebrew, Japanese, and Chinese (although we were beaten by the Stanford team for the former two and by the HIT-SCIR team for the latter two). By contrast, it sometimes falls below the mean for the easier languages, but typically only by a very small fraction (for example 99.99 vs. 100.00 for 3 treebanks). Finally, it is worth noting that the maximum-matching segmenter developed specifically for Thai achieved a score of 69.93, which was more than 5 points better than any other system. Our results for UPOS tagging i"
K18-2011,I17-1018,1,0.925902,"ext, without any linguistic annotation, and output full labelled dependency trees for 82 test treebanks covering 46 different languages. Besides the labeled attachment score (LAS) used to evaluate systems in the 2017 edition of the Shared Task (Zeman et al., 2017), this year’s task introduces two new metrics: morphology-aware labeled attachment score (MLAS) and bi-lexical dependency score (BLEX). The Uppsala system focuses exclusively on LAS and MLAS, and consists of a three-step pipeline. The first step is a model for joint sentence and word segmentation which uses the BiRNN-CRF framework of Shao et al. (2017, 2018) to predict sentence and word boundaries in the raw input and Corrigendum: After the test phase was over, we discovered that we had used a non-permitted resource when developing the UPOS tagger for Thai PUD (see Section 4). Setting our LAS, MLAS and UPOS scores to 0.00 for Thai PUD gives the corrected scores: LAS 72.31, MLAS 59.17, UPOS 90.50. This does not affect the ranking for any of the three scores, as confirmed by the shared task organizers. 2 Resources All three components of our system were trained principally on the training sets of Universal Dependencies v2.2 released to coinc"
K18-2011,D18-1291,1,0.828983,"Missing"
K18-2011,P18-2098,1,0.816536,"Missing"
K18-2011,tiedemann-2012-parallel,0,0.122801,"Missing"
K18-2011,C96-1035,0,0.0335101,"Missing"
K18-2011,K18-2001,1,0.844683,"Missing"
K18-2011,P07-2045,0,\N,Missing
K18-2011,J08-4010,1,\N,Missing
K18-2011,J08-3003,1,\N,Missing
L16-1248,N01-1016,0,0.120865,"ll transcribed lexical tokens, typically by introduction of new labels for speech-specific phenomena, while on the other side we find schemes, in which only well-formed, written-like constructions are included in the resulting syntactic trees, disregarding disfluencies and other types of ’noisy’ structural particularities. This prevalent multi-layer approach has partially been motivated by the data-driven parsing systems themselves, usually adopting a two-pass pipeline architecture, in which the structural particularities are first removed and followed by parsing of normalized transcriptions (Charniak and Johnson, 2001). Recent advances in parsing systems using nonmonotonic transition-based algorithms, however, show that joint treatment of disfluencies and other syntactic relations actually out-performs state-of-the-art pipeline approaches (Rasooli and Tetreault, 2013; Honnibal and Johnson, 2014). Such heterogeneity of spoken language annotation schemes inevitably leads to a restricted usage of existing spoken language treebanks in linguistic research and parsing systems alike, limiting any direct comparison between spoken language treebanks of different formalisms, modalities (spoken or written) or language"
L16-1248,erjavec-etal-2010-jos,0,0.176528,"Missing"
L16-1248,Q14-1011,0,0.0265362,"pes of ’noisy’ structural particularities. This prevalent multi-layer approach has partially been motivated by the data-driven parsing systems themselves, usually adopting a two-pass pipeline architecture, in which the structural particularities are first removed and followed by parsing of normalized transcriptions (Charniak and Johnson, 2001). Recent advances in parsing systems using nonmonotonic transition-based algorithms, however, show that joint treatment of disfluencies and other syntactic relations actually out-performs state-of-the-art pipeline approaches (Rasooli and Tetreault, 2013; Honnibal and Johnson, 2014). Such heterogeneity of spoken language annotation schemes inevitably leads to a restricted usage of existing spoken language treebanks in linguistic research and parsing systems alike, limiting any direct comparison between spoken language treebanks of different formalisms, modalities (spoken or written) or languages. The need for a cross-linguistically harmonized treatment of non-languagespecific phenomena is even more important in the field of spoken language resources, as these are still very limited in terms of number, size and availability due to their costly construction. To ensure its"
L16-1248,lacheret-etal-2014-rhapsodie,0,0.0632412,"arning on annotated spoken data, rather than using models built on written language observation. Since the influential syntactic annotation of the Switchboard section of the Penn Treebank (Godfrey et al., 1992; Marcus et al., 1993), several syntactically annotated spoken corpora have emerged, such as the Verbmobil treebanks for English, German and Japanese (Hinrichs et al., 2000), the CGN treebank for Dutch (van der Wouden et al., 2002), the NoTa treebank for Norwegian (Johannessen and Jørgensen, 2006), the PDTSL treebank for Czech (Hajiˇc et al., 2008), and the Rhapsodie treebank for French (Lacheret et al., 2014). However, until now, no syntactically annotated data has been available for spoken Slovenian. In addition to differences in the underlying phrase-based or dependency-based grammatical formalisms, existing spoken treebanks vary considerably in their approach to annotation of syntactic particularities of spoken language, even though these are not generally considered as languagespecific. On one side of the spectrum are annotation schemes providing syntactic analysis of all transcribed lexical tokens, typically by introduction of new labels for speech-specific phenomena, while on the other side"
L16-1248,J93-2004,0,0.0607613,"ta consisting of shorter and more elliptic sentences, less and simpler nominal phrases, and more relations marking disfluencies, interaction, deixis and modality. Keywords: dependency treebank, spontaneous speech, Universal Dependencies 1. Introduction It is nowadays a well-established fact that data-driven parsing systems used in different speech-processing applications benefit from learning on annotated spoken data, rather than using models built on written language observation. Since the influential syntactic annotation of the Switchboard section of the Penn Treebank (Godfrey et al., 1992; Marcus et al., 1993), several syntactically annotated spoken corpora have emerged, such as the Verbmobil treebanks for English, German and Japanese (Hinrichs et al., 2000), the CGN treebank for Dutch (van der Wouden et al., 2002), the NoTa treebank for Norwegian (Johannessen and Jørgensen, 2006), the PDTSL treebank for Czech (Hajiˇc et al., 2008), and the Rhapsodie treebank for French (Lacheret et al., 2014). However, until now, no syntactically annotated data has been available for spoken Slovenian. In addition to differences in the underlying phrase-based or dependency-based grammatical formalisms, existing spo"
L16-1248,de-marneffe-etal-2014-universal,1,0.845093,"f dependency trees, however, it is a straightforward task to filter out the nonlexical tokens and obtain representations with words only. 4. 4.1. Annotation Scheme Universal Dependencies Universal Dependencies2 is a recently proposed annotation scheme for development of cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective (Nivre, 2015). It is the result of previous similar standardization projects (Zeman, 2008; Petrov et al., 2012; Marneffe et al., 2014) and has already been applied to more than 30 different languages (Nivre et al., 2015), including (written) Slovenian. A detailed description of the design principles and the relation taxonomy is given in Nivre (2015) and Nivre et al. (2016), with the main principles being that dependency relations hold primarily between content words, function words attach to the content word they specify and punctuation marks attach to the clause or phrase to which they belong. The basic dependency representation forms a tree, but additional dependencies can be added in the so-called enhanced representation."
L16-1248,L16-1262,1,0.900831,"Missing"
L16-1248,petrov-etal-2012-universal,0,0.0780137,"re considered nodes of dependency trees, however, it is a straightforward task to filter out the nonlexical tokens and obtain representations with words only. 4. 4.1. Annotation Scheme Universal Dependencies Universal Dependencies2 is a recently proposed annotation scheme for development of cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective (Nivre, 2015). It is the result of previous similar standardization projects (Zeman, 2008; Petrov et al., 2012; Marneffe et al., 2014) and has already been applied to more than 30 different languages (Nivre et al., 2015), including (written) Slovenian. A detailed description of the design principles and the relation taxonomy is given in Nivre (2015) and Nivre et al. (2016), with the main principles being that dependency relations hold primarily between content words, function words attach to the content word they specify and punctuation marks attach to the clause or phrase to which they belong. The basic dependency representation forms a tree, but additional dependencies can be added in the so-called"
L16-1248,D13-1013,0,0.0469295,"ing disfluencies and other types of ’noisy’ structural particularities. This prevalent multi-layer approach has partially been motivated by the data-driven parsing systems themselves, usually adopting a two-pass pipeline architecture, in which the structural particularities are first removed and followed by parsing of normalized transcriptions (Charniak and Johnson, 2001). Recent advances in parsing systems using nonmonotonic transition-based algorithms, however, show that joint treatment of disfluencies and other syntactic relations actually out-performs state-of-the-art pipeline approaches (Rasooli and Tetreault, 2013; Honnibal and Johnson, 2014). Such heterogeneity of spoken language annotation schemes inevitably leads to a restricted usage of existing spoken language treebanks in linguistic research and parsing systems alike, limiting any direct comparison between spoken language treebanks of different formalisms, modalities (spoken or written) or languages. The need for a cross-linguistically harmonized treatment of non-languagespecific phenomena is even more important in the field of spoken language resources, as these are still very limited in terms of number, size and availability due to their costly"
L16-1248,van-der-wouden-etal-2002-syntactic,0,0.404729,"Missing"
L16-1248,P13-4001,0,0.0284453,"Missing"
L16-1248,zeman-2008-reusable,0,0.222712,"tion tokens are considered nodes of dependency trees, however, it is a straightforward task to filter out the nonlexical tokens and obtain representations with words only. 4. 4.1. Annotation Scheme Universal Dependencies Universal Dependencies2 is a recently proposed annotation scheme for development of cross-linguistically consistent treebank annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective (Nivre, 2015). It is the result of previous similar standardization projects (Zeman, 2008; Petrov et al., 2012; Marneffe et al., 2014) and has already been applied to more than 30 different languages (Nivre et al., 2015), including (written) Slovenian. A detailed description of the design principles and the relation taxonomy is given in Nivre (2015) and Nivre et al. (2016), with the main principles being that dependency relations hold primarily between content words, function words attach to the content word they specify and punctuation marks attach to the clause or phrase to which they belong. The basic dependency representation forms a tree, but additional dependencies can be ad"
L16-1262,W13-2308,0,0.0114723,"g diverse tag sets to a common standard. The morphological layer also builds on Interset (Zeman, 2008), which started as a tool for conversion between morphosyntactic tag sets of multiple languages. It dates back to 2006 when it was used in the first experiments with cross-lingual delexicalized parser adaptation (Zeman and Resnik, 2008). The Stanford dependencies, used in the syntactic layer, were developed for English in 2005 and eventually emerged as the de facto standard for dependency analysis of English. They have since been adapted to a number of different languages (Chang et al., 2009; Bosco et al., 2013; Haverinen et al., 2013; Seraji et al., 2013; Lipenkova and Souˇcek, 2014). These resources have featured in other attempts at universal standards. The Google Universal Dependency Treebank (UDT) project (McDonald et al., 2013) was the first attempt to combine the Stanford dependencies and the Google universal part-of-speech tags into a universal annotation scheme: treebanks were released for 6 languages in 2013 (English, French, German, Spanish, Swedish and Korean) and for 11 languages in 2014 (Brazilian Portuguese, English, Finnish, French, German, Italian, Indonesian, Japanese, Korean, Span"
L16-1262,W06-2920,0,0.443151,"clauses as an important subtype of adnominal clauses. By design, we can always map back to the core label set by stripping the specific relations that appear after the colon. For a complete list of currently used languagespecific relations, we refer to the UD website. 2 Complete guidelines for the enhanced representations have not been worked out yet, and only one treebank (Finnish) uses them so far, but see Schuster and Manning (2016) for a concrete proposal for English. 3.4. Format and Tools The data is encoded in the CoNLL-U format, which is an evolution of the widely used CoNLL-X format (Buchholz and Marsi, 2006), where each word/token is represented in tab-separated columns on one line and sentence boundaries are marked by blank lines. The 10 columns on a word/token line are used to specify a unique id (integer for words, ranges for multiword tokens), word form, lemma, universal part-of-speech tag, optional language-specific part-ofspeech tag, morphological features, head, dependency relation, additional dependencies in the enhanced representation and miscellaneous information. The format is illustrated in Figure 3, with the French sentence from Figure 2. To support work on treebanks in this format,"
L16-1262,W09-2307,1,0.329071,"standard for mapping diverse tag sets to a common standard. The morphological layer also builds on Interset (Zeman, 2008), which started as a tool for conversion between morphosyntactic tag sets of multiple languages. It dates back to 2006 when it was used in the first experiments with cross-lingual delexicalized parser adaptation (Zeman and Resnik, 2008). The Stanford dependencies, used in the syntactic layer, were developed for English in 2005 and eventually emerged as the de facto standard for dependency analysis of English. They have since been adapted to a number of different languages (Chang et al., 2009; Bosco et al., 2013; Haverinen et al., 2013; Seraji et al., 2013; Lipenkova and Souˇcek, 2014). These resources have featured in other attempts at universal standards. The Google Universal Dependency Treebank (UDT) project (McDonald et al., 2013) was the first attempt to combine the Stanford dependencies and the Google universal part-of-speech tags into a universal annotation scheme: treebanks were released for 6 languages in 2013 (English, French, German, Spanish, Swedish and Korean) and for 11 languages in 2014 (Brazilian Portuguese, English, Finnish, French, German, Italian, Indonesian, Ja"
L16-1262,P11-1061,1,0.573621,"UNCT Definite=Def Gender=Fem Number=Plur Definite=Def Gender=Masc Definite=Def Gender=Masc Number=Plur Number=Plur Person=3 Number=Plur Number=Plur Number=Sing Number=Sing Tense=Pres Figure 2: UD annotation for a French sentence. (Translation: However, girls love chocolate desserts.) 2. History 3. UD comprises two layers of annotation with diverse origins. The Google universal tag set used in the morphological layer grew out of the cross-linguistic error analysis based on the CoNLL-X shared task data by McDonald and Nivre (2007). It was initially used for unsupervised partof-speech tagging by Das and Petrov (2011), and has been adopted as a widely used standard for mapping diverse tag sets to a common standard. The morphological layer also builds on Interset (Zeman, 2008), which started as a tool for conversion between morphosyntactic tag sets of multiple languages. It dates back to 2006 when it was used in the first experiments with cross-lingual delexicalized parser adaptation (Zeman and Resnik, 2008). The Stanford dependencies, used in the syntactic layer, were developed for English in 2005 and eventually emerged as the de facto standard for dependency analysis of English. They have since been adapt"
L16-1262,W08-1301,1,0.58058,"Missing"
L16-1262,de-marneffe-etal-2006-generating,1,0.213978,"Missing"
L16-1262,de-marneffe-etal-2014-universal,1,0.831309,"Missing"
L16-1262,E14-4028,0,0.0377832,"Missing"
L16-1262,N15-3011,1,0.696846,"Missing"
L16-1262,D07-1013,1,0.230402,"hocolat . le fille adorer le dessert a` le chocolat . DET NOUN VERB DET NOUN ADP DET NOUN PUNCT Definite=Def Gender=Fem Number=Plur Definite=Def Gender=Masc Definite=Def Gender=Masc Number=Plur Number=Plur Person=3 Number=Plur Number=Plur Number=Sing Number=Sing Tense=Pres Figure 2: UD annotation for a French sentence. (Translation: However, girls love chocolate desserts.) 2. History 3. UD comprises two layers of annotation with diverse origins. The Google universal tag set used in the morphological layer grew out of the cross-linguistic error analysis based on the CoNLL-X shared task data by McDonald and Nivre (2007). It was initially used for unsupervised partof-speech tagging by Das and Petrov (2011), and has been adopted as a widely used standard for mapping diverse tag sets to a common standard. The morphological layer also builds on Interset (Zeman, 2008), which started as a tool for conversion between morphosyntactic tag sets of multiple languages. It dates back to 2006 when it was used in the first experiments with cross-lingual delexicalized parser adaptation (Zeman and Resnik, 2008). The Stanford dependencies, used in the syntactic layer, were developed for English in 2005 and eventually emerged"
L16-1262,P13-2017,1,0.877648,"Missing"
L16-1262,W15-2127,0,0.0113361,"n English, we also obtain parallel representations between prepositional phrases and subordinate clauses, which are in practice often introduced by a preposition, as in (5). nmod case nsubj (5) a. Sue 1662 det left after the rehearsal advcl nsubj b. Sue Language mark nsubj left after we did The choice to make content words the backbone of the syntactic representations may seem to be at odds with the strong tendency in modern syntactic theory to give priority to functional heads, a tendency that is found in both constituency-based and dependency-based approaches to syntax (Brug´e et al., 2012; Osborne and Maxwell, 2015). We believe, however, that this conflict is more apparent than real. The UD view is that we need to recognize both lexical and functional heads, but in order to maximize parallelism across languages, only lexical heads are inferable from the topology of our tree structures. Functional heads are instead represented as specifying features of content words, using dedicated relation labels, features which can alternatively be specified through morphological processes. In the dependency grammar tradition, this is very close to the view of Tesni`ere (1959), according to whom dependencies hold betwe"
L16-1262,petrov-etal-2012-universal,1,0.717175,"exist to build consistent resources for many languages, and the UD project is a merger of some of the initiatives. It combines the (universal) Stanford dependencies (de Marneffe et al., 2006; de Marneffe and Manning, 2008; de Marneffe et al., 2014), the universal sv: en nsubj katt conj jagar r˚attor conj och m¨oss cc conj nsubj ? da: en dobj kat jager rotter og mus conj det en: a nsubj cat dobj chases cc rats and mice Figure 1: Divergent annotation of parallel structures Google dependency scheme (Universal Dependency Treebanks) (McDonald et al., 2013), the Google universal partof-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tag sets (Zeman, 2008) used in the HamleDT treebanks (a project that transforms existing treebanks under a common annotation scheme, Zeman et al. 2012). UD is thus based on common usage and existing de facto standards, and is intended to replace all the previous versions by a single coherent standard.1 The general philosophy is to provide a universal inventory of categories and guidelines to facilitate consistent annotation of similar constructions across languages, while allowing languagespecific extensions when necessary. In this paper, we p"
L16-1262,rosa-etal-2014-hamledt,1,0.832586,"Missing"
L16-1262,L16-1376,1,0.208211,"fferent languages. For instance, while the universal UD scheme has a single relation acl for adnominal clauses, several languages make use of the subtype acl:relcl to distinguish relative clauses as an important subtype of adnominal clauses. By design, we can always map back to the core label set by stripping the specific relations that appear after the colon. For a complete list of currently used languagespecific relations, we refer to the UD website. 2 Complete guidelines for the enhanced representations have not been worked out yet, and only one treebank (Finnish) uses them so far, but see Schuster and Manning (2016) for a concrete proposal for English. 3.4. Format and Tools The data is encoded in the CoNLL-U format, which is an evolution of the widely used CoNLL-X format (Buchholz and Marsi, 2006), where each word/token is represented in tab-separated columns on one line and sentence boundaries are marked by blank lines. The 10 columns on a word/token line are used to specify a unique id (integer for words, ranges for multiword tokens), word form, lemma, universal part-of-speech tag, optional language-specific part-ofspeech tag, morphological features, head, dependency relation, additional dependencies i"
L16-1262,E12-2021,1,0.581828,"Missing"
L16-1262,stepanek-pajas-2010-querying,0,0.067769,"Missing"
L16-1262,P13-2103,1,0.625022,"hese resources have featured in other attempts at universal standards. The Google Universal Dependency Treebank (UDT) project (McDonald et al., 2013) was the first attempt to combine the Stanford dependencies and the Google universal part-of-speech tags into a universal annotation scheme: treebanks were released for 6 languages in 2013 (English, French, German, Spanish, Swedish and Korean) and for 11 languages in 2014 (Brazilian Portuguese, English, Finnish, French, German, Italian, Indonesian, Japanese, Korean, Spanish and Swedish). The first proposal for incorporating morphology was made by Tsarfaty (2013). The second version of HamleDT (Rosa et al., 2014) provided Stanford/Google annotation for 30 languages by automatically harmonizing treebanks with different native annotations. These efforts were followed by the development of the universal Stanford dependencies (USD), revising Stanford Dependencies for cross-linguistic annotations in light of the Google scheme (de Marneffe et al., 2014). UD is the result of merging all these initiatives into a single coherent framework, based on the universal Stanford dependencies, an extended version of the Google universal tag set, a revised subset of the"
L16-1262,I08-3008,1,0.20904,"the morphological layer grew out of the cross-linguistic error analysis based on the CoNLL-X shared task data by McDonald and Nivre (2007). It was initially used for unsupervised partof-speech tagging by Das and Petrov (2011), and has been adopted as a widely used standard for mapping diverse tag sets to a common standard. The morphological layer also builds on Interset (Zeman, 2008), which started as a tool for conversion between morphosyntactic tag sets of multiple languages. It dates back to 2006 when it was used in the first experiments with cross-lingual delexicalized parser adaptation (Zeman and Resnik, 2008). The Stanford dependencies, used in the syntactic layer, were developed for English in 2005 and eventually emerged as the de facto standard for dependency analysis of English. They have since been adapted to a number of different languages (Chang et al., 2009; Bosco et al., 2013; Haverinen et al., 2013; Seraji et al., 2013; Lipenkova and Souˇcek, 2014). These resources have featured in other attempts at universal standards. The Google Universal Dependency Treebank (UDT) project (McDonald et al., 2013) was the first attempt to combine the Stanford dependencies and the Google universal part-of-"
L16-1262,zeman-etal-2012-hamledt,1,0.729155,"Missing"
L16-1262,zeman-2008-reusable,1,0.897534,"erger of some of the initiatives. It combines the (universal) Stanford dependencies (de Marneffe et al., 2006; de Marneffe and Manning, 2008; de Marneffe et al., 2014), the universal sv: en nsubj katt conj jagar r˚attor conj och m¨oss cc conj nsubj ? da: en dobj kat jager rotter og mus conj det en: a nsubj cat dobj chases cc rats and mice Figure 1: Divergent annotation of parallel structures Google dependency scheme (Universal Dependency Treebanks) (McDonald et al., 2013), the Google universal partof-speech tags (Petrov et al., 2012), and the Interset interlingua for morphosyntactic tag sets (Zeman, 2008) used in the HamleDT treebanks (a project that transforms existing treebanks under a common annotation scheme, Zeman et al. 2012). UD is thus based on common usage and existing de facto standards, and is intended to replace all the previous versions by a single coherent standard.1 The general philosophy is to provide a universal inventory of categories and guidelines to facilitate consistent annotation of similar constructions across languages, while allowing languagespecific extensions when necessary. In this paper, we present version 1 of the universal guidelines and explain the underlying d"
L16-1374,de-marneffe-etal-2014-universal,1,0.91623,"Missing"
L16-1374,de-marneffe-etal-2006-generating,0,0.111941,"Missing"
L16-1374,W08-1301,0,0.127764,"Missing"
L16-1374,foth-etal-2014-size,0,0.0446328,"Missing"
L16-1374,nivre-etal-2006-maltparser,1,0.750147,"ttp://stp.lingfil.uu.se/∼mojgan/UPDT.html 3 The treebank data is extracted from the open source, validated Uppsala Persian Corpus (UPC), which is currently the largest freely available corpus of Persian. The corpus consists of 2,704,028 tokens and annotated with part-of-speech tags and morphological features. For a comprehensive description of the corpus pertaining to the tokenization and morphological annotation see Seraji (2015, Chapter 3) but annotated with special labels at the syntactic level instead. The syntactic annotation of the UPDT has been done semi-automatically using MaltParser (Nivre et al., 2006) in a bootstrapping scenario. All sentences have been manually validated. When converting the UPDT to the Persian UD, all words containing unsegmented clitics (pronominal and copula clitics) annotated with complex labels in the UPDT, were separated from the clitics and received distinct labels in the Persian UD. Figure 1 illustrates the differences between the two treebanks for a Persian sentence. In this example, the direct object (dobj) in the UPDT consists of the word mother and the possessive pronominal clitic her/his (colored in pink), marked with the label dobj/pc. This label in the UPDT"
L16-1374,petrov-etal-2012-universal,0,0.137394,"Missing"
L16-1374,W15-2133,1,0.849148,"e been separated from the clitics and appear with distinct labels in the Persian UD. The treebank has its original syntactic annotation scheme based on Stanford Typed Dependencies. In this paper, we present the approaches taken in the development of the Persian UD. Keywords: Universal Dependencies, Persian, Treebank 1. Introduction In the past decade, the development of numerous dependency parsers for different languages has frequently been benefited by the use of syntactically annotated resources, or treebanks (B¨ohmov´a et al., 2003; Haverinen et al., 2010; Kromann, 2003; Foth et al., 2014; Seraji et al., 2015; Vincze et al., 2010). However, treebanks only exist for a small number of languages, and considering the number of 7,000+ languages in the world,1 a large number of languages still lack treebanks. Due to the diverse typologies and grammatical structures that exist across languages, treebanks are created with different annotation schemes. These annotation variations can further be explained by different linguistic theories and the syntactic annotations that treebank developers select based on their own preferences (Nivre, 2015). These dissimilarities in annotation schemes often have an impact"
L16-1374,zeman-2008-reusable,0,0.112212,"n that having a common standard and cross-linguistically valid annotation scheme would favor parsing research. Recently, there have been a number of initiatives for developing data sets with cross-linguistically consistent annotation scheme for morphological and syntactic structures. These efforts have resulted in the emergence of the Stanford Typed Dependencies Representation (de Marneffe et al., 2006; de Marneffe and Manning, 2008), the Google Universal Part-of-Speech Tagset (Petrov et al., 2012), and Interset interlingua for morphosyntactic features used in the HamleDT treebank collection (Zeman, 2008; Zeman et al., 2012). The most recent effort is the Universal Dependencies (UD), which more or less combine all the earlier efforts in this regard. In 1 http://www.bbc.co.uk/languages/guide/languages.shtml this paper, we present how we adapt the Universal Dependencies to Persian by converting the Uppsala Persian Dependency Treebank (UPDT) (Seraji, 2015) to the Persian Universal Dependencies (Persian UD). First, we briefly describe the Universal Dependencies and then we present the morphosyntactic annotations used in the extended version of the Persian UD. 2. Universal Dependencies Universal D"
L16-1374,zeman-etal-2012-hamledt,0,0.0364471,"Missing"
megyesi-etal-2008-swedish,J93-1004,0,\N,Missing
megyesi-etal-2008-swedish,nivre-etal-2006-talbanken05,1,\N,Missing
megyesi-etal-2008-swedish,nivre-etal-2006-maltparser,1,\N,Missing
megyesi-etal-2008-swedish,steinberger-etal-2006-jrc,0,\N,Missing
megyesi-etal-2008-swedish,N06-1042,0,\N,Missing
megyesi-etal-2008-swedish,W06-2920,0,\N,Missing
megyesi-etal-2008-swedish,A00-1031,0,\N,Missing
megyesi-etal-2008-swedish,megyesi-etal-2006-building,1,\N,Missing
megyesi-etal-2008-swedish,W07-2441,0,\N,Missing
megyesi-etal-2008-swedish,J03-1002,0,\N,Missing
megyesi-etal-2008-swedish,W07-2420,1,\N,Missing
megyesi-etal-2010-english,J93-1004,0,\N,Missing
megyesi-etal-2010-english,megyesi-etal-2008-swedish,1,\N,Missing
megyesi-etal-2010-english,cmejrek-etal-2004-prague,0,\N,Missing
megyesi-etal-2010-english,nivre-etal-2006-talbanken05,1,\N,Missing
megyesi-etal-2010-english,nivre-etal-2006-maltparser,1,\N,Missing
megyesi-etal-2010-english,steinberger-etal-2006-jrc,0,\N,Missing
megyesi-etal-2010-english,N06-1042,0,\N,Missing
megyesi-etal-2010-english,W06-2920,0,\N,Missing
megyesi-etal-2010-english,A00-1031,0,\N,Missing
megyesi-etal-2010-english,W07-2441,0,\N,Missing
megyesi-etal-2010-english,J03-1002,0,\N,Missing
megyesi-etal-2010-english,W07-2420,1,\N,Missing
megyesi-etal-2010-english,W09-4636,1,\N,Missing
N07-1050,afonso-etal-2002-floresta,0,0.0445123,"Missing"
N07-1050,H92-1026,0,0.0521052,"rresponds to unrestricted non-projective parsing. With low values of d, we will reduce the number of calls to L INK(i, j), which will reduce the overall parsing time provided that the time required to compute P ERMISSIBLE(i, j, d) is insignificant compared to the time needed for L INK(i, j). This is typically the case in data-driven systems, where L INK(i, j) requires a call to a trained classifier, while P ERMISSIBLE(i, j, d) only needs access to the partially built graph G.2 4 History-Based Parsing History-based parsing uses features of the parsing history to predict the next parser action (Black et al., 1992). In the current setup, this involves using features of the partially built dependency graph G and the input x = (w1 , . . . , wn ) to predict the outcome of the nondeterministic L INK(i, j) operation. Given that we use a deterministic parsing strategy, this reduces to a pure classification problem. Let Φ(i, j, G) = (φ1 ,. . . ,φm ) be a feature vector representation of the parser history at the time of performing L INK(i, j). The task of the historybased classifier is then to map Φ(i, j, G) to one of the following actions: r 1. Add the arc i → j (for some r ∈ R). r 2. Add the arc j → i (for s"
N07-1050,W06-2920,0,0.212304,"Missing"
N07-1050,dzeroski-etal-2006-towards,0,0.0239769,"Missing"
N07-1050,W05-1505,0,0.0855815,"Missing"
N07-1050,W02-2016,0,0.199616,"Missing"
N07-1050,P06-2066,1,0.910911,"Missing"
N07-1050,E06-1011,0,0.0875215,"here the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. The most popular strategy for capturing nonprojective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nov´ak, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006). And it is rare to find parsers that derive non-projective structures directly, the notable exception being the non-projective spanning tree parser proposed by McDonald et al. (2005). There are essentially two arguments that have been advanced against using parsing algorithms that derive non-projective dependency structures directly. The first is that the added expressivity compromises efficiency, since the parsing problem for a grammar that allows arbitrary non-projective dependency structures has been shown to be N P complete (Neuhaus and Br¨oker, 1997). On the other hand, most data-driven"
N07-1050,H05-1066,0,0.0986893,"Missing"
N07-1050,W06-2932,0,0.0624856,"he reduction in parsing time with limited degrees of non-projectivity is substantial, especially considering the very marginal drop in accuracy. In order to compare the performance to the state of the art in dependency parsing, we have retrained the non-projective parser on the entire training data set for each language and evaluated it on the final test set from the CoNLL-X shared task (Buchholz 402 and Marsi, 2006). Thus, table 4 shows labeled attachment scores, the main evaluation metric used in the shared task, in comparison to the two highest scoring systems from the original evaluation (McDonald et al., 2006; Nivre et al., 2006). The incremental non-projective parser has the best reported score for Danish and outperforms at least one of the other two systems for four languages out of five, although most of the differences are probably too small to be statistically significant. But whereas the spanning tree parser of McDonald et al. (2006) and the pseudo-projective parser of Nivre et al. (2006) achieve this performance only with special pre- or post-processing,7 the approach presented here derives a labeled non-projective graph in a single incremental process and hence at least has the advantage o"
N07-1050,P97-1043,0,0.160906,"Missing"
N07-1050,P05-1013,1,0.749121,"al., 2005). Whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. The most popular strategy for capturing nonprojective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nov´ak, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006). And it is rare to find parsers that derive non-projective structures directly, the notable exception being the non-projective spanning tree parser proposed by McDonald et al. (2005). There are essentially two arguments that have been advanced against using parsing algorithms that derive non-projective dependency structures directly. The first is that the added expressivity compromises efficiency, since the parsing problem for a grammar that allows arbitrary non-projective dependen"
N07-1050,W04-2407,1,0.881497,"Missing"
N07-1050,W06-2933,1,0.694548,"Missing"
N07-1050,W03-3023,0,0.175882,"Missing"
N07-1050,E06-1010,1,\N,Missing
N10-1050,J93-2003,0,0.072497,"e a word alignment over a parallel corpus. We show that alignment via Stochastic Bracketing LITGs is considerably faster than Stochastic Bracketing ITGs, while still yielding alignments superior to the widelyused heuristic of intersecting bidirectional IBM alignments. Performance is measured as the translation quality of a phrase-based machine translation system built upon the word alignments, and an improvement of 2.85 BLEU points over baseline is noted for French– English. 1 Introduction Machine translation relies heavily on word alignments, which are usually produced by training IBMmodels (Brown et al., 1993) in both directions and combining the resulting alignments via some heuristic. Automatically training an Inversion Transduction Grammar ( ITG) has been suggested as a viable way of producing superior alignments (Saers and Wu, 2009). The main problem of using Bracketing ITGs for alignment is that exhaustive biparsing runs in O(n6 ) time. Several ways to lower the complexity of ITGs has been suggested, but in this paper, a different approach is taken. Instead of using full ITGs, we explore the possibility of subjecting the grammar to a linear constraint, making exhaustive biparsing of a sentence"
N10-1050,P09-1104,0,0.256675,"Missing"
N10-1050,P07-2045,0,0.0192853,"m in a bucket can be analyzed in 8 possible ways, requiring O(1) time. In summary, we have: O(n) × O(n3 ) × O(1) = O(n4 ) The pruning scheme works by limiting the number of items that are processed from each bucket, reducing the cost of processing a bucket from O(n3 ) to O(b), where b is the beam width. This gives time complexity O(n) × O(b) × O(1) = O(bn). 343 We used the guidelines of the shared task of WMT ’081 to train our baseline system as well as our experimental system. This includes induction of word alignments with GIZA ++ (Och and Ney, 2003), induction of a Phrase-based SMT system (Koehn et al., 2007), and tuning with minimum error rate training (Och, 2003), as well as applying some utility scripts provided for the workshop. The translation model is combined with a 5-gram language model (Stolcke, 2002). Our experimental system uses alignments from the Viterbi parses, extracted during EM training of an SBLITG on the training corpus, instead of GIZA ++. Since EM will converge fairly slowly, it was limited to 10 iterations, after which it was halted. We used the French–English part of the WMT ’08 shared task, but limited the training set to sentence pairs where both sentences were of length 2"
N10-1050,J03-1002,0,0.0176392,"aking the total number of items in a bucket O(n3 ). Each item in a bucket can be analyzed in 8 possible ways, requiring O(1) time. In summary, we have: O(n) × O(n3 ) × O(1) = O(n4 ) The pruning scheme works by limiting the number of items that are processed from each bucket, reducing the cost of processing a bucket from O(n3 ) to O(b), where b is the beam width. This gives time complexity O(n) × O(b) × O(1) = O(bn). 343 We used the guidelines of the shared task of WMT ’081 to train our baseline system as well as our experimental system. This includes induction of word alignments with GIZA ++ (Och and Ney, 2003), induction of a Phrase-based SMT system (Koehn et al., 2007), and tuning with minimum error rate training (Och, 2003), as well as applying some utility scripts provided for the workshop. The translation model is combined with a 5-gram language model (Stolcke, 2002). Our experimental system uses alignments from the Viterbi parses, extracted during EM training of an SBLITG on the training corpus, instead of GIZA ++. Since EM will converge fairly slowly, it was limited to 10 iterations, after which it was halted. We used the French–English part of the WMT ’08 shared task, but limited the trainin"
N10-1050,P03-1021,0,0.0182863,"ime. In summary, we have: O(n) × O(n3 ) × O(1) = O(n4 ) The pruning scheme works by limiting the number of items that are processed from each bucket, reducing the cost of processing a bucket from O(n3 ) to O(b), where b is the beam width. This gives time complexity O(n) × O(b) × O(1) = O(bn). 343 We used the guidelines of the shared task of WMT ’081 to train our baseline system as well as our experimental system. This includes induction of word alignments with GIZA ++ (Och and Ney, 2003), induction of a Phrase-based SMT system (Koehn et al., 2007), and tuning with minimum error rate training (Och, 2003), as well as applying some utility scripts provided for the workshop. The translation model is combined with a 5-gram language model (Stolcke, 2002). Our experimental system uses alignments from the Viterbi parses, extracted during EM training of an SBLITG on the training corpus, instead of GIZA ++. Since EM will converge fairly slowly, it was limited to 10 iterations, after which it was halted. We used the French–English part of the WMT ’08 shared task, but limited the training set to sentence pairs where both sentences were of length 20 or less. This was necessary in order to carry out exhau"
N10-1050,P02-1040,0,0.0775543,"Missing"
N10-1050,W09-2304,1,0.850266,"secting bidirectional IBM alignments. Performance is measured as the translation quality of a phrase-based machine translation system built upon the word alignments, and an improvement of 2.85 BLEU points over baseline is noted for French– English. 1 Introduction Machine translation relies heavily on word alignments, which are usually produced by training IBMmodels (Brown et al., 1993) in both directions and combining the resulting alignments via some heuristic. Automatically training an Inversion Transduction Grammar ( ITG) has been suggested as a viable way of producing superior alignments (Saers and Wu, 2009). The main problem of using Bracketing ITGs for alignment is that exhaustive biparsing runs in O(n6 ) time. Several ways to lower the complexity of ITGs has been suggested, but in this paper, a different approach is taken. Instead of using full ITGs, we explore the possibility of subjecting the grammar to a linear constraint, making exhaustive biparsing of a sentence pair in O(n4 ) time possible. This can be further improved by applying pruning. A transduction is the bilingual version of a language. A language (Ll ) can be formally viewed as a set of sentences, sequences of tokens taken from a"
N10-1050,W09-3804,1,0.78707,"Missing"
N10-1050,P95-1033,1,0.573616,"one as transduction, that is: a sentence in one language is rewritten into the other language. In NLP, interest has shifted away from hand-crafted grammars, towards stochastic grammars induced from corpora. To induce a stochastic grammar from a parallel corpus, expectations of all possible parses over a sentence pair are typically needed. S TGs can biparse sentence pairs in polynomial time, but are unable to account for the complexities typically found in natural languages. S DTGs do account for the complexities in natural languages, but are intractable for biparsing. Inversion transductions (Wu, 1995; Wu, 1997) are a special case of transductions that are not monotone, but where permutations are severely limited. By limiting the possible permutations, biparsing becomes tractable. This in turn means that ITGs can be induced from parallel corpora in polynomial time, 341 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 341–344, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics as well as account for most of the reorderings found between natural languages. An Inversion transduction is limited so that it"
N10-1050,J97-3002,1,0.906411,"nsduction, that is: a sentence in one language is rewritten into the other language. In NLP, interest has shifted away from hand-crafted grammars, towards stochastic grammars induced from corpora. To induce a stochastic grammar from a parallel corpus, expectations of all possible parses over a sentence pair are typically needed. S TGs can biparse sentence pairs in polynomial time, but are unable to account for the complexities typically found in natural languages. S DTGs do account for the complexities in natural languages, but are intractable for biparsing. Inversion transductions (Wu, 1995; Wu, 1997) are a special case of transductions that are not monotone, but where permutations are severely limited. By limiting the possible permutations, biparsing becomes tractable. This in turn means that ITGs can be induced from parallel corpora in polynomial time, 341 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 341–344, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics as well as account for most of the reorderings found between natural languages. An Inversion transduction is limited so that it must be exp"
N10-1050,P08-1012,0,0.537157,"Missing"
N13-1126,P05-1022,0,0.20208,"Missing"
N13-1126,N09-1009,0,0.0242072,"k, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Ni"
N13-1126,D11-1005,0,0.216775,"OUN P Figure 1: A Greek sentence which is correctly parsed by a delexicalized English parser, provided that part-of-speech tags are available in both the source and target language. 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models can be used to selectively subsample training sentences to improve accuracy. Recently, inspired by the phylogenetic prior of Berg-Kirkpatrick and Klein (2010), Søgaard and Wulff (2012) proposed — among other ideas — a typologically informed weighting heuristic for linearly interpolating source language parameters. However, this weighting did not provide significant improvemen"
N13-1126,P11-1061,0,0.119063,"e transfer parsers in an ensemble-training algorithm. Our final model outperforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related lang"
N13-1126,P07-1033,0,0.0106786,"Missing"
N13-1126,D12-1001,0,0.440814,"t al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguously. Learning with multiple languages has been shown to benefit unsupervised learning (Cohen and Smith, 1 Note that Täckström et al. (2012"
N13-1126,C96-1058,0,0.260825,"Missing"
N13-1126,N09-1068,0,0.0477374,"Missing"
N13-1126,P09-1042,0,0.364312,"art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder"
N13-1126,P04-1061,0,0.0287204,"ed learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, subs"
N13-1126,C12-1089,0,0.0235319,"ate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguously. Learning with multiple languages has been shown to benefit unsupervised learning (Cohen and Smith, 1 Note that Täckström et al. (2012) and Durrett et al. (2012) do require bitext or a bilingual dictionary. The same holds for most cross-lingual representations, e.g., Klementiev et al. (2012). 1062 ROOT PUNC DOBJ DET Ο NSUBJ POBJ PREP DET Τζόν έδωσε στην Μαρία το βιβλίο . (The) (John) (gave) (to-the) (Maria) (the) (book) . DET NOUN VERB ADP NOUN DET NOUN P Figure 1: A Greek sentence which is correctly parsed by a delexicalized English parser, provided that part-of-speech tags are available in both the source and target language. 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonal"
N13-1126,P06-1043,0,0.0598052,"Missing"
N13-1126,P05-1012,1,0.614302,"ng (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Nivre, 2008). In this paper, we improve upon the state of the art in cross-lingual transfer of dependency parsers from multiple source languages by adapting feature-rich discriminatively trained parsers to a specific target language. First, in §4 we show how selective sharing of model parameters based on typological traits can be incorporated into a delexicalized discriminative graph-based parsing model. This requires a careful decomposition of features into language-generic and language-specific sets in order to tie specific target language parameters to their relevant source language count"
N13-1126,D11-1006,1,0.696635,"ransfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kir"
N13-1126,D10-1120,0,0.204747,"anually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to u"
N13-1126,P12-1066,0,0.744312,"out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Nivre, 2008). In this paper, we improve upon the state of the art in cross-lingual transfer of"
N13-1126,J08-4003,1,0.328548,"09; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Nivre, 2008). In this paper, we improve upon the state of the art in cross-lingual transfer of dependency parsers from multiple source languages by adapting feature-rich discriminatively trained parsers to a specific target language. First, in §4 we show how selective sharing of model parameters based on typological traits can be incorporated into a delexicalized discriminative graph-based parsing model. This requires a careful decomposition of features into language-generic and language-specific sets in order to tie specific target language parameters to their relevant source language counterparts. The r"
N13-1126,petrov-etal-2012-universal,1,0.100225,"fall into the delexicalized transfer approach to multilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguousl"
N13-1126,P02-1035,0,0.0630198,"Missing"
N13-1126,N06-2033,0,0.225801,"Missing"
N13-1126,D07-1111,0,0.0551291,"Missing"
N13-1126,N09-1010,0,0.0669165,", 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by Naseem et al. (2012) for multisource cross-lingual transfer. In particular, Naseem et al. showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages. However, these methods all employ generative models with strong independence assumptions and weak feature representations, which upper bounds their accuracy far below that of feature-rich discriminative parsers (McDonald et al., 2005; Nivre, 2008). In this p"
N13-1126,C12-2115,0,0.434966,"es. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models can be used to selectively subsample training sentences to improve accuracy. Recently, inspired by the phylogenetic prior of Berg-Kirkpatrick and Klein (2010), Søgaard and Wulff (2012) proposed — among other ideas — a typologically informed weighting heuristic for linearly interpolating source language parameters. However, this weighting did not provide significant improvements over uniform weighting. The aforementioned approaches work well for transfer between similar languages. However, their assumptions cease to hold for typologically divergent languages; a target language can rarely be described as a linear combination of data or model parameters from a set of source languages, as languages tend to share varied typological traits; this critical insight is discussed furt"
N13-1126,P11-2120,0,0.254226,"; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). Annotations in multiple languages can be combined in delexicalized transfer as well, as long as the parser features are available across the involved languages. This idea was explored by McDonald et al. (2011), who showed that target language accuracy can be improved by simply concatenating delexicalized treebanks in multiple languages. In similar work, Cohen et al. (2011) proposed a mixture model in which the parameters of a generative target language parser is expressed as a linear interpolation of source language parameters, whereas Søgaard (2011) showed that target side language models can be used to selectively subsample training sentences to improve accuracy. Recently, inspired by the phylogenetic prior of Berg-Kirkpatrick and Klein (2010), Søgaard and Wulff (2012) proposed — among other ideas — a typologically informed weighting heuristic for linearly interpolating source language parameters. However, this weighting did not provide significant improvements over uniform weighting. The aforementioned approaches work well for transfer between similar languages. However, their assumptions cease to hold for typologically divergent langu"
N13-1126,W09-1104,0,0.425983,"Missing"
N13-1126,N12-1052,1,0.41114,"ltilingual syntactic parsing (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Søgaard, 2011). In contrast to annotation projection approaches (Yarowsky et al., 2001; Hwa et al., 2005; Ganchev et al., 2009; Spreyer and Kuhn, 2009), delexicalized transfer methods do not rely on any bitext. Instead, a parser is trained on annotations in a source language, relying solely on features that are available in both the source and the target language, such as “universal” part-ofspeech tags (Zeman and Resnik, 2008; Naseem et al., 2010; Petrov et al., 2012), cross-lingual word clusters (Täckström et al., 2012) or type-level features derived from bilingual dictionaries (Durrett et al., 2012).1 This parser is then directly used to parse the target language. For languages with similar typology, this method can be quite accurate, especially when compared to purely unsupervised methods. For instance, a parser trained on English with only part-of-speech features can correctly parse the Greek sentence in Figure 1, even without knowledge of the lexical items since the sequence of part-of-speech tags determines the syntactic structure almost unambiguously. Learning with multiple languages has been shown to"
N13-1126,W12-1908,1,0.889289,"Missing"
N13-1126,H01-1035,0,0.0353175,"redictions from multiple transfer parsers in an ensemble-training algorithm. Our final model outperforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model paramet"
N13-1126,I08-3008,0,0.646019,"erforms the state of the art in multi-source transfer parsing on 15 out of 16 evaluated languages. 1 Introduction Many languages still lack access to core NLP tools, such as part-of-speech taggers and syntactic parsers. This is largely due to the reliance on fully supervised learning methods, which require large quantities of manually annotated training data. Recently, methods for cross-lingual transfer have appeared as a promising avenue for overcoming this hurdle for both part-of-speech tagging (Yarowsky et al., 2001; Das and Petrov, 2011) and syntactic dependency parsing (Hwa et al., 2005; Zeman and Resnik, 2008; Ganchev et al., 2009; McDonald et al., 2011; Naseem et al., ∗ Work primarily carried out while at Google, NY. 2012). While these methods do not yet compete with fully supervised approaches, they can drastically outperform both unsupervised methods (Klein and Manning, 2004) and weakly supervised methods (Naseem et al., 2010; Berg-Kirkpatrick and Klein, 2010). A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen a"
N13-1126,P10-1131,0,\N,Missing
N18-1105,D16-1131,0,0.0261869,"ara, 2016; Kummerfeld and Klein, 2017). However, all of these works are primarily concerned with recovering traces for phenomena such as Wh-movement or control and raising constructions and, with the exception of Kummerfeld and Klein (2017), none of these works attempt to output the co-indexing that is used for analyzing gapping constructions. And again, none of these works try to reconstruct elided material. Lastly, several methods have been proposed for resolving other forms of ellipsis, including VP ellipsis (Hardt, 1997; Nielsen, 2004; Lappin, 2005; McShane and Babkin, 2016) and sluicing (Anand and Hardt, 2016) but none of these methods consider gapping constructions. 7 Conclusion We presented two methods to recover elided predicates in sentences with gapping. Our experiments suggest that both methods work equally well in a realistic end-to-end setting. While in general, recall is still low, the oracle experiments suggest that both methods can recover elided predicates from correct dependency trees, which suggests that as parsers become more and more accurate, the gap recovery accuracy should also increase. We also demonstrated that our method can be used to automatically add the enhanced UD represe"
N18-1105,W03-1005,0,0.0844519,"Norwegian (Haugereid, 2017). The grammar-based parser built with augmented transition networks (Woods, 1970) provided an extension in the form of the SYSCONJ operation (Woods, 1973) to parse some gapping constructions, but also this approach lacked explicit reconstruction mechanisms and provided only limited coverage. There also exists a long line of work on postprocessing surface-syntax constituency trees to recover traces in the PTB (Johnson, 2002; Levy and Manning, 2004; Campbell, 2004; Gabbard et al., 2006), pre-processing sentences such that they contain tokens for traces before parsing (Dienes and Dubey, 2003b), or directly parsing sentences to either PTB-style trees with empty elements or pre-processed trees that can be deterministically converted to PTB-style trees (Collins, 1163 conj conj xcomp xcomp obl nsubj:pass obl nsubj:pass xcomp obl nsubj:pass tänks Ullnaområdet öka med 9000 , tänks0 Märsta industriområde öka0 med 7000 , tänks00 Jordbro öka00 med 4000 , ... is-thought Ullna-area increase with 9000 , is-thought Märsta industrial-area increase with 7000 , is-thought Jordbro increase with 4000 , .... ‘The Ullna area is expected to grow by 9,000 (new workplaces), the Märsta industrial area b"
N18-1105,P03-1055,0,0.0917889,"Norwegian (Haugereid, 2017). The grammar-based parser built with augmented transition networks (Woods, 1970) provided an extension in the form of the SYSCONJ operation (Woods, 1973) to parse some gapping constructions, but also this approach lacked explicit reconstruction mechanisms and provided only limited coverage. There also exists a long line of work on postprocessing surface-syntax constituency trees to recover traces in the PTB (Johnson, 2002; Levy and Manning, 2004; Campbell, 2004; Gabbard et al., 2006), pre-processing sentences such that they contain tokens for traces before parsing (Dienes and Dubey, 2003b), or directly parsing sentences to either PTB-style trees with empty elements or pre-processed trees that can be deterministically converted to PTB-style trees (Collins, 1163 conj conj xcomp xcomp obl nsubj:pass obl nsubj:pass xcomp obl nsubj:pass tänks Ullnaområdet öka med 9000 , tänks0 Märsta industriområde öka0 med 7000 , tänks00 Jordbro öka00 med 4000 , ... is-thought Ullna-area increase with 9000 , is-thought Märsta industrial-area increase with 7000 , is-thought Jordbro increase with 4000 , .... ‘The Ullna area is expected to grow by 9,000 (new workplaces), the Märsta industrial area b"
N18-1105,K17-3002,1,0.838127,"number of sentences in our corpus for each of the gap types. 4.2 Parsing experiments Parser We used the parser by Dozat and Manning (2017) for parsing to the two different intermediate dependency representations. This parser is a graph-based parser (McDonald et al., 2005) that uses a biLSTM to compute token representations and then uses a multi-layer perceptron with biaffine attention to compute arc and label scores. Setup We trained the parser on the COMBINED training corpus with gold tokenization, and predicted fine-grained and universal part-of-speech tags, for which we used the tagger by Dozat et al. (2017). We trained the tagger on the COMBINED training corpus. As pre-trained embeddings, we used the word2vec (Mikolov et al., 2013) embeddings that were provided for the CoNLL 2017 Shared Task (Zeman et al., 2017), and we used the same hyperparameters as Dozat et al. (2017). Evaluation We evaluated the parseability of the two dependency representations using labeled and unlabeled attachment scores (LAS and UAS). Further, to specifically evaluate how well parsers are able to parse gapping constructions according to the two annotation schemes, we also computed the LAS and UAS just for the head token"
N18-1105,W17-0406,0,0.133513,"Missing"
N18-1105,W11-2912,0,0.0234673,"literature. As Swedish is a Germanic language like English and thus shares many structural properties, we cannot conclude that our method is applicable to any language based on just this experiment. However, given that our method does not rely on language-specific structural patterns, we expect it to work well for a wide range of languages. but given that UD treebanks are annotated with orphan relations, using the the COMPOSITE procedure would require additional manual annotations in practice. 6 Related work Gapping constructions have been little studied in NLP, but several approaches (e.g., Dukes and Habash 2011; Simkó and Vincze 2017) parse to dependency trees with empty nodes. Seeker et al. (2012) compared three ways of parsing with empty heads: adding a transition that inserts empty nodes, using composite relation labels for nodes that depend on an elided node, and pre-inserting empties before parsing. These papers all focus on recovering nodes for elided function words such as auxiliaries; none of them attempt to recover and resolve the content word elisions of gapping. Ficler and Goldberg (2016) modified PTB annotations of argument-cluster coordinations (ACCs), i.e., gapping constructions with t"
N18-1105,P16-2012,0,0.0257928,"ctice. 6 Related work Gapping constructions have been little studied in NLP, but several approaches (e.g., Dukes and Habash 2011; Simkó and Vincze 2017) parse to dependency trees with empty nodes. Seeker et al. (2012) compared three ways of parsing with empty heads: adding a transition that inserts empty nodes, using composite relation labels for nodes that depend on an elided node, and pre-inserting empties before parsing. These papers all focus on recovering nodes for elided function words such as auxiliaries; none of them attempt to recover and resolve the content word elisions of gapping. Ficler and Goldberg (2016) modified PTB annotations of argument-cluster coordinations (ACCs), i.e., gapping constructions with two post-verbal orphan phrases, which make up a subset of the gapping constructions in the PTB. While the modified annotation style leads to higher parsing accuracy of ACCs, it is specific to ACCs and does not generalize to other gapping constructions. Moreover, they did not reconstruct gapped ACC clauses. Traditional grammarbased chart parsers (Kay, 1980; Klein and Manning, 2001) did handle empty nodes and so could in principle provide a parse of gapping sentences though additional mechanisms"
N18-1105,N06-1024,0,0.0516315,"been noted for the English Resource Grammar (Flickinger, 2017, p.c.) and for an HPSG implementation for Norwegian (Haugereid, 2017). The grammar-based parser built with augmented transition networks (Woods, 1970) provided an extension in the form of the SYSCONJ operation (Woods, 1973) to parse some gapping constructions, but also this approach lacked explicit reconstruction mechanisms and provided only limited coverage. There also exists a long line of work on postprocessing surface-syntax constituency trees to recover traces in the PTB (Johnson, 2002; Levy and Manning, 2004; Campbell, 2004; Gabbard et al., 2006), pre-processing sentences such that they contain tokens for traces before parsing (Dienes and Dubey, 2003b), or directly parsing sentences to either PTB-style trees with empty elements or pre-processed trees that can be deterministically converted to PTB-style trees (Collins, 1163 conj conj xcomp xcomp obl nsubj:pass obl nsubj:pass xcomp obl nsubj:pass tänks Ullnaområdet öka med 9000 , tänks0 Märsta industriområde öka0 med 7000 , tänks00 Jordbro öka00 med 4000 , ... is-thought Ullna-area increase with 9000 , is-thought Märsta industrial-area increase with 7000 , is-thought Jordbro increase wi"
N18-1105,J97-4002,0,0.223721,", 2003a; Schmid, 2006; Cai et al., 2011; Hayashi and Nagata, 2016; Kato and Matsubara, 2016; Kummerfeld and Klein, 2017). However, all of these works are primarily concerned with recovering traces for phenomena such as Wh-movement or control and raising constructions and, with the exception of Kummerfeld and Klein (2017), none of these works attempt to output the co-indexing that is used for analyzing gapping constructions. And again, none of these works try to reconstruct elided material. Lastly, several methods have been proposed for resolving other forms of ellipsis, including VP ellipsis (Hardt, 1997; Nielsen, 2004; Lappin, 2005; McShane and Babkin, 2016) and sluicing (Anand and Hardt, 2016) but none of these methods consider gapping constructions. 7 Conclusion We presented two methods to recover elided predicates in sentences with gapping. Our experiments suggest that both methods work equally well in a realistic end-to-end setting. While in general, recall is still low, the oracle experiments suggest that both methods can recover elided predicates from correct dependency trees, which suggests that as parsers become more and more accurate, the gap recovery accuracy should also increase."
N18-1105,P16-2016,0,0.0187532,"ordbro öka00 med 4000 , ... is-thought Ullna-area increase with 9000 , is-thought Märsta industrial-area increase with 7000 , is-thought Jordbro increase with 4000 , .... ‘The Ullna area is expected to grow by 9,000 (new workplaces), the Märsta industrial area by 7,000, Jordbro by 4,000, ...’ Figure 2: Dependency graph for part of the sentence sv-ud-train-1102 as output by the ORPHAN procedure. The system correctly predicts the copy nodes for the matrix and the embedded verb, and correctly attaches the arguments to the copy nodes. 1997; Dienes and Dubey, 2003a; Schmid, 2006; Cai et al., 2011; Hayashi and Nagata, 2016; Kato and Matsubara, 2016; Kummerfeld and Klein, 2017). However, all of these works are primarily concerned with recovering traces for phenomena such as Wh-movement or control and raising constructions and, with the exception of Kummerfeld and Klein (2017), none of these works attempt to output the co-indexing that is used for analyzing gapping constructions. And again, none of these works try to reconstruct elided material. Lastly, several methods have been proposed for resolving other forms of ellipsis, including VP ellipsis (Hardt, 1997; Nielsen, 2004; Lappin, 2005; McShane and Babkin, 201"
N18-1105,J07-3004,0,0.0665134,"Missing"
N18-1105,P01-1044,1,0.481659,"tion words such as auxiliaries; none of them attempt to recover and resolve the content word elisions of gapping. Ficler and Goldberg (2016) modified PTB annotations of argument-cluster coordinations (ACCs), i.e., gapping constructions with two post-verbal orphan phrases, which make up a subset of the gapping constructions in the PTB. While the modified annotation style leads to higher parsing accuracy of ACCs, it is specific to ACCs and does not generalize to other gapping constructions. Moreover, they did not reconstruct gapped ACC clauses. Traditional grammarbased chart parsers (Kay, 1980; Klein and Manning, 2001) did handle empty nodes and so could in principle provide a parse of gapping sentences though additional mechanisms would be needed for reconstruction. In practice, though, dealing with gapping in a grammar-based framework is not straightforward and can lead to a combinatorial explosion that slows down parsing in general, as has been noted for the English Resource Grammar (Flickinger, 2017, p.c.) and for an HPSG implementation for Norwegian (Haugereid, 2017). The grammar-based parser built with augmented transition networks (Woods, 1970) provided an extension in the form of the SYSCONJ operati"
N18-1105,Q17-1031,0,0.169729,"crease with 9000 , is-thought Märsta industrial-area increase with 7000 , is-thought Jordbro increase with 4000 , .... ‘The Ullna area is expected to grow by 9,000 (new workplaces), the Märsta industrial area by 7,000, Jordbro by 4,000, ...’ Figure 2: Dependency graph for part of the sentence sv-ud-train-1102 as output by the ORPHAN procedure. The system correctly predicts the copy nodes for the matrix and the embedded verb, and correctly attaches the arguments to the copy nodes. 1997; Dienes and Dubey, 2003a; Schmid, 2006; Cai et al., 2011; Hayashi and Nagata, 2016; Kato and Matsubara, 2016; Kummerfeld and Klein, 2017). However, all of these works are primarily concerned with recovering traces for phenomena such as Wh-movement or control and raising constructions and, with the exception of Kummerfeld and Klein (2017), none of these works attempt to output the co-indexing that is used for analyzing gapping constructions. And again, none of these works try to reconstruct elided material. Lastly, several methods have been proposed for resolving other forms of ellipsis, including VP ellipsis (Hardt, 1997; Nielsen, 2004; Lappin, 2005; McShane and Babkin, 2016) and sluicing (Anand and Hardt, 2016) but none of the"
N18-1105,J93-2004,0,0.0604335,"path between want and play, we also have to make a copy of write to reconstruct the UD graph of the gapped clause. 4 Experiments Both methods rely on a dependency parser followed by a post-processing step. We evaluated the individual steps and the end-to-end performance. 4.1 Data We used the UD English Web Treebank v2.1 (henceforth EWT; Silveira et al., 2014; Nivre et al., 2017) for training and evaluating parsers. As the treebank is relatively small and therefore only contains very few sentences with gapping, we also extracted gapping constructions from the WSJ and Brown portions of the PTB (Marcus et al., 1993) and the GENIA corpus (Ohta et al., 2002). Further, we copied sentences from the Wikipedia page on gapping7 and from published papers on gapping. The sentences in the EWT already contain annotations with the orphan relation and copy nodes for the enhanced representation, and we manually added both of these annotations for the remaining examples. The composite relations can 7 https://en.wikipedia.org/wiki/Gapping, accessed on Aug 24, 2017. be automatically obtained from the enhanced representation by removing the copy nodes and concatenating the dependency labels, which we did to build the trai"
N18-1105,H05-1066,0,0.335074,"Missing"
N18-1105,2016.lilt-13.1,0,0.178264,"ayashi and Nagata, 2016; Kato and Matsubara, 2016; Kummerfeld and Klein, 2017). However, all of these works are primarily concerned with recovering traces for phenomena such as Wh-movement or control and raising constructions and, with the exception of Kummerfeld and Klein (2017), none of these works attempt to output the co-indexing that is used for analyzing gapping constructions. And again, none of these works try to reconstruct elided material. Lastly, several methods have been proposed for resolving other forms of ellipsis, including VP ellipsis (Hardt, 1997; Nielsen, 2004; Lappin, 2005; McShane and Babkin, 2016) and sluicing (Anand and Hardt, 2016) but none of these methods consider gapping constructions. 7 Conclusion We presented two methods to recover elided predicates in sentences with gapping. Our experiments suggest that both methods work equally well in a realistic end-to-end setting. While in general, recall is still low, the oracle experiments suggest that both methods can recover elided predicates from correct dependency trees, which suggests that as parsers become more and more accurate, the gap recovery accuracy should also increase. We also demonstrated that our method can be used to auto"
N18-1105,C04-1157,0,0.771587,"id, 2006; Cai et al., 2011; Hayashi and Nagata, 2016; Kato and Matsubara, 2016; Kummerfeld and Klein, 2017). However, all of these works are primarily concerned with recovering traces for phenomena such as Wh-movement or control and raising constructions and, with the exception of Kummerfeld and Klein (2017), none of these works attempt to output the co-indexing that is used for analyzing gapping constructions. And again, none of these works try to reconstruct elided material. Lastly, several methods have been proposed for resolving other forms of ellipsis, including VP ellipsis (Hardt, 1997; Nielsen, 2004; Lappin, 2005; McShane and Babkin, 2016) and sluicing (Anand and Hardt, 2016) but none of these methods consider gapping constructions. 7 Conclusion We presented two methods to recover elided predicates in sentences with gapping. Our experiments suggest that both methods work equally well in a realistic end-to-end setting. While in general, recall is still low, the oracle experiments suggest that both methods can recover elided predicates from correct dependency trees, which suggests that as parsers become more and more accurate, the gap recovery accuracy should also increase. We also demonst"
N18-1105,L16-1262,1,0.828827,"k Gapping constructions have been little studied in NLP, but several approaches (e.g., Dukes and Habash 2011; Simkó and Vincze 2017) parse to dependency trees with empty nodes. Seeker et al. (2012) compared three ways of parsing with empty heads: adding a transition that inserts empty nodes, using composite relation labels for nodes that depend on an elided node, and pre-inserting empties before parsing. These papers all focus on recovering nodes for elided function words such as auxiliaries; none of them attempt to recover and resolve the content word elisions of gapping. Ficler and Goldberg (2016) modified PTB annotations of argument-cluster coordinations (ACCs), i.e., gapping constructions with two post-verbal orphan phrases, which make up a subset of the gapping constructions in the PTB. While the modified annotation style leads to higher parsing accuracy of ACCs, it is specific to ACCs and does not generalize to other gapping constructions. Moreover, they did not reconstruct gapped ACC clauses. Traditional grammarbased chart parsers (Kay, 1980; Klein and Manning, 2001) did handle empty nodes and so could in principle provide a parse of gapping sentences though additional mechanisms"
N18-1105,S15-2153,0,0.0745365,"Missing"
N18-1105,D14-1162,1,0.106118,"Missing"
N18-1105,P06-1023,0,0.0419441,"område öka0 med 7000 , tänks00 Jordbro öka00 med 4000 , ... is-thought Ullna-area increase with 9000 , is-thought Märsta industrial-area increase with 7000 , is-thought Jordbro increase with 4000 , .... ‘The Ullna area is expected to grow by 9,000 (new workplaces), the Märsta industrial area by 7,000, Jordbro by 4,000, ...’ Figure 2: Dependency graph for part of the sentence sv-ud-train-1102 as output by the ORPHAN procedure. The system correctly predicts the copy nodes for the matrix and the embedded verb, and correctly attaches the arguments to the copy nodes. 1997; Dienes and Dubey, 2003a; Schmid, 2006; Cai et al., 2011; Hayashi and Nagata, 2016; Kato and Matsubara, 2016; Kummerfeld and Klein, 2017). However, all of these works are primarily concerned with recovering traces for phenomena such as Wh-movement or control and raising constructions and, with the exception of Kummerfeld and Klein (2017), none of these works attempt to output the co-indexing that is used for analyzing gapping constructions. And again, none of these works try to reconstruct elided material. Lastly, several methods have been proposed for resolving other forms of ellipsis, including VP ellipsis (Hardt, 1997; Nielsen,"
N18-1105,W17-0416,1,0.856912,"ions that are useful for NLP tasks. UD defines two types of representation: the basic UD representation which is a strict surface syntax dependency tree and the enhanced UD representation (Schuster and Manning, 2016) which may be a graph instead of a tree and may contain additional nodes. The analysis of gapping in the enhanced representation makes use of copy nodes for elided predicates and additional edges for elided arguments, which we both try to automatically reconstruct in this paper. In the simple case in which only one predicate was elided, there is exactly one 2 See Johnson (2014) or Schuster et al. (2017) for a more comprehensive overview of cross-linguistically attested gapping constructions. 1157 copy node for the elided predicate, which leads to a structure that is identical to the structure of the same sentence without a gap.3 conj nsubj cc obj nsubj obj John bought books and Mary bought0 flowers If a clause contains a more complex gap, the enhanced representation contains copies for all content words that are required to attach the remnants. have existed if nothing had been elided. For example, in the following sentence, the verb bought, which would have been attached to the head of the f"
N18-1105,L16-1376,1,0.905765,"Missing"
N18-1105,C12-2105,0,0.105338,"y, the number of composite relations is unbounded: xcomp conj&gt;xcomp&gt;xcomp&gt;xcomp&gt;obj The rationale for not copying all arguments is again to keep the graph simple, while still encoding all relations between content words. Arguments can be arbitrarily complex and it seems misguided to copy entire subtrees of arguments which, e.g., could contain multiple adverbial clauses. Note that linking to existing nodes would not work in the case of verb clusters because they do not satisfy the subtree constraint. 3 3.1 conj&gt;cc obj Methods Composite relations Our first method adapts one of the procedures by Seeker et al. (2012), which represents gaps in dependency trees by attaching dependents of an elided predicate with composite relations. These relations represent the dependency path that would 3 To enhance the readability of our examples, we place the copy node in the sentence where the elided predicate would have been pronounced. However, as linear order typically does not matter for extracting information with dependency patterns, our procedures only try to recover the structure of canonical sentences but not their linear order. conj&gt;nsubj det conj&gt;cc ... and Mary a play 3.2 Orphan procedure Our second method"
N18-1105,silveira-etal-2014-gold,0,0.147706,"Missing"
N18-1105,W17-6527,0,0.0216789,"is a Germanic language like English and thus shares many structural properties, we cannot conclude that our method is applicable to any language based on just this experiment. However, given that our method does not rely on language-specific structural patterns, we expect it to work well for a wide range of languages. but given that UD treebanks are annotated with orphan relations, using the the COMPOSITE procedure would require additional manual annotations in practice. 6 Related work Gapping constructions have been little studied in NLP, but several approaches (e.g., Dukes and Habash 2011; Simkó and Vincze 2017) parse to dependency trees with empty nodes. Seeker et al. (2012) compared three ways of parsing with empty heads: adding a transition that inserts empty nodes, using composite relation labels for nodes that depend on an elided node, and pre-inserting empties before parsing. These papers all focus on recovering nodes for elided function words such as auxiliaries; none of them attempt to recover and resolve the content word elisions of gapping. Ficler and Goldberg (2016) modified PTB annotations of argument-cluster coordinations (ACCs), i.e., gapping constructions with two post-verbal orphan ph"
N18-1105,C00-2137,0,0.0547731,"tly at p &lt; 0.01. ORPHAN COMPOSITE Development UASg LASg UASg 72.36 68.36 72.56* 62.41 64.73*** 49.45 Test LASg 65.79*** 46.24 Table 4: Labeled (LASg ) and unlabeled attachment score (UASg ) of head tokens of remnants for parsers trained and evaluated on the UD representation (ORPHAN) and the composite relations representation (COMPOSITE) on the development and test sets of the COMBINED treebank. Results that differ significantly are marked with * (p &lt; 0.05) or *** (p &lt; 0.001). tistical significance of pairwise comparisons, we performed two-tailed approximate randomization tests (Noreen, 1989; Yeh, 2000) with an adapted version of the sigf package (Padó, 2006). Results Table 3 shows the overall parsing results on the development and test sets of the two treebanks. There was no significant difference between the parser that was trained on the UD representation (ORPHAN) and the parser trained on the composite representation (COMPOSITE) when tested on the EWT data sets, which is not surprising considering that there is just one sentence with gapping each in the development and the test split. When evaluated on the GAPPING datasets, the OR PHAN parser performs significantly better (p &lt; 0.01) in t"
N18-1105,P02-1018,0,\N,Missing
N18-1105,P11-2037,0,\N,Missing
N18-1105,P04-1082,0,\N,Missing
N18-1105,P16-1088,0,\N,Missing
N19-1159,D15-1041,1,0.825182,"haracters ch1:m of wi (BiLSTM(ch1:m )). xi = e(wi ) ◦ p(wi ) ◦ BiLSTM(ch1:m ) Without a POS tag embedding, the word vector is a representation of the word type. With POS information, we have some information about the word in the context of the sentence and the tagger has had access to the full sentence. The representation of the word at the input of the BiLSTM is therefore more contextualised and it can be expected that a recursive composition function will be less helpful than when POS information is not used. Character information has been shown to be useful for dependency parsing first by Ballesteros et al. (2015). Ballesteros et al. (2015) and Smith et al. (2018b) among others have shown that POS and character information are somewhat complementary. Ballesteros et al. (2015) used similar character vectors in the S-LSTM parser but did not look at the impact of composition when using these vectors. Here, we experiment with ablating either or both of the character and POS vectors. We look at the impact of using composition on the full model as well as these ablated models. We hypothesise that composition is most helpful when those vectors are not used, since they give information about the functional use"
N19-1159,P15-1033,1,0.906149,"crucial for transition-based parsers. To capture history-based information, composition is better than a forward LSTM on its own, but it is even better to have a forward LSTM as part of a BiLSTM. We correlate results with language properties, showing that the improved lookahead of a backward LSTM is especially important for head-final languages. 1 Introduction Recursive neural networks allow us to construct vector representations of trees or subtrees. They have been used for constituency parsing by Socher et al. (2013) and Dyer et al. (2016) and for dependency parsing by Stenetorp (2013) and Dyer et al. (2015), among others. In particular, Dyer et al. (2015) showed that composing representations of subtrees using recursive neural networks can be beneficial for transition-based dependency parsing. These results were further strengthened in Kuncoro et al. (2017) who showed, using ablation experiments, that composition is key in the Recurrent Neural Network Grammar (RNNG) generative parser by Dyer et al. (2016). In a parallel development, Kiperwasser and Goldberg (2016b) showed that using BiLSTMs for feature extraction can lead to high parsing accuracy even with fairly simple parsing architectures, an"
N19-1159,N16-1024,1,0.870152,"features and the forward LSTM to the rich history-based features both crucial for transition-based parsers. To capture history-based information, composition is better than a forward LSTM on its own, but it is even better to have a forward LSTM as part of a BiLSTM. We correlate results with language properties, showing that the improved lookahead of a backward LSTM is especially important for head-final languages. 1 Introduction Recursive neural networks allow us to construct vector representations of trees or subtrees. They have been used for constituency parsing by Socher et al. (2013) and Dyer et al. (2016) and for dependency parsing by Stenetorp (2013) and Dyer et al. (2015), among others. In particular, Dyer et al. (2015) showed that composing representations of subtrees using recursive neural networks can be beneficial for transition-based dependency parsing. These results were further strengthened in Kuncoro et al. (2017) who showed, using ablation experiments, that composition is key in the Recurrent Neural Network Grammar (RNNG) generative parser by Dyer et al. (2016). In a parallel development, Kiperwasser and Goldberg (2016b) showed that using BiLSTMs for feature extraction can lead to h"
N19-1159,N18-1108,0,0.0222468,"shared task (Zeman et al., 2017) and 10 out of the 10 highest performing systems of the 2018 CoNLL shared task (Zeman et al., 2018). This raises the question of whether features extracted with BiLSTMs in themselves capture information about subtrees, thus making recursive composition superfluous. Some support for this hypothesis comes from the results of Linzen et al. (2016) which indicate that LSTMs can capture hierarchical information: they can be trained to predict long-distance number agreement in English. Those results were extended to more constructions and three additional languages by Gulordava et al. (2018). However, Kuncoro et al. (2018) have also shown that although sequential LSTMs can learn syntactic information, a recursive neural network which explicitly models hierarchy (the RNNG model from Dyer et al. (2015)) is better at this: it performs better on the number agreement task from Linzen et al. (2016). To further explore this question in the context of dependency parsing, we investigate the use of recursive composition (henceforth referred to as composition) in a parser with an architecture like the one in Kiperwasser and Goldberg (2016b). This allows us to explore variations of features"
N19-1159,Q16-1032,0,0.292801,"es. They have been used for constituency parsing by Socher et al. (2013) and Dyer et al. (2016) and for dependency parsing by Stenetorp (2013) and Dyer et al. (2015), among others. In particular, Dyer et al. (2015) showed that composing representations of subtrees using recursive neural networks can be beneficial for transition-based dependency parsing. These results were further strengthened in Kuncoro et al. (2017) who showed, using ablation experiments, that composition is key in the Recurrent Neural Network Grammar (RNNG) generative parser by Dyer et al. (2016). In a parallel development, Kiperwasser and Goldberg (2016b) showed that using BiLSTMs for feature extraction can lead to high parsing accuracy even with fairly simple parsing architectures, and using BiLSTMs for feature extraction has therefore become very popular in dependency parsing. It is used in the state-of-the-art parser of Dozat and Manning (2017), was used in 8 of the 10 highest performing systems of the 2017 CoNLL shared task (Zeman et al., 2017) and 10 out of the 10 highest performing systems of the 2018 CoNLL shared task (Zeman et al., 2018). This raises the question of whether features extracted with BiLSTMs in themselves capture inform"
N19-1159,Q16-1023,0,0.38479,"es. They have been used for constituency parsing by Socher et al. (2013) and Dyer et al. (2016) and for dependency parsing by Stenetorp (2013) and Dyer et al. (2015), among others. In particular, Dyer et al. (2015) showed that composing representations of subtrees using recursive neural networks can be beneficial for transition-based dependency parsing. These results were further strengthened in Kuncoro et al. (2017) who showed, using ablation experiments, that composition is key in the Recurrent Neural Network Grammar (RNNG) generative parser by Dyer et al. (2016). In a parallel development, Kiperwasser and Goldberg (2016b) showed that using BiLSTMs for feature extraction can lead to high parsing accuracy even with fairly simple parsing architectures, and using BiLSTMs for feature extraction has therefore become very popular in dependency parsing. It is used in the state-of-the-art parser of Dozat and Manning (2017), was used in 8 of the 10 highest performing systems of the 2017 CoNLL shared task (Zeman et al., 2017) and 10 out of the 10 highest performing systems of the 2018 CoNLL shared task (Zeman et al., 2018). This raises the question of whether features extracted with BiLSTMs in themselves capture inform"
N19-1159,P11-1068,0,0.0687526,"steros et al. (2015) used similar character vectors in the S-LSTM parser but did not look at the impact of composition when using these vectors. Here, we experiment with ablating either or both of the character and POS vectors. We look at the impact of using composition on the full model as well as these ablated models. We hypothesise that composition is most helpful when those vectors are not used, since they give information about the functional use of the word in context. Parser We use UUParser, a variant of the K&G transition-based parser that employs the arc-hybrid transition system from Kuhlmann et al. (2011) extended with a SWAP transition and a StaticDynamic oracle, as described in de Lhoneux et al. (2017b)4 . The SWAP transition is used to allow the construction of non-projective dependency trees (Nivre, 2009). We use default hyperparameters. When using POS tags, we use the universal POS tags from the UD treebanks which are coarsegrained and consistent across languages. Those POS tags are predicted by UDPipe (Straka et al., 2016) both for training and parsing. This parser obtained the 7th best LAS score on average in the 2018 CoNLL shared task (Zeman et al., 2018), about 2.5 LAS points below th"
N19-1159,E17-1117,1,0.904856,"Missing"
N19-1159,P18-1132,0,0.0947468,"Missing"
N19-1159,K17-3022,1,0.911906,"Missing"
N19-1159,W17-6314,1,0.904094,"Missing"
N19-1159,Q16-1037,0,0.200219,"res, and using BiLSTMs for feature extraction has therefore become very popular in dependency parsing. It is used in the state-of-the-art parser of Dozat and Manning (2017), was used in 8 of the 10 highest performing systems of the 2017 CoNLL shared task (Zeman et al., 2017) and 10 out of the 10 highest performing systems of the 2018 CoNLL shared task (Zeman et al., 2018). This raises the question of whether features extracted with BiLSTMs in themselves capture information about subtrees, thus making recursive composition superfluous. Some support for this hypothesis comes from the results of Linzen et al. (2016) which indicate that LSTMs can capture hierarchical information: they can be trained to predict long-distance number agreement in English. Those results were extended to more constructions and three additional languages by Gulordava et al. (2018). However, Kuncoro et al. (2018) have also shown that although sequential LSTMs can learn syntactic information, a recursive neural network which explicitly models hierarchy (the RNNG model from Dyer et al. (2015)) is better at this: it performs better on the number agreement task from Linzen et al. (2016). To further explore this question in the conte"
N19-1159,de-marneffe-etal-2014-universal,1,0.845216,"Missing"
N19-1159,D07-1013,1,0.833013,"the recurrent cell does not help the forward LSTM case but the LSTM cell does to some extent. It is interesting to note that using composition, especially using an LSTM cell, bridges a substantial part of the gap between the bw and the bi models. These results can be related to the literature on transition-based dependency parsing. Transitionbased parsers generally rely on two types of features: history-based features over the emerging dependency tree and lookahead features over the buffer of remaining input. The former are based on a hierarchical structure, the latter are purely sequential. McDonald and Nivre (2007) and McDonald and Nivre (2011) have shown that historybased features enhance transition-based parsers as long as they do not suffer from error propagation. However, Nivre (2006) has also shown that lookahead features are absolutely crucial given the greedy left-to-right parsing strategy. backward LSTM provides an improved lookahead. Similarly to the lookahead in statistical parsing, it is sequential. The difference is that it gives information about upcoming words with unbounded length. The forward LSTM in this model architecture provides history-based information but unlike in statistical par"
N19-1159,J08-4003,1,0.569151,"e the same for all occurrences of a word type. Type vectors are then passed through a feature function which learns representations of words in the context of the sentence. xi = e(wi ) vi = f (x1:n , i) We refer to the vector vi as a token vector, as it is different for different tokens of the same word type. In Kiperwasser and Goldberg (2016b), the feature function used is a BiLSTM. As is usual in transition-based parsing, parsing involves taking transitions from an initial configuration to a terminal one. Parser configurations are represented by a stack, a buffer and set of dependency arcs (Nivre, 2008). For each configuration c, the feature extractor concatenates the token representations of core elements from the stack and 1 Kiperwasser and Goldberg (2016b) also define a graphbased parser with similar feature extraction, but we focus on transition-based parsing. buffer. These token vectors are passed to a classifier, typically a Multilayer Perceptron (MLP). The MLP scores transitions together with the arc labels for transitions that involve adding an arc. Both the word type vectors and the BiLSTMs are trained together with the model. 3 Composing Subtree Representations Dyer et al. (2015) l"
N19-1159,P09-1040,1,0.805646,"vectors. We look at the impact of using composition on the full model as well as these ablated models. We hypothesise that composition is most helpful when those vectors are not used, since they give information about the functional use of the word in context. Parser We use UUParser, a variant of the K&G transition-based parser that employs the arc-hybrid transition system from Kuhlmann et al. (2011) extended with a SWAP transition and a StaticDynamic oracle, as described in de Lhoneux et al. (2017b)4 . The SWAP transition is used to allow the construction of non-projective dependency trees (Nivre, 2009). We use default hyperparameters. When using POS tags, we use the universal POS tags from the UD treebanks which are coarsegrained and consistent across languages. Those POS tags are predicted by UDPipe (Straka et al., 2016) both for training and parsing. This parser obtained the 7th best LAS score on average in the 2018 CoNLL shared task (Zeman et al., 2018), about 2.5 LAS points below the best system, which uses an ensemble system as well as ELMo embeddings, as introduced by Peters et al. (2018). Note, however, that we use a slightly impoverished version of the model used for the shared task"
N19-1159,P17-2018,0,0.0183754,"POS and/or character information for Czech and English, it does it to a much smaller extent for Basque and Finnish. We hypothesise that arc depth might impact the usefulness of composition, since more depth means more matrix multiplications with the composition function. However, we find no correlation between average arc depth of the treebanks and usefulness of composition. It is an open question why composition helps some languages more than others. Note that we are not the first to use composition over vectors obtained from a BiLSTM in the context of dependency parsing, as this was done by Qi and Manning (2017). The difference is that they compose vectors before scoring transitions. It was also done by Kiperwasser and Goldberg (2016a) who showed that using BiLSTM vectors for words in their Tree LSTM parser is helpful but they did not compare this to using BiLSTM vectors without the Tree LSTM. Recurrent and recursive LSTMs in the way they have been considered in this paper are two ways of constructing contextual information and making it available for local decisions in a greedy parser. The strength of recursive LSTMs is that they can build this contextual information using hierarchical context rathe"
N19-1159,N06-2033,0,0.0398274,"4.6 74.4 92.7 66.7 83.1 79.2 59.5 60.2 85.3 67.3 77.2 93.1 68.1 79.9 70.5 48.7 52.8 83.1 62.6 74.2 79.5 53.4 79.8 71.5 51.2 54.7 83.3 63.4 74.7 80.2 55.0 80.8 73.8 74.5 75.9 76.0 72.8 74.8 67.2 68.2 Table 1: LAS for bi, bw and f w, without and with composition (+lc) with an LSTM. Difference > 0.5 with +lc in bold. 5.3 Ensemble To investigate further the information captured by BiLSTMs, we ensemble the 6 versions of the models with POS and character information with the different feature extractors (bi, bw, f w) with (+lc) and without composition. We use the (unweighted) reparsing technique of Sagae and Lavie (2006)6 and ignoring labels. As can be seen from the UAS scores in Table 2, the ensemble (full) largely outperforms the parser using only a BiLSTM, indicating that the information obtained from the different models is complementary. To investigate the contribution of each of the 6 models, we ablate each one by one. As can be seen from Table 2, ablating either of the BiLSTM models or the backward LSTM using composition, results in the least effective of the ablated models, further strengthening the conclusion that BiLSTMs are powerful feature extractors. 6 Conclusion We investigated the impact of com"
N19-1159,K18-2011,1,0.908244,"Missing"
N19-1159,D18-1291,1,0.894709,"Missing"
N19-1159,P13-1045,0,0.0455775,"o be related to lookahead features and the forward LSTM to the rich history-based features both crucial for transition-based parsers. To capture history-based information, composition is better than a forward LSTM on its own, but it is even better to have a forward LSTM as part of a BiLSTM. We correlate results with language properties, showing that the improved lookahead of a backward LSTM is especially important for head-final languages. 1 Introduction Recursive neural networks allow us to construct vector representations of trees or subtrees. They have been used for constituency parsing by Socher et al. (2013) and Dyer et al. (2016) and for dependency parsing by Stenetorp (2013) and Dyer et al. (2015), among others. In particular, Dyer et al. (2015) showed that composing representations of subtrees using recursive neural networks can be beneficial for transition-based dependency parsing. These results were further strengthened in Kuncoro et al. (2017) who showed, using ablation experiments, that composition is key in the Recurrent Neural Network Grammar (RNNG) generative parser by Dyer et al. (2016). In a parallel development, Kiperwasser and Goldberg (2016b) showed that using BiLSTMs for feature e"
N19-1159,L16-1680,0,0.0471752,"Missing"
N19-1159,K18-2001,1,0.888735,"Missing"
N19-1159,J11-1007,1,\N,Missing
nilsson-nivre-2008-malteval,W06-2920,0,\N,Missing
nilsson-nivre-2008-malteval,D07-1096,1,\N,Missing
nivre-etal-2006-maltparser,W04-2407,1,\N,Missing
nivre-etal-2006-maltparser,W03-3023,0,\N,Missing
nivre-etal-2006-maltparser,W04-0308,1,\N,Missing
nivre-etal-2006-maltparser,H92-1026,0,\N,Missing
nivre-etal-2006-maltparser,J03-4003,0,\N,Missing
nivre-etal-2006-maltparser,P95-1037,0,\N,Missing
nivre-etal-2006-maltparser,W03-3017,1,\N,Missing
nivre-etal-2006-talbanken05,P96-1025,0,\N,Missing
nivre-etal-2006-talbanken05,P95-1037,0,\N,Missing
P05-1013,P04-1041,0,0.076531,"Missing"
P05-1013,W01-1828,0,0.0408168,"Missing"
P05-1013,P04-1040,0,0.0289751,"Missing"
P05-1013,P02-1018,0,0.058443,"dependency structures, notably Tapanainen and J¨arvinen (1997) and Wang and Harper (2004) for English, Foth et al. (2004) for German, and Holan (2004) for Czech. In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003). Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004). In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques. First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al., 1998) and encoding information about these lifts in arc labels. When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures"
P05-1013,P98-1106,0,0.930393,"?   ?  Adv  ? ? VB C T R na jedna je jen only to is one-FEM - SG (“Only one of them concerns quality.”) N4 kvalitu quality ? Z: . .) Figure 1: Dependency graph for Czech sentence from the Prague Dependency Treebank1 There exist a few robust broad-coverage parsers that produce non-projective dependency structures, notably Tapanainen and J¨arvinen (1997) and Wang and Harper (2004) for English, Foth et al. (2004) for German, and Holan (2004) for Czech. In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003). Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004). In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques. First, the training data f"
P05-1013,P04-1082,0,0.0145443,"l. (2004) for German, and Holan (2004) for Czech. In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003). Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004). In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques. First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al., 1998) and encoding information about these lifts in arc labels. When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts. By applying an inverse transformation to the ou"
P05-1013,A00-2018,0,0.103689,"Missing"
P05-1013,P04-1042,0,0.0441506,") for English, Foth et al. (2004) for German, and Holan (2004) for Czech. In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003). Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004). In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques. First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al., 1998) and encoding information about these lifts in arc labels. When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts. By applying an inverse transfo"
P05-1013,P99-1065,0,0.620093,"Missing"
P05-1013,C04-1010,1,0.661972,"they are applied to parser output. Before Feature type Word form Part-of-speech Dep type of head leftmost dep rightmost dep Top−1 + + Top + + + + + Next + + Next+1 + + Next+2 Next+3 + + + Table 2: Features used in predicting the next parser action we turn to the evaluation, however, we need to introduce the data-driven dependency parser used in the latter experiments. 3 Memory-Based Dependency Parsing In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al., 2004) and English (Nivre and Scholz, 2004). The parser builds dependency graphs by traversing the input from left to right, using a stack to store tokens that are not yet complete with respect to their dependents. At each point during the derivation, the parser has a choice between pushing the next input token onto the stack – with or without adding an arc from the token on top of the stack to the token pushed – and popping a token from the stack – with or without adding an arc from the next input token to the token popped. More details on the parsing algorithm can be found in Nivre (2003). The choice between different actions is in g"
P05-1013,J90-4003,0,0.346498,"om the Prague Dependency Treebank show that the combined system can handle nonprojective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy. This leads to the best reported performance for robust non-projective parsing of Czech. 1 Introduction It is sometimes claimed that one of the advantages of dependency grammar over approaches based on constituency is that it allows a more adequate treatment of languages with variable word order, where discontinuous syntactic constructions are more common than in languages like English (Mel’ˇcuk, 1988; Covington, 1990). However, this argument is only plausible if the formal framework allows non-projective dependency structures, i.e. structures where a head and its dependents may correspond to a discontinuous constituent. From the point of view of computational implementation this can be problematic, since the inclusion of non-projective This is in contrast to dependency treebanks, e.g. Prague Dependency Treebank (Hajiˇc et al., 2001b), Danish Dependency Treebank (Kromann, 2003), and the METU Treebank of Turkish (Oflazer et al., 2003), which generally allow annotations with nonprojective dependency structure"
P05-1013,W04-2407,1,0.792852,"g V¨axj¨o University SE-35195 V¨axj¨o, Sweden {nivre,jni}@msi.vxu.se Abstract structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness. Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures. This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004). It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003). In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures. We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures. Experiments using data from the Prague Dependency Treebank show that the combined system can handle no"
P05-1013,P03-1055,0,0.0205883,"ctures, notably Tapanainen and J¨arvinen (1997) and Wang and Harper (2004) for English, Foth et al. (2004) for German, and Holan (2004) for Czech. In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003). Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004). In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques. First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al., 1998) and encoding information about these lifts in arc labels. When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc l"
P05-1013,W03-3017,1,0.827162,"(Nivre et al., 2004) and English (Nivre and Scholz, 2004). The parser builds dependency graphs by traversing the input from left to right, using a stack to store tokens that are not yet complete with respect to their dependents. At each point during the derivation, the parser has a choice between pushing the next input token onto the stack – with or without adding an arc from the token on top of the stack to the token pushed – and popping a token from the stack – with or without adding an arc from the next input token to the token popped. More details on the parsing algorithm can be found in Nivre (2003). The choice between different actions is in general nondeterministic, and the parser relies on a memorybased classifier, trained on treebank data, to predict the next action based on features of the current parser configuration. Table 2 shows the features used in the current version of the parser. At each point during the derivation, the prediction is based on six word tokens, the two topmost tokens on the stack, and the next four input tokens. For each token, three types of features may be taken into account: the word form; the part-of-speech assigned by an automatic tagger; and labels on pr"
P05-1013,J03-4001,0,0.0144321,"and in practice also accuracy and robustness. Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures. This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004). It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003). In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures. We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures. Experiments using data from the Prague Dependency Treebank show that the combined system can handle nonprojective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy. This leads to the best reported performan"
P05-1013,P01-1024,0,0.00722431,"VB C T R na jedna je jen only to is one-FEM - SG (“Only one of them concerns quality.”) N4 kvalitu quality ? Z: . .) Figure 1: Dependency graph for Czech sentence from the Prague Dependency Treebank1 There exist a few robust broad-coverage parsers that produce non-projective dependency structures, notably Tapanainen and J¨arvinen (1997) and Wang and Harper (2004) for English, Foth et al. (2004) for German, and Holan (2004) for Czech. In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003). Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004). In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques. First, the training data for the parser is projectivize"
P05-1013,1993.iwpt-1.22,0,0.508741,"Missing"
P05-1013,C96-1058,0,0.443833,"Projective Dependency Parsing Joakim Nivre and Jens Nilsson School of Mathematics and Systems Engineering V¨axj¨o University SE-35195 V¨axj¨o, Sweden {nivre,jni}@msi.vxu.se Abstract structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness. Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures. This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004). It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003). In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures. We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective stru"
P05-1013,A97-1011,0,0.174345,"Missing"
P05-1013,W04-0307,0,0.0174332,"as an asymptotic goal. 99 Proceedings of the 43rd Annual Meeting of the ACL, pages 99–106, c Ann Arbor, June 2005. 2005 Association for Computational Linguistics    AuxP    Atr ? R Z (Out-of  ? P nich them  AuxZ  AuxP Sb  AuxZ ?   ?  Adv  ? ? VB C T R na jedna je jen only to is one-FEM - SG (“Only one of them concerns quality.”) N4 kvalitu quality ? Z: . .) Figure 1: Dependency graph for Czech sentence from the Prague Dependency Treebank1 There exist a few robust broad-coverage parsers that produce non-projective dependency structures, notably Tapanainen and J¨arvinen (1997) and Wang and Harper (2004) for English, Foth et al. (2004) for German, and Holan (2004) for Czech. In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990; Kahane et al., 1998; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003). Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; L"
P05-1013,P01-1035,0,0.0383087,"Missing"
P05-1013,W03-3023,0,0.711251,"atics and Systems Engineering V¨axj¨o University SE-35195 V¨axj¨o, Sweden {nivre,jni}@msi.vxu.se Abstract structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness. Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures. This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004). It is also true of the adaptation of the Collins parser for Czech (Collins et al., 1999) and the finite-state dependency parser for Turkish by Oflazer (2003). In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures. We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures. Experiments using data from the Prague Dependency Treebank show that the combined"
P05-1013,C86-1046,0,\N,Missing
P05-1013,J03-4003,0,\N,Missing
P05-1013,C98-1102,0,\N,Missing
P06-1033,P03-1054,0,0.0158378,"University jha@msi.vxu.se Introduction It has become increasingly clear that the choice of suitable internal representations can be a very important factor in data-driven approaches to syntactic parsing, and that accuracy can often be improved by internal transformations of a given kind of representation. This is well illustrated by the Collins parser (Collins, 1997; Collins, 1999), scrutinized by Bikel (2004), where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation. Other examples can be found in the work of Johnson (1998) and Klein and Manning (2003), which show that well-chosen transformations of syntactic representations can greatly improve the parsing accuracy obtained with probabilistic context-free grammars. In this paper, we apply essentially the same techniques to data-driven dependency parsing, 257 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 257–264, c Sydney, July 2006. 2006 Association for Computational Linguistics 2 Background 2.1 the conjuncts, and instead let the conjuncts have a direct dependency relation to the same head (Tesni`ere, 1959; Hudson, 19"
P06-1033,W98-0502,0,0.0449993,"ical analysis, where the conjunction depends on the first conjunct, while the second conjunct depends on the conjunction. In cases of multiple coordination, this can be generalized to a chain, where each element except the first depends on the preceding one. This more syntactically oriented approach has been advocated notably by Mel’ˇcuk (1988) and will be called Mel’ˇcuk style (MS). It is illustrated in figure 2, which shows a transformed version of the dependency graph in figure 1, where the elements of the coordination form a chain with the first conjunct (bojovnost´ı) as the topmost head. Lombardo and Lesmo (1998) conjecture that MS is more suitable than PS for incremental dependency parsing. The difference between the more semantically oriented PS and the more syntactically oriented MS is seen also in the analysis of verb groups, where the former treats the main verb as the head, since it is the bearer of valency, while the latter treats the auxiliary verb as the head, since it is the finite element of the clause. Without questioning the theoretical validity of either approach, we can again ask which analysis is best suited to achieve high accuracy in parsing. Dependency Graphs The basic idea in depen"
P06-1033,E06-1011,0,0.0112314,"Missing"
P06-1033,A00-2018,0,0.0593295,"MS is one of the hypotheses explored in the experimental study below. 2.4 form the dependency structure for coordination but does not present any results. Graph transformations in dependency parsing have also been used in order to recover nonprojective dependencies together with parsers that are restricted to projective dependency graphs. Thus, Nivre and Nilsson (2005) improve parsing accuracy for MaltParser by projectivizing training data and applying an inverse transformation to the output of the parser, while Hall and Nov´ak (2005) apply post-processing to the output of Charniak’s parser (Charniak, 2000). In the final experiments below, we combine these techniques with the transformations investigated in this paper. MaltParser MaltParser (Nivre and Hall, 2005; Nivre et al., 2006) is a data-driven parser-generator, which can induce a dependency parser from a treebank, and which supports several parsing algorithms and learning algorithms. In the experiments below we use the algorithm of Nivre (2003), which constructs a labeled dependency graph in one leftto-right pass over the input. Classifiers that predict the next parser action are constructed through memory-based learning (MBL), using the T"
P06-1033,P99-1065,0,0.0830956,"Missing"
P06-1033,P05-1013,1,0.831833,"ness itself distinguished final of-the-tournament (“The final of the tournament was distinguished by great fighting spirit and unexpected hardness”) Figure 2: Transformed dependency graph for a Czech sentence from the Prague Dependency Treebank this to MS is one of the hypotheses explored in the experimental study below. 2.4 form the dependency structure for coordination but does not present any results. Graph transformations in dependency parsing have also been used in order to recover nonprojective dependencies together with parsers that are restricted to projective dependency graphs. Thus, Nivre and Nilsson (2005) improve parsing accuracy for MaltParser by projectivizing training data and applying an inverse transformation to the output of the parser, while Hall and Nov´ak (2005) apply post-processing to the output of Charniak’s parser (Charniak, 2000). In the final experiments below, we combine these techniques with the transformations investigated in this paper. MaltParser MaltParser (Nivre and Hall, 2005; Nivre et al., 2006) is a data-driven parser-generator, which can induce a dependency parser from a treebank, and which supports several parsing algorithms and learning algorithms. In the experiment"
P06-1033,P97-1003,0,0.015225,"tion for a deterministic data-driven dependency parser. Combining these transformations with previously proposed techniques for recovering nonprojective dependencies leads to state-ofthe-art accuracy for the given data set. 1 Johan Hall V¨axj¨o University jha@msi.vxu.se Introduction It has become increasingly clear that the choice of suitable internal representations can be a very important factor in data-driven approaches to syntactic parsing, and that accuracy can often be improved by internal transformations of a given kind of representation. This is well illustrated by the Collins parser (Collins, 1997; Collins, 1999), scrutinized by Bikel (2004), where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation. Other examples can be found in the work of Johnson (1998) and Klein and Manning (2003), which show that well-chosen transformations of syntactic representations can greatly improve the parsing accuracy obtained with probabilistic context-free grammars. In this paper, we apply essentially the same techniques to data-driven dependency parsing, 257 Proceedings of the 21st International Conference on Computational Linguistics and 4"
P06-1033,nivre-etal-2006-maltparser,1,0.806084,"that pose special problems for dependency-based approaches. The basic idea is that we can facilitate learning by transforming the training data for the parser and that we can subsequently recover the original representations by applying an inverse transformation to the parser’s output. The data used in the experiments come from the Prague Dependency Treebank (PDT) (Hajiˇc, 1998; Hajiˇc et al., 2001), the largest available dependency treebank, annotated according to the theory of Functional Generative Description (FGD) (Sgall et al., 1986). The parser used is MaltParser (Nivre and Hall, 2005; Nivre et al., 2006), a freely available system that combines a deterministic parsing strategy with discriminative classifiers for predicting the next parser action. The paper is structured as follows. Section 2 provides the necessary background, including a definition of dependency graphs, a discussion of different approaches to the analysis of coordination and verb groups in dependency grammar, as well as brief descriptions of PDT, MaltParser and some related work. Section 3 introduces a set of dependency graph transformations, specifically defined to deal with the dependency annotation found in PDT, which are"
P06-1033,W03-3017,1,0.600125,"ltParser by projectivizing training data and applying an inverse transformation to the output of the parser, while Hall and Nov´ak (2005) apply post-processing to the output of Charniak’s parser (Charniak, 2000). In the final experiments below, we combine these techniques with the transformations investigated in this paper. MaltParser MaltParser (Nivre and Hall, 2005; Nivre et al., 2006) is a data-driven parser-generator, which can induce a dependency parser from a treebank, and which supports several parsing algorithms and learning algorithms. In the experiments below we use the algorithm of Nivre (2003), which constructs a labeled dependency graph in one leftto-right pass over the input. Classifiers that predict the next parser action are constructed through memory-based learning (MBL), using the T I MBL software package (Daelemans and Van den Bosch, 2005), and support vector machines (SVM), using LIBSVM (Chang and Lin, 2005). 2.5 3 Dependency Graph Transformations In this section, we describe algorithms for transforming dependency graphs in PDT from PS to MS and back, starting with coordination and continuing with verb groups. Related Work Other ways of improving parsing accuracy with respe"
P06-1033,W05-1504,0,0.0127147,"atistically significant (McNemar’s test) with respect to attachment score (labeled and unlabeled) and unlabeled exact match, with p &lt; 0.01 except for the unlabeled exact match score of the verb group transformation, where 0.01 &lt; p &lt; 0.05. For the labeled exact match, no differences are significant. The experimental results indicate that MS is more suitable than PS as the target representation for deterministic data-driven dependency parsing. A relevant question is of course why this is the case. A partial explanation may be found in the “short-dependency preference” exhibited by most parsers (Eisner and Smith, 2005), with MaltParser being no exception. The first row of table 4 shows the accuracy of the parser for different arc lengths under the baseline condition (i.e., with no transformations). We see that it performs very well on bank contains 19 erroneous heads. 262 90.1 1 51.9 54.1 52.9 83.6 2-3 29.4 29.1 29.2 70.5 4-6 11.2 10.7 10.7 59.5 7-10 4.4 3.8 4.2 45.9 113.0 2.4 2.9 Table 4: Baseline labeled AS per arc length on ∆e (row 1); proportion of arcs per arc length in ∆t (rows 3–5) short arcs, but that accuracy drops quite rapidly as the arcs get longer. This can be related to the mean arc length in"
P06-1033,C00-2086,0,0.0239246,"ict the next parser action are constructed through memory-based learning (MBL), using the T I MBL software package (Daelemans and Van den Bosch, 2005), and support vector machines (SVM), using LIBSVM (Chang and Lin, 2005). 2.5 3 Dependency Graph Transformations In this section, we describe algorithms for transforming dependency graphs in PDT from PS to MS and back, starting with coordination and continuing with verb groups. Related Work Other ways of improving parsing accuracy with respect to coordination include learning patterns of morphological and semantical information for the conjuncts (Park and Cho, 2000). More specifically for PDT, Collins et al. (1999) relabel coordinated phrases after converting dependency structures to phrase structures, and Zeman (2004) uses a kind of pattern matching, based on frequencies of the parts-of-speech of conjuncts and conjunctions. Zeman also mentions experiments to trans3.1 Coordination The PS-to-MS transformation for coordination will be designated τc (∆), where ∆ is a data set. The transformation begins with the identification of a base conjunction, based on its dependency type (Coord) and/or its part-of-speech (Jˆ). For example, the word a (and) in figure 1"
P06-1033,W05-1513,0,0.0201085,"Missing"
P06-1033,W05-1505,0,0.0458694,"Missing"
P06-1033,W05-1518,0,0.0131298,"Missing"
P06-1033,J98-4004,0,0.0626781,"Johan Hall V¨axj¨o University jha@msi.vxu.se Introduction It has become increasingly clear that the choice of suitable internal representations can be a very important factor in data-driven approaches to syntactic parsing, and that accuracy can often be improved by internal transformations of a given kind of representation. This is well illustrated by the Collins parser (Collins, 1997; Collins, 1999), scrutinized by Bikel (2004), where several transformations are applied in order to improve the analysis of noun phrases, coordination and punctuation. Other examples can be found in the work of Johnson (1998) and Klein and Manning (2003), which show that well-chosen transformations of syntactic representations can greatly improve the parsing accuracy obtained with probabilistic context-free grammars. In this paper, we apply essentially the same techniques to data-driven dependency parsing, 257 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 257–264, c Sydney, July 2006. 2006 Association for Computational Linguistics 2 Background 2.1 the conjuncts, and instead let the conjuncts have a direct dependency relation to the same head"
P06-1033,J04-4004,0,\N,Missing
P06-1033,J03-4003,0,\N,Missing
P06-2041,H92-1026,0,0.0185906,"ntal setup, including data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) 1. V = Zn+1 2. E ⊆ V × V 3. L : E → R The set V of nodes (or vertices) is the set Zn+1 = {0, 1, 2, . . . , n} (n ∈ Z+ ), i.e., the set of nonnegative integers up to and including n. This means that every token index i of the sentence is a node (1 ≤ i ≤ n) and that there is a special node 0, which does not correspond to any token of the sentence and which will always be a root of the dependency graph (normall"
P06-2041,P05-1022,0,0.0149171,"lts reported for more complex parsing models. 1 Jens Nilsson V¨axj¨o University jha@msi.vxu.se Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, c Sydney, July 2006. 2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre"
P06-2041,A00-2018,0,0.0209077,"s, albeit with considerably longer training times. The results also confirm that classifier-based deterministic parsing can achieve parsing accuracy very close to the best results reported for more complex parsing models. 1 Jens Nilsson V¨axj¨o University jha@msi.vxu.se Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, c Sydney, July 2006. 2006 Association for Computational Linguistics performance than M"
P06-2041,I05-3003,0,0.0776211,"ap the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the algorithms of Yamada and Matsumoto (2003) and Nivre (2003), while Sagae and Lavie (2005) find that SVM gives better Deterministic parsing guided by treebankinduced classifiers has emerged as a simple and efficient alternative to more complex models for data-driven parsing. We present a systematic comparison of memory-based learning (MBL) and support vector machines (SVM) for inducing classifiers for deterministic dependency parsing, using data from Chinese, English and Swedish, together with a variety of diff"
P06-2041,J05-1003,0,0.0134431,"ry close to the best results reported for more complex parsing models. 1 Jens Nilsson V¨axj¨o University jha@msi.vxu.se Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, c Sydney, July 2006. 2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the det"
P06-2041,W04-2407,1,0.787439,"o University jni@msi.vxu.se Joakim Nivre V¨axj¨o University and Uppsala University nivre@msi.vxu.se Abstract parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among"
P06-2041,daelemans-hoste-2002-evaluation,0,0.0140922,"ency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on data from three different languages – Chinese, English, and Swedish – and on five different feature models of varying complexity, with a separate optimization of learning algorithm parameters for each combination of language and feature model. The central importance of feature selection and parameter optimization in machine learning research has been shown very clearly in recent research (Daelemans and Hoste, 2002; Daelemans et al., 2003). The rest of the paper is structured as follows. Section 2 presents the parsing framework, including the deterministic parsing algorithm and the history-based feature models. Section 3 discusses the two learning algorithms used in the experiments, and section 4 describes the experimental setup, including data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but reli"
P06-2041,W03-3017,1,0.944707,"avie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the algorithms of Yamada and Matsumoto (2003) and Nivre (2003), while Sagae and Lavie (2005) find that SVM gives better Deterministic parsing guided by treebankinduced classifiers has emerged as a simple and efficient alternative to more complex models for data-driven parsing. We present a systematic comparison of memory-based learning (MBL) and support vector machines (SVM) for inducing classifiers for deterministic dependency parsing, using data from Chinese, English and Swedish, together with a variety of different feature models. The comparison shows that SVM gives higher accuracy for richly articulated feature models across all languages, albeit wit"
P06-2041,W97-0301,0,0.070373,"ture models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) 1. V = Zn+1 2. E ⊆ V × V 3. L : E → R The set V of nodes (or vertices) is the set Zn+1 = {0, 1, 2, . . . , n} (n ∈ Z+ ), i.e., the set of nonnegative integers up to and including n. This means that every token index i of the sentence is a node (1 ≤ i ≤ n) and that there is a special node 0, which does not correspond to any token of the sentence and which will always be a root of the dependency graph (normally the only root). We use V + to den"
P06-2041,W05-1513,0,0.0294234,"by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusi"
P06-2041,W04-3201,0,0.0213426,"es in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, c Sydney, July 2006. 2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on data from three different languages – Chinese, English, and Swedish – and on five d"
P06-2041,P99-1069,0,0.0106965,"ve parsing accuracy very close to the best results reported for more complex parsing models. 1 Jens Nilsson V¨axj¨o University jha@msi.vxu.se Introduction Mainstream approaches in statistical parsing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, c Sydney, July 2006. 2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for depende"
P06-2041,N01-1025,0,0.0293937,") are address functions, identifying the head (h), the leftmost child (l), and the rightmost child (r), of the token identified by α (according to the function h). 3.2 SVM in its simplest form is a binary classifier that tries to separate positive and negative cases in training data by a hyperplane using a linear kernel function. The goal is to find the hyperplane that separates the training data into two classes with the largest margin. By using other kernel functions, such as polynomial or radial basis function (RBF), feature vectors are mapped into a higher dimensional space (Vapnik, 1998; Kudo and Matsumoto, 2001). Multi-class classification with n classes can be handled by the one-versus-all method, with n classifiers that each separate one class from the rest, or the one-versus-one method, with n(n − 1)/2 classifiers, one for each pair of classes (Vural and Dy, 2004). SVM requires all features to be numerical, which means that symbolic features have to be converted, normally by introducing one binary feature for each value of the symbolic feature. For the experiments reported in this paper we use the LIBSVM library (Wu et al., 2004; Chang and Lin, 2005) with the polynomial kernel K(xi , xj ) = (γxTi"
P06-2041,W02-2016,0,0.220245,"(2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the"
P06-2041,P95-1037,0,0.131906,"g data sets, feature models, learning algorithm parameters, and evaluation metrics. Experimental results are presented and discussed in section 5, and conclusions in section 6. 2 Inductive Dependency Parsing The system we use for the experiments uses no grammar but relies completely on inductive learning from treebank data. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based models for predicting the next parser action (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999) 3. Discriminative learning to map histories to parser actions (Kudo and Matsumoto, 2002; Yamada and Matsumoto, 2003; Nivre et al., 2004) 1. V = Zn+1 2. E ⊆ V × V 3. L : E → R The set V of nodes (or vertices) is the set Zn+1 = {0, 1, 2, . . . , n} (n ∈ Z+ ), i.e., the set of nonnegative integers up to and including n. This means that every token index i of the sentence is a node (1 ≤ i ≤ n) and that there is a special node 0, which does not correspond to any token of the sentence and which will always be a root of the dependency graph (normally the only root)"
P06-2041,W03-3023,0,0.708299,"s extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which is based on the idea that learning is the simple storage of experiences in memory and that solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans and Van den Bosch, 2005), has been used primarily by Nivre et al. (2004), Nivre and Scholz (2004), and Sagae and Lavie (2005). Comparative studies of learning algorithms are relatively rare. Cheng et al. (2005b) report that SVM outperforms MaxEnt models in Chinese dependency parsing, using the algorithms of Yamada and Mats"
P06-2041,P05-1012,0,0.136879,"sing are based on nondeterministic parsing techniques, usually employing some kind of dynamic programming, in combination with generative probabilistic models that provide an n-best ranking of the set of candidate analyses derived by the parser (Collins, 1997; Collins, 1999; Charniak, 2000). These parsers can be enhanced by using a discriminative model, which reranks the analyses output by the parser (Johnson et al., 1999; Collins and Duffy, 2005; Charniak and Johnson, 2005). Alternatively, discriminative models can be used to search the complete space of possible parses (Taskar et al., 2004; McDonald et al., 2005). A radically different approach is to perform disambiguation deterministically, using a greedy 316 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 316–323, c Sydney, July 2006. 2006 Association for Computational Linguistics performance than MBL in a constituency-based shift-reduce parser for English. In this paper, we present a detailed comparison of SVM and MBL for dependency parsing using the deterministic algorithm of Nivre (2003). The comparison is based on data from three different languages – Chinese, English, and Swedish – and on five different feature models"
P06-2041,C04-1010,1,0.623039,"re V¨axj¨o University and Uppsala University nivre@msi.vxu.se Abstract parsing algorithm that approximates a globally optimal solution by making a sequence of locally optimal choices, guided by a classifier trained on gold standard derivations from a treebank. This methodology has emerged as an alternative to more complex models, especially in dependencybased parsing. It was first used for unlabeled dependency parsing by Kudo and Matsumoto (2002) (for Japanese) and Yamada and Matsumoto (2003) (for English). It was extended to labeled dependency parsing by Nivre et al. (2004) (for Swedish) and Nivre and Scholz (2004) (for English). More recently, it has been applied with good results to lexicalized phrase structure parsing by Sagae and Lavie (2005). The machine learning methods used to induce classifiers for deterministic parsing are dominated by two approaches. Support vector machines (SVM), which combine the maximum margin strategy introduced by Vapnik (1995) with the use of kernel functions to map the original feature space to a higher-dimensional space, have been used by Kudo and Matsumoto (2002), Yamada and Matsumoto (2003), and Sagae and Lavie (2005), among others. Memory-based learning (MBL), which"
P06-2041,P97-1003,0,\N,Missing
P06-2041,J03-4003,0,\N,Missing
P06-2041,H94-1020,0,\N,Missing
P06-2041,P93-1005,0,\N,Missing
P06-2066,P99-1065,0,0.137744,"Missing"
P06-2066,P01-1024,0,0.0276704,"e rooted at j . These subtrees interleave, as T1 contains the nodes 2 and 4, and T2 contains the nodes 3 and 5. 1 2i 3 4 5 j (a) gd D 0, ed D 0, wnC 6 1 2i 3 4 j 5 6 (b) gd D 1, ed D 1, wnC 1 2i 3 j 4 5 6 (c) gd D 2, ed D 1, wn Figure 3: Gap degree, edge degree, and well-nestedness 3.3 or more edges .i; k/ in T by edges .j ; k/, where j ! i . The exact conditions under which a certain lifting may take place are specified in the rules of the grammar. A dependency tree is acceptable, if it can be lifted to form a projective graph.3 A similar design is pursued in Topological Dependency Grammar (Duchier and Debusmann, 2001), where a dependency analysis consists of two, mutually constraining graphs: the ID graph represents information about immediate dominance, the LP graph models the topological structure of a sentence. As a principle of the grammar, the LP graph is required to be a lift of the ID graph; this lifting can be constrained in the lexicon. Edge degree The notion of edge degree was introduced by Nivre (2006) in order to allow mildly non-projective structures while maintaining good parsing efficiency in data-driven dependency parsing.2 Define the span of an edge .i; j / as the interval S..i; j // WD Œm"
P06-2066,C96-1058,0,0.0661308,"ing of the sentence, it corresponds to a ban on discontinuous constituents in phrase structure representations. Projectivity is an interesting constraint on dependency structures both from a theoretical and a practical perspective. Dependency grammars that only allow projective structures are closely related to context-free grammars (Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and"
P06-2066,E06-1012,0,0.0178577,"Missing"
P06-2066,W05-1505,0,0.0357835,"antees good parsing complexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous. This is especially relevant for languages with free or flexible word order. However, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (Nivre and Nilsson, 2005; Hall and Novák, 2005; McDonald and Pereira, 2006). This raises the question of whether it is possible to characterize a class of mildly non-projective dependency structures that is rich enough to account for naturally occurring syntactic constructions, yet restricted enough to enable efficient parsing. In this paper, we review a number of proposals for classes of dependency structures that lie between strictly projective and completely unrestricted non-projective structures. These classes have in common that they can be characterized in terms of properties of the dependency structures themselves, rather than in t"
P06-2066,E06-1011,0,0.0143615,"mplexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous. This is especially relevant for languages with free or flexible word order. However, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (Nivre and Nilsson, 2005; Hall and Novák, 2005; McDonald and Pereira, 2006). This raises the question of whether it is possible to characterize a class of mildly non-projective dependency structures that is rich enough to account for naturally occurring syntactic constructions, yet restricted enough to enable efficient parsing. In this paper, we review a number of proposals for classes of dependency structures that lie between strictly projective and completely unrestricted non-projective structures. These classes have in common that they can be characterized in terms of properties of the dependency structures themselves, rather than in terms of grammar formalisms th"
P06-2066,H05-1066,0,0.266303,"Missing"
P06-2066,P05-1013,1,0.388197,"hile this constraint guarantees good parsing complexity, it is well-known that certain syntactic constructions can only be adequately represented by non-projective dependency structures, where the projection of a head can be discontinuous. This is especially relevant for languages with free or flexible word order. However, recent results in non-projective dependency parsing, especially using data-driven methods, indicate that most non-projective structures required for the analysis of natural language are very nearly projective, differing only minimally from the best projective approximation (Nivre and Nilsson, 2005; Hall and Novák, 2005; McDonald and Pereira, 2006). This raises the question of whether it is possible to characterize a class of mildly non-projective dependency structures that is rich enough to account for naturally occurring syntactic constructions, yet restricted enough to enable efficient parsing. In this paper, we review a number of proposals for classes of dependency structures that lie between strictly projective and completely unrestricted non-projective structures. These classes have in common that they can be characterized in terms of properties of the dependency structures themse"
P06-2066,W03-3017,1,0.874638,"an interesting constraint on dependency structures both from a theoretical and a practical perspective. Dependency grammars that only allow projective structures are closely related to context-free grammars (Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and relate them to each other. 3.1 1 Yli-Jyrä (2003) proposes multiplanarity as a generalization of planarity suitable for modell"
P06-2066,E06-1010,1,0.876226,"(Gaifman, 1965; Obre¸bski and Grali´nski, 2004); among other things, they have the same (weak) expressivity. The projectivity constraint also leads to favourable parsing complexities: chart-based parsing of projective dependency grammars can be done in cubic time (Eisner, 1996); hard-wiring projectivity into a deterministic dependency parser leads to linear-time parsing in the worst case (Nivre, 2003). 508 3 Relaxations of projectivity While the restriction to projective analyses has a number of advantages, there is clear evidence that it cannot be maintained for real-world data (Zeman, 2004; Nivre, 2006). For example, the graph in Figure 1 is non-projective: the yield of the node 1 (marked by the dashed rectangles) does not form an interval—the node 2 is ‘missing’. In this section, we present several proposals for structural constraints that relax projectivity, and relate them to each other. 3.1 1 Yli-Jyrä (2003) proposes multiplanarity as a generalization of planarity suitable for modelling dependency analyses, and evaluates it experimentally using data from DDT. Definition 5 A dependency graph G D .V I E/ is m-planar, if it can be split into m planar graphs 1 2 3 4 5 (b) 2-planar Figure 2:"
P06-2066,W04-1508,0,0.0346234,"Missing"
P06-2066,P92-1012,0,0.861113,"Missing"
P06-2066,1993.iwpt-1.22,0,0.0968269,"an interval (.2; 3; 4/), so i has gap degree 0. In Graph 3b, i D .2; 3; 6/ contains a single gap (.3; 6/), so the gap degree of i is 1. In the rightmost graph, the gap degree of i is 2, since i D .2; 4; 6/ contains two gaps (.2; 4/ and .4; 6/). Definition 7 The gap degree of a dependency graph G , gd.G/, is the maximum among the gap degrees of its nodes. Definition 4 A dependency graph is planar, if it does not contain nodes a; b; c; d such that linked.a; c/ ^ linked.b; d/ ^ a &lt; b &lt; c &lt; d : 3 (a) 1-planar Planarity and multiplanarity The notion of planarity appears in work on Link Grammar (Sleator and Temperley, 1993), where it is traced back to Mel’ˇcuk (1988). Informally, a dependency graph is planar, if its edges can be drawn above the sentence without crossing. We emphasize the word above, because planarity as it is understood here does not coincide with the standard graph-theoretic concept of the same name, where one would be allowed to also use the area below the sentence to disentangle the edges. Figure 2a shows a dependency graph that is planar but not projective: while there are no crossing edges, the yield of the node 1 (the set f1; 3g) does not form an interval. Using the notation linked.i; j /"
P06-2066,P98-1106,0,0.104755,"ependent is .1; 5/, but the root of the connected component f2; 3; 4g is dominated by 1. Both Graph 3b and 3c have edge degree 1: the edge .3; 6/ in Graph 3b and the edges .2; 4/, .3; 5/ and .4; 6/ in Graph 3c each span a single connected component that is not dominated by the respective head. 3.4 Related work Apart from proposals for structural constraints relaxing projectivity, there are dependency frameworks that in principle allow unrestricted graphs, but provide mechanisms to control the actually permitted forms of non-projectivity in the grammar. The non-projective dependency grammar of Kahane et al. (1998) is based on an operation on dependency trees called lifting: a ‘lift’ of a tree T is the new tree that is obtained when one replaces one 3.5 Discussion The structural conditions we have presented here naturally fall into two groups: multiplanarity, gap degree and edge degree are parametric constraints with an infinite scale of possible values; planarity and well-nestedness come as binary constraints. We discuss these two groups in turn. Parametric constraints With respect to the graded constraints, we find that multiplanarity is different from both gap degree and edge degree in that it involv"
P06-2066,C98-1102,0,\N,Missing
P07-1122,dzeroski-etal-2006-towards,0,0.0627161,"Missing"
P07-1122,W05-1505,0,0.0402116,"Missing"
P07-1122,J98-4004,0,0.0559025,"sformations appear to be more sensitive to parsing strategy but have a constant positive effect over several languages. 1 Johan Hall∗ Introduction Treebank parsers are trained on syntactically annotated sentences and a major part of their success can be attributed to extensive manipulations of the training data as well as the output of the parser, usually in the form of various tree transformations. This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al. (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). Corresponding manipulations in the form of tree transformations for dependency-based parsers have recently 968 gained more interest (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006; Nilsson et al., 2006) but are still less studied, partly because constituency-based parsing has dominated the field for a long time, and partly because dependency structures have less structure to manipulate than constituent structures. Most of the studies in this tradition focus on a particular parsing model and a particular data set, which m"
P07-1122,P98-1106,0,0.0399914,"ection 2 surveys tree transformations used in dependency parsing and discusses dependencies between transformations, on the one hand, and treebanks and parsers, on the other. Section 3 introduces the four treebanks used in this study, and section 4 briefly describes the two parsers. Experimental results are presented in section 5 and conclusions in section 6. 2 2.1 Background Non-projectivity The tree transformations that have attracted most interest in the literature on dependency parsing are those concerned with recovering non-projectivity. The definition of non-projectivity can be found in Kahane et al. (1998). Informally, an arc is projective if all tokens it covers are descendants of the arc’s head token, and a dependency tree is projective if all its arcs are projective.1 The full potential of dependency parsing can only be realized if non-projectivity is allowed, which pose a problem for projective dependency parsers. Direct non-projective parsing can be performed with good accuracy, e.g., using the Chu-Liu-Edmonds al1 If dependency arcs are drawn above the linearly ordered sequence of tokens, preceded by a special root node, then a nonprojective dependency tree always has crossing arcs. 969 go"
P07-1122,P03-1054,0,0.0120051,"ar to be more sensitive to parsing strategy but have a constant positive effect over several languages. 1 Johan Hall∗ Introduction Treebank parsers are trained on syntactically annotated sentences and a major part of their success can be attributed to extensive manipulations of the training data as well as the output of the parser, usually in the form of various tree transformations. This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al. (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). Corresponding manipulations in the form of tree transformations for dependency-based parsers have recently 968 gained more interest (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006; Nilsson et al., 2006) but are still less studied, partly because constituency-based parsing has dominated the field for a long time, and partly because dependency structures have less structure to manipulate than constituent structures. Most of the studies in this tradition focus on a particular parsing model and a particular data set, which means that it is difficult"
P07-1122,E06-1011,0,0.082226,"ccess can be attributed to extensive manipulations of the training data as well as the output of the parser, usually in the form of various tree transformations. This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al. (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). Corresponding manipulations in the form of tree transformations for dependency-based parsers have recently 968 gained more interest (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006; Nilsson et al., 2006) but are still less studied, partly because constituency-based parsing has dominated the field for a long time, and partly because dependency structures have less structure to manipulate than constituent structures. Most of the studies in this tradition focus on a particular parsing model and a particular data set, which means that it is difficult to say whether the effect of a given transformation is dependent on a particular parsing strategy or on properties of a particular language or treebank, or both. The aim of this study is to further investigate some tree transfo"
P07-1122,H05-1066,0,0.0919218,"Missing"
P07-1122,W06-2932,0,0.0977238,"Missing"
P07-1122,P06-1033,1,0.935391,"xtensive manipulations of the training data as well as the output of the parser, usually in the form of various tree transformations. This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al. (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). Corresponding manipulations in the form of tree transformations for dependency-based parsers have recently 968 gained more interest (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006; Nilsson et al., 2006) but are still less studied, partly because constituency-based parsing has dominated the field for a long time, and partly because dependency structures have less structure to manipulate than constituent structures. Most of the studies in this tradition focus on a particular parsing model and a particular data set, which means that it is difficult to say whether the effect of a given transformation is dependent on a particular parsing strategy or on properties of a particular language or treebank, or both. The aim of this study is to further investigate some tree transformation techniques prev"
P07-1122,P05-1013,1,0.92199,"annotated sentences and a major part of their success can be attributed to extensive manipulations of the training data as well as the output of the parser, usually in the form of various tree transformations. This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al. (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). Corresponding manipulations in the form of tree transformations for dependency-based parsers have recently 968 gained more interest (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006; Nilsson et al., 2006) but are still less studied, partly because constituency-based parsing has dominated the field for a long time, and partly because dependency structures have less structure to manipulate than constituent structures. Most of the studies in this tradition focus on a particular parsing model and a particular data set, which means that it is difficult to say whether the effect of a given transformation is dependent on a particular parsing strategy or on properties of a particular language or treebank, or both. The aim of thi"
P07-1122,W06-2920,0,0.0458822,"ost-processing, and where the parser is treated as a black box, such as the pseudo-projective parsing technique proposed by Nivre and Nilsson (2005) and the tree transformations investigated in Nilsson et al. (2006). To study the influence of lanProceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 968–975, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics guage and treebank specific properties we will use data from Arabic, Czech, Dutch, and Slovene, taken from the CoNLL-X shared task on multilingual dependency parsing (Buchholz and Marsi, 2006). To study the influence of parsing methodology, we will compare two different parsers: MaltParser (Nivre et al., 2004) and MSTParser (McDonald et al., 2005). Note that, while it is possible in principle to distinguish between syntactic properties of a language as such and properties of a particular syntactic annotation of the language in question, it will be impossible to tease these apart in the experiments reported here, since this would require having not only multiple languages but also multiple treebanks for each language. In the following, we will therefore speak about the properties of"
P07-1122,P04-1082,0,0.0174705,"If dependency arcs are drawn above the linearly ordered sequence of tokens, preceded by a special root node, then a nonprojective dependency tree always has crossing arcs. 969 gorithm, as proposed by McDonald et al. (2005). On the other hand, non-projective parsers tend, among other things, to be slower. In order to maintain the benefits of projective parsing, tree transformations techniques to recover non-projectivity while using a projective parser have been proposed in several studies, some described below. In discussing the recovery of empty categories in data-driven constituency parsing, Campbell (2004) distinguishes between approaches based on pure post-processing and approaches based on a combination of preprocessing and post-processing. The same division can be made for the recovery of nonprojective dependencies in data-driven dependency parsing. Pure Post-processing Hall and Nov´ak (2005) propose a corrective modeling approach. The motivation is that the parsers of Collins et al. (1999) and Charniak (2000) adapted to Czech are not able to create the non-projective arcs present in the treebank, which is unsatisfactory. They therefore aim to correct erroneous arcs in the parser’s output (s"
P07-1122,A00-2018,0,0.711742,"rategy but sensitive to language or treebank specific properties. By contrast, the construction specific transformations appear to be more sensitive to parsing strategy but have a constant positive effect over several languages. 1 Johan Hall∗ Introduction Treebank parsers are trained on syntactically annotated sentences and a major part of their success can be attributed to extensive manipulations of the training data as well as the output of the parser, usually in the form of various tree transformations. This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al. (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). Corresponding manipulations in the form of tree transformations for dependency-based parsers have recently 968 gained more interest (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006; Nilsson et al., 2006) but are still less studied, partly because constituency-based parsing has dominated the field for a long time, and partly because dependency structures have less structure to manipulate than constituent structures."
P07-1122,P99-1065,0,0.126046,"Missing"
P07-1122,W04-2407,1,0.921307,"ivre and Nilsson (2005) and the tree transformations investigated in Nilsson et al. (2006). To study the influence of lanProceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 968–975, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics guage and treebank specific properties we will use data from Arabic, Czech, Dutch, and Slovene, taken from the CoNLL-X shared task on multilingual dependency parsing (Buchholz and Marsi, 2006). To study the influence of parsing methodology, we will compare two different parsers: MaltParser (Nivre et al., 2004) and MSTParser (McDonald et al., 2005). Note that, while it is possible in principle to distinguish between syntactic properties of a language as such and properties of a particular syntactic annotation of the language in question, it will be impossible to tease these apart in the experiments reported here, since this would require having not only multiple languages but also multiple treebanks for each language. In the following, we will therefore speak about the properties of treebanks (rather than languages), but it should be understood that these properties in general depend both on propert"
P07-1122,W06-2933,1,0.866014,"Missing"
P07-1122,P06-1055,0,0.0256405,"to language or treebank specific properties. By contrast, the construction specific transformations appear to be more sensitive to parsing strategy but have a constant positive effect over several languages. 1 Johan Hall∗ Introduction Treebank parsers are trained on syntactically annotated sentences and a major part of their success can be attributed to extensive manipulations of the training data as well as the output of the parser, usually in the form of various tree transformations. This can be seen in state-of-the-art constituency-based parsers such as Collins (1999), Charniak (2000), and Petrov et al. (2006), and the effects of different transformations have been studied by Johnson (1998), Klein and Manning (2003), and Bikel (2004). Corresponding manipulations in the form of tree transformations for dependency-based parsers have recently 968 gained more interest (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006; Nilsson et al., 2006) but are still less studied, partly because constituency-based parsing has dominated the field for a long time, and partly because dependency structures have less structure to manipulate than constituent structures. Most of the studies in thi"
P07-1122,J04-4004,0,\N,Missing
P07-1122,J03-4003,0,\N,Missing
P07-1122,C98-1102,0,\N,Missing
P08-1108,W06-2922,0,0.042532,"component arcs, and perform parsing by searching for the highest-scoring graph. This type of model has been used by, among others, Eisner (1996), McDonald et al. (2005a), and Nakagawa (2007). In transition-based parsing, we instead learn a model for scoring transitions from one parser state to the next, conditioned on the parse history, and perform parsing by greedily taking the highest-scoring transition out of every parser state until we have derived a complete dependency graph. This approach is represented, for example, by the models of Yamada and Matsumoto (2003), Nivre et al. (2004), and Attardi (2006). Theoretically, these approaches are very different. The graph-based models are globally trained and use exact inference algorithms, but define features over a limited history of parsing decisions. The transitionbased models are essentially the opposite. They use local training and greedy inference algorithms, but 950 Proceedings of ACL-08: HLT, pages 950–958, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics define features over a rich history of parsing decisions. This is a fundamental trade-off that is hard to overcome by tractable means. Both models have bee"
P08-1108,A00-2018,0,0.0608921,"ike the models presented here, integration takes place only at parsing time, not at learning time, and requires at least three different base parsers. The same technique was used by Hall et al. (2007) to combine six transition-based parsers in the best performing system in the CoNLL 2007 shared task. Feature-based integration in the sense of letting a subset of the features for one model be derived from the output of a different model has been exploited for dependency parsing by McDonald (2006), who trained an instance of MSTParser using features generated by the parsers of Collins (1999) and Charniak (2000), which improved unlabeled accuracy by 1.7 percentage points, again on data from the Penn Treebank. In addition, feature-based integration has been used by Taskar et al. (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al. (2004), who trained classifiers on auxiliary data to guide named entity classifiers. Feature-based integration also has points in common with co-training, which have been applied to syntactic parsing by Sarkar (2001) and Steedman et al. (2003), among others. The difference, of course, is that standard co-"
P08-1108,W04-1513,0,0.0099063,"show how these results can be exploited to improve parsing accuracy by integrating a graph-based and a transition-based model. By letting one model generate features for the other, we consistently improve accuracy for both models, resulting in a significant improvement of the state of the art when evaluated on data sets from the CoNLL-X shared task. 1 Figure 1: Dependency graph for an English sentence. Introduction Syntactic dependency graphs have recently gained a wide interest in the natural language processing community and have been used for many problems ranging from machine translation (Ding and Palmer, 2004) to ontology construction (Snow et al., 2005). A dependency graph for a sentence represents each word and its syntactic dependents through labeled directed arcs, as shown in figure 1. One advantage of this representation is that it extends naturally to discontinuous constructions, which arise due to long distance dependencies or in languages where syntactic structure is encoded in morphology rather than in word order. This is undoubtedly one of the reasons for the emergence of dependency parsers for a wide range of languages. Many of these parsers are based on data-driven parsing models, which"
P08-1108,D07-1098,0,0.0151148,"out integrating the two models. Thus, Nakagawa (2007) and Hall (2007) both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme. For transition-based models, the trend is to alleviate error propagation by abandoning greedy, deterministic inference in favor of beam search with globally normalized models for scoring transition sequences, either generative (Titov and Henderson, 2007a; Titov and Henderson, 2007b) or conditional (Duan et al., 2007; Johansson and Nugues, 2007). 6 Conclusion In this paper, we have demonstrated how the two dominant approaches to data-driven dependency parsing, graph-based models and transition-based models, can be integrated by letting one model learn from features generated by the other. Our experimental results show that both models consistently improve their accuracy when given access to features generated by the other model, which leads to a significant advancement of the state of the art in data-driven dependency parsing. Moreover, a comparative error analysis reveals that the improvements are largel"
P08-1108,C96-1058,0,0.141901,"aphs for sentences solely from an annotated corpus and can be easily ported to any language or domain in which annotated resources exist. Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased (McDonald and Nivre, 2007). In graph-based parsing, we learn a model for scoring possible dependency graphs for a given sentence, typically by factoring the graphs into their component arcs, and perform parsing by searching for the highest-scoring graph. This type of model has been used by, among others, Eisner (1996), McDonald et al. (2005a), and Nakagawa (2007). In transition-based parsing, we instead learn a model for scoring transitions from one parser state to the next, conditioned on the parse history, and perform parsing by greedily taking the highest-scoring transition out of every parser state until we have derived a complete dependency graph. This approach is represented, for example, by the models of Yamada and Matsumoto (2003), Nivre et al. (2004), and Attardi (2006). Theoretically, these approaches are very different. The graph-based models are globally trained and use exact inference algorith"
P08-1108,N04-1001,0,0.0290764,"d task. Feature-based integration in the sense of letting a subset of the features for one model be derived from the output of a different model has been exploited for dependency parsing by McDonald (2006), who trained an instance of MSTParser using features generated by the parsers of Collins (1999) and Charniak (2000), which improved unlabeled accuracy by 1.7 percentage points, again on data from the Penn Treebank. In addition, feature-based integration has been used by Taskar et al. (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al. (2004), who trained classifiers on auxiliary data to guide named entity classifiers. Feature-based integration also has points in common with co-training, which have been applied to syntactic parsing by Sarkar (2001) and Steedman et al. (2003), among others. The difference, of course, is that standard co-training is a weakly supervised method, where guide features replace, rather than complement, the gold standard annotation during 957 training. Feature-based integration is also similar to parse re-ranking (Collins, 2000), where one parser produces a set of candidate parses and a secondstage classif"
P08-1108,D07-1097,1,0.729656,"Missing"
P08-1108,P07-1050,0,0.0814548,"roduces a set of candidate parses and a secondstage classifier chooses the most likely one. However, feature-based integration is not explicitly constrained to any parse decisions that the guide model might make and only the single most likely parse is used from the guide model, making it significantly more efficient than re-ranking. Finally, there are several recent developments in data-driven dependency parsing, which can be seen as targeting the specific weaknesses of graph-based and transition-based models, respectively, though without integrating the two models. Thus, Nakagawa (2007) and Hall (2007) both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme. For transition-based models, the trend is to alleviate error propagation by abandoning greedy, deterministic inference in favor of beam search with globally normalized models for scoring transition sequences, either generative (Titov and Henderson, 2007a; Titov and Henderson, 2007b) or conditional (Duan et al., 2007; Johansson and Nugues, 2007). 6 Conclusion In this"
P08-1108,P07-1120,0,0.0182811,"for (a) dependency length and (b) distance to root. German, Portuguese and Slovene. Finally, given that the two base models had the previously best performance for these data sets, the guided models achieve a substantial improvement of the state of the art. While there is no statistically significant difference between the two base models, they are both outperformed by MaltMST (p &lt; 0.0001), which in turn has significantly lower accuracy than MSTMalt (p &lt; 0.0005). An extension to the models described so far would be to iteratively integrate the two parsers in the spirit of pipeline iteration (Hollingshead and Roark, 2007). For example, one could start with a Malt model, use it to train a guided MSTMalt model, then use that as the guide to train a MaltMSTMalt model, etc. We ran such experiments, but found that accuracy did not increase significantly and in some cases decreased slightly. This was true regardless of which parser began the iterative process. In retrospect, this result is not surprising. Since the initial integration effectively incorporates knowledge from both parsing systems, there is little to be gained by adding additional parsers in the chain. 4.2 Analysis The experimental results presented so"
P08-1108,D07-1123,0,0.0809681,"two models. Thus, Nakagawa (2007) and Hall (2007) both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme. For transition-based models, the trend is to alleviate error propagation by abandoning greedy, deterministic inference in favor of beam search with globally normalized models for scoring transition sequences, either generative (Titov and Henderson, 2007a; Titov and Henderson, 2007b) or conditional (Duan et al., 2007; Johansson and Nugues, 2007). 6 Conclusion In this paper, we have demonstrated how the two dominant approaches to data-driven dependency parsing, graph-based models and transition-based models, can be integrated by letting one model learn from features generated by the other. Our experimental results show that both models consistently improve their accuracy when given access to features generated by the other model, which leads to a significant advancement of the state of the art in data-driven dependency parsing. Moreover, a comparative error analysis reveals that the improvements are largely predictable from theoretica"
P08-1108,D07-1013,1,0.629031,"s or in languages where syntactic structure is encoded in morphology rather than in word order. This is undoubtedly one of the reasons for the emergence of dependency parsers for a wide range of languages. Many of these parsers are based on data-driven parsing models, which learn to produce dependency graphs for sentences solely from an annotated corpus and can be easily ported to any language or domain in which annotated resources exist. Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased (McDonald and Nivre, 2007). In graph-based parsing, we learn a model for scoring possible dependency graphs for a given sentence, typically by factoring the graphs into their component arcs, and perform parsing by searching for the highest-scoring graph. This type of model has been used by, among others, Eisner (1996), McDonald et al. (2005a), and Nakagawa (2007). In transition-based parsing, we instead learn a model for scoring transitions from one parser state to the next, conditioned on the parse history, and perform parsing by greedily taking the highest-scoring transition out of every parser state until we have de"
P08-1108,W07-2216,1,0.134744,"rther defines the score of a dependency graph as the sum of the 1 We use the common convention of representing words by their index in the sentence. 951 score of all the arcs it contains. As a result, the dependency parsing problem is written: X G = arg max s(i, j, l) G=(V,A) (i,j,l)∈A This problem is equivalent to finding the highest scoring directed spanning tree in the complete graph over the input sentence, which can be solved in O(n2 ) time (McDonald et al., 2005b). Additional parameterizations are possible that take more than one arc into account, but have varying effects on complexity (McDonald and Satta, 2007). An advantage of graph-based methods is that tractable inference enables the use of standard structured learning techniques that globally set parameters to maximize parsing performance on the training set (McDonald et al., 2005a). The primary disadvantage of these models is that scores – and as a result any feature representations – are restricted to a single arc or a small number of arcs in the graph. The specific graph-based model studied in this work is that presented by McDonald et al. (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive s"
P08-1108,P05-1012,1,0.648377,"ces solely from an annotated corpus and can be easily ported to any language or domain in which annotated resources exist. Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased (McDonald and Nivre, 2007). In graph-based parsing, we learn a model for scoring possible dependency graphs for a given sentence, typically by factoring the graphs into their component arcs, and perform parsing by searching for the highest-scoring graph. This type of model has been used by, among others, Eisner (1996), McDonald et al. (2005a), and Nakagawa (2007). In transition-based parsing, we instead learn a model for scoring transitions from one parser state to the next, conditioned on the parse history, and perform parsing by greedily taking the highest-scoring transition out of every parser state until we have derived a complete dependency graph. This approach is represented, for example, by the models of Yamada and Matsumoto (2003), Nivre et al. (2004), and Attardi (2006). Theoretically, these approaches are very different. The graph-based models are globally trained and use exact inference algorithms, but define features"
P08-1108,H05-1066,1,0.332049,"Missing"
P08-1108,W06-2932,1,0.684549,"are possible that take more than one arc into account, but have varying effects on complexity (McDonald and Satta, 2007). An advantage of graph-based methods is that tractable inference enables the use of standard structured learning techniques that globally set parameters to maximize parsing performance on the training set (McDonald et al., 2005a). The primary disadvantage of these models is that scores – and as a result any feature representations – are restricted to a single arc or a small number of arcs in the graph. The specific graph-based model studied in this work is that presented by McDonald et al. (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models Transition-based dependency parsing systems use a model parameterized over transitions of an abstract machine for deriving dependency graphs, such that every transition sequence from the designated initial configuration to some terminal configuration derives a valid depen"
P08-1108,D07-1100,0,0.135669,"corpus and can be easily ported to any language or domain in which annotated resources exist. Practically all data-driven models that have been proposed for dependency parsing in recent years can be described as either graph-based or transitionbased (McDonald and Nivre, 2007). In graph-based parsing, we learn a model for scoring possible dependency graphs for a given sentence, typically by factoring the graphs into their component arcs, and perform parsing by searching for the highest-scoring graph. This type of model has been used by, among others, Eisner (1996), McDonald et al. (2005a), and Nakagawa (2007). In transition-based parsing, we instead learn a model for scoring transitions from one parser state to the next, conditioned on the parse history, and perform parsing by greedily taking the highest-scoring transition out of every parser state until we have derived a complete dependency graph. This approach is represented, for example, by the models of Yamada and Matsumoto (2003), Nivre et al. (2004), and Attardi (2006). Theoretically, these approaches are very different. The graph-based models are globally trained and use exact inference algorithms, but define features over a limited history"
P08-1108,W04-2407,1,0.288215,"ng the graphs into their component arcs, and perform parsing by searching for the highest-scoring graph. This type of model has been used by, among others, Eisner (1996), McDonald et al. (2005a), and Nakagawa (2007). In transition-based parsing, we instead learn a model for scoring transitions from one parser state to the next, conditioned on the parse history, and perform parsing by greedily taking the highest-scoring transition out of every parser state until we have derived a complete dependency graph. This approach is represented, for example, by the models of Yamada and Matsumoto (2003), Nivre et al. (2004), and Attardi (2006). Theoretically, these approaches are very different. The graph-based models are globally trained and use exact inference algorithms, but define features over a limited history of parsing decisions. The transitionbased models are essentially the opposite. They use local training and greedy inference algorithms, but 950 Proceedings of ACL-08: HLT, pages 950–958, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics define features over a rich history of parsing decisions. This is a fundamental trade-off that is hard to overcome by tractable means."
P08-1108,W06-2933,1,0.872408,"Missing"
P08-1108,W03-3017,1,0.306869,"erminal configuration is reached. This can be seen as a greedy search for the optimal dependency graph, based on a sequence of locally optimal decisions in terms of the transition system. Many transition systems for data-driven dependency parsing are inspired by shift-reduce parsing, 2 http://mstparser.sourceforge.net where each configuration c contains a stack σc for storing partially processed nodes and a buffer βc containing the remaining input. Transitions in such a system add arcs to the dependency graph and manipulate the stack and buffer. One example is the transition system defined by Nivre (2003), which parses a sentence x = w0 , w1 , . . . , wn in O(n) time. To learn a scoring function on transitions, these systems rely on discriminative learning methods, such as memory-based learning or support vector machines, using a strictly local learning procedure where only single transitions are scored (not complete transition sequences). The main advantage of these models is that features are not restricted to a limited number of graph arcs but can take into account the entire dependency graph built so far. The major disadvantage is that the greedy parsing strategy may lead to error propagat"
P08-1108,N06-2033,0,0.554753,"ghts of the guided features to be small (since they are not needed at training time). On the other hand, an online learning algorithm will recognize the guided features as strong indicators early in training and give them a high weight as a result. Features with high weight early in training tend to have the most impact on the final classifier due to both weight regularization and averaging. This is in fact observed when inspecting the weights of MSTMalt . 5 Related Work Combinations of graph-based and transition-based models for data-driven dependency parsing have previously been explored by Sagae and Lavie (2006), who report improvements of up to 1.7 percentage points over the best single parser when combining three transition-based models and one graph-based model for unlabeled dependency parsing, evaluated on data from the Penn Treebank. The combined parsing model is essentially an instance of the graph-based model, where arc scores are derived from the output of the different component parsers. Unlike the models presented here, integration takes place only at parsing time, not at learning time, and requires at least three different base parsers. The same technique was used by Hall et al. (2007) to"
P08-1108,N01-1023,0,0.0547264,"an instance of MSTParser using features generated by the parsers of Collins (1999) and Charniak (2000), which improved unlabeled accuracy by 1.7 percentage points, again on data from the Penn Treebank. In addition, feature-based integration has been used by Taskar et al. (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al. (2004), who trained classifiers on auxiliary data to guide named entity classifiers. Feature-based integration also has points in common with co-training, which have been applied to syntactic parsing by Sarkar (2001) and Steedman et al. (2003), among others. The difference, of course, is that standard co-training is a weakly supervised method, where guide features replace, rather than complement, the gold standard annotation during 957 training. Feature-based integration is also similar to parse re-ranking (Collins, 2000), where one parser produces a set of candidate parses and a secondstage classifier chooses the most likely one. However, feature-based integration is not explicitly constrained to any parse decisions that the guide model might make and only the single most likely parse is used from the gu"
P08-1108,H05-1010,0,0.0205901,"as used by Hall et al. (2007) to combine six transition-based parsers in the best performing system in the CoNLL 2007 shared task. Feature-based integration in the sense of letting a subset of the features for one model be derived from the output of a different model has been exploited for dependency parsing by McDonald (2006), who trained an instance of MSTParser using features generated by the parsers of Collins (1999) and Charniak (2000), which improved unlabeled accuracy by 1.7 percentage points, again on data from the Penn Treebank. In addition, feature-based integration has been used by Taskar et al. (2005), who trained a discriminative word alignment model using features derived from the IBM models, and by Florian et al. (2004), who trained classifiers on auxiliary data to guide named entity classifiers. Feature-based integration also has points in common with co-training, which have been applied to syntactic parsing by Sarkar (2001) and Steedman et al. (2003), among others. The difference, of course, is that standard co-training is a weakly supervised method, where guide features replace, rather than complement, the gold standard annotation during 957 training. Feature-based integration is als"
P08-1108,D07-1099,0,0.0840753,"es of graph-based and transition-based models, respectively, though without integrating the two models. Thus, Nakagawa (2007) and Hall (2007) both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme. For transition-based models, the trend is to alleviate error propagation by abandoning greedy, deterministic inference in favor of beam search with globally normalized models for scoring transition sequences, either generative (Titov and Henderson, 2007a; Titov and Henderson, 2007b) or conditional (Duan et al., 2007; Johansson and Nugues, 2007). 6 Conclusion In this paper, we have demonstrated how the two dominant approaches to data-driven dependency parsing, graph-based models and transition-based models, can be integrated by letting one model learn from features generated by the other. Our experimental results show that both models consistently improve their accuracy when given access to features generated by the other model, which leads to a significant advancement of the state of the art in data-driven dependency parsing. Moreover, a com"
P08-1108,W07-2218,0,0.0947249,"es of graph-based and transition-based models, respectively, though without integrating the two models. Thus, Nakagawa (2007) and Hall (2007) both try to overcome the limited feature scope of graph-based models by adding global features, in the former case using Gibbs sampling to deal with the intractable inference problem, in the latter case using a re-ranking scheme. For transition-based models, the trend is to alleviate error propagation by abandoning greedy, deterministic inference in favor of beam search with globally normalized models for scoring transition sequences, either generative (Titov and Henderson, 2007a; Titov and Henderson, 2007b) or conditional (Duan et al., 2007; Johansson and Nugues, 2007). 6 Conclusion In this paper, we have demonstrated how the two dominant approaches to data-driven dependency parsing, graph-based models and transition-based models, can be integrated by letting one model learn from features generated by the other. Our experimental results show that both models consistently improve their accuracy when given access to features generated by the other model, which leads to a significant advancement of the state of the art in data-driven dependency parsing. Moreover, a com"
P08-1108,W03-3023,0,0.726168,"entence, typically by factoring the graphs into their component arcs, and perform parsing by searching for the highest-scoring graph. This type of model has been used by, among others, Eisner (1996), McDonald et al. (2005a), and Nakagawa (2007). In transition-based parsing, we instead learn a model for scoring transitions from one parser state to the next, conditioned on the parse history, and perform parsing by greedily taking the highest-scoring transition out of every parser state until we have derived a complete dependency graph. This approach is represented, for example, by the models of Yamada and Matsumoto (2003), Nivre et al. (2004), and Attardi (2006). Theoretically, these approaches are very different. The graph-based models are globally trained and use exact inference algorithms, but define features over a limited history of parsing decisions. The transitionbased models are essentially the opposite. They use local training and greedy inference algorithms, but 950 Proceedings of ACL-08: HLT, pages 950–958, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics define features over a rich history of parsing decisions. This is a fundamental trade-off that is hard to overcome"
P08-1108,W06-2920,0,\N,Missing
P08-1108,J03-4003,0,\N,Missing
P08-1108,D07-1096,1,\N,Missing
P09-1040,P97-1043,0,0.0426251,"Missing"
P09-1040,W06-2922,0,0.697518,"mpirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora. Evaluation on data from five languages shows state-of-the-art accuracy, with especially good results for the labeled exact match score. 1 Introduction Syntactic parsing using dependency structures has become a standard technique in natural language processing with many different parsing models, in particular data-driven models that can be trained on syntactically annotated corpora (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Attardi, 2006; Titov and Henderson, 2007). A hallmark of many of these models is that they can be implemented very efficiently. Thus, transition-based parsers normally run in linear or quadratic time, using greedy deterministic search or fixed-width beam search (Nivre et al., 2004; Attardi, 2006; Johansson and Nugues, 2007; Titov and Henderson, 2007), and graph-based models support exact inference in at most cubic time, which is efficient enough to make global discriminative training practically feasible (McDonald et al., 2005a; McDonald et al., 2005b). However, one problem that still has not found a satis"
P09-1040,P08-1108,1,0.778354,"with a completely correct labeled dependency tree. The score in brackets is the attachment score for the (small) subset of tokens that are connected to their head by a non-projective arc in the gold standard parse. For comparison, the table also includes results for the two best performing systems in the original CoNLL-X shared task, Malt-06 (Nivre et al., 2006) and MST-06 (McDonald et al., 2006), as well as the integrated system MSTMalt , which is a graph-based parser guided by the predictions of a transition-based parser and currently has the best reported results on the CoNLL-X data sets (Nivre and McDonald, 2008). Looking first at the overall attachment score, we see that Su gives a substantial improvement over Sp (and outperforms Spp ) for Czech and Slovene, where the scores achieved are rivaled only by the combo system MSTMalt . For these languages, there is no statistical difference between Su and MSTMalt , which are both significantly better than all the other parsers, except Spp for Czech (McNemar’s test, α = .05). This is accompanied by an improvement on non-projective arcs, where in Figure 5, where black dots represent training sentences (parsed with the oracle) and white dots represent test se"
P09-1040,W06-2920,0,0.381984,"(white) for Arabic (1460/146 sentences) and Danish (5190/322 sentences). be tested experimentally in the next section. tions occurs when no S WAP transitions are performed, in which case the behavior of the system is identical to the simpler system Sp . This is important, because it means that the best-case complexity of the deterministic parser is still O(n) and that the we can expect to observe the best case for all sentences with projective dependency trees. 4 Experiments Our experiments are based on five data sets from the CoNLL-X shared task: Arabic, Czech, Danish, Slovene, and Turkish (Buchholz and Marsi, 2006). These languages have been selected because the data come from genuine dependency treebanks, whereas all the other data sets are based on some kind of conversion from another type of representation, which could potentially distort the distribution of different types of structures in the data. The exact number of additional transitions needed to reach a terminal configuration is determined by the number of S WAP transitions. Since S WAP moves one node from Σ to B, there will be one additional S HIFT for every S WAP, which means that the total number of transitions is 2n + 2k, where k is the nu"
P09-1040,P05-1013,1,0.816592,"usually modeled by non-projective 351 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 351–359, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP  ROOT 0    NMOD  DET  SBJ   VG  ? ? ? ? ROOT  P ADV  ?  DET   ? ?  PC ? ? A1 hearing2 is3 scheduled4 on5 the6 issue7 today8 .9 Figure 1: Dependency tree for an English sentence (non-projective). be well-formed, we in addition require that it is a tree rooted at the node 0, as illustrated in Figure 1. projective dependencies by post-processing the output of a strictly projective parser (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006). In this paper, we will adopt a different strategy, suggested in recent work by Nivre (2008b) and Titov et al. (2009), and propose an algorithm that only combines adjacent substructures but derives non-projective trees by reordering the input words. The rest of the paper is structured as follows. In Section 2, we define the formal representations needed and introduce the framework of transitionbased dependency parsing. In Section 3, we first define a minimal transition system and explain how it can be used to perform projective dependency pa"
P09-1040,W04-2407,1,0.926529,"linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora. Evaluation on data from five languages shows state-of-the-art accuracy, with especially good results for the labeled exact match score. 1 Introduction Syntactic parsing using dependency structures has become a standard technique in natural language processing with many different parsing models, in particular data-driven models that can be trained on syntactically annotated corpora (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Attardi, 2006; Titov and Henderson, 2007). A hallmark of many of these models is that they can be implemented very efficiently. Thus, transition-based parsers normally run in linear or quadratic time, using greedy deterministic search or fixed-width beam search (Nivre et al., 2004; Attardi, 2006; Johansson and Nugues, 2007; Titov and Henderson, 2007), and graph-based models support exact inference in at most cubic time, which is efficient enough to make global discriminative training practically feasible (McDonald et al., 2005a; McDonald et al., 2005b). However, one p"
P09-1040,E09-1034,0,0.0718479,"Missing"
P09-1040,W06-2933,1,0.545869,"Missing"
P09-1040,W05-1505,0,0.0739147,"Missing"
P09-1040,W04-0308,1,0.634629,"is given by an upper bound on the length of transition sequences in S. 2. R IGHT-A RCl updates a configuration with i, j on top of the stack by adding (i, l, j) to A and replacing i, j on the stack by i alone. 3. S HIFT updates a configuration with i as the first node of the buffer by removing i from the buffer and pushing it onto the stack. The system Sp = (C, Tp , cs , Ct ) is sound and complete for the set of projective dependency trees (over some label set L) and has been used, in slightly different variants, by a number of transition-based dependency parsers (Yamada and Matsumoto, 2003; Nivre, 2004; Attardi, 2006; 353 Transition Stack (Σ) [ROOT0 ] S HIFT [ROOT0 , A1 ] S HIFT [ROOT0 , A1 , hearing2 ] LA DET [ROOT0 , hearing2 ] S HIFT [ROOT0 , hearing2 , is3 ] S HIFT [ROOT0 , . . . , is3 , scheduled4 ] S HIFT [ROOT0 , . . . , scheduled4 , on5 ] S WAP [ROOT0 , . . . , is3 , on5 ] S WAP [ROOT0 , hearing2 , on5 ] S HIFT [ROOT0 , . . . , on5 , is3 ] S HIFT [ROOT0 , . . . , is3 , scheduled4 ] S HIFT [ROOT0 , . . . , scheduled4 , the6 ] S WAP [ROOT0 , . . . , is3 , the6 ] S WAP [ROOT0 , . . . , on5 , the6 ] S HIFT [ROOT0 , . . . , the6 , is3 ] S HIFT [ROOT0 , . . . , is3 , scheduled4 ] S HIFT ["
P09-1040,P07-1077,0,0.0249242,"transition sequences from the training sets (as described below in Section 4.2), to see whether the trained parsers deviate from the ideal case. The result for Arabic and Danish can be seen The running time of a deterministic transitionbased parser using the system Su is O(n) in the best case and O(n2 ) in the worst case. But what about the average case? Empirical studies, based on data from a wide range of languages, have shown that dependency trees tend to be projective and that most non-projective trees only contain a small number of discontinuities (Nivre, 2006; Kuhlmann and Nivre, 2006; Havelka, 2007). This should mean that the expected number of swaps per sentence is small, and that the running time is linear on average for the range of inputs that occur in natural languages. This is a hypothesis that will 356 System Su Sp Spp Malt-06 MST-06 MSTMalt Arabic AS EM 67.1 (9.1) 11.6 67.3 (18.2) 11.6 67.2 (18.2) 11.6 66.7 (18.2) 11.0 66.9 (0.0) 10.3 68.6 (9.4) 11.0 Czech AS 82.4 (73.8) 80.9 (3.7) 82.1 (60.7) 78.4 (57.9) 80.2 (61.7) 82.3 (69.2) EM 35.3 31.2 34.0 27.4 29.9 31.2 Danish AS EM 84.2 (22.5) 26.7 84.6 (0.0) 27.0 84.7 (22.5) 28.9 84.8 (27.5) 26.7 84.8 (62.5) 25.5 86.7 (60.0) 29.8 Sloven"
P09-1040,D07-1123,0,0.0162628,"actic parsing using dependency structures has become a standard technique in natural language processing with many different parsing models, in particular data-driven models that can be trained on syntactically annotated corpora (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Attardi, 2006; Titov and Henderson, 2007). A hallmark of many of these models is that they can be implemented very efficiently. Thus, transition-based parsers normally run in linear or quadratic time, using greedy deterministic search or fixed-width beam search (Nivre et al., 2004; Attardi, 2006; Johansson and Nugues, 2007; Titov and Henderson, 2007), and graph-based models support exact inference in at most cubic time, which is efficient enough to make global discriminative training practically feasible (McDonald et al., 2005a; McDonald et al., 2005b). However, one problem that still has not found a satisfactory solution in data-driven dependency parsing is the treatment of discontinuous syntactic constructions, usually modeled by non-projective 351 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 351–359, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP  ROOT 0"
P09-1040,N07-1050,1,0.815907,"the overall attachment score, and we conjecture that the strength of the positive effect is dependent on the frequency of non-projective arcs in the language. 5 There are also affinities to the system of Attardi (2006), which combines non-adjacent nodes on the stack instead of swapping nodes and is equivalent to a restricted version of our system, where no more than two consecutive S WAP transitions are permitted. This restriction preserves linear worstcase complexity at the expense of completeness. Finally, the algorithm first described by Covington (2001) and used for data-driven parsing by Nivre (2007), is complete but has quadratic complexity even in the best case. 6 Conclusion We have presented a novel transition system for dependency parsing that can handle unrestricted non-projective trees. The system reuses standard techniques for building projective trees by combining adjacent nodes (representing subtrees with adjacent yields), but adds a simple mechanism for swapping the order of nodes on the stack, which gives a system that is sound and complete for the set of all dependency trees over a given label set but behaves exactly like the standard system for the subset of projective trees."
P09-1040,P06-2066,1,0.809102,"iers trained on the oracle transition sequences from the training sets (as described below in Section 4.2), to see whether the trained parsers deviate from the ideal case. The result for Arabic and Danish can be seen The running time of a deterministic transitionbased parser using the system Su is O(n) in the best case and O(n2 ) in the worst case. But what about the average case? Empirical studies, based on data from a wide range of languages, have shown that dependency trees tend to be projective and that most non-projective trees only contain a small number of discontinuities (Nivre, 2006; Kuhlmann and Nivre, 2006; Havelka, 2007). This should mean that the expected number of swaps per sentence is small, and that the running time is linear on average for the range of inputs that occur in natural languages. This is a hypothesis that will 356 System Su Sp Spp Malt-06 MST-06 MSTMalt Arabic AS EM 67.1 (9.1) 11.6 67.3 (18.2) 11.6 67.2 (18.2) 11.6 66.7 (18.2) 11.0 66.9 (0.0) 10.3 68.6 (9.4) 11.0 Czech AS 82.4 (73.8) 80.9 (3.7) 82.1 (60.7) 78.4 (57.9) 80.2 (61.7) 82.3 (69.2) EM 35.3 31.2 34.0 27.4 29.9 31.2 Danish AS EM 84.2 (22.5) 26.7 84.6 (0.0) 27.0 84.7 (22.5) 28.9 84.8 (27.5) 26.7 84.8 (62.5) 25.5 86.7 (6"
P09-1040,J08-4003,1,0.508641,"2-7 August 2009. 2009 ACL and AFNLP  ROOT 0    NMOD  DET  SBJ   VG  ? ? ? ? ROOT  P ADV  ?  DET   ? ?  PC ? ? A1 hearing2 is3 scheduled4 on5 the6 issue7 today8 .9 Figure 1: Dependency tree for an English sentence (non-projective). be well-formed, we in addition require that it is a tree rooted at the node 0, as illustrated in Figure 1. projective dependencies by post-processing the output of a strictly projective parser (Nivre and Nilsson, 2005; Hall and Nov´ak, 2005; McDonald and Pereira, 2006). In this paper, we will adopt a different strategy, suggested in recent work by Nivre (2008b) and Titov et al. (2009), and propose an algorithm that only combines adjacent substructures but derives non-projective trees by reordering the input words. The rest of the paper is structured as follows. In Section 2, we define the formal representations needed and introduce the framework of transitionbased dependency parsing. In Section 3, we first define a minimal transition system and explain how it can be used to perform projective dependency parsing in linear time; we then extend the system with a single transition for swapping the order of words in the input and demonstrate that the e"
P09-1040,E09-1055,0,0.144182,"Missing"
P09-1040,E06-1011,0,0.449656,"g, SE-35195 V¨axj¨o E-mail: joakim.nivre@lingfil.uu.se Abstract dependency trees, as illustrated in Figure 1. In a projective dependency tree, the yield of every subtree is a contiguous substring of the sentence. This is not the case for the tree in Figure 1, where the subtrees rooted at node 2 (hearing) and node 4 (scheduled) both have discontinuous yields. Allowing non-projective trees generally makes parsing computationally harder. Exact inference for parsing models that allow non-projective trees is NP hard, except under very restricted independence assumptions (Neuhaus and Br¨oker, 1997; McDonald and Pereira, 2006; McDonald and Satta, 2007). There is recent work on algorithms that can cope with important subsets of all nonprojective trees in polynomial time (Kuhlmann and Satta, 2009; G´omez-Rodr´ıguez et al., 2009), but the time complexity is at best O(n6 ), which can be problematic in practical applications. Even the best algorithms for deterministic parsing run in quadratic time, rather than linear (Nivre, 2008a), unless restricted to a subset of non-projective structures as in Attardi (2006) and Nivre (2007). But allowing non-projective dependency trees also makes parsing empirically harder, because"
P09-1040,W07-2218,0,0.212413,"tes based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora. Evaluation on data from five languages shows state-of-the-art accuracy, with especially good results for the labeled exact match score. 1 Introduction Syntactic parsing using dependency structures has become a standard technique in natural language processing with many different parsing models, in particular data-driven models that can be trained on syntactically annotated corpora (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Attardi, 2006; Titov and Henderson, 2007). A hallmark of many of these models is that they can be implemented very efficiently. Thus, transition-based parsers normally run in linear or quadratic time, using greedy deterministic search or fixed-width beam search (Nivre et al., 2004; Attardi, 2006; Johansson and Nugues, 2007; Titov and Henderson, 2007), and graph-based models support exact inference in at most cubic time, which is efficient enough to make global discriminative training practically feasible (McDonald et al., 2005a; McDonald et al., 2005b). However, one problem that still has not found a satisfactory solution in data-dri"
P09-1040,W07-2216,0,0.0328691,"Missing"
P09-1040,P05-1012,0,0.0245143,"notated corpora (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Attardi, 2006; Titov and Henderson, 2007). A hallmark of many of these models is that they can be implemented very efficiently. Thus, transition-based parsers normally run in linear or quadratic time, using greedy deterministic search or fixed-width beam search (Nivre et al., 2004; Attardi, 2006; Johansson and Nugues, 2007; Titov and Henderson, 2007), and graph-based models support exact inference in at most cubic time, which is efficient enough to make global discriminative training practically feasible (McDonald et al., 2005a; McDonald et al., 2005b). However, one problem that still has not found a satisfactory solution in data-driven dependency parsing is the treatment of discontinuous syntactic constructions, usually modeled by non-projective 351 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 351–359, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP  ROOT 0    NMOD  DET  SBJ   VG  ? ? ? ? ROOT  P ADV  ?  DET   ? ?  PC ? ? A1 hearing2 is3 scheduled4 on5 the6 issue7 today8 .9 Figure 1: Dependency tree for an English sentence (non-projective). be"
P09-1040,W03-3023,0,0.947076,"deterministic parsing from linear to quadratic in the worst case, but empirical estimates based on treebank data show that the expected running time is in fact linear for the range of data attested in the corpora. Evaluation on data from five languages shows state-of-the-art accuracy, with especially good results for the labeled exact match score. 1 Introduction Syntactic parsing using dependency structures has become a standard technique in natural language processing with many different parsing models, in particular data-driven models that can be trained on syntactically annotated corpora (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Attardi, 2006; Titov and Henderson, 2007). A hallmark of many of these models is that they can be implemented very efficiently. Thus, transition-based parsers normally run in linear or quadratic time, using greedy deterministic search or fixed-width beam search (Nivre et al., 2004; Attardi, 2006; Johansson and Nugues, 2007; Titov and Henderson, 2007), and graph-based models support exact inference in at most cubic time, which is efficient enough to make global discriminative training practically feasible (McDonald et al., 2005a; McDonald et al., 20"
P09-1040,H05-1066,0,0.609911,"Missing"
P09-1040,W06-2932,0,0.0277573,"Table 1 shows the labeled parsing accuracy of the parsers measured in two ways: attachment score (AS) is the percentage of tokens with the correct head and dependency label; exact match (EM) is the percentage of sentences with a completely correct labeled dependency tree. The score in brackets is the attachment score for the (small) subset of tokens that are connected to their head by a non-projective arc in the gold standard parse. For comparison, the table also includes results for the two best performing systems in the original CoNLL-X shared task, Malt-06 (Nivre et al., 2006) and MST-06 (McDonald et al., 2006), as well as the integrated system MSTMalt , which is a graph-based parser guided by the predictions of a transition-based parser and currently has the best reported results on the CoNLL-X data sets (Nivre and McDonald, 2008). Looking first at the overall attachment score, we see that Su gives a substantial improvement over Sp (and outperforms Spp ) for Czech and Slovene, where the scores achieved are rivaled only by the combo system MSTMalt . For these languages, there is no statistical difference between Su and MSTMalt , which are both significantly better than all the other parsers, except"
P09-1040,E06-1010,1,\N,Missing
P10-1151,afonso-etal-2002-floresta,0,0.077213,"Missing"
P10-1151,W03-2405,0,0.0743588,"Missing"
P10-1151,W06-2920,0,0.578526,"r. Secondly, we present a transition-based parsing algorithm for 2-planar dependency trees, developed in two steps. We begin by showing how the stack-based algorithm of Nivre (2003) can be generalized from projective to planar structures. We then extend the system by adding a second stack and show that the resulting system captures exactly the set of 2-planar structures. Although the contributions of this paper are mainly theoretical, we also present an empirical evaluation of the 2planar parser, showing that it outperforms the projective parser on four data sets from the CoNLL-X shared task (Buchholz and Marsi, 2006). 1492 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1492–1501, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics 2 Preliminaries 2.1 Dependency Graphs Let w = w1 . . . wn be an input string.1 An interval (with endpoints i and j) of the string w is a set of the form [i, j] = {wk |i ≤ k ≤ j}. Definition 1. A dependency graph for w is a directed graph G = (Vw , E), where Vw = [1, n] and E ⊆ Vw × Vw . We call an edge (wi , wj ) in a dependency graph G a dependency link2 from wi to wj . We say that wi is the parent ("
P10-1151,C96-1058,0,0.0688547,"led a dependency forest. Definition 3. A dependency forest G for a string w1 . . . wn is projective iff bwi c is an interval for every word wi ∈ [1, n]. Projective dependency trees correspond to the set of structures that can be induced from lexicalised context-free derivations (Kuhlmann, 2007; Gaifman, 1965). Like context-free grammars, projective dependency trees are not sufficient to represent all the linguistic phenomena observed in natural languages, but they have the advantage of being efficiently parsable: their parsing problem can be solved in cubic time with chart parsing techniques (Eisner, 1996; G´omez-Rodr´ıguez et al., 2008), while in the case of general non-projective dependency forests, it is only tractable under strong independence assumptions (McDonald et al., 2005b; McDonald and Satta, 2007). 2.3 Planarity Definition 2. A dependency graph G for a string w1 . . . wn is said to be a forest iff it satisfies: 1. Acyclicity: If wi →∗ wj , then not wj → wi . The concept of planarity (Sleator and Temperley, 1993) is closely related to projectivity3 and can be informally defined as the property of a dependency forest whose links can be drawn above the words without crossing.4 To defi"
P10-1151,P08-1110,1,0.91145,"Missing"
P10-1151,E09-1034,1,0.880589,"Missing"
P10-1151,P07-1077,0,0.0733295,"lanes with colours and say that a dependency graph G is m-planar if it is possible to assign one of m colours to each of its links in such a way that links with the same colour do not cross. Note that there may be multiple ways of dividing an m-planar graph into planes, as shown in the example of Figure 1. 3 Determining Multiplanarity Several constraints on non-projective dependency structures have been proposed recently that seek a good balance between parsing efficiency and coverage of non-projective phenomena present in natural language treebanks. For example, Kuhlmann and Nivre (2006) and Havelka (2007) have shown that the vast majority of structures present in existing treebanks are well-nested and have a small gap degree (Bodirsky et al., 2005), leading to an interest in parsers for these kinds of structures (G´omezRodr´ıguez et al., 2009). No similar analysis has been performed for m-planar structures, although Yli-Jyr¨a (2003) provides evidence that all except two structures in the Danish dependency treebank are at most 3-planar. However, his analysis is based on constraints that restrict the possible ways of assigning planes to dependency links, and he is not guaranteed to find the mini"
P10-1151,P07-1021,0,0.062204,"Missing"
P10-1151,P06-2066,1,0.801977,", i.e., i 6= j ⇔ wi 6= wj . This can be guaranteed in practice by annotating each terminal symbol with its position in the input. 2 In practice, dependency links are usually labeled, but to simplify the presentation we will ignore labels throughout most of the paper. However, all the results and algorithms presented can be applied to labeled dependency graphs and will be so applied in the experimental evaluation. 2.4 Multiplanarity The concept of planarity on its own does not seem to be very relevant as an extension of projectivity for practical dependency parsing. According to the results by Kuhlmann and Nivre (2006), most non-projective structures in dependency treebanks are also non-planar, so being able to parse planar structures will only give us a modest improvement in coverage with respect to a projective parser. However, our interest in planarity is motivated by the fact that it can be generalised to multiplanarity (Yli-Jyr¨a, 2003): 3 For dependency forests that are extended with a unique artificial root located at position 0, as is commonly done, the two notions are equivalent. 4 Planarity in the context of dependency structures is not to be confused with the homonymous concept in graph theory, w"
P10-1151,E09-1055,0,0.066818,"Missing"
P10-1151,P81-1022,0,0.645754,"Missing"
P10-1151,W06-2933,1,0.902061,"Missing"
P10-1151,P09-1039,0,0.103239,"Missing"
P10-1151,W07-2216,0,0.0633145,"roduction Dependency-based syntactic parsing has become a widely used technique in natural language processing, and many different parsing models have been proposed in recent years (Yamada and Matsumoto, 2003; Nivre et al., 2004; McDonald et al., 2005a; Titov and Henderson, 2007; Martins et al., 2009). One of the unresolved issues in this area is the proper treatment of non-projective dependency trees, which seem to be required for an adequate representation of predicate-argument structure, but which undermine the efficiency of dependency parsing (Neuhaus and Br¨oker, 1997; BuchKromann, 2006; McDonald and Satta, 2007). Caught between the Scylla of linguistically inadequate projective trees and the Charybdis of computationally intractable non-projective trees, some researchers have sought a middle ground by exploring classes of mildly non-projective dependency structures that strike a better balance between expressivity and complexity (Nivre, 2006; In this paper, we explore another characterization of mildly non-projective dependency trees based on the notion of multiplanarity. This was originally proposed by Yli-Jyr¨a (2003) but has so far played a marginal role in the dependency parsing literature, becaus"
P10-1151,P05-1012,0,0.0371918,"ncy trees correspond to the set of structures that can be induced from lexicalised context-free derivations (Kuhlmann, 2007; Gaifman, 1965). Like context-free grammars, projective dependency trees are not sufficient to represent all the linguistic phenomena observed in natural languages, but they have the advantage of being efficiently parsable: their parsing problem can be solved in cubic time with chart parsing techniques (Eisner, 1996; G´omez-Rodr´ıguez et al., 2008), while in the case of general non-projective dependency forests, it is only tractable under strong independence assumptions (McDonald et al., 2005b; McDonald and Satta, 2007). 2.3 Planarity Definition 2. A dependency graph G for a string w1 . . . wn is said to be a forest iff it satisfies: 1. Acyclicity: If wi →∗ wj , then not wj → wi . The concept of planarity (Sleator and Temperley, 1993) is closely related to projectivity3 and can be informally defined as the property of a dependency forest whose links can be drawn above the words without crossing.4 To define planarity more formally, we first define crossing links as follows: let (wi , wk ) and (wj , wl ) be dependency links in a dependency graph G. Without loss of generality, we ass"
P10-1151,H05-1066,0,0.478655,"Missing"
P10-1151,P97-1043,0,0.134556,"Missing"
P10-1151,P05-1013,1,0.824732,"e results in the next section. 6 Empirical Evaluation In order to get a first estimate of the empirical accuracy that can be obtained with transition-based 2-planar parsing, we have evaluated the parser on four data sets from the CoNLL-X shared task (Buchholz and Marsi, 2006): Czech, Danish, German and Portuguese. As our baseline, we take the strictly projective arc-eager transition system proposed by Nivre (2003), as implemented in the freely available MaltParser system (Nivre et al., 2006a), with and without the pseudo-projective parsing technique for recovering non-projective dependencies (Nivre and Nilsson, 2005). For the two baseline systems, we use the parameter settings used by Nivre et al. (2006b) in the original shared task, where the pseudo-projective version of MaltParser was one of the two top performing systems (Buchholz and Marsi, 2006). For our 2planar parser, we use the same kernelized SVM classifiers as MaltParser, using the LIBSVM package (Chang and Lin, 2001), with feature models that are similar to MaltParser but extended with features defined over the second stack.7 In Table 2, we report labeled (LAS) and unlabeled (UAS) attachment score on the four languages for all three systems. Fo"
P10-1151,W04-2407,1,0.668237,"Missing"
P10-1151,W03-3017,1,0.841258,"literature, because no algorithm was known for determining whether an arbitrary tree was mplanar, and no parsing algorithm existed for any constant value of m. The contribution of this paper is twofold. First, we present a procedure for determining the minimal number m such that a dependency tree is m-planar and use it to show that the overwhelming majority of sentences in dependency treebanks have a tree that is at most 2planar. Secondly, we present a transition-based parsing algorithm for 2-planar dependency trees, developed in two steps. We begin by showing how the stack-based algorithm of Nivre (2003) can be generalized from projective to planar structures. We then extend the system by adding a second stack and show that the resulting system captures exactly the set of 2-planar structures. Although the contributions of this paper are mainly theoretical, we also present an empirical evaluation of the 2planar parser, showing that it outperforms the projective parser on four data sets from the CoNLL-X shared task (Buchholz and Marsi, 2006). 1492 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1492–1501, c Uppsala, Sweden, 11-16 July 2010. 2010 As"
P10-1151,J08-4003,1,0.853845,"2 case. 4 Parsing 1-Planar Structures In this section, we present a deterministic lineartime parser for planar dependency structures. The parser is a variant of Nivre’s arc-eager projective parser (Nivre, 2003), modified so that it can also handle graphs that are planar but not projective. As seen in Table 1, this only gives a modest improvement in coverage compared to projective parsing, so the main interest of this algorithm lies in the fact that it can be generalised to deal with 2-planar structures, as shown in the next section. 4.1 Transition Systems In the transition-based framework of Nivre (2008), a deterministic dependency parser is defined by a non-deterministic transition system, specifying a set of elementary operations that can be executed during the parsing process, and an oracle that deterministically selects a single transition at each choice point of the parsing process. Definition 6. A transition system for dependency parsing is a quadruple S = (C, T, cs , Ct ) where 1. C is a set of possible parser configurations, 2. T is a set of transitions, each of which is a partial function t : C → C, 3. cs is a function that maps each input sentence w to an initial configuration cs (w"
P10-1151,C08-1095,0,0.0150134,"e same reason, we remove the constraint in Nivre’s parser by which words without a head cannot be reduced. This has the side effect of making the parser able to output cyclic graphs. Since we are interested in planar dependency forests, which do not contain cycles, we only apply A RC transitions after checking that there is no undirected path between the nodes to be linked. This check can be done without affecting the linear-time complexity of the 1496 parser by storing the weakly connected component of each node in g(c). The fine-grained transitions used by this parser have also been used by Sagae and Tsujii (2008) to parse DAGs. However, the latter parser differs from ours in the constraints, since it does not allow the reduction of words without a head (disallowing forests with covered roots) and does not enforce the acyclicity constraint (which is guaranteed by post-processing the graphs to break cycles). 4.3 Correctness and Complexity For reasons of space, we can only give a sketch of the correctness proof. We wish to prove that the planar transition system is sound and complete for the set Fp of all planar dependency forests. To prove soundness, we have to show that, for every sentence w and transi"
P10-1151,1993.iwpt-1.22,0,0.244733,"guistic phenomena observed in natural languages, but they have the advantage of being efficiently parsable: their parsing problem can be solved in cubic time with chart parsing techniques (Eisner, 1996; G´omez-Rodr´ıguez et al., 2008), while in the case of general non-projective dependency forests, it is only tractable under strong independence assumptions (McDonald et al., 2005b; McDonald and Satta, 2007). 2.3 Planarity Definition 2. A dependency graph G for a string w1 . . . wn is said to be a forest iff it satisfies: 1. Acyclicity: If wi →∗ wj , then not wj → wi . The concept of planarity (Sleator and Temperley, 1993) is closely related to projectivity3 and can be informally defined as the property of a dependency forest whose links can be drawn above the words without crossing.4 To define planarity more formally, we first define crossing links as follows: let (wi , wk ) and (wj , wl ) be dependency links in a dependency graph G. Without loss of generality, we assume that min(i, k) ≤ min(j, l). Then, the links are said to be crossing if min(i, k) < min(j, l) < max (i, k) < max (j, l). 2. Single-head: If wj → wi , then not wk → wi (for every k 6= j). Definition 4. A dependency graph is planar iff it does no"
P10-1151,W07-2218,0,0.169298,"Missing"
P10-1151,W03-3023,0,0.525037,"Missing"
P10-1151,E06-1010,1,\N,Missing
P10-1151,nivre-etal-2006-maltparser,1,\N,Missing
P11-2033,D07-1101,0,0.496386,"ers we are aware of through the combination of their POS-tag with information from S0 and N0 . Such use is exemplified by 190 the feature templates “from three words” in Table 1. We further use their word and POS-tag information as “unigram” features in Table 2. Moreover, we include the dependency label information in the unigram features, represented by l in the table. Unigram label information has been used in MaltParser (Nivre et al., 2006a; Nivre, 2006). Third-order features of S 0 and N0 Higher-order context features have been used by graph-based dependency parsers to improve accuracies (Carreras, 2007; Koo and Collins, 2010). We include information of third order dependency arcs in our new feature templates, when available. In Table 2, S0h2 , S0l2 , S0r2 and N0l2 refer to the head of S0h , the second leftmost modifier and the second rightmost modifier of S0 , and the second leftmost modifier of N0 , respectively. The new templates include unigram word, POS-tag and dependency labels of S0h2 , S0l2 , S0r2 and N0l2 , as well as POS-tag combinations with S0 and N0 . Set of dependency labels with S0 and N0 As a more global feature, we include the set of unique dependency labels from the modifie"
P11-2033,cer-etal-2010-parsing,0,0.0840264,"Missing"
P11-2033,W02-1001,0,0.651947,"rc-standard (Yamada and Matsumoto, 2003; Huang and Sagae, 2010) process. We adopt the arc-eager system1 , for which the actions are: • Shift, which removes the front of the queue and pushes it onto the top of the stack; • Reduce, which pops the top item off the stack; • LeftArc, which pops the top item off the stack, and adds it as a modifier to the front of the queue; • RightArc, which removes the front of the queue, pushes it onto the stack and adds it as a modifier to the top of the stack. Further, we follow Zhang and Clark (2008) and Huang et al. (2009) and use the generalized perceptron (Collins, 2002) for global learning and beamsearch for decoding. Unlike both earlier globallearning parsers, which only perform unlabeled parsing, we perform labeled parsing by augmenting the LeftArc and RightArc actions with the set of dependency labels. Hence our work is in line with Titov and Henderson (2007) in using labeled transitions with global learning. Moreover, we will see that label information can actually improve link accuracy. 3 Feature Templates At each step during a parsing process, the parser configuration can be represented by a tuple hS, N, Ai, where S is the stack, N is the queue of inco"
P11-2033,de-marneffe-etal-2006-generating,0,0.273267,"Missing"
P11-2033,P10-1110,0,0.878958,"inguistics:shortpapers, pages 188–193, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 The Transition-based Parsing Algorithm In a typical transition-based parsing process, the input words are put into a queue and partially built structures are organized by a stack. A set of shiftreduce actions are defined, which consume words from the queue and build the output parse. Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003; Huang and Sagae, 2010) process. We adopt the arc-eager system1 , for which the actions are: • Shift, which removes the front of the queue and pushes it onto the top of the stack; • Reduce, which pops the top item off the stack; • LeftArc, which pops the top item off the stack, and adds it as a modifier to the front of the queue; • RightArc, which removes the front of the queue, pushes it onto the stack and adds it as a modifier to the top of the stack. Further, we follow Zhang and Clark (2008) and Huang et al. (2009) and use the generalized perceptron (Collins, 2002) for global learning and beamsearch for decoding."
P11-2033,D09-1127,0,0.319641,"Missing"
P11-2033,D07-1123,0,0.0191833,"ndency parsing (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010) utilize a deterministic shift-reduce process for making structural predictions. Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser (Nivre et al., 2006b; McDonald et al., 2005; McDonald and Nivre, 2007). Recent research has addressed two potential disadvantages of systems like MaltParser. In the aspect of decoding, beam-search (Johansson and Nugues, 2007; Zhang and Clark, 2008; Huang et al., 2009) and partial dynamic-programming (Huang and Sagae, 2010) have been applied to improve upon 188 Joakim Nivre Uppsala University Department of Linguistics and Philology joakim.nivre@lingfil.uu.se greedy one-best search, and positive results were reported. In the aspect of training, global structural learning has been used to replace local learning on each decision (Zhang and Clark, 2008; Huang et al., 2009), although the effect of global learning has not been separated out and studied alone. In this short paper, we study a third aspect in a statistical"
P11-2033,P10-1001,0,0.752146,"s been used to replace local learning on each decision (Zhang and Clark, 2008; Huang et al., 2009), although the effect of global learning has not been separated out and studied alone. In this short paper, we study a third aspect in a statistical system: feature definition. Representing the type of information a statistical system uses to make predictions, feature templates can be one of the most important factors determining parsing accuracy. Various recent attempts have been made to include non-local features into graph-based dependency parsing (Smith and Eisner, 2008; Martins et al., 2009; Koo and Collins, 2010). Transitionbased parsing, by contrast, can easily accommodate arbitrarily complex representations involving nonlocal features. Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing (Zhang and Clark, 2009; Wang et al., 2006), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser (Nivre et al., 2006a). We explore considerably richer feature representations and"
P11-2033,P08-1068,0,0.724975,"Missing"
P11-2033,P09-1039,0,0.246008,"structural learning has been used to replace local learning on each decision (Zhang and Clark, 2008; Huang et al., 2009), although the effect of global learning has not been separated out and studied alone. In this short paper, we study a third aspect in a statistical system: feature definition. Representing the type of information a statistical system uses to make predictions, feature templates can be one of the most important factors determining parsing accuracy. Various recent attempts have been made to include non-local features into graph-based dependency parsing (Smith and Eisner, 2008; Martins et al., 2009; Koo and Collins, 2010). Transitionbased parsing, by contrast, can easily accommodate arbitrarily complex representations involving nonlocal features. Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing (Zhang and Clark, 2009; Wang et al., 2006), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser (Nivre et al., 2006a). We explore considerably richer feat"
P11-2033,D07-1013,1,0.745444,"hey give a signficant improvement of the state of the art. An open source release of our parser is freely available. 1 Introduction Transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010) utilize a deterministic shift-reduce process for making structural predictions. Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser (Nivre et al., 2006b; McDonald et al., 2005; McDonald and Nivre, 2007). Recent research has addressed two potential disadvantages of systems like MaltParser. In the aspect of decoding, beam-search (Johansson and Nugues, 2007; Zhang and Clark, 2008; Huang et al., 2009) and partial dynamic-programming (Huang and Sagae, 2010) have been applied to improve upon 188 Joakim Nivre Uppsala University Department of Linguistics and Philology joakim.nivre@lingfil.uu.se greedy one-best search, and positive results were reported. In the aspect of training, global structural learning has been used to replace local learning on each decision (Zhang and Clark, 2008; Huang et al.,"
P11-2033,E06-1011,0,0.816632,"Missing"
P11-2033,P05-1012,0,0.9789,"the Chinese Treebank, they give a signficant improvement of the state of the art. An open source release of our parser is freely available. 1 Introduction Transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010) utilize a deterministic shift-reduce process for making structural predictions. Compared to graph-based dependency parsing, it typically offers linear time complexity and the comparative freedom to define non-local features, as exemplified by the comparison between MaltParser and MSTParser (Nivre et al., 2006b; McDonald et al., 2005; McDonald and Nivre, 2007). Recent research has addressed two potential disadvantages of systems like MaltParser. In the aspect of decoding, beam-search (Johansson and Nugues, 2007; Zhang and Clark, 2008; Huang et al., 2009) and partial dynamic-programming (Huang and Sagae, 2010) have been applied to improve upon 188 Joakim Nivre Uppsala University Department of Linguistics and Philology joakim.nivre@lingfil.uu.se greedy one-best search, and positive results were reported. In the aspect of training, global structural learning has been used to replace local learning on each decision (Zhang and"
P11-2033,P81-1022,0,0.736428,"Missing"
P11-2033,W06-2933,1,0.798448,"Missing"
P11-2033,D07-1111,0,0.0803254,"ature set by combining it with the word and POS-tag of S0 and N0 , as shown in Table 2. It is worth noticing that the use of distance information in our transition-based model is different from that in a typical graph-based parser such as MSTParser. The distance between S0 and N0 will correspond to the distance between a pair of head and modifier when an LeftArc action is taken, for example, but not when a Shift action is taken. Valency of S0 and N0 The number of modifiers to a given head is used by the graph-based submodel of Zhang and Clark (2008) and the models of Martins et al. (2009) and Sagae and Tsujii (2007). We include similar information in our model. In particular, we calculate the number of left and right modifiers separately, calling them left valency and right valency, respectively. Left and right valencies are represented by vl and vr in Table 2, respectively. They are combined with the word and POS-tag of S0 and N0 to form new feature templates. Again, the use of valency information in our transition-based parser is different from the aforementioned graph-based models. In our case, valency information is put into the context of the shift-reduce process, and used together with each action"
P11-2033,D08-1016,0,0.00728383,"ect of training, global structural learning has been used to replace local learning on each decision (Zhang and Clark, 2008; Huang et al., 2009), although the effect of global learning has not been separated out and studied alone. In this short paper, we study a third aspect in a statistical system: feature definition. Representing the type of information a statistical system uses to make predictions, feature templates can be one of the most important factors determining parsing accuracy. Various recent attempts have been made to include non-local features into graph-based dependency parsing (Smith and Eisner, 2008; Martins et al., 2009; Koo and Collins, 2010). Transitionbased parsing, by contrast, can easily accommodate arbitrarily complex representations involving nonlocal features. Complex non-local features, such as bracket matching and rhythmic patterns, are used in transition-based constituency parsing (Zhang and Clark, 2009; Wang et al., 2006), and most transitionbased dependency parsers incorporate some nonlocal features, but current practice is nevertheless to use a rather restricted set of features, as exemplified by the default feature models in MaltParser (Nivre et al., 2006a). We explore co"
P11-2033,W07-2218,0,0.236678,"pops the top item off the stack, and adds it as a modifier to the front of the queue; • RightArc, which removes the front of the queue, pushes it onto the stack and adds it as a modifier to the top of the stack. Further, we follow Zhang and Clark (2008) and Huang et al. (2009) and use the generalized perceptron (Collins, 2002) for global learning and beamsearch for decoding. Unlike both earlier globallearning parsers, which only perform unlabeled parsing, we perform labeled parsing by augmenting the LeftArc and RightArc actions with the set of dependency labels. Hence our work is in line with Titov and Henderson (2007) in using labeled transitions with global learning. Moreover, we will see that label information can actually improve link accuracy. 3 Feature Templates At each step during a parsing process, the parser configuration can be represented by a tuple hS, N, Ai, where S is the stack, N is the queue of incoming words, and A is the set of dependency arcs that have been built. Denoting the top of stack 1 It is very likely that the type of features explored in this paper would be beneficial also for the arc-standard system, although the exact same feature templates would not be applicable because of di"
P11-2033,W06-0121,0,0.0414168,"Missing"
P11-2033,W03-3023,0,0.942541,"ociation for Computational Linguistics:shortpapers, pages 188–193, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 The Transition-based Parsing Algorithm In a typical transition-based parsing process, the input words are put into a queue and partially built structures are organized by a stack. A set of shiftreduce actions are defined, which consume words from the queue and build the output parse. Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003; Huang and Sagae, 2010) process. We adopt the arc-eager system1 , for which the actions are: • Shift, which removes the front of the queue and pushes it onto the top of the stack; • Reduce, which pops the top item off the stack; • LeftArc, which pops the top item off the stack, and adds it as a modifier to the front of the queue; • RightArc, which removes the front of the queue, pushes it onto the stack and adds it as a modifier to the top of the stack. Further, we follow Zhang and Clark (2008) and Huang et al. (2009) and use the generalized perceptron (Collins, 2002) for global learning and"
P11-2033,D08-1059,1,0.926236,"gs of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 188–193, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics 2 The Transition-based Parsing Algorithm In a typical transition-based parsing process, the input words are put into a queue and partially built structures are organized by a stack. A set of shiftreduce actions are defined, which consume words from the queue and build the output parse. Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003; Huang and Sagae, 2010) process. We adopt the arc-eager system1 , for which the actions are: • Shift, which removes the front of the queue and pushes it onto the top of the stack; • Reduce, which pops the top item off the stack; • LeftArc, which pops the top item off the stack, and adds it as a modifier to the front of the queue; • RightArc, which removes the front of the queue, pushes it onto the stack and adds it as a modifier to the top of the stack. Further, we follow Zhang and Clark (2008) and Huang et al. (2009) and use the generalized percept"
P11-2033,W09-3825,1,0.743729,"Missing"
P11-2033,nivre-etal-2006-maltparser,1,\N,Missing
P11-2033,N10-1115,0,\N,Missing
P11-2033,L10-1000,0,\N,Missing
P11-2123,P08-1037,1,0.85019,"s been an interesting research avenue since the early days of NLP, and several research works have tried to test the intuition that semantics should help parsing, as can be exemplified by the classical PP attachment experiments (Ratnaparkhi, 1994). Although there have been some significant results (see Section 2), this issue continues to be elusive. In principle, dependency parsing offers good prospects for experimenting with word-to-word-semantic relationships. We present a set of experiments using semantic classes in dependency parsing of the Penn Treebank (PTB). We extend the tests made in Agirre et al. (2008), who used different types of semantic information, obtaining significant improvements in two constituency parsers, showing how semantic information helps in constituency parsing. As our baseline parser, we use MaltParser (Nivre, 2006). We will evaluate the parser on both the full PTB (Marcus et al. 1993) and on a senseRelated Work Agirre et al. (2008) trained two state-of-the-art statistical parsers (Charniak, 2000; Bikel, 2004) on semantically-enriched input, where content words had been substituted with their semantic classes. This was done trying to overcome the limitations of lexicalized"
P11-2123,W10-1409,0,0.0250465,"Missing"
P11-2123,W07-2217,0,0.225938,"Missing"
P11-2123,P96-1025,0,0.0264451,"information, obtaining significant improvements in two constituency parsers, showing how semantic information helps in constituency parsing. As our baseline parser, we use MaltParser (Nivre, 2006). We will evaluate the parser on both the full PTB (Marcus et al. 1993) and on a senseRelated Work Agirre et al. (2008) trained two state-of-the-art statistical parsers (Charniak, 2000; Bikel, 2004) on semantically-enriched input, where content words had been substituted with their semantic classes. This was done trying to overcome the limitations of lexicalized approaches to parsing (Magerman, 1995; Collins, 1996; Charniak, 1997; Collins, 2003), where related words, like scissors and knife cannot be generalized. This simple method allowed incorporating lexical semantic information into the parser. They tested the parsers in both a full parsing and a PP attachment context. The experiments showed that semantic classes gave significant improvement relative to the baseline, demonstrating that a simplistic approach to incorporating lexical semantics into a parser significantly improves its performance. This work presented the first results over both WordNet and the Penn Treebank to show that semantic proce"
P11-2123,W00-1320,0,0.189552,"lins, 2003), where related words, like scissors and knife cannot be generalized. This simple method allowed incorporating lexical semantic information into the parser. They tested the parsers in both a full parsing and a PP attachment context. The experiments showed that semantic classes gave significant improvement relative to the baseline, demonstrating that a simplistic approach to incorporating lexical semantics into a parser significantly improves its performance. This work presented the first results over both WordNet and the Penn Treebank to show that semantic processing helps parsing. Collins (2000) tested a combined parsing/word sense disambiguation model based in WordNet which did not obtain improvements in parsing. Koo et al. (2008) presented a semisupervised method for training dependency parsers, using word clusters derived from a large unannotated corpus as features. They demonstrate the effectiveness of the approach in a series of dependency parsing experiments on PTB and the Prague Dependency Treebank, showing that the cluster-based features yield substantial gains in performance across a wide range of conditions. Suzuki et al. (2009) also experiment with the same method combined"
P11-2123,J03-4003,0,0.00944448,"ant improvements in two constituency parsers, showing how semantic information helps in constituency parsing. As our baseline parser, we use MaltParser (Nivre, 2006). We will evaluate the parser on both the full PTB (Marcus et al. 1993) and on a senseRelated Work Agirre et al. (2008) trained two state-of-the-art statistical parsers (Charniak, 2000; Bikel, 2004) on semantically-enriched input, where content words had been substituted with their semantic classes. This was done trying to overcome the limitations of lexicalized approaches to parsing (Magerman, 1995; Collins, 1996; Charniak, 1997; Collins, 2003), where related words, like scissors and knife cannot be generalized. This simple method allowed incorporating lexical semantic information into the parser. They tested the parsers in both a full parsing and a PP attachment context. The experiments showed that semantic classes gave significant improvement relative to the baseline, demonstrating that a simplistic approach to incorporating lexical semantics into a parser significantly improves its performance. This work presented the first results over both WordNet and the Penn Treebank to show that semantic processing helps parsing. Collins (20"
P11-2123,W07-1204,0,0.339922,"Missing"
P11-2123,W07-2416,0,0.0408988,"Missing"
P11-2123,1997.iwpt-1.15,0,0.307704,"Missing"
P11-2123,P08-1068,0,0.047626,"ic information into the parser. They tested the parsers in both a full parsing and a PP attachment context. The experiments showed that semantic classes gave significant improvement relative to the baseline, demonstrating that a simplistic approach to incorporating lexical semantics into a parser significantly improves its performance. This work presented the first results over both WordNet and the Penn Treebank to show that semantic processing helps parsing. Collins (2000) tested a combined parsing/word sense disambiguation model based in WordNet which did not obtain improvements in parsing. Koo et al. (2008) presented a semisupervised method for training dependency parsers, using word clusters derived from a large unannotated corpus as features. They demonstrate the effectiveness of the approach in a series of dependency parsing experiments on PTB and the Prague Dependency Treebank, showing that the cluster-based features yield substantial gains in performance across a wide range of conditions. Suzuki et al. (2009) also experiment with the same method combined with semi-supervised learning. 699 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pa"
P11-2123,P95-1037,0,0.0201255,"pes of semantic information, obtaining significant improvements in two constituency parsers, showing how semantic information helps in constituency parsing. As our baseline parser, we use MaltParser (Nivre, 2006). We will evaluate the parser on both the full PTB (Marcus et al. 1993) and on a senseRelated Work Agirre et al. (2008) trained two state-of-the-art statistical parsers (Charniak, 2000; Bikel, 2004) on semantically-enriched input, where content words had been substituted with their semantic classes. This was done trying to overcome the limitations of lexicalized approaches to parsing (Magerman, 1995; Collins, 1996; Charniak, 1997; Collins, 2003), where related words, like scissors and knife cannot be generalized. This simple method allowed incorporating lexical semantic information into the parser. They tested the parsers in both a full parsing and a PP attachment context. The experiments showed that semantic classes gave significant improvement relative to the baseline, demonstrating that a simplistic approach to incorporating lexical semantics into a parser significantly improves its performance. This work presented the first results over both WordNet and the Penn Treebank to show that"
P11-2123,J93-2004,0,0.038773,"tion 2), this issue continues to be elusive. In principle, dependency parsing offers good prospects for experimenting with word-to-word-semantic relationships. We present a set of experiments using semantic classes in dependency parsing of the Penn Treebank (PTB). We extend the tests made in Agirre et al. (2008), who used different types of semantic information, obtaining significant improvements in two constituency parsers, showing how semantic information helps in constituency parsing. As our baseline parser, we use MaltParser (Nivre, 2006). We will evaluate the parser on both the full PTB (Marcus et al. 1993) and on a senseRelated Work Agirre et al. (2008) trained two state-of-the-art statistical parsers (Charniak, 2000; Bikel, 2004) on semantically-enriched input, where content words had been substituted with their semantic classes. This was done trying to overcome the limitations of lexicalized approaches to parsing (Magerman, 1995; Collins, 1996; Charniak, 1997; Collins, 2003), where related words, like scissors and knife cannot be generalized. This simple method allowed incorporating lexical semantic information into the parser. They tested the parsers in both a full parsing and a PP attachmen"
P11-2123,P04-1036,0,0.0166737,"(wordform+SF), WSF_N (wordform+SF for nouns) and WSF_V (for verbs). For a given semantic representation, we need some form of WSD to determine the semantics of each token occurrence of a target word. We experimented with three options: a) gold-standard (GOLD) annotations from SemCor, which gives the upper bound performance of the semantic representation, b) first Sense (1ST), where all token instances of a given word are tagged with their most frequent sense in WordNet, and c) automatic Sense Ranking (ASR) which uses the sense returned by an unsupervised system based on an independent corpus (McCarthy et al. 2004). For the full Penn Treebank experiments, we only had access to the first sense, taken from Wordnet 1.7. 4 Results In the following two subsections, we will first present the results in the SemCor/PTB intersection, with the option of using gold, 1st sense and automatic sense information (subsection 4.1) and the next subsection (4.2) will show the results on the full PTB, using 1st sense information. All results are shown as labelled attachment score (LAS). 4.1 Semcor/PTB (GOLD/1ST/ASR) We conducted a series of experiments testing: • Each individual semantic feature, which gives 9 possibilities"
P11-2123,H94-1048,0,0.0188251,"Missing"
P11-2123,I05-1007,0,0.183342,"Missing"
P11-2123,P11-2033,1,0.824536,"Missing"
P11-2123,A00-2018,0,\N,Missing
P11-2123,J04-4004,0,\N,Missing
P11-2123,P10-1001,0,\N,Missing
P11-2123,D09-1058,0,\N,Missing
P11-2123,D07-1096,1,\N,Missing
P12-2002,P06-1084,0,0.124895,"lattice structure, as illustrated in Figure 2. 1 We use the Hebrew transliteration in Sima’an et al. (2001). The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). 2 7 Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARS E VAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans hi, labe"
P12-2002,H91-1060,0,0.0520979,"(assuming gold segmented and tagged input) and realistic ones (not assuming gold segmentation and tags). Our evaluation of segmentation and parsing for Modern Hebrew sheds new light on the performance of the best parsing systems to date in the different scenarios. 1 Introduction A parser takes a sentence in natural language as input and returns a syntactic parse tree representing the sentence’s human-perceived interpretation. Current state-of-the-art parsers assume that the spacedelimited words in the input are the basic units of syntactic analysis. Standard evaluation procedures and metrics (Black et al., 1991; Buchholz and Marsi, 2006) accordingly assume that the yield of the parse tree is known in advance. This assumption breaks down when parsing morphologically rich languages (Tsarfaty et al., 2010), where every space-delimited word may be effectively composed of multiple morphemes, each of which having a distinct role in the syntactic parse tree. In order to parse such input the text needs to undergo morphological segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highl"
P12-2002,W06-2920,0,0.759533,"nted and tagged input) and realistic ones (not assuming gold segmentation and tags). Our evaluation of segmentation and parsing for Modern Hebrew sheds new light on the performance of the best parsing systems to date in the different scenarios. 1 Introduction A parser takes a sentence in natural language as input and returns a syntactic parse tree representing the sentence’s human-perceived interpretation. Current state-of-the-art parsers assume that the spacedelimited words in the input are the basic units of syntactic analysis. Standard evaluation procedures and metrics (Black et al., 1991; Buchholz and Marsi, 2006) accordingly assume that the yield of the parse tree is known in advance. This assumption breaks down when parsing morphologically rich languages (Tsarfaty et al., 2010), where every space-delimited word may be effectively composed of multiple morphemes, each of which having a distinct role in the syntactic parse tree. In order to parse such input the text needs to undergo morphological segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to"
P12-2002,D07-1022,0,0.66495,"at is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the different segmentation possibilities of the entire word sequence. One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). If the selected segmentation is different from the gold segmentation, the gold and parse trees are rendered incomparable and standard evaluation metrics break down. Evaluation scenarios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice"
P12-2002,W10-1412,0,0.163913,"s by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank (Sima’an et al., 2001) and its conversion into unlabeled dependencies (Goldberg, 2011a). We use PARS E VAL for evaluating phrase-structure trees, ATTACH S CORES for evaluating dependency trees, and T ED E VAL for evaluating all trees in all scenarios. We implement S EG E VAL for evaluating segmentation based on our T ED E VAL implementation, replacing the tree distance and size with str"
P12-2002,P11-2124,0,0.1301,"to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice structure. We demonstrate the informativeness of our metrics by evaluating joint segmentation and parsing performance for the Semitic language Modern Hebrew, using the best performing systems, both constituencybased and dependency-based (Tsarfaty, 2010; Goldberg, 2011a). Our experiments demonstrate that, for all parsers, significant performance gaps between realistic and non-realistic scenarios crucially depend on the kind of information initially provided to the parser. The tool and metrics that we provide are completely general and can straightforwardly apply to other languages, treebanks and different tasks. 6 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 6–10, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguistics (tree1) (tree2) TOP TOP PP PP IN 0 B1 “in” IN NP NP 0 B1"
P12-2002,C10-1045,0,0.706763,"h word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the different segmentation possibilities of the entire word sequence. One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). If the selected segmentation is different from the gold segmentation, the gold and parse trees are rendered incomparable and standard evaluation metrics break down. Evaluation scenarios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined in terms of a lattice structure. We demonstrate the informativeness of our me"
P12-2002,P05-1071,0,0.0219498,"teration in Sima’an et al. (2001). The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). 2 7 Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARS E VAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans hi, label, ji where i, j are terminal boundaries. Now, the NP dominating “shadow of"
P12-2002,P06-1055,0,0.0346381,"onalrealizational trees (RR). We parse all sentences in the dev set. RR extra decoration is removed prior to evaluation. Gold Predicted Raw Gold Predicted Raw MP MP MP EF EF EF S EG E VAL 100.00 100.00 95.07 100.00 100.00 95.07 ATT S CORES U: 83.59 U: 82.00 N/A U: 84.68 U: 83.97 N/A T ED E VAL U: 91.76 U: 91.20 U: 87.03 U: 92.25 U: 92:02 U: 87.75 Table 2: Dependency parsing results by MaltParser (MP) and EasyFirst (EF), trained on the treebank converted into unlabeled dependencies, and parsing the entire dev-set. For constituency-based parsing we use two models trained by the Berkeley parser (Petrov et al., 2006) one on phrase-structure (PS) trees and one on relational-realizational (RR) trees (Tsarfaty and Sima’an, 2008). In the raw scenario we let a latticebased parser choose its own segmentation and tags (Goldberg, 2011b). For dependency parsing we use MaltParser (Nivre et al., 2007b) optimized for Hebrew by Ballesteros and Nivre (2012), and the EasyFirst parser of Goldberg and Elhadad (2010) with the features therein. Since these parsers cannot choose their own tags, automatically predicted segments and tags are provided by Adler and Elhadad (2006). We use the standard split of the Hebrew treebank"
P12-2002,roark-etal-2006-sparseval,0,0.0433542,"rphological analysis of an input sentence x is then a lattice L obtained through the concatenation of the lattices L1 , . . . , Ln where MA(w1 ) = L1 , . . . , MA(wn ) = Ln . Now, let x = w1 , . . . , wn be a sentence with a morphological analysis lattice MA(x) = L. We define the output space YMA(x)=L for h (abbreviated YL ), as the set of linearly-ordered labeled trees such that the yield of LEX entries hs1 , p1 i,. . . ,hsk , pk i in each tree (where si ∈ T and pi ∈ N , and possibly k 6= n) corresponds to a path through the lattice L. 3 A tool that could potentially apply here is SParseval (Roark et al., 2006). But since it does not respect word-boundaries, it fails to apply to such lattices. Cohen and Smith (2007) aimed to fix this, but in their implementation syntactic nodes internal to word boundaries may be lost without scoring. 8 TED (p, g) |p |+ |g |− 2 The term |p |+ |g |− 2 is a normalization factor defined in terms of the worst-case scenario, in which the parser has only made incorrect decisions. We would need to delete all lexemes and nodes in p and add all the lexemes and nodes of g, except for roots. An Example Both trees in Figure 1 are contained in YL for the lattice L in Figure 2. If"
P12-2002,D07-1046,0,0.0803698,"lustrated in Figure 2. 1 We use the Hebrew transliteration in Sima’an et al. (2001). The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008). Examples for similar phenomena in Arabic may be found in Green and Manning (2010). 2 7 Figure 2: The morphological segmentation possibilities of BCLM HNEIM. Double-circles are word boundaries. In practice, a statistical component is required to decide on the correct morphological segmentation, that is, to pick out the correct path through the lattice. This may be done based on linear local context (Adler and Elhadad, 2006; Shacham and Wintner, 2007; Bar-haim et al., 2008; Habash and Rambow, 2005), or jointly with parsing (Tsarfaty, 2006; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). Either way, an incorrect morphological segmentation hypothesis introduces errors into the parse hypothesis, ultimately providing a parse tree which spans a different yield than the gold terminals. In such cases, existing evaluation metrics break down. To understand why, consider the trees in Figure 1. Metrics like PARS E VAL (Black et al., 1991) calculate the harmonic means of precision and recall on labeled spans hi, label, ji where i, j are termin"
P12-2002,C08-1112,1,0.882329,"Missing"
P12-2002,W10-1401,1,0.874484,"formance of the best parsing systems to date in the different scenarios. 1 Introduction A parser takes a sentence in natural language as input and returns a syntactic parse tree representing the sentence’s human-perceived interpretation. Current state-of-the-art parsers assume that the spacedelimited words in the input are the basic units of syntactic analysis. Standard evaluation procedures and metrics (Black et al., 1991; Buchholz and Marsi, 2006) accordingly assume that the yield of the parse tree is known in advance. This assumption breaks down when parsing morphologically rich languages (Tsarfaty et al., 2010), where every space-delimited word may be effectively composed of multiple morphemes, each of which having a distinct role in the syntactic parse tree. In order to parse such input the text needs to undergo morphological segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the diff"
P12-2002,D11-1036,1,0.867769,"ad of terminal boundaries (Tsarfaty, 2006) will fail here too, since the missing overt definite article H will cause similar misalignments. Metrics for dependencybased evaluation such as ATTACHMENT S CORES (Buchholz and Marsi, 2006) suffer from similar problems, since they assume that both trees have the same nodes — an assumption that breaks down in the case of incorrect morphological segmentation. Although great advances have been made in parsing MRLs in recent years, this evaluation challenge remained unsolved.3 In this paper we present a solution to this challenge by extending T ED E VAL (Tsarfaty et al., 2011) for handling trees over lattices. 3 The Proposal: Distance-Based Metrics Input and Output Spaces We view the joint task as a structured prediction function h : X → Y from input space X onto output space Y. Each element x ∈ X is a sequence x = w1 , . . . , wn of spacedelimited words from a set W. We assume a lexicon LEX , distinct from W, containing pairs of segments drawn from a set T of terminals and PoS categories drawn from a set N of nonterminals. Edit Scripts and Edit Costs We assume a set A={ADD(c, i, j),DEL(c, i, j),ADD(hs, pi, i, j), DEL (hs, pi, i, j)} of edit operations which can ad"
P12-2002,E12-1006,1,0.855597,"hat we train the parsers for predicted on a treebank containing predicted tags. There is however a great drop when moving from predicted to raw, which confirms that evaluation benchmarks on gold input as in Nivre et al. (2007a) do not provide a realistic indication of parser performance. For all tables, T ED E VAL results are on a similar scale. However, results are not yet comparable across parsers. RR trees are flatter than bare-bone PS trees. PS and DEP trees have different label sets. Cross-framework evaluation may be conducted by combining this metric with the cross-framework protocol of Tsarfaty et al. (2012). 5 Conclusion We presented distance-based metrics defined for trees over lattices and applied them to evaluating parsers on joint morphological and syntactic disambiguation. Our contribution is both technical, providing an evaluation tool that can be straightforwardly applied for parsing scenarios involving trees over lattices,4 and methodological, suggesting to evaluate parsers in all possible scenarios in order to get a realistic indication of parser performance. Acknowledgements We thank Shay Cohen, Yoav Goldberg and Spence Green for discussion of this challenge. This work was supported by"
P12-2002,P06-3009,1,0.918431,"segmentation, that is, identifying the morphological segments of each word and assigning the corresponding part-ofspeech (PoS) tags to them. Morphologically complex words may be highly ambiguous and in order to segment them correctly their analysis has to be disambiguated. The multiple morphological analyses of input words may be represented via a lattice that encodes the different segmentation possibilities of the entire word sequence. One can either select a segmentation path prior to parsing, or, as has been recently argued, one can let the parser pick a segmentation jointly with decoding (Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008; Green and Manning, 2010). If the selected segmentation is different from the gold segmentation, the gold and parse trees are rendered incomparable and standard evaluation metrics break down. Evaluation scenarios restricted to gold input are often used to bypass this problem, but, as shall be seen shortly, they present an overly optimistic upperbound on parser performance. This paper presents a full treatment of evaluation in different parsing scenarios, using distance-based measures defined for trees over a shared common denominator defined"
P12-2002,P08-1043,1,\N,Missing
P12-2002,D07-1096,1,\N,Missing
P12-2002,ballesteros-nivre-2012-maltoptimizer-system,1,\N,Missing
P13-1014,W06-2922,0,0.033519,"he increased availability of dependency treebanks and the perceived usefulness of dependency structures as an interface to downstream applications, but a very important reason is also the high efficiency offered by dependency parsers, enabling web-scale parsing with high throughput. The most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others. However, while these parsers are capable of processing tens of thousands of tokens per second with the right choice of classifiers, they are also known to perform slightly below the state-ofthe-art because of search errors and subsequent error propagation (McDonald and Nivre, 2007), and recent research on transition-based dependency parsing has therefore explored different ways of improving their accuracy. The most common approach is to use beam search instead of greedy decoding, in combination with a globally trained model that tries to minimize the loss over the entire sentence"
P13-1014,J13-1002,1,0.531399,"Missing"
P13-1014,D12-1133,1,0.832693,"cent research on transition-based dependency parsing has therefore explored different ways of improving their accuracy. The most common approach is to use beam search instead of greedy decoding, in combination with a globally trained model that tries to minimize the loss over the entire sentence instead of a locally trained classifier that tries to maximize the accuracy of single decisions (given no previous errors), as first proposed by Zhang and Clark (2008). With these methods, transition-based parsers have reached state-of-the-art accuracy for a number of languages (Zhang and Nivre, 2011; Bohnet and Nivre, 2012). However, the drawback with this approach is that parsing speed is proportional to the size of the beam, which means that the most accurate transition-based parsers are not nearly as fast as the original greedy transition-based parsers. Another line of research tries to retain the efficiency of greedy classifier-based parsing by instead improving the way in which classifiers are learned from data. While the classical approach limits training data to parser states that result from oracle predictions (derived from a treebank), these novel approaches allow the classifier to explore states that r"
P13-1014,P11-2121,0,0.0182271,"sing speed is proportional to the size of the beam, which means that the most accurate transition-based parsers are not nearly as fast as the original greedy transition-based parsers. Another line of research tries to retain the efficiency of greedy classifier-based parsing by instead improving the way in which classifiers are learned from data. While the classical approach limits training data to parser states that result from oracle predictions (derived from a treebank), these novel approaches allow the classifier to explore states that result from its own (sometimes erroneous) predictions (Choi and Palmer, 2011; Goldberg and Nivre, 2012). In this paper, we explore an orthogonal approach to improving the accuracy of transition-based parsers, without sacrificing their advantage in efficiency, by introducing a new type of transition system. While all previous transition systems assume a static parsing strategy with respect to top-down and bottom-up processing, our new system allows a dynamic strategy for ordering parsing decisions. This has the advantage that the parser can postpone difficult decisions until the relevant information becomes available, in a way that is not possible in existing transitio"
P13-1014,P02-1034,0,0.0237564,"e c with S HIFT p ← length of left spine of σ1 s ← length of right spine of σ2 T ← {lak |k ∈ [1, p]} ∪ {rak |k ∈ [1, s]} ∪ {sh} bestT ← argmaxt∈T score(t, c) bestCorrectT ← argmaxt∈T ∧isCorrect(t) score(t, c) if bestT 6= bestCorrectT then ω ~ ←ω ~ − φ(bestT , c) +φ(bestCorrectT , c) update c with bestCorrectT a feature vector representation for a transition t applying to a configuration c. The function φ will be discussed at length in §4.3. The vector ω ~ is trained using the perceptron algorithm in combination with the averaging method to avoid overfitting; see Freund and Schapire (1999) and Collins and Duffy (2002) for details. The training data set consists of pairs (w, Ag ), where w is a sentence and Ag is the set of arcs of the gold (desired) dependency tree for w. At training time, each pair (w, Ag ) is processed using the learning algorithm described as Algorithm 2. The algorithm is based on the notions of correct and incorrect transitions, discussed at length in §4.2. Algorithm 2 parses w following Algorithm 1 and using the current ω ~ , until the highest score selected transition bestT is incorrect according to Ag . When this happens, ω ~ is updated by decreasing the weights of the features assoc"
P13-1014,de-marneffe-etal-2006-generating,0,0.0118961,"Missing"
P13-1014,N10-1115,0,0.135202,"Missing"
P13-1014,C12-1059,1,0.875507,"nal to the size of the beam, which means that the most accurate transition-based parsers are not nearly as fast as the original greedy transition-based parsers. Another line of research tries to retain the efficiency of greedy classifier-based parsing by instead improving the way in which classifiers are learned from data. While the classical approach limits training data to parser states that result from oracle predictions (derived from a treebank), these novel approaches allow the classifier to explore states that result from its own (sometimes erroneous) predictions (Choi and Palmer, 2011; Goldberg and Nivre, 2012). In this paper, we explore an orthogonal approach to improving the accuracy of transition-based parsers, without sacrificing their advantage in efficiency, by introducing a new type of transition system. While all previous transition systems assume a static parsing strategy with respect to top-down and bottom-up processing, our new system allows a dynamic strategy for ordering parsing decisions. This has the advantage that the parser can postpone difficult decisions until the relevant information becomes available, in a way that is not possible in existing transition systems. A second advanta"
P13-1014,P10-2035,0,0.115835,"ally static) arc-standard strategy, when evaluated on English. The idea of representing the right spine of a tree within the stack elements of a shift-reduce device is quite old in parsing, predating empirical approaches. It has been mainly exploited to solve the PP-attachment problem, motivated by psycholinguistic models. The same representation is also adopted in applications of discourse parsing, where right spines are usually called right frontiers; see for instance Subba and Di Eugenio (2009). In the context of transition-based dependency parsers, right spines have also been exploited by Kitagawa and Tanaka-Ishii (2010) to decide where to attach the next word from the buffer. In this paper we have generalized their approach by introducing the symmetrical notion of left spine, and by allowing attachment of full trees rather than attachment of a single word.2 Since one can regard a spine as a stack in itself, whose elements are tree nodes, our model is reminiscent of the embedded pushdown automata of Schabes and Vijay-Shanker (1990), used to parse tree adjoining grammars (Joshi and Schabes, 1997) and exploiting a stack of stacks. However, by imposing projectivity, we do not use the extra-power of the latter cl"
P13-1014,J93-2004,0,0.043969,"Missing"
P13-1014,D07-1013,1,0.773892,"he most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others. However, while these parsers are capable of processing tens of thousands of tokens per second with the right choice of classifiers, they are also known to perform slightly below the state-ofthe-art because of search errors and subsequent error propagation (McDonald and Nivre, 2007), and recent research on transition-based dependency parsing has therefore explored different ways of improving their accuracy. The most common approach is to use beam search instead of greedy decoding, in combination with a globally trained model that tries to minimize the loss over the entire sentence instead of a locally trained classifier that tries to maximize the accuracy of single decisions (given no previous errors), as first proposed by Zhang and Clark (2008). With these methods, transition-based parsers have reached state-of-the-art accuracy for a number of languages (Zhang and Nivre"
P13-1014,W03-3017,1,0.815661,"ors, such as the increased availability of dependency treebanks and the perceived usefulness of dependency structures as an interface to downstream applications, but a very important reason is also the high efficiency offered by dependency parsers, enabling web-scale parsing with high throughput. The most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others. However, while these parsers are capable of processing tens of thousands of tokens per second with the right choice of classifiers, they are also known to perform slightly below the state-ofthe-art because of search errors and subsequent error propagation (McDonald and Nivre, 2007), and recent research on transition-based dependency parsing has therefore explored different ways of improving their accuracy. The most common approach is to use beam search instead of greedy decoding, in combination with a globally trained model that tries to minimize the loss over the"
P13-1014,W04-0308,1,0.921029,"only informally, for individual families of grammar formalisms. In the context of dependency parsing, a parsing strategy is called purely bottom-up if every dependency h → d is constructed only after all dependencies of the form d → i have been constructed. Here h → d denotes a dependency with h the head node and d the dependent node. In contrast, a parsing strategy is called purely top-down if h → d is constructed before any dependency of the form d → i. If we consider transition-based dependency parsing (Nivre, 2008), the purely bottom-up strategy is implemented by the arc-standard model of Nivre (2004). After building a dependency h → d, this model immediately removes from its stack node d, preventing further attachment of dependents to this node. A second popular parser, the arc-eager model of Nivre (2003), instead adopts a mixed strategy. In this model, a dependency h → d is constructed using a purely bottom-up strategy if it represents a left-arc, that is, if the dependent d is placed to the left of the head h in the input string. In contrast, if h → d represents a right-arc (defined symmetrically), then this dependency is constructed before any right-arc d → i (top-down) but after any l"
P13-1014,J08-4003,1,0.94824,"tegies do not have a general mathematical definition; they are instead specified, often only informally, for individual families of grammar formalisms. In the context of dependency parsing, a parsing strategy is called purely bottom-up if every dependency h → d is constructed only after all dependencies of the form d → i have been constructed. Here h → d denotes a dependency with h the head node and d the dependent node. In contrast, a parsing strategy is called purely top-down if h → d is constructed before any dependency of the form d → i. If we consider transition-based dependency parsing (Nivre, 2008), the purely bottom-up strategy is implemented by the arc-standard model of Nivre (2004). After building a dependency h → d, this model immediately removes from its stack node d, preventing further attachment of dependents to this node. A second popular parser, the arc-eager model of Nivre (2003), instead adopts a mixed strategy. In this model, a dependency h → d is constructed using a purely bottom-up strategy if it represents a left-arc, that is, if the dependent d is placed to the left of the head h in the input string. In contrast, if h → d represents a right-arc (defined symmetrically), t"
P13-1014,P90-1035,0,0.638239,"Missing"
P13-1014,N09-1064,0,0.0141892,"Missing"
P13-1014,W03-3023,0,0.0555796,"is probably due to many factors, such as the increased availability of dependency treebanks and the perceived usefulness of dependency structures as an interface to downstream applications, but a very important reason is also the high efficiency offered by dependency parsers, enabling web-scale parsing with high throughput. The most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others. However, while these parsers are capable of processing tens of thousands of tokens per second with the right choice of classifiers, they are also known to perform slightly below the state-ofthe-art because of search errors and subsequent error propagation (McDonald and Nivre, 2007), and recent research on transition-based dependency parsing has therefore explored different ways of improving their accuracy. The most common approach is to use beam search instead of greedy decoding, in combination with a globally trained model that tries to minimize the"
P13-1014,D08-1059,0,0.0727333,"they are also known to perform slightly below the state-ofthe-art because of search errors and subsequent error propagation (McDonald and Nivre, 2007), and recent research on transition-based dependency parsing has therefore explored different ways of improving their accuracy. The most common approach is to use beam search instead of greedy decoding, in combination with a globally trained model that tries to minimize the loss over the entire sentence instead of a locally trained classifier that tries to maximize the accuracy of single decisions (given no previous errors), as first proposed by Zhang and Clark (2008). With these methods, transition-based parsers have reached state-of-the-art accuracy for a number of languages (Zhang and Nivre, 2011; Bohnet and Nivre, 2012). However, the drawback with this approach is that parsing speed is proportional to the size of the beam, which means that the most accurate transition-based parsers are not nearly as fast as the original greedy transition-based parsers. Another line of research tries to retain the efficiency of greedy classifier-based parsing by instead improving the way in which classifiers are learned from data. While the classical approach limits tra"
P13-1014,P11-2033,1,0.518003,"nd Nivre, 2007), and recent research on transition-based dependency parsing has therefore explored different ways of improving their accuracy. The most common approach is to use beam search instead of greedy decoding, in combination with a globally trained model that tries to minimize the loss over the entire sentence instead of a locally trained classifier that tries to maximize the accuracy of single decisions (given no previous errors), as first proposed by Zhang and Clark (2008). With these methods, transition-based parsers have reached state-of-the-art accuracy for a number of languages (Zhang and Nivre, 2011; Bohnet and Nivre, 2012). However, the drawback with this approach is that parsing speed is proportional to the size of the beam, which means that the most accurate transition-based parsers are not nearly as fast as the original greedy transition-based parsers. Another line of research tries to retain the efficiency of greedy classifier-based parsing by instead improving the way in which classifiers are learned from data. While the classical approach limits training data to parser states that result from oracle predictions (derived from a treebank), these novel approaches allow the classifier"
P13-2017,W06-2920,0,0.808379,"ebank is made freely available in order to facilitate research on multilingual dependency parsing.1 1 Introduction In recent years, syntactic representations based on head-modifier dependency relations between words have attracted a lot of interest (K¨ubler et al., 2009). Research in dependency parsing – computational methods to predict such representations – has increased dramatically, due in large part to the availability of dependency treebanks in a number of languages. In particular, the CoNLL shared tasks on dependency parsing have provided over twenty data sets in a standardized format (Buchholz and Marsi, 2006; Nivre et al., 2007). While these data sets are standardized in terms of their formal representation, they are still heterogeneous treebanks. That is to say, despite them all being dependency treebanks, which annotate each sentence with a dependency tree, they subscribe to different annotation schemes. This can include superficial differences, such as the renaming of common relations, as well as true divergences concerning the analysis of linguistic constructions. Common divergences are found in the 1 Downloadable at https://code.google.com/p/uni-dep-tb/. 92 Proceedings of the 51st Annual Mee"
P13-2017,W02-1503,0,0.0535563,"Missing"
P13-2017,W09-2307,0,0.0712427,"Missing"
P13-2017,P11-1061,1,0.243183,"aking fine-grained label distinctions was discouraged. Once these guidelines were fixed, annotators selected roughly an equal amount of sentences to be annotated from each domain in the unlabeled data. As the sentences were already randomly selected from a larger corpus, annotators were told to view the sentences in order and to discard a sentence only if it was 1) fragmented because of a sentence splitting error; 2) not from the language of interest; 3) incomprehensible to a native speaker; or 4) shorter than three words. The selected sentences were pre-processed using cross-lingual taggers (Das and Petrov, 2011) and parsers (McDonald et al., 2011). The annotators modified the pre-parsed trees using the TrEd2 tool. At the beginning of the annotation process, double-blind annotation, followed by manual arbitration and consensus, was used iteratively for small batches of data until the guidelines were finalized. Most of the data was annotated using single-annotation and full review: one annotator annotating the data and another reviewing it, making changes in close collaboration with the original annotator. As a final step, all annotated data was semi-automatically checked for annotation consistency. 2."
P13-2017,W08-1301,0,0.173029,"Missing"
P13-2017,D11-1006,1,0.855635,"icient if one’s goal is to build monolingual parsers and evaluate their quality without reference to other languages, as in the original CoNLL shared tasks, but there are many cases where heterogenous treebanks are less than adequate. First, a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components. Second, consistent syntactic representations are desirable in the evaluation of unsupervised (Klein and Manning, 2004) or cross-lingual syntactic parsers (Hwa et al., 2005). In the cross-lingual study of McDonald et al. (2011), where delexicalized parsing models from a number of source languages were evaluated on a set of target languages, it was observed that the best target language was frequently not the closest typologically to the source. In one stunning example, Danish was the worst source language when parsing Swedish, solely due to greatly divergent annotation schemes. In order to overcome these difficulties, some cross-lingual studies have resorted to heuristics to homogenize treebanks (Hwa et al., 2005; Smith and Eisner, 2009; Ganchev et al., 2009), but we are only aware of a few systematic attempts to cr"
P13-2017,P07-1122,1,0.763455,"as head in copula constructions. For Swedish, we developed a set of deterministic rules for converting the Talbanken part of the Swedish Treebank (Nivre and Megyesi, 2007) to a representation as close as possible to the Stanford dependencies for English. This mainly consisted in relabeling dependency relations and, due to the fine-grained label set used in the Swedish Treebank (Teleman, 1974), this could be done with high precision. In addition, a small number of constructions required structural conversion, notably coordination, which in the Swedish Treebank is given a Prague style analysis (Nilsson et al., 2007). For both English and Swedish, we mapped the language-specific partof-speech tags to universal tags using the mappings of Petrov et al. (2012). Towards A Universal Treebank The Stanford typed dependencies for English (De Marneffe et al., 2006; de Marneffe and Manning, 2008) serve as the point of departure for our ‘universal’ dependency representation, together with the tag set of Petrov et al. (2012) as the underlying part-of-speech representation. The Stanford scheme, partly inspired by the LFG framework, has emerged as a de facto standard for dependency annotation in English and has recentl"
P13-2017,de-marneffe-etal-2006-generating,0,0.333356,"Missing"
P13-2017,P09-1042,1,0.250489,"arsers (Hwa et al., 2005). In the cross-lingual study of McDonald et al. (2011), where delexicalized parsing models from a number of source languages were evaluated on a set of target languages, it was observed that the best target language was frequently not the closest typologically to the source. In one stunning example, Danish was the worst source language when parsing Swedish, solely due to greatly divergent annotation schemes. In order to overcome these difficulties, some cross-lingual studies have resorted to heuristics to homogenize treebanks (Hwa et al., 2005; Smith and Eisner, 2009; Ganchev et al., 2009), but we are only aware of a few systematic attempts to create homogenous syntactic dependency annotation in multiple languages. In terms of automatic construction, Zeman et al. (2012) attempt to harmonize a large number of dependency treebanks by mapping their annotation to a version of the Prague Dependency Treebank scheme (Hajiˇc et al., 2001; B¨ohmov´a et al., 2003). Additionally, there have been efforts to manually or semimanually construct resources with common synWe present a new collection of treebanks with homogeneous syntactic dependency annotation for six languages: German, English,"
P13-2017,W12-1909,0,0.0247816,"Missing"
P13-2017,petrov-etal-2012-universal,1,0.702758,"nal Linguistics tactic analyses across multiple languages using alternate syntactic theories as the basis for the representation (Butt et al., 2002; Helmreich et al., 2004; Hovy et al., 2006; Erjavec, 2012). In order to facilitate research on multilingual syntactic analysis, we present a collection of data sets with uniformly analyzed sentences for six languages: German, English, French, Korean, Spanish and Swedish. This resource is freely available and we plan to extend it to include more data and languages. In the context of part-of-speech tagging, universal representations, such as that of Petrov et al. (2012), have already spurred numerous examples of improved empirical cross-lingual systems (Zhang et al., 2012; Gelling et al., 2012; T¨ackstr¨om et al., 2013). We aim to do the same for syntactic dependencies and present cross-lingual parsing experiments to highlight some of the benefits of cross-lingually consistent annotation. First, results largely conform to our expectations of which target languages should be useful for which source languages, unlike in the study of McDonald et al. (2011). Second, the evaluation scores in general are significantly higher than previous cross-lingual studies, su"
P13-2017,D09-1086,0,0.0317978,"ross-lingual syntactic parsers (Hwa et al., 2005). In the cross-lingual study of McDonald et al. (2011), where delexicalized parsing models from a number of source languages were evaluated on a set of target languages, it was observed that the best target language was frequently not the closest typologically to the source. In one stunning example, Danish was the worst source language when parsing Swedish, solely due to greatly divergent annotation schemes. In order to overcome these difficulties, some cross-lingual studies have resorted to heuristics to homogenize treebanks (Hwa et al., 2005; Smith and Eisner, 2009; Ganchev et al., 2009), but we are only aware of a few systematic attempts to create homogenous syntactic dependency annotation in multiple languages. In terms of automatic construction, Zeman et al. (2012) attempt to harmonize a large number of dependency treebanks by mapping their annotation to a version of the Prague Dependency Treebank scheme (Hajiˇc et al., 2001; B¨ohmov´a et al., 2003). Additionally, there have been efforts to manually or semimanually construct resources with common synWe present a new collection of treebanks with homogeneous syntactic dependency annotation for six lang"
P13-2017,Q13-1001,1,0.0665003,"Missing"
P13-2017,W04-2709,0,0.0429789,"annotation schemes. This can include superficial differences, such as the renaming of common relations, as well as true divergences concerning the analysis of linguistic constructions. Common divergences are found in the 1 Downloadable at https://code.google.com/p/uni-dep-tb/. 92 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 92–97, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics tactic analyses across multiple languages using alternate syntactic theories as the basis for the representation (Butt et al., 2002; Helmreich et al., 2004; Hovy et al., 2006; Erjavec, 2012). In order to facilitate research on multilingual syntactic analysis, we present a collection of data sets with uniformly analyzed sentences for six languages: German, English, French, Korean, Spanish and Swedish. This resource is freely available and we plan to extend it to include more data and languages. In the context of part-of-speech tagging, universal representations, such as that of Petrov et al. (2012), have already spurred numerous examples of improved empirical cross-lingual systems (Zhang et al., 2012; Gelling et al., 2012; T¨ackstr¨om et al., 201"
P13-2017,P13-2103,0,0.129897,"Missing"
P13-2017,N06-2015,0,0.0347787,"s can include superficial differences, such as the renaming of common relations, as well as true divergences concerning the analysis of linguistic constructions. Common divergences are found in the 1 Downloadable at https://code.google.com/p/uni-dep-tb/. 92 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 92–97, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics tactic analyses across multiple languages using alternate syntactic theories as the basis for the representation (Butt et al., 2002; Helmreich et al., 2004; Hovy et al., 2006; Erjavec, 2012). In order to facilitate research on multilingual syntactic analysis, we present a collection of data sets with uniformly analyzed sentences for six languages: German, English, French, Korean, Spanish and Swedish. This resource is freely available and we plan to extend it to include more data and languages. In the context of part-of-speech tagging, universal representations, such as that of Petrov et al. (2012), have already spurred numerous examples of improved empirical cross-lingual systems (Zhang et al., 2012; Gelling et al., 2012; T¨ackstr¨om et al., 2013). We aim to do th"
P13-2017,zeman-etal-2012-hamledt,0,0.060315,"Missing"
P13-2017,P03-1054,0,0.0144203,"nch data set is shown in Figure 1. We take two approaches to generating data. The first is traditional manual annotation, as previously used by Helmreich et al. (2004) for multilingual syntactic treebank construction. The second, used only for English and Swedish, is to automatically convert existing treebanks, as in Zeman et al. (2012). 2.1 Automatic Conversion Since the Stanford dependencies for English are taken as the starting point for our universal annotation scheme, we begin by describing the data sets produced by automatic conversion. For English, we used the Stanford parser (v1.6.8) (Klein and Manning, 2003) to convert the Wall Street Journal section of the Penn Treebank (Marcus et al., 1993) to basic dependency trees, including punctuation and with the copula verb as head in copula constructions. For Swedish, we developed a set of deterministic rules for converting the Talbanken part of the Swedish Treebank (Nivre and Megyesi, 2007) to a representation as close as possible to the Stanford dependencies for English. This mainly consisted in relabeling dependency relations and, due to the fine-grained label set used in the Swedish Treebank (Teleman, 1974), this could be done with high precision. In"
P13-2017,P11-2033,1,0.192695,"Missing"
P13-2017,P04-1061,0,0.0673447,"word expressions (Nilsson et al., 2007; K¨ubler et al., 2009; Zeman et al., 2012). These data sets can be sufficient if one’s goal is to build monolingual parsers and evaluate their quality without reference to other languages, as in the original CoNLL shared tasks, but there are many cases where heterogenous treebanks are less than adequate. First, a homogeneous representation is critical for multilingual language technologies that require consistent cross-lingual analysis for downstream components. Second, consistent syntactic representations are desirable in the evaluation of unsupervised (Klein and Manning, 2004) or cross-lingual syntactic parsers (Hwa et al., 2005). In the cross-lingual study of McDonald et al. (2011), where delexicalized parsing models from a number of source languages were evaluated on a set of target languages, it was observed that the best target language was frequently not the closest typologically to the source. In one stunning example, Danish was the worst source language when parsing Swedish, solely due to greatly divergent annotation schemes. In order to overcome these difficulties, some cross-lingual studies have resorted to heuristics to homogenize treebanks (Hwa et al., 2"
P13-2017,D12-1125,0,0.0145332,"for the representation (Butt et al., 2002; Helmreich et al., 2004; Hovy et al., 2006; Erjavec, 2012). In order to facilitate research on multilingual syntactic analysis, we present a collection of data sets with uniformly analyzed sentences for six languages: German, English, French, Korean, Spanish and Swedish. This resource is freely available and we plan to extend it to include more data and languages. In the context of part-of-speech tagging, universal representations, such as that of Petrov et al. (2012), have already spurred numerous examples of improved empirical cross-lingual systems (Zhang et al., 2012; Gelling et al., 2012; T¨ackstr¨om et al., 2013). We aim to do the same for syntactic dependencies and present cross-lingual parsing experiments to highlight some of the benefits of cross-lingually consistent annotation. First, results largely conform to our expectations of which target languages should be useful for which source languages, unlike in the study of McDonald et al. (2011). Second, the evaluation scores in general are significantly higher than previous cross-lingual studies, suggesting that most of these studies underestimate true accuracy. Finally, unlike all previous cross-ling"
P13-2017,J93-2004,0,\N,Missing
P13-2017,W08-1300,0,\N,Missing
P13-2017,D07-1096,1,\N,Missing
P13-4033,W09-2404,0,0.256094,"på (particular attentive on) + Simplified expression Table 2: Example translation snippets with comments Feature Baseline TTR OVIX QW QP All BLEU 0.243 0.243 0.243 0.242 0.243 0.235 OVIX 56.88 55.25 54.65 57.16 57.07 47.80 LIX 51.17 51.04 51.00 51.16 51.06 49.29 Table 1: Results for adding single lexical consistency features to Docent To evaluate our system we used the BLEU score (Papineni et al., 2002) together with a set of readability metrics, since readability is what we hoped to improve by adding consistency features. Here we used OVIX to confirm a direct impact on consistency, and LIX (Björnsson, 1968), which is a common readability measure for Swedish. Unfortunately we do not have access to simplified translated text, so we calculate the MT metrics against a standard reference, which means that simple texts will likely have worse scores than complicated texts closer to the reference translation. We tuned the standard features using Moses and MERT, and then added each lexical consistency feature with a small weight, using a grid search approach to find values with a small impact. The results are shown in Table 1. As can be seen, for individual features the translation quality was maintained"
P13-4033,D12-1026,0,0.0267005,"se and published on Github1 to make it easy for other researchers to use it in their own experiments. Motivation 2 Most of the research on statistical machine translation (SMT) that was conducted during the last 20 years treated every text as a “bag of sentences” and disregarded all relations between elements in different sentences. Systematic research into explicitly discourse-related problems has only begun very recently in the SMT community (Hardmeier, 2012) with work on topics such as pronominal anaphora (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), verb tense (Gong et al., 2012) and discourse connectives (Meyer et al., 2012). One of the problems that hamper the development of cross-sentence models for SMT is the fact that the assumption of sentence independence is at the heart of the dynamic programming (DP) beam search algorithm most commonly used for decoding in phrase-based SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-level phrase-based SMT decoding (Hardmeier et al., 2"
P13-4033,E12-3001,0,0.0603375,"the GNU General Public License and published on Github1 to make it easy for other researchers to use it in their own experiments. Motivation 2 Most of the research on statistical machine translation (SMT) that was conducted during the last 20 years treated every text as a “bag of sentences” and disregarded all relations between elements in different sentences. Systematic research into explicitly discourse-related problems has only begun very recently in the SMT community (Hardmeier, 2012) with work on topics such as pronominal anaphora (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), verb tense (Gong et al., 2012) and discourse connectives (Meyer et al., 2012). One of the problems that hamper the development of cross-sentence models for SMT is the fact that the assumption of sentence independence is at the heart of the dynamic programming (DP) beam search algorithm most commonly used for decoding in phrase-based SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-level phrase-based S"
P13-4033,2010.iwslt-papers.10,1,0.855274,"s. The code is released under the GNU General Public License and published on Github1 to make it easy for other researchers to use it in their own experiments. Motivation 2 Most of the research on statistical machine translation (SMT) that was conducted during the last 20 years treated every text as a “bag of sentences” and disregarded all relations between elements in different sentences. Systematic research into explicitly discourse-related problems has only begun very recently in the SMT community (Hardmeier, 2012) with work on topics such as pronominal anaphora (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), verb tense (Gong et al., 2012) and discourse connectives (Meyer et al., 2012). One of the problems that hamper the development of cross-sentence models for SMT is the fact that the assumption of sentence independence is at the heart of the dynamic programming (DP) beam search algorithm most commonly used for decoding in phrase-based SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-leve"
P13-4033,D12-1108,1,0.812834,"(Gong et al., 2012) and discourse connectives (Meyer et al., 2012). One of the problems that hamper the development of cross-sentence models for SMT is the fact that the assumption of sentence independence is at the heart of the dynamic programming (DP) beam search algorithm most commonly used for decoding in phrase-based SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-level phrase-based SMT decoding (Hardmeier et al., 2012). Our decoding algorithm is based on local search instead of dynamic programming and permits the integration of Document-Level Decoding with Local Search Our decoder is based on the phrase-based SMT model described by Koehn et al. (2003) and implemented, for example, in the popular Moses decoder (Koehn et al., 2007). Translation is performed by splitting the input sentence into a number of contiguous word sequences, called phrases, which are translated into the target language through a phrase dictionary lookup and optionally reordered. The choice between different translations of an ambiguous"
P13-4033,W11-2123,0,0.0578591,"e models that makes it possible to build a baseline system with a configuration comparable to that of a typical Moses baseline system. The published source code also includes prototype implementations of a few document-level models. These models should be considered work in progress and serve as a demonstration of the cross-sentence modelling capabilities of the decoder. They have not yet reached a state of maturity that would make them suitable for production use. The sentence-level models provided by Docent include the phrase table, n-gram language models implemented with the KenLM toolkit (Heafield, 2011), an unlexicalised distortion cost model with geometric decay (Koehn et al., 2003) and a word penalty cost. All of these features are designed to be compatible with the corresponding features in Moses. From among the typical set of baseline features in Moses, we have not implemented the lexicalised distortion model, but this model could easily be added if required. Docent uses the same binary file format for phrase tables as Moses, so the same training apparatus can be used. DP-based SMT decoders have a parameter called distortion limit that limits the difference in word order between the inpu"
P13-4033,D11-1125,0,0.0200806,"iscourselevel corpus annotations such as coreference links. 195 These annotations can then be accessed by the feature models. To allow for additional targetlanguage information such as morphological features of target words, Docent can handle simple word-level annotations that are encoded in the phrase table in the same way as target language factors in Moses. In order to optimise feature weights we have adapted the Moses tuning infrastructure to Docent. In this way we can take advantage of all its features, for instance using different optimisation algorithms such as MERT (Och, 2003) or PRO (Hopkins and May, 2011), and selective tuning of a subset of features. Since document features only give meaningful scores on the document level and not on the sentence level, we naturally perform optimisation on document level, which typically means that we need more data than for the optimisation of sentence-based decoding. The results we obtain are relatively stable and competitive with sentence-level optimisation of the same models (Stymne et al., 2013a). 4 Implementing Feature Models Efficiently While translating a document, the local search decoder attempts to make a great number of moves. For each move, a sco"
P13-4033,N03-1017,0,0.011021,"ystematic research into explicitly discourse-related problems has only begun very recently in the SMT community (Hardmeier, 2012) with work on topics such as pronominal anaphora (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), verb tense (Gong et al., 2012) and discourse connectives (Meyer et al., 2012). One of the problems that hamper the development of cross-sentence models for SMT is the fact that the assumption of sentence independence is at the heart of the dynamic programming (DP) beam search algorithm most commonly used for decoding in phrase-based SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-level phrase-based SMT decoding (Hardmeier et al., 2012). Our decoding algorithm is based on local search instead of dynamic programming and permits the integration of Document-Level Decoding with Local Search Our decoder is based on the phrase-based SMT model described by Koehn et al. (2003) and implemented, for example, in the popular Moses decoder (Koehn et al., 2007). Translation is"
P13-4033,P07-2045,0,0.0251314,"ed SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-level phrase-based SMT decoding (Hardmeier et al., 2012). Our decoding algorithm is based on local search instead of dynamic programming and permits the integration of Document-Level Decoding with Local Search Our decoder is based on the phrase-based SMT model described by Koehn et al. (2003) and implemented, for example, in the popular Moses decoder (Koehn et al., 2007). Translation is performed by splitting the input sentence into a number of contiguous word sequences, called phrases, which are translated into the target language through a phrase dictionary lookup and optionally reordered. The choice between different translations of an ambiguous source phrase and the ordering of the target phrases are guided by a scoring function that combines a set of scores taken from the phrase table with scores from other models such as an n-gram language model. The actual translation process is realised as a search for the highest-scoring translation in the space of a"
P13-4033,2007.tmi-papers.13,0,0.0462402,"ocument at every 1 https://github.com/chardmeier/docent/wiki 193 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 193–198, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics stage of the search progress. Search proceeds by making small changes to the current search state in order to transform it gradually into a better translation. This differs from the DP algorithm used in other decoders, which starts with an empty translation and expands it bit by bit. It is similar to previous work on phrase-based SMT decoding by Langlais et al. (2007), but enables the creation of document-level models, which was not addressed by earlier approaches. Docent currently implements two search algorithms that are different generalisations of the hill climbing local search algorithm by Hardmeier et al. (2012). The original hill climbing algorithm starts with an initial state and generates possible successor states by randomly applying simple elementary operations to the state. After each operation, the new state is scored and accepted if its score is better than that of the previous state, else rejected. Search terminates when the decoder cannot f"
P13-4033,W10-1737,0,0.254585,"Missing"
P13-4033,2012.amta-papers.20,0,0.0288297,"r other researchers to use it in their own experiments. Motivation 2 Most of the research on statistical machine translation (SMT) that was conducted during the last 20 years treated every text as a “bag of sentences” and disregarded all relations between elements in different sentences. Systematic research into explicitly discourse-related problems has only begun very recently in the SMT community (Hardmeier, 2012) with work on topics such as pronominal anaphora (Le Nagard and Koehn, 2010; Hardmeier and Federico, 2010; Guillou, 2012), verb tense (Gong et al., 2012) and discourse connectives (Meyer et al., 2012). One of the problems that hamper the development of cross-sentence models for SMT is the fact that the assumption of sentence independence is at the heart of the dynamic programming (DP) beam search algorithm most commonly used for decoding in phrase-based SMT systems (Koehn et al., 2003). For integrating cross-sentence features into the decoding process, researchers had to adopt strategies like two-pass decoding (Le Nagard and Koehn, 2010). We have previously proposed an algorithm for document-level phrase-based SMT decoding (Hardmeier et al., 2012). Our decoding algorithm is based on local"
P13-4033,W03-2117,0,0.0178285,"as originally proposed by Hardmeier et al. (2012) to improve lexical cohesion in a document. It is a cross-sentence model over sequences of content words that are scored based on their similarity in a word vector space. The readability models serve to improve the readability of the translation by encouraging the selection of easier and more consistent target words. They are described and demonstrated in more detail in section 5. Docent can read input files both in the NISTXML format commonly used to encode documents in MT shared tasks such as NIST or WMT and in the more elaborate MMAX format (Müller and Strube, 2003). The MMAX format makes it possible to include a wide range of discourselevel corpus annotations such as coreference links. 195 These annotations can then be accessed by the feature models. To allow for additional targetlanguage information such as morphological features of target words, Docent can handle simple word-level annotations that are encoded in the phrase table in the same way as target language factors in Moses. In order to optimise feature weights we have adapted the Moses tuning infrastructure to Docent. In this way we can take advantage of all its features, for instance using dif"
P13-4033,P03-1021,0,0.00654474,"e a wide range of discourselevel corpus annotations such as coreference links. 195 These annotations can then be accessed by the feature models. To allow for additional targetlanguage information such as morphological features of target words, Docent can handle simple word-level annotations that are encoded in the phrase table in the same way as target language factors in Moses. In order to optimise feature weights we have adapted the Moses tuning infrastructure to Docent. In this way we can take advantage of all its features, for instance using different optimisation algorithms such as MERT (Och, 2003) or PRO (Hopkins and May, 2011), and selective tuning of a subset of features. Since document features only give meaningful scores on the document level and not on the sentence level, we naturally perform optimisation on document level, which typically means that we need more data than for the optimisation of sentence-based decoding. The results we obtain are relatively stable and competitive with sentence-level optimisation of the same models (Stymne et al., 2013a). 4 Implementing Feature Models Efficiently While translating a document, the local search decoder attempts to make a great number"
P13-4033,P02-1040,0,0.105205,"ound to genitive construction − Changing long compound to English-based abbreviation − Removal of important word − Bad grammar because of changed part of speech and missing verb planen (the plan) särskilt uppmärksam på (particular attentive on) + Simplified expression Table 2: Example translation snippets with comments Feature Baseline TTR OVIX QW QP All BLEU 0.243 0.243 0.243 0.242 0.243 0.235 OVIX 56.88 55.25 54.65 57.16 57.07 47.80 LIX 51.17 51.04 51.00 51.16 51.06 49.29 Table 1: Results for adding single lexical consistency features to Docent To evaluate our system we used the BLEU score (Papineni et al., 2002) together with a set of readability metrics, since readability is what we hoped to improve by adding consistency features. Here we used OVIX to confirm a direct impact on consistency, and LIX (Björnsson, 1968), which is a common readability measure for Swedish. Unfortunately we do not have access to simplified translated text, so we calculate the MT metrics against a standard reference, which means that simple texts will likely have worse scores than complicated texts closer to the reference translation. We tuned the standard features using Moses and MERT, and then added each lexical consisten"
P13-4033,W13-3308,1,0.807594,"oes not require that another phrase be moved in the opposite direction at the same time. A pair of operations called permute-phrases and linearisephrases can reorder a sequence of phrases into random order and back into the order corresponding to the source language. Since the search algorithm in Docent is stochastic, repeated runs of the decoder will generally produce different output. However, the variance of the output is usually small, especially when initialising with a DP search pass, and it tends to be lower than the variance introduced by feature weight tuning (Hardmeier et al., 2012; Stymne et al., 2013a). 3 Available Feature Models In its current version, Docent implements a selection of sentence-local feature models that makes it possible to build a baseline system with a configuration comparable to that of a typical Moses baseline system. The published source code also includes prototype implementations of a few document-level models. These models should be considered work in progress and serve as a demonstration of the cross-sentence modelling capabilities of the decoder. They have not yet reached a state of maturity that would make them suitable for production use. The sentence-level mo"
P13-4033,W13-5634,1,0.909717,"oes not require that another phrase be moved in the opposite direction at the same time. A pair of operations called permute-phrases and linearisephrases can reorder a sequence of phrases into random order and back into the order corresponding to the source language. Since the search algorithm in Docent is stochastic, repeated runs of the decoder will generally produce different output. However, the variance of the output is usually small, especially when initialising with a DP search pass, and it tends to be lower than the variance introduced by feature weight tuning (Hardmeier et al., 2012; Stymne et al., 2013a). 3 Available Feature Models In its current version, Docent implements a selection of sentence-local feature models that makes it possible to build a baseline system with a configuration comparable to that of a typical Moses baseline system. The published source code also includes prototype implementations of a few document-level models. These models should be considered work in progress and serve as a demonstration of the cross-sentence modelling capabilities of the decoder. They have not yet reached a state of maturity that would make them suitable for production use. The sentence-level mo"
P13-4033,W10-2602,1,0.794735,"the readability of texts by encouraging simple and consistent terminology (Stymne et al., 2013b). This work is a first step towards achieving joint SMT and text simplification, with the final goal of adapting MT to user groups such as people with reading disabilities. Lexical consistency modelling for SMT has been attempted before. The suggested approaches have been limited by the use of sentence-level decoders, however, and had to resort to procedures like post processing (Carpuat, 2009), multiple decoding runs with frozen counts from previous runs (Ture et al., 2012), or cache-based models (Tiedemann, 2010). In Docent, however, we always have access to a full document translation, which makes it straightforward to include features directly into the decoder. We implemented four features on the document level. The first two features are type token ratio (TTR) and a reformulation of it, OVIX, which is less sensitive to text length. These ratios have been related to the “idea density” of a text (Mühlenbock and Kokkinakis, 2009). We also wanted to encourage consistent translations of words, for which we used the Q-value (Deléger et al., 2006), which has been proposed to measure term quality. We appli"
P13-4033,N12-1046,0,0.0590301,"can be used in Docent in order to improve the readability of texts by encouraging simple and consistent terminology (Stymne et al., 2013b). This work is a first step towards achieving joint SMT and text simplification, with the final goal of adapting MT to user groups such as people with reading disabilities. Lexical consistency modelling for SMT has been attempted before. The suggested approaches have been limited by the use of sentence-level decoders, however, and had to resort to procedures like post processing (Carpuat, 2009), multiple decoding runs with frozen counts from previous runs (Ture et al., 2012), or cache-based models (Tiedemann, 2010). In Docent, however, we always have access to a full document translation, which makes it straightforward to include features directly into the decoder. We implemented four features on the document level. The first two features are type token ratio (TTR) and a reformulation of it, OVIX, which is less sensitive to text length. These ratios have been related to the “idea density” of a text (Mühlenbock and Kokkinakis, 2009). We also wanted to encourage consistent translations of words, for which we used the Q-value (Deléger et al., 2006), which has been p"
P14-2106,P08-1068,0,0.258192,"nversion. 1 Introduction This work presents a set of experiments to investigate the use of lexical semantic information in dependency parsing of English. Whether semantics improve parsing is one interesting research topic both on parsing and lexical semantics. Broadly speaking, we can classify the methods to incorporate semantic information into parsers in two: systems using static lexical semantic repositories, such as WordNet or similar ontologies (Agirre et al., 2008; Agirre et al., 2011; Fujita et al., 2010), and systems using dynamic semantic clusters automatically acquired from corpora (Koo et al., 2008; Suzuki et al., 2009). Our main objective will be to determine whether static semantic knowledge can help parsing. We will apply different types of semantic information to three dependency parsers. Specifically, we will test the following questions: • Does semantic information in WordNet help dependency parsing? Agirre et al. (2011) found improvements in dependency parsing 2 Related work Broadly speaking, we can classify the attempts to add external knowledge to a parser in two sets: using large semantic repositories such as WordNet and approaches that use information automatically acquired f"
P14-2106,P08-1037,1,0.914971,"ombinations, showing that the semantically enhanced parsers yield a small significant gain only on the more semantically oriented LTH treebank conversion. 1 Introduction This work presents a set of experiments to investigate the use of lexical semantic information in dependency parsing of English. Whether semantics improve parsing is one interesting research topic both on parsing and lexical semantics. Broadly speaking, we can classify the methods to incorporate semantic information into parsers in two: systems using static lexical semantic repositories, such as WordNet or similar ontologies (Agirre et al., 2008; Agirre et al., 2011; Fujita et al., 2010), and systems using dynamic semantic clusters automatically acquired from corpora (Koo et al., 2008; Suzuki et al., 2009). Our main objective will be to determine whether static semantic knowledge can help parsing. We will apply different types of semantic information to three dependency parsers. Specifically, we will test the following questions: • Does semantic information in WordNet help dependency parsing? Agirre et al. (2011) found improvements in dependency parsing 2 Related work Broadly speaking, we can classify the attempts to add external kno"
P14-2106,S12-1031,0,0.0345955,"Missing"
P14-2106,P11-2123,1,0.834298,"r introducing related work in section 2, section 3 describes the treebank conversions, parsers and semantic features. Section 4 presents the results and section 5 draws the main conclusions. This paper presents experiments with WordNet semantic classes to improve dependency parsing. We study the effect of semantic classes in three dependency parsers, using two types of constituencyto-dependency conversions of the English Penn Treebank. Overall, we can say that the improvements are small and not significant using automatic POS tags, contrary to previously published results using gold POS tags (Agirre et al., 2011). In addition, we explore parser combinations, showing that the semantically enhanced parsers yield a small significant gain only on the more semantically oriented LTH treebank conversion. 1 Introduction This work presents a set of experiments to investigate the use of lexical semantic information in dependency parsing of English. Whether semantics improve parsing is one interesting research topic both on parsing and lexical semantics. Broadly speaking, we can classify the methods to incorporate semantic information into parsers in two: systems using static lexical semantic repositories, such"
P14-2106,P04-1036,0,0.0398379,"UMENT singleton synset, and also in the ARTIFACT SF along with thousands of words including cutter. These are the two extremes of semantic granularity in WordNet. For each semantic representation, we need to determine the semantics of each occurrence of a target word. Agirre et al. (2011) used i) gold-standard annotations from SemCor, a subset of the PTB, to give an upper bound performance of the semantic representation, ii) first sense, where all instances of a word were tagged with their most frequent sense, and iii) automatic sense ranking, predicting the most frequent sense for each word (McCarthy et al., 2004). As we will make use of the full PTB, we only have access to the first sense information. Clusters. Koo et al. (2008) describe a semi4 Results In all the experiments we employed a baseline feature set using word forms and parts of speech, and an enriched feature set (WordNet or clusters). We firstly tested the addition of each individual semantic feature to each parser, evaluating its contribution to the parser’s performance. For the combinations, instead of feature-engineering each parser with the wide array of different possibilities for features, as in Agirre et al. (2011), we adopted the"
P14-2106,J04-4004,0,0.106253,"Missing"
P14-2106,W10-1409,0,0.0387869,"Missing"
P14-2106,P05-1012,0,0.0747214,"output are lower than those for Penn2Malt conversions. 3.2 We have made use of three parsers representative of successful paradigms in dependency parsing. MaltParser (Nivre et al., 2007) is a deterministic transition-based dependency parser that obtains a dependency tree in linear-time in a single pass over the input using a stack of partially analyzed items and the remaining input sequence, by means of history-based feature models. We added two features that inspect the semantic feature at the top of the stack and the next input token. MST 3 represents global, exhaustive graphbased parsing (McDonald et al., 2005; McDonald et al., 2006) that finds the highest scoring directed spanning tree in a graph. The learning procedure is global since model parameters are set relative to classifying the entire dependency graph, in contrast to the local but richer contexts used by transition-based parsers. The system can be trained using first or second order models. The second order projective algorithm performed best on both conversions, and we used it in the rest of the evaluations. We modified the system in order to add semantic features, combining them with wordforms and POS tags, on the parent and child node"
P14-2106,W06-2932,0,0.0292674,"those for Penn2Malt conversions. 3.2 We have made use of three parsers representative of successful paradigms in dependency parsing. MaltParser (Nivre et al., 2007) is a deterministic transition-based dependency parser that obtains a dependency tree in linear-time in a single pass over the input using a stack of partially analyzed items and the remaining input sequence, by means of history-based feature models. We added two features that inspect the semantic feature at the top of the stack and the next input token. MST 3 represents global, exhaustive graphbased parsing (McDonald et al., 2005; McDonald et al., 2006) that finds the highest scoring directed spanning tree in a graph. The learning procedure is global since model parameters are set relative to classifying the entire dependency graph, in contrast to the local but richer contexts used by transition-based parsers. The system can be trained using first or second order models. The second order projective algorithm performed best on both conversions, and we used it in the rest of the evaluations. We modified the system in order to add semantic features, combining them with wordforms and POS tags, on the parent and child nodes of each arc. ZPar4 (Zh"
P14-2106,A00-2018,0,0.262203,"Missing"
P14-2106,W02-1001,0,0.126521,"Missing"
P14-2106,W09-3829,0,0.0385685,"Missing"
P14-2106,J03-4003,0,0.120933,"Missing"
P14-2106,N06-2033,0,0.0327289,"the best performing system was evaluated on the test set (section 23). 651 Parsers Best baseline (ZPar) Best single parser (ZPar + Clusters) Best combination (3 baseline parsers) Best combination of 3 parsers: 3 baselines + 3 SF extensions Best combination of 3 parsers: 3 baselines + 3 SS extensions Best combination of 3 parsers: 3 baselines + 3 cluster extensions LAS 91.52 91.74 (+0.22) 91.90 (+0.38) UAS 92.57 92.63 93.01 91.93 (+0.41) 92.95 91.87 (+0.35) 92.92 91.90 (+0.38) 92.90 4.2 Subsection 4.1 presented the results of the base algorithms and their extensions based on semantic features. Sagae and Lavie (2006) report improvements over the best single parser when combining three transition-based models and one graph-based model. The same technique was also used by the winning team of the CoNLL 2007 Shared Task (Hall et al., 2007), combining six transition-based parsers. We used MaltBlender5 , a tool for merging the output of several dependency parsers, using the Chu-Liu/Edmonds directed MST algorithm. After several tests we noticed that weighted voting by each parser’s labeled accuracy gave good results, using it in the rest of the experiments. We trained different types of combination: • Base algor"
P14-2106,D07-1097,1,0.82722,"F extensions Best combination of 3 parsers: 3 baselines + 3 SS extensions Best combination of 3 parsers: 3 baselines + 3 cluster extensions LAS 91.52 91.74 (+0.22) 91.90 (+0.38) UAS 92.57 92.63 93.01 91.93 (+0.41) 92.95 91.87 (+0.35) 92.92 91.90 (+0.38) 92.90 4.2 Subsection 4.1 presented the results of the base algorithms and their extensions based on semantic features. Sagae and Lavie (2006) report improvements over the best single parser when combining three transition-based models and one graph-based model. The same technique was also used by the winning team of the CoNLL 2007 Shared Task (Hall et al., 2007), combining six transition-based parsers. We used MaltBlender5 , a tool for merging the output of several dependency parsers, using the Chu-Liu/Edmonds directed MST algorithm. After several tests we noticed that weighted voting by each parser’s labeled accuracy gave good results, using it in the rest of the experiments. We trained different types of combination: • Base algorithms. This set includes the 3 baseline algorithms, MaltParser, MST, and ZPar. • Extended parsers, adding semantic information to the baselines. We include the three base algorithms and their semantic extensions (SF, SS, an"
P14-2106,N10-1091,0,0.0577312,"Missing"
P14-2106,W07-2416,0,0.0729244,"Missing"
P14-2106,D09-1058,0,0.0187841,"uction This work presents a set of experiments to investigate the use of lexical semantic information in dependency parsing of English. Whether semantics improve parsing is one interesting research topic both on parsing and lexical semantics. Broadly speaking, we can classify the methods to incorporate semantic information into parsers in two: systems using static lexical semantic repositories, such as WordNet or similar ontologies (Agirre et al., 2008; Agirre et al., 2011; Fujita et al., 2010), and systems using dynamic semantic clusters automatically acquired from corpora (Koo et al., 2008; Suzuki et al., 2009). Our main objective will be to determine whether static semantic knowledge can help parsing. We will apply different types of semantic information to three dependency parsers. Specifically, we will test the following questions: • Does semantic information in WordNet help dependency parsing? Agirre et al. (2011) found improvements in dependency parsing 2 Related work Broadly speaking, we can classify the attempts to add external knowledge to a parser in two sets: using large semantic repositories such as WordNet and approaches that use information automatically acquired from corpora. In the fi"
P14-2106,P10-1001,0,0.0300867,"Missing"
P14-2106,N12-1052,0,0.0566838,"Missing"
P14-2106,W03-3023,0,0.153063,"Missing"
P14-2106,D08-1059,1,0.816794,"6) that finds the highest scoring directed spanning tree in a graph. The learning procedure is global since model parameters are set relative to classifying the entire dependency graph, in contrast to the local but richer contexts used by transition-based parsers. The system can be trained using first or second order models. The second order projective algorithm performed best on both conversions, and we used it in the rest of the evaluations. We modified the system in order to add semantic features, combining them with wordforms and POS tags, on the parent and child nodes of each arc. ZPar4 (Zhang and Clark, 2008; Zhang and Nivre, 2011) performs transition-based dependency parsing with a stack of partial analysis and a queue of remaining inputs. In contrast to MaltParser (local model and greedy deterministic search) ZPar applies global discriminative learning and beam search. We extend the feature set of ZPar to include semantic features. Each set of semantic information is represented by two atomic Experimental Framework In this section we will briefly describe the PTBbased datasets (subsection 3.1), followed by the data-driven parsers used for the experiments (subsection 3.2). Finally, we will descr"
P14-2106,P11-2033,1,0.836904,"st scoring directed spanning tree in a graph. The learning procedure is global since model parameters are set relative to classifying the entire dependency graph, in contrast to the local but richer contexts used by transition-based parsers. The system can be trained using first or second order models. The second order projective algorithm performed best on both conversions, and we used it in the rest of the evaluations. We modified the system in order to add semantic features, combining them with wordforms and POS tags, on the parent and child nodes of each arc. ZPar4 (Zhang and Clark, 2008; Zhang and Nivre, 2011) performs transition-based dependency parsing with a stack of partial analysis and a queue of remaining inputs. In contrast to MaltParser (local model and greedy deterministic search) ZPar applies global discriminative learning and beam search. We extend the feature set of ZPar to include semantic features. Each set of semantic information is represented by two atomic Experimental Framework In this section we will briefly describe the PTBbased datasets (subsection 3.1), followed by the data-driven parsers used for the experiments (subsection 3.2). Finally, we will describe the different types"
P14-2106,P07-1122,1,\N,Missing
P14-2106,W07-1204,0,\N,Missing
P16-1016,P14-1070,1,0.339889,"itionally modified as in take a long nap. Such cases show that MWEs may be decomposable and partially analyzable, which implies the need for predicting their internal structure in order to compute their meaning. From a syntactic point of view, MWEs often have a regular structure and do not need special syntactic annotation. Some MWEs have an irregular structure, such as by and large which on the surface is a coordination of a preposition and an adjective. They are syntactically as well as semantically non-compositional and cannot be represented with standard syntactic structures, as stated in Candito and Constant (2014). Many of these irregular MWEs are complex grammatical words like because of, in spite of and in order to – fixed (grammatical) MWEs in the sense of Sag et al. (2002). In some treebanks, these are annotated using special structures and labels because they canWe present a transition-based system that jointly predicts the syntactic structure and lexical units of a sentence by building two structures over the input words: a syntactic dependency tree and a forest of lexical units including multiword expressions (MWEs). This combined representation allows us to capture both the syntactic and semant"
P16-1016,W13-4905,1,0.871842,"otated. Candito and Constant (2014) proposed a representation where the irregular and regular MWEs are distinguished: irregular MWEs are integrated in the syntactic tree as above; regular MWEs are anStatistical MWE-aware dependency parsing has received a growing interest since Nivre and Nilsson (2004). The main challenge resides in finding the best orchestration strategy. Past research has explored either pipeline or joint approaches. Pipeline strategies consist in positioning the MWE recognition either before or after the parser itself, as in Nivre and Nilsson (2004), Eryi˘git et al. (2011), Constant et al. (2013), and Kong et al. (2014) for pre-identification and as in Vincze et al. (2013a) for post-identification. Joint strategies have mainly consisted in using off-the-shelf 168 References parsers and integrating MWE annotation in the syntactic structure, so that MWE identification is blind for the parser (Nivre and Nilsson, 2004; Eryi˘git et al., 2011; Seddah et al., 2013; Vincze et al., 2013b; Candito and Constant, 2014; Nasr et al., 2015). Our system includes a special treatment of MWEs using specific transitions in a classical transition-based system, in line with the proposal of Nivre (2014). Co"
P16-1016,N16-1127,1,0.854995,"Missing"
P16-1016,C14-1052,0,0.0485001,"Missing"
P16-1016,W11-3806,0,0.166932,"Missing"
P16-1016,Q13-1033,1,0.817811,"ry ci (0 ≤ i &lt; m) there is some transition t ∈ T such that t(ci ) = ci+1 . Every transition sequence defines a representation for the input sentence. Training a transition-based parser means training the model for scoring transition sequences. This requires an oracle that determines what is an optimal transition sequence given an input sentence and the correct output representation (as given by treebank). Static oracles define a single unique transition sequence for each input-output pair. Dynamic oracles allow more than one optimal transition sequence and can also score nonoptimal sequences (Goldberg and Nivre, 2013). Once a scoring model has been trained, parsing is usually performed as best-first search under this model, using greedy search or beam search. 3.2 Joint Syntactic and Lexical Analysis To perform joint syntactic and lexical analysis we need to be able to build structure in two parallel dimensions: the syntactic dimension, represented by a dependency tree, and the lexical dimension, represented by a forest of (binary) trees. The two dimensions share the token-level representation, as well as the level of fixed MWEs, but the syntactic tree and the non-fixed MWEs are independent. We extend the p"
P16-1016,J13-4002,1,0.901911,"Missing"
P16-1016,W07-2416,0,0.020799,"014) derived from the SPMRL shared task version (Seddah et al., 2013). Fixed and non-fixed MWEs are distinguished, but are limited to contiguous ones only. The STREUSLE corpus (Schneider et al., 2014b) corresponds to a subpart of the English Web Treebank (EWT). It consists of reviews and is comprehensively annotated in contiguous and discontiguous MWEs. Fixed and non-fixed expressions are not distinguished though the distinction between non-compositional and collocational MWEs is made. This implies that the MergeF transition is not used on this dataset. Practically, we used the LTH converter (Johansson and Nugues, 2007) to obtain the dependency version of the EWT constituent version. We also used the predicted linguistic attributes used in Constant and Le Roux (2015) and in Constant et al. (2016). Both datasets include predicted POS tags, lemmas and morphology, as well as features computed from compound dictionary lookup. None of them is entirely satisfying with respect to our model, but they allow us to evaluate the feasibility of the approach. Statistics on the two datasets are provided in Table 1. Results are provided in Table 2 for French and in Table 3 for English. In order to evaluate the syntactic lay"
P16-1016,Q14-1016,0,0.310048,",556 10,987 FTB Dev 1,235 38,820 2,119 925 Test 2,541 75,216 4,043 1,992 Table 1: Dataset statistics. We also implemented pipeline systems where: (i) fixed MWEs are identified by applying only the Fixed system; (ii) elements of predicted MWEs are merged into single tokens; (iii) the retokenized text is parsed using the Baseline or Implicit systems trained on a dataset where fixed MWEs consist of single tokens. We carried out our experiments on two different datasets annotating both the syntactic structure and the MWEs: the French Treebank [FTB] (Abeill´e et al., 2003) and the STREUSLE corpus (Schneider et al., 2014b) combined with the English Web Treebank [EWT] (Bies et al., 2012). They are commonly used for evaluating the most recent MWE-aware dependency parsers and supervised MWE identification systems. Concerning the FTB, we used the dependency version developed in Candito and Constant (2014) derived from the SPMRL shared task version (Seddah et al., 2013). Fixed and non-fixed MWEs are distinguished, but are limited to contiguous ones only. The STREUSLE corpus (Schneider et al., 2014b) corresponds to a subpart of the English Web Treebank (EWT). It consists of reviews and is comprehensively annotated"
P16-1016,C14-1177,1,0.588641,"Missing"
P16-1016,schneider-etal-2014-comprehensive,0,0.0729657,",556 10,987 FTB Dev 1,235 38,820 2,119 925 Test 2,541 75,216 4,043 1,992 Table 1: Dataset statistics. We also implemented pipeline systems where: (i) fixed MWEs are identified by applying only the Fixed system; (ii) elements of predicted MWEs are merged into single tokens; (iii) the retokenized text is parsed using the Baseline or Implicit systems trained on a dataset where fixed MWEs consist of single tokens. We carried out our experiments on two different datasets annotating both the syntactic structure and the MWEs: the French Treebank [FTB] (Abeill´e et al., 2003) and the STREUSLE corpus (Schneider et al., 2014b) combined with the English Web Treebank [EWT] (Bies et al., 2012). They are commonly used for evaluating the most recent MWE-aware dependency parsers and supervised MWE identification systems. Concerning the FTB, we used the dependency version developed in Candito and Constant (2014) derived from the SPMRL shared task version (Seddah et al., 2013). Fixed and non-fixed MWEs are distinguished, but are limited to contiguous ones only. The STREUSLE corpus (Schneider et al., 2014b) corresponds to a subpart of the English Web Treebank (EWT). It consists of reviews and is comprehensively annotated"
P16-1016,P15-1108,0,0.468114,"n of new transitions. To the best of our knowledge, this system is the first transition-based parser that includes a specific mechanism for handling MWEs in two dimensions. Previous related research has usually proposed either pipeline approaches with MWE identification performed either before or after dependency parsing (Kong et al., 2014; Vincze et al., 2013a) or workaround joint solutions using off-the-shelf parsers trained on dependency treebanks where MWEs are annotated by specific subtrees (Nivre and Nilsson, 2004; Eryi˘git et al., 2011; Vincze et al., 2013b; Candito and Constant, 2014; Nasr et al., 2015). 2 In the new representation, each lexical unit – whether a single word or an MWE – is associated with a lexical node, which has linguistic attributes such as surface form, lemma, part-ofspeech tag and morphological features. With an obvious reuse of terminology from context-free grammar, lexical nodes corresponding to MWEs are said to be non-terminal, because they have other lexical nodes as children, while lexical nodes corresponding to single words are terminal (and do not have any children). Some lexical nodes are also syntactic nodes, that is, nodes of the syntactic dependency tree. Thes"
P16-1016,W04-0308,1,0.585364,"noting that, although our representation in general allows lexical nodes with arbitrary branching factor for flat MWEs, it is often convenient for parsing to assume that all trees are binary (Crabb´e, 2014). For the rest of the paper, we therefore assume that non-binary trees are always transformed into equivalent binary trees using either right or left binarization. Such transformations add intermediate temporary nodes that are only used for internal processing. 3 Arc-Standard Dependency Parsing Our starting point is the arc-standard transition system for dependency parsing first defined in Nivre (2004) and represented schematically in Figure 3. A configuration in this system consists of a triple c = (σ, β, A), where σ is a stack containing partially processed nodes, β is a buffer containing remaining input nodes, and A is a set of dependency arcs. The initialization function maps x = x1 , . . . , xn to cs (x) = ([ ], [1, . . . , n], { }), and the set Ct of terminal configurations contains any configuration of the form c = ([i], [ ], A). The dependency tree defined by such a terminal configuration is ({1, . . . , n}, A). There are three possible transitions: Transition-Based Model A transiti"
P16-1016,P13-2046,0,0.0657652,"wo stacks (instead of one). It is synchronized by using a single buffer, in order to handle the factorization of the two structures. It also includes different hard constraints on the system in order to reduce ambiguities artificially created by the addition of new transitions. To the best of our knowledge, this system is the first transition-based parser that includes a specific mechanism for handling MWEs in two dimensions. Previous related research has usually proposed either pipeline approaches with MWE identification performed either before or after dependency parsing (Kong et al., 2014; Vincze et al., 2013a) or workaround joint solutions using off-the-shelf parsers trained on dependency treebanks where MWEs are annotated by specific subtrees (Nivre and Nilsson, 2004; Eryi˘git et al., 2011; Vincze et al., 2013b; Candito and Constant, 2014; Nasr et al., 2015). 2 In the new representation, each lexical unit – whether a single word or an MWE – is associated with a lexical node, which has linguistic attributes such as surface form, lemma, part-ofspeech tag and morphological features. With an obvious reuse of terminology from context-free grammar, lexical nodes corresponding to MWEs are said to be no"
P16-1016,I13-1024,0,0.356417,"wo stacks (instead of one). It is synchronized by using a single buffer, in order to handle the factorization of the two structures. It also includes different hard constraints on the system in order to reduce ambiguities artificially created by the addition of new transitions. To the best of our knowledge, this system is the first transition-based parser that includes a specific mechanism for handling MWEs in two dimensions. Previous related research has usually proposed either pipeline approaches with MWE identification performed either before or after dependency parsing (Kong et al., 2014; Vincze et al., 2013a) or workaround joint solutions using off-the-shelf parsers trained on dependency treebanks where MWEs are annotated by specific subtrees (Nivre and Nilsson, 2004; Eryi˘git et al., 2011; Vincze et al., 2013b; Candito and Constant, 2014; Nasr et al., 2015). 2 In the new representation, each lexical unit – whether a single word or an MWE – is associated with a lexical node, which has linguistic attributes such as surface form, lemma, part-ofspeech tag and morphological features. With an obvious reuse of terminology from context-free grammar, lexical nodes corresponding to MWEs are said to be no"
P16-1016,W14-0804,0,0.150141,"ms of syntax, the Explicit system does not have any positive impact (on par or degraded scores), whereas the Implicit system allows us to obtain slightly better results on French and a significant improvement on English. The very good performances on English might be explained by the fact that it contains a non-negligeable set of discontiguous MWEs which complicates the prediction of explicit Complete transitions. When compared with weaker systems, we can see that the addition of the lexical layer helps improve the prediction of the syntactic layer, which confirms results on symbolic parsing (Wehrli, 2014). The syntactic layer does not seem to impact the lexical layer prediction: we observe comparable results. This might be due to the fact that syntax is helpful for long-distance discontiguity only, which does not appear in our datasets (the English dataset contains MWEs with small gaps). Another explanation could also be that syntactic parsing accuracy is rather low due to the use of a simple greedy algorithm. Developing more advanced transition-based parsing methods like beam-search may help improve both syntactic parsing accuracy and MWE identification. When comparing joint systems with pipe"
P16-1016,J08-4003,1,\N,Missing
P16-1016,L16-1262,1,\N,Missing
P18-2098,Q16-1031,0,0.0226612,"Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics the parser (see section 3.1). To the best of our knowledge this approach is novel when applied to the monolingual case as treebank embeddings. The most similar approach we have found in the literature is Lim and Poibeau (2017), who used one-hot treebank representations to combine data for improving monolingual parsing for three tiny treebanks, with improvements of 0.6–1.9 LAS. It is also related to work on domain embeddings for machine translation (Kobus et al., 2017), and language embeddings for parsing (Ammar et al., 2016). We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-write rules (Aufrant et al., 2016), or machine translation"
P18-2098,W17-6314,1,0.74758,"Missing"
P18-2098,C16-1012,0,0.069536,"ge embeddings for parsing (Ammar et al., 2016). We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-write rules (Aufrant et al., 2016), or machine translation (Tiedemann, 2015). Unlike much work on cross-lingual parsing, we do not focus on a low-resource scenario. dev data for most languages, results were mixed on the actual PUD test sets. For the two Norwegian language variants, concatenation has been proposed (Velldal et al., 2017), but it hurts results unless combined with machine translation. Training on concatenated treebanks can be improved by a subsequent fine-tuning step. In this set-up, after training the model on concatenated data, it is refined for each treebank by training only on its own training set for a few a"
P18-2098,K17-3006,0,0.0400169,"al. (2017) and Das et al. (2017) used this strategy to parse the PUD test sets in the 2017 CoNLL Shared Task. Little details are given on the results, but while it was successful on 619 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 619–625 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics the parser (see section 3.1). To the best of our knowledge this approach is novel when applied to the monolingual case as treebank embeddings. The most similar approach we have found in the literature is Lim and Poibeau (2017), who used one-hot treebank representations to combine data for improving monolingual parsing for three tiny treebanks, with improvements of 0.6–1.9 LAS. It is also related to work on domain embeddings for machine translation (Kobus et al., 2017), and language embeddings for parsing (Ammar et al., 2016). We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedem"
P18-2098,W18-0207,0,0.0121505,"representations to combine data for improving monolingual parsing for three tiny treebanks, with improvements of 0.6–1.9 LAS. It is also related to work on domain embeddings for machine translation (Kobus et al., 2017), and language embeddings for parsing (Ammar et al., 2016). We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-write rules (Aufrant et al., 2016), or machine translation (Tiedemann, 2015). Unlike much work on cross-lingual parsing, we do not focus on a low-resource scenario. dev data for most languages, results were mixed on the actual PUD test sets. For the two Norwegian language variants, concatenation has been proposed (Velldal et al., 2017), but it hurts results unless combined with machine translation. Training"
P18-2098,P09-1040,1,0.826754,"aster/udapi/block/ eval/conll17.py 620 3.1 The Parser based on LAS score on the dev set, using average dev scores when training on more than one treebank, and apply the model from this epoch to the test data. UUParser2 We use (de Lhoneux et al., 2017a), which is based on the transition-based parser of Kiperwasser and Goldberg (2016), and adapted to UD. It uses the arc-hybrid transition system from Kuhlmann et al. (2011) extended with a S WAP transition and a static-dynamic oracle, as described in de Lhoneux et al. (2017b). This model allows the construction of non-projective dependency trees (Nivre, 2009). A configuration c is represented by a feature function φ(·) over a subset of its elements and, for each configuration, transitions are scored by a classifier. In this case, the classifier is a multilayer perceptron (MLP) and φ(·) is a concatenation of the BiLSTM vectors vi of words on top of the stack and at the beginning of the buffer. The MLP scores transitions together with the arc labels for transitions that involve adding an arc. For an input sentence of length n with words w1 , . . . , wn , the parser creates a sequence of vectors x1:n , where the vector xi representing wi is the conca"
P18-2098,K17-3019,0,0.021669,"human annotators, whereas others are based entirely on automatic conversions. All this means that it is often far from trivial to combine multiple treebanks for the same language. 2 Training with Multiple Treebanks The most obvious way to combine treebanks for a particular language, provided that they use the same annotation scheme, is simply to concatenate the training sets. This has the advantage that it does not require any modifications to the parser itself, and it produces a single model that can be directly used for any input from the language in question. Bj¨orkelund et al. (2017) and Das et al. (2017) used this strategy to parse the PUD test sets in the 2017 CoNLL Shared Task. Little details are given on the results, but while it was successful on 619 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 619–625 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics the parser (see section 3.1). To the best of our knowledge this approach is novel when applied to the monolingual case as treebank embeddings. The most similar approach we have found in the literature is Lim and Poibeau (2017), who used"
P18-2098,K17-3001,1,0.721773,"checked by human annotators, whereas others are based entirely on automatic conversions. All this means that it is often far from trivial to combine multiple treebanks for the same language. 2 Training with Multiple Treebanks The most obvious way to combine treebanks for a particular language, provided that they use the same annotation scheme, is simply to concatenate the training sets. This has the advantage that it does not require any modifications to the parser itself, and it produces a single model that can be directly used for any input from the language in question. Bj¨orkelund et al. (2017) and Das et al. (2017) used this strategy to parse the PUD test sets in the 2017 CoNLL Shared Task. Little details are given on the results, but while it was successful on 619 Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 619–625 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics the parser (see section 3.1). To the best of our knowledge this approach is novel when applied to the monolingual case as treebank embeddings. The most similar approach we have found in the literature is Lim and Poi"
P18-2098,Q16-1023,0,0.0626433,"efit of using treebank embeddings is that we can train a single model for each language using all available data while remaining sensitive to the differences between treebanks. The addition of treebank embeddings requires only minor modifications to 1 https://github.com/udapi/ udapi-python/blob/master/udapi/block/ eval/conll17.py 620 3.1 The Parser based on LAS score on the dev set, using average dev scores when training on more than one treebank, and apply the model from this epoch to the test data. UUParser2 We use (de Lhoneux et al., 2017a), which is based on the transition-based parser of Kiperwasser and Goldberg (2016), and adapted to UD. It uses the arc-hybrid transition system from Kuhlmann et al. (2011) extended with a S WAP transition and a static-dynamic oracle, as described in de Lhoneux et al. (2017b). This model allows the construction of non-projective dependency trees (Nivre, 2009). A configuration c is represented by a feature function φ(·) over a subset of its elements and, for each configuration, transitions are scored by a classifier. In this case, the classifier is a multilayer perceptron (MLP) and φ(·) is a concatenation of the BiLSTM vectors vi of words on top of the stack and at the beginn"
P18-2098,kobus-etal-2017-domain,0,0.0152307,"Computational Linguistics (Short Papers), pages 619–625 c Melbourne, Australia, July 15 - 20, 2018. 2018 Association for Computational Linguistics the parser (see section 3.1). To the best of our knowledge this approach is novel when applied to the monolingual case as treebank embeddings. The most similar approach we have found in the literature is Lim and Poibeau (2017), who used one-hot treebank representations to combine data for improving monolingual parsing for three tiny treebanks, with improvements of 0.6–1.9 LAS. It is also related to work on domain embeddings for machine translation (Kobus et al., 2017), and language embeddings for parsing (Ammar et al., 2016). We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-w"
P18-2098,P11-1068,0,0.16891,"Missing"
P18-2098,N16-1161,0,0.0187953,"the literature is Lim and Poibeau (2017), who used one-hot treebank representations to combine data for improving monolingual parsing for three tiny treebanks, with improvements of 0.6–1.9 LAS. It is also related to work on domain embeddings for machine translation (Kobus et al., 2017), and language embeddings for parsing (Ammar et al., 2016). We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-write rules (Aufrant et al., 2016), or machine translation (Tiedemann, 2015). Unlike much work on cross-lingual parsing, we do not focus on a low-resource scenario. dev data for most languages, results were mixed on the actual PUD test sets. For the two Norwegian language variants, concatenation has been proposed (Velldal et al., 201"
P18-2098,W17-0201,0,0.0232521,"vetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-write rules (Aufrant et al., 2016), or machine translation (Tiedemann, 2015). Unlike much work on cross-lingual parsing, we do not focus on a low-resource scenario. dev data for most languages, results were mixed on the actual PUD test sets. For the two Norwegian language variants, concatenation has been proposed (Velldal et al., 2017), but it hurts results unless combined with machine translation. Training on concatenated treebanks can be improved by a subsequent fine-tuning step. In this set-up, after training the model on concatenated data, it is refined for each treebank by training only on its own training set for a few additional epochs. This enables the models to learn differences between treebanks, but it requires more training, and results in separate models for each treebank. When the parser is applied to new data, there is thus a choice of which fine-tuned version to use. This approach was used by Che et al. (201"
P18-2098,E17-2102,0,0.0172275,"and Poibeau (2017), who used one-hot treebank representations to combine data for improving monolingual parsing for three tiny treebanks, with improvements of 0.6–1.9 LAS. It is also related to work on domain embeddings for machine translation (Kobus et al., 2017), and language embeddings for parsing (Ammar et al., 2016). We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-write rules (Aufrant et al., 2016), or machine translation (Tiedemann, 2015). Unlike much work on cross-lingual parsing, we do not focus on a low-resource scenario. dev data for most languages, results were mixed on the actual PUD test sets. For the two Norwegian language variants, concatenation has been proposed (Velldal et al., 2017), but it hurts results unles"
P18-2098,K17-3007,0,0.326154,"s thus a choice of which fine-tuned version to use. This approach was used by Che et al. (2017) and Shi et al. (2017) for languages with multiple treebanks in the CoNLL 2017 Shared Task. Che et al. (2017) apply fine-tuning to all but the largest treebank for each language, and show average gains of 1.8 LAS for a subset of nine treebanks. Shi et al. (2017) show that the choice of treebank for parsing the PUD test set is important, but do not have any specific evaluation of the effect of fine-tuning. Another approach, not explored in this paper, is shared gated adversarial networks, proposed by Sato et al. (2017) for the CoNLL 2017 Shared Task. They use treebank prediction as an adversarial task. In this model, treebank-specific BiLSTMs are constructed for all treebanks in addition to a shared BiLSTM which is used both for parsing and for the adversarial task. This method requires knowing at test time which treebank the input belongs to. Sato et al. (2017) show that this strategy can give substantial improvements, especially for small treebanks. For large treebanks, however, there are mostly no or only minor improvements. 3 Experimental Setup We perform experiments for 24 treebanks from 9 languages, u"
P18-2098,K17-3003,0,0.0583157,"t hurts results unless combined with machine translation. Training on concatenated treebanks can be improved by a subsequent fine-tuning step. In this set-up, after training the model on concatenated data, it is refined for each treebank by training only on its own training set for a few additional epochs. This enables the models to learn differences between treebanks, but it requires more training, and results in separate models for each treebank. When the parser is applied to new data, there is thus a choice of which fine-tuned version to use. This approach was used by Che et al. (2017) and Shi et al. (2017) for languages with multiple treebanks in the CoNLL 2017 Shared Task. Che et al. (2017) apply fine-tuning to all but the largest treebank for each language, and show average gains of 1.8 LAS for a subset of nine treebanks. Shi et al. (2017) show that the choice of treebank for parsing the PUD test set is important, but do not have any specific evaluation of the effect of fine-tuning. Another approach, not explored in this paper, is shared gated adversarial networks, proposed by Sato et al. (2017) for the CoNLL 2017 Shared Task. They use treebank prediction as an adversarial task. In this model"
P18-2098,W15-2137,0,0.0788772,"We previously used a similar architecture for combining languages with very small training sets with additional languages (de Lhoneux et al., 2017a). Language embeddings have also been explored for other cross-lingual tasks such as lan¨ guage modeling (Tsvetkov et al., 2016; Ostling and Tiedemann, 2017) and POS-tagging (Bjerva and Augenstein, 2018). Cross-lingual parsing, however, often requires substantially more complex models. They typically include features such as multilingual word embeddings (Ammar et al., 2016), linguistic re-write rules (Aufrant et al., 2016), or machine translation (Tiedemann, 2015). Unlike much work on cross-lingual parsing, we do not focus on a low-resource scenario. dev data for most languages, results were mixed on the actual PUD test sets. For the two Norwegian language variants, concatenation has been proposed (Velldal et al., 2017), but it hurts results unless combined with machine translation. Training on concatenated treebanks can be improved by a subsequent fine-tuning step. In this set-up, after training the model on concatenated data, it is refined for each treebank by training only on its own training set for a few additional epochs. This enables the models"
P18-2098,K17-3005,0,\N,Missing
P18-2098,K17-3004,0,\N,Missing
Q13-1001,I05-1075,0,\N,Missing
Q13-1001,D12-1127,0,\N,Missing
Q13-1001,J93-2004,0,\N,Missing
Q13-1001,N12-1052,1,\N,Missing
Q13-1001,N10-1083,0,\N,Missing
Q13-1001,H05-1107,0,\N,Missing
Q13-1001,W06-2920,0,\N,Missing
Q13-1001,N01-1026,0,\N,Missing
Q13-1001,C10-1124,0,\N,Missing
Q13-1001,D10-1056,0,\N,Missing
Q13-1001,P08-1085,0,\N,Missing
Q13-1001,D12-1075,0,\N,Missing
Q13-1001,P08-1086,0,\N,Missing
Q13-1001,P09-1057,0,\N,Missing
Q13-1001,P02-1035,0,\N,Missing
Q13-1001,petrov-etal-2012-universal,1,\N,Missing
Q13-1001,P10-1040,0,\N,Missing
Q13-1001,2005.mtsummit-papers.11,0,\N,Missing
Q13-1001,D07-1096,1,\N,Missing
Q13-1001,P05-1044,0,\N,Missing
Q13-1033,P11-2121,0,0.0181593,"78 79.25 Table 1: Results on the CoNLL 2007 data set. UAS, including punctuation. Each number is an average over 5 runs with different randomization seeds. All experiments used the same exploration parameters of k=1, p=0.9. 6 Related Work The error propagation problem for greedy transitionbased parsing was diagnosed by McDonald and Nivre (2007) and has been tackled with a variety of techniques including parser stacking (Nivre and McDonald, 2008; Martins et al., 2008) and beam search and structured prediction (Zhang and Clark, 2008; Zhang and Nivre, 2011). The technique called bootstrapping in Choi and Palmer (2011) is similar in spirit to training with exploration but is applied iteratively in batch mode and is only approximate due to the use of static oracles. Dynamic oracles were first explored by Goldberg and Nivre (2012). In machine learning more generally, our approach can be seen as a problem-specific instance of imitation learning (Abbeel and Ng, 2004; Vlachos, 2012; He et al., 2012; Daum´e III et al., 2009; Ross et al., 2011), where the dynamic oracle is used to implement the optimal expert needed in the imitation learning setup. Indeed, our training procedure is closely related to DAgger (Ross"
Q13-1033,N10-1115,1,0.92174,"0/2013. 2013 Association for Computational Linguistics. In this paper, we extend the work of Goldberg and Nivre (2012) by giving a general characterization of dynamic oracles as oracles that are nondeterministic, in that they return sets of transitions, and complete, in that they are defined for all possible states. We then define a formal property of transition systems which we call arc decomposition, and introduce a framework for deriving dynamic oracles for arc-decomposable systems. Using this framework, we derive novel dynamic oracles for the hybrid (Kuhlmann et al., 2011) and easy-first (Goldberg and Elhadad, 2010) transition systems, which are arc-decomposable (as is the arc-eager system). We also show that the popular arc-standard system (Nivre, 2004) is not arc-decomposable, and so deriving a dynamic oracle for it remains an open research question. Finally, we perform a set of experiments on the CoNLL 2007 data sets, validating that the use of dynamic oracles for exploring states that result from parsing mistakes during training is beneficial across transition systems. 2 Transition-Based Dependency Parsing We begin with a quick review of transition-based dependency parsing, presenting the arc-eager,"
Q13-1033,C12-1059,1,0.160773,", without considering any parser state outside this sequence. Thus, once the parser strays from the golden path at test time, it ventures into unknown territory and is forced to react to situations it has never been trained for. Introduction Greedy transition-based parsers are easy to implement and are very efficient, but they are generally not as accurate as parsers that are based on global search (McDonald et al., 2005; Koo and Collins, 2010) or as transition-based parsers that use beam search (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010; Kuhlmann et In recent work (Goldberg and Nivre, 2012), we introduced the concept of a dynamic oracle, which is non-deterministic and not restricted to a single golden path, but instead provides optimal predictions for any possible state the parser might be in. Dynamic oracles are non-deterministic in the sense that they return a set of valid transitions for a given parser state and gold tree. Moreover, they are welldefined and optimal also for states from which the gold tree cannot be derived, in the sense that they return the set of transitions leading to the best tree derivable from each state. We showed experimentally that, using a dynamic or"
Q13-1033,P10-1110,0,0.178213,"ned to predict transitions along this gold sequence, without considering any parser state outside this sequence. Thus, once the parser strays from the golden path at test time, it ventures into unknown territory and is forced to react to situations it has never been trained for. Introduction Greedy transition-based parsers are easy to implement and are very efficient, but they are generally not as accurate as parsers that are based on global search (McDonald et al., 2005; Koo and Collins, 2010) or as transition-based parsers that use beam search (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010; Kuhlmann et In recent work (Goldberg and Nivre, 2012), we introduced the concept of a dynamic oracle, which is non-deterministic and not restricted to a single golden path, but instead provides optimal predictions for any possible state the parser might be in. Dynamic oracles are non-deterministic in the sense that they return a set of valid transitions for a given parser state and gold tree. Moreover, they are welldefined and optimal also for states from which the gold tree cannot be derived, in the sense that they return the set of transitions leading to the best tree derivable from each s"
Q13-1033,P10-1001,0,0.0488287,"y parsers are normally trained. Given a treebank oracle, a gold sequence of transitions is derived, and a predictor is trained to predict transitions along this gold sequence, without considering any parser state outside this sequence. Thus, once the parser strays from the golden path at test time, it ventures into unknown territory and is forced to react to situations it has never been trained for. Introduction Greedy transition-based parsers are easy to implement and are very efficient, but they are generally not as accurate as parsers that are based on global search (McDonald et al., 2005; Koo and Collins, 2010) or as transition-based parsers that use beam search (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010; Kuhlmann et In recent work (Goldberg and Nivre, 2012), we introduced the concept of a dynamic oracle, which is non-deterministic and not restricted to a single golden path, but instead provides optimal predictions for any possible state the parser might be in. Dynamic oracles are non-deterministic in the sense that they return a set of valid transitions for a given parser state and gold tree. Moreover, they are welldefined and optimal also for states from which the gold t"
Q13-1033,P11-1068,0,0.524194,"Missing"
Q13-1033,D08-1017,0,0.023359,"70 84.40 84.30 83.43 83.83 85.31 85.11 86.02 86.93 85.57 85.47 84.93 87.69 84.96 86.28 66.59 67.05 64.80 66.12 72.10 73.92 73.16 74.10 80.17 80.43 78.78 79.25 Table 1: Results on the CoNLL 2007 data set. UAS, including punctuation. Each number is an average over 5 runs with different randomization seeds. All experiments used the same exploration parameters of k=1, p=0.9. 6 Related Work The error propagation problem for greedy transitionbased parsing was diagnosed by McDonald and Nivre (2007) and has been tackled with a variety of techniques including parser stacking (Nivre and McDonald, 2008; Martins et al., 2008) and beam search and structured prediction (Zhang and Clark, 2008; Zhang and Nivre, 2011). The technique called bootstrapping in Choi and Palmer (2011) is similar in spirit to training with exploration but is applied iteratively in batch mode and is only approximate due to the use of static oracles. Dynamic oracles were first explored by Goldberg and Nivre (2012). In machine learning more generally, our approach can be seen as a problem-specific instance of imitation learning (Abbeel and Ng, 2004; Vlachos, 2012; He et al., 2012; Daum´e III et al., 2009; Ross et al., 2011), where the dynamic or"
Q13-1033,D07-1013,1,0.845191,"91.30 91.06 92.50 92.85 86.10 88.69 86.43 87.62 88.57 89.41 77.38 77.39 75.91 76.90 78.92 79.29 81.59 83.62 83.43 84.04 82.73 83.70 84.40 84.30 83.43 83.83 85.31 85.11 86.02 86.93 85.57 85.47 84.93 87.69 84.96 86.28 66.59 67.05 64.80 66.12 72.10 73.92 73.16 74.10 80.17 80.43 78.78 79.25 Table 1: Results on the CoNLL 2007 data set. UAS, including punctuation. Each number is an average over 5 runs with different randomization seeds. All experiments used the same exploration parameters of k=1, p=0.9. 6 Related Work The error propagation problem for greedy transitionbased parsing was diagnosed by McDonald and Nivre (2007) and has been tackled with a variety of techniques including parser stacking (Nivre and McDonald, 2008; Martins et al., 2008) and beam search and structured prediction (Zhang and Clark, 2008; Zhang and Nivre, 2011). The technique called bootstrapping in Choi and Palmer (2011) is similar in spirit to training with exploration but is applied iteratively in batch mode and is only approximate due to the use of static oracles. Dynamic oracles were first explored by Goldberg and Nivre (2012). In machine learning more generally, our approach can be seen as a problem-specific instance of imitation lea"
Q13-1033,P05-1012,0,0.114542,"the way in which greedy parsers are normally trained. Given a treebank oracle, a gold sequence of transitions is derived, and a predictor is trained to predict transitions along this gold sequence, without considering any parser state outside this sequence. Thus, once the parser strays from the golden path at test time, it ventures into unknown territory and is forced to react to situations it has never been trained for. Introduction Greedy transition-based parsers are easy to implement and are very efficient, but they are generally not as accurate as parsers that are based on global search (McDonald et al., 2005; Koo and Collins, 2010) or as transition-based parsers that use beam search (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010; Kuhlmann et In recent work (Goldberg and Nivre, 2012), we introduced the concept of a dynamic oracle, which is non-deterministic and not restricted to a single golden path, but instead provides optimal predictions for any possible state the parser might be in. Dynamic oracles are non-deterministic in the sense that they return a set of valid transitions for a given parser state and gold tree. Moreover, they are welldefined and optimal also for stat"
Q13-1033,P08-1108,1,0.23282,"3.62 83.43 84.04 82.73 83.70 84.40 84.30 83.43 83.83 85.31 85.11 86.02 86.93 85.57 85.47 84.93 87.69 84.96 86.28 66.59 67.05 64.80 66.12 72.10 73.92 73.16 74.10 80.17 80.43 78.78 79.25 Table 1: Results on the CoNLL 2007 data set. UAS, including punctuation. Each number is an average over 5 runs with different randomization seeds. All experiments used the same exploration parameters of k=1, p=0.9. 6 Related Work The error propagation problem for greedy transitionbased parsing was diagnosed by McDonald and Nivre (2007) and has been tackled with a variety of techniques including parser stacking (Nivre and McDonald, 2008; Martins et al., 2008) and beam search and structured prediction (Zhang and Clark, 2008; Zhang and Nivre, 2011). The technique called bootstrapping in Choi and Palmer (2011) is similar in spirit to training with exploration but is applied iteratively in batch mode and is only approximate due to the use of static oracles. Dynamic oracles were first explored by Goldberg and Nivre (2012). In machine learning more generally, our approach can be seen as a problem-specific instance of imitation learning (Abbeel and Ng, 2004; Vlachos, 2012; He et al., 2012; Daum´e III et al., 2009; Ross et al., 2011"
Q13-1033,W03-3017,1,0.927277,"racle, which is non-deterministic and not restricted to a single golden path, but instead provides optimal predictions for any possible state the parser might be in. Dynamic oracles are non-deterministic in the sense that they return a set of valid transitions for a given parser state and gold tree. Moreover, they are welldefined and optimal also for states from which the gold tree cannot be derived, in the sense that they return the set of transitions leading to the best tree derivable from each state. We showed experimentally that, using a dynamic oracle for the arc-eager transition system (Nivre, 2003), a greedy parser can be trained to perform well also after incurring a mistake, thus alleviating the effect of error propagation and resulting in consistently better parsing accuracy. 403 Transactions of the Association for Computational Linguistics, 1 (2013) 403–414. Action Editor: Jason Eisner. c Submitted 6/2013; Published 10/2013. 2013 Association for Computational Linguistics. In this paper, we extend the work of Goldberg and Nivre (2012) by giving a general characterization of dynamic oracles as oracles that are nondeterministic, in that they return sets of transitions, and complete, in"
Q13-1033,W04-0308,1,0.443746,"of dynamic oracles as oracles that are nondeterministic, in that they return sets of transitions, and complete, in that they are defined for all possible states. We then define a formal property of transition systems which we call arc decomposition, and introduce a framework for deriving dynamic oracles for arc-decomposable systems. Using this framework, we derive novel dynamic oracles for the hybrid (Kuhlmann et al., 2011) and easy-first (Goldberg and Elhadad, 2010) transition systems, which are arc-decomposable (as is the arc-eager system). We also show that the popular arc-standard system (Nivre, 2004) is not arc-decomposable, and so deriving a dynamic oracle for it remains an open research question. Finally, we perform a set of experiments on the CoNLL 2007 data sets, validating that the use of dynamic oracles for exploring states that result from parsing mistakes during training is beneficial across transition systems. 2 Transition-Based Dependency Parsing We begin with a quick review of transition-based dependency parsing, presenting the arc-eager, arcstandard, hybrid and easy-first transitions systems in a common notation. The transition-based parsing framework (Nivre, 2008) assumes a t"
Q13-1033,J08-4003,1,0.655058,"ard system (Nivre, 2004) is not arc-decomposable, and so deriving a dynamic oracle for it remains an open research question. Finally, we perform a set of experiments on the CoNLL 2007 data sets, validating that the use of dynamic oracles for exploring states that result from parsing mistakes during training is beneficial across transition systems. 2 Transition-Based Dependency Parsing We begin with a quick review of transition-based dependency parsing, presenting the arc-eager, arcstandard, hybrid and easy-first transitions systems in a common notation. The transition-based parsing framework (Nivre, 2008) assumes a transition system, an abstract machine that processes sentences and produces parse trees. The transition system has a set of configurations and a set of transitions which are applied to configurations. When parsing a sentence, the system is initialized to an initial configuration based on the input sentence, and transitions are repeatedly applied to this configuration. After a finite number of transitions, the system arrives at a terminal configuration, and a parse tree is read off the terminal configuration. In a greedy parser, a classifier is used to choose the transition to take"
Q13-1033,D08-1059,0,0.607499,"transitions is derived, and a predictor is trained to predict transitions along this gold sequence, without considering any parser state outside this sequence. Thus, once the parser strays from the golden path at test time, it ventures into unknown territory and is forced to react to situations it has never been trained for. Introduction Greedy transition-based parsers are easy to implement and are very efficient, but they are generally not as accurate as parsers that are based on global search (McDonald et al., 2005; Koo and Collins, 2010) or as transition-based parsers that use beam search (Zhang and Clark, 2008) or dynamic programming (Huang and Sagae, 2010; Kuhlmann et In recent work (Goldberg and Nivre, 2012), we introduced the concept of a dynamic oracle, which is non-deterministic and not restricted to a single golden path, but instead provides optimal predictions for any possible state the parser might be in. Dynamic oracles are non-deterministic in the sense that they return a set of valid transitions for a given parser state and gold tree. Moreover, they are welldefined and optimal also for states from which the gold tree cannot be derived, in the sense that they return the set of transitions"
Q13-1033,P11-2033,1,0.368327,"6.59 67.05 64.80 66.12 72.10 73.92 73.16 74.10 80.17 80.43 78.78 79.25 Table 1: Results on the CoNLL 2007 data set. UAS, including punctuation. Each number is an average over 5 runs with different randomization seeds. All experiments used the same exploration parameters of k=1, p=0.9. 6 Related Work The error propagation problem for greedy transitionbased parsing was diagnosed by McDonald and Nivre (2007) and has been tackled with a variety of techniques including parser stacking (Nivre and McDonald, 2008; Martins et al., 2008) and beam search and structured prediction (Zhang and Clark, 2008; Zhang and Nivre, 2011). The technique called bootstrapping in Choi and Palmer (2011) is similar in spirit to training with exploration but is applied iteratively in batch mode and is only approximate due to the use of static oracles. Dynamic oracles were first explored by Goldberg and Nivre (2012). In machine learning more generally, our approach can be seen as a problem-specific instance of imitation learning (Abbeel and Ng, 2004; Vlachos, 2012; He et al., 2012; Daum´e III et al., 2009; Ross et al., 2011), where the dynamic oracle is used to implement the optimal expert needed in the imitation learning setup. Inde"
Q13-1034,C00-2143,1,0.361351,"bank covered by morphological analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training"
Q13-1034,boguslavsky-etal-2002-development,1,0.676986,"cal analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training corpus. At both learning a"
Q13-1034,E12-1009,1,0.573095,"ther support for this choice, at least for the languages considered in this paper. Note also that the choice is not motivated by efficiency concerns, since increasing the values of kp and km has only a marginal effect on running time, as explained in Section 2.4. Finally, the choice not to consider k-best lemmas is dictated by the fact that our lemmatizer only provides a 1-best analysis. For the first three models, we use the same feature representations as Bohnet and Nivre (2012),9 consisting of their adaptation of the features used by Zhang and Nivre (2011), the graph completion features of Bohnet and Kuhn (2012), and the special features over k-best tags introduced specifically for joint tagging and parsing by Bohnet and Nivre (2012). For the J OINT model, we simply add features over the k-best morphological descriptions analogous to the features over k-best tags.10 Experimental results for these four models can be found in Table 2. From the P IPELINE results, we see that the 1-best accuracy of the preprocessing tagger ranges from 95.0 (Finnish) to 99.2 (Czech) for POS, and from 89.4 (Finnish) to 96.5 (Hungarian) for MOR. The lemmatizer does a good job for four of the languages (93.9–97.9) but has re"
Q13-1034,D12-1133,1,0.0763756,"s, which tend to assume that all morphological disambiguation has been performed before syntactic analysis begins. However, as argued by Lee et al. (2011), in morphologically rich languages there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. Lee et al. (2011) go on to show that a discriminative model for joint morphological disambiguation and dependency parsing gives consistent improvements in morphological and syntactic accuracy, compared to a pipeline model, for Ancient Greek, Czech, Hungarian and Latin. Similarly, Bohnet and Nivre (2012) propose a model for 1 See https://sites.google.com/site/spmrl2013/home/sharedtask. 415 Transactions of the Association for Computational Linguistics, 1 (2013) 415–428. Action Editor: Brian Roark. c Submitted 7/2013; Revised 9/2013; Published 10/2013. 2013 Association for Computational Linguistics. joint part-of-speech tagging and dependency parsing and report improved accuracy for Czech and German (but also for Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approa"
Q13-1034,C10-1011,1,0.684406,"nguages. For Czech, the best previous UAS on the standard train-test split of the PDT is 87.32, reported by Koo et al. (2010) with a parser using non-projective head automata and dual decomposition, while the best LAS is 78.82 LAS from Nilsson et al. (2006), using a greedy arc-eager transitionbased system with pseudo-projective parsing. Our best results are 1.7 percentage points better for UAS (89.0) and almost 5 percentage points better for LAS (83.7).14 For Finnish, the only previous results are from Haverinen et al. (2013), who achieve 81.01 LAS and 84.97 UAS with the graph-based parser of Bohnet (2010). We get substantial improvements with 83.1 LAS and 86.6 UAS. We also improve slightly over their best POS score, obtained with the HunPos tagger (Hal´acsy et al., 2007) together with the OMorFi analyzer (95.7 vs. 95.4). For German, the best previous results on the same train-test split are from Seeker and Kuhn (2012), using the graphbased parser of Bohnet (2010) in a pipeline architecture. With the same evaluation setup as in this paper, they achieve 91.50 LAS and 93.48 UAS – 13 L EX S OFT averages 0.132 ms per sentence on an Intel i73930K processor with 6 cores, against 0.112 ms for P IPELIN"
Q13-1034,J92-4003,0,0.242366,"striking for German, where the soft lexical constraints are clearly beneficial (especially for the MOR score) despite not being quite compatible with the morphological descriptions in the training set. In terms of statistical signifance, L EX S OFT outperforms the J OINT model with respect to the PMD score for all languages (p < 0.01). It is also significantly better than L EX H ARD for all languages except Finnish (p < 0.01). 6 Word Clusters Finally, we add word cluster features to the best model for each language (L EX H ARD for Finnish, L EX S OFT for the others).11 We use Brown clusters (Brown et al., 1992), with 800 clusters for all languages, and we use the same feature representation as Bohnet and Nivre (2012). The results in Table 2 show small but consistent improvements in almost all metrics for all languages, confirming the benefit of cluster features for morphologically rich languages. It is worth noting that we see the biggest improvement for Finnish, the language with the smallest training set and therefore most likely to 11 The best model was selected according to results on the dev set (cross-validation on the training set for Finnish). suffer from sparse data, where the syntactic acc"
Q13-1034,W06-2920,0,0.719913,"re languages, it has also been observed that typological differences between languages lead to new challenges. In particular, it has been found over and over again that languages exhibiting rich morphological structure, often together with a relatively free word order, usually obtain lower parsing accuracy, especially in comparison to English. One striking demonstration of this tendency can be found in the CoNLL shared tasks on multilingual dependency parsing, organized in 2006 and 2007, where richly inflected languages clustered at the lower end of the scale with respect to parsing accuracy (Buchholz and Marsi, 2006; Nivre et al., 2007). These and similar observations have led to an increased interest in the special challenges posed by parsing morphologically rich languages, as evidenced most clearly by a new series of workshops devoted to this topic (Tsarfaty et al., 2010), as well as a special issue in Computational Linguistics (Tsarfaty et al., 2013) and a shared task on parsing morphologically rich languages.1 One hypothesized explanation for the lower parsing accuracy observed for richly inflected languages is the strict separation of morphological and syntactic analysis assumed in many parsing fram"
Q13-1034,D07-1022,0,0.0694561,"ish), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that"
Q13-1034,D11-1114,0,0.0374383,"Missing"
Q13-1034,P04-1015,0,0.261816,"put sentence x with weight vector w. The symbols h.c, h.s and h.f denote, respectively, the configuration, score and feature vector of a hypothesis h; Γc denotes the MS-parse defined by c. to 0.0, make N iterations over the training data and update the weight vector for every sentence x where the transition sequence C0,m corresponding to the gold parse is different from the highest scoring tran4 More precisely, we use the ∗ sition sequence C0,m 0. passive-aggressive update of Crammer et al. (2006). We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010). This means that, at learning time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4 Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-de"
Q13-1034,W02-1001,0,0.162454,"inear for natural language data sets, due to the sparsity of non-projective dependencies (Nivre, 2009). The running time is also linear in |D |+ |P × M |, which means that joint prediction only gives a linear increase in running time, often quite marginal because |D |> |P × M |. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all weights 3 While there exist exact dynamic programming algorithms for projective transition systems (Huang and Sagae, 2010; Kuhlmann et al., 2011) and even for restricted non-projective systems (Cohen et al., 2011), parsing is intractable for systems like ours that permit arbitrary non-projective trees. PARSE(x, w) 1 h0 .c ← cs (x) 2 h0 .s ← 0.0 3 h0 .f ← {0.0}dim(w) 4 B EAM ← [h0 ] 5 while ∃h ∈ B EAM : h.c 6∈ Ct 6 T MP ← [ ] 7 foreach h ∈ B EAM 8 foreach t ∈ T : P ERMISSIBLE(h.c, t) 9 h.f ← h.f + f(x, h.c"
Q13-1034,H05-1100,0,0.0303135,"and German (but also for Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus"
Q13-1034,E12-1007,1,0.93185,"22 1105 33 151,971 71,263 200,249,814 538,138 14 454 78 97,905 35,039 195,897,041 639,446 Table 1: Statistics about data sets and resources used in the experiments. Treebank: number of tokens in data sets; number of labels in label sets. Morphology: number of word forms and lemmas in treebank covered by morphological analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Rus"
Q13-1034,W09-1205,0,0.0234606,"binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependen"
Q13-1034,J13-1007,0,0.0248062,"Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of lexical features can also be tackled by the use of distributional word clusters as pioneered by Koo et al. (2008). In this paper, we present a transition-based model that jointly predicts complex morphological representations and dependency relations, generalizing the approach of Bohnet and Nivre (2012) to include the full range"
Q13-1034,P08-1043,0,0.0558272,"case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-"
Q13-1034,P98-1080,1,0.597993,"Missing"
Q13-1034,A00-2013,0,0.0703501,"Missing"
Q13-1034,P07-2053,0,0.0543962,"Missing"
Q13-1034,I11-1136,0,0.0554181,"hang and Clark (2008), we assume that the score is given by a linear model whose feature representations decompose in the same way: s(x, C0,m ) = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has show"
Q13-1034,P10-1110,0,0.18704,"near increase in running time, often quite marginal because |D |> |P × M |. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all weights 3 While there exist exact dynamic programming algorithms for projective transition systems (Huang and Sagae, 2010; Kuhlmann et al., 2011) and even for restricted non-projective systems (Cohen et al., 2011), parsing is intractable for systems like ours that permit arbitrary non-projective trees. PARSE(x, w) 1 h0 .c ← cs (x) 2 h0 .s ← 0.0 3 h0 .f ← {0.0}dim(w) 4 B EAM ← [h0 ] 5 while ∃h ∈ B EAM : h.c 6∈ Ct 6 T MP ← [ ] 7 foreach h ∈ B EAM 8 foreach t ∈ T : P ERMISSIBLE(h.c, t) 9 h.f ← h.f + f(x, h.c, t) 10 h.s ← h.s + f(x, h.c, t) · w 11 h.c ← t(h.c) 12 T MP ← I NSERT(h, T MP) 13 B EAM ← P RUNE(T MP) 14 h∗ ← T OP(B EAM) 15 return Γh∗c Figure 2: Beam search algorithm for finding the best MSparse for input s"
Q13-1034,P08-1068,0,0.0257504,"rphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of lexical features can also be tackled by the use of distributional word clusters as pioneered by Koo et al. (2008). In this paper, we present a transition-based model that jointly predicts complex morphological representations and dependency relations, generalizing the approach of Bohnet and Nivre (2012) to include the full range of morphological information. We start by investigating different ways of integrating morphological features into the model, go on to examine the effect of using rule-based morphological analyzers to derive hard or soft constraints on the morphological analysis, and finally add word cluster features to combat lexical sparsity. We evaluate our methods on data from Czech, Finnish,"
Q13-1034,D10-1125,0,0.0274644,"Missing"
Q13-1034,P11-1068,0,0.0182537,"Missing"
Q13-1034,P11-1089,0,0.0278511,"al., 2010), as well as a special issue in Computational Linguistics (Tsarfaty et al., 2013) and a shared task on parsing morphologically rich languages.1 One hypothesized explanation for the lower parsing accuracy observed for richly inflected languages is the strict separation of morphological and syntactic analysis assumed in many parsing frameworks (Tsarfaty et al., 2010; Tsarfaty et al., 2013). This is true in particular for data-driven dependency parsers, which tend to assume that all morphological disambiguation has been performed before syntactic analysis begins. However, as argued by Lee et al. (2011), in morphologically rich languages there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. Lee et al. (2011) go on to show that a discriminative model for joint morphological disambiguation and dependency parsing gives consistent improvements in morphological and syntactic accuracy, compared to a pipeline model, for Ancient Greek, Czech, Hungarian and Latin. Similarly, Bohnet and Nivre (2012) propose a model for 1 See https://sites.google.com/site/spmrl2013/home/sharedtask. 415 Transactions of the Association for Computa"
Q13-1034,P06-1033,1,0.867756,"Missing"
Q13-1034,W09-3811,1,0.599747,"ng time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4 Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-dependents before right-dependents and applies the lazy swapping strategy of Nivre et al. (2009). 419 3 Data Sets and Resources Throughout the paper, we experiment with data from five languages: Czech, Finnish, German, Hungarian, and Russian. For each language, we use a morphologically and syntactically annotated corpus (treebank), divided into a training set, a development set and a test set. In addition, we use a lexicon generated by a rule-based morphological analyzer, and distributional word clusters derived from a large unlabeled corpus. Below we describe the specific resources used for each language. Table 1 provides descriptive statistics about the resources. Czech For training an"
Q13-1034,W03-3017,1,0.552345,"ections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the S WAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly different impl"
Q13-1034,W04-0308,1,0.586101,"e representations decompose in the same way: s(x, C0,m ) = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark,"
Q13-1034,P09-1040,1,0.939947,"Γ = (A, π, µ, λ, δ) is an MS-parse for x. We take the initial configuration for a sentence x = w1 , . . . , wn to be cs (x) = ([0], [1, . . . , n], (∅, ⊥, ⊥, ⊥, ⊥)), where ⊥ is the function that is undefined for all arguments, and we take the set Ct of terminal configurations to be the set of all configurations of the form c = ([0], [ ], Γ) (for any Γ). The MS-parse defined for x by c = (Σ, B, (A, π, µ, λ, δ)) is Γc = (A, π, µ, λ, δ), and the MS-parse defined for x by a complete transition sequence C0,m is Γtm (cm ) . The set T of transitions is shown in Figure 1. It is based on the system of Nivre (2009), where a dependency tree is built by repeated applications of the L EFT-A RCd and R IGHT-A RCd transitions, which add an arc (with some label d ∈ D) between the two topmost nodes on the stack (with the leftmost or rightmost node as the dependent, respectively). The S HIFT transition is used to move nodes from the buffer to the stack, and the S WAP transition is used to permute nodes in order to allow non-projective dependencies. Bohnet and Nivre (2012) modified this system by replacing the simple S HIFT transition by S HIFTp , which not only moves a node from the buffer to the stack but also"
Q13-1034,W11-4644,0,0.0793275,"Missing"
Q13-1034,W09-3829,0,0.0396525,"Missing"
Q13-1034,schmid-etal-2004-smor,0,0.0195468,"Missing"
Q13-1034,seeker-kuhn-2012-making,0,0.0289485,"Missing"
Q13-1034,C10-2129,1,0.896137,"Missing"
Q13-1034,spoustova-spousta-2012-high,0,0.0221884,"Missing"
Q13-1034,W07-2218,0,0.0373151,") = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search deco"
Q13-1034,tron-etal-2006-morphdb,0,0.119292,"Missing"
Q13-1034,W10-1401,0,0.0166567,"Missing"
Q13-1034,J13-1003,1,0.829911,"Missing"
Q13-1034,P06-3009,0,0.0901789,"Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and E"
Q13-1034,varadi-2002-hungarian,0,0.105288,"Missing"
Q13-1034,W03-3023,0,0.0799723,"tantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the S WAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly"
Q13-1034,D08-1059,0,0.738873,"so that a node moved from the buffer to the stack is assigned not only a tag p but also a morphological description m and a lemma l. In this way, we get a joint model for the prediction of part-ofspeech tags, morphological features, lemmas, and dependency trees. 2.3 Scoring In transition-based parsing, we score parses in an indirect fashion by scoring transition sequences. In general, we assume that the score function s factors by configuration-transition pairs: s(x, C0,m ) = m X s(x, ci , ti ) (1) i=0 Moreover, when using structured learning, as first proposed for transition-based parsing by Zhang and Clark (2008), we assume that the score is given by a linear model whose feature representations decompose in the same way: s(x, C0,m ) = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011)"
Q13-1034,P11-2033,1,0.457721,"ection 7, we present an empirical analysis that gives further support for this choice, at least for the languages considered in this paper. Note also that the choice is not motivated by efficiency concerns, since increasing the values of kp and km has only a marginal effect on running time, as explained in Section 2.4. Finally, the choice not to consider k-best lemmas is dictated by the fact that our lemmatizer only provides a 1-best analysis. For the first three models, we use the same feature representations as Bohnet and Nivre (2012),9 consisting of their adaptation of the features used by Zhang and Nivre (2011), the graph completion features of Bohnet and Kuhn (2012), and the special features over k-best tags introduced specifically for joint tagging and parsing by Bohnet and Nivre (2012). For the J OINT model, we simply add features over the k-best morphological descriptions analogous to the features over k-best tags.10 Experimental results for these four models can be found in Table 2. From the P IPELINE results, we see that the 1-best accuracy of the preprocessing tagger ranges from 95.0 (Finnish) to 99.2 (Czech) for POS, and from 89.4 (Finnish) to 96.5 (Hungarian) for MOR. The lemmatizer does a"
Q13-1034,C12-2136,1,0.0524599,"out the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the S WAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly different implementations of the permissibility condition invoked in line 8, which can be used to filter out labels that are improbable or incom"
Q13-1034,C98-1077,0,\N,Missing
Q13-1034,W09-1201,1,\N,Missing
Q13-1034,D07-1096,1,\N,Missing
Q18-1030,K17-3005,0,0.024135,"gmentation and parsing F1-score (76.95) is reported and compared against the parsing score (85.70) with gold word segmentation. The evaluation scores re5 LDC2010T13, LDC2011T09, LDC2010T08 LDC2012T07 7 LDC2012E93,98,89,99,107,125, LDC2013E12,21 6 ported in both Monroe et al. (2014) and Goldberg and Elhadad (2013) are not directly comparable to the evaluation scores on Arabic and Hebrew in this paper, as they are obtained on different datasets. For universal word segmentation, apart from UDPipe described in Section 6.3, there are several systems that are developed for specific language groups. Che et al. (2017) build a similar Bi-LSTM word segmentation model targeting languages without space delimiters like Chinese and Japanese. The proposed model incorporates rich statistics-based features gathered from large-scale unlabelled data, such as character unigram embeddings, character bigram embeddings and the point-wise mutual information of adjacent characters. Bj¨orkelund et al. (2017) use a CRF-based tagger for multiword token rich languages like Arabic and Hebrew. A predicted Levenshtein edit script is employed to transform the multiword tokens into their components. The evaluation scores on a selec"
Q18-1030,D15-1141,0,0.0157937,"r lexicon size, are relatively stable across different UD treebanks for the same language, which indicates that they do capture properties of these languages, although some variation inevitably occurs due to corpus properties like genre. In this paper, we thoroughly investigate the correlations between the proposed statistical factors and segmentation accuracy. Moreover, we aim to find specific settings that can be applied to improve segmentation accuracy for each language group. 4 Sequence Tagging Model Word segmentation can be modelled as a characterlevel sequence labelling task (Xue, 2003; Chen et al., 2015). Characters as basic input units are passed into a sequence labelling model and a sequence of tags that are associated with word boundaries are predicted. In this section, we introduce the boundary tags adopted in this paper. Theoretically, binary classification is sufficient to indicate whether a character is the end of a word for segmentation. In practice, more fine-grained tagsets result in higher segmentation accuracy (Zhao et al., 2006). Following the work of Shao et al. (2017), we employ a baseline tagset consisting of four tags: B, I, E, and S, to indicate a character positioned at the"
Q18-1030,W14-4012,0,0.0145111,"Missing"
Q18-1030,K17-3022,1,0.898384,"Missing"
Q18-1030,K17-3002,0,0.0894629,"ucer is much more powerful in processing the non-segmental multiword tokens that are not covered by the dictionary than the suffix rules for analysing multiword tokens in UDPipe. UDPipe obtains higher scores on a few datasets. Our model overfits the small training data of Uyghur Arabic Chinese Hebrew Japanese Vietnamese Segmentation Accuracy UDPipe This Paper 93.77 97.16 90.47 93.82 85.16 91.01 92.03 93.77 85.53 87.79 UDPipe parser UAS LAS UDPipe This Paper UDPipe This Paper 72.34 78.22 66.41 71.79 63.20 67.91 59.07 63.31 62.14 71.18 57.82 66.59 78.08 81.77 76.73 80.83 47.72 50.87 43.10 46.03 Dozat et al. (2017) UAS LAS UDPipe This Paper UDPipe This Paper 77.52 83.55 72.89 78.42 71.24 76.33 68.20 73.04 67.61 76.39 64.02 72.37 80.21 83.79 79.44 82.99 50.28 53.78 45.54 48.86 Table 12: Extrinsic evaluations with dependency parsing on the test sets. The parsing accuracies are reported in unlabelled attachment score (UAS) and labelled attachment score (LAS). Buryat Kurmanji North Sami Upper Sorbian Space 71.99 78.97 79.07 72.35 NLTK 97.99 97.37 99.20 94.60 Sample 88.07 93.37 92.82 93.34 Transfer 97.99 (Russian) 96.71 (Spanish) 99.81 (German) 93.66 (Spanish) Table 13: Evaluation on the surprise languages."
Q18-1030,J13-1007,0,0.0302636,"ly enlarges the search space and therefore the model becomes extremely inefficient both for training and tagging. The joint POS tagging model is nonetheless applicable to Japanese and Vietnamese. Monroe et al. (2014) present a data-driven word segmentation system for Arabic based on a sequence labelling framework. An extended tagset is designed for Arabic-specific orthographic rules and applied together with hand-crafted features in a CRF framework. It obtains 98.23 F1-score on newswire Arabic Treebank,5 97.61 on Broadcast News Treebank,6 and 92.10 on the Egyptian Arabic dataset.7 For Hebrew, Goldberg and Elhadad (2013) perform word segmentation jointly with syntactic disambiguation using lattice parsing. Each lattice arc corresponds to a word and its corresponding POS tag, and a path through the lattice corresponds to a specific word segmentation and POS tagging of the sentence. The proposed model is evaluated on the Hebrew Treebank (Guthmann et al., 2009). The joint word segmentation and parsing F1-score (76.95) is reported and compared against the parsing score (85.70) with gold word segmentation. The evaluation scores re5 LDC2010T13, LDC2011T09, LDC2010T08 LDC2012T07 7 LDC2012E93,98,89,99,107,125, LDC201"
Q18-1030,W02-0109,0,0.0156233,"o Average F1-scores. The scores of the surprise languages are excluded and presented separately as no corresponding UDPipe models are available. Our system obtains higher segmentation accuracy overall. It achieves substantially better accuracies on languages that are challenging to segment, namely Chinese, Japanese, Vietnamese, Arabic and Hebrew. The two systems yield very similar scores, when these languages are excluded as shown in Table 8, in which the two systems are also compared with two rule-based baselines, a simple space-based tokeniser and the tokenisation model for English in NLTK (Loper and Bird, 2002). The NLTK model obtains relatively high accuracy while the spacebased baseline substantially underperforms, which indicates that relying on white space alone is insufficient for word segmentation in general. On the majority of the space-delimited languages without productive non-segmental multiword tokens, both UDPipe and our segmentation system yield near-perfect scores in Table 9. In general, referring back to Figure 1, languages that are clustered at the bottom-left corner are relatively trivial to segment. The evaluation scores are notably lower on Semitic languages as well as languages w"
Q18-1030,P14-2034,0,0.0733593,"the universal model presented in this paper can be obtained. However, the joint POS tagging system is difficult to generalise as single characters in space-delimited languages are usually not informative for POS tagging. Additionally, compared to Chinese, sentences in space-delimited languages have a much greater number of characters on average. Combining the POS tags with segmentation tags drastically enlarges the search space and therefore the model becomes extremely inefficient both for training and tagging. The joint POS tagging model is nonetheless applicable to Japanese and Vietnamese. Monroe et al. (2014) present a data-driven word segmentation system for Arabic based on a sequence labelling framework. An extended tagset is designed for Arabic-specific orthographic rules and applied together with hand-crafted features in a CRF framework. It obtains 98.23 F1-score on newswire Arabic Treebank,5 97.61 on Broadcast News Treebank,6 and 92.10 on the Egyptian Arabic dataset.7 For Hebrew, Goldberg and Elhadad (2013) perform word segmentation jointly with syntactic disambiguation using lattice parsing. Each lattice arc corresponds to a word and its corresponding POS tag, and a path through the lattice"
Q18-1030,L16-1262,1,0.890118,"Missing"
Q18-1030,W13-3504,0,0.0230707,"es without word delimiters. Nonetheless, our system obtains substantially higher scores on the languages that are more challenging to process. For Chinese, Japanese and Vietnamese, our system benefits substantially from the concatenated 3-gram character representation, which has been demonstrated in Section 6.2.2. Besides, we employ a more fine-grained tagset with CRF loss instead of the binary tags adopted in UDPipe. As presented in Zhao et al. (2006), more fine-grained tagging schemes outperform binary tags, which is supported by the experimental results on morpheme segmentation reported in Ruokolainen et al. (2013). We further investigate the merits of the finegrained tags over the binary tags as well as the effectiveness of the CRF interface by the experiments presented in Table 10 with the variances of our segmentation system. The fine-grained tags denote the boundary tags introduced in Table 3. The binary Dataset Ancient Greek Arabic-PUD Catalan Czech Czech-PUD Dutch-LassySmall English-PUD Finnish French French-Sequoia German Greek Hindi-PUD Irish Japanese Korean Latin-PROIEL Norwegian-Nynorsk Polish Portuguese-PUD Russian-PUD Slovenian Spanish-AnCora Swedish-LinES Turkish-PUD Uyghur UDPipe 99.98 90."
Q18-1030,I17-1018,1,0.946453,"equence Tagging Model Word segmentation can be modelled as a characterlevel sequence labelling task (Xue, 2003; Chen et al., 2015). Characters as basic input units are passed into a sequence labelling model and a sequence of tags that are associated with word boundaries are predicted. In this section, we introduce the boundary tags adopted in this paper. Theoretically, binary classification is sufficient to indicate whether a character is the end of a word for segmentation. In practice, more fine-grained tagsets result in higher segmentation accuracy (Zhao et al., 2006). Following the work of Shao et al. (2017), we employ a baseline tagset consisting of four tags: B, I, E, and S, to indicate a character positioned at the beginning (B), inside (I), or at the end (E) of a word, or occurring as a single-character word (S). The baseline tagset can be applied to word segmentation of Chinese and Japanese without further modification. For languages with space-delimiters, we add an extra tag X to mark the characters, mostly spaces, that do not belong to any words/tokens. As illustrated in Figure 2, the regular spaces are marked with X while the space in a multitoken word like 50 000 is disambiguated with I."
Q18-1030,K17-3009,0,0.073967,"Missing"
Q18-1030,O03-4002,0,0.67766,"rent definitions of the concept of a word. In this paper, we will follow the teminologies of Universal Dependencies (UD), where words are defined as basic syntactic units that do not always coincide with phonological or orthographic words. Some orthographic tokens, known in UD as multiword tokens, therefore need to be broken into smaller units that cannot always be obtained by splitting the input character sequence.1 To perform word segmentation in the UD framework, neither rule-based tokenisers that rely on white space nor the naive character-level sequence tagging model proposed previously (Xue, 2003) are ideal. In this paper, we present an enriched sequence labelling model for universal word segmentation. It is capable of segmenting languages in very diverse written forms. Furthermore, it simultaneously identifies the multiword tokens defined by the UD framework that cannot be resolved simply by splitting 1 Note that this notion of multiword token has nothing to do with the notion of multiword expression (MWE) as discussed, for example, in Sag et al. (2002). 421 Transactions of the Association for Computational Linguistics, vol. 6, pp. 421–435, 2018. Action Editor: Sebastian Pad´o . Submi"
Q18-1030,Y06-1012,0,0.037929,"tion accuracy for each language group. 4 Sequence Tagging Model Word segmentation can be modelled as a characterlevel sequence labelling task (Xue, 2003; Chen et al., 2015). Characters as basic input units are passed into a sequence labelling model and a sequence of tags that are associated with word boundaries are predicted. In this section, we introduce the boundary tags adopted in this paper. Theoretically, binary classification is sufficient to indicate whether a character is the end of a word for segmentation. In practice, more fine-grained tagsets result in higher segmentation accuracy (Zhao et al., 2006). Following the work of Shao et al. (2017), we employ a baseline tagset consisting of four tags: B, I, E, and S, to indicate a character positioned at the beginning (B), inside (I), or at the end (E) of a word, or occurring as a single-character word (S). The baseline tagset can be applied to word segmentation of Chinese and Japanese without further modification. For languages with space-delimiters, we add an extra tag X to mark the characters, mostly spaces, that do not belong to any words/tokens. As illustrated in Figure 2, the regular spaces are marked with X while the space in a multitoken"
R19-1136,P17-1080,0,0.0288899,"e encoders. Encoders are responsible for providing source hidden representations to the decoder. Encoderfree models have to use word embeddings to represent source tokens without the help of encoders. Thus, the source-side representations probably lead to the performance gap. PPL 11.7 10.3 9.9 9.5 9.6 BLEU 15.9 17.6 18.4 18.6 18.9 Table 4: The performance of Transformer models that have different layers in the encoder, including the perplexity (PPL) on the development set and the BLEU scores on newstest2015. It has been shown that encoders could extract syntactic and semantic features in NMT (Belinkov et al., 2017a,b; Poliak et al., 2018). In the meantime, contextual information is encoded in hidden representations as well. Hence we conclude that the quality of source representations is the main factor causing the big gap between Transformer and Trans-noEnc. In Table 5, our additional experiments on DE→EN and ZH→EN confirm that models with contextualized representations are much better. Transformer models always outperform TransnoEnc models substantially. Lan. DE→EN ZH→EN Figure 1: The attention entropy of each attention layer and the entire attention mechanism. 4.3 Param. 71.4M 76.9M 87.9M 98.9M 104.4"
R19-1136,I17-1001,0,0.062453,"Missing"
R19-1136,P17-1106,0,0.0293548,"ngs of NMT models. However, Ghader and Monz (2017) and Koehn and Knowles (2017) have shown that the attention mechanism is different from a word alignment. While there are linguistically plausible explanations in some cases – when translating a verb, knowledge about the subject, object etc. may be relevant information – other cases are harder to explain, such as an off-by-one mismatch between attention and word alignment for some models. We suspect that such a pattern can be learned if relevant information is passed to neighboring representations via recurrent or self-attentional connections. Ding et al. (2017) show that only using attention is not sufficient for deep interpretation and propose to use layer-wise relevance propagation to better understand NMT. Wang et al. (2018) replace the attention model with an alignment model and a lexical model to make NMT models more interpretable. The proposed model is not superior but on a par with the attentional model. They clarify the difference between alignment models and attention models by saying that that the alignment model is to identify translation equivalents while the attention model is to predict the next target word. In this paper, we try to un"
R19-1136,I17-1004,0,0.654762,"et al., 2017) represent the source. The decoder is a standard Transformer (Vaswani et al., 2017) or recurrent neural network (RNN) that attends to embeddings via attention mechanisms. As motivation for our architecture simplification, consider the attention mechanism1 (Bahdanau et al., 2015; Luong et al., 2015), which has been introduced to extract features from the hidden representations in encoders dynamically. Attention and alignment were initially used interchangeably, but it was soon discovered that the attention mechanism can behave very differently from traditional word alignment (see Ghader and Monz, 2017; Koehn and Knowles, 2017). One reason for this discrepancy is that the attention mechanism operates on representations that potentially includes information from the whole sentence due to the encoder’s recurrent or self-attentional architecture. Intuitively, bypassing these encoder layers and attending word embeddings directly could lead to a more alignment-like, and thus predictable and interpretable behavior of the attention model. By comparing encoder-free models with conventional models, we can better understand the working mechanism of NMT, figure out which components are more crucial, a"
R19-1136,E17-3017,1,0.836013,"nificantly improves the alignment quality and performs as well as the aligners based on traditional IBM models. 3 Experiments In addition to training Transformer and TransnoEnc models, we also compare Trans-noEnc with NMT models based on RNNs (RNNS2S). We train RNNS2S models without encoders (RNNS2SnoEnc), without attention mechanisms (RNNS2SnoAtt), and without both encoders and attention mechanisms (RNNS2S-noAtt-noEnc) to explore which component is more important for NMT. We also investigate the importance of positional embeddings in Trans-noEnc. 3.1 Experimental Settings We use the Sockeye (Hieber et al., 2017) toolkit, which is based on MXNet (Chen et al., 2015), to train models. Each encoder/decoder has 6 layers. For RNNS2S, we choose long short-term memory (LSTM) RNN units. Transformers have 8 attention heads. The size of embeddings and hidden states is 768. We tie the source, target, and output embeddings. The dropout rate of embeddings and Transformer blocks is set to 0.1. The dropout rate 1187 of RNNs is 0.2. All the models are trained with a single GPU. During training, each mini-batch contains 2,048 tokens. A model checkpoint is saved every 1,000 updates. We use Adam (Kingma and Ba, 2015) as"
R19-1136,D13-1176,0,0.11271,"ce. The decoder is a standard Transformer or recurrent neural network that directly attends to embeddings via attention mechanisms. Experimental results show (1) that the attention mechanism in encoder-free models acts as a strong feature extractor, (2) that the word embeddings in encoder-free models are competitive to those in conventional models, (3) that non-contextualized source representations lead to a big performance drop, and (4) that encoder-free models have different effects on alignment quality for German→English and Chinese→English. 1 Introduction Neural machine translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) has emerged in the last few years and has achieved new state-ofthe-art performance. However, NMT models are black boxes for humans and are hard to interpret. NMT models employ encoder-decoder architectures where an encoder encodes source-side sentences and an attentional decoder generates targetside sentences based on the outputs of the encoder. In this paper, we attempt to obtain a more interpretable NMT model by simplifying the encoderdecoder architecture. We train encoder-free models where the sums of word embeddings and s"
R19-1136,W17-3204,0,0.402881,"t the source. The decoder is a standard Transformer (Vaswani et al., 2017) or recurrent neural network (RNN) that attends to embeddings via attention mechanisms. As motivation for our architecture simplification, consider the attention mechanism1 (Bahdanau et al., 2015; Luong et al., 2015), which has been introduced to extract features from the hidden representations in encoders dynamically. Attention and alignment were initially used interchangeably, but it was soon discovered that the attention mechanism can behave very differently from traditional word alignment (see Ghader and Monz, 2017; Koehn and Knowles, 2017). One reason for this discrepancy is that the attention mechanism operates on representations that potentially includes information from the whole sentence due to the encoder’s recurrent or self-attentional architecture. Intuitively, bypassing these encoder layers and attending word embeddings directly could lead to a more alignment-like, and thus predictable and interpretable behavior of the attention model. By comparing encoder-free models with conventional models, we can better understand the working mechanism of NMT, figure out which components are more crucial, and learn lessons for impro"
R19-1136,P18-1164,0,0.145965,"the difference between alignment models and attention models by saying that that the alignment model is to identify translation equivalents while the attention model is to predict the next target word. In this paper, we try to understand NMT by simplifying the model. We explore the importance of different NMT components and what causes the performance gap after model simplification. 2.2 Alignments and Source Embeddings Nguyen and Chiang (2018) introduce a lexical model to generate a target word directly based on the source words. With the lexical model, NMT models generate better alignments. Kuang et al. (2018) propose three different methods to bridge source and target word embeddings. The bridging methods can significantly improve the translation quality. Moreover, the word alignments generated by the model are improved as well. Our encoder-free model is a simplification and only attends to the source word embeddings. We aim to interpret NMT models rather than pursuing better performance. Different from previous work, Zenkel et al. (2019) introduce a separate alignment layer directly optimizing the word alignment. The alignment layer is an attention network learning to attend to source tokens give"
R19-1136,D15-1166,0,0.655745,"ctly attends to embeddings via attention mechanisms. Experimental results show (1) that the attention mechanism in encoder-free models acts as a strong feature extractor, (2) that the word embeddings in encoder-free models are competitive to those in conventional models, (3) that non-contextualized source representations lead to a big performance drop, and (4) that encoder-free models have different effects on alignment quality for German→English and Chinese→English. 1 Introduction Neural machine translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015) has emerged in the last few years and has achieved new state-ofthe-art performance. However, NMT models are black boxes for humans and are hard to interpret. NMT models employ encoder-decoder architectures where an encoder encodes source-side sentences and an attentional decoder generates targetside sentences based on the outputs of the encoder. In this paper, we attempt to obtain a more interpretable NMT model by simplifying the encoderdecoder architecture. We train encoder-free models where the sums of word embeddings and sinusoid embeddings (Vaswani et al., 2017) represent the source. The"
R19-1136,N18-1031,0,0.0160366,"odel with an alignment model and a lexical model to make NMT models more interpretable. The proposed model is not superior but on a par with the attentional model. They clarify the difference between alignment models and attention models by saying that that the alignment model is to identify translation equivalents while the attention model is to predict the next target word. In this paper, we try to understand NMT by simplifying the model. We explore the importance of different NMT components and what causes the performance gap after model simplification. 2.2 Alignments and Source Embeddings Nguyen and Chiang (2018) introduce a lexical model to generate a target word directly based on the source words. With the lexical model, NMT models generate better alignments. Kuang et al. (2018) propose three different methods to bridge source and target word embeddings. The bridging methods can significantly improve the translation quality. Moreover, the word alignments generated by the model are improved as well. Our encoder-free model is a simplification and only attends to the source word embeddings. We aim to interpret NMT models rather than pursuing better performance. Different from previous work, Zenkel et a"
R19-1136,J03-1002,0,0.0344722,"Missing"
R19-1136,P02-1040,0,0.106525,"ls are trained with a single GPU. During training, each mini-batch contains 2,048 tokens. A model checkpoint is saved every 1,000 updates. We use Adam (Kingma and Ba, 2015) as the optimizer. The initial learning rate is set to 0.0001. If the performance on the validation set has not improved for 8 checkpoints, the learning rate is multiplied by 0.7. We set the early stopping patience to 32 checkpoints. The training data is from the WMT15 shared task (Bojar et al., 2015) on Finnish–English (FI– EN). We choose newsdev2015 as the validation set and use newstest2015 as the test set. All the BLEU (Papineni et al., 2002) scores are measured by SacreBLEU (Post, 2018). There are about 2.1M sentence pairs in the training set after preprocessing. We learn a joint BPE model with 32K subword units (Sennrich et al., 2016). We employ the models that have the best perplexity on the validation set for the evaluation. We set the beam size to 8 during inference. To test the universality of our findings, we conduct experiments on DE→EN and ZH→EN as well. For DE→EN, we use the training data from the WMT17 shared task (Bojar et al., 2017). We use newstest2013 as the validation set and newstest2017 as the test set. We learn"
R19-1136,N18-2082,0,0.050386,"Missing"
R19-1136,W18-6319,0,0.0611463,"ini-batch contains 2,048 tokens. A model checkpoint is saved every 1,000 updates. We use Adam (Kingma and Ba, 2015) as the optimizer. The initial learning rate is set to 0.0001. If the performance on the validation set has not improved for 8 checkpoints, the learning rate is multiplied by 0.7. We set the early stopping patience to 32 checkpoints. The training data is from the WMT15 shared task (Bojar et al., 2015) on Finnish–English (FI– EN). We choose newsdev2015 as the validation set and use newstest2015 as the test set. All the BLEU (Papineni et al., 2002) scores are measured by SacreBLEU (Post, 2018). There are about 2.1M sentence pairs in the training set after preprocessing. We learn a joint BPE model with 32K subword units (Sennrich et al., 2016). We employ the models that have the best perplexity on the validation set for the evaluation. We set the beam size to 8 during inference. To test the universality of our findings, we conduct experiments on DE→EN and ZH→EN as well. For DE→EN, we use the training data from the WMT17 shared task (Bojar et al., 2017). We use newstest2013 as the validation set and newstest2017 as the test set. We learn a joint BPE model with 32k subword units. For"
R19-1136,P16-1162,1,0.372616,"tial learning rate is set to 0.0001. If the performance on the validation set has not improved for 8 checkpoints, the learning rate is multiplied by 0.7. We set the early stopping patience to 32 checkpoints. The training data is from the WMT15 shared task (Bojar et al., 2015) on Finnish–English (FI– EN). We choose newsdev2015 as the validation set and use newstest2015 as the test set. All the BLEU (Papineni et al., 2002) scores are measured by SacreBLEU (Post, 2018). There are about 2.1M sentence pairs in the training set after preprocessing. We learn a joint BPE model with 32K subword units (Sennrich et al., 2016). We employ the models that have the best perplexity on the validation set for the evaluation. We set the beam size to 8 during inference. To test the universality of our findings, we conduct experiments on DE→EN and ZH→EN as well. For DE→EN, we use the training data from the WMT17 shared task (Bojar et al., 2017). We use newstest2013 as the validation set and newstest2017 as the test set. We learn a joint BPE model with 32k subword units. For ZH→EN, we choose the CWMT parallel data of the WMT17 shared task for training. We use newsdev2017 as the validation set and newstest2017 as the test set"
R19-1136,D18-1458,1,0.905703,"Missing"
R19-1136,W18-6304,1,0.912854,"inese and English separately. There are about 5.9M and 9M sentence pairs in the training set after preprocessing in DE→EN and ZH→EN, respectively. 3.2 Results Table 1 shows the performance of all the trained models. Encoder-free models (NMT-noEncs) perform rather poorly compared to conventional NMT models.3 It is interesting that Trans-noEnc obtains a BLEU score similar to the RNNS2S model. Even though the attention networks only attend to the non-contextualized word embeddings, Trans-noEnc still performs as well as the RNNS2S by paying attention to the context with multiple attention layers. Tang et al. (2018a) find that the superiority of Transformer models is attributed to the self-attention network which is a powerful semantic feature extractor. Given our results, we conclude that the attention mechanism is also a strong feature extractor in Trans-noEnc without self-attention in the encoder. Model Transformer Trans-noEnc RNNS2S RNNS2S-noEnc RNNS2S-noAtt RNNS2S-noAtt-noEnc Trans-noEnc-noPos Param. 104.4M 71.4M 91.5M 64.3M 90.3M 63.1M 71.4M PPL 9.6 11.7 14.9 25.2 33.3 53.7 26.6 BLEU 18.9 15.9 15.9 12.5 8.2 4.1 7.1 Table 1: The performance of NMT models. PPL is the perplexity on the development se"
R19-1136,P18-2060,0,0.0312967,"e linguistically plausible explanations in some cases – when translating a verb, knowledge about the subject, object etc. may be relevant information – other cases are harder to explain, such as an off-by-one mismatch between attention and word alignment for some models. We suspect that such a pattern can be learned if relevant information is passed to neighboring representations via recurrent or self-attentional connections. Ding et al. (2017) show that only using attention is not sufficient for deep interpretation and propose to use layer-wise relevance propagation to better understand NMT. Wang et al. (2018) replace the attention model with an alignment model and a lexical model to make NMT models more interpretable. The proposed model is not superior but on a par with the attentional model. They clarify the difference between alignment models and attention models by saying that that the alignment model is to identify translation equivalents while the attention model is to predict the next target word. In this paper, we try to understand NMT by simplifying the model. We explore the importance of different NMT components and what causes the performance gap after model simplification. 2.2 Alignment"
seraji-etal-2012-basic,nivre-etal-2006-maltparser,1,\N,Missing
seraji-etal-2012-basic,W08-1301,0,\N,Missing
seraji-etal-2012-basic,W03-2904,0,\N,Missing
seraji-etal-2012-basic,W11-4654,1,\N,Missing
seraji-etal-2014-persian,de-marneffe-etal-2006-generating,0,\N,Missing
seraji-etal-2014-persian,nivre-etal-2006-maltparser,1,\N,Missing
seraji-etal-2014-persian,W09-2307,0,\N,Missing
seraji-etal-2014-persian,W06-2920,0,\N,Missing
seraji-etal-2014-persian,W08-1301,0,\N,Missing
seraji-etal-2014-persian,N13-1031,0,\N,Missing
seraji-etal-2014-persian,P13-2103,0,\N,Missing
seraji-etal-2014-persian,seraji-etal-2012-basic,1,\N,Missing
W01-1720,J95-4004,0,0.214148,"Missing"
W01-1720,J90-2002,0,0.0443976,"Missing"
W01-1720,A92-1018,0,0.180103,"Missing"
W01-1720,P95-1037,0,0.133805,"Missing"
W01-1720,J94-2001,0,0.0961531,"Missing"
W01-1720,J95-2002,0,0.101623,"Missing"
W03-3017,W98-0507,0,0.253983,"ependency-based representations have turned out to be useful in statistical approaches to parsing and disambiguation (see, e.g., Collins [4, 5, 6], Eisner [15, 16, 17], Samuelsson [25]) and they also appear well suited for languages with less rigid word order constraints (Covington [9, 10], Collins et al. [7]). Several dierent parsing techniques have been used with dependency grammar. The most common approach is probably to use some version of the dynamic programming algorithms familiar from context-free parsing, with or without statistical disambiguation (Eisner [15, 16, 17], Barbero et al. [2], Courtin and Genthial [8], Samuelsson [25]). Another school proposes that dependency parsing should be cast as a constraint satisfaction problem and solved using constraint programming (Maruyama [22], Menzel and Schröder [24], Duchier [12, 13, 14]). Here I will instead pursue a deterministic approach to dependency parsing, similar to shiftreduce parsing for context-free grammar. In the past, deterministic parsing of natural language has mostly been motivated by psycholinguistic concerns, as in the well-known Parsifal system of Marcus [21]. However, deterministic parsing also has the more dire"
W03-3017,P96-1025,0,0.00852743,"Missing"
W03-3017,P97-1003,0,0.019145,"Missing"
W03-3017,P99-1065,0,0.0294603,"entences were used as input to the parser. This means that the vocabulary of the grammar consists of word-tag pairs, although most of the grammar rules used only take parts of speech into account. The grammar used in the experiment is hand-crafted and contains a total of 126 rules, divided into 90 left-headed rules (of the form rules (of the form w w0 ). w ! w0 ) and 36 right-headed Parser Mean Std Baseline 80.0 13.2 S/R 87.8 11.0 S/RA 89.0 10.6 Table 1: Attachment scores (mean and standard deviation) Parsing accuracy was measured by the attachment score used by Eisner [15] and Collins et al. [7], which is computed as the proportion of words in a sentence that is assigned the correct head (or no head if the word is a root). The overall attachment score was then calculated as the mean attachment score over all sentences in the sample. As mentioned in the previous section, dierent scheduling policies for the parser transitions yield dierent deterministic parsers. In this experiment, three dierent versions of the parser were compared:  The baseline parser uses the constant priority ordering of transitions dened in section 3 Left-Arc  &gt; Right-Arc &gt; Reduce &gt; Shift (cf. also Figure 3)"
W03-3017,W98-0511,0,0.282217,"tions have turned out to be useful in statistical approaches to parsing and disambiguation (see, e.g., Collins [4, 5, 6], Eisner [15, 16, 17], Samuelsson [25]) and they also appear well suited for languages with less rigid word order constraints (Covington [9, 10], Collins et al. [7]). Several dierent parsing techniques have been used with dependency grammar. The most common approach is probably to use some version of the dynamic programming algorithms familiar from context-free parsing, with or without statistical disambiguation (Eisner [15, 16, 17], Barbero et al. [2], Courtin and Genthial [8], Samuelsson [25]). Another school proposes that dependency parsing should be cast as a constraint satisfaction problem and solved using constraint programming (Maruyama [22], Menzel and Schröder [24], Duchier [12, 13, 14]). Here I will instead pursue a deterministic approach to dependency parsing, similar to shiftreduce parsing for context-free grammar. In the past, deterministic parsing of natural language has mostly been motivated by psycholinguistic concerns, as in the well-known Parsifal system of Marcus [21]. However, deterministic parsing also has the more direct practical advantage of"
W03-3017,C96-1058,0,0.517184,"Missing"
W03-3017,P90-1005,0,0.0591882,"appear well suited for languages with less rigid word order constraints (Covington [9, 10], Collins et al. [7]). Several dierent parsing techniques have been used with dependency grammar. The most common approach is probably to use some version of the dynamic programming algorithms familiar from context-free parsing, with or without statistical disambiguation (Eisner [15, 16, 17], Barbero et al. [2], Courtin and Genthial [8], Samuelsson [25]). Another school proposes that dependency parsing should be cast as a constraint satisfaction problem and solved using constraint programming (Maruyama [22], Menzel and Schröder [24], Duchier [12, 13, 14]). Here I will instead pursue a deterministic approach to dependency parsing, similar to shiftreduce parsing for context-free grammar. In the past, deterministic parsing of natural language has mostly been motivated by psycholinguistic concerns, as in the well-known Parsifal system of Marcus [21]. However, deterministic parsing also has the more direct practical advantage of providing very ecient disambiguation. If the disambiguation can be performed with high accuracy and robustness, deterministic parsing becomes an interesting alternative to m"
W03-3017,W98-0509,0,0.028177,"nguages with less rigid word order constraints (Covington [9, 10], Collins et al. [7]). Several dierent parsing techniques have been used with dependency grammar. The most common approach is probably to use some version of the dynamic programming algorithms familiar from context-free parsing, with or without statistical disambiguation (Eisner [15, 16, 17], Barbero et al. [2], Courtin and Genthial [8], Samuelsson [25]). Another school proposes that dependency parsing should be cast as a constraint satisfaction problem and solved using constraint programming (Maruyama [22], Menzel and Schröder [24], Duchier [12, 13, 14]). Here I will instead pursue a deterministic approach to dependency parsing, similar to shiftreduce parsing for context-free grammar. In the past, deterministic parsing of natural language has mostly been motivated by psycholinguistic concerns, as in the well-known Parsifal system of Marcus [21]. However, deterministic parsing also has the more direct practical advantage of providing very ecient disambiguation. If the disambiguation can be performed with high accuracy and robustness, deterministic parsing becomes an interesting alternative to more traditional algorithms"
W03-3017,C00-2099,0,0.0346064,"Missing"
W03-3017,1993.iwpt-1.22,0,0.502011,"or branch point within this tradition. However, most researchers seem to agree that, even if the assumption of projectivity is questionable from a theoretical point of view, it is nevertheless a reasonable approximation in practical parsing systems. First of all, it must be noted that projectivity is not a property of the dependency graph in itself but only in relation to the linear ordering of tokens in the surface string. Several dierent denitions of projectivity can be found in the literature, but they are all roughly equivalent (see, e.g., Mel£uk [23], Hudson [20], Sleator and Temperley [27, 28]). I will follow Hudson [20] and dene projectivity in terms of an extended notion of adjacency: 1. A dependency graph is projective i every dependent node is graph adjacent to its head. 2. Two nodes n and n0 are graph adjacent i every node 0 surface string is dominated by n or n n00 occurring between n and n0 in the in the graph. Note that projectivity does not imply that the graph is connected; nor does it imply that the graph is acyclic (although it does exclude cycles of length greater than 2). We are now in a position to dene what we mean by a well-formed dependency graph:  n = (i; w)"
W04-0308,A00-2018,0,0.0299887,"etical in that it connects parsing to cognitive modeling, where there is psycholinguistic evidence suggesting that human parsing is largely incremental (Marslen-Wilson, 1973; Frazier, 1987). However, most state-of-the-art parsing methods today do not adhere to the principle of incrementality, for different reasons. Parsers that attempt to disambiguate the input completely — full parsing — typically first employ some kind of dynamic programming algorithm to derive a packed parse forest and then applies a probabilistic top-down model in order to select the most probable analysis (Collins, 1997; Charniak, 2000). Since the first step is essentially nondeterministic, this seems to rule out incrementality at least in a strict sense. By contrast, parsers that only partially disambiguate the input — partial parsing — are usually deterministic and construct the final analysis in one pass over the input (Abney, 1991; Daelemans et al., 1999). But since they normally output a sequence of unconnected phrases or chunks, they fail to satisfy the constraint of incrementality for a different reason. Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic parsing"
W04-0308,P97-1003,0,0.0223939,"n is more theoretical in that it connects parsing to cognitive modeling, where there is psycholinguistic evidence suggesting that human parsing is largely incremental (Marslen-Wilson, 1973; Frazier, 1987). However, most state-of-the-art parsing methods today do not adhere to the principle of incrementality, for different reasons. Parsers that attempt to disambiguate the input completely — full parsing — typically first employ some kind of dynamic programming algorithm to derive a packed parse forest and then applies a probabilistic top-down model in order to select the most probable analysis (Collins, 1997; Charniak, 2000). Since the first step is essentially nondeterministic, this seems to rule out incrementality at least in a strict sense. By contrast, parsers that only partially disambiguate the input — partial parsing — are usually deterministic and construct the final analysis in one pass over the input (Abney, 1991; Daelemans et al., 1999). But since they normally output a sequence of unconnected phrases or chunks, they fail to satisfy the constraint of incrementality for a different reason. Deterministic dependency parsing has recently been proposed as a robust and efficient method for s"
W04-0308,W99-0707,0,0.0715384,"ers that attempt to disambiguate the input completely — full parsing — typically first employ some kind of dynamic programming algorithm to derive a packed parse forest and then applies a probabilistic top-down model in order to select the most probable analysis (Collins, 1997; Charniak, 2000). Since the first step is essentially nondeterministic, this seems to rule out incrementality at least in a strict sense. By contrast, parsers that only partially disambiguate the input — partial parsing — are usually deterministic and construct the final analysis in one pass over the input (Abney, 1991; Daelemans et al., 1999). But since they normally output a sequence of unconnected phrases or chunks, they fail to satisfy the constraint of incrementality for a different reason. Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre, 2003). In some ways, this approach can be seen as a compromise between traditional full and partial parsing. Essentially, it is a kind of full parsing in that the goal is to build a complete syntactic analysis for the input string, not just identify major"
W04-0308,W04-2407,1,0.727921,"Missing"
W04-0308,W03-3017,1,0.905304,"to rule out incrementality at least in a strict sense. By contrast, parsers that only partially disambiguate the input — partial parsing — are usually deterministic and construct the final analysis in one pass over the input (Abney, 1991; Daelemans et al., 1999). But since they normally output a sequence of unconnected phrases or chunks, they fail to satisfy the constraint of incrementality for a different reason. Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre, 2003). In some ways, this approach can be seen as a compromise between traditional full and partial parsing. Essentially, it is a kind of full parsing in that the goal is to build a complete syntactic analysis for the input string, not just identify major constituents. But it resembles partial parsing in being robust, efficient and deterministic. Taken together, these properties seem to make dependency parsing suitable for incremental processing, although existing implementations normally do not satisfy this constraint. For example, Yamada and Matsumoto (2003) use a multipass bottom-up algorithm, c"
W04-0308,W03-3023,0,0.829227,"ondeterministic, this seems to rule out incrementality at least in a strict sense. By contrast, parsers that only partially disambiguate the input — partial parsing — are usually deterministic and construct the final analysis in one pass over the input (Abney, 1991; Daelemans et al., 1999). But since they normally output a sequence of unconnected phrases or chunks, they fail to satisfy the constraint of incrementality for a different reason. Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre, 2003). In some ways, this approach can be seen as a compromise between traditional full and partial parsing. Essentially, it is a kind of full parsing in that the goal is to build a complete syntactic analysis for the input string, not just identify major constituents. But it resembles partial parsing in being robust, efficient and deterministic. Taken together, these properties seem to make dependency parsing suitable for incremental processing, although existing implementations normally do not satisfy this constraint. For example, Yamada and Matsumoto (2003) use a multipass bottom-u"
W04-0308,J00-3002,0,\N,Missing
W04-2407,W03-3005,0,0.0204339,"rmedness conditions on dependency graphs Initialization hnil, W, ∅i Termination hS, nil, Ai Left-Arc hwi |S, wj |I, Ai → hS, wj |I, A ∪ {(wj , r, wi )}i ¬∃wk ∃r0 (wk , r0 , wi ) ∈ A Right-Arc hwi |S, wj |I, Ai → hwj |wi |S, I, A ∪ {(wi , r, wj )}i ¬∃wk ∃r0 (wk , r0 , wj ) ∈ A Reduce hwi |S, I, Ai → hS, I, Ai ∃wj ∃r(wj , r, wi ) ∈ A Shift hS, wi |I, Ai → hwi |S, I, Ai Figure 3: Parser transitions 2.3 Guided Parsing One way of turning a nondeterministic parser into a deterministic one is to use a guide (or oracle) that can inform the parser at each nondeterministic choice point; cf. Kay (2000), Boullier (2003). Guided parsing is normally used to improve the efficiency of a nondeterministic parser, e.g. by letting a simpler (but more efficient) parser construct a first analysis that can be used to guide the choice of the more complex (but less efficient) parser. This is the approach taken, for example, in Boullier (2003). In our case, we rather want to use the guide to improve the accuracy of a deterministic parser, starting from a baseline of randomized choice. One way of doing this is to use a treebank, i.e. a corpus of analyzed sentences, to train a classifier that can predict the next transition"
W04-2407,A00-2018,0,0.70002,"itting first the features TOP. LEFT and LOOK and then the features TOP. RIGHT and NEXT. LEFT; if even this does not help, the classifier predicts Reduce if permissible and Shift otherwise. This model, which we will refer to as the MCLE model, is described in more detail in Nivre (2004). 3.2 Data It is standard practice in data-driven approaches to natural language parsing to use treebanks both for training and evaluation. Thus, the Penn Treebank of American English (Marcus et al., 1993) has been used to train and evaluate the best available parsers of unrestricted English text (Collins, 1999; Charniak, 2000). One problem when developing a parser for Swedish is that there is no comparable large-scale treebank available for Swedish. For the experiments reported in this paper we have used a manually annotated corpus of written Swedish, created at Lund University in the 1970’s and consisting mainly of informative texts from official sources (Einarsson, 1976). Although the original annotation scheme is an eclectic combination of constituent structure, dependency structure, and topological fields (Teleman, 1974), it has proven possible to convert the annotated sentences to dependency graphs with fairly"
W04-2407,P99-1065,0,0.465604,"ependency graph, of the kind depicted in Figure 1. Deterministic parsing means that we always derive a single analysis for each input string. Moreover, this single analysis is derived in a monotonic fashion with no redundancy or backtracking, which makes it possible to parse natural language sentences in linear time (Nivre, 2003). In this paper, we report experiments using memorybased learning (Daelemans, 1999) to guide the parser described in Nivre (2003), using data from a small treebank of Swedish (Einarsson, 1976). Unlike most previous work on data-driven dependency parsing (Eisner, 1996; Collins et al., 1999; Yamada and Matsumoto, 2003; Nivre, 2003), we assume that dependency graphs are labeled with dependency types, although the evaluation will give results for both labeled and unlabeled representations. The paper is structured as follows. Section 2 gives the necessary background definitions and introduces the idea of guided parsing as well as memory-based learning. Section 3 describes the data used in the experiments, the evaluation metrics, and the models and algorithms used in the learning process. Results from the experiments are given in section 4, while conclusions and suggestions for furt"
W04-2407,C96-1058,0,0.865442,"construct a dependency graph, of the kind depicted in Figure 1. Deterministic parsing means that we always derive a single analysis for each input string. Moreover, this single analysis is derived in a monotonic fashion with no redundancy or backtracking, which makes it possible to parse natural language sentences in linear time (Nivre, 2003). In this paper, we report experiments using memorybased learning (Daelemans, 1999) to guide the parser described in Nivre (2003), using data from a small treebank of Swedish (Einarsson, 1976). Unlike most previous work on data-driven dependency parsing (Eisner, 1996; Collins et al., 1999; Yamada and Matsumoto, 2003; Nivre, 2003), we assume that dependency graphs are labeled with dependency types, although the evaluation will give results for both labeled and unlabeled representations. The paper is structured as follows. Section 2 gives the necessary background definitions and introduces the idea of guided parsing as well as memory-based learning. Section 3 describes the data used in the experiments, the evaluation metrics, and the models and algorithms used in the learning process. Results from the experiments are given in section 4, while conclusions an"
W04-2407,2000.iwpt-1.3,0,0.0709277,"e 2: Well-formedness conditions on dependency graphs Initialization hnil, W, ∅i Termination hS, nil, Ai Left-Arc hwi |S, wj |I, Ai → hS, wj |I, A ∪ {(wj , r, wi )}i ¬∃wk ∃r0 (wk , r0 , wi ) ∈ A Right-Arc hwi |S, wj |I, Ai → hwj |wi |S, I, A ∪ {(wi , r, wj )}i ¬∃wk ∃r0 (wk , r0 , wj ) ∈ A Reduce hwi |S, I, Ai → hS, I, Ai ∃wj ∃r(wj , r, wi ) ∈ A Shift hS, wi |I, Ai → hwi |S, I, Ai Figure 3: Parser transitions 2.3 Guided Parsing One way of turning a nondeterministic parser into a deterministic one is to use a guide (or oracle) that can inform the parser at each nondeterministic choice point; cf. Kay (2000), Boullier (2003). Guided parsing is normally used to improve the efficiency of a nondeterministic parser, e.g. by letting a simpler (but more efficient) parser construct a first analysis that can be used to guide the choice of the more complex (but less efficient) parser. This is the approach taken, for example, in Boullier (2003). In our case, we rather want to use the guide to improve the accuracy of a deterministic parser, starting from a baseline of randomized choice. One way of doing this is to use a treebank, i.e. a corpus of analyzed sentences, to train a classifier that can predict th"
W04-2407,J93-2004,0,0.0272075,"Missing"
W04-2407,W03-3017,1,0.780684,"is evaluated on held-out data derived from the treebank, and its performance as a parser guide is evaluated by parsing the held-out portion of the treebank. The evaluation shows that memory-based learning gives a signficant improvement over a previous probabilistic model based on maximum conditional likelihood estimation and that the inclusion of lexical features improves the accuracy even further. 1 Introduction Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre, 2003). Dependency parsing means that the goal of the parsing process is to construct a dependency graph, of the kind depicted in Figure 1. Deterministic parsing means that we always derive a single analysis for each input string. Moreover, this single analysis is derived in a monotonic fashion with no redundancy or backtracking, which makes it possible to parse natural language sentences in linear time (Nivre, 2003). In this paper, we report experiments using memorybased learning (Daelemans, 1999) to guide the parser described in Nivre (2003), using data from a small treebank of Swedish (Einarsson,"
W04-2407,W03-3018,0,0.0133182,"003). 2.2 Parsing Algorithm The parsing algorithm presented in Nivre (2003) is in many ways similar to the basic shift-reduce algorithm for context-free grammars (Aho et al., 1986), although the parse actions are different given that no nonterminal symbols are used. Moreover, unlike the algorithm of Yamada and Matsumoto (2003), the algorithm considered here actually uses a blend of bottom-up and top-down processing, constructing left-dependencies bottom-up and rightdependencies top-down, in order to achieve incrementality. For a similar but nondeterministic approach to dependency parsing, see Obrebski (2003). Parser configurations are represented by triples hS, I, Ai, where S is the stack (represented as a list), I is the list of (remaining) input tokens, and A is the (current) arc relation for the dependency graph. Given an input string W , the parser is initialized to hnil, W, ∅i and terminates when it reaches a configuration hS, nil, Ai (for any list S and set of arcs A). The input string W is accepted if the dependency graph D = (W, A) given at termination is well-formed; otherwise W is rejected. The behavior of the parser is defined by the transitions defined in Figure 3 (where wi , wj and w"
W04-2407,H92-1086,0,0.0124214,"reported in this paper, we apply memorybased learning within a deterministic dependency parsing framework. 2.4 Memory-Based Learning Memory-based learning and problem solving is based on two fundamental principles: learning is the simple storage of experiences in memory, and solving a new problem is achieved by reusing solutions from similar previously solved problems (Daelemans, 1999). It is inspired by the nearest neighbor approach in statistical pattern recognition and artificial intelligence (Fix and Hodges, 1952), as well as the analogical modeling approach in linguistics (Skousen, 1989; Skousen, 1992). In machine learning terms, it can be characterized as a lazy learning method, since it defers processing of input until needed and processes input by combining stored data (Aha, 1997). Memory-based learning has been successfully applied to a number of problems in natural language processing, such as grapheme-to-phoneme conversion, partof-speech tagging, prepositional-phrase attachment, and base noun phrase chunking (Daelemans et al., 2002). Most relevant in the present context is the use of memorybased learning to predict the actions of a shift-reduce parser, with promising results reported"
W04-2407,W03-3023,0,0.861337,"racy of a classifier as such is evaluated on held-out data derived from the treebank, and its performance as a parser guide is evaluated by parsing the held-out portion of the treebank. The evaluation shows that memory-based learning gives a signficant improvement over a previous probabilistic model based on maximum conditional likelihood estimation and that the inclusion of lexical features improves the accuracy even further. 1 Introduction Deterministic dependency parsing has recently been proposed as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre, 2003). Dependency parsing means that the goal of the parsing process is to construct a dependency graph, of the kind depicted in Figure 1. Deterministic parsing means that we always derive a single analysis for each input string. Moreover, this single analysis is derived in a monotonic fashion with no redundancy or backtracking, which makes it possible to parse natural language sentences in linear time (Nivre, 2003). In this paper, we report experiments using memorybased learning (Daelemans, 1999) to guide the parser described in Nivre (2003), using data from a small treebank of Swedi"
W04-2407,J03-4003,0,\N,Missing
W05-1708,H92-1026,0,0.255148,"e models and learning methods. Data-driven dependency parsing has recently been explored as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre et al., 2004). Dependency parsing means that the goal of the parsing process is to construct a dependency graph, of the kind depicted in Figure 1. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based feature models for predicting the next parser action (Black et al., 1992) 3. Discriminative machine learning to map histories to parser actions (Yamada and Matsumoto, 2003; Nivre et al., 2004) Given the restriction imposed by these components, we present a software design for datadriven dependency parsing of unrestricted natural language text. The most important feature of the design is a clean separation of parsing algorithms, feature models, and learning methods, so that these components can be varied independently of each other. Moreover, the design makes it possible to use the same basic components both for inducing a model from treebank data in the learning ph"
W05-1708,P99-1065,0,0.0243937,"The design has been realized in MaltParser, which supports several parsing algorithms and learning methods, for which complex feature models can be defined in a special description language. 1 Introduction One of the advantages of data-driven approaches to syntactic parsing is the relative ease with which they can be ported to new languages or domains, provided that the necessary linguistic data resources are available. Thus, the parser of Collins (1999), originally developed for English and trained on Wall Street Journal data, has been successfully applied to languages as different as Czech (Collins et al., 1999) and Chinese (Sun and Jurafsky, 2004). However, most available systems for data-driven syntactic parsing lack another kind of flexibility, namely the possibility to combine different parsing algorithms with different feature models and learning methods. Data-driven dependency parsing has recently been explored as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre et al., 2004). Dependency parsing means that the goal of the parsing process is to construct a dependency graph, of the kind depicted in Figure 1. The methodolo"
W05-1708,W00-1303,0,0.0259251,"is learning algorithm, and supports all the options provided by that package. Support Vector Machines (SVMs) was formulated in the late seventies by Vapnik (1979), but the main development as a machine learning approach has taken place in the last decade. SVMs have been used for many pattern recognition problems. In the field of natural language Hall & Nivre: A generic architecture for data-driven dependency parsing 54 Proceedings of the 15th NODALIDA conference, Joensuu 2005 processing, SVMs have been used for example for text categorization (Joachims, 1998) and syntactic dependency parsing (Kudo and Matsumoto, 2000). SVMs rely on kernel functions to induce a maximum-margin hyperplane classifier at learning time, which can be used to predict the next action at parsing time. MaltParser uses the library LIBSVM (Wu et al., 2004) to implement this algorithm with all the options provided by this library. 5 Conclusion We have presented a generic architecture for data-driven dependency parsing that provides a strict modularization of parsing algorithm, feature model and learning method. The main advantage of this design is that these three dimensions can be varied independently of each other, but the design also"
W05-1708,P95-1037,0,0.0399286,". A formal model M defining permissible representations for sentences (such as the model of dependency graphs defined above). 2. A parameterized stochastic model MΘ , defining a score S(x, y) for every sentence x and well-formed representation y . 3. An inductive learning algorithm L for estimating the parameters Θ from a representative sample Tt = (x1 : y1 , . . . , xn : yn ) of sentences with their correct representations (normally a treebank sample). Inductive dependency parsing is compatible with a variety of different models, but we focus here on history-based models (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999), which can be defined in three steps: each decision di in the decision sequence D = (d1 , . . . , dm ), conditioned on the history H = (d1 , . . . , di−1 ). 3. Define a function Φ that groups histories into equivalence classes, thereby reducing the number of parameters in Θ. In a conditional history-based model, the score S(x, y) defined by the model is the conditional probability P (y |x) of the analysis y given the sentence x, which means that the input sentence is a conditioning variable for each decision in the decision sequence: P (y |x) = P (d1 , . . ."
W05-1708,W04-2407,1,0.799736,"99), originally developed for English and trained on Wall Street Journal data, has been successfully applied to languages as different as Czech (Collins et al., 1999) and Chinese (Sun and Jurafsky, 2004). However, most available systems for data-driven syntactic parsing lack another kind of flexibility, namely the possibility to combine different parsing algorithms with different feature models and learning methods. Data-driven dependency parsing has recently been explored as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre et al., 2004). Dependency parsing means that the goal of the parsing process is to construct a dependency graph, of the kind depicted in Figure 1. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based feature models for predicting the next parser action (Black et al., 1992) 3. Discriminative machine learning to map histories to parser actions (Yamada and Matsumoto, 2003; Nivre et al., 2004) Given the restriction imposed by these components, we present a software design for datadri"
W05-1708,W03-3017,1,0.894206,"namely the possibility to combine different parsing algorithms with different feature models and learning methods. Data-driven dependency parsing has recently been explored as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre et al., 2004). Dependency parsing means that the goal of the parsing process is to construct a dependency graph, of the kind depicted in Figure 1. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based feature models for predicting the next parser action (Black et al., 1992) 3. Discriminative machine learning to map histories to parser actions (Yamada and Matsumoto, 2003; Nivre et al., 2004) Given the restriction imposed by these components, we present a software design for datadriven dependency parsing of unrestricted natural language text. The most important feature of the design is a clean separation of parsing algorithms, feature models, and learning methods, so that these components can be varied independently of each other. Moreover, the design makes it possible to us"
W05-1708,W04-0308,1,0.783867,"XML format. The latter is an XML version of the Malt-TAB format. In the sections below, we describe the main components in the architecture from the point of view of how they are implemented in the MaltParser system. 4.1 Parser The user of MaltParser can choose between several deterministic parsing algorithms, including the algorithms described by Nivre (2003; 2004) and the incremental parsing algorithms described by Covington (2001). Ling@JoY 1, 2006 Nivre’s algorithm is a linear-time algorithm limited to projective dependency structures. It can be run in arc-eager or arc-standard mode (cf. (Nivre, 2004)). Covington’s algorithm is a quadratic-time algorithm for unrestricted dependency structures, which proceeds by trying to link each new token to each preceding token. It can be run in a projective mode, where the linking operation is restricted to projective dependency structures, or in a non-projective mode, allowing non-projective (but acyclic) dependency structures. 4.2 Guide The MaltParser system comes with a formal specification language for feature functions, which enables the user to define arbitrarily complex feature models in terms of address functions, attribute functions and mappin"
W05-1708,W97-0301,0,0.0183835,"M defining permissible representations for sentences (such as the model of dependency graphs defined above). 2. A parameterized stochastic model MΘ , defining a score S(x, y) for every sentence x and well-formed representation y . 3. An inductive learning algorithm L for estimating the parameters Θ from a representative sample Tt = (x1 : y1 , . . . , xn : yn ) of sentences with their correct representations (normally a treebank sample). Inductive dependency parsing is compatible with a variety of different models, but we focus here on history-based models (Black et al., 1992; Magerman, 1995; Ratnaparkhi, 1997; Collins, 1999), which can be defined in three steps: each decision di in the decision sequence D = (d1 , . . . , dm ), conditioned on the history H = (d1 , . . . , di−1 ). 3. Define a function Φ that groups histories into equivalence classes, thereby reducing the number of parameters in Θ. In a conditional history-based model, the score S(x, y) defined by the model is the conditional probability P (y |x) of the analysis y given the sentence x, which means that the input sentence is a conditioning variable for each decision in the decision sequence: P (y |x) = P (d1 , . . . , dm |x) = m Y P ("
W05-1708,W03-3023,0,0.0239294,"s, the parser of Collins (1999), originally developed for English and trained on Wall Street Journal data, has been successfully applied to languages as different as Czech (Collins et al., 1999) and Chinese (Sun and Jurafsky, 2004). However, most available systems for data-driven syntactic parsing lack another kind of flexibility, namely the possibility to combine different parsing algorithms with different feature models and learning methods. Data-driven dependency parsing has recently been explored as a robust and efficient method for syntactic parsing of unrestricted natural language text (Yamada and Matsumoto, 2003; Nivre et al., 2004). Dependency parsing means that the goal of the parsing process is to construct a dependency graph, of the kind depicted in Figure 1. The methodology is based on three essential components: 1. Deterministic parsing algorithms for building dependency graphs (Yamada and Matsumoto, 2003; Nivre, 2003) 2. History-based feature models for predicting the next parser action (Black et al., 1992) 3. Discriminative machine learning to map histories to parser actions (Yamada and Matsumoto, 2003; Nivre et al., 2004) Given the restriction imposed by these components, we present a softwa"
W06-2933,E06-1012,1,0.814664,"Missing"
W06-2933,W02-2016,0,0.0490859,"the parser. We present evaluation results and an error analysis focusing on Swedish and Turkish. 1 Introduction The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data. Our methodology for performing this task is based on four essential components: • A deterministic algorithm for building labeled projective dependency graphs (Nivre, 2006). • History-based feature models for predicting the next parser action (Black et al., 1992). • Support vector machines for mapping histories to parser actions (Kudo and Matsumoto, 2002). • Graph transformations for recovering nonprojective structures (Nivre and Nilsson, 2005). All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1 1 www.msi.vxu.se/users/nivre/research/MaltParser.html Parsing Methodology Parsing Algorithm The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004). The algorithm builds a l"
W06-2933,P05-1013,1,0.532688,"kish. 1 Introduction The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data. Our methodology for performing this task is based on four essential components: • A deterministic algorithm for building labeled projective dependency graphs (Nivre, 2006). • History-based feature models for predicting the next parser action (Black et al., 1992). • Support vector machines for mapping histories to parser actions (Kudo and Matsumoto, 2002). • Graph transformations for recovering nonprojective structures (Nivre and Nilsson, 2005). All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1 1 www.msi.vxu.se/users/nivre/research/MaltParser.html Parsing Methodology Parsing Algorithm The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store pa"
W06-2933,afonso-etal-2002-floresta,0,0.0180917,"Missing"
W06-2933,W03-2405,0,0.0151541,"Missing"
W06-2933,H92-1026,0,0.0219311,"raining data for the classifiers and applying an inverse transformation to the output of the parser. We present evaluation results and an error analysis focusing on Swedish and Turkish. 1 Introduction The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data. Our methodology for performing this task is based on four essential components: • A deterministic algorithm for building labeled projective dependency graphs (Nivre, 2006). • History-based feature models for predicting the next parser action (Black et al., 1992). • Support vector machines for mapping histories to parser actions (Kudo and Matsumoto, 2002). • Graph transformations for recovering nonprojective structures (Nivre and Nilsson, 2005). All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1 1 www.msi.vxu.se/users/nivre/research/MaltParser.html Parsing Methodology Parsing Algorithm The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (200"
W06-2933,dzeroski-etal-2006-towards,0,0.0501737,"Missing"
W06-2933,W04-2407,1,0.792788,"to parser actions (Kudo and Matsumoto, 2002). • Graph transformations for recovering nonprojective structures (Nivre and Nilsson, 2005). All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1 1 www.msi.vxu.se/users/nivre/research/MaltParser.html Parsing Methodology Parsing Algorithm The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and adding arcs using four elementary actions (where top is the token on top of the stack and next is the next token): • S HIFT: Push next onto the stack. • R EDUCE: Pop the stack. • R IGHT-A RC (r): Add an arc labeled r from top to next; push next onto the stack. • L EFT-A RC (r): Add an arc labeled r from next to top; pop the stack. Although the parser only derives projective graphs, the fact that graphs are labeled allows non-projective dependencies t"
W06-2933,nivre-etal-2006-maltparser,1,0.676158,"le languages using a single dependency parser that has the capacity to learn from treebank data. Our methodology for performing this task is based on four essential components: • A deterministic algorithm for building labeled projective dependency graphs (Nivre, 2006). • History-based feature models for predicting the next parser action (Black et al., 1992). • Support vector machines for mapping histories to parser actions (Kudo and Matsumoto, 2002). • Graph transformations for recovering nonprojective structures (Nivre and Nilsson, 2005). All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1 1 www.msi.vxu.se/users/nivre/research/MaltParser.html Parsing Methodology Parsing Algorithm The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and adding arcs using four elementary actions (whe"
W06-2933,W03-3017,1,0.778197,"al., 1992). • Support vector machines for mapping histories to parser actions (Kudo and Matsumoto, 2002). • Graph transformations for recovering nonprojective structures (Nivre and Nilsson, 2005). All experiments have been performed using MaltParser (Nivre et al., 2006), version 0.4, which is made available together with the suite of programs used for pre- and post-processing.1 1 www.msi.vxu.se/users/nivre/research/MaltParser.html Parsing Methodology Parsing Algorithm The parsing algorithm used for all languages is the deterministic algorithm first proposed for unlabeled dependency parsing by Nivre (2003) and extended to labeled dependency parsing by Nivre et al. (2004). The algorithm builds a labeled dependency graph in one left-to-right pass over the input, using a stack to store partially processed tokens and adding arcs using four elementary actions (where top is the token on top of the stack and next is the next token): • S HIFT: Push next onto the stack. • R EDUCE: Pop the stack. • R IGHT-A RC (r): Add an arc labeled r from top to next; push next onto the stack. • L EFT-A RC (r): Add an arc labeled r from next to top; pop the stack. Although the parser only derives projective graphs, the"
W06-2933,W03-2403,0,0.0419858,"Missing"
W06-2933,W03-3023,0,0.793427,"Missing"
W06-2933,E06-1011,0,\N,Missing
W06-2933,W05-1505,0,\N,Missing
W06-2933,C04-1040,0,\N,Missing
W06-2933,J03-4003,0,\N,Missing
W06-2933,H05-1066,0,\N,Missing
W06-2933,C04-1010,1,\N,Missing
W06-2933,P93-1005,0,\N,Missing
W07-2220,W06-2920,0,0.0430463,"he same column-based format for labeled data with six input columns and two output columns for each word of a sentence: • Input: word-id, word form, lemma, coarse part of speech, fine part-of-speech, morphosyntactic features. Introduction The annual Conference on Computational Natural Language Learning (CoNLL) has for the past nine years organized a shared task, where participants train and test their learning systems on the same data sets. In 2006, the shared task was multilingual dependency parsing, where participants had to train and test a parser on data from thirteen different languages (Buchholz and Marsi, 2006). In 2007, the task was extended by adding a second track for (monolingual) domain adaptation. The CoNLL 2007 shared task on dependency parsing featured two tracks: • In the multilingual track, the task was to train a parser using labeled data from Arabic, Basque, Catalan, Chinese, Czech, English, Greek, Hungarian, Italian, and Turkish. • In the domain adaptation track, the task was to adapt a parser for English news text to other • Output: head (word-id), dependency label. The main evaluation metric for both tracks was the labeled attachment score (LAS), i.e., the percentage of words that hav"
W07-2220,D07-1101,0,0.0174559,"cDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based mode"
W07-2220,E06-1011,0,0.0141761,"d Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically"
W07-2220,H05-1066,0,0.120826,"Missing"
W07-2220,P05-1013,1,0.892206,"Missing"
W07-2220,W03-3017,1,0.833736,"e two dominant approaches in data-driven dependency parsing in recent years (McDonald and Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away f"
W07-2220,N06-2033,0,0.0137312,"best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et al., 2007a) and the domain adaptation track (Sagae and Tsujii, 2007). 169 Multilingual Parsing The ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: • Low (LAS = 76.3–76.9): Arabic, Basque, Greek • Medium (LAS = 79.2–80.2): Czech, Hungarian, Turkish • High (LAS = 84.4–89.6): Catalan, Chinese, English, Italian To a large extent, these classes appear to be definable from typological properties. The class with the highest top scores"
W07-2220,D07-1111,0,0.0582374,"s clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et al., 2007a) and the domain adaptation track (Sagae and Tsujii, 2007). 169 Multilingual Parsing The ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: • Low (LAS = 76.3–76.9): Arabic, Basque, Greek • Medium (LAS = 79.2–80.2): Czech, Hungarian, Turkish • High (LAS = 84.4–89.6): Catalan, Chinese, English, Italian To a large extent, these classes appear to be definable from typological properties. The class with the highest top scores contains languages with a rather impoverished morphology. Medium scores are reached by the two agglutinative languages, Hungarian and Turkish, as wel"
W07-2220,D07-1099,0,0.0135427,"loring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly to move away from deterministic parsing by adding a probability model for scoring a set of candidate parses typically derived using a heuristic search strategy. The probability model may be either conditional (Duan et al., 2007) or generative (Titov and Henderson, 2007). An interesting way of combining the two main approaches is to use a graph-based model to build an ensemble of transition-based parsers. This technique, first proposed by Sagae and Lavie (2006), was used in the highest scoring system in both the multilingual track (Hall et al., 2007a) and the domain adaptation track (Sagae and Tsujii, 2007). 169 Multilingual Parsing The ten languages involved in the multilingual track can be grouped into three classes with respect to the best parsing accuracy achieved: • Low (LAS = 76.3–76.9): Arabic, Basque, Greek • Medium (LAS = 79.2–80.2): Czech, Hungarian"
W07-2220,W03-3023,0,0.0521451,"odels belonging to one of the two dominant approaches in data-driven dependency parsing in recent years (McDonald and Nivre, 2007): • In graph-based models, every possible dependency graph for a given input sentence is given a score that decomposes into scores for the arcs of the graph. The optimal parse can be found using a spanning tree algorithm (Eisner, 1996; McDonald et al., 2005). • In transition-based models, dependency graphs are modeled by sequences of parsing actions (or transitions) for building them. The search for an optimal parse is often deterministic and guided by classifiers (Yamada and Matsumoto, 2003; Nivre, 2003). The majority of graph-based parsers in the shared task were based on what McDonald and Pereira (2006) call the first-order model, where the score of each arc is independent of every other arc, but there were also attempts at exploring higher-order models, either with exact inference limited to projective dependency graphs (Carreras, 2007), or with approximate inference (Nakagawa, 2007). Another innovation was the use of k-best spanning tree algorithms for inference with a non-projective first-order model (Hall et al., 2007b). For transition-based parsers, the trend was clearly"
W07-2220,D07-1102,0,\N,Missing
W07-2220,D07-1013,1,\N,Missing
W07-2220,D07-1097,1,\N,Missing
W07-2220,C96-1058,0,\N,Missing
W07-2220,D07-1098,0,\N,Missing
W07-2220,D07-1096,1,\N,Missing
W07-2444,A00-2018,0,0.194401,", it is quite clear that they provide partly independent, complementary views of syntactic structure. It is therefore increasingly common that syntactic representations combine elements of both, in particular in annotation schemes for treebanks, such as the TIGER Treebank for German (Brants et al., 2002), the Alpino Treebank for Dutch (Van der Beek et al., 2002), and Talbanken05 for Swedish (Nivre et al., 2006c). However, there are not many parsers available that can produce hybrid constituency-dependency representations. Widely used statistical parsers, like those of Collins (1997; 1999) and Charniak (2000) output a pure constituency representation (despite making heavy use of lexical dependencies for internal processing) and have to rely on post-processing to add information about grammatical functions (Blaheta and Charniak, 2000). More recently, Gabbard et al. (2006) have shown how a version of the Collins parser can be used to derive the full Penn Treebank annotation including both constituent structure and grammatical function tags. It is also worth mentioning that many grammar-driven parsers, based on frameworks such as LFG (Riezler et al., 2002) and HPSG (Toutanova et al., 2002), produce r"
W07-2444,P97-1003,0,0.182313,"still a matter of debate, it is quite clear that they provide partly independent, complementary views of syntactic structure. It is therefore increasingly common that syntactic representations combine elements of both, in particular in annotation schemes for treebanks, such as the TIGER Treebank for German (Brants et al., 2002), the Alpino Treebank for Dutch (Van der Beek et al., 2002), and Talbanken05 for Swedish (Nivre et al., 2006c). However, there are not many parsers available that can produce hybrid constituency-dependency representations. Widely used statistical parsers, like those of Collins (1997; 1999) and Charniak (2000) output a pure constituency representation (despite making heavy use of lexical dependencies for internal processing) and have to rely on post-processing to add information about grammatical functions (Blaheta and Charniak, 2000). More recently, Gabbard et al. (2006) have shown how a version of the Collins parser can be used to derive the full Penn Treebank annotation including both constituent structure and grammatical function tags. It is also worth mentioning that many grammar-driven parsers, based on frameworks such as LFG (Riezler et al., 2002) and HPSG (Toutano"
W07-2444,N06-1024,0,0.0793697,"ER Treebank for German (Brants et al., 2002), the Alpino Treebank for Dutch (Van der Beek et al., 2002), and Talbanken05 for Swedish (Nivre et al., 2006c). However, there are not many parsers available that can produce hybrid constituency-dependency representations. Widely used statistical parsers, like those of Collins (1997; 1999) and Charniak (2000) output a pure constituency representation (despite making heavy use of lexical dependencies for internal processing) and have to rely on post-processing to add information about grammatical functions (Blaheta and Charniak, 2000). More recently, Gabbard et al. (2006) have shown how a version of the Collins parser can be used to derive the full Penn Treebank annotation including both constituent structure and grammatical function tags. It is also worth mentioning that many grammar-driven parsers, based on frameworks such as LFG (Riezler et al., 2002) and HPSG (Toutanova et al., 2002), produce representations that combine elements of constituency and dependency. In this paper, we show how hybrid representations can be parsed in a dependency-based encoding inspired by Collins (1999). We evaluate the technique using an existing data-driven dependency parser ("
W07-2444,nivre-etal-2006-maltparser,1,0.923391,"duction Most natural language parsers use representations that are based on constituency or dependency. While the relative merits of constituency and dependency representations are still a matter of debate, it is quite clear that they provide partly independent, complementary views of syntactic structure. It is therefore increasingly common that syntactic representations combine elements of both, in particular in annotation schemes for treebanks, such as the TIGER Treebank for German (Brants et al., 2002), the Alpino Treebank for Dutch (Van der Beek et al., 2002), and Talbanken05 for Swedish (Nivre et al., 2006c). However, there are not many parsers available that can produce hybrid constituency-dependency representations. Widely used statistical parsers, like those of Collins (1997; 1999) and Charniak (2000) output a pure constituency representation (despite making heavy use of lexical dependencies for internal processing) and have to rely on post-processing to add information about grammatical functions (Blaheta and Charniak, 2000). More recently, Gabbard et al. (2006) have shown how a version of the Collins parser can be used to derive the full Penn Treebank annotation including both constituent"
W07-2444,W06-2933,1,0.890569,"Missing"
W07-2444,nivre-etal-2006-talbanken05,1,0.788103,"duction Most natural language parsers use representations that are based on constituency or dependency. While the relative merits of constituency and dependency representations are still a matter of debate, it is quite clear that they provide partly independent, complementary views of syntactic structure. It is therefore increasingly common that syntactic representations combine elements of both, in particular in annotation schemes for treebanks, such as the TIGER Treebank for German (Brants et al., 2002), the Alpino Treebank for Dutch (Van der Beek et al., 2002), and Talbanken05 for Swedish (Nivre et al., 2006c). However, there are not many parsers available that can produce hybrid constituency-dependency representations. Widely used statistical parsers, like those of Collins (1997; 1999) and Charniak (2000) output a pure constituency representation (despite making heavy use of lexical dependencies for internal processing) and have to rely on post-processing to add information about grammatical functions (Blaheta and Charniak, 2000). More recently, Gabbard et al. (2006) have shown how a version of the Collins parser can be used to derive the full Penn Treebank annotation including both constituent"
W07-2444,P02-1035,0,0.0389169,"al parsers, like those of Collins (1997; 1999) and Charniak (2000) output a pure constituency representation (despite making heavy use of lexical dependencies for internal processing) and have to rely on post-processing to add information about grammatical functions (Blaheta and Charniak, 2000). More recently, Gabbard et al. (2006) have shown how a version of the Collins parser can be used to derive the full Penn Treebank annotation including both constituent structure and grammatical function tags. It is also worth mentioning that many grammar-driven parsers, based on frameworks such as LFG (Riezler et al., 2002) and HPSG (Toutanova et al., 2002), produce representations that combine elements of constituency and dependency. In this paper, we show how hybrid representations can be parsed in a dependency-based encoding inspired by Collins (1999). We evaluate the technique using an existing data-driven dependency parser (MaltParser), trained and tested on Swedish treebank data (Talbanken05). The results show that it is possible to derive hybrid constituency-dependency representations with only a marginal loss in accuracy compared to pure representations of either kind. The rest of the paper is structured"
W07-2444,A00-2031,0,0.022189,"ation schemes for treebanks, such as the TIGER Treebank for German (Brants et al., 2002), the Alpino Treebank for Dutch (Van der Beek et al., 2002), and Talbanken05 for Swedish (Nivre et al., 2006c). However, there are not many parsers available that can produce hybrid constituency-dependency representations. Widely used statistical parsers, like those of Collins (1997; 1999) and Charniak (2000) output a pure constituency representation (despite making heavy use of lexical dependencies for internal processing) and have to rely on post-processing to add information about grammatical functions (Blaheta and Charniak, 2000). More recently, Gabbard et al. (2006) have shown how a version of the Collins parser can be used to derive the full Penn Treebank annotation including both constituent structure and grammatical function tags. It is also worth mentioning that many grammar-driven parsers, based on frameworks such as LFG (Riezler et al., 2002) and HPSG (Toutanova et al., 2002), produce representations that combine elements of constituency and dependency. In this paper, we show how hybrid representations can be parsed in a dependency-based encoding inspired by Collins (1999). We evaluate the technique using an ex"
W07-2444,W06-2920,0,0.0793001,"Missing"
W07-2444,J03-4003,0,\N,Missing
W08-1007,W06-2920,0,0.0471256,"the constituent structures with a dependency-based algorithm. This paper is structured as follows. Section 2 briefly describes the MaltParser system, while section 3 continues with presenting the dependency parsing. Section 4 explains how a transition-based dependency-driven parser can be turned into a constituency parser. Section 5 presents the experimental evaluation and discusses the results. Finally section 6 concludes. 2 MaltParser MaltParser is a transition-based parsing system which was one of the top performing systems on multilingual dependency parsing in the CoNLL 2006 shared task (Buchholz and Marsi, 2006; Nivre et al., 2006) and the CoNLL shared task 2007 (Nivre et al., 2007; Hall et al., 2007). The basic idea of MaltParser is to derive dependency graphs using a greedy parsing algorithm that approximates a glob1 MaltParser is distributed with an open-source license and can be downloaded free of charge from following page: http://www.vxu.se/msi/users/jha/maltparser/ 47 Proceedings of the ACL-08: HLT Workshop on Parsing German (PaGe-08), pages 47–54, c Columbus, Ohio, USA, June 2008. 2008 Association for Computational Linguistics ally optimal solution by making a sequence of locally optimal cho"
W08-1007,P03-1013,0,0.151867,"Missing"
W08-1007,P05-1039,0,0.0390045,"Missing"
W08-1007,D07-1097,1,0.897037,"Missing"
W08-1007,W06-2932,0,0.0993673,"Missing"
W08-1007,P05-1013,1,0.919797,"wo German treebanks is that they Figure 1: The sentence ”For this statement has Beckmeyer until now not presented any evidence.” is taken from dependency version of T¨uBa-D/Z treebank. contain non-projective structures, such as the dependency graph illustrated in Figure 1. Nivre’s parsing algorithm only produces projective dependency structures, and therefore we used pseudo-projective parsing for recovering non-projective structures. The training data are projectivized and information about these transformations is encoded into the arc labels to enable deprojectivizition of the parser output (Nivre and Nilsson, 2005). 4 Constituency Parsing This section explains how a transition-based dependency parser can be used for parsing constituent structures. The basic idea is to use the common practice of transforming a constituent structure into a dependency graph and encode the inverse mapping with complex arc labels. Note that the goal is not to create the best dependency representation of a constituent structure. Instead the main objective is to find a general method to transform constituency to dependency so that is easy to do the inverse transformation without losing any information. Moreover, another goal i"
W08-1007,W06-2933,1,0.908537,"Missing"
W08-1007,D07-1066,0,0.0439758,"Missing"
W08-1007,A97-1014,0,0.419702,"Missing"
W08-1007,W06-1614,0,\N,Missing
W08-1007,D07-1096,1,\N,Missing
W08-2121,D07-1101,0,0.331336,"sults, but the improvement is not large. These initial efforts indicate at least that the joint modeling of this problem is not a trivial task. The D Arch. and D Inference columns summarize the parsing architectures and the corresponding inference strategies. Similar to last year’s shared task (Nivre et al., 2007), the vast majority of parsing models fall in two classes: transition-based (“trans” in the table) or graph-based (“graph”) models. By and large, transition-based models use a greedy inference strategy, whereas graph-based models used different Maximum Spanning Tree (MST) algorithms: Carreras (2007) – MSTC , Eisner (2000) – MSTE , or Chu-Liu/Edmonds (McDonald et al., 2005; Chu and Liu, 1965; Edmonds, 1967) – MSTCL/E . More interestingly, most of the best systems used some strategy to mitigate parsing errors. In the top three systems in the closed challenge, two (che and ciaramita) used parser combination through voting and/or stacking of different models (see the D Comb. column). Samuelsson et al. (2008) perform a MST inference with the bag of all dependencies output by the individual MALT parser variants. Johansson and Nugues (2008) use a single parsing model, but this model is extended"
W08-2121,W08-2134,0,0.108513,"movements, split clauses, and split noun phrases. 6.3 Normalized SRL Performance Table 6.3 lists the scores for the semantic subtask measured as the ratio of the labeled F1 score and LAS. As previously mentioned, this score estimates the performance of the SRL component independent of the performance of the syntactic parser. This analysis is not a substitute for the actual experiment where the SRL components are evaluated using correct syntactic information but, nevertheless, it indicates several interesting facts. First, the ranking of the top three systems in Table 10 changes: the system of Che et al. (2008) is now ranked first, and the system of Johansson and Nugues (2008) is second. This shows that Che et al. have a relatively stronger SRL component, whereas Johansson and Nugues developed a better parser. Second, several other systems improved their ranking compared to Table 10: e.g., chen from position thirteenth to ninth and choi from sixteenth to eighth. This indicates that these systems were penalized in the official ranking mainly due to the relative poor performance of their parsers. Note that this experiment is relevant only for systems that implemented pipeline architectures, where the"
W08-2121,W08-2139,0,0.0101528,"MaltParser with labels enriched with semantic information; Llu´ıs and M`arquez, who used a modified version of the Eisner algorithm to jointly predict syntactic and semantic dependencies; and finally, Sun et al. (2008), who integrated dependency label classification and argument identification using a maximum-entropy Markov model. Additionally, Johansson and Nugues (2008), who had the highest ranked system in the closed challenge, integrate syntactic and semantic analysis in a final reranking step, which maximizes the joint syntactic-semantic score in the top k solutions. In the same spirit, Chen et al. (2008) search in the top k solutions for the one that maximizes a global measure, in this case the joint probability of the complete problem. These joint learning strategies are summarized in the Joint Learning/Opt. column in the table. The system of Riedel and MezaRuiz (2008) deserves a special mention: even though Riedel and Meza-Ruiz did not implement a syntactic parser, they are the only group that performed the complete SRL subtask – i.e., predicate identification and classification, argument identification and classification – jointly, simultaneously for all the predicates in a sentence. They"
W08-2121,M98-1028,0,0.0358658,"and other phenomena, based on a theoretical perspective similar to that of Government and Binding Theory (Chomsky, 1981). 3.1.2 BBN Pronoun Coreference and Entity Type Corpus BBN’s NE annotation of the Wall Street Journal corpus (Weischedel and Brunstein, 2005) takes the form of SGML inline markup of text, tokenized to be completely compatible with the Penn Treebank annotation, e.g., fearlast and cannot are split in the same ways. Named entity categories include: Person, Organization, Location, GPE, Facility, Money, Percent, Time and Date, based on the definitions of these categories in MUC (Chinchor and Robinson, 1998) and ACE7 tasks. Subcategories are included as well. Note however that from this corpus we only use NE boundaries to derive NAME dependencies between NE tokens, e.g., we create a NAME dependency from Mary to Smith given the NE mention Mary Smith. 3.1.3 Proposition Bank I (PropBank) The PropBank annotation (Palmer et al., 2005) classifies the arguments of all the main verbs in the Penn Treebank corpus, other than be. Arguments are numbered (ARG0, ARG1, . . .) based on lexical entries or frame files. Different sets of arguments are assumed for different rolesets. Dependent constituents that fall"
W08-2121,W08-2138,1,0.51476,"Missing"
W08-2121,W06-1670,0,0.0107243,"haracters (“ ”) are used in columns 2–5 to ensure the same number of rows for all columns corresponding to one sentence. All syntactic and semantic dependencies are annotated relative to the split word forms (columns 6–8). Table 2 shows the columns available to the systems participating in the open challenge: namedentity labels as in the CoNLL-2003 Shared Task (Tjong Kim San and De Meulder, 2003) and from the BBN Wall Street Journal Entity Corpus,2 WordNet supersense tags, and the output of an offthe-shelf dependency parser (Nivre et al., 2007b). Columns 1–3 were predicted using the tagger of Ciaramita and Altun (2006). Because the BBN corpus shares lexical content with the Penn Treebank, we generated the BBN tags using a 2-fold cross-validation procedure. 2.2 Evaluation Measures We separate the evaluation measures into two groups: (i) official measures, which were used for the ranking of participating systems, and (ii) additional unofficial measures, which provide further insight into the performance of the participating systems. 2.2.1 Official Evaluation Measures The official evaluation measures consist of three different scores: (i) syntactic dependencies are scored using the labeled attachment score (LA"
W08-2121,W05-0620,1,0.81831,"Missing"
W08-2121,gimenez-marquez-2004-svmtool,1,0.278194,"Missing"
W08-2121,C04-1186,0,0.0984296,"formalism, but also extends them significantly: this year’s syntactic dependencies include more information such as named-entity boundaries; the semantic dependencies model roles of both verbal and nominal predicates. In this paper, we define the shared task and describe how the data sets were created. Furthermore, we report and analyze the results and describe the approaches of the participating systems. 1 • SRL is performed and evaluated using a dependency-based representation for both syntactic and semantic dependencies. While SRL on top of a dependency treebank has been addressed before (Hacioglu, 2004), our approach has several novelties: (i) our constituent-to-dependency conversion strategy transforms all annotated semantic arguments in PropBank and NomBank not just a subset; (ii) we address propositions centered around both verbal (PropBank) and nominal (NomBank) predicates. Introduction In 2004 and 2005 the shared tasks of the Conference on Computational Natural Language Learning (CoNLL) were dedicated to semantic role labeling (SRL), in a monolingual setting (English). In 2006 and 2007 the shared tasks were devoted to the parsing of syntactic dependencies, using corpora from up to 13 la"
W08-2121,W08-2122,0,0.366479,"Missing"
W08-2121,W08-2136,0,0.0382094,"Missing"
W08-2121,W08-2123,1,0.339084,"-TMP AM-MNR AM-LOC A3 AM-MOD AM-ADV AM-DIS R-A0 AM-NEG A4 C-A1 R-A1 AM-PNC AM-EXT AM-CAU AM-DIR R-AM-TMP R-A2 R-AM-LOC R-AM-MNR A5 AM-PRD C-A0 C-A2 R-AM-CAU C-A3 R-A3 C-AM-MNR C-AM-ADV AM-REC AA R-AM-PNC C-AM-EXT C-AM-TMP C-A4 Frequency &lt; 10 Frequency 161409 109437 51197 25913 13080 11409 10269 9986 9496 5369 4432 4097 3281 3118 2565 2445 1428 1346 1318 797 307 246 155 91 78 70 65 50 37 29 24 20 16 14 12 11 11 11 70 watanabe). Remarkably, the top-scoring system (johansson) is in a class of its own, with scores 2–3 points higher than the next system. This is most likely caused by the fact that Johansson and Nugues (2008) implemented a thorough system that addressed all facets of the task with state-ofthe-art methods: second-order parsing model, argument identification/classification models separately tuned for PropBank and NomBank, reranking inference for the SRL task, and, finally, joint optimization of the complete task using metalearning (more details in Section 5). Table 11 lists the official results in the open challenge. The results in this challenge are lower than in the closed challenge, but this was somewhat to be expected considering that there were fewer participants in this challenge and none of t"
W08-2121,W08-2135,0,0.0101844,"sks: Henderson et al. (2008), who implemented a generative history-based model (Incremental Sigmoid Belief Networks with vectors of latent variables) where syntactic and semantic structures are separately 170 generated but using a synchronized derivation (sequence of actions); Samuelsson et al. (2008), who, within an ensemble-based architecture, implemented a joint syntactic-semantic model using MaltParser with labels enriched with semantic information; Llu´ıs and M`arquez, who used a modified version of the Eisner algorithm to jointly predict syntactic and semantic dependencies; and finally, Sun et al. (2008), who integrated dependency label classification and argument identification using a maximum-entropy Markov model. Additionally, Johansson and Nugues (2008), who had the highest ranked system in the closed challenge, integrate syntactic and semantic analysis in a final reranking step, which maximizes the joint syntactic-semantic score in the top k solutions. In the same spirit, Chen et al. (2008) search in the top k solutions for the one that maximizes a global measure, in this case the joint probability of the complete problem. These joint learning strategies are summarized in the Joint Learn"
W08-2121,W07-2416,1,0.71052,"oNLL) were dedicated to semantic role labeling (SRL), in a monolingual setting (English). In 2006 and 2007 the shared tasks were devoted to the parsing of syntactic dependencies, using corpora from up to 13 languages. The CoNLL-2008 shared task1 proposes a unified dependency-based c 2008. ° Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 1 http://www.yr-bcn.es/conll2008 159 • Based on the observation that a richer set of syntactic dependencies improves semantic processing (Johansson and Nugues, 2007), the syntactic dependencies modeled are more complex than the ones used in the previous CoNLL shared tasks. For example, we now include apposition links, dependencies derived from named entity (NE) structures, and better modeling of long-distance grammatical relations. • A practical framework is provided for the joint learning of syntactic and semantic dependencies. CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 159–177 Manchester, August 2008 Given the complexity of this shared task, we limited the evaluation to a monolingual, Englishonly set"
W08-2121,W03-0419,0,0.0172595,"Missing"
W08-2121,W08-2124,1,0.554724,"Missing"
W08-2121,W08-2140,0,0.0210024,"a single parsing model, but this model is extended with second-order features. The PA Arch. and PA Inference columns summarize the architectures and inference strategies used for the identification and classification of predicates and arguments. The columns indicate that most systems modeled the SRL problem as a token-by-token classification problem (“class” in the table) with a corresponding greedy inference strategy. Some systems (e.g., yuret, samuelsson, henderson, lluis) incorporate SRL within parsing, in which case we report the corresponding parsing architecture and inference approach. Vickrey and Koller (2008) simplify the sentences to be labeled using a set of hand-crafted rules before deploying a classification model on top of a constituent-based representation. Unlike in the case of parsing, few systems (yuret, samuelssson, and morante) combine several PA models and the combination is limited to simple voting strategies (see the PA Comb. column). Finally, the ML Methods column lists the Machine Learning (ML) methods used. The column indicates that maximum entropy (ME) was the most popular method (12 distinct systems relied on it). Support Vector Machines (SVM) (eight systems) and the Perceptron"
W08-2121,J93-2004,0,0.0476215,"of the constituent-to-dependency conversion process. The section concludes with an overview of the shared task corpora. 3.1 Input Corpora Input to our merging procedures includes the Penn Treebank, BBN’s named entity corpus, PropBank and NomBank. In this section, we will provide brief descriptions of these annotations in terms of both form and content. All annotations are currently being distributed by the Linguistic Data Consortium, with the exception of NomBank, which is freely downloadable.6 6 http://nlp.cs.nyu.edu/meyers/NomBank. html 162 3.1.1 Penn Treebank 3 The Penn Treebank 3 corpus (Marcus et al., 1993) consists of hand-coded parses of the Wall Street Journal (test, development and training) and a small subset of the Brown corpus (W. N. Francis and H. Kuˆcera, 1964) (test only). These hand parses are notated in-line and sometimes involve changing the strings of the input data. For example, in file wsj 0309, the token fearlast in the text corresponds to the two tokens fear and last in the annotated data. In a similar way, cannot is regularly split to can and not. It is significant that the other annotations assume the tokenization of the Penn Treebank, as this makes it easier for us to merge"
W08-2121,W03-3023,0,0.13388,"s(T ) return create-dependency-tree(T ) 3.2 Conversion to Dependencies 3.2.1 Syntactic Dependencies There exists no large-scale dependency treebank for English, and we thus had to construct a dependency-annotated corpus automatically from the Penn Treebank (Marcus et al., 1993). Since dependency syntax represents grammatical structure by means of labeled binary head–dependent relations rather than phrases, the task of the conversion procedure is to identify and label the head–dependent pairs. The idea underpinning constituent-to-dependency conversion algorithms (Magerman, 1994; Collins, 1999; Yamada and Matsumoto, 2003) is that head–dependent pairs are created from constituents by selecting one word in each phrase as the head and setting all other as its dependents. The dependency labels are then inferred from the phrase–subphrase or phrase–word relations. Our conversion procedure (Johansson and Nugues, 2007) differs from this basic approach by exploiting the rich structure of the constituent format used in Penn Treebank 3: procedure import-glarf(T ) Import a GLARF surface dependency graph G for each multi-word name N in G for each token d in N Set the function tag of d to NAME for each dependency link h →L"
W08-2121,H05-1066,0,0.305206,"ate at least that the joint modeling of this problem is not a trivial task. The D Arch. and D Inference columns summarize the parsing architectures and the corresponding inference strategies. Similar to last year’s shared task (Nivre et al., 2007), the vast majority of parsing models fall in two classes: transition-based (“trans” in the table) or graph-based (“graph”) models. By and large, transition-based models use a greedy inference strategy, whereas graph-based models used different Maximum Spanning Tree (MST) algorithms: Carreras (2007) – MSTC , Eisner (2000) – MSTE , or Chu-Liu/Edmonds (McDonald et al., 2005; Chu and Liu, 1965; Edmonds, 1967) – MSTCL/E . More interestingly, most of the best systems used some strategy to mitigate parsing errors. In the top three systems in the closed challenge, two (che and ciaramita) used parser combination through voting and/or stacking of different models (see the D Comb. column). Samuelsson et al. (2008) perform a MST inference with the bag of all dependencies output by the individual MALT parser variants. Johansson and Nugues (2008) use a single parsing model, but this model is extended with second-order features. The PA Arch. and PA Inference columns summari"
W08-2121,W08-2126,0,0.0266466,"mBank, reranking inference for the SRL task, and, finally, joint optimization of the complete task using metalearning (more details in Section 5). Table 11 lists the official results in the open challenge. The results in this challenge are lower than in the closed challenge, but this was somewhat to be expected considering that there were fewer participants in this challenge and none of the top five groups in the closed challenge submitted results in the open challenge. Only one of the systems that participated in both challenges (zhang) improved the results submitted in the closed challenge. Zhang et al. (2008) achieved this by extracting features for their semantic subtask models both from the parser used in the closed challenge and a secondary parser that was trained on a different corpus. The improvements measured were relatively small for the in-domain WSJ corpus (0.2 labeled macro F1 points) but larger for the out-of-domain Brown corpus (approximately 1 labeled macro F1 point). Table 9: Statistics for semantic roles. 4 Submissions and Results Nineteen groups submitted test runs in the closed challenge and five groups participated in the open challenge. Three of the latter groups participated on"
W08-2121,W01-1511,0,0.0379316,"Missing"
W08-2121,W04-2705,1,0.723818,"Missing"
W08-2121,W06-2933,1,0.512001,"Missing"
W08-2121,J05-1004,0,0.584805,"compatible with the Penn Treebank annotation, e.g., fearlast and cannot are split in the same ways. Named entity categories include: Person, Organization, Location, GPE, Facility, Money, Percent, Time and Date, based on the definitions of these categories in MUC (Chinchor and Robinson, 1998) and ACE7 tasks. Subcategories are included as well. Note however that from this corpus we only use NE boundaries to derive NAME dependencies between NE tokens, e.g., we create a NAME dependency from Mary to Smith given the NE mention Mary Smith. 3.1.3 Proposition Bank I (PropBank) The PropBank annotation (Palmer et al., 2005) classifies the arguments of all the main verbs in the Penn Treebank corpus, other than be. Arguments are numbered (ARG0, ARG1, . . .) based on lexical entries or frame files. Different sets of arguments are assumed for different rolesets. Dependent constituents that fall into categories independent of the lexical entries are classified as various types 7 http://projects.ldc.upenn.edu/ace/ of ARGM (TMP, ADV, etc.).8 Rather than using PropBank directly, we used the version created for the CoNLL-2005 shared task (Carreras and M`arquez, 2005). PropBank’s pointers to subtrees are converted into th"
W08-2121,W08-2125,0,0.116607,"g paper in the proceedings. Results are sorted in descending order of the labeled F1 score for semantic dependencies on the WSJ+Brown corpus. The number in parentheses next to the WSJ+Brown scores indicates the system rank in the corresponding task. 5 Approaches Table 5 summarizes the properties of the systems that participated in the closed the open challenges. The second column of the table highlights the overall architectures. We used + to indicate that the components are sequentially connected. The lack of a + sign indicates that the corresponding tasks are performed jointly. For example, Riedel and Meza-Ruiz (2008) perform predicate and argument identification and classification jointly, whereas Ciaramita et al. (2008) implemented a pipeline architecture of three components. We use the ||to indicate that several different architectures that span multiple subtasks were deployed in parallel. This summary of system architectures indicates that it is common that systems combine several components in the semantic or syntactic subtasks – e.g., nine systems jointly performed predicate/argument identification and classification – but only four systems combined components between the syntactic and semantic subta"
W08-2121,J03-4003,0,\N,Missing
W08-2121,D07-1096,1,\N,Missing
W08-2121,W04-2412,1,\N,Missing
W09-1113,W06-2922,0,0.0162399,"ccadic movements. Given such a system, we can train a classifier to predict the next transition given the information in the current configuration. In order to derive a complete transition sequence, we start in an initial configuration, representing the reader’s state before the first fixation, and repeatedly apply the transition predicted by the classifier until we reach a terminal state, representing the reader’s state after having read the entire text. At an abstract level, this is essentially the same idea as in transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2006; Attardi, 2006). In the following subsections, we discuss the different components of the model in turn, including the transition system, the classifier used, the features used to represent data, and the search algorithm used to derive complete transition sequences. 4.1 Transition System A transition system is an abstract machine consisting of a set of configurations and transitions between configurations. A configuration in the current system is a triple C = (L, R, F ), where 1. L is a list of tokens representing the left context, including the currently fixated token and all preceding tokens in the text. 2"
W09-1113,W03-3023,0,0.0383631,"on states and transitions representing saccadic movements. Given such a system, we can train a classifier to predict the next transition given the information in the current configuration. In order to derive a complete transition sequence, we start in an initial configuration, representing the reader’s state before the first fixation, and repeatedly apply the transition predicted by the classifier until we reach a terminal state, representing the reader’s state after having read the entire text. At an abstract level, this is essentially the same idea as in transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2006; Attardi, 2006). In the following subsections, we discuss the different components of the model in turn, including the transition system, the classifier used, the features used to represent data, and the search algorithm used to derive complete transition sequences. 4.1 Transition System A transition system is an abstract machine consisting of a set of configurations and transitions between configurations. A configuration in the current system is a triple C = (L, R, F ), where 1. L is a list of tokens representing the left context, including the currently fixated token and all pr"
W09-1201,burchardt-etal-2006-salsa,1,0.483589,"Missing"
W09-1201,D07-1101,0,0.391748,"Missing"
W09-1201,W09-1202,0,0.0278745,"order syntactic parsing and a particular setting for Catalan 16 and Spanish. (Gesmundo et al., 2009) use an incremental parsing model with synchronous syntactic and semantic derivations and a joint probability model for syntactic and semantic dependency structures. The system uses a single input queue but two separate stacks and synchronizes syntactic and semantic derivations at every word. The synchronous derivations are modeled with an Incremental Sigmoid Belief Network that has latent variables for both syntactic and semantic states and connections from syntax to semantics and vice versa. (Dai et al., 2009) designed an iterative system to exploit the inter-connections between the different subtasks of the CoNLL shared task. The idea is to decompose the joint learning problem into four subtasks – syntactic dependency identification, syntactic dependency labeling, semantic dependency identification and semantic dependency labeling. The initial step is to use a pipeline approach to use the input of one subtask as input to the next, in the order specified. The iterative steps then use additional features that are not available in the initial step to improve the accuracy of the overall system. For ex"
W09-1201,W09-1205,0,0.222475,"al token; and (c), the existence of an edge between each pair of tokens. Subsequently, they combine the (possibly conflicting) output of the three classifiers by a ranking approach to determine the most likely structure that meets all well-formedness constraints. (Llu´ıs et al., 2009) present a joint approach based on an extension of Eisner’s parser to accommodate also semantic dependency labels. This architecture is similar to the one presented by the same authors in the past edition, with the extension to a second-order syntactic parsing and a particular setting for Catalan 16 and Spanish. (Gesmundo et al., 2009) use an incremental parsing model with synchronous syntactic and semantic derivations and a joint probability model for syntactic and semantic dependency structures. The system uses a single input queue but two separate stacks and synchronizes syntactic and semantic derivations at every word. The synchronous derivations are modeled with an Incremental Sigmoid Belief Network that has latent variables for both syntactic and semantic states and connections from syntax to semantics and vice versa. (Dai et al., 2009) designed an iterative system to exploit the inter-connections between the differen"
W09-1201,W09-1212,1,0.83271,"Missing"
W09-1201,S07-1008,1,0.697359,"Missing"
W09-1201,H05-1066,1,0.168004,"Missing"
W09-1201,W04-2705,1,0.527791,"Missing"
W09-1201,W09-1219,0,0.0294123,"Missing"
W09-1201,H05-1108,1,0.506508,"y, adding further manual labels where necessary. Then, we used frequency and grammatical realization information to map the remaining roles onto higher-numbered Arg roles. We considerably simplified the annotations provided by SALSA, which use a rather complex annotation scheme. In particular, we removed annotation for multi-word expressions (which may be non-contiguous), annotations involving multiple frames for the same predicate (metaphors, underspecification), and inter-sentence roles. The out-of-domain dataset was taken from a study on the multi-lingual projection of FrameNet annotation (Pado and Lapata, 2005). It is sampled from the EUROPARL corpus and was chosen to maximize the lexical coverage, i.e., it contains of a large number of infrequent predicates. Both syntactic and semantic structure were annotated manually, in the TIGER and SALSA format, respectively. Since it uses a simplified annotation schemes, we did not have to discard any annotation. For both datasets, we converted the syntactic TIGER (Brants et al., 2002) representations into dependencies with a similar set of head-finding rules used for the preparation of the CoNLL-X shared task German dataset. Minor modifications (for the con1"
W09-1201,C08-1085,1,0.175934,"Missing"
W09-1201,J05-1004,0,0.213522,"nnotation of the Wall Street Journal corpus (Weischedel and Brunstein, 2005) takes the form of SGML inline markup of text, tokenized to be completely compatible with the Penn Treebank annotation. For the CoNLL-2008 shared task evaluation, this corpus was extended by the task organizers to cover the subset of the Brown corpus used as a secondary testing dataset. From this corpus we only used NE boundaries to derive NAME dependencies between NE tokens, e.g., we create a NAME dependency from Mary to Smith given the NE mention Mary Smith. • Proposition Bank I (PropBank) – The PropBank annotation (Palmer et al., 2005) classifies the arguments of all the main verbs in the Penn Treebank corpus, other than be. Arguments are numbered (Arg0, Arg1, . . .) based on lexical entries or frame files. Different sets of arguments are assumed for different rolesets. Dependent constituents that fall into categories independent of the lexical entries are classified as various types of adjuncts (ArgM-TMP, -ADV, etc.). • NomBank – NomBank annotation (Meyers et al., 2004) uses essentially the same framework as PropBank to annotate arguments of nouns. Differences between PropBank and NomBank stem from differences between noun"
W09-1201,E09-1087,1,0.646818,"Missing"
W09-1201,W08-2121,1,0.597132,"Missing"
W09-1201,taule-etal-2008-ancora,0,0.543017,"Missing"
W09-1201,cmejrek-etal-2004-prague,1,0.63993,"Missing"
W09-1201,kawahara-etal-2002-construction,1,\N,Missing
W09-1201,J93-2004,0,\N,Missing
W09-1201,D07-1096,1,\N,Missing
W09-3804,P07-2045,0,0.0103169,"re made with different pruning parameters. The EM process was halted when a relative improvement in log-likelihood of 10−3 was no longer achieved over the previous iteration. Evaluation We evaluate the parser on a translation task (WMT’08 shared task3 ). In order to evaluate on a translation task, a translation system has to be built. We use the alignments from the Viterbi parses of the training corpus to substitute the alignments of GIZA++. This is the same approach as taken in Saers & Wu (2009). We will evaluate the resulting translations with two automatic 3 Setup We use the Moses Toolkit (Koehn et al., 2007) to train our phrase-based SMT models. The toolkit also includes scripts for applying GIZA++ (Och and Ney, 2003) as a word aligner. We have trained several systems, one using GIZA++ (our baseline system), one with no pruning at all, and 6 different values of b (1, 10, 25, 50, 75 and 100). We used the grow-diag-final-and method to extract phrases from the word alignment, and MERT (Och, 2003) to optimize the resulting model. We trained a 5-gram SRI language model (Stolcke, 2002) using the corpus supplied for this purpose by the shared task organizers. All of the above is consistent with the guid"
W09-3804,2005.mtsummit-papers.11,0,0.0102206,"s, one using GIZA++ (our baseline system), one with no pruning at all, and 6 different values of b (1, 10, 25, 50, 75 and 100). We used the grow-diag-final-and method to extract phrases from the word alignment, and MERT (Och, 2003) to optimize the resulting model. We trained a 5-gram SRI language model (Stolcke, 2002) using the corpus supplied for this purpose by the shared task organizers. All of the above is consistent with the guidelines for building a baseline system for the WMT’08 shared task. The translation tasks we applied the above procedure to are all taken from the Europarl corpus (Koehn, 2005). We selected the tasks German-English, French-English and SpanishEnglish. Furthermore, we restricted the training sentence pairs so that none of the sentences exceeded length 10. This was necessary to be able to carry out exhaustive search. The total amount of training data was roughly 100,000 sentence pairs in each language pair, which is a relatively small corpus, but by no means a toy example. Analysis 5 Empirical results http://www.statmt.org/wmt08/ 31 Metric Baseline (GIZA++) ∞ BLEU NIST time 0.2597 6.6352 0.2663 6.7407 03:20:00 BLEU NIST time 0.2059 5.8668 0.2113 5.9380 03:40:00 BLEU NI"
W09-3804,J03-1002,0,0.0233874,"he item being extended. This fact can be exploited to limit the number of possible siblings explored, but has no impact on time complexity. 3.3 metrics: BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 6 In this section we describe the experimental setup as well as the outcomes. Viterbi parsing When doing Viterbi parsing, all derivations but the most probable are discarded. This gives an unambiguous parse, which dictates exactly one alignment between e and f . The alignment of the Viterbi parse can be used to substitute that of other word aligners (Saers and Wu, 2009) such as GIZA++ (Och and Ney, 2003). 4 6.1 Looking at the algorithm, it is clear that there will be a total of T + V = O(n) agendas, each containing items of a certain length. The items in an agenda can start anywhere in the alignment space: O(n2 ) possible starting points, but once the end point in one language is set, the end point in the other follows from that, adding a factor O(n). This means that each agenda contains O(n3 ) active items. Each active item has to go through all possible siblings in the recursive step. Since the start point of the sibling is determined by the item itself (it has to be adjacent), only the O(n"
W09-3804,P03-1021,0,0.00690123,"pus to substitute the alignments of GIZA++. This is the same approach as taken in Saers & Wu (2009). We will evaluate the resulting translations with two automatic 3 Setup We use the Moses Toolkit (Koehn et al., 2007) to train our phrase-based SMT models. The toolkit also includes scripts for applying GIZA++ (Och and Ney, 2003) as a word aligner. We have trained several systems, one using GIZA++ (our baseline system), one with no pruning at all, and 6 different values of b (1, 10, 25, 50, 75 and 100). We used the grow-diag-final-and method to extract phrases from the word alignment, and MERT (Och, 2003) to optimize the resulting model. We trained a 5-gram SRI language model (Stolcke, 2002) using the corpus supplied for this purpose by the shared task organizers. All of the above is consistent with the guidelines for building a baseline system for the WMT’08 shared task. The translation tasks we applied the above procedure to are all taken from the Europarl corpus (Koehn, 2005). We selected the tasks German-English, French-English and SpanishEnglish. Furthermore, we restricted the training sentence pairs so that none of the sentences exceeded length 10. This was necessary to be able to carry"
W09-3804,P02-1040,0,0.106966,"ld a set of extensions E(i) for all active items i. All items in E(i) are then activated by placing them on their corresponding agenda (i ∈ A|i |). E(Xstuv ) = {XStU v |0 ≤ S ≤ s, 0 ≤ U ≤ u, XSsU u ∈ C} ∪ {XsSuU |t ≤ S ≤ T, v ≤ U ≤ V, XtSvU ∈ C} ∪ {XsSU v |t ≤ S ≤ T, 0 ≤ U ≤ u, XtSU u ∈ C} ∪ {XStuU |0 ≤ S ≤ s, v ≤ U ≤ V, XSsvU ∈ C} 30 Since we are processing the agendas in order, any item in the chart will be as long as or shorter than the item being extended. This fact can be exploited to limit the number of possible siblings explored, but has no impact on time complexity. 3.3 metrics: BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 6 In this section we describe the experimental setup as well as the outcomes. Viterbi parsing When doing Viterbi parsing, all derivations but the most probable are discarded. This gives an unambiguous parse, which dictates exactly one alignment between e and f . The alignment of the Viterbi parse can be used to substitute that of other word aligners (Saers and Wu, 2009) such as GIZA++ (Och and Ney, 2003). 4 6.1 Looking at the algorithm, it is clear that there will be a total of T + V = O(n) agendas, each containing items of a certain length. The items in an agenda"
W09-3804,W09-2304,1,0.789481,"will be as long as or shorter than the item being extended. This fact can be exploited to limit the number of possible siblings explored, but has no impact on time complexity. 3.3 metrics: BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 6 In this section we describe the experimental setup as well as the outcomes. Viterbi parsing When doing Viterbi parsing, all derivations but the most probable are discarded. This gives an unambiguous parse, which dictates exactly one alignment between e and f . The alignment of the Viterbi parse can be used to substitute that of other word aligners (Saers and Wu, 2009) such as GIZA++ (Och and Ney, 2003). 4 6.1 Looking at the algorithm, it is clear that there will be a total of T + V = O(n) agendas, each containing items of a certain length. The items in an agenda can start anywhere in the alignment space: O(n2 ) possible starting points, but once the end point in one language is set, the end point in the other follows from that, adding a factor O(n). This means that each agenda contains O(n3 ) active items. Each active item has to go through all possible siblings in the recursive step. Since the start point of the sibling is determined by the item itself (i"
W09-3804,W95-0106,1,0.822411,"as they must be completely made up of terminals. For notational convenience, the orientation of the rule is written as surrounding the production, like so: X → γ, X → [γ] and X → hγi. The vocabularies of the languages may both include the empty token , allowing for deletions and insertions. The empty biterminal, / is not allowed. 2.1 Stochastic ITGs In a Stochastic ITG (SITG), each rule is also associated with a probability, such that X P r(X → γ) = 1 γ for all X ∈ N . The probability of a deriva∗ tion S ⇒ e/f is defined as the production of the probabilities of all rules used. As shown by Wu (1995), it is possible to fit the parameters of a SITG to a parallel corpus via EM (expectationmaximization) estimation. 2.2 3.1 Bracketing ITGs In the initial step, the set of lexical items L is built. All lexical items i ∈ L are then activated by placing them on their corresponding agenda A|i |.   0 ≤ s ≤ t ≤ T,   L = Xstuv 0 ≤ u ≤ v ≤ V,  X → es..t /fu..v ∈ ∆  An ITG where there is only one nonterminal (other than the start symbol) is called a bracketing ITG (BITG). Since the one nonterminal is devoid of information, it can only be used to group its children together, imposing a bracketing"
W09-3804,J97-3002,1,\N,Missing
W09-3807,W04-2407,1,0.760173,"a sequence of transitions. The parser starts with an empty stack and terminates when the input queue is empty, parsing input from left to right. It has four transitions (LeftArc, Right-Arc, Reduce and Shift), manipulating these data structures. The algorithm has a linear time complexity as it is guaranteed to terminate after at most 2n transitions, given that the length of the input sentence is n. In contrast to a parser guided by a grammar (e.g., ordinary shift-reduce parsing for contextfree grammars), this parser is guided by a classifier induced from empirical data using machine learning (Nivre et al., 2004). Hence, the parser requires training data containing dependency trees. In other words, the parser has a training phase where the training data is used by the training module in order to learn the correct sequence of transitions. The training data can contain dependency trees for sentences of any language irrespectively of whether the language is a natural or formal one. The training module produces the correct transition sequences using the dependency trees of the training data. These correct parser configurations and transition sequences are then provided as training data to a classifier, wh"
W09-3807,P81-1022,0,0.762957,"Missing"
W09-3807,P06-2041,1,0.8495,"information in the syntax trees is 3.4 Dependency Tree ⇒ Syntax Tree The inverse conversion is a bottom-up and topdown process on the convertible dependency tree 53 Figure 4: Non-convertible dependency trees for example (2) using L EFT (upper) and F REQ (lower). parsing algorithm, as well as an implementation of the conversion strategy from syntax trees to dependency trees and back, presented in subsections 3.3 and 3.4. It comes with the machine learner LIBSVM (Chang and Lin, 2001), producing the most accurate results for parsing natural languages compared to other evaluated machine learners (Hall et al., 2006). LIBSVM requires training data. The source files of the following projects have been converted into dependency trees: (must contain complex arc labels). First, the algorithm visits every terminal in the convertible dependency tree and restores the spines of nonterminals with labels for each terminal using the information in the first sublabel of the incoming arc. Thus, the bottom-up process results in a spine of zero or more arcs from each terminal to the highest nonterminal of which the terminal is the terminal head. Secondly, the spines are weaved together according to the arcs of the depen"
W09-3807,W03-3017,1,0.76812,"only needs correct examples of the source and the expected analysis model. Then it automatically trains and adapts a generic parser. As we will show, training data for adapting to a new programming language can even be generated automatically. Hence, the effort for creating a parser for a new programming language is quite small. The basic idea – applying natural language parsing to programming languages – has been presented to the program maintenance community before (Nilsson et al., 2009). This paper contributes with experimental results on Figure 1: Sentence with a dependency tree. gorithm (Nivre, 2003), can produce such dependency trees. It bears a resemblance to the shiftreduce parser for context-free grammars, with the most apparent difference being that terminals (not nonterminals) are pushed onto the stack. Parser configurations are represented by a stack, a list of (remaining) input tokens, and the (current) set of arcs for the dependency tree. Similar to the shift-reduce parser, the construction of syntactic structure is created by a sequence of transitions. The parser starts with an empty stack and terminates when the input queue is empty, parsing input from left to right. It has fou"
W09-3807,P95-1037,0,0.146506,"b). (2) Train the generic parser with the training data. This automated training phase needs to be done for every new programming language we adapt to. 51 cannot be used for the inverse conversion, which we call non-convertible dependency trees. The conversion is performed in a two-step approach. First, the algorithm traverses the syntax tree from the root and identifies the head-child and the terminal head for all nonterminals in a recursive depth-first search. To identify the head-child for each nonterminal, the algorithm uses heuristics called head-finding rules, inspired by, for instance, Magerman (1995). Three head-finding strategies have been investigated. For each nonterminal: complexity of the parsing algorithm of section 2, a quite unusual property compared to other NLP parsers guided by machine learning with state-ofthe-art accuracy. 3.2 Source Code ⇒ Syntax Tree In order to produce training data for the parser for a programming language, an analyzer that constructs syntax trees for correct and complete source code of the programming language is needed. We are in this study focusing on Java, Python and C/C++, and consequently need one such analyzer for each language. For example, figure"
W09-3807,nivre-etal-2006-maltparser,1,\N,Missing
W09-3807,J04-4004,0,\N,Missing
W09-3807,D07-1096,1,\N,Missing
W09-3811,P06-2066,1,0.802427,"Missing"
W09-3811,W07-2216,0,0.0168965,"Missing"
W09-3811,W06-2932,0,0.0595059,"Missing"
W09-3811,P08-1108,1,0.817536,"Missing"
W09-3811,W06-2933,1,0.712712,"Missing"
W09-3811,J08-4003,1,0.159262,"Missing"
W09-3811,P09-1040,1,0.77487,"makes the treatment of non-projectivity central for accurate dependency parsing. Unfortunately, parsing with unrestricted non-projective structures is a hard problem, for which exact inference is not possible in polynomial time except under drastic independence assumptions (McDonald and Satta, 2007), and most data-driven parsers therefore use approximate methods (Nivre et al., 2006; McDonald et al., 2006). One recently explored approach is to perform online reordering by swapping adjacent words of the input sentence while building the dependency structure. Using this technique, the system of Nivre (2009) processes unrestricted non-projective structures with state-ofthe-art accuracy in observed linear time. The normal procedure for training a transitionbased parser is to use an oracle that predicts an Background The fundamental reason why sentences with nonprojective dependency trees are hard to parse is that they contain dependencies between non-adjacent substructures. The basic idea in online reordering is to allow the parser to swap input words so that all dependency arcs can be constructed between adjacent subtrees. This idea is implemented in the transition system proposed by Nivre (2009)"
W09-4631,W06-2920,0,0.10314,"combined to produce an analysis supported by a majority of component systems. This technique was first ˇ proposed by Zeman and Zabokrtsk´ y (2005) and further refined by Sagae and Lavie (2006), who showed that it could be construed as a special form of spanning tree parsing. In parser combination by stacking, the outputs of one or more parsers are used as features for a data-driven parser that can learn from the predictions of other models. Parser stacking was recently used by Nivre and McDonald (2008) to advance the state of the art on the multilingual test sets from the CoNLL-X shared task (Buchholz and Marsi, 2006). We describe a series of experiments, where we first try to optimize the voting strategy, by investigating different schemes for assigning weights to Kristiina Jokinen and Eckhard Bick (Eds.) NODALIDA 2009 Conference Proceedings, pp. 219–222 Joakim Nivre Uppsala University Uppsala, Sweden joakim.nivre@lingfil.uu.se the votes of different systems. We then compare voting to the alternative method of stacking. The paper is organized as follows. Section 2 describes the tools, resources and methods, common to all experiments, as well as the component parsers, used for voting and stacking. Optimiza"
W09-4631,D07-1097,1,0.889458,"e maximum spanning tree algorithm previously proposed for dependency parsing by McDonald et al. (2005). If all dependency arcs proposed by some parser are stored in a graph and weighted by their number of votes, then extracting the maximum spanning tree (MST) from this graph yields the optimal dependency tree. Sagae and Lavie (2006) also showed that accuracy can be further improved if votes are weighted by the accuracy of the component parser on all arcs where the dependent token has the same part of speech. This weighting scheme, which we will refer to as the default model, was later used by Hall et al. (2007) to achieve the best overall score in the CoNLL 2007 shared task by combining six different parsers. Samuelsson et al. (2008) used a variation on the default model, where weights are first set according to accuracy but are then iteratively updated using the following simple principle: at each iteration the MST is compared to the reference parse, after which all weights of correct arcs are given a small increase and all incorrect ones a small decrease. This technique resulted in minor score improvements over the default model. In order to obtain a baseline, the default model was applied to the"
W09-4631,H05-1066,0,0.281259,"Missing"
W09-4631,P08-1108,1,0.942743,"arsers: voting and stacking. In parser combination by voting, the outputs of (at least three) independent parsers are combined to produce an analysis supported by a majority of component systems. This technique was first ˇ proposed by Zeman and Zabokrtsk´ y (2005) and further refined by Sagae and Lavie (2006), who showed that it could be construed as a special form of spanning tree parsing. In parser combination by stacking, the outputs of one or more parsers are used as features for a data-driven parser that can learn from the predictions of other models. Parser stacking was recently used by Nivre and McDonald (2008) to advance the state of the art on the multilingual test sets from the CoNLL-X shared task (Buchholz and Marsi, 2006). We describe a series of experiments, where we first try to optimize the voting strategy, by investigating different schemes for assigning weights to Kristiina Jokinen and Eckhard Bick (Eds.) NODALIDA 2009 Conference Proceedings, pp. 219–222 Joakim Nivre Uppsala University Uppsala, Sweden joakim.nivre@lingfil.uu.se the votes of different systems. We then compare voting to the alternative method of stacking. The paper is organized as follows. Section 2 describes the tools, reso"
W09-4631,P81-1022,0,0.757514,"Missing"
W09-4631,W03-3017,1,0.731395,"n systems, and the joint system was trained on the resulting training set. All results are evaluated using the labeled attachment score, which is the percentage of tokens with correctly determined heads and dependency relations in the test corpus. Intermediate models are evaluated on the WSJ testing corpus, whereas the final scores are presented for both WSJ and Brown. All component parsers (as well as the stacking parser) were trained using MaltParser (Nivre et al., 2006), a data-driven dependency parser generator that implements two parsing algorithms: the shift-reduce algorithm proposed by Nivre (2003), Mark Fishel and Joakim Nivre in an arc-eager and an arc-standard variant (NivreEager and Nivre-Std), and the incremental parsing algorithm first described in Covington (2001), in a projective and a non-projective variant (Cov-Proj and Cov-NonProj). We used eight component parsers, defined by the four algorithm variants times two directions (forward and reverse), which is the same setup as in Samuelsson et al. (2008). Feature models and parameter settings were taken from Hall et al. (2007). The scores of the eight parsers on the two test corpora are presented in Table 1. The highest score is"
W09-4631,N06-2033,0,0.0641483,"neral technique that can be used to boost accuracy in natural language processing tasks. By combining several models for performing the same task, we can exploit the unique advantage of each model and reduce some of the random errors. In this paper, we study two techniques for combining data-driven dependency parsers: voting and stacking. In parser combination by voting, the outputs of (at least three) independent parsers are combined to produce an analysis supported by a majority of component systems. This technique was first ˇ proposed by Zeman and Zabokrtsk´ y (2005) and further refined by Sagae and Lavie (2006), who showed that it could be construed as a special form of spanning tree parsing. In parser combination by stacking, the outputs of one or more parsers are used as features for a data-driven parser that can learn from the predictions of other models. Parser stacking was recently used by Nivre and McDonald (2008) to advance the state of the art on the multilingual test sets from the CoNLL-X shared task (Buchholz and Marsi, 2006). We describe a series of experiments, where we first try to optimize the voting strategy, by investigating different schemes for assigning weights to Kristiina Jokine"
W09-4631,W08-2136,1,0.886879,"Missing"
W09-4631,W08-2121,1,0.868696,"Missing"
W09-4631,W05-1518,0,0.259765,"Missing"
W09-4631,nivre-etal-2006-maltparser,1,\N,Missing
W10-1411,I08-2099,1,0.672793,"y ERG Sameer DAT book gave “Malay gave the book to Sameer” (S-IO-DO-V)1 b. malaya ne kitaba sameer ko dii. (S-DO-IO-V) c. sameer ko malaya ne kitaba dii. (IO-S-DO-V) d. sameer ko kitaba malaya ne dii. (IO-DO-S-V) e. kitaba malaya ne sameer ko dii. (DO-S-IO-V) f. kitaba sameer ko malaya ne dii. (DO-IO-S-V) Hindi also has a rich case marking system, although case marking is not obligatory. For example, in (1), while the subject and indirect object are explicitly marked for the ergative (ERG) and dative (DAT) cases, the direct object is unmarked for the accusative. The Hindi dependency treebank (Begum et al., 2008) used for the experiment was released as part of the ICON09 dependency parsing tools contest (Husain, 2009). The dependency framework (Bharati et al., 1995) used in the treebank is inspired by Panini’s grammar of Sanskrit. The core labels, called karakas, are syntactico-semantic relations that identify the participant in the action denoted by the verb. For example, in (1), ‘Malay’ is the agent, ‘book’ is the theme, and ‘Sameer’ is the beneficiary in the activity of ‘give’. In the treebank, these three labels are marked as k1, k2, and k4 respectively. Note, however, that the notion of karaka do"
W10-1411,J95-3006,0,0.638182,"encode syntactically relevant information in different ways, and it has been hypothesized that the integration of morphological and syntactic information could be a key to better accuracy. However, it has also been noted that incorporating these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways. In this paper, we are concerned with Hindi, an Indian language with moderately rich morphology and relatively free word order. There have been several previous attempts at parsing Hindi as well as other Indian languages (Bharati et al., 1995, Bharati et al., 2009b). Many techniques were tried out recently at the ICON09 dependency parsing tools contest (Husain, 2009). Both the best performing system (Ambati et al., 2009a) and the system in second place (Nivre, 2009b) used a transition-based approach to dependency parsing, as implemented in MaltParser (Nivre et al., 2007b). Other data driven parsing efforts for Indian languages in the past have been Bharati et al. (2008), Husain et al. (2009), Mannem et al. (2009b) and Gadde et al. (2010). In this paper, we continue to explore the transition-based approach to Hindi dependency parsi"
W10-1411,W09-3812,1,0.868761,"the surface level morpho-syntactic information (Vaidya et al., 2009). The syntactic relational cues (such as case markers) help identify many of the karakas. In general, the highest available karaka,2 if not case-marked, agrees with the verb in an active sentence. In addition, the tense, 1 S=Subject; IO=Indirect Object; DO=Direct Object; V=Verb; ERG=Ergative; DAT=Dative 2 These are the karta karaka (k1) and karma karaka (k2). k1 and k2 can be roughly translated as ‘agent’ and ‘theme’ respectively. For a complete description of the tagset and the dependency scheme, see Begum et al. (2008) and Bharati et al. (2009a). 95 aspect and modality (TAM) marker can many a times control the case markers that appear on k1. For example, in (1) ‘Malay’ takes an ergative case because of the past perfective TAM marker (that appears as a suffix in this case) of the main verb ‘gave’. Many dependency relations other than karakas are purely syntactic. These include relations such as noun modifier (nmod), verb modifier (vmod), conjunct relation (ccof), etc. Each sentence is manually chunked and then annotated for dependency relations. A chunk is a minimal, non-recursive structure consisting of correlated groups of words ("
W10-1411,J08-3003,1,0.887374,"Missing"
W10-1411,N10-1093,1,0.827268,"i, the majority of non-projective arcs are inter-clausal (Mannem et al., 2009a), involving conjunctions and relative clauses. There have been some attempts at handling inter-clausal non-projectivity in Hindi. Husain et al. (2009) proposed a two-stage approach that can handle some of the inter-clausal nonprojective structures. 0 Non-Projectivity Dependency Precision 5.5 They have shown that most long distance relations are inter-clausal, and therefore, using such a clause motivated parsing setup helps in maximizing both short distance and long distance dependency accuracy. In a similar spirit, Gadde et al. (2010) showed that using clausal features helps in identifying long distance dependencies. They have shown that providing clause information in the form of clause boundaries and clausal heads can help a parser make better predictions about long distance dependencies. Dependency Length Dependency Recall identifying pof or misclassifies other labels as pof. In particular, the confusion is with k2 and k1s which are object/theme and noun complements of k1, respectively. These labels share similar contextual features like the nominal element in the verb complex. Table 3 includes the confusion matrix for"
W10-1411,W09-3819,0,0.0625767,"Missing"
W10-1411,D07-1097,1,0.877085,"Missing"
W10-1411,P09-3002,0,0.358589,"Missing"
W10-1411,W06-2932,0,0.0414507,"Missing"
W10-1411,D07-1013,1,0.747991,"Missing"
W10-1411,P07-1122,1,0.89772,"Missing"
W10-1411,J08-4003,1,0.869472,"Missing"
W10-1411,P08-1108,1,0.863885,"Missing"
W10-1411,P09-1040,1,0.891117,"ing these language specific features in parsing is not always straightforward and many intuitive features do not always work in expected ways. In this paper, we are concerned with Hindi, an Indian language with moderately rich morphology and relatively free word order. There have been several previous attempts at parsing Hindi as well as other Indian languages (Bharati et al., 1995, Bharati et al., 2009b). Many techniques were tried out recently at the ICON09 dependency parsing tools contest (Husain, 2009). Both the best performing system (Ambati et al., 2009a) and the system in second place (Nivre, 2009b) used a transition-based approach to dependency parsing, as implemented in MaltParser (Nivre et al., 2007b). Other data driven parsing efforts for Indian languages in the past have been Bharati et al. (2008), Husain et al. (2009), Mannem et al. (2009b) and Gadde et al. (2010). In this paper, we continue to explore the transition-based approach to Hindi dependency parsing, building on the state-of-the-art results of Ambati et al. (2009a) and Nivre (2009b) and exploring the common pool of features used by those systems. Through a series of experiments we select features incrementally to arrive"
W10-1411,W09-3824,0,0.111422,"Missing"
W10-1411,C08-1112,0,0.136807,"Missing"
W10-1411,W09-3036,0,\N,Missing
W10-1411,J08-4010,1,\N,Missing
W10-1411,R09-2001,1,\N,Missing
W10-1411,P93-1015,1,\N,Missing
W10-1411,D07-1096,1,\N,Missing
W10-1724,P02-1040,0,0.0791218,"→eC A→Be A→eC A→Be A→ A→f C A→Bf A→Cf A→f B A→ 3 Setup The baseline system for the shared task was a phrase based translation model based on bidirectional IBM- (Brown et al., 1993) and HMMmodels (Vogel et al., 1996) combined with the grow-diag-final-and heuristic. This is computed with the GIZA++ tool (Och and Ney, 2003) and the Moses toolkit (Koehn et al., 2007). The language model was a 5-gram SRILM (Stolcke, 2002). Parameters in the final translation system were determined with Minimum Error-Rate Training (Och, 2003), and translation quality was assessed with the automatic measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 168 Corpus German–English Europarl German–English news commentary English news commentary German–English news commentary German–English news commentary Type out of domain in-domain in-domain in-domain tuning data in-domain test data Size 1,219,343 sentence pairs 86,941 sentence pairs 48,653,884 sentences 2,051 sentence pairs 2,489 sentence pairs Table 1: Corpora available for the German–English translation task after baseline cleaning. System GIZA++ SBLITG SBLITG (only Europarl) SBLITG (only news) GIZA++ and SBLITG GIZA++ and SBLITG (only Europarl) GIZA++ and SBLI"
W10-1724,W09-2304,1,0.799204,"d one L2 ) synchronized CFG rules: ITG L1 ,L2 CFG L1 φ While training a Stochastic Bracketing ITG (SBITG) or LITG (SBLITG) with EM, expectations of probabilities over the biparse-forest are calculated. These expectations approach the true probabilities, and can be used as approximations. The probabilities over the biparse-forest can be used to select the one-best parse-tree, which in turn forces an alignment over the sentence pair. The alignments given by SBITGs and SBLITGs has been shown to give better translation quality than bidirectional IBM-models, when applied to short sentence corpora (Saers and Wu, 2009; Saers et al., 2009; Saers et al., 2010). In this paper we explore whether this hold for SBLITGs on standard sentence corpora. CFG L2 A→[BC] A→BC A→BC A→hBCi A→BC A→CB A → e/f A→e A→f Inducing an ITG from a parallel corpus is still slow, as the time complexity is O(Gn6 ). Several ways to get around this has been proposed (Zhang et al., 2008; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Taking a closer look at the linear ITGs (Saers et al., 2010), there are five rules in normal form. Decomposing these five rule types into monolingual rule types reveals that the monolingual g"
W10-1724,W09-3804,1,0.712078,"zed CFG rules: ITG L1 ,L2 CFG L1 φ While training a Stochastic Bracketing ITG (SBITG) or LITG (SBLITG) with EM, expectations of probabilities over the biparse-forest are calculated. These expectations approach the true probabilities, and can be used as approximations. The probabilities over the biparse-forest can be used to select the one-best parse-tree, which in turn forces an alignment over the sentence pair. The alignments given by SBITGs and SBLITGs has been shown to give better translation quality than bidirectional IBM-models, when applied to short sentence corpora (Saers and Wu, 2009; Saers et al., 2009; Saers et al., 2010). In this paper we explore whether this hold for SBLITGs on standard sentence corpora. CFG L2 A→[BC] A→BC A→BC A→hBCi A→BC A→CB A → e/f A→e A→f Inducing an ITG from a parallel corpus is still slow, as the time complexity is O(Gn6 ). Several ways to get around this has been proposed (Zhang et al., 2008; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Taking a closer look at the linear ITGs (Saers et al., 2010), there are five rules in normal form. Decomposing these five rule types into monolingual rule types reveals that the monolingual grammars are linear g"
W10-1724,N10-1050,1,0.31957,"1 ,L2 CFG L1 φ While training a Stochastic Bracketing ITG (SBITG) or LITG (SBLITG) with EM, expectations of probabilities over the biparse-forest are calculated. These expectations approach the true probabilities, and can be used as approximations. The probabilities over the biparse-forest can be used to select the one-best parse-tree, which in turn forces an alignment over the sentence pair. The alignments given by SBITGs and SBLITGs has been shown to give better translation quality than bidirectional IBM-models, when applied to short sentence corpora (Saers and Wu, 2009; Saers et al., 2009; Saers et al., 2010). In this paper we explore whether this hold for SBLITGs on standard sentence corpora. CFG L2 A→[BC] A→BC A→BC A→hBCi A→BC A→CB A → e/f A→e A→f Inducing an ITG from a parallel corpus is still slow, as the time complexity is O(Gn6 ). Several ways to get around this has been proposed (Zhang et al., 2008; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Taking a closer look at the linear ITGs (Saers et al., 2010), there are five rules in normal form. Decomposing these five rule types into monolingual rule types reveals that the monolingual grammars are linear grammars (LGs): LITG L"
W10-1724,J93-2003,0,0.0146871,"to get around this has been proposed (Zhang et al., 2008; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Taking a closer look at the linear ITGs (Saers et al., 2010), there are five rules in normal form. Decomposing these five rule types into monolingual rule types reveals that the monolingual grammars are linear grammars (LGs): LITG L1 ,L2 A → [ e/f C A → [ B e/f A → h e/f C A → h B e/f A → / ] ] i i LG L1 LGL2 A→eC A→Be A→eC A→Be A→ A→f C A→Bf A→Cf A→f B A→ 3 Setup The baseline system for the shared task was a phrase based translation model based on bidirectional IBM- (Brown et al., 1993) and HMMmodels (Vogel et al., 1996) combined with the grow-diag-final-and heuristic. This is computed with the GIZA++ tool (Och and Ney, 2003) and the Moses toolkit (Koehn et al., 2007). The language model was a 5-gram SRILM (Stolcke, 2002). Parameters in the final translation system were determined with Minimum Error-Rate Training (Och, 2003), and translation quality was assessed with the automatic measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 168 Corpus German–English Europarl German–English news commentary English news commentary German–English news commentary German–En"
W10-1724,P09-1104,0,0.0989571,"G), the grammar constant (G) can be eliminated, but O(n6 ) is still prohibitive for large data sets. There has been some work on approximate inference of ITGs. Zhang et al. (2008) present a method for evaluating spans in the sentence pair to determine whether they should be excluded or not. The algorithm has a best case time complexity of O(n3 ). Saers, Nivre & Wu (2009) introduce a beam pruning scheme, which reduces time complexity to O(bn3 ). They also show that severe pruning is possible without significant deterioration in alignment quality (as measured by downstream translation quality). Haghighi et al. (2009) use a simpler aligner as guidance for pruning, which reduces the time complexity by two orders of magnitude. Their work also partially implements the phrasal ITGs for translationdriven segmentation introduced in Wu (1997), although they only allow for one-to-many alignments, rather than many-to-many alignments. A more extreme approach is taken in Saers, Nivre & Wu (2010). Not only is the search severely pruned, but the grammar itself is limited to a lin167 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 167–171, c Uppsala, Sweden, 15-16 July 201"
W10-1724,P07-1065,0,0.0244674,"German–English translation task after baseline cleaning. System GIZA++ SBLITG SBLITG (only Europarl) SBLITG (only news) GIZA++ and SBLITG GIZA++ and SBLITG (only Europarl) GIZA++ and SBLITG (only news) BLEU 17.88 17.61 17.46 15.49 17.66 17.58 17.48 NIST 5.9748 5.8846 5.8491 5.4987 5.9650 5.9819 5.9693 Table 2: Results for the German–English translation task. with both. We also combined all three SBLITG systems with the baseline system to see whether the additional translation paths would help. The system we submitted corresponds to the “GIZA ++ and SBLITG (only news)” system, but with RandLM (Talbot and Osborne, 2007) as language model rather than SRILM. This was because we lacked the necessary RAM resources to calculate the full SRILM model before the system submission deadline. We chose to focus on the German–English translation task. The corpora resources available for that task is summarized in Table 1. We used the entire news commentary monolingual data concatenated with the English side of the Europarl bilingual data to train the language model. In retrospect, this was probably a bad choice, as others seem to prefer the use of two language models instead. We contrasted the baseline system with pure S"
W10-1724,C96-2141,0,0.186002,"ed (Zhang et al., 2008; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Taking a closer look at the linear ITGs (Saers et al., 2010), there are five rules in normal form. Decomposing these five rule types into monolingual rule types reveals that the monolingual grammars are linear grammars (LGs): LITG L1 ,L2 A → [ e/f C A → [ B e/f A → h e/f C A → h B e/f A → / ] ] i i LG L1 LGL2 A→eC A→Be A→eC A→Be A→ A→f C A→Bf A→Cf A→f B A→ 3 Setup The baseline system for the shared task was a phrase based translation model based on bidirectional IBM- (Brown et al., 1993) and HMMmodels (Vogel et al., 1996) combined with the grow-diag-final-and heuristic. This is computed with the GIZA++ tool (Och and Ney, 2003) and the Moses toolkit (Koehn et al., 2007). The language model was a 5-gram SRILM (Stolcke, 2002). Parameters in the final translation system were determined with Minimum Error-Rate Training (Och, 2003), and translation quality was assessed with the automatic measures BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 168 Corpus German–English Europarl German–English news commentary English news commentary German–English news commentary German–English news commentary Type out of d"
W10-1724,J97-3002,1,0.335182,"air to determine whether they should be excluded or not. The algorithm has a best case time complexity of O(n3 ). Saers, Nivre & Wu (2009) introduce a beam pruning scheme, which reduces time complexity to O(bn3 ). They also show that severe pruning is possible without significant deterioration in alignment quality (as measured by downstream translation quality). Haghighi et al. (2009) use a simpler aligner as guidance for pruning, which reduces the time complexity by two orders of magnitude. Their work also partially implements the phrasal ITGs for translationdriven segmentation introduced in Wu (1997), although they only allow for one-to-many alignments, rather than many-to-many alignments. A more extreme approach is taken in Saers, Nivre & Wu (2010). Not only is the search severely pruned, but the grammar itself is limited to a lin167 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 167–171, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics This means that LITGs are transduction grammars that transduce between linear languages. There is also a nice parallel in search time complexities between CFGs and ITGs on"
W10-1724,P08-1012,0,0.0607247,"TGs nor SDTGs are intuitively useful in translating natural languages, since STGs have no way to model reordering, and SDTGs require exponential time to be induced from examples (parallel corpora). Since Lately, there has been some interest in using Inversion Transduction Grammars (ITGs) for alignment purposes. The main problem with ITGs is the time complexity, O(Gn6 ) doesn’t scale well. By limiting the grammar to a bracketing ITG (BITG), the grammar constant (G) can be eliminated, but O(n6 ) is still prohibitive for large data sets. There has been some work on approximate inference of ITGs. Zhang et al. (2008) present a method for evaluating spans in the sentence pair to determine whether they should be excluded or not. The algorithm has a best case time complexity of O(n3 ). Saers, Nivre & Wu (2009) introduce a beam pruning scheme, which reduces time complexity to O(bn3 ). They also show that severe pruning is possible without significant deterioration in alignment quality (as measured by downstream translation quality). Haghighi et al. (2009) use a simpler aligner as guidance for pruning, which reduces the time complexity by two orders of magnitude. Their work also partially implements the phrasa"
W10-1724,P07-2045,0,\N,Missing
W10-1724,J03-1002,0,\N,Missing
W10-1724,P03-1021,0,\N,Missing
W10-2008,W09-1113,1,0.379162,"e, 2006a; Pollatsek et al., 2006; Reichle et al., 2009) and SWIFT (Engbert et al., 2002; Engbert et al., 2005) account for numerous of the known facts about saccade behavior in reading. This includes word frequency and predictability effects on fixation times, word skipping rates, and preview and spillover effects. A recent approach to eye-movement modeling, less tied to psychophysiological assumptions about the mechanisms that drive eye movements, is to build models directly from eye-tracking data using machine learning techniques inspired by recent work in natural language processing. Thus, Nilsson and Nivre (2009) show how a classifier can be trained on authentic eye-tracking data and then used to predict the saccade behavior of individual readers on new texts. Methodologically this differs from the standard approach in computational modeling of eye movement control, where model parameters are often fitted to data but model predictions are not evaluated on unseen data in order to assess the generalization error of these predictions. Without questioning the validity of the standard approach, we believe that the strict separation of training data and test data assumed in machine learning may provide addi"
W10-3802,J93-2003,0,0.053371,"parallel corpora an approximate search for parses is needed. The trade-off between speed and end-toend translation quality is investigated and compared to Inversion Transduction Grammars (Wu, 1997) and the standard tool for word alignment, Background Any form of automatic translation that relies on generalizations of observed translations needs to align these translations on a sub-sentential level. The standard way of doing this is by aligning words, which works well for languages that use white space separators between words. The standard method is a combination of the family of IBM-models (Brown et al., 1993) and Hidden Markov Models (Vogel et al., 1996). These methods all arrive at a function (A) from language 1 (F ) to language 2 (E). By running the process in both directions, two functions can be estimated and then combined to form an alignment. The simplest of these combinations are intersection and union, but usually, the intersection is heuristically extended. Transduction grammars on the other hand, impose a shared structure on the sentence pairs, thus forcing a consistent alignment in both directions. This method 10 Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statisti"
W10-3802,P81-1022,0,0.735882,"refer to that pair of terminals as a biterminal, which will be written as e/f . Any SDTG can be rephrased to contain permuted nonterminal productions and biterminal productions only, and we will call this the normal form of SDTGs. Note that it is not possible to produce a two-normal form for SDTGs, as there are some rules that are not binarizable (Wu, 1997; Huang et al., 2009). This is an important point to make, since efficient parsing for CFGs is based on either restricting parsing to only handle binary grammars (Cocke, 1969; Kasami, 1965; Younger, 1967), or rely on onthe-fly binarization (Earley, 1970). When translating with a grammar, parsing only has to be done in F , which is binarizable (since it is a CFG ), and can therefor be computed in polynomial time (O(n3 )). Once there is a parse tree for F , the corresponding tree for E can be easily constructed. When inducing a grammar from examples, however, biparsing (finding an analysis that is consistent across a sentence pair) is needed. The time complexity for biparsing with SDTGs is O(n2n+2 ), which is clearly intractable. Inversion Transduction Grammars or ITGs (Wu, 1997) are transduction grammars that have a two-normal form, thus guara"
W10-3802,P09-1104,0,0.0427671,"directions, two functions can be estimated and then combined to form an alignment. The simplest of these combinations are intersection and union, but usually, the intersection is heuristically extended. Transduction grammars on the other hand, impose a shared structure on the sentence pairs, thus forcing a consistent alignment in both directions. This method 10 Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 10–18, COLING 2010, Beijing, August 2010. has proved successful in the settings it has been tried (Zhang et al., 2008; Saers and Wu, 2009; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Most efforts focus on cutting down time complexity so that larger data sets than toyexamples can be processed. 3 Transduction Grammars Transduction grammars were first introduced in Lewis and Stearns (1968), and further developed in Aho and Ullman (1972). The original notation called for regular CFG-rules in language F with rephrased E productions, either in curly brackets, or comma separated. The bilingual version of CFGs is called Syntax-Directed Transduction Grammars ( SDTGs). To differentiate identical nonterminal symbols, indices were used (the b"
W10-3802,J09-4009,0,0.0165327,"terminals are pair up with the empty string (ǫ). A → X x B X a B ; 0, 1, 2, 3 X a → a, ǫ X x → ǫ, x Lexical rules involving the empty string are referred to as singletons. Whenever a preterminal is used to pair up two terminal symbols, we refer to that pair of terminals as a biterminal, which will be written as e/f . Any SDTG can be rephrased to contain permuted nonterminal productions and biterminal productions only, and we will call this the normal form of SDTGs. Note that it is not possible to produce a two-normal form for SDTGs, as there are some rules that are not binarizable (Wu, 1997; Huang et al., 2009). This is an important point to make, since efficient parsing for CFGs is based on either restricting parsing to only handle binary grammars (Cocke, 1969; Kasami, 1965; Younger, 1967), or rely on onthe-fly binarization (Earley, 1970). When translating with a grammar, parsing only has to be done in F , which is binarizable (since it is a CFG ), and can therefor be computed in polynomial time (O(n3 )). Once there is a parse tree for F , the corresponding tree for E can be easily constructed. When inducing a grammar from examples, however, biparsing (finding an analysis that is consistent across"
W10-3802,P07-2045,0,0.00937191,"03:10 35 17:00 1:49 6.7312 6.7101 6.6657 6.6637 6.6464 6.6464 Training times 38:00 1:20:00 3:40 7:33 Table 2: Results for the Spanish–English translation task. out (see table 1). The GIZA++ system was built according to the instructions for creating a baseline system for the Fifth Workshop on Statistical Machine Translation (WMT’10),1 but the above corpora were used instead of those supplied by the workshop. This includes word alignment with GIZA++, a 5-gram language model built with SRILM (Stolcke, 2002) and parameter tuning with MERT (Och, 2003). To carry out the actual translations, Moses (Koehn et al., 2007) was used. The SBITG and SBLTG systems were built in exactly the same way, except that the alignments from GIZA++ were replaced by those from the respective grammars. In addition to trying out exhaustive biparsing 1 http://www.statmt.org/wmt10/ 15 for SBITGs and SBLTGs on three different translation tasks, several different levels of pruning were tried (1, 10, 25, 50, 75 and 100). We also used the grammar induced from SBLTGs with a beam size of 25 to seed SBITGs (see section 5), which were then run for an additional iteration of EM, also with beam size 25. All systems are evaluated with BLEU ("
W10-3802,2005.mtsummit-papers.11,0,0.0193828,"study the impact of pruning on efficiency and translation quality. Initial grammars will be estimated by counting cooccurrences in the training corpus, after which expectation-maximization (EM) will be used to refine the initial estimate. At the last iteration, the one-best parse of each sentence will be considered as the word alignment of that sentence. In order to keep the experiments comparable, relatively small corpora will be used. If larger corpora were used, it would not be possible to get any results for unpruned SBITGs because of the prohibitive time complexity. The Europarl corpus (Koehn, 2005) was used as a starting point, and then all sentence pairs where one of the sentences were longer than 10 tokens were filtered Figure 1: Trade-offs between translation quality (as measured by BLEU) and biparsing time (in seconds plotted on a logarithmic scale) for SBLTGs, SBITGs and the combination. System 1 10 Beam size 50 25 75 100 ∞ 0.2661 0.2625 0.2597 0.2671 0.2633 0.2597 0.2663 0.2628 0.2597 6.7329 6.6714 6.6464 6.7445 6.6863 6.6464 6.6793 6.6765 6.6464 2:00:00 9:44 2:40:00 12:13 3:20:00 11:59 BLEU SBITG SBLTG GIZA++ 0.1234 0.2574 0.2597 0.2608 0.2645 0.2597 0.2655 0.2631 0.2597 0.2653 0"
W10-3802,J03-1002,0,0.0148984,"Missing"
W10-3802,P03-1021,0,0.00600772,"++ SBITG SBLTG 3.9705 6.6023 6.6464 6.6439 6.6800 6.6464 03:10 35 17:00 1:49 6.7312 6.7101 6.6657 6.6637 6.6464 6.6464 Training times 38:00 1:20:00 3:40 7:33 Table 2: Results for the Spanish–English translation task. out (see table 1). The GIZA++ system was built according to the instructions for creating a baseline system for the Fifth Workshop on Statistical Machine Translation (WMT’10),1 but the above corpora were used instead of those supplied by the workshop. This includes word alignment with GIZA++, a 5-gram language model built with SRILM (Stolcke, 2002) and parameter tuning with MERT (Och, 2003). To carry out the actual translations, Moses (Koehn et al., 2007) was used. The SBITG and SBLTG systems were built in exactly the same way, except that the alignments from GIZA++ were replaced by those from the respective grammars. In addition to trying out exhaustive biparsing 1 http://www.statmt.org/wmt10/ 15 for SBITGs and SBLTGs on three different translation tasks, several different levels of pruning were tried (1, 10, 25, 50, 75 and 100). We also used the grammar induced from SBLTGs with a beam size of 25 to seed SBITGs (see section 5), which were then run for an additional iteration of"
W10-3802,P02-1040,0,0.0841085,"was used. The SBITG and SBLTG systems were built in exactly the same way, except that the alignments from GIZA++ were replaced by those from the respective grammars. In addition to trying out exhaustive biparsing 1 http://www.statmt.org/wmt10/ 15 for SBITGs and SBLTGs on three different translation tasks, several different levels of pruning were tried (1, 10, 25, 50, 75 and 100). We also used the grammar induced from SBLTGs with a beam size of 25 to seed SBITGs (see section 5), which were then run for an additional iteration of EM, also with beam size 25. All systems are evaluated with BLEU (Papineni et al., 2002) and NIST (Doddington, 2002). 7 Results The results for the three different translation tasks are presented in Tables 2, 3 and 4. It is interesting to note that the trend they portray is quite similar. When the beam is very narrow, GIZA++ is better, but already at beam size 10, both transduction grammars are superior. ConSystem 1 10 Beam size 50 25 75 100 ∞ 0.2668 0.2672 0.2603 0.2655 0.2662 0.2603 0.2663 0.2649 0.2603 6.8068 6.8020 6.6907 6.8088 6.7925 6.6907 6.8151 6.7784 6.6907 2:10:00 9:35 2:45:00 13:56 3:10:00 10:52 BLEU SBITG SBLTG GIZA++ 0.1268 0.2600 0.2603 0.2632 0.2638 0.2603 0.2654"
W10-3802,W09-2304,1,0.787343,"the process in both directions, two functions can be estimated and then combined to form an alignment. The simplest of these combinations are intersection and union, but usually, the intersection is heuristically extended. Transduction grammars on the other hand, impose a shared structure on the sentence pairs, thus forcing a consistent alignment in both directions. This method 10 Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 10–18, COLING 2010, Beijing, August 2010. has proved successful in the settings it has been tried (Zhang et al., 2008; Saers and Wu, 2009; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Most efforts focus on cutting down time complexity so that larger data sets than toyexamples can be processed. 3 Transduction Grammars Transduction grammars were first introduced in Lewis and Stearns (1968), and further developed in Aho and Ullman (1972). The original notation called for regular CFG-rules in language F with rephrased E productions, either in curly brackets, or comma separated. The bilingual version of CFGs is called Syntax-Directed Transduction Grammars ( SDTGs). To differentiate identical nonterminal symbols, i"
W10-3802,W09-3804,1,0.888955,"ns can be estimated and then combined to form an alignment. The simplest of these combinations are intersection and union, but usually, the intersection is heuristically extended. Transduction grammars on the other hand, impose a shared structure on the sentence pairs, thus forcing a consistent alignment in both directions. This method 10 Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 10–18, COLING 2010, Beijing, August 2010. has proved successful in the settings it has been tried (Zhang et al., 2008; Saers and Wu, 2009; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Most efforts focus on cutting down time complexity so that larger data sets than toyexamples can be processed. 3 Transduction Grammars Transduction grammars were first introduced in Lewis and Stearns (1968), and further developed in Aho and Ullman (1972). The original notation called for regular CFG-rules in language F with rephrased E productions, either in curly brackets, or comma separated. The bilingual version of CFGs is called Syntax-Directed Transduction Grammars ( SDTGs). To differentiate identical nonterminal symbols, indices were used (the bag of nonterminals f"
W10-3802,N10-1050,1,0.576259,"that Linear Transduction Grammars (LTGs) generate the same transductions as Linear Inversion Transduction Grammars, and present a scheme for arriving at LTGs by bilingualizing Linear Grammars. We also present a method for obtaining Inversion Transduction Grammars from Linear (Inversion) Transduction Grammars, which can speed up grammar induction from parallel corpora dramatically. 2 1 Introduction In this paper we introduce Linear Transduction Grammars ( LTGs), which are the bilingual case of Linear Grammars ( LGs). We also show that LTG s are equal to Linear Inversion Transduction Grammars (Saers et al., 2010). To be able to induce transduction grammars directly from parallel corpora an approximate search for parses is needed. The trade-off between speed and end-toend translation quality is investigated and compared to Inversion Transduction Grammars (Wu, 1997) and the standard tool for word alignment, Background Any form of automatic translation that relies on generalizations of observed translations needs to align these translations on a sub-sentential level. The standard way of doing this is by aligning words, which works well for languages that use white space separators between words. The stan"
W10-3802,C96-2141,0,0.410167,"rses is needed. The trade-off between speed and end-toend translation quality is investigated and compared to Inversion Transduction Grammars (Wu, 1997) and the standard tool for word alignment, Background Any form of automatic translation that relies on generalizations of observed translations needs to align these translations on a sub-sentential level. The standard way of doing this is by aligning words, which works well for languages that use white space separators between words. The standard method is a combination of the family of IBM-models (Brown et al., 1993) and Hidden Markov Models (Vogel et al., 1996). These methods all arrive at a function (A) from language 1 (F ) to language 2 (E). By running the process in both directions, two functions can be estimated and then combined to form an alignment. The simplest of these combinations are intersection and union, but usually, the intersection is heuristically extended. Transduction grammars on the other hand, impose a shared structure on the sentence pairs, thus forcing a consistent alignment in both directions. This method 10 Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 10–18, COLING 2010, Bei"
W10-3802,J97-3002,1,0.885768,"rom Linear (Inversion) Transduction Grammars, which can speed up grammar induction from parallel corpora dramatically. 2 1 Introduction In this paper we introduce Linear Transduction Grammars ( LTGs), which are the bilingual case of Linear Grammars ( LGs). We also show that LTG s are equal to Linear Inversion Transduction Grammars (Saers et al., 2010). To be able to induce transduction grammars directly from parallel corpora an approximate search for parses is needed. The trade-off between speed and end-toend translation quality is investigated and compared to Inversion Transduction Grammars (Wu, 1997) and the standard tool for word alignment, Background Any form of automatic translation that relies on generalizations of observed translations needs to align these translations on a sub-sentential level. The standard way of doing this is by aligning words, which works well for languages that use white space separators between words. The standard method is a combination of the family of IBM-models (Brown et al., 1993) and Hidden Markov Models (Vogel et al., 1996). These methods all arrive at a function (A) from language 1 (F ) to language 2 (E). By running the process in both directions, two f"
W10-3802,P08-1012,0,0.0612347,"e 2 (E). By running the process in both directions, two functions can be estimated and then combined to form an alignment. The simplest of these combinations are intersection and union, but usually, the intersection is heuristically extended. Transduction grammars on the other hand, impose a shared structure on the sentence pairs, thus forcing a consistent alignment in both directions. This method 10 Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 10–18, COLING 2010, Beijing, August 2010. has proved successful in the settings it has been tried (Zhang et al., 2008; Saers and Wu, 2009; Haghighi et al., 2009; Saers et al., 2009; Saers et al., 2010). Most efforts focus on cutting down time complexity so that larger data sets than toyexamples can be processed. 3 Transduction Grammars Transduction grammars were first introduced in Lewis and Stearns (1968), and further developed in Aho and Ullman (1972). The original notation called for regular CFG-rules in language F with rephrased E productions, either in curly brackets, or comma separated. The bilingual version of CFGs is called Syntax-Directed Transduction Grammars ( SDTGs). To differentiate identical no"
W11-0612,W10-2010,0,0.110104,"Missing"
W11-0612,N01-1021,0,0.0470278,"nevertheless beyond the scope of this paper. Most of the stimulus variables included in the analysis have been shown to correlate with reading times in other regression studies: the number of letters in the word, the logarithm of the word’s relative frequency (based on occurrences in the British National Corpus), the logarithm of the conditional (bigram) probability of the word (based on occurrences in the Google Web 1T 5-gram corpus (Brants and Franz, 2006)), the syntactic surprisal and entropy scores3 (computed here using the probabilistic PCFG parser by Roark et al. (2009)). The surprisal (Hale, 2001) at word wi refers to the negative log probability of wi given the preceding words, computed using the prefix probabilities of the parser. A number of studies have previously established a positive relation between surprisal and word-reading times (Boston et al., 2008; Demberg and Keller, 2008; Roark et al., 2009). The entropy, as quantified here, approximates the structural uncertainty associated with the rest of the sentence, or what is yet to be computed (Roark et al., 2009). In this experiment, we use the first 16 texts in the Dundee corpus for parameter estimation, and the following two t"
W11-0612,D09-1034,0,0.0444273,"Missing"
W11-1512,W07-0901,0,0.0611734,"Missing"
W11-1512,A00-1031,0,0.0571329,"verb interpretation present in the dictionary, regardless of context. For example, the word f¨or will always be analysed both as a verb (bring) and as a preposition (for), even though in most cases the prepositional interpretation is the correct one. When running the maximum five steps in the verb extraction procedure, the tagger will disambiguate in cases where the morphological analyser has produced both a verb interpretation and a non-verb interpretation. The tagger used in this study is HunPOS (Hal´acsy et al., 2007), a free and open source reimplementation of the HMM-based TnT-tagger by Brants (2000). Megyesi (2008) showed that the HunPOS tagger trained on the Stockholm-Ume˚a Corpus (Gustafson-Capkov´a and Hartmann, 2006) is one of the best performing taggers for Swedish texts. 4 Experiments This section describes the experimental setup including data preparation and experiments. 4.1 Data Preparation A subset of Per Larssons dombok, a selection of court records from 1638, was used as a basis for developing the automatic verb extraction tool. This text consists of 11 439 tokens in total, and was printed by Edling (1937). The initial 984 tokens of the text were used as development data, i.e"
W11-1512,P07-2053,0,0.150869,"Missing"
W11-1512,J75-4040,0,0.797531,"Missing"
W11-1512,W09-4636,0,\N,Missing
W11-4602,W05-1505,0,0.0720976,"Missing"
W11-4602,P10-1110,0,0.0539841,"hoice of transition system Nivre (2009), and transition systems can be extended to handle directed acyclic graphs (Sagae and Tsujii, 2008). Transition-based parsers can base their decisions on very rich representations of the derivation history (including the partially built dependency graph) but may suffer from error propagation due to search errors especially if the statistical model is trained to maximize the accuracy of local transitions rather than complete transition sequences. Zhang and Clark (2008) showed how these problems can be alleviated by global optimization and beam search, and Huang and Sagae (2010) obtained further improvements through ambiguity packing. technique is parser stacking, where one parser is used to generate input features for another parser, a method that was used by Nivre and McDonald (2008) to combine chart parsing and transitionbased parsing, with further improvements reported by Torres Martins et al. (2008). Finally, Koo et al. (2010) used dual decomposition to combine thirdorder chart parsing and arc-factored spanning tree parsing with excellent empirical results. 4 Comparative Evaluation When Yamada and Matsumoto (2003) presented the first comparative evaluation of de"
W11-4602,P10-1001,0,0.0607461,"form of context-free parsing and reuse chart parsing algorithms like CKY and Earley, an idea that is implicit already in Hays (1964). Thanks to the constraints on dependency trees, it is possible to reduce complexity to O(n3 ) for lexicalized parsing using the spanbased representation proposed by Eisner (1996). Coupled with statistical models of increasing complexity, this technique has resulted in excellent parsing accuracy for projective trees, with features defined over single arcs (McDonald et al., 2005a), pairs of arcs (McDonald and Pereira, 2006; Carreras, 2007) or even triples of arcs (Koo and Collins, 2010). These models are usually referred to as first-, second- and third-order models. One limitation of this parsing approach is that it does not easily extend to non-projective trees, let alone 3.3 Transition-Based Parsing A third prominent method is to view parsing as deterministic search through a transition system (or state machine), guided by a statistical 7 Joakim Nivre Parser Yamada and Matsumoto (2003) McDonald et al. (2005a) Collins (1999) McDonald and Pereira (2006) Charniak (2000) Koo et al. (2010) Sagae and Lavie (2006) Zhang and Nivre (2011) Koo and Collins (2010) Type Trans-Local Cha"
W11-4602,D10-1125,0,0.294903,"pairs of arcs (McDonald and Pereira, 2006; Carreras, 2007) or even triples of arcs (Koo and Collins, 2010). These models are usually referred to as first-, second- and third-order models. One limitation of this parsing approach is that it does not easily extend to non-projective trees, let alone 3.3 Transition-Based Parsing A third prominent method is to view parsing as deterministic search through a transition system (or state machine), guided by a statistical 7 Joakim Nivre Parser Yamada and Matsumoto (2003) McDonald et al. (2005a) Collins (1999) McDonald and Pereira (2006) Charniak (2000) Koo et al. (2010) Sagae and Lavie (2006) Zhang and Nivre (2011) Koo and Collins (2010) Type Trans-Local Chart-1st PCFG Chart-2nd PCFG Hybrid-Dual Hybrid-MST Trans-Global Chart-3rd UAS 90.3 90.9 91.5 91.5 92.1 92.5 92.7 92.9 93.0 Parser Collins (1999) McDonald et al. (2005a) Charniak (2000) McDonald et al. (2005b) Hall and Nov´ak (2005) McDonald and Pereira (2006) Nivre (2009) ˇ Zeman and Zabokrtsk´ y (2005) Koo et al. (2010) Type PCFG Chart-1st PCFG MST PCFG+Post Chart-2nd+Post Trans-Local Hybrid-Greedy Hybrid-Dual UAS 82.2 83.3 84.3 84.4 85.0 85.2 86.1 86.3 87.3 Table 1: Dependency parsing for English (WSJPTB"
W11-4602,J93-2004,0,0.0395889,"ng, where one parser is used to generate input features for another parser, a method that was used by Nivre and McDonald (2008) to combine chart parsing and transitionbased parsing, with further improvements reported by Torres Martins et al. (2008). Finally, Koo et al. (2010) used dual decomposition to combine thirdorder chart parsing and arc-factored spanning tree parsing with excellent empirical results. 4 Comparative Evaluation When Yamada and Matsumoto (2003) presented the first comparative evaluation of dependency parsing for English, using data from the WSJ section of the Penn Treebank (Marcus et al., 1993) with what has later become known as the Penn2Malt conversion to dependencies, they observed that although their own bare-bones dependency parser had the advantage of simplicity and efficiency, it was not quite as accurate as the parsers of Collins (1999) and Charniak (2000). However, as the results reported in Table 1 clearly show, there has been a tremendous development since then, and the third-order chart parser of Koo and Collins (2010) is now as accurate as any phrase structure parser. Bare-bones dependency parsers are also the most efficient parsers available, with an average parsing ti"
W11-4602,P09-1039,0,0.0197097,"is a sum of independent arc weights. Under these assumptions, finding the highest scoring dependency tree is equivalent to finding the maximum directed spanning tree in a complete graph containing all possible dependency arcs, a problem that can be computed in O(n2 ) time using algorithms from graph theory. Unfortunately, any attempt to extend the scope of weighted constraints beyond single arcs makes the parsing problem NP complete. Another variation of the constraint-based approach is the use of integer linear programming, which was pioneered by Riedel et al. (2006) and further improved by Martins et al. (2009). Parsing Techniques 3.1 Chart Parsing Techniques A straightforward method for dependency parsing is to view it as a restricted form of context-free parsing and reuse chart parsing algorithms like CKY and Earley, an idea that is implicit already in Hays (1964). Thanks to the constraints on dependency trees, it is possible to reduce complexity to O(n3 ) for lexicalized parsing using the spanbased representation proposed by Eisner (1996). Coupled with statistical models of increasing complexity, this technique has resulted in excellent parsing accuracy for projective trees, with features defined"
W11-4602,P90-1005,0,0.41366,"ic graphs. Dependency parsers are generally evaluated by measuring precision and recall on dependency relations, with or without labels. When dependency graphs are restricted to trees, precision and recall coincide and are normally referred to as the attachment score. 3 3.2 Parsing as Constraint Satisfaction A different approach is to view parsing as a constraint satisfaction problem, starting from a compact representation of all dependency graphs compatible with the input and successively eliminating invalid graphs through the propagation of grammatical constraints, as originally proposed by Maruyama (1990). By adding numerical weights to constraints and defining the score of a graph as a function of the weights of violated constraints, Menzel and Schr¨oder (1998) turned this into an optimization problem where the goal is to find the highest-scoring dependency graph. Constraintbased parsing can easily accommodate different classes of dependency graphs and do not have the same inherent limitations on features or constraints as chart parsing, but the parsing problem is computationally intractable in general, so exact search methods cannot be used except in special cases. An interesting special cas"
W11-4602,E06-1011,0,0.42056,"ire graphs to be connected and acyclic, then words can have more than one head, which is convenient for representing deep syntactic relations. If we require the graph to be a tree, then each word can have at most one head, but we can still represent extraction phenomena using nonBolette Sandford Pedersen, Gunta Neˇspore and Inguna Skadin¸a (Eds.) NODALIDA 2011 Conference Proceedings, pp. 6–11 Bare-Bones Dependency Parsing — A Case for Occam’s Razor? Figure 1: Dependency graphs: directed acyclic graph (left), tree (middle), projective tree (right). directed acyclic graphs. However, as shown by McDonald and Pereira (2006), it is possible to recover both non-projective arcs and multiple heads through post-processing. projective arcs. If we require every subtree to have a contiguous yield, finally, we get the class of projective trees. The different classes are illustrated in Figure 1. Regardless of what restrictions we put on dependency graphs, the parsing problem consists in finding the optimal set of arcs, given the nodes as input. This is different from phrase structure parsing, where only the terminal nodes are given as input and both internal nodes and edges have to be inferred during parsing. Many algorit"
W11-4602,P05-1012,0,0.638914,"aints and defining the score of a graph as a function of the weights of violated constraints, Menzel and Schr¨oder (1998) turned this into an optimization problem where the goal is to find the highest-scoring dependency graph. Constraintbased parsing can easily accommodate different classes of dependency graphs and do not have the same inherent limitations on features or constraints as chart parsing, but the parsing problem is computationally intractable in general, so exact search methods cannot be used except in special cases. An interesting special case is the arc-factored model defined by McDonald et al. (2005b), where the score of a dependency tree is a sum of independent arc weights. Under these assumptions, finding the highest scoring dependency tree is equivalent to finding the maximum directed spanning tree in a complete graph containing all possible dependency arcs, a problem that can be computed in O(n2 ) time using algorithms from graph theory. Unfortunately, any attempt to extend the scope of weighted constraints beyond single arcs makes the parsing problem NP complete. Another variation of the constraint-based approach is the use of integer linear programming, which was pioneered by Riede"
W11-4602,H05-1066,0,0.147458,"Missing"
W11-4602,W98-0509,0,0.11284,"Missing"
W11-4602,P05-1011,0,0.0323006,"009) evaluated a number of statistical parsers specifically on their capacity to recover unbounded dependencies like those involved in different types of relative clauses, interrogative clauses and right node raising. The evaluation was extended to bare-bones dependency parsers in Nivre et al. (2010), and the overall results show that systems like MaltParser and MSTParser, augmented with simple post-processing for inferring multiple heads, perform at least as well as other types of treebank parsers, although not quite as well as grammar-driven systems like those of Clark and Curran (2004) and Miyao and Tsujii (2005). 5 References Giuseppe Attardi. 2006. Experiments with a multilanguage non-projective dependency parser. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 166– 170. Gosse Bouma, Jori Mur, Gertjan van Noord, Lonneke van der Plas, and J¨org Tiedemann. 2005. Question answering for dutch using dependency relations. In Working Notes of the 6th Workshop of the CrossLanguage Evaluation Forum (CLEF 2005). Marie Candito, Joakim Nivre, Pascal Denis, and Enrique Henestroza Anguiano. 2010. Benchmarking of statistical dependency parsers for french. In Coling 2"
W11-4602,P08-1108,1,0.829896,"sentations of the derivation history (including the partially built dependency graph) but may suffer from error propagation due to search errors especially if the statistical model is trained to maximize the accuracy of local transitions rather than complete transition sequences. Zhang and Clark (2008) showed how these problems can be alleviated by global optimization and beam search, and Huang and Sagae (2010) obtained further improvements through ambiguity packing. technique is parser stacking, where one parser is used to generate input features for another parser, a method that was used by Nivre and McDonald (2008) to combine chart parsing and transitionbased parsing, with further improvements reported by Torres Martins et al. (2008). Finally, Koo et al. (2010) used dual decomposition to combine thirdorder chart parsing and arc-factored spanning tree parsing with excellent empirical results. 4 Comparative Evaluation When Yamada and Matsumoto (2003) presented the first comparative evaluation of dependency parsing for English, using data from the WSJ section of the Penn Treebank (Marcus et al., 1993) with what has later become known as the Penn2Malt conversion to dependencies, they observed that although"
W11-4602,P81-1022,0,0.462262,"Missing"
W11-4602,C10-1094,1,0.879542,"Missing"
W11-4602,W03-3017,1,0.864919,"McDonald and Pereira (2006) Nivre (2009) ˇ Zeman and Zabokrtsk´ y (2005) Koo et al. (2010) Type PCFG Chart-1st PCFG MST PCFG+Post Chart-2nd+Post Trans-Local Hybrid-Greedy Hybrid-Dual UAS 82.2 83.3 84.3 84.4 85.0 85.2 86.1 86.3 87.3 Table 1: Dependency parsing for English (WSJPTB, Penn2Malt); unlabeled attachment scores. Table 2: Dependency parsing for Czech (PDT); unlabeled attachment scores. model for predicting the next transition, an idea first proposed by Yamada and Matsumoto (2003). Transition-based parsing can be very efficient, with linear running time for projective dependency trees (Nivre, 2003) and limited subsets of non-projective trees (Attardi, 2006). For arbitrary non-projective trees, the worst-case complexity is quadratic, but observed running time can still be linear with an appropriate choice of transition system Nivre (2009), and transition systems can be extended to handle directed acyclic graphs (Sagae and Tsujii, 2008). Transition-based parsers can base their decisions on very rich representations of the derivation history (including the partially built dependency graph) but may suffer from error propagation due to search errors especially if the statistical model is tra"
W11-4602,P09-1040,1,0.863752,"sing as deterministic search through a transition system (or state machine), guided by a statistical 7 Joakim Nivre Parser Yamada and Matsumoto (2003) McDonald et al. (2005a) Collins (1999) McDonald and Pereira (2006) Charniak (2000) Koo et al. (2010) Sagae and Lavie (2006) Zhang and Nivre (2011) Koo and Collins (2010) Type Trans-Local Chart-1st PCFG Chart-2nd PCFG Hybrid-Dual Hybrid-MST Trans-Global Chart-3rd UAS 90.3 90.9 91.5 91.5 92.1 92.5 92.7 92.9 93.0 Parser Collins (1999) McDonald et al. (2005a) Charniak (2000) McDonald et al. (2005b) Hall and Nov´ak (2005) McDonald and Pereira (2006) Nivre (2009) ˇ Zeman and Zabokrtsk´ y (2005) Koo et al. (2010) Type PCFG Chart-1st PCFG MST PCFG+Post Chart-2nd+Post Trans-Local Hybrid-Greedy Hybrid-Dual UAS 82.2 83.3 84.3 84.4 85.0 85.2 86.1 86.3 87.3 Table 1: Dependency parsing for English (WSJPTB, Penn2Malt); unlabeled attachment scores. Table 2: Dependency parsing for Czech (PDT); unlabeled attachment scores. model for predicting the next transition, an idea first proposed by Yamada and Matsumoto (2003). Transition-based parsing can be very efficient, with linear running time for projective dependency trees (Nivre, 2003) and limited subsets of non-p"
W11-4602,P06-1055,0,0.0396344,"cheme is that the output may not be a well-formed dependency graphs even if all the component parsers output well-formed graphs. This problem was solved by Sagae and Lavie (2006), who showed that we can use the spanning tree method of McDonald et al. (2005b) for parser combination by letting parsers vote for arcs in the complete graph and then extract the maximum spanning tree. Another hybrid 8 Bare-Bones Dependency Parsing — A Case for Occam’s Razor? extent they are also adequate as theoretical models of natural language syntax in general is of course a completely different question. parser (Petrov et al., 2006; Petrov and Klein, 2007) and the parser of Charniak and Johnson (2005). However, the evaluation was performed after converting the parser output to so-called collapsed dependencies, a conversion process that is less accurate for dependency trees than for phrase structure trees. More importantly, the bare-bones dependency parsers were run without proper optimization, whereas most of the phrase structure parsers have been optimized for a long time not only for English but in particular for the type of Wall Street Journal text that was used in the evaluation. It is therefore likely that the eval"
W11-4602,P11-2033,1,0.871309,"6; Carreras, 2007) or even triples of arcs (Koo and Collins, 2010). These models are usually referred to as first-, second- and third-order models. One limitation of this parsing approach is that it does not easily extend to non-projective trees, let alone 3.3 Transition-Based Parsing A third prominent method is to view parsing as deterministic search through a transition system (or state machine), guided by a statistical 7 Joakim Nivre Parser Yamada and Matsumoto (2003) McDonald et al. (2005a) Collins (1999) McDonald and Pereira (2006) Charniak (2000) Koo et al. (2010) Sagae and Lavie (2006) Zhang and Nivre (2011) Koo and Collins (2010) Type Trans-Local Chart-1st PCFG Chart-2nd PCFG Hybrid-Dual Hybrid-MST Trans-Global Chart-3rd UAS 90.3 90.9 91.5 91.5 92.1 92.5 92.7 92.9 93.0 Parser Collins (1999) McDonald et al. (2005a) Charniak (2000) McDonald et al. (2005b) Hall and Nov´ak (2005) McDonald and Pereira (2006) Nivre (2009) ˇ Zeman and Zabokrtsk´ y (2005) Koo et al. (2010) Type PCFG Chart-1st PCFG MST PCFG+Post Chart-2nd+Post Trans-Local Hybrid-Greedy Hybrid-Dual UAS 82.2 83.3 84.3 84.4 85.0 85.2 86.1 86.3 87.3 Table 1: Dependency parsing for English (WSJPTB, Penn2Malt); unlabeled attachment scores. Tab"
W11-4602,W06-2934,0,0.0480898,"Missing"
W11-4602,P02-1035,0,0.0384843,"in to examine whether the simpler model can in fact rival the performance of more complex systems. Although the empirical evidence is still limited, I conclude that bare-bones dependency parsers fare well in terms of parsing accuracy and often excel in terms of efficiency. 1 Introduction The notion of dependency has come to play an increasingly central role in natural language parsing in recent years. On the one hand, lexical dependencies have been incorporated in statistical models for a variety of syntactic representations such as phrase structure trees (Collins, 1999), LFG representations (Riezler et al., 2002), and CCG derivations (Clark and Curran, 2004). On the other hand, dependency relations extracted from such representations have been exploited in many practical applications, for example, information extraction (Culotta and Sorensen, 2004), question answering (Bouma et al., 2005), and machine translation (Ding and Palmer, 2004). Given these developments, it is not surprising that there has also been a growing interest in parsing models that map sentences directly to dependency trees, an approach that will be referred to as bare-bones dependency parsing to distinguish it from parsing methods w"
W11-4602,D09-1085,0,0.0140528,"n results, although representative for out-ofthe-box comparisons on this particular data set, do not generalize to other settings. Evidence for this conclusion comes from a similar study by Candito et al. (2010), where different types of parsers were evaluated on data from the French Treebank, and where there was practically no difference in accuracy between the best bare-bones dependency parsers (MaltParser, MSTParser) and the best phrase structure parser (Berkeley). With respect to efficiency, the transition-based MaltParser was found to be about ten times faster than the other two parsers. Rimell et al. (2009) evaluated a number of statistical parsers specifically on their capacity to recover unbounded dependencies like those involved in different types of relative clauses, interrogative clauses and right node raising. The evaluation was extended to bare-bones dependency parsers in Nivre et al. (2010), and the overall results show that systems like MaltParser and MSTParser, augmented with simple post-processing for inferring multiple heads, perform at least as well as other types of treebank parsers, although not quite as well as grammar-driven systems like those of Clark and Curran (2004) and Miya"
W11-4602,N06-2033,0,0.130822,"Donald and Pereira, 2006; Carreras, 2007) or even triples of arcs (Koo and Collins, 2010). These models are usually referred to as first-, second- and third-order models. One limitation of this parsing approach is that it does not easily extend to non-projective trees, let alone 3.3 Transition-Based Parsing A third prominent method is to view parsing as deterministic search through a transition system (or state machine), guided by a statistical 7 Joakim Nivre Parser Yamada and Matsumoto (2003) McDonald et al. (2005a) Collins (1999) McDonald and Pereira (2006) Charniak (2000) Koo et al. (2010) Sagae and Lavie (2006) Zhang and Nivre (2011) Koo and Collins (2010) Type Trans-Local Chart-1st PCFG Chart-2nd PCFG Hybrid-Dual Hybrid-MST Trans-Global Chart-3rd UAS 90.3 90.9 91.5 91.5 92.1 92.5 92.7 92.9 93.0 Parser Collins (1999) McDonald et al. (2005a) Charniak (2000) McDonald et al. (2005b) Hall and Nov´ak (2005) McDonald and Pereira (2006) Nivre (2009) ˇ Zeman and Zabokrtsk´ y (2005) Koo et al. (2010) Type PCFG Chart-1st PCFG MST PCFG+Post Chart-2nd+Post Trans-Local Hybrid-Greedy Hybrid-Dual UAS 82.2 83.3 84.3 84.4 85.0 85.2 86.1 86.3 87.3 Table 1: Dependency parsing for English (WSJPTB, Penn2Malt); unlabeled"
W11-4602,C08-1095,0,0.0174314,"Dependency parsing for Czech (PDT); unlabeled attachment scores. model for predicting the next transition, an idea first proposed by Yamada and Matsumoto (2003). Transition-based parsing can be very efficient, with linear running time for projective dependency trees (Nivre, 2003) and limited subsets of non-projective trees (Attardi, 2006). For arbitrary non-projective trees, the worst-case complexity is quadratic, but observed running time can still be linear with an appropriate choice of transition system Nivre (2009), and transition systems can be extended to handle directed acyclic graphs (Sagae and Tsujii, 2008). Transition-based parsers can base their decisions on very rich representations of the derivation history (including the partially built dependency graph) but may suffer from error propagation due to search errors especially if the statistical model is trained to maximize the accuracy of local transitions rather than complete transition sequences. Zhang and Clark (2008) showed how these problems can be alleviated by global optimization and beam search, and Huang and Sagae (2010) obtained further improvements through ambiguity packing. technique is parser stacking, where one parser is used to"
W11-4602,D08-1017,0,0.0351256,"Missing"
W11-4602,W03-3023,0,0.374931,"cellent parsing accuracy for projective trees, with features defined over single arcs (McDonald et al., 2005a), pairs of arcs (McDonald and Pereira, 2006; Carreras, 2007) or even triples of arcs (Koo and Collins, 2010). These models are usually referred to as first-, second- and third-order models. One limitation of this parsing approach is that it does not easily extend to non-projective trees, let alone 3.3 Transition-Based Parsing A third prominent method is to view parsing as deterministic search through a transition system (or state machine), guided by a statistical 7 Joakim Nivre Parser Yamada and Matsumoto (2003) McDonald et al. (2005a) Collins (1999) McDonald and Pereira (2006) Charniak (2000) Koo et al. (2010) Sagae and Lavie (2006) Zhang and Nivre (2011) Koo and Collins (2010) Type Trans-Local Chart-1st PCFG Chart-2nd PCFG Hybrid-Dual Hybrid-MST Trans-Global Chart-3rd UAS 90.3 90.9 91.5 91.5 92.1 92.5 92.7 92.9 93.0 Parser Collins (1999) McDonald et al. (2005a) Charniak (2000) McDonald et al. (2005b) Hall and Nov´ak (2005) McDonald and Pereira (2006) Nivre (2009) ˇ Zeman and Zabokrtsk´ y (2005) Koo et al. (2010) Type PCFG Chart-1st PCFG MST PCFG+Post Chart-2nd+Post Trans-Local Hybrid-Greedy Hybrid-"
W11-4602,W05-1518,0,0.0653038,"Missing"
W11-4602,D08-1059,0,0.0507316,"es, the worst-case complexity is quadratic, but observed running time can still be linear with an appropriate choice of transition system Nivre (2009), and transition systems can be extended to handle directed acyclic graphs (Sagae and Tsujii, 2008). Transition-based parsers can base their decisions on very rich representations of the derivation history (including the partially built dependency graph) but may suffer from error propagation due to search errors especially if the statistical model is trained to maximize the accuracy of local transitions rather than complete transition sequences. Zhang and Clark (2008) showed how these problems can be alleviated by global optimization and beam search, and Huang and Sagae (2010) obtained further improvements through ambiguity packing. technique is parser stacking, where one parser is used to generate input features for another parser, a method that was used by Nivre and McDonald (2008) to combine chart parsing and transitionbased parsing, with further improvements reported by Torres Martins et al. (2008). Finally, Koo et al. (2010) used dual decomposition to combine thirdorder chart parsing and arc-factored spanning tree parsing with excellent empirical resu"
W12-1010,A00-1031,0,0.0554963,"ka (“search”). System Overview The extraction of verbs and their complements is basically performed in five steps: 1. Tokenisation 2. Normalisation 3. Part-of-speech tagging 4. Parsing 5. Extraction of verb constructions 67 3.3 Part-of-speech Tagging 4. Predicative complement (SP) The purpose of part-of-speech tagging in our experiments is both to find the verbs in the text and to prepare for the parsing step, in which the complements are identified. Part-of-speech tagging is performed using HunPOS (Hal´acsy et al., 2007), a free and open source reimplementation of the HMM-based TnT-tagger by Brants (2000). The tagger is used with a pre-trained language model based on the Stockholm-Ume˚a Corpus (SUC), a balanced, manually annotated corpus of different text types representative of the Swedish language in the 1990s, comprising approximately one million tokens (Gustafson-Capkov´a and Hartmann, 2006). Megyesi (2009) showed that the HunPOS tagger trained on SUC, is one of the best performing taggers for (contemporary) Swedish texts. 3.4 5. Prepositional complement (OA) 6. Infinitive complement of object (VO) 7. Verb particle (PL) Subjects are included only if the verb has been analysed as a passive"
W12-1010,P07-2053,0,0.0751988,"Missing"
W12-1010,W09-4636,1,0.852988,"tagging in our experiments is both to find the verbs in the text and to prepare for the parsing step, in which the complements are identified. Part-of-speech tagging is performed using HunPOS (Hal´acsy et al., 2007), a free and open source reimplementation of the HMM-based TnT-tagger by Brants (2000). The tagger is used with a pre-trained language model based on the Stockholm-Ume˚a Corpus (SUC), a balanced, manually annotated corpus of different text types representative of the Swedish language in the 1990s, comprising approximately one million tokens (Gustafson-Capkov´a and Hartmann, 2006). Megyesi (2009) showed that the HunPOS tagger trained on SUC, is one of the best performing taggers for (contemporary) Swedish texts. 3.4 5. Prepositional complement (OA) 6. Infinitive complement of object (VO) 7. Verb particle (PL) Subjects are included only if the verb has been analysed as a passive verb by the tagger, in which case the subject is likely to correspond to the direct object in the active voice. In an attempt to improve precision in the complement extraction phase, we also use valency dictionaries for filtering the suggested complements. The valency frame of a verb tells us what complements t"
W12-1010,P81-1022,0,0.809621,"Missing"
W12-1010,nivre-etal-2006-talbanken05,1,0.77627,"t to improve precision in the complement extraction phase, we also use valency dictionaries for filtering the suggested complements. The valency frame of a verb tells us what complements the verb is likely to occur with. The assumption is that this information could be useful for removing unlikely complements, i.e., complements that are not part of the valency frame for the verb in question. The following example illustrates the potential usefulness of this method: Parsing The normalised and tagged input text is parsed using MaltParser version 1.6, a data-driven dependency parser developed by Nivre et al. (2006a). In our experiments, the parser is run with a pretrained model1 for parsing contemporary Swedish text, based on the Talbanken section of the Swedish Treebank (Nivre et al., 2006b). The parser produces dependency trees labeled with grammatical functions, which can be used to identify different types of complements. 3.5 J midler tijd kom greffuinnans gotze fougte thijtt However, the Countess’ estate bailiff came there In this case, the parser analysed the partial noun phrase greffuinnans gotze (“the Countess’ estate”) as a direct object connected to kom (“came”). However, since the word kom i"
W12-1010,W11-1512,1,0.891185,"Missing"
W12-1010,W11-1501,0,0.22367,"Missing"
W12-1010,nivre-etal-2006-maltparser,1,\N,Missing
W12-3112,W12-3102,0,0.16462,"Missing"
W12-3112,gimenez-marquez-2004-svmtool,0,0.0199658,"Missing"
W12-3112,P07-2053,0,0.040547,"Missing"
W12-3112,2011.eamt-1.32,1,0.932815,"ystem, along with the models used and diagnostic output produced by the SMT system as well as manual translation quality annotations on a 1–5 scale for each sentence. Additionally, a set of 17 baseline features was made available to the participants. Systems were evaluated on a test set of 422 sentences annotated in the same way. Uppsala University submitted two systems to this shared task. Our systems were fairly successful and achieved results that were outperformed by only one competing group. They improve over the baseline performance in two ways, building on and extending earlier work by Hardmeier (2011), on which the system description in the following sections is partly based: On the one hand, we enhance the set of 17 baseline features provided by the organisers with another 82 explicitly defined features. On the other hand, we use syntactic tree kernels to extract implicit features from constituency and dependency parse trees over the input sentences and the Machine Translation (MT) output. The experimental results confirm the findings of our earlier work, showing tree kernels to be a valuable tool for rapid prototyping of QE systems. 2 Features Our QE systems used two types of features: O"
W12-3112,W10-2910,0,0.0230381,"al., 2006). POS tagging was done with HunPOS (Hal´acsy et al., 2007) for English and SVMTool (Gim´enez and M´arquez, 2004) for Spanish, with the models provided by the OPUS project (Tiedemann, 2009). As in previous work (Hardmeier, 2011), we treated the parser as a black box and made no attempt to handle the fact that parsing accuracy may be decreased over malformed SMT output. To be used with tree kernels, the output of the dependency parser had to be transformed into a single tree structure with a unique label per node and unlabelled edges, similar to a constituency parse tree. We followed Johansson and Moschitti (2010) in using a tree representation which encodes partof-speech tags, dependency relations and words as sequences of child nodes (see fig. 1). Figure 1: Representation of the dependency tree fragment VP S for the words Nicole ’s dad NP Mary brought NP V brought NP V VP N D N D N D N a cat a cat 2006b). Predicted scores less than 1 were set to 1 and predicted scores greater than 5 were set to 5 as this was known to be the range of valid scores. Our learning algorithm had some free hyperparameters. Three of them were optimised by joint grid search with 5-fold cross-validation over the training set:"
W12-3112,P03-1054,0,0.00290698,"with 1 : 1, 1 : n, n : 1 and m : n alignments (10 features) • average number of translations per word, unweighted and weighted by word frequency and reciprocal word frequency (3 features) 110 Parse trees Both the English input text and the Spanish Machine Translations were annotated with syntactic parse trees from which to derive implicit features. In English, we were able to produce both constituency and dependency parses. In Spanish, we were limited to dependency parses because of the better availability of parsing models. English constituency parses were produced with the Stanford parser (Klein and Manning, 2003) using the model bundled with the parser. For dependency parsing, we used MaltParser (Nivre et al., 2006). POS tagging was done with HunPOS (Hal´acsy et al., 2007) for English and SVMTool (Gim´enez and M´arquez, 2004) for Spanish, with the models provided by the OPUS project (Tiedemann, 2009). As in previous work (Hardmeier, 2011), we treated the parser as a black box and made no attempt to handle the fact that parsing accuracy may be decreased over malformed SMT output. To be used with tree kernels, the output of the dependency parser had to be transformed into a single tree structure with a"
W12-3112,E06-1015,0,0.689341,"D N N D D N N brought D nomial instead. The improvement an plan over the Gaussian NP NP NP a a a cat cat a a cat kernel was, however, marginal. N D N D direct stock purchase a cat N D V N A tree and some of its Partial Tree Fragments 3.3 Tree kernels To exploit parse tree information in our Machine Fig. 3. A tree with some of its partial trees Fig. 4. A dependency tree of a question. Figure 2: Tree fragments extracted by the Subset Tree Learning (ML) component, we used tree kernel (PTs). Kernel and by the Partial Tree Kernel. Illustrations by functions. Tree kernels (Collins and Duffy, 2001) Moschitti (2006a). are kernel functions defined over pairs of tree structures. They measure the similarity between two trees counting form the number of common substructures. 3 Machine Learning component constraint over the SSTs, we obtain a morebygeneral of substructures that we Implicitly, they define an infinite-dimensional feacall by the application of partial 3.1 partial Overviewtrees (PTs). These can be generated ture space whose dimensions correspond to all posproduction of the consequently [VP [V]] and are [VP The QE sharedrules task asked bothgrammar, for an estimate of sible tree fragments. Feature"
W12-3112,2009.mtsummit-papers.16,0,0.012036,"he complete set of 17 baseline features provided by the workshop organisers. Additionally, the UU best system also contained all the features presented by Hardmeier (2011) with the exception 109 Proceedings of the 7th Workshop on Statistical Machine Translation, pages 109–113, c Montr´eal, Canada, June 7-8, 2012. 2012 Association for Computational Linguistics of a few features specific to the film subtitle genre and inapplicable to the text type of the shared task, as well as a small number of features not included in that work. Many of these features were modelled on QE features described by Specia et al. (2009). In particular, the following features were included in addition to the baseline feature set: • number of words, length ratio (4 features) • source and target type-token ratios (2 features) • number of tokens matching particular patterns (3 features each): – – – – – – – – – – numbers opening and closing parentheses strong punctuation signs weak punctuation signs ellipsis signs hyphens single and double quotes apostrophe-s tokens short alphabetic tokens (≤ 3 letters) long alphabetic tokens (≥ 4 letters) • translation model entropy for the input words, cumulatively per sentence and averaged per"
W12-3112,nivre-etal-2006-maltparser,1,\N,Missing
W12-5205,W06-2920,0,0.094102,"sing using global learning and exact (or nearly exact) inference algorithms. A graph-based parser extracts the highest scoring spanning tree from a complete graph containing all possible dependency arcs, using a scoring model that decomposes into scores for smaller subgraphs of a tree. MSTParser implements first- and second-order models, where subgraphs are single arcs and pairs of arcs, respectively, and provides different algorithms for projective and non-projective trees. MaltParser and MSTParser were the top scoring systems in the CoNLL 2006 shared task on multilingual dependency parsing (Buchholz and Marsi, 2006) and has since been applied to a wide range of languages. 2 Note that this unit may in turn take a direct object. Hence the need to distinguish the light verb object from an ordinary direct object. 37 Category acc acomp acomp-lvc advcl advmod amod appos aux auxpass cc ccomp complm conj cop dep det dobj dobj-lvc mark mwe neg nn npadvmod nsubj nsubj-lvc nsubjpass num number parataxis pobj poss predet prep prep-lvc punct quantmod rcmod rel root tmod xcomp Description accusative marker adjectival complement adjectival complement in light verb construction adverbial clause modifier adverbial modifi"
W12-5205,P07-2053,0,0.0681602,"Missing"
W12-5205,W08-1301,0,0.0392585,"l descriptions and texts about culture and art. The corpus is annotated with morpho-syntactic and partly semantic features. The aim is to expand the treebank with 10,000 sentences in the near future by using data-driven dependency parsers for bootstrapping, and manual validation of the annotation. In the treebank, each head and dependent relation is marked and annotated with functional categories, indicating the grammatical function of the dependent to the head. The treebank annotation scheme is based on Stanford Typed Dependencies (STD) which has become a de facto standard for English today (Marneffe and Manning, 2008). The STD annotation scheme has been applied to Persian and was extended to cover all syntactic relations that are not covered by the original scheme developed for English. Five new labels were added to describe various relations in light verb constructions, and the accusative marker. The added relations are introduced below with a description. The entire annotation scheme can be found in Table 1 where the extended relations introduced for Persian are marked in italic.1 acc: accusative marker An accusative marker is a clitic attached to the direct object of a transitive verb. acomp-lvc: adject"
W12-5205,P05-1012,0,0.720462,"in the recent decade, as the approach seems better suited than phrase structure representations for languages with free or flexible word order (Kübler et al., 2009). Dependency parsing, in addition, has been shown to be useful in language technology applications, such as machine translation and information extraction, when detecting the underlying syntactic pattern of a sentence, because of their transparent encoding of predicate-argument structure (Kübler et al., 2009). This paper presents the adaptation and evaluation of two dependency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005a) for Persian. The parsers are trained on a syntactically annotated corpus developed for Persian; the Uppsala PErsian Dependency Treebank (UPEDT) (Seraji et al., 2012). The paper is organized as follows. Section 2 briefly describes the structure and the characteristics of the Persian language, followed by a description of the dependency structure and the functional annotation of the Persian dependency treebank on which the data-driven parsers are trained. A short description of MaltParser and MSTParser ends the section. Section 3 introduces the design of our experiments and Section 4 presents"
W12-5205,H05-1066,0,0.829695,"in the recent decade, as the approach seems better suited than phrase structure representations for languages with free or flexible word order (Kübler et al., 2009). Dependency parsing, in addition, has been shown to be useful in language technology applications, such as machine translation and information extraction, when detecting the underlying syntactic pattern of a sentence, because of their transparent encoding of predicate-argument structure (Kübler et al., 2009). This paper presents the adaptation and evaluation of two dependency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005a) for Persian. The parsers are trained on a syntactically annotated corpus developed for Persian; the Uppsala PErsian Dependency Treebank (UPEDT) (Seraji et al., 2012). The paper is organized as follows. Section 2 briefly describes the structure and the characteristics of the Persian language, followed by a description of the dependency structure and the functional annotation of the Persian dependency treebank on which the data-driven parsers are trained. A short description of MaltParser and MSTParser ends the section. Section 3 introduces the design of our experiments and Section 4 presents"
W12-5205,W03-3017,1,0.631345,"pendency parsing. The parser is an implementation of inductive dependency parsing (Nivre, 2006) and can be used to develop a parser for a new language given a dependency treebank representing the syntactic relations of that language. The system is characterized as transition-based, allowing the user to choose different parsing algorithms and to define optional feature models indicating lexical features, part-of-speech features and dependency type features. The main parsing algorithms available in MaltParser are Nivre’s algorithms, including the arc-eager and arc-standard versions described in Nivre (2003) and Nivre (2004), Covington’s algorithms, containing the projective and non-projective versions described by Covington (2001), and Stack algorithms, including the projective and non-projective versions of the algorithm described in Nivre (2009) and Nivre et al. (2009). The Covington and the Stack algorithms can handle non-projective trees whereas the Nivre algorithm does not (Ballesteros and Nivre, 2010). For the optimization of MaltParser we used MaltOptimizer (Ballesteros and Nivre, 2010) developed specifically to optimize MaltParser for new data sets with respect to parsing algorithm and f"
W12-5205,W04-0308,1,0.797357,"The parser is an implementation of inductive dependency parsing (Nivre, 2006) and can be used to develop a parser for a new language given a dependency treebank representing the syntactic relations of that language. The system is characterized as transition-based, allowing the user to choose different parsing algorithms and to define optional feature models indicating lexical features, part-of-speech features and dependency type features. The main parsing algorithms available in MaltParser are Nivre’s algorithms, including the arc-eager and arc-standard versions described in Nivre (2003) and Nivre (2004), Covington’s algorithms, containing the projective and non-projective versions described by Covington (2001), and Stack algorithms, including the projective and non-projective versions of the algorithm described in Nivre (2009) and Nivre et al. (2009). The Covington and the Stack algorithms can handle non-projective trees whereas the Nivre algorithm does not (Ballesteros and Nivre, 2010). For the optimization of MaltParser we used MaltOptimizer (Ballesteros and Nivre, 2010) developed specifically to optimize MaltParser for new data sets with respect to parsing algorithm and feature selection."
W12-5205,P09-1040,1,0.872395,"is characterized as transition-based, allowing the user to choose different parsing algorithms and to define optional feature models indicating lexical features, part-of-speech features and dependency type features. The main parsing algorithms available in MaltParser are Nivre’s algorithms, including the arc-eager and arc-standard versions described in Nivre (2003) and Nivre (2004), Covington’s algorithms, containing the projective and non-projective versions described by Covington (2001), and Stack algorithms, including the projective and non-projective versions of the algorithm described in Nivre (2009) and Nivre et al. (2009). The Covington and the Stack algorithms can handle non-projective trees whereas the Nivre algorithm does not (Ballesteros and Nivre, 2010). For the optimization of MaltParser we used MaltOptimizer (Ballesteros and Nivre, 2010) developed specifically to optimize MaltParser for new data sets with respect to parsing algorithm and feature selection. MSTParser (McDonald et al., 2005b,a) is also an open source system but based on the graphbased approach to dependency parsing using global learning and exact (or nearly exact) inference algorithms. A graph-based parser extracts"
W12-5205,nivre-etal-2006-maltparser,1,0.903386,"tions have become more widely used in the recent decade, as the approach seems better suited than phrase structure representations for languages with free or flexible word order (Kübler et al., 2009). Dependency parsing, in addition, has been shown to be useful in language technology applications, such as machine translation and information extraction, when detecting the underlying syntactic pattern of a sentence, because of their transparent encoding of predicate-argument structure (Kübler et al., 2009). This paper presents the adaptation and evaluation of two dependency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005a) for Persian. The parsers are trained on a syntactically annotated corpus developed for Persian; the Uppsala PErsian Dependency Treebank (UPEDT) (Seraji et al., 2012). The paper is organized as follows. Section 2 briefly describes the structure and the characteristics of the Persian language, followed by a description of the dependency structure and the functional annotation of the Persian dependency treebank on which the data-driven parsers are trained. A short description of MaltParser and MSTParser ends the section. Section 3 introduces the design of o"
W12-5205,W09-3811,1,0.854798,"as transition-based, allowing the user to choose different parsing algorithms and to define optional feature models indicating lexical features, part-of-speech features and dependency type features. The main parsing algorithms available in MaltParser are Nivre’s algorithms, including the arc-eager and arc-standard versions described in Nivre (2003) and Nivre (2004), Covington’s algorithms, containing the projective and non-projective versions described by Covington (2001), and Stack algorithms, including the projective and non-projective versions of the algorithm described in Nivre (2009) and Nivre et al. (2009). The Covington and the Stack algorithms can handle non-projective trees whereas the Nivre algorithm does not (Ballesteros and Nivre, 2010). For the optimization of MaltParser we used MaltOptimizer (Ballesteros and Nivre, 2010) developed specifically to optimize MaltParser for new data sets with respect to parsing algorithm and feature selection. MSTParser (McDonald et al., 2005b,a) is also an open source system but based on the graphbased approach to dependency parsing using global learning and exact (or nearly exact) inference algorithms. A graph-based parser extracts the highest scoring spa"
W12-5205,seraji-etal-2012-basic,1,0.925034,"endency parsing, in addition, has been shown to be useful in language technology applications, such as machine translation and information extraction, when detecting the underlying syntactic pattern of a sentence, because of their transparent encoding of predicate-argument structure (Kübler et al., 2009). This paper presents the adaptation and evaluation of two dependency parsers, MaltParser (Nivre et al., 2006) and MSTParser (McDonald et al., 2005a) for Persian. The parsers are trained on a syntactically annotated corpus developed for Persian; the Uppsala PErsian Dependency Treebank (UPEDT) (Seraji et al., 2012). The paper is organized as follows. Section 2 briefly describes the structure and the characteristics of the Persian language, followed by a description of the dependency structure and the functional annotation of the Persian dependency treebank on which the data-driven parsers are trained. A short description of MaltParser and MSTParser ends the section. Section 3 introduces the design of our experiments and Section 4 presents the results of the evaluation covering the results of MaltParser and MSTParser, as well as an error analysis for the developed parsers. Finally, Section 5 concludes th"
W12-5205,ballesteros-nivre-2012-maltoptimizer-system,1,\N,Missing
W13-2229,J03-1002,0,0.0232763,"Missing"
W13-2229,D12-1108,1,0.797773,"n of the search space. While this decoding approach delivers excellent search performance at a very reasonable speed, it limits the information available to the feature models to an n-gram window similar to a language model history. In stack decoding, it is difficult to implement models with sentence-internal long-range dependencies and cross-sentence dependencies, where the model score of a given sentence depends on the translations generated for another sentence. In contrast to this very popular stack decoding approach, our decoder Docent implements a search procedure based on local search (Hardmeier et al., 2012). At any stage of the search process, its search state consists of a complete document translation, making it easy for feature models to access the complete document with its current translation at any point in time. The search algorithm is a stochastic variant of standard hill climbing. At each step, it generates a successor of the current search state by randomly applying We describe the Uppsala University system for WMT13, for English-to-German translation. We use the Docent decoder, a local search decoder that translates at the document level. We add tunable distortion limits, that is, sof"
W13-2229,P03-1021,0,0.00789271,"he translation models were trained using the Moses toolkit (Koehn et al., 2007), with standard settings with 5 features, phrase probabilities and lexical weighting in both directions and a phrase penalty. We applied significance-based filtering (Johnson et al., 2007) to the resulting phrase tables. For decoding we used the Docent decoder with random initialization and standard parameter settings (Hardmeier et al., 2012; Hardmeier et al., 2013), which beside translation and language model features include a word penalty and a distortion penalty. Parameter optimization was performed using MERT (Och, 2003) at the document-level (Stymne et al., 2013a). In this setup we calculate both model and metric scores on the document-level instead of on the sentence-level. We produce kbest lists by sampling from the decoder. In each optimization run we run 40,000 hill-climbing iterations of the decoder, and sample translations with interval 100, from iteration 10,000. This procedure has been shown to give competitive results to standard tuning with Moses (Koehn et al., 2007) with relatively stable results (Stymne et al., 2013a). For tuning data we concatenated the tuning sets news-test 2008–2010 and newssy"
W13-2229,P02-1040,0,0.0863828,"y the WMT13 workshop. We always concatenated the two bilingual corpora Europarl and News Commentary, which we will call EP-NC. We pre-processed all corpora by using the tools provided for tokenization and we also lower-cased all corpora. For the bilingual corpora we also filtered sentence pairs with a length ratio larger than three, or where either sentence was longer than 60 tokens. Recasing was performed as a post-processing step, trained using the resources To evaluate our system we use newstest2012, which has 99 documents and 3003 sentences. In this article we give lower-case Bleu scores (Papineni et al., 2002), except in Section 6 where we investigate the effect of different recasing models. 226 Cleaning None Basic Langid Alignment-based Sentences 2,399,123 2,271,912 2,072,294 1,512,401 Reduction sentences into four categories, cases where both languages were correctly identified, but under the confidence threshold of 0.999, cases where both languages were incorrectly identified, and cases where one language was incorrectly identified. Overall the language identification was accurate on 54 of the 93 removed sentences. In 18 of the cases where it was wrong, the sentences were not translation corresp"
W13-2229,P13-4033,1,0.906674,"at the document level. We add tunable distortion limits, that is, soft constraints on the maximum distortion allowed, to Docent. We also investigate cleaning of the noisy Common Crawl corpus. We show that we can use alignment-based filtering for cleaning with good results. Finally we investigate effects of corpus selection for recasing. 1 The Docent Decoder Introduction In this paper we present the Uppsala University submission to WMT 2013. We have submitted one system, for translation from English to German. In our submission we use the document-level decoder Docent (Hardmeier et al., 2012; Hardmeier et al., 2013). In the current setup, we take advantage of Docent in that we introduce tunable distortion limits, that is, modeling distortion limits as soft constraints instead of as hard constraints. In addition we perform experiments on corpus cleaning. We investigate how the noisy Common Crawl corpus can be cleaned, and suggest an alignmentbased cleaning method, which works well. We also investigate corpus selection for recasing. In Section 2 we introduce our decoder, Docent, followed by a general system description in Section 3. In Section 4 we describe our experiments with corpus cleaning, and in Sect"
W13-2229,E12-1055,0,0.0123678,"ined two separate models, one on the German side of EP-NC, and one on the monolingual News corpus. In both cases we trained 5-gram models. For the large News corpus we used entropy-based pruning, with 10−8 as a threshold (Stolcke, 1998). The language models were trained using the SRILM toolkit (Stolcke, 2002) and during decoding we used the KenLM toolkit (Heafield, 2011). For the translation model we also trained two models, one with EP-NC, and one with Common Crawl. These two models were interpolated and used as a single model at decoding time, based on perplexity minimization interpolation (Sennrich, 2012), see details in Section 4. The translation models were trained using the Moses toolkit (Koehn et al., 2007), with standard settings with 5 features, phrase probabilities and lexical weighting in both directions and a phrase penalty. We applied significance-based filtering (Johnson et al., 2007) to the resulting phrase tables. For decoding we used the Docent decoder with random initialization and standard parameter settings (Hardmeier et al., 2012; Hardmeier et al., 2013), which beside translation and language model features include a word penalty and a distortion penalty. Parameter optimizati"
W13-2229,W11-2123,0,0.0206337,"-internal reordering by exploiting the fact that Docent implements distortion limits as soft constraints rather than strictly enforced limitations. We do not include any of our document-level feature functions. 3 For the language model we trained two separate models, one on the German side of EP-NC, and one on the monolingual News corpus. In both cases we trained 5-gram models. For the large News corpus we used entropy-based pruning, with 10−8 as a threshold (Stolcke, 1998). The language models were trained using the SRILM toolkit (Stolcke, 2002) and during decoding we used the KenLM toolkit (Heafield, 2011). For the translation model we also trained two models, one with EP-NC, and one with Common Crawl. These two models were interpolated and used as a single model at decoding time, based on perplexity minimization interpolation (Sennrich, 2012), see details in Section 4. The translation models were trained using the Moses toolkit (Koehn et al., 2007), with standard settings with 5 features, phrase probabilities and lexical weighting in both directions and a phrase penalty. We applied significance-based filtering (Johnson et al., 2007) to the resulting phrase tables. For decoding we used the Doce"
W13-2229,D07-1103,0,0.0298921,"lkit (Stolcke, 2002) and during decoding we used the KenLM toolkit (Heafield, 2011). For the translation model we also trained two models, one with EP-NC, and one with Common Crawl. These two models were interpolated and used as a single model at decoding time, based on perplexity minimization interpolation (Sennrich, 2012), see details in Section 4. The translation models were trained using the Moses toolkit (Koehn et al., 2007), with standard settings with 5 features, phrase probabilities and lexical weighting in both directions and a phrase penalty. We applied significance-based filtering (Johnson et al., 2007) to the resulting phrase tables. For decoding we used the Docent decoder with random initialization and standard parameter settings (Hardmeier et al., 2012; Hardmeier et al., 2013), which beside translation and language model features include a word penalty and a distortion penalty. Parameter optimization was performed using MERT (Och, 2003) at the document-level (Stymne et al., 2013a). In this setup we calculate both model and metric scores on the document-level instead of on the sentence-level. We produce kbest lists by sampling from the decoder. In each optimization run we run 40,000 hill-c"
W13-2229,N03-1017,0,0.0408954,"Missing"
W13-2229,W13-3308,1,0.864943,"of the complete document. On the downside, there is an increased risk of search errors because the document-level hill-climbing decoder cannot make as strong assumptions about the problem structure as the stack decoder does. In practice, this drawback can be mitigated by initializing the hill-climber with the output of a stack decoding pass using the baseline set of models without document-level features (Hardmeier et al., 2012). Since its inception, Docent has been used to experiment with document-level semantic language models (Hardmeier et al., 2012) and models to enhance text readability (Stymne et al., 2013b). Work on other discourse phenomena is ongoing. In the present paper, we focus on sentence-internal reordering by exploiting the fact that Docent implements distortion limits as soft constraints rather than strictly enforced limitations. We do not include any of our document-level feature functions. 3 For the language model we trained two separate models, one on the German side of EP-NC, and one on the monolingual News corpus. In both cases we trained 5-gram models. For the large News corpus we used entropy-based pruning, with 10−8 as a threshold (Stolcke, 1998). The language models were tra"
W13-2229,2005.iwslt-1.8,0,0.114614,"Missing"
W13-2229,W13-5634,1,0.871264,"of the complete document. On the downside, there is an increased risk of search errors because the document-level hill-climbing decoder cannot make as strong assumptions about the problem structure as the stack decoder does. In practice, this drawback can be mitigated by initializing the hill-climber with the output of a stack decoding pass using the baseline set of models without document-level features (Hardmeier et al., 2012). Since its inception, Docent has been used to experiment with document-level semantic language models (Hardmeier et al., 2012) and models to enhance text readability (Stymne et al., 2013b). Work on other discourse phenomena is ongoing. In the present paper, we focus on sentence-internal reordering by exploiting the fact that Docent implements distortion limits as soft constraints rather than strictly enforced limitations. We do not include any of our document-level feature functions. 3 For the language model we trained two separate models, one on the German side of EP-NC, and one on the monolingual News corpus. In both cases we trained 5-gram models. For the large News corpus we used entropy-based pruning, with 10−8 as a threshold (Stolcke, 1998). The language models were tra"
W13-2229,W08-0318,0,0.0188269,"s EP-NC-News EP-NC-CC-News EP-NC 13.8 13.9 13.9 13.9 13.9 EP-NC-CC 14.4 14.5 14.5 14.5 14.5 Language model News EP-NC-News 14.8 14.8 14.9 14.8 14.9 14.9 14.9 14.9 14.9 14.9 EP-NC-CC-News 14.8 14.8 14.9 14.9 15.0 Table 7: Case-sensitive Bleu scores with different corpus combinations for the language model and translation model (TM) for recasing Test system Docent (random) Docent (stack) Moses Docent (random) Docent (stack) Moses ing. It is common to train the system on truecased data instead of lower-cased data, which has been shown to lead to small gains for the English– German language pair (Koehn et al., 2008). In this framework there is still a need to find the correct case for the first word of each sentence, for which a similar corpus study might be useful. 7 Tuning system Docent Docent Docent Moses Moses Moses Bleu 15.7 15.9 15.9 15.9 16.8 16.8 Table 8: Bleu scores for Docent initialized randomly or with stack decoding compared to Moses. Tuning is performed with either Moses or Docent. For the top line we used tunable distortion limits 6,10 with Docent, in the other cases a standard hard distortion limit of 6, since Moses does not allow soft distortion limits. Comparison to Moses So far we have"
W13-2229,P12-3005,0,0.118617,"Missing"
W13-2229,P07-2045,0,\N,Missing
W13-3308,D11-1084,0,0.0941275,"in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to it. It can be used with any decoder that outputs feature values at the document level. phrase-table (Meyer and Popescu-Belis, 2012) or by using factored decoding (Meyer et al., 2012) to disambiguate connectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type of approach is to integrate topic modeling into phrase tables (Zhao and Xing"
W13-3308,W12-3102,0,0.0373536,"Missing"
W13-3308,D07-1007,0,0.0195191,"onnectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type of approach is to integrate topic modeling into phrase tables (Zhao and Xing, 2010; Su et al., 2012). For a more thorough overview of discourse in SMT, see Hardmeier (2012). 3 Sentence-Level Tuning Traditionally, feature weight optimization, or tuning, for SMT is performed by an iterative process where a development set is translated to produce a k-best list. The parameters are then optimized using some procedure, generally to favor translations in the k-be"
W13-3308,D12-1026,0,0.234011,"ion (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to it. It can be used with any decoder that outputs feature values at the document level. phrase-table (Meyer and Popescu-Belis, 2012) or by using factored decoding (Meyer et al., 2012) to disambiguate connectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type of approach is to integrate topic modeling into phrase tables (Zhao and Xing, 2010; Su et al., 2"
W13-3308,W09-2404,0,0.411772,"ng has been used to annotate surface forms either in the corpus or in the Discourse has largely been ignored in traditional machine translation (MT). Typically each sentence has been translated in isolation, essentially yielding translations that are bags of sentences. It is well known from translation studies, however, that discourse is important in order to achieve good translations of documents (Hatim and Mason, 1990). Most attempts to address discourse-level issues for statistical machine translation (SMT) have had to resort to solutions such as postprocessing to address lexical cohesion (Carpuat, 2009) or two-step translation to address pronoun anaphora (Le Nagard and Koehn, 2010). Recently, however, we presented Docent (Hardmeier et al., 2012; Hardmeier et al., 2013), a decoder based on local search that translates full documents. So far this decoder has not included a feature weight optimization framework. However, feature weight optimization, or tuning, is important for any modern SMT decoder to achieve a good translation performance. In previous research with Docent, we used grid search to find weights for document-level features 60 Proceedings of the Workshop on Discourse in Machine Tr"
W13-3308,E12-3001,0,0.09251,"ic programming for exploring a large search space (Och et al., 2001). Because of the dynamic programming assumptions it is hard to directly include discourse-level features into a traditional SMT decoder. Nevertheless, there have been several attempts to integrate intersentential and long distance models for discourselevel phenomena into standard decoders, usually as ad-hoc additions to standard models, addressing a single phenomenon. Several studies have tried to improve pronoun anaphora by adding information about the antecedent, either by using two-step decoding (Le Nagard and Koehn, 2010; Guillou, 2012) or by extracting information from previously translated sentences (Hardmeier and Federico, 2010), unfortunately without any convincing results. To address the translation of discourse connectives, source-side pre-processing has been used to annotate surface forms either in the corpus or in the Discourse has largely been ignored in traditional machine translation (MT). Typically each sentence has been translated in isolation, essentially yielding translations that are bags of sentences. It is well known from translation studies, however, that discourse is important in order to achieve good tra"
W13-3308,P07-1005,0,0.016844,"ed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type of approach is to integrate topic modeling into phrase tables (Zhao and Xing, 2010; Su et al., 2012). For a more thorough overview of discourse in SMT, see Hardmeier (2012). 3 Sentence-Level Tuning Traditionally, feature weight optimization, or tuning, for SMT is performed by an iterative process where a development set is translated to produce a k-best list. The parameters are then optimized using some procedure, generally to favor translations in the k-best list that have a high score on some MT metric. The translation step"
W13-3308,2010.iwslt-papers.10,1,0.900759,"he dynamic programming assumptions it is hard to directly include discourse-level features into a traditional SMT decoder. Nevertheless, there have been several attempts to integrate intersentential and long distance models for discourselevel phenomena into standard decoders, usually as ad-hoc additions to standard models, addressing a single phenomenon. Several studies have tried to improve pronoun anaphora by adding information about the antecedent, either by using two-step decoding (Le Nagard and Koehn, 2010; Guillou, 2012) or by extracting information from previously translated sentences (Hardmeier and Federico, 2010), unfortunately without any convincing results. To address the translation of discourse connectives, source-side pre-processing has been used to annotate surface forms either in the corpus or in the Discourse has largely been ignored in traditional machine translation (MT). Typically each sentence has been translated in isolation, essentially yielding translations that are bags of sentences. It is well known from translation studies, however, that discourse is important in order to achieve good translations of documents (Hatim and Mason, 1990). Most attempts to address discourse-level issues f"
W13-3308,N12-1047,0,0.127102,"best lists. This is repeated until some end condition is satisfied, for instance for a set number of iterations, until there is only very small changes in parameter weights, or until there are no new translations in the k-best lists. SMT tuning is a hard problem in general, partly because the correct output is unreachable and also because the translation process includes latent variables, which means that many efficient standard optimization procedures cannot be used (Gimpel and Smith, 2012). Nevertheless, there are a number of techniques including MERT (Och, 2003), MIRA (Chiang et al., 2008; Cherry and Foster, 2012), PRO (Hopkins and May, 2011), and Rampion (Gimpel and Smith, 2012). All of these optimization methods can be plugged into the standard optimization loop. All of the methods work relatively well in practice, even though there are limitations, for instance that many methods are non-deterministic meaning that their results are somewhat unstable. However, there are some important differences. MERT is based on scores for the full test set, whereas the other methods are based on sentence-level scores. MERT also has the drawback that it only works well for small sets of features. In this paper we ar"
W13-3308,D12-1108,1,0.932337,"slation (MT). Typically each sentence has been translated in isolation, essentially yielding translations that are bags of sentences. It is well known from translation studies, however, that discourse is important in order to achieve good translations of documents (Hatim and Mason, 1990). Most attempts to address discourse-level issues for statistical machine translation (SMT) have had to resort to solutions such as postprocessing to address lexical cohesion (Carpuat, 2009) or two-step translation to address pronoun anaphora (Le Nagard and Koehn, 2010). Recently, however, we presented Docent (Hardmeier et al., 2012; Hardmeier et al., 2013), a decoder based on local search that translates full documents. So far this decoder has not included a feature weight optimization framework. However, feature weight optimization, or tuning, is important for any modern SMT decoder to achieve a good translation performance. In previous research with Docent, we used grid search to find weights for document-level features 60 Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimiz"
W13-3308,D08-1024,0,0.0690584,"Missing"
W13-3308,P13-4033,1,0.695247,"each sentence has been translated in isolation, essentially yielding translations that are bags of sentences. It is well known from translation studies, however, that discourse is important in order to achieve good translations of documents (Hatim and Mason, 1990). Most attempts to address discourse-level issues for statistical machine translation (SMT) have had to resort to solutions such as postprocessing to address lexical cohesion (Carpuat, 2009) or two-step translation to address pronoun anaphora (Le Nagard and Koehn, 2010). Recently, however, we presented Docent (Hardmeier et al., 2012; Hardmeier et al., 2013), a decoder based on local search that translates full documents. So far this decoder has not included a feature weight optimization framework. However, feature weight optimization, or tuning, is important for any modern SMT decoder to achieve a good translation performance. In previous research with Docent, we used grid search to find weights for document-level features 60 Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to i"
W13-3308,P11-2031,0,0.0276307,"ment-level feature weight optimization for SMT. We first describe the experimental setup, followed by baseline results using sentencelevel optimization. We then present validation experiments with standard sentence-level features, 1 http://www.statmt.org/wmt13/ translation-task.html 63 System Moses Docent-M Docent-R Moses Docent-M Docent-R million iterations. We show results on the Bleu (Papineni et al., 2002) and NIST (Doddington, 2002) metrics. For German–English we show the average result and standard deviation of three optimization runs, to control for optimizer instability as proposed by Clark et al. (2011). For English–Swedish we report results on single optimization runs, due to time constraints. 5.2 Bleu 17.7 17.7 15.2 (0.05) 18.3 (0.04) 18.3 (0.04) 18.1 (0.13) NIST 6.25 6.25 5.88 (0.00) 6.22 (0.01) 6.22 (0.01) 6.23 (0.01) Table 2: Baseline results, where Docent-M is initialized with Moses and Docent-R randomly Docs 111 345 100 200 100 200 300 Baselines Most importantly, we would like to show the effectiveness of the document-level tuning procedure described above. In order to do this, we created a baseline using sentence-level optimization with a tuning set of 2525 sentences and the News2009"
W13-3308,D11-1125,0,0.344821,"til some end condition is satisfied, for instance for a set number of iterations, until there is only very small changes in parameter weights, or until there are no new translations in the k-best lists. SMT tuning is a hard problem in general, partly because the correct output is unreachable and also because the translation process includes latent variables, which means that many efficient standard optimization procedures cannot be used (Gimpel and Smith, 2012). Nevertheless, there are a number of techniques including MERT (Och, 2003), MIRA (Chiang et al., 2008; Cherry and Foster, 2012), PRO (Hopkins and May, 2011), and Rampion (Gimpel and Smith, 2012). All of these optimization methods can be plugged into the standard optimization loop. All of the methods work relatively well in practice, even though there are limitations, for instance that many methods are non-deterministic meaning that their results are somewhat unstable. However, there are some important differences. MERT is based on scores for the full test set, whereas the other methods are based on sentence-level scores. MERT also has the drawback that it only works well for small sets of features. In this paper we are not concerned with the actu"
W13-3308,W12-3139,0,0.205173,"5.2 (0.05) 18.3 (0.04) 18.3 (0.04) 18.1 (0.13) NIST 6.25 6.25 5.88 (0.00) 6.22 (0.01) 6.22 (0.01) 6.23 (0.01) Table 2: Baseline results, where Docent-M is initialized with Moses and Docent-R randomly Docs 111 345 100 200 100 200 300 Baselines Most importantly, we would like to show the effectiveness of the document-level tuning procedure described above. In order to do this, we created a baseline using sentence-level optimization with a tuning set of 2525 sentences and the News2009 corpus for evaluation. Increasing the tuning set is known to give only modest improvements (Turchi et al., 2012; Koehn and Haddow, 2012). The feature weights optimized with the standard Moses decoder can then directly be used in our document-level decoder as we only include sentence-level features in our baseline model. As expected, these optimized weights also lead to a better performance in document-level decoding compared to an untuned model as shown in Table 2. Note, that Docent can be initialized in two ways, by Moses and randomly. Not surprisingly, the result for the runs initialized with Moses are identical with the pure sentence-level decoder. Initializing randomly gives a slightly lower Bleu score but with a larger va"
W13-3308,N12-1023,0,0.0116367,"repeated using the new weights for decoding, and optimization is continued on a new k-best list, or on a combination of all k-best lists. This is repeated until some end condition is satisfied, for instance for a set number of iterations, until there is only very small changes in parameter weights, or until there are no new translations in the k-best lists. SMT tuning is a hard problem in general, partly because the correct output is unreachable and also because the translation process includes latent variables, which means that many efficient standard optimization procedures cannot be used (Gimpel and Smith, 2012). Nevertheless, there are a number of techniques including MERT (Och, 2003), MIRA (Chiang et al., 2008; Cherry and Foster, 2012), PRO (Hopkins and May, 2011), and Rampion (Gimpel and Smith, 2012). All of these optimization methods can be plugged into the standard optimization loop. All of the methods work relatively well in practice, even though there are limitations, for instance that many methods are non-deterministic meaning that their results are somewhat unstable. However, there are some important differences. MERT is based on scores for the full test set, whereas the other methods are ba"
W13-3308,N03-1017,0,0.0371705,"rity of scoring and the process of extracting k-best lists. For document-level features we do not have meaningful scores on the sentence level which are required in standard optimization frameworks. Furthermore, the extraction of k-best lists is not as Here we instead choose to work with the recent document-level SMT decoder Docent (Hardmeier et al., 2012). Unlike in traditional decoding were documents are generated sentence by sentence, feature models in Docent always have access to the complete discourse context, even before decoding is finished. It implements the phrase-based SMT approach (Koehn et al., 2003) and is based on local search, where a state consists of a full translation of a document, which is improved by applying a series of operations to improve the translation. A hill-climbing strategy is used to find a (local) maximum. The operations allow changing the translation of a phrase, changing the word order by swapping the positions of two phrases, and resegmenting phrases. The initial state can either be initialized randomly in monotonic order, or be based on an initial run from a standard sentence-based decoder. The number of iterations in the decoder is controlled by two parameters, t"
W13-3308,P12-1048,0,0.0480289,"t al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type of approach is to integrate topic modeling into phrase tables (Zhao and Xing, 2010; Su et al., 2012). For a more thorough overview of discourse in SMT, see Hardmeier (2012). 3 Sentence-Level Tuning Traditionally, feature weight optimization, or tuning, for SMT is performed by an iterative process where a development set is translated to produce a k-best list. The parameters are then optimized using some procedure, generally to favor translations in the k-best list that have a high score on some MT metric. The translation step is then repeated using the new weights for decoding, and optimization is continued on a new k-best list, or on a combination of all k-best lists. This is repeated until"
W13-3308,W10-2602,1,0.888675,"shop on Discourse in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to it. It can be used with any decoder that outputs feature values at the document level. phrase-table (Meyer and Popescu-Belis, 2012) or by using factored decoding (Meyer et al., 2012) to disambiguate connectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type of approach is to integrate topic modeling into phrase t"
W13-3308,2005.mtsummit-papers.11,0,0.014426,"is already somewhat unstable this is a potential issue that needs to be explored further, which we do in Section 5. Implementation-wise we adapted Docent to output k-lists and adapted the infrastructure available for tuning in the Moses decoder (Koehn et al., 2007) to work with document-level scores. This setup allows us to use the variety of optimization procedures implemented there. 5 5.1 Experimental Setup Most of our experiments are for German-toEnglish news translation using data from the WMT13 workshop.1 We also show results with document-level features for English-to-Swedish Europarl (Koehn, 2005). The size of the training, tuning, and test sets are shown in Table 1. First of all, we need to extract documents for tuning and testing with Docent. Fortunately, the news data already contain document markup, corresponding to individual news articles. For Europarl we define a document as a consecutive sequence of utterances from a single speaker. To investigate the effect of the size of the tuning set, we used different subsets of the available tuning data. All our document-level experiments are carried out with Docent but we also contrast with the Moses decoder (Koehn et al., 2007). For the"
W13-3308,W10-1737,0,0.202315,"Missing"
W13-3308,N12-1046,0,0.199813,"el features 60 Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to it. It can be used with any decoder that outputs feature values at the document level. phrase-table (Meyer and Popescu-Belis, 2012) or by using factored decoding (Meyer et al., 2012) to disambiguate connectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type of approach is to int"
W13-3308,W12-0117,0,0.0131317,"ed a feature weight optimization framework. However, feature weight optimization, or tuning, is important for any modern SMT decoder to achieve a good translation performance. In previous research with Docent, we used grid search to find weights for document-level features 60 Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to it. It can be used with any decoder that outputs feature values at the document level. phrase-table (Meyer and Popescu-Belis, 2012) or by using factored decoding (Meyer et al., 2012) to disambiguate connectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has"
W13-3308,2011.mtsummit-papers.13,0,0.118068,"ts for document-level features 60 Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to it. It can be used with any decoder that outputs feature values at the document level. phrase-table (Meyer and Popescu-Belis, 2012) or by using factored decoding (Meyer et al., 2012) to disambiguate connectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities for each sentence (Carpuat and Wu, 2007), by introducing extra features in the phrasetable (Chan et al., 2007), or as a k-best re-ranking task (Specia et al., 2008). Another type o"
W13-3308,2012.amta-papers.20,0,0.335871,"eight optimization, or tuning, is important for any modern SMT decoder to achieve a good translation performance. In previous research with Docent, we used grid search to find weights for document-level features 60 Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pages 60–69, c Sofia, Bulgaria, August 9, 2013. 2013 Association for Computational Linguistics level feature weight optimization is not limited to it. It can be used with any decoder that outputs feature values at the document level. phrase-table (Meyer and Popescu-Belis, 2012) or by using factored decoding (Meyer et al., 2012) to disambiguate connectives, with small improvements. Lexical consistency has been addressed by the use of post-processing (Carpuat, 2009), multi-pass decoding (Xiao et al., 2011; Ture et al., 2012), and cache models (Tiedemann, 2010; Gong et al., 2011). Gong et al. (2012) addressed the issue of tense selection for translation from Chinese, by the use of inter-sentential tense n-grams, exploiting information from previously translated sentences. Another way to use a larger context is by integrating word sense disambiguation and SMT. This has been done by re-initializing phrase probabilities f"
W13-3308,W01-1408,0,0.0344757,"res to model discourse phenomena such as anaphora, discourse connectives, and lexical consistency. In this paper, we therefore propose an approach that supports discourse-wide features in documentlevel decoding by adapting existing frameworks for sentence-level optimization. Furthermore, we include a thorough empirical investigation of this approach. Introduction 2 Discourse-Level SMT Traditional SMT systems translate texts sentence by sentence, assuming independence between sentences. This assumption allows efficient algorithms based on dynamic programming for exploring a large search space (Och et al., 2001). Because of the dynamic programming assumptions it is hard to directly include discourse-level features into a traditional SMT decoder. Nevertheless, there have been several attempts to integrate intersentential and long distance models for discourselevel phenomena into standard decoders, usually as ad-hoc additions to standard models, addressing a single phenomenon. Several studies have tried to improve pronoun anaphora by adding information about the antecedent, either by using two-step decoding (Le Nagard and Koehn, 2010; Guillou, 2012) or by extracting information from previously translat"
W13-3308,P03-1021,0,0.0673075,"est list, or on a combination of all k-best lists. This is repeated until some end condition is satisfied, for instance for a set number of iterations, until there is only very small changes in parameter weights, or until there are no new translations in the k-best lists. SMT tuning is a hard problem in general, partly because the correct output is unreachable and also because the translation process includes latent variables, which means that many efficient standard optimization procedures cannot be used (Gimpel and Smith, 2012). Nevertheless, there are a number of techniques including MERT (Och, 2003), MIRA (Chiang et al., 2008; Cherry and Foster, 2012), PRO (Hopkins and May, 2011), and Rampion (Gimpel and Smith, 2012). All of these optimization methods can be plugged into the standard optimization loop. All of the methods work relatively well in practice, even though there are limitations, for instance that many methods are non-deterministic meaning that their results are somewhat unstable. However, there are some important differences. MERT is based on scores for the full test set, whereas the other methods are based on sentence-level scores. MERT also has the drawback that it only works"
W13-3308,P02-1040,0,0.0886974,"riments, the decoder always stopped when reaching the rejection limit, usually between 1–5 Experiments In this section we report experimental results where we investigate several issues in connection with document-level feature weight optimization for SMT. We first describe the experimental setup, followed by baseline results using sentencelevel optimization. We then present validation experiments with standard sentence-level features, 1 http://www.statmt.org/wmt13/ translation-task.html 63 System Moses Docent-M Docent-R Moses Docent-M Docent-R million iterations. We show results on the Bleu (Papineni et al., 2002) and NIST (Doddington, 2002) metrics. For German–English we show the average result and standard deviation of three optimization runs, to control for optimizer instability as proposed by Clark et al. (2011). For English–Swedish we report results on single optimization runs, due to time constraints. 5.2 Bleu 17.7 17.7 15.2 (0.05) 18.3 (0.04) 18.3 (0.04) 18.1 (0.13) NIST 6.25 6.25 5.88 (0.00) 6.22 (0.01) 6.22 (0.01) 6.23 (0.01) Table 2: Baseline results, where Docent-M is initialized with Moses and Docent-R randomly Docs 111 345 100 200 100 200 300 Baselines Most importantly, we would like to sh"
W13-3308,W13-5634,1,0.917086,"an restarting the decoder from the previous best state. 62 Training Tuning Test German–English Type Sentences Europarl 1.9M News Commentary 178K News2009 2525 News2008-2010 7567 News2012 3003 Documents – – 111 345 99 English–Swedish Type Sentences Europarl 1.5M – – Europarl (Moses) 2000 Europarl (Docent) 1338 Europarl 690 Documents – – – 100 20 Table 1: Domain and number of sentences and documents for the corpora which can be compared to standard optimization. Finally, we report results with a set of documentlevel features that have been proposed for joint translation and text simplification (Stymne et al., 2013). As seen in Figure 1, there are some additional parameters in our procedure: the sample start iteration and the sample interval. We also need to set the number of decoder iterations to run. In Section 5 we empirically investigate the effect of these parameters. Compared to sentence-level optimization, we also have a smaller number of units to get scores from, since we use documents as units, and not sentences. The importance of this depends on the optimization algorithm. MERT calculates metric scores over the full tuning set, not for individual sentences, and should not be affected too much b"
W13-3308,P07-2045,0,\N,Missing
W13-4902,W10-1411,1,0.823095,"S and 72.80 UAS in the Predicted condition. To find that CASE is the most important feature is not surprising, as CASE has been shown to be the most helpful feature for many languages (at least in the Gold condition). But whereas few other features have been shown to help for other languages, in our case the majority of features (8 out of 12 in the Gold condition) are beneficial for Lithuanian. The so-called agreement features (GENDER, NUMBER and PERSON) are beneficial for Lithuanian (at least in the Gold condition) as well as for Arabic (Marton et al., 2013), but not such languages as Hindi (Ambati et al., 2010) and Hebrew (Goldberg and Elhadad, 2010). In the Predicted condition, their positive impact is marginal at best, possibly because NUMBER is very poorly predicted by the morphoFigure 4: The contribution of individual morphological features in the Gold condition. The x axis represents feature models incorporating different attributes; the y axis represents LAS. The horizontal line at 74.20 represents the LAS of Baseline+FEATS. Figure 5: The contribution of individual morphological features in the Predicted condition. The x axis represents feature models incorporating different attributes; the y"
W13-4902,W06-2920,0,0.0598652,"ion During the last decades, we have seen a tremendous increase in the number of syntactic parsers available for different languages, often enabled by the development of syntactically annotated corpora, or treebanks. The added linguistic diversity has highlighted the fact that typological differences between languages lead to new challenges, both in parsing technology and treebank annotation. In particular, it has been observed repeatedly that richly inflected languages, which often also exhibit relatively free word order, usually obtain lower parsing accuracy, especially compared to English (Buchholz and Marsi, 2006; Nivre et al., 2007). This has led to a special interest in parsing methods for such languages (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In this paper, we contribute to the growing pool of empirical evidence by presenting the first statistical dependency parsing results for Lithuanian, a morphologically rich Baltic language characterized as one of the most archaic living Indo-European languages (Gimbutas, 1963). Using the newly developed Lithuanian Treebank, we train and evaluate a greedy transition-based parser and in particular investigate the impact of rich morphological features on"
W13-4902,W07-1713,0,0.075779,"Missing"
W13-4902,J08-3003,1,0.881472,"stical dependency parsing results for Lithuanian, a morphologically rich Baltic language characterized as one of the most archaic living Indo-European languages (Gimbutas, 1963). Using the newly developed Lithuanian Treebank, we train and evaluate a greedy transition-based parser and in particular investigate the impact of rich morphological features on parsing accuracy. Our experiments show that virtually all morphological features can be beneficial when parsing Lithuanian, which contrasts with many previous studies that have mainly found a positive impact for isolated features such as CASE (Eryigit et al., 2008). Using all available features, we achieve a labeled attachment score of 74.7 with gold morphology (including partof-speech tags and lemmas) and 68.1 with predicted morphology. The corresponding unlabeled attachment scores are 77.8 and 72.8, respectively. 2 The Lithuanian Treebank The Lithuanian Treebank was developed by the Center of Computational Linguistics, Vytautas Magnus University.1 The annotated texts are taken from the newspaper domain and thus represent normative Lithuanian language. The treebank contains 1,566 sentences and 24,265 tokens: 19,625 words (9,848 distinct) plus 4,640 pun"
W13-4902,W10-1412,0,0.0559836,"d annotations, but these produced even worse results, confirming that it is better to make the training condition resemble the parsing condition. Despite noisy information, morphological features are still very beneficial compared to not using them at all (see Figure 5). Our findings thus agree with what has been found for Arabic by Marton et al. (2013) but seem to contradict the results obtained 7 We tried to reduce data sparseness a little bit by changing all words into lowercase, but the drop in accuracy revealed that orthographic information is also important for parsing. 18 for Hebrew by Goldberg and Elhadad (2010). As we can see from both curves in Figure 4 and Figure 5, the top contributors are CASE, VOICE, and TENSE, but the CASE feature gives the biggest contribution to accuracy. It boosts LAS by 6.51 points in the Gold condition and almost 5 points in the Predicted condition, whereas the contribution of all the other morphological features is less than 1 point (and not statistically significant). In a control experiment we reversed the order in which morphological features are added (presented in Figure 4 and Figure 5), adding CASE at the very end. In this case, the addition of all features except"
W13-4902,J93-2004,0,0.0418822,"ant for any metric or condition (with p values in the range 0.35–0.87). 5 Discussion First of all, we may conclude that the Baseline feature model (without morphological information) does not perform very well for a morphologically rich language like Lithuanian (see Figure 4 and Figure 5), despite giving high accuracy for morphologically impoverished languages like English. However, it is likely that the accuracy of the Baseline model would be a bit higher for the Lithuanian Treebank if PoS tags incorporated some morphological information as they do, for example, in the English Penn Treebank (Marcus et al., 1993). It thus seems that basic PoS tags as well as lemmas are too general to be beneficial enough for Lithuanian. The simple morphemic word form could be more useful (even despite the fact that Lithuanian is syncretic language), but the treebank is currently too small, making the data too sparse to create a robust model.7 Thus, the effective way of dealing with unseen words is by incorporating morphological information. In the Predicted condition, we always see a drop in accuracy compared to the Gold condition, although our case is not exceptional. For example, the Baseline model has a drop in LAS"
W13-4902,J13-1008,0,0.0762543,"nts from Gold to Predicted, but this gap could possibly be narrowed by retuning the feature model for the Predicted condition instead of simply reusing the model tuned for the Gold condition. We also tried training the model on gold annotations for parsing predicted annotations, but these produced even worse results, confirming that it is better to make the training condition resemble the parsing condition. Despite noisy information, morphological features are still very beneficial compared to not using them at all (see Figure 5). Our findings thus agree with what has been found for Arabic by Marton et al. (2013) but seem to contradict the results obtained 7 We tried to reduce data sparseness a little bit by changing all words into lowercase, but the drop in accuracy revealed that orthographic information is also important for parsing. 18 for Hebrew by Goldberg and Elhadad (2010). As we can see from both curves in Figure 4 and Figure 5, the top contributors are CASE, VOICE, and TENSE, but the CASE feature gives the biggest contribution to accuracy. It boosts LAS by 6.51 points in the Gold condition and almost 5 points in the Predicted condition, whereas the contribution of all the other morphological"
W13-4902,P05-1013,1,0.739075,"for15 mats and feature specifications in a flexible way. Finally, MaltParser has already been applied to a wide range of languages, to which the results can be compared. In particular, MaltParser was used to obtain the only published dependency parsing results for Latvian, the language most closely related to Lithuanian (Pretkalnin.a and Rituma, 2013). In our experiments, we use the latest release of MaltParser (Version 1.7.2).4 After preliminary experiments, we decided to use the arc-eager transition system (Nivre, 2003) with pseudo-projective parsing to recover non-projective dependencies (Nivre and Nilsson, 2005) and the LIBLINEAR learning package with multiclass SVMs (Fan et al., 2008). Table 3 lists the options that were explored in the preliminary experiments. We first tested all possible combinations of learning method and parsing algorithms and then performed a greedy sequential tuning of the options related to covered roots, pseudoprojective parsing, and all combinations of allowroot and allow-reduce. In order to use MaltParser on the Lithuanian Treebank, we first converted the data to the CoNLL-X format,5 treating all morphological feature bundles 4 5 Available at http://maltparser.org. See htt"
W13-4902,P81-1022,0,0.413833,"Missing"
W13-4902,W06-2933,1,0.87676,"Missing"
W13-4902,W03-3017,1,0.693042,"on systems and classifiers that can be explored and also supports user-defined input for15 mats and feature specifications in a flexible way. Finally, MaltParser has already been applied to a wide range of languages, to which the results can be compared. In particular, MaltParser was used to obtain the only published dependency parsing results for Latvian, the language most closely related to Lithuanian (Pretkalnin.a and Rituma, 2013). In our experiments, we use the latest release of MaltParser (Version 1.7.2).4 After preliminary experiments, we decided to use the arc-eager transition system (Nivre, 2003) with pseudo-projective parsing to recover non-projective dependencies (Nivre and Nilsson, 2005) and the LIBLINEAR learning package with multiclass SVMs (Fan et al., 2008). Table 3 lists the options that were explored in the preliminary experiments. We first tested all possible combinations of learning method and parsing algorithms and then performed a greedy sequential tuning of the options related to covered roots, pseudoprojective parsing, and all combinations of allowroot and allow-reduce. In order to use MaltParser on the Lithuanian Treebank, we first converted the data to the CoNLL-X for"
W13-4902,J08-4003,1,0.850847,"ological information is limited by syncretism in CASE, NUMBER and GENDER. Thus, the form mamos (mother(s)) can be either plural nominative or singular genitive; the form mokytojas (teacher(s)) can be either masculine singular nominative or feminine plural accusative. 3 Parsing Framework We use the open-source system MaltParser (Nivre et al., 2006a) for our parsing experiments with the Lithuanian Treebank. MaltParser is a transitionbased dependency parser that performs parsing as greedy search through a transition system, guided by a history-based classifier for predicting the next transition (Nivre, 2008). Although more accurate dependency parsers exist these days, MaltParser appeared suitable for our experiments for a number of reasons. First of all, greedy transition-based parsers have been shown to perform well with relatively small amounts of training data (Nivre et al., 2006b). Secondly, MaltParser implements a number of different transition systems and classifiers that can be explored and also supports user-defined input for15 mats and feature specifications in a flexible way. Finally, MaltParser has already been applied to a wide range of languages, to which the results can be compared."
W13-4902,W13-5625,0,0.0711922,"on-based parsers have been shown to perform well with relatively small amounts of training data (Nivre et al., 2006b). Secondly, MaltParser implements a number of different transition systems and classifiers that can be explored and also supports user-defined input for15 mats and feature specifications in a flexible way. Finally, MaltParser has already been applied to a wide range of languages, to which the results can be compared. In particular, MaltParser was used to obtain the only published dependency parsing results for Latvian, the language most closely related to Lithuanian (Pretkalnin.a and Rituma, 2013). In our experiments, we use the latest release of MaltParser (Version 1.7.2).4 After preliminary experiments, we decided to use the arc-eager transition system (Nivre, 2003) with pseudo-projective parsing to recover non-projective dependencies (Nivre and Nilsson, 2005) and the LIBLINEAR learning package with multiclass SVMs (Fan et al., 2008). Table 3 lists the options that were explored in the preliminary experiments. We first tested all possible combinations of learning method and parsing algorithms and then performed a greedy sequential tuning of the options related to covered roots, pseud"
W13-4902,W10-1401,0,0.0363799,"Missing"
W13-4902,J13-1003,1,0.864653,"Missing"
W13-4902,nivre-etal-2006-maltparser,1,\N,Missing
W13-4902,J08-4010,1,\N,Missing
W13-4902,D07-1096,1,\N,Missing
W13-4917,P06-1084,0,0.0139791,"s of incomplete lexicon coverage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leadi"
W13-4917,P08-1083,1,0.743016,"in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respectable accuracy.25 4.7 The Hungarian Treebank Hungarian is an agglutinative language, thus a lemma can have hundreds of word forms due to derivational or inflectional affixation (nomina"
W13-4917,W13-4903,0,0.0228459,"such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Re"
W13-4917,W10-1411,1,0.835873,"challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and w"
W13-4917,W10-1408,1,0.383126,"Missing"
W13-4917,E12-2012,1,0.0774441,"parsing evaluation campaign SANCL 2012 (Petrov and McDonald, 2012). The present shared task was extremely demanding on our participants. From 30 individuals or teams who registered and obtained the data sets, we present results for the seven teams that accomplished successful executions on these data in the relevant scenarios in the given the time frame. 5.1 Dependency Track Seven teams participated in the dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To"
W13-4917,W13-4907,0,0.0733412,"Missing"
W13-4917,W10-1404,0,0.0222482,"merged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and"
W13-4917,W13-4916,1,0.230959,"Missing"
W13-4917,H91-1060,0,0.199934,"n the expected performance of parsers in real-world scenarios. Results reported for MRLs using gold morphological information are then, at best, optimistic. One reason for adopting this less-than-realistic evaluation scenario in previous tasks has been the lack of sound metrics for the more realistic scenario. Standard evaluation metrics assume that the number of terminals in the parse hypothesis equals the number of terminals in the gold tree. When the predicted morphological segmentation leads to a different number of terminals in the gold and parse trees, standard metrics such as ParsEval (Black et al., 1991) or Attachment Scores (Buchholz and Marsi, 2006) fail to produce a score. In this task, we use TedEval (Tsarfaty et al., 2012b), a metric recently suggested for joint morpho-syntactic evaluation, in which normalized tree-edit distance (Bille, 2005) on morphosyntactic trees allows us to quantify the success on the joint task in realistic parsing scenarios. Finally, the previous tasks focused on dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performa"
W13-4917,D12-1133,1,0.807979,"cy-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed"
W13-4917,C10-1011,0,0.0102695,"r system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-"
W13-4917,W07-1506,0,0.220289,"s of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version is available from http://www.ims. uni-stuttgart.de/forschung/ressourcen/ korpora/tiger.html 159 to the &quot;raising&quot; algorithm described by Boyd (2007). In a third steps, all those newly introduced nodes that did not cover the head daughter of the original discontinuous node were deleted. For the second and the third step, we used the same script as for the Swedish constituency data. Predicted Morphology For the predicted scenario, a single sequence of POS tags and morphological features has been assigned using the MATE toolchain via a model trained on the train set via crossvalidation on the training set. The MATE toolchain was used to provide predicted annotation for lemmas, POS tags, morphology, and syntax. In order to achieve the best re"
W13-4917,W06-2920,0,0.827477,"ouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency relations are marked between input tokens directly, and allow the annotation of non-projective dependencies that are parseable efficiently. Dependency syntax was applied to the description of different types of languages (Tesnière, 1959; Mel’ˇcuk, 2001), which raised the hope that in these settings, parsing MRLs will further improve. However, the 2007 shared task organizers (Nivre et al., 2007a) concluded that: &quot;[Performance] classes are more ea"
W13-4917,W10-1409,1,0.0435485,"for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing"
W13-4917,candito-etal-2010-statistical,1,0.0386487,"g of 18,535 sentences,18 split into 14,759 sentences for training, 1,235 sentences for development, and 2,541 sentences for the final evaluation.19 Adapting the Data to the Shared Task The constituency trees are provided in an extended PTB bracketed format, with morphological features at the pre-terminal level only. They contain slight, automatically performed, modifications with respect to the original trees of the French treebank. The syntagmatic projection of prepositions and complementizers was normalized, in order to have prepositions and complementizers as heads in the dependency trees (Candito et al., 2010). The dependency representations are projective dependency trees, obtained through automatic conversion from the constituency trees. The conversion procedure is an enhanced version of the one described by Candito et al. (2010). Both the constituency and the dependency representations make use of coarse- and fine-grained POS tags (CPOS and FPOS respectively). The CPOS are the categories from the original treebank. The FPOS 18 The process of functional annotation is still ongoing, the objective of the FTB providers being to have all the 20000 sentences annotated with functional tags. 19 The firs"
W13-4917,W08-2102,0,0.0353476,"troduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality par"
W13-4917,A00-2018,0,0.0705659,"n analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing E"
W13-4917,W11-3801,1,0.926035,"ers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard Engli"
W13-4917,chrupala-etal-2008-learning,0,0.045003,"Missing"
W13-4917,W10-1406,0,0.0618994,"Missing"
W13-4917,W13-4909,0,0.199525,"derived from the Hebrew Treebank V2 (Sima’an et al., 2001; Guthmann et al., 2009). The treebank is based on just over 6000 sentences from the daily newspaper ‘Ha’aretz’, manually annotated with morphological information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same"
W13-4917,J03-4003,0,0.48866,"omparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the ma"
W13-4917,W13-4905,1,0.719588,"method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZE"
W13-4917,W13-4906,1,0.680312,"dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 200"
W13-4917,W08-1301,0,0.0393335,"Missing"
W13-4917,P98-1062,0,0.0491049,"Missing"
W13-4917,P08-1109,0,0.0220424,"ences. In order to avoid comparing apples and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Str"
W13-4917,J13-1005,1,0.838989,"html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? How to parse effectively in the face of resource scarcity? The first step to answering all of these"
W13-4917,W13-4908,1,0.872762,"Missing"
W13-4917,W10-1412,1,0.789087,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,N10-1115,1,0.576439,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,P08-1085,1,0.364225,"overage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respe"
W13-4917,E09-1038,1,0.867766,"ices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming to the lexical resource used to build the lattices, and is shared by the two treebanks. The higher level is syntactic, and follows the tag set and annotation decisions of the original constituency treebank.23 In addition, we unified the representation of morphological features, and fixed inconsistencies and mistakes in the treebanks. Data Split The Hebrew treebank is one of the smallest in our language set, and hence it is provided in only the small (5k) setting. For the sake of comparabilit"
W13-4917,C10-1045,1,0.826872,"nflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Haba"
W13-4917,W12-3410,0,0.0157938,"umulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realis"
W13-4917,J13-1009,1,0.747017,"Missing"
W13-4917,P09-2056,1,0.833708,".2 The Arabic Treebanks Arabic is a morphologically complex language which has rich inflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional A"
W13-4917,D07-1116,1,0.604822,"010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Habash et al., 2007). The CATiB treebank uses the word tokenization of the PATB 11 The LDC kindly provided their latest version of the Arabic Treebanks. In particular, we used PATB 1 v4.1 (Maamouri et al., 2005), PATB 2 v3.1 (Maamouri et al., 2004a) and PATB 3 v3.3. (Maamouri et al., 2009) train: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS tags #total NTs Dep. Label Set Size train5k: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS Tags #total NTs Dep. Label Set Size dev: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Toke"
W13-4917,P07-2053,0,0.0323622,"Missing"
W13-4917,D07-1097,1,0.346865,"Missing"
W13-4917,D10-1002,0,0.0151688,"oaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predica"
W13-4917,P08-1067,0,0.0226773,"a-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information co"
W13-4917,J98-4004,0,0.0891486,"ir strengths and weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying t"
W13-4917,J13-1006,1,0.798597,"hbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? Ho"
W13-4917,P03-1054,0,0.00438043,"d weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank"
W13-4917,W06-1614,1,0.812546,"nd machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) hi"
W13-4917,kubler-etal-2008-compare,1,0.91565,"node to the root node in the output tree and the corresponding path in the gold tree. The path consists of a sequence of node labels between the terminal node and the root node, and the similarity of two paths is calculated by using the Levenshtein distance. This distance is normalized by path length, and the score of the tree is an aggregated score of the values for all terminals in the tree (xt is the leaf-ancestor path of t in tree x). P LA(h, g) = t∈yield(g) Lv(ht ,gt )/(len(ht )+len(gt )) |yield(g)| This metric was shown to be less sensitive to differences between annotation schemes in (Kübler et al., 2008), and was shown by Rehbein and van Genabith (2007a) to evaluate trees more faithfully than ParsEval in the face of certain annotation decisions. We used the implementation of Wagner (2012).6 3.4.2 Evaluation Metrics for Dependency Structures Attachment Scores Labeled and Unlabeled Attachment scores have been proposed as evaluation metrics for dependency parsing in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007a) and have since assumed the role of standard metrics in multiple shared tasks and independent studies. Assume that g, h are gold and hypothesized dependency trees"
W13-4917,W12-3408,1,0.878953,"Missing"
W13-4917,P03-1056,0,0.0207769,"disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on depend"
W13-4917,W12-4615,1,0.809959,"ly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This was done in three steps. In the first step, the head daughters of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version"
W13-4917,J93-2004,0,0.0437888,"participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend."
W13-4917,D10-1004,0,0.0390834,"nd MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for"
W13-4917,J13-1008,1,0.913933,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,W13-4910,1,0.915357,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,N06-1020,0,0.225446,"for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on"
W13-4917,P05-1012,0,0.042194,"Missing"
W13-4917,moreno-etal-2000-treebank,0,0.0581254,"e generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency"
W13-4917,nivre-etal-2006-talbanken05,1,0.442193,"subject agreement with respect to person and number has been dropped in modern Swedish. The Data Set The Swedish data sets are taken from the Talbanken section of the Swedish Treebank (Nivre and Megyesi, 2007). Talbanken is a syntactically annotated corpus developed in the 1970s, originally annotated according to the MAMBA scheme (Teleman, 1974) with a syntactic layer consisting of flat phrase structure and grammatical functions. The syntactic annotation was later automatically converted to full phrase structure with grammatical functions and from that to dependency structure, as described by Nivre et al. (2006). Both the phrase structure and the dependency version use the functional labels from the original MAMBA scheme, which provides a fine-grained classification of syntactic functions with 65 different labels, while the phrase structure annotation (which had to be inferred automatically) uses a coarse set of only 8 labels. For the release of the Swedish treebank, the POS level was re-annotated to conform to the current de facto standard for Swedish, which is the Stockholm-Umeå tagset (Ejerhed et al., 1992) with 25 base tags and 25 morpho-syntactic features, which together produce over 150 complex"
W13-4917,P06-1055,0,0.480329,"as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it"
W13-4917,N10-1003,0,0.0195824,"2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for morphological analysis and POS tagging. Finally, as already mentioned, AI:KU clusters words and POS tags in an unsupervised fashion exploiting additional, un-annotated data. 5.2 Constituency Track A single team participated in the constituency parsing task, the IMS:S ZEGED :CIS team (Björkelund et al., 2013). Their phrase-structure parsing system uses a combination of 8 PCFG-LA parsers, trained using a product-of-grammars procedure (Petrov, 2010). The 50-best parses of this combination are then reranked by a model based on the reranker by Charniak and Johnson (2005).33 5.3 6.1 Baselines We additionally provide the results of two baseline systems for the nine languages, one for constituency parsing and one for dependency parsing. For the dependency track, our baseline system is MaltParser in its default configuration (the arc-eager algorithm and liblinear for training). Results marked as BASE :M ALT in the next two sections report the results of this baseline system in different scenarios. The constituency parsing baseline is based on"
W13-4917,W07-2460,0,0.109747,"Missing"
W13-4917,D07-1066,0,0.0884872,"Missing"
W13-4917,W11-3808,0,0.027114,"rameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer an"
W13-4917,N06-2033,0,0.0563478,"rst dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2"
W13-4917,schmid-etal-2004-smor,0,0.00857226,"information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming t"
W13-4917,W10-1410,1,0.889145,"Missing"
W13-4917,seeker-kuhn-2012-making,1,0.106665,"n constituency data set is based on the TiGer treebank release 2.2.21 The original annotation scheme represents discontinuous constituents such that all arguments of a predicate are always grouped under a single node regardless of whether there is intervening material between them or not (Brants et al., 2002). Furthermore, punctuation and several other elements, such as parentheses, are not attached to the tree. In order to make the constituency treebank usable for PCFG parsing, we adapted this treebank as described shortly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This w"
W13-4917,P12-1046,0,0.00731402,"based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formatio"
W13-4917,W11-3803,0,0.0414253,"to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCF"
W13-4917,W10-1405,1,0.891538,"Missing"
W13-4917,W10-1401,1,0.779419,"sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 146–182, c Seattle, Washington, USA, 18 October 2013. 2013 Association for Computational Linguistics recently, advances in PCFG-LA parsing (Petrov et al., 2006) and language-agnostic data-driven dependency parsing (McD"
W13-4917,D11-1036,1,0.926772,"dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performance between parsers of different types. We are now faced with an additional question: how can we compare parsing results across different frameworks? Adopting standard metrics will not suffice as we would be comparing apples and oranges. In contrast, TedEval is defined for both phrase structures and dependency structures through the use of an intermediate representation called function trees (Tsarfaty et al., 2011; Tsarfaty et al., 2012a). Using TedEval thus allows us to explore both dependency and constituency parsing frameworks and meaningfully compare the performance of parsers of different types. 149 3 3.1 Defining the Shared-Task Input and Output We define a parser as a structure prediction function that maps sequences of space-delimited input tokens (henceforth, tokens) in a language to a set of parse trees that capture valid morpho-syntactic structures in that language. In the case of constituency parsing, the output structures are phrase-structure trees. In dependency parsing, the output consis"
W13-4917,E12-1006,1,0.148172,"er languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologicall"
W13-4917,P13-2103,1,0.111695,"les and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Structures ParsEval The ParsEval metrics (B"
W13-4917,P11-2033,1,0.563308,"em, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure o"
W13-4917,R13-1099,1,0.0375053,"orphology In order to provide the same POS tag set for the constituent and dependency treebanks, we used the dependency POS tagset for both treebank instances. Both versions of the treebank are available with gold standard and automatic morphological annotation. The automatic POS tagging was carried out by a 10-fold cross-validation on the shared task data set by magyarlanc, a natural language toolkit for processing Hungarian texts (segmentation, morphological analysis, POS tagging, and dependency parsing). The annotation provides POS tags and deep morphological features for each input token (Zsibrita et al., 2013).28 28 The full data sets of both the constituency and dependency versions of the Szeged Treebank are available at 161 4.8 The Korean Treebank The Treebank The Korean corpus is generated by collecting constituent trees from the K AIST Treebank (Choi et al., 1994), then converting the constituent trees to dependency trees using head-finding rules and heuristics. The K AIST Treebank consists of about 31K manually annotated constituent trees from 97 different sources (e.g., newspapers, novels, textbooks). After filtering out trees containing annotation errors, a total of 27,363 trees with 350,090"
W13-4917,E93-1064,0,\N,Missing
W13-4917,C00-1001,0,\N,Missing
W13-4917,C10-1061,1,\N,Missing
W13-4917,J13-1003,1,\N,Missing
W13-4917,C08-1112,1,\N,Missing
W13-4917,W08-1008,1,\N,Missing
W13-4917,P05-1022,0,\N,Missing
W13-4917,P98-1063,0,\N,Missing
W13-4917,C98-1060,0,\N,Missing
W13-4917,vincze-etal-2010-hungarian,1,\N,Missing
W13-4917,D07-1096,1,\N,Missing
W13-5617,W11-4106,0,0.0615877,"2,086 1527–1812 787,122 30,827 33,544 Table 1: Corpus distribution, given in number of tokens in the documents. Total = Number of tokens in the whole corpus. Training = Number of tokens in the training sample of the corpus. Evaluation = Number of tokens in the evaluation sample of the corpus. 4 Method This paper explores an approach to normalisation of historical text using the Levenshtein edit distance measure for comparing the original word form to word forms listed in an electronically available dictionary or corpus of contemporary language. Our approach is similar to the one presented by Bollmann et al. (2011) in that Levenshtein similarity is used in the normalisation Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 166 of 474] process. In the Bollmann approach, however, the Levenshtein weights are calculated on the basis of aligned parallel data, consisting of the same text in an old spelling version and a modern spelling version, respectively. Our approach does not presuppose access to such a corpus, since the Levenshtein distance is solely computed by comparing the historical word forms to tokens presen"
W13-5617,A00-1031,0,0.0357907,"Missing"
W13-5617,P07-2053,0,0.129018,"Missing"
W13-5617,2008.eamt-1.25,0,0.0568932,"Missing"
W13-5634,2012.eamt-1.33,0,0.0610232,"Missing"
W13-5634,W09-2404,0,0.0675313,"summarization, as measured by user studies (Margarido et al., 2008) and automatic metrics (Smith and Jönsson, 2011). In these studies the readability was generally better in the summarized texts than in the original texts. Stymne and Smith (2012) showed that SMT is affected by summarization, but found no relation between readability and SMT quality measured by standard evaluation metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexical consistency. The effect of lexical consistency in translation has been studied by Carpuat (2009) and Carpuat and Simard (2012). Tiedemann (2010) proposed cached models to push consistent translation with some success in the case of domain adaptation. The use of word sense disambiguation in SMT is another example where wide contextual information can be incorporated on the source side (Carpuat and Wu, 2007; Chan et al., 2007) Another study related to ours is Genzel et al. (2010), who study poetry translation and perform joint translation and poetry creation of news text as well as translation of poems that keep the Proceedings of the 19th Nordic Conference of Computational Linguistics (NO"
W13-5634,W12-3156,0,0.0177139,"easured by user studies (Margarido et al., 2008) and automatic metrics (Smith and Jönsson, 2011). In these studies the readability was generally better in the summarized texts than in the original texts. Stymne and Smith (2012) showed that SMT is affected by summarization, but found no relation between readability and SMT quality measured by standard evaluation metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexical consistency. The effect of lexical consistency in translation has been studied by Carpuat (2009) and Carpuat and Simard (2012). Tiedemann (2010) proposed cached models to push consistent translation with some success in the case of domain adaptation. The use of word sense disambiguation in SMT is another example where wide contextual information can be incorporated on the source side (Carpuat and Wu, 2007; Chan et al., 2007) Another study related to ours is Genzel et al. (2010), who study poetry translation and perform joint translation and poetry creation of news text as well as translation of poems that keep the Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electr"
W13-5634,D07-1007,0,0.0351635,"relation between readability and SMT quality measured by standard evaluation metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexical consistency. The effect of lexical consistency in translation has been studied by Carpuat (2009) and Carpuat and Simard (2012). Tiedemann (2010) proposed cached models to push consistent translation with some success in the case of domain adaptation. The use of word sense disambiguation in SMT is another example where wide contextual information can be incorporated on the source side (Carpuat and Wu, 2007; Chan et al., 2007) Another study related to ours is Genzel et al. (2010), who study poetry translation and perform joint translation and poetry creation of news text as well as translation of poems that keep the Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 382 of 474] poetic form. They use features in the decoder such as rhyme and meter. They also introduce constraints over the target language output in order to adapt to the task-specific properties. However, they do not work on the document leve"
W13-5634,P07-1005,0,0.0350039,"bility and SMT quality measured by standard evaluation metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexical consistency. The effect of lexical consistency in translation has been studied by Carpuat (2009) and Carpuat and Simard (2012). Tiedemann (2010) proposed cached models to push consistent translation with some success in the case of domain adaptation. The use of word sense disambiguation in SMT is another example where wide contextual information can be incorporated on the source side (Carpuat and Wu, 2007; Chan et al., 2007) Another study related to ours is Genzel et al. (2010), who study poetry translation and perform joint translation and poetry creation of news text as well as translation of poems that keep the Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 382 of 474] poetic form. They use features in the decoder such as rhyme and meter. They also introduce constraints over the target language output in order to adapt to the task-specific properties. However, they do not work on the document level, which would be an"
W13-5634,daelemans-etal-2004-automatic,0,0.0211848,"a har sagt det - EU:s möte i Lissabon lagt särskild vikt vid vår för att genomföra risk i så att den plan att bli klar under 2003. SL (high) Som ledamöterna vet vissa talare har nämnt - Europeiska rådet i Lissabon särskilt uppmärksammat främja våra ansträngningar att genomföra riskkapital så att handlingsplanen avslutas 2003. Table 5: Examples of translation output from a sample of systems sentence compression (e.g., Knight and Marcu, 2000; Specia, 2010). Furthermore, there is a wide range of publications using other methods for monolingual sentence compression and text simplification, (e.g., Daelemans et al., 2004; Cohn and Lapata, 2009). Readability has also been investigated as an effect of text summarization, as measured by user studies (Margarido et al., 2008) and automatic metrics (Smith and Jönsson, 2011). In these studies the readability was generally better in the summarized texts than in the original texts. Stymne and Smith (2012) showed that SMT is affected by summarization, but found no relation between readability and SMT quality measured by standard evaluation metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexi"
W13-5634,D11-1108,0,0.0132082,"et al. (2012) investigate the task of translating subtitles where time and space constraints are important, which leads to the task of sentence compression, which is related to our work on simplifying translated texts. They introduce dynamic length penalties which they integrate in a standard SMT decoder. Their model successfully compresses subtitles on three data sets. However, they also show that a similar compression can be achieved with appropriate tuning data that meets the length constraints. There are also a number of studies that use SMT techniques for monolingual paraphrasing (e.g., Ganitkevitch et al., 2011) and Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 381 of 474] Source As the honourable Members know - some speakers have mentioned it - the European Council at Lisbon paid particular attention to promoting our efforts to implement risk capital in such a way that the action plan will be finished in 2003. Baseline Som de ärade ledamöterna vet - vissa talare har nämnt det - som Europeiska rådet i Lissabon ägnat särskild uppmärksamhet åt att främja våra ansträngningar att genomföra riskkapital på ett s"
W13-5634,D10-1016,0,0.0191157,"on metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexical consistency. The effect of lexical consistency in translation has been studied by Carpuat (2009) and Carpuat and Simard (2012). Tiedemann (2010) proposed cached models to push consistent translation with some success in the case of domain adaptation. The use of word sense disambiguation in SMT is another example where wide contextual information can be incorporated on the source side (Carpuat and Wu, 2007; Chan et al., 2007) Another study related to ours is Genzel et al. (2010), who study poetry translation and perform joint translation and poetry creation of news text as well as translation of poems that keep the Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 382 of 474] poetic form. They use features in the decoder such as rhyme and meter. They also introduce constraints over the target language output in order to adapt to the task-specific properties. However, they do not work on the document level, which would be an interesting direction for future work. 6 Conclusion a"
W13-5634,D12-1108,1,0.934115,"rt words as indicators. Our goal is to incorporate these features in machine translation in order to combine text simplification and adequate translation in one system. To the best of our knowledge, this has not been attempted before and represents a novel and challenging idea in the field of MT research. Global features such as the ones mentioned above require new approaches to the general problem of decoding in SMT. Fortunately, we have recently presented a new document-level decoder, which, contrary to standard SMT decoders, translates documents as a unit instead of sentences in isolation (Hardmeier et al., 2012). This allows us to define document-wide features in the target language to test our ideas. Our application is also a good test case for the capabilities of the decoder and we would like to use our findings in future developments of general user-targeted machine translation. The contributions of this paper are thus two-fold: (1) We show that document-wide decoding can effectively use global features and (2) we demonstrate that readability features can be used in SMT to produce simplified text translations. The remainder of the paper is organized as follows: First, we introduce important backgr"
W13-5634,2005.mtsummit-papers.11,0,0.0391844,"alue feature both on word level and on phrase level. On the phrase level we consider the phrases used by the SMT decoder, and on the word level we consider individual source words, and their alignment to 0 − N target words. TTR = Q-value = 4 C(tokens) C(types) f (st) n(s) + n(t) (7) (8) Experiments In the following, we show results for our experiments with the Docent decoder that include readability features and compare them to runs without them. The systems are evaluated using both MT and readability metrics. 4.1 Experimental Setup We evaluate our models on parliamentary texts from Europarl (Koehn, 2005), which contain both complex sentences and a lot of domain-specific terminology. All tests are performed for English–Swedish translation. Our system is trained on 1,488,322 sentences. For evaluation, we extracted 20 documents with a total of 690 sentences from a separate part of Europarl. A document is defined as a complete contiguous sequence of utterances of one speaker. We excluded documents that are shorter than 20 sentences and longer than 79 sentences. Moses (Koehn et al., 2007) was used for training the translation model and SRILM (Stolcke, 2002) for training the language model. We init"
W13-5634,P07-2045,0,0.0103962,"both MT and readability metrics. 4.1 Experimental Setup We evaluate our models on parliamentary texts from Europarl (Koehn, 2005), which contain both complex sentences and a lot of domain-specific terminology. All tests are performed for English–Swedish translation. Our system is trained on 1,488,322 sentences. For evaluation, we extracted 20 documents with a total of 690 sentences from a separate part of Europarl. A document is defined as a complete contiguous sequence of utterances of one speaker. We excluded documents that are shorter than 20 sentences and longer than 79 sentences. Moses (Koehn et al., 2007) was used for training the translation model and SRILM (Stolcke, 2002) for training the language model. We initialized our experiments with a Moses model that uses standard features of a phrase-based system: a 5-gram language model, five translation model features, a distance-based reordering penalty, and a word counter. These features were optimized using minimum error-rate training (Och, 2003) and the same weights were then used in Docent. Currently, we are developing the optimization procedure in Docent and could not use it in this work. We thus used a grid search approach for choosing weig"
W13-5634,N03-1017,0,0.0152721,"endence between the sentences in a text. This independence assumption is exploited in the most popular SMT decoding algorithms, which efficiently explore a very large search space by using dynamic programming (Och et al., 2001). Integrating discourse-wide information into traditional SMT decoders is difficult because of these dynamic programming assumptions. We therefore implement our document-level readability models in the recently published document-level SMT decoder Docent (Hardmeier et al., 2012), which does not have these limitations. The model implemented by Docent is phrase-based SMT (Koehn et al., 2003). The decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by applying a series of operations using a hill climbing strategy to find a (local) maximum of the score function. The three operations used are to change the translation of phrases, to swap the position of two phrases , and to resegment phrases. This setup is not limited by dynamic programming constraints, so we can define Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference"
W13-5634,P03-1021,0,0.0433779,"of Europarl. A document is defined as a complete contiguous sequence of utterances of one speaker. We excluded documents that are shorter than 20 sentences and longer than 79 sentences. Moses (Koehn et al., 2007) was used for training the translation model and SRILM (Stolcke, 2002) for training the language model. We initialized our experiments with a Moses model that uses standard features of a phrase-based system: a 5-gram language model, five translation model features, a distance-based reordering penalty, and a word counter. These features were optimized using minimum error-rate training (Och, 2003) and the same weights were then used in Docent. Currently, we are developing the optimization procedure in Docent and could not use it in this work. We thus used a grid search approach for choosing weights for the readability-based features with low, medium, and high impact relative to the standard features. We performed automatic evaluations using a set of common metrics for MT quality and readability. For MT quality we used BLEU (Papineni et al., 2002) and NIST (Doddington, 2002), Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Con"
W13-5634,W01-1408,0,0.0740805,"paper is organized as follows: First, we introduce important background on document-level decoding and readability. Thereafter, we present our experiments using a set of global features. Finally, we add some information about related work, summarize our findings and give ideas about future work. 2 Document-wide SMT Most current SMT systems translate sentences individually, assuming independence between the sentences in a text. This independence assumption is exploited in the most popular SMT decoding algorithms, which efficiently explore a very large search space by using dynamic programming (Och et al., 2001). Integrating discourse-wide information into traditional SMT decoders is difficult because of these dynamic programming assumptions. We therefore implement our document-level readability models in the recently published document-level SMT decoder Docent (Hardmeier et al., 2012), which does not have these limitations. The model implemented by Docent is phrase-based SMT (Koehn et al., 2003). The decoder uses a local search approach whose state consists of a complete translation of an entire document at any time. The initial state is improved by applying a series of operations using a hill climb"
W13-5634,P02-1040,0,0.0861851,"ive translation model features, a distance-based reordering penalty, and a word counter. These features were optimized using minimum error-rate training (Och, 2003) and the same weights were then used in Docent. Currently, we are developing the optimization procedure in Docent and could not use it in this work. We thus used a grid search approach for choosing weights for the readability-based features with low, medium, and high impact relative to the standard features. We performed automatic evaluations using a set of common metrics for MT quality and readability. For MT quality we used BLEU (Papineni et al., 2002) and NIST (Doddington, 2002), Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 378 of 474] Feature Reference Baseline OVIX TTR Qw Qp nLW nXLW SL Weight – – low medium high low medium high low medium high low medium high low medium high low medium high low medium high BLEU↑ – 0.243 0.243 0.228 0.144 0.243 0.225 0.150 0.242 0.231 0.165 0.243 0.229 0.097 0.244 0.225 0.106 0.241 0.225 0.224 0.242 0.211 0.150 NIST↑ – 6.12 6.11 5.83 4.41 6.12 5.75 4.48 6.10 5.90 4.93 6.12 5.99 3.90 6.14 5.96 4.11 6.10 5.85 5"
W13-5634,W11-4627,0,0.0286822,"det i Lissabon särskilt uppmärksammat främja våra ansträngningar att genomföra riskkapital så att handlingsplanen avslutas 2003. Table 5: Examples of translation output from a sample of systems sentence compression (e.g., Knight and Marcu, 2000; Specia, 2010). Furthermore, there is a wide range of publications using other methods for monolingual sentence compression and text simplification, (e.g., Daelemans et al., 2004; Cohn and Lapata, 2009). Readability has also been investigated as an effect of text summarization, as measured by user studies (Margarido et al., 2008) and automatic metrics (Smith and Jönsson, 2011). In these studies the readability was generally better in the summarized texts than in the original texts. Stymne and Smith (2012) showed that SMT is affected by summarization, but found no relation between readability and SMT quality measured by standard evaluation metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexical consistency. The effect of lexical consistency in translation has been studied by Carpuat (2009) and Carpuat and Simard (2012). Tiedemann (2010) proposed cached models to push consistent translatio"
W13-5634,P11-4010,1,0.864145,"Missing"
W13-5634,W10-2602,1,0.879769,"rgarido et al., 2008) and automatic metrics (Smith and Jönsson, 2011). In these studies the readability was generally better in the summarized texts than in the original texts. Stymne and Smith (2012) showed that SMT is affected by summarization, but found no relation between readability and SMT quality measured by standard evaluation metrics. There is also related work concerned with the integration of wide contextual features in machine translation, such as lexical consistency. The effect of lexical consistency in translation has been studied by Carpuat (2009) and Carpuat and Simard (2012). Tiedemann (2010) proposed cached models to push consistent translation with some success in the case of domain adaptation. The use of word sense disambiguation in SMT is another example where wide contextual information can be incorporated on the source side (Carpuat and Wu, 2007; Chan et al., 2007) Another study related to ours is Genzel et al. (2010), who study poetry translation and perform joint translation and poetry creation of news text as well as translation of poems that keep the Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Pr"
W14-0605,N07-1047,0,0.030979,"Missing"
W14-0605,W11-4106,0,0.293147,"Missing"
W14-0605,P12-2059,0,0.0503476,"Missing"
W14-0605,W13-2302,0,0.0925176,"Missing"
W14-0605,P00-1056,0,0.103449,"Missing"
W14-0605,W13-5617,1,0.536528,"to the frequency with which the specific source characters are left unchanged, in accordance with the following formula: avg editdistance +(1.96∗standard deviation) If several normalisation candidates have the same edit distance as compared to the source word, the most frequent candidate is chosen, based on modern corpus data. If none of the highest-ranked normalisation candidates are present in the corpus, or if there are several candidates with the same frequency distribution, a final candidate is randomly chosen. 3.3 The SMT-based Approach In the SMT-based approach, originally presented by Pettersson et al. (2013a), spelling normalisation is treated as a translation task. To address changes in spelling rather than full translation of words and phrases, character-based translation (without lexical reordering) is performed, a well-known technique for transliteration and 34 character-level translation between closely related languages (Matthews, 2007; Vilar et al., 2007; Nakov and Tiedemann, 2012). In character-level SMT, phrases are modeled as character sequences instead of word sequences, and translation models are trained on character-aligned parallel corpora whereas language models are trained on cha"
W14-0605,P11-1038,0,0.0292904,"Missing"
W14-0605,rognvaldsson-etal-2012-icelandic,0,0.030181,",089 144,248 Szeged 1,257,089 144,248 Szeged 1,257,089 144,248 Table 3: Language resources for Hungarian. 1 For information on how to access the data sets used in our experiments, please contact the authors. 36 4.4 Icelandic to train a language model in the SMT-based approach. Table 5 presents in more detail the data sets used in the Swedish experiments. For training, tuning and evaluation in the Icelandic experiments, we use a manually normalised subset of the Icelandic Parsed Historical Corpus (IcePaHC), a manually tagged and parsed diachronic corpus of texts from the time period 1150–2008 (Rögnvaldsson et al., 2012). This subset contains four texts from the 15th century: three sagas (Vilhjálm’s saga, Jarlmann’s saga, and Ector’s saga) and one narrative-religious text (Miðaldaævintýri). As a dictionary for Levenshtein calculations we use a combination of Beygingarlýsing Íslensks Nútímamáls, BÍN (a database of modern Icelandic inflectional forms (Bjarnadóttir, 2012)), and all tokens occurring 100 times or more in the Tagged Icelandic Corpus of Contemporary Icelandic texts, MÍM (Helgadóttir et al., 2012).2 The frequency-based choice of a final normalisation candidate in the Levenshtein approach, as well as"
W14-0605,W11-0415,0,0.132854,"the Hungarian Generative Diachronic Syntax project, HGDS (Simon, To appear), in total 11 codices from the time period 1440–1541. The Szeged Treebank is used as the single modern language resource both for the Levenshtein-based and for the SMT-based approach (Csendes et al., 2005). Table 3 presents in more detail the data sets used in the Hungarian experiments. Resource Training Tuning Evaluation Lev. dict. Lev. freq. SMT lm German For training, tuning and evaluation in the German experiments, we use a manually normalised subset of the GerManC corpus of German texts from the period 1650–1800 (Scheible et al., 2011). This subset contains 22 texts from the period 1659– 1780, within the genres of drama, newspaper text, Data Tokens Types HGDS 137,669 45,529 HGDS 17 181 8 827 HGDS 17,214 8,798 Szeged 1,257,089 144,248 Szeged 1,257,089 144,248 Szeged 1,257,089 144,248 Table 3: Language resources for Hungarian. 1 For information on how to access the data sets used in our experiments, please contact the authors. 36 4.4 Icelandic to train a language model in the SMT-based approach. Table 5 presents in more detail the data sets used in the Swedish experiments. For training, tuning and evaluation in the Icelandic"
W14-0605,W07-0705,0,0.0155825,"Missing"
W14-0812,C12-2049,0,0.0220494,"of candidates in another corpus like the web. Villaviciencio (2005), for example, uses number of hits on Google for validating the likelihood of particle verbs. However, as Ramisch (2012) states in his introduction, MWE is an institutionalised phenomenon. This means that an MWE is frequently used and is part of the vocabulary of a speaker as well as the simple words. It means also that MWEs have specific statistical properties that have been studied. The results of those studies are statistical measures such as dice score, maximum likelihood estimate, pointwise mutual information, T-score. As Islam et al. (2012) remark in a study of Google Ngram, those measures of association are language independent. And it is demonstrated by Pecina (2008) that combining different collocation measures using standard statistical classification methods improves over using a single collocation measure. However, nowadays, using only lexical association measures for extraction and validation of MWE is not considered the most effective method. The tendency these last years is to combine association measures with linguistic features (Ramisch et al., 2010a; Pecina, 2008; Tsvetkov and Wintner, 2011). 2.2 Mwetoolkit Among the"
W14-0812,2005.mtsummit-papers.11,0,0.0131014,"ish and French corpora, but they never use the data generated by mwetoolkit to train a model. In contrast, Zilio et al. (2011) make a study involving training a model but use it only on English and use extra lexical resources to complement the machine learning method, so their study does not focus just on classifier evaluation. This paper presents the first evaluation of mwetoolkit on French together with two resources very commonly used by the French NLP community: the tagger TreeTagger (Schmid, 1994) and the dictionary Dela.1 Training and test data are taken from the French Europarl corpus (Koehn, 2005) and classifiers are trained using the Weka machine learning toolkit (Hall et al., 2009). The primary goal is to evaluate what level of precision can be achieved for nominal MWEs, using a manual evaluation of MWEs extracted, and to what extent the MWEs extracted are novel and can be used to enrich the lexicon. In addition, we will investigate what effect the choice of part-of-speech patterns used to generate the training data has on precision and novelty. Our results indicate that classifiers 1 http://www-igm.univ-mlv.fr/˜unitex/ index.php?page=5&html=bibliography.html 72 Proceedings of the 10"
W14-0812,C10-3015,0,0.134657,"e of its syntactic, distributional or semantic properties cannot be deduced from the properties of its component” (Silberztein and L.A.D.L., 1990). So how can we extract them? Statistical association measures have long been used for MWE extraction (Pecina, 2010), and by training supervised classifiers that use association measures as features we can further improve the quality of the extraction process. However, supervised machine learning requires annotated data, which creates a bottleneck in the absence of large corpora annotated for MWEs. In order to circumvent this bottleneck, mwetoolkit (Ramisch et al., 2010b) generates training instances by first extracting candidates that fit a certain part-of-speech pattern, such as Noun-Noun or Noun-Adjective, and then marking the candidates as positive or negative instances depending on whether they can be found in a given lexicon or not. Such a training set will presumably not contain any false positives (that is, candidates marked as positive instances that are not real MWEs), but depending on the coverage of the lexicon there will be a smaller or larger proportion of false negatives. The question is what quality can be obtained using such a noisy training"
W14-0812,W12-3301,0,0.0285566,"Missing"
W14-0812,D11-1077,0,0.0301907,"e mutual information, T-score. As Islam et al. (2012) remark in a study of Google Ngram, those measures of association are language independent. And it is demonstrated by Pecina (2008) that combining different collocation measures using standard statistical classification methods improves over using a single collocation measure. However, nowadays, using only lexical association measures for extraction and validation of MWE is not considered the most effective method. The tendency these last years is to combine association measures with linguistic features (Ramisch et al., 2010a; Pecina, 2008; Tsvetkov and Wintner, 2011). 2.2 Mwetoolkit Among the tools developed for extracting MWEs, mwetoolkit is one of the most recent. Developed by Ramisch et al. (2010b) it aims not only at extracting candidates for potential MWEs, but also at extracting their association measures. Provided that a lexicon of MWEs is available and provided a preprocessed corpus, mwetoolkit makes it pos73 sible to train a machine learning system with the association measures as features with a minimum of implementation. Ramisch et al. (2010b) provide experiments on Portuguese, English and Greek. Zilio et al. (2011) provide experiments with thi"
W14-0812,W11-4529,0,0.391612,"et will presumably not contain any false positives (that is, candidates marked as positive instances that are not real MWEs), but depending on the coverage of the lexicon there will be a smaller or larger proportion of false negatives. The question is what quality can be obtained using such a noisy training set. To the best of our knowledge, we cannot find the answer for French in literature. Indeed, Ramisch et al. (2012) compares the performance of mwetoolkit with another toolkit on English and French corpora, but they never use the data generated by mwetoolkit to train a model. In contrast, Zilio et al. (2011) make a study involving training a model but use it only on English and use extra lexical resources to complement the machine learning method, so their study does not focus just on classifier evaluation. This paper presents the first evaluation of mwetoolkit on French together with two resources very commonly used by the French NLP community: the tagger TreeTagger (Schmid, 1994) and the dictionary Dela.1 Training and test data are taken from the French Europarl corpus (Koehn, 2005) and classifiers are trained using the Weka machine learning toolkit (Hall et al., 2009). The primary goal is to e"
W14-0817,A00-1031,0,0.0289143,"also that prepositional paraphrases are more efficient for machine translation experiments. However, when examining the compound nouns closely it becomes obvious that the potential paraphrases fall in one of the following four categories. The first category is compound nouns that are easy to paraphrase by a prepositional phrase only, (Examples 1a, 1b), sometimes with several possible prepositions, as in the latter case. (1) Paraphrasing Compound Nouns To extract candidate compound nouns for paraphrasing, we first tagged the Swedish Europarl corpus and a subset of Swedish Wikipedia using TnT (Brants, 2000) trained on the StockholmUme˚a Corpus. The resulting corpus was used to compile a frequency dictionary and a tag dictionary, which were given as input to a modified version of the splitting algorithm from Koehn and Knight (2003), producing a list of nouns with possible split points and the constituents and their tags, if any, sorted by descending frequency. The modifications to the splitting algorithm include a lower bound, ignoring all tokens shorter than 6 100 a. psalmf¨orfattare (hymn writer) f¨orfattare av psalmer writer of hymns b. j¨arnv¨agsstation (railway station) station {f¨or, p˙a, l"
W14-0817,E03-1076,0,0.393439,"ction Swedish is a highly productive language, new words can be constructed fairly easily by concatenating one word with another. This is done across word classes, although, as can be expected, predominantly with content words. Due to this high productivity, an exhaustive dictionary of noun compounds in Swedish does not, and can not exist. Instead, in this project, noun compounds are extracted from the Swedish Europarl corpus (Koehn, 2005) and a subset of Swedish Wikipedia,1 using a slight modification of the splitting method described in Stymne and Holmqvist (2008), based on previous work by Koehn and Knight (2003). The assumption that paraphrases of noun compounds can help in machine translation is sup1 http://sv.wikipedia.org/ Previous studies on the semantics of compound nouns have, at least for the English language, in general focused on finding abstract categories to distinguish different compound nouns from each other. Although different in form, the main idea is that a finite set of relations hold between the constituents of all compound nouns. Experiments have been done to analyse such categories in Girju et al. (2005), and applied studies on paraphrasing compound nouns with some form of predica"
W14-0817,P07-2045,0,0.00268158,"here is no use paraphrasing these compound nouns, and as such they are left out. (4) a. stadsr¨attighet (city rights) b. domkyrka (cathedral) All compound nouns that are decomposable into their constituents were paraphrased according to the criteria listed above as far as possible. 4 Machine Translation Experiments To evaluate the effect of compound paraphrasing, a phrase-based statistical machine translation system was trained on a subset of roughly 55,000 sentences from Swedish-English Europarl, with the Swedish compound nouns paraphrased before training. The system was trained using Moses (Koehn et al., 2007) with default settings, using a 5-gram language model created from the English side of the training corpus using SRILM (Stolcke, 2002). A test set was paraphrased in the same way and run through the decoder. We tested two versions of the system, one where all 200 paraphrases were used, and one where only the paraphrases in the first two categories (transparent prepositional and verb phrases) were used. As a baseline, we used a system trained with the same settings on 101 the unmodified training corpus and applied to the unmodified test corpus. The systems were evaluated in two ways. First, we"
W14-0817,2005.mtsummit-papers.11,0,0.0376319,"translation. The results indicate a slight improvement in translation of the paraphrased compound nouns, with a minor loss in overall BLEU score. 1 2 Background Introduction Swedish is a highly productive language, new words can be constructed fairly easily by concatenating one word with another. This is done across word classes, although, as can be expected, predominantly with content words. Due to this high productivity, an exhaustive dictionary of noun compounds in Swedish does not, and can not exist. Instead, in this project, noun compounds are extracted from the Swedish Europarl corpus (Koehn, 2005) and a subset of Swedish Wikipedia,1 using a slight modification of the splitting method described in Stymne and Holmqvist (2008), based on previous work by Koehn and Knight (2003). The assumption that paraphrases of noun compounds can help in machine translation is sup1 http://sv.wikipedia.org/ Previous studies on the semantics of compound nouns have, at least for the English language, in general focused on finding abstract categories to distinguish different compound nouns from each other. Although different in form, the main idea is that a finite set of relations hold between the constituen"
W14-0817,sjobergh-kann-2004-finding,0,0.0634274,"Missing"
W14-0817,2008.eamt-1.25,0,0.0809465,"inor loss in overall BLEU score. 1 2 Background Introduction Swedish is a highly productive language, new words can be constructed fairly easily by concatenating one word with another. This is done across word classes, although, as can be expected, predominantly with content words. Due to this high productivity, an exhaustive dictionary of noun compounds in Swedish does not, and can not exist. Instead, in this project, noun compounds are extracted from the Swedish Europarl corpus (Koehn, 2005) and a subset of Swedish Wikipedia,1 using a slight modification of the splitting method described in Stymne and Holmqvist (2008), based on previous work by Koehn and Knight (2003). The assumption that paraphrases of noun compounds can help in machine translation is sup1 http://sv.wikipedia.org/ Previous studies on the semantics of compound nouns have, at least for the English language, in general focused on finding abstract categories to distinguish different compound nouns from each other. Although different in form, the main idea is that a finite set of relations hold between the constituents of all compound nouns. Experiments have been done to analyse such categories in Girju et al. (2005), and applied studies on pa"
W14-0821,P05-1066,0,0.740782,"he results, as well as their discussion, where we present possible reasons why VPCs performed worse in the experiments, which finally leads to our conclusions in Section 7. An appendix lists all the verb pairs used to construct the test suite. 2 Related Work A lot of research has been done on the identification, classification, and extraction of VPCs, with 124 Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 124–131, c Gothenburg, Sweden, 26-27 April 2014. 2014 Association for Computational Linguistics the majority of work done on English. For example, Villavicencio (2005) presents a study about the availability of VPCs in lexical resources and proposes an approach to use semantic classification to identify as many VPC candidates as possible. She then validates these candidates using the retrieved results from online search engines. Many linguistic studies analyse VPCs in German, or English, respectively, mostly discussing the grammar theory that underlies the compositionality of MWEs in general or presenting more particular studies such as theories and experiments about language acquisition. An example would be the work of Behrens (1998), in which she contrast"
W14-0821,holmqvist-etal-2012-alignment,0,0.293211,"t to English, where the particle is always separated from the verb, German VPCs are separable, meaning that the particle can either be attached as a prefix to the verb or stand separate from it, depending on factors such as tense and voice, along with whether the VPC is found in a main clause or subordinate clause. The fact that German VPCs are separable means that word order differences between the source and target language can occur in statistical machine translation (SMT). It has been shown that the translation quality of translation systems can suffer from such differences in word order (Holmqvist et al., 2012). Since VPCs make up for a significant amount of verbs in English, as well as in German, they are a likely source for translation errors. This makes it essential to analyse any issues with VPCs that occur while translating, in order to be able to develop possible improvements. In our approach, we investigate if the presence of VPCs causes translation errors. We do this by creating and utilising a dataset of 236 sentences, using a collection of 59 German verb pairs, each consisting of a VPC and a synonymous simplex verb, a test suite that is made freely available. We discuss the English transla"
W14-0821,Y11-1015,0,\N,Missing
W14-1011,Q13-1034,1,0.861869,"Missing"
W14-1011,de-marneffe-etal-2006-generating,0,0.0211219,"Missing"
W14-1011,petrov-etal-2012-universal,0,0.0371417,"le-based morphological analysis, specifically targeting the challenges posed by richly inflected languages. In the second part, I will present the Universal Dependency Treebank Project, a recent initiative seeking to create multilingual corpora with morphosyntactic annotation that is consistent across languages. 2 3 Treebanks for Multilingual Parsing In McDonald et al. (2013), we present a new collection of treebanks with homogeneous syntactic annotation for six languages: German, English, Swedish, Spanish, French and Korean. The annotation is based on the Google universal part-ofspeech tags (Petrov et al., 2012) and the Stanford dependencies (de Marneffe et al., 2006), adapted and harmonized across languages. To show the usefulness of such a resource, we also present a case study of cross-lingual transfer parsing with more reliable evaluation than has been possible before. The ‘universal’ treebank is made freely available in order to facilitate research on multilingual dependency parsing.1 A second release including eleven languages is planned for the spring of 2014. 4 Morphological and Syntactic Parsing Conclusion Although both projects reviewed in the talk may contribute to a better understanding o"
W14-1011,W09-2307,0,\N,Missing
W14-1011,W06-2920,0,\N,Missing
W14-1011,W02-1503,0,\N,Missing
W14-1011,P13-2017,1,\N,Missing
W14-1614,de-marneffe-etal-2006-generating,0,0.0246402,"Missing"
W14-1614,D12-1001,0,0.257649,"can assume that SMT will produce output that is much closer to the input than manual translations in parallel texts usually are. Even if this may seem like a short-coming in general, in the case of annotation projection it should rather be an advantage, because it makes it more straightforward and less error-prone to transfer annotation from source to target. Furthermore, the alignment between words and phrases is inherently provided as an output of all common SMT models. Hence, no additional procedures have to be performed on top of the translated corpus. Recent research (Zhao et al., 2009; Durrett et al., 2012) has attempted to address synthetic data creation for syntactic parsing via bilingual lexica. We seek to build on this work by utilizing more advanced translation techniques. Further in the paper, we first describe the tools and resources used in our experiments (§2). We elaborate on our approach to translating treebanks (§3) and projecting syntactic annotations (§4) for a new language. Finally, we provide empirical evaluation of the suggested approach (§5) and observe a substantial increase in parsing accuracy over the delexicalized parsing baselines. 2 Resources and Tools In our experiments,"
W14-1614,D13-1205,0,0.0415106,"Missing"
W14-1614,D07-1097,1,0.448738,"Missing"
W14-1614,P13-2121,0,0.0129603,"Missing"
W14-1614,2005.mtsummit-papers.11,0,0.0215141,"anslation, we select the popular Moses toolbox (Koehn et al., 2007) and the phrasebased translation paradigm as our basic framework. Phrase-based SMT has the advantage of being straightforward and efficient in training and decoding, while maintaining robustness and reliability for many language pairs. More details about the setup and the translation procedures are given in Section 3 below. The most essential ingredient for translation performance is the parallel corpus used for training the translation models. For our experiments we use the freely available and widely used Europarl corpus v7 (Koehn, 2005).4 It is commonly used for training SMT models and includes parallel data for all languages represented in the Universal Treebank except Korean, which we will, therefore, leave out in our experiments. For tuning we apply the newstest 2012 data provided by the annual workshop on statistical machine translation.5 For language modeling, we use a combination of 2 http://www.maltparser.org/ http://nil.fdi.ucm.es/maltoptimizer/ 4 http://www.statmt.org/europarl/ 5 http://www.statmt.org/wmt14 3 DE DE EN ES FR SV 94 M 94 M 103 M 96 M 105 M 104 M 81 M 89 M 89 M 91 M SV 2.0 M 1.9 M 1.9 M 1.8 M 2.0 M 2.0"
W14-1614,D11-1006,0,0.540929,"Missing"
W14-1614,P80-1024,0,0.824454,"Missing"
W14-1614,P12-1066,0,0.342974,"ired. In addition, training can be performed on gold standard annotation. However, model transfer assumes a common fea130 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 130–140, c Baltimore, Maryland USA, June 26-27 2014. 2014 Association for Computational Linguistics ture representation across languages (McDonald et al., 2013), which can be a strong bottleneck. Several extensions have been proposed to make the approach more robust. First of all, multiple source languages can be involved to increase the statistical basis for learning (McDonald et al., 2011; Naseem et al., 2012), a strategy that can also be used in the case of annotation projection. Cross-lingual word clusters can be created to obtain additional universal features (T¨ackstr¨om et al., 2012). Techniques for target language adaptation can be used to improve model transfer with multiple sources (T¨ackstr¨om et al., 2013b). 1.2 The Translation Approach In this paper, we propose a third strategy, based on automatically translating training data to a new language in order to create annotated resources directly from the original source. Recent advances in statistical machine translation (SMT) combined with"
W14-1614,nivre-etal-2006-maltparser,1,0.855992,"Missing"
W14-1614,W06-2933,1,0.560504,"Missing"
W14-1614,J03-1002,0,0.00756484,"tom row = number of sentences in monolingual corpora. Europarl and News data provided from the same source. The statistics of the corpora are given in Table 1. 3 Translating Treebanks The main contribution of this paper is the empirical study of automatic treebank translation for parser transfer. We compare three different translation approaches in order to investigate the influence of several parameters. All of them are based on automatic word alignment and subsequent extraction of translation equivalents as common in phrase-based SMT. In particular, word alignment is performed using GIZA++ (Och and Ney, 2003) and IBM model 4 as the final model for creating the Viterbi word alignments for all parallel corpora used in our experiments. For the extraction of translation tables, we use the Moses toolkit with its standard settings to extract phrase tables with a maximum of seven tokens per phrase from a symmetrized word alignment. Symmetrization is done using the grow-diagfinal-and heuristics (Koehn et al., 2003). We tune phrase-based SMT models using minimum error rate training (Och, 2003) and the development data for each language pair. The language model is a standard 5-gram model estimated from the"
W14-1614,N03-1017,0,0.016743,"rs. All of them are based on automatic word alignment and subsequent extraction of translation equivalents as common in phrase-based SMT. In particular, word alignment is performed using GIZA++ (Och and Ney, 2003) and IBM model 4 as the final model for creating the Viterbi word alignments for all parallel corpora used in our experiments. For the extraction of translation tables, we use the Moses toolkit with its standard settings to extract phrase tables with a maximum of seven tokens per phrase from a symmetrized word alignment. Symmetrization is done using the grow-diagfinal-and heuristics (Koehn et al., 2003). We tune phrase-based SMT models using minimum error rate training (Och, 2003) and the development data for each language pair. The language model is a standard 5-gram model estimated from the monolingual data using modified Kneser-Ney smoothing without pruning (applying KenLM tools (Heafield et al., 2013)). Our first translation approach is based on a very simple word-by-word translation model. For this, we select the most reliable translations of single words from the phrase translation tables extracted from the parallel corpora as described above. We restrict the model to tokens with alpha"
W14-1614,P03-1021,0,0.0115556,"lation equivalents as common in phrase-based SMT. In particular, word alignment is performed using GIZA++ (Och and Ney, 2003) and IBM model 4 as the final model for creating the Viterbi word alignments for all parallel corpora used in our experiments. For the extraction of translation tables, we use the Moses toolkit with its standard settings to extract phrase tables with a maximum of seven tokens per phrase from a symmetrized word alignment. Symmetrization is done using the grow-diagfinal-and heuristics (Koehn et al., 2003). We tune phrase-based SMT models using minimum error rate training (Och, 2003) and the development data for each language pair. The language model is a standard 5-gram model estimated from the monolingual data using modified Kneser-Ney smoothing without pruning (applying KenLM tools (Heafield et al., 2013)). Our first translation approach is based on a very simple word-by-word translation model. For this, we select the most reliable translations of single words from the phrase translation tables extracted from the parallel corpora as described above. We restrict the model to tokens with alphabetic characters only using pre-defined Unicode character 132 sets. The selecti"
W14-1614,P07-2045,0,0.00757185,"Missing"
W14-1614,petrov-etal-2012-universal,0,0.209401,"Missing"
W14-1614,J96-1001,0,0.0271066,"this, we select the most reliable translations of single words from the phrase translation tables extracted from the parallel corpora as described above. We restrict the model to tokens with alphabetic characters only using pre-defined Unicode character 132 sets. The selection of translation alternatives is based on the Dice coefficient, which combines the two essential conditional translation probabilities given in the phrase table. The Dice coefficient is in fact the harmonic mean of these two probabilities and has successfully been used for the extraction of translation equivalents before (Smadja et al., 1996): 2 p(s, t) Dice(s, t) = =2 p(s) + p(t)  1 1 + p(s|t) p(t|s) O RIGINAL DE EN ES FR SV 14.0 0.00 7.90 13.3 4.20 WORD - BASED DE EN ES FR −1 SV MT DE EN ES FR SV – 43.3 54.9 68.2 34.1 49.1 – 25.1 39.6 5.20 62.6 27.6 – 32.8 21.6 52.8 34.8 12.3 – 33.7 60.4 0.00 18.3 57.8 – P HRASE - BASED MT DE Other association measures would be possible as well but Smadja et al. (1996) argue that the Dice coefficient is more robust with respect to low frequency events than other common metrics such as pointwise mutual information, which can be a serious issue with the unsmoothed probability estimations in stan"
W14-1614,N12-1052,0,0.404703,"Missing"
W14-1614,N13-1126,1,0.679337,"Missing"
W14-1614,H01-1035,0,0.857418,"nguages (Bender, 2013). Many applications require robust tools and the development of language-specific resources is expensive and time consuming. Furthermore, many tasks such as data-driven syntactic parsing require strong supervision to achieve reasonable results for real-world applications, since the performance of fully unsupervised methods lags behind by a large margin in comparison with the state of the Previous Cross-Lingual Approaches Annotation projection relies on the mapping of linguistic annotation across languages using parallel corpora and automatic alignment as basic resources (Yarowsky et al., 2001; Hwa et al., 2005; T¨ackstr¨om et al., 2013a). Tools that exist for the source language are used to annotate the source side of the corpus and projection heuristics are then applied to map the annotation through word alignment onto the corresponding target language text. Target language tools can then be trained on the projected annotation assuming that the mapping is sufficiently correct. Less frequent, but also possible, is the scenario where the source side of the corpus contains manual annotation (Agi´c et al., 2012). This addresses the problem created by projecting noisy annotations, but"
W14-1614,I08-3008,0,0.60358,"rsers on. More elaborated phrase-based models together with advanced annotation projection strategies do not necessarily lead to any improvements. As future work, we want to improve our model by (i) studying the impact of other SMT properties and improve the quality of treebank translation, (ii) implementing more sophisticated methods for annotation projection and (iii) using n-best lists provided by SMT models to introduce additional synthetic data using a single resource. We also aim at (iv) applying our approach to transfer parsing for closely related languages (see Agi´c et al. (2012) and Zeman and Resnik (2008) for related work), (v) testing it in a multi-source transfer scenario (McDonald et al., 2011) and, finally, (vi) comparing different dependency parsing paradigms within our experimental framework. Multi-source approaches are especially appealing using the translation approach. However, initial experiments (which we omit in this presentation) revealed that simple concatenation is not sufficient to obtain results that improve upon the single-best translated treebanks. A careful selection of appropriate training examples and their weights given to the training procedure seems to be essential to"
W14-1614,P11-2033,1,0.630094,"to slightly higher scores as we have noted in our experiments but we do not report those numbers here. Note also that the columns represent the target languages (used for testing), while the rows denote the source languages (used in training), as in McDonald et al. (2013). From the table, we can see that the baseline scores are compatible with the ones in the original experiments presented by (McDonald et al., 2013), included in Table 3 for reference. The differences are due to parser selection, as they use a transition-based parser with beam search and perceptron learning along the lines of Zhang and Nivre (2011) whereas we rely on greedy transition-based parsing with linear support vector machines. In the following, we will compare results to our baseline as we have a comparable setup in those experiments. However, most improvements shown below also apply in comparison with (McDonald et al., 2013). 135 5.2 Translated Treebanks Now we turn to the experiments on translated treebanks. We consider two setups. First, we look at the effect of translation when training delexicalized parsers. In this way, we can perform a direct comparison to the baseline performance presented WORD - BASED M ONOLINGUAL DE EN"
W14-1614,P09-1007,0,0.0505267,"omain. Secondly, we can assume that SMT will produce output that is much closer to the input than manual translations in parallel texts usually are. Even if this may seem like a short-coming in general, in the case of annotation projection it should rather be an advantage, because it makes it more straightforward and less error-prone to transfer annotation from source to target. Furthermore, the alignment between words and phrases is inherently provided as an output of all common SMT models. Hence, no additional procedures have to be performed on top of the translated corpus. Recent research (Zhao et al., 2009; Durrett et al., 2012) has attempted to address synthetic data creation for syntactic parsing via bilingual lexica. We seek to build on this work by utilizing more advanced translation techniques. Further in the paper, we first describe the tools and resources used in our experiments (§2). We elaborate on our approach to translating treebanks (§3) and projecting syntactic annotations (§4) for a new language. Finally, we provide empirical evaluation of the suggested approach (§5) and observe a substantial increase in parsing accuracy over the delexicalized parsing baselines. 2 Resources and To"
W14-1614,E12-2012,1,\N,Missing
W14-1614,W06-2920,0,\N,Missing
W14-1614,Q13-1001,1,\N,Missing
W14-1614,D07-1096,1,\N,Missing
W14-1614,P13-2017,1,\N,Missing
W14-3312,J92-4003,0,0.0276371,"nd 109 corpora. The first three of these corpora were included integrally into the training set after filtering out sentences of more than 80 words. The Common crawl and 109 data sets were run through an additional filtering step with an SVM classifier, closely following Mediani et al. (2011). The system includes three language models, a regular 6-gram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998) trained with KenLM (Heafield, 2011), a 4-gram bilingual language model (Niehues et al., 2011) with Kneser-Ney smoothing trained with KenLM and a 9-gram model over Brown clusters (Brown et al., 1992) with Witten-Bell smoothing (Witten and Bell, 1991) trained with SRILM (Stolcke, 2002). 122 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 122–129, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics place all pronouns that should be handled by the classifier, i.e. instances of il and elle aligned to it and instances of ils and elles aligned to they, with special placeholders. At decoding time, if a placeholder is encountered in a target language phrase, the applicable pronouns are generated with equal translation model proba"
W14-3312,P10-2033,0,0.0198937,"e case-sensitive phrase-based systems with lexicalized reordering trained on data provided by WMT. Word alignment is performed using fast align (Dyer et al., 2013). For tuning we use newstest2011. Additionally, we also test parallel data from OPUS (Tiedemann, 2012) filtered by a method adopted from Mediani et al. (2011). To contrast our baseline system, we trained a phrase-based model on parallel data that has been aligned on data pre-ordered using the reordering rules for German, which has been restored to the original word order after word alignment and before phrase extraction (similar to (Carpuat et al., 2010; Stymne et al., 2010)). We expect that the word alignment is improved by reducing crossings and long-distance links. However, the translation model as such has the same limitations as the baseline system in terms of long-range distortions. The final system is a two-step model in which we apply translation and language models trained on preordered target language data to perform the first step, which also includes a reordered POS language model. The second step is also treated as a translation problem as in Sudoh et al. (2011), and in our newstest2013 19.3 19.4 18.6 19.5 19.5 19.7 newstest2014"
W14-3312,W13-2210,0,0.0299303,"Missing"
W14-3312,P05-1066,0,0.162059,"Missing"
W14-3312,N13-1073,0,0.0402683,"US The fall of Saddam ushers in the right circumstances. Der Sturz von Saddam leitet solche richtigen Umst¨ande ein. Der Sturz von Saddam ein leitet solche richtigen Umst¨ande. Table 1: Two examples of pre-ordering outputs. The first two lines are the original English and German sentences and the third line shows the reordered sentence. We use three systems based on Moses to compare the effect of reordering on alignment and translation. All systems are case-sensitive phrase-based systems with lexicalized reordering trained on data provided by WMT. Word alignment is performed using fast align (Dyer et al., 2013). For tuning we use newstest2011. Additionally, we also test parallel data from OPUS (Tiedemann, 2012) filtered by a method adopted from Mediani et al. (2011). To contrast our baseline system, we trained a phrase-based model on parallel data that has been aligned on data pre-ordered using the reordering rules for German, which has been restored to the original word order after word alignment and before phrase extraction (similar to (Carpuat et al., 2010; Stymne et al., 2010)). We expect that the word alignment is improved by reducing crossings and long-distance links. However, the translation"
W14-3312,C10-1043,0,0.0141995,"l training data and a POS language model trained on tagged news data. The LMs are trained in the same way as for English–French. All systems are tuned using MERT (Och, 2003). Phrase-tables are filtered using entropy-based pruning (Johnson et al., 2007) as implemented in Moses. All BLEU scores are given for uncased data. 4.1 Pre-Ordered Alignment and Post-Ordered Translation The use of syntactic reordering as a separate preprocessing step has already a long tradition in statistical MT. Handcrafted rules (Collins et al., 2005; Popovi´c and Ney, 2006) or data-driven models (Xia and McCord, 2004; Genzel, 2010; Rottmann and Vogel, 2007; Niehues and Kolss, 2009) for preordering training data and system input have been explored in numerous publications. For certain language pairs, such as German and English, this method can be very effective and often improves the quality of standard SMT systems significantly. Typically, the source language is reordered to better match the syntax of the target language when translating between languages that exhibit consistent word order differences, which are difficult to handle In our experiments, we focus on the translation from English to German. Post-ordering be"
W14-3312,E12-1074,0,0.0128122,"tables. Another reason is the possible distance of finite and infinitival verbs in German verb phrases that can lead to the same problems described above with verb-particle constructions. The auxiliary or modal verb is placed at the second position but the main verb appears at the end of the associated verb phrase. The distances can be arbitrarily long and long-range dependencies are quite frequent. Similarly, negation particles and adverbials move away from the inflected verb forms in certain constructions. For more details on specific phenomena in German, we refer to (Collins et al., 2005; Gojun and Fraser, 2012). Pre-ordering, i.e. moving English words into German word order does not seem to be a good option as we loose the connection between related items when moving particles and main verbs away from their associated elements. Hence, we are interested in reordering the target language German into English word order which can be beneficial in two ways: (i) Reordering the German part of the parallel training data makes it possible to improve word alignment (which tends to prefer monotonic mappings) and subsequent phrase extraction which leads to better translation models. (ii) We can explore a two-st"
W14-3312,D13-1037,1,0.676415,"n Smith Uppsala University Department of Linguistics and Philology firstname.lastname@lingfil.uu.se Abstract We describe the Uppsala University systems for WMT14. We look at the integration of a model for translating pronominal anaphora and a syntactic dependency projection model for English–French. Furthermore, we investigate post-ordering and tunable POS distortion models for English– German. 1 Introduction In this paper we describe the Uppsala University systems for WMT14. We present three different systems. Two of them are based on the documentlevel decoder Docent (Hardmeier et al., 2012; Hardmeier et al., 2013a). In our English–French system we extend Docent to handle pronoun anaphora, and in our English–German system we add partof-speech phrase-distortion models to Docent. For German–English we also have a system based on Moses (Koehn et al., 2007). Again the focus is on word order, this time by using pre- and postreordering. 2 Document-Level Decoding Traditional SMT decoders translate texts as bags of sentences, assuming independence between sentences. This assumption allows efficient algorithms for exploring a large search space based on dynamic programming (Och et al., 2001). Because of the dyn"
W14-3312,W11-2123,0,0.0336108,"em submitted by Cho et al. (2013) to the WMT 2013 shared task. Our phrase table is trained on data taken from the News commentary, Europarl, UN, Common crawl and 109 corpora. The first three of these corpora were included integrally into the training set after filtering out sentences of more than 80 words. The Common crawl and 109 data sets were run through an additional filtering step with an SVM classifier, closely following Mediani et al. (2011). The system includes three language models, a regular 6-gram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998) trained with KenLM (Heafield, 2011), a 4-gram bilingual language model (Niehues et al., 2011) with Kneser-Ney smoothing trained with KenLM and a 9-gram model over Brown clusters (Brown et al., 1992) with Witten-Bell smoothing (Witten and Bell, 1991) trained with SRILM (Stolcke, 2002). 122 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 122–129, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics place all pronouns that should be handled by the classifier, i.e. instances of il and elle aligned to it and instances of ils and elles aligned to they, with special pl"
W14-3312,D07-1103,0,0.0113749,"Common crawl data was filtered using the method of Stymne et al. (2013). We use factored models with POS tags as a second output factor for German. The possibility to use language models for different factors has been added to our Docent decoder. Language models include an in-domain news language model, an out-of-domain model trained on the target side of the parallel training data and a POS language model trained on tagged news data. The LMs are trained in the same way as for English–French. All systems are tuned using MERT (Och, 2003). Phrase-tables are filtered using entropy-based pruning (Johnson et al., 2007) as implemented in Moses. All BLEU scores are given for uncased data. 4.1 Pre-Ordered Alignment and Post-Ordered Translation The use of syntactic reordering as a separate preprocessing step has already a long tradition in statistical MT. Handcrafted rules (Collins et al., 2005; Popovi´c and Ney, 2006) or data-driven models (Xia and McCord, 2004; Genzel, 2010; Rottmann and Vogel, 2007; Niehues and Kolss, 2009) for preordering training data and system input have been explored in numerous publications. For certain language pairs, such as German and English, this method can be very effective and o"
W14-3312,2005.iwslt-1.8,0,0.039688,"tymne et al., 2013) that it was useful to relax the hard distortion limit by either using a soft constraint, which could be tuned, or removing the limit completely. In that work we still used the standard parametrization of distortion, based on the positions of the first and last words in phrases. Our Docent decoder, however, always provides us with a full target translation that is step-wise improved, which means that we can apply distortion measures on the phrase-level without resorting to heuristics, which, for instance, are needed in the case of the lexicalized reordering models in Moses (Koehn et al., 2005). Because of this it is possible to use phrase-based distortion, where we calculate distortion based on the order of phrases, not on the order of some words. It is possible to parametrize phrase-distortion in different ways. In this work we use the phrase-distortion distance and a soft limit on the distortion distance, to mimic the word-based distortion. In our experiments we always set the soft limit to a distance of four phrases. In addition we use a measure based on how many crossings a phrase order gives rise to. We thus have three phrase-distortion features. As captured by lexicalized reo"
W14-3312,2009.mtsummit-posters.13,0,0.0172318,"e shortest distance between any pair of words in the aligned sets. The network is a binary classifier trained to discriminate positive examples extracted from human-made reference 123 amod nn auxpass by SMT systems with limited reordering capabilities such as phrase-based models. Preordering is often done on the entire training data as well to optimize translation models for the pre-ordered input. Less common is the idea of post-ordering, which refers to a separate step after translating source language input to an intermediate target language with corrupted (source-language like) word order (Na et al., 2009; Sudoh et al., 2011). punct nsubjpass prep pobj Domestic meat production is dominated by chicken . La production int´erieure de viande est domin´ee par le poulet . Figure 2: Dependency projection model translations from negative examples extracted from n-best lists generated by a baseline SMT system. 4 English–German For English–German we have two systems, one based on Moses, and one based on Docent. In both cases we have focused on word order, particularly for verbs and particles. Both our systems are trained on the same data made available by WMT. The Common crawl data was filtered using th"
W14-3312,D12-1108,1,0.882504,"mne J¨org Tiedemann Aaron Smith Uppsala University Department of Linguistics and Philology firstname.lastname@lingfil.uu.se Abstract We describe the Uppsala University systems for WMT14. We look at the integration of a model for translating pronominal anaphora and a syntactic dependency projection model for English–French. Furthermore, we investigate post-ordering and tunable POS distortion models for English– German. 1 Introduction In this paper we describe the Uppsala University systems for WMT14. We present three different systems. Two of them are based on the documentlevel decoder Docent (Hardmeier et al., 2012; Hardmeier et al., 2013a). In our English–French system we extend Docent to handle pronoun anaphora, and in our English–German system we add partof-speech phrase-distortion models to Docent. For German–English we also have a system based on Moses (Koehn et al., 2007). Again the focus is on word order, this time by using pre- and postreordering. 2 Document-Level Decoding Traditional SMT decoders translate texts as bags of sentences, assuming independence between sentences. This assumption allows efficient algorithms for exploring a large search space based on dynamic programming (Och et al., 2"
W14-3312,W09-0435,0,0.11068,"trained on tagged news data. The LMs are trained in the same way as for English–French. All systems are tuned using MERT (Och, 2003). Phrase-tables are filtered using entropy-based pruning (Johnson et al., 2007) as implemented in Moses. All BLEU scores are given for uncased data. 4.1 Pre-Ordered Alignment and Post-Ordered Translation The use of syntactic reordering as a separate preprocessing step has already a long tradition in statistical MT. Handcrafted rules (Collins et al., 2005; Popovi´c and Ney, 2006) or data-driven models (Xia and McCord, 2004; Genzel, 2010; Rottmann and Vogel, 2007; Niehues and Kolss, 2009) for preordering training data and system input have been explored in numerous publications. For certain language pairs, such as German and English, this method can be very effective and often improves the quality of standard SMT systems significantly. Typically, the source language is reordered to better match the syntax of the target language when translating between languages that exhibit consistent word order differences, which are difficult to handle In our experiments, we focus on the translation from English to German. Post-ordering becomes attractive for several reasons: One reason is"
W14-3312,P13-4033,1,0.682907,"n Smith Uppsala University Department of Linguistics and Philology firstname.lastname@lingfil.uu.se Abstract We describe the Uppsala University systems for WMT14. We look at the integration of a model for translating pronominal anaphora and a syntactic dependency projection model for English–French. Furthermore, we investigate post-ordering and tunable POS distortion models for English– German. 1 Introduction In this paper we describe the Uppsala University systems for WMT14. We present three different systems. Two of them are based on the documentlevel decoder Docent (Hardmeier et al., 2012; Hardmeier et al., 2013a). In our English–French system we extend Docent to handle pronoun anaphora, and in our English–German system we add partof-speech phrase-distortion models to Docent. For German–English we also have a system based on Moses (Koehn et al., 2007). Again the focus is on word order, this time by using pre- and postreordering. 2 Document-Level Decoding Traditional SMT decoders translate texts as bags of sentences, assuming independence between sentences. This assumption allows efficient algorithms for exploring a large search space based on dynamic programming (Och et al., 2001). Because of the dyn"
W14-3312,W11-2124,0,0.0221714,"ared task. Our phrase table is trained on data taken from the News commentary, Europarl, UN, Common crawl and 109 corpora. The first three of these corpora were included integrally into the training set after filtering out sentences of more than 80 words. The Common crawl and 109 data sets were run through an additional filtering step with an SVM classifier, closely following Mediani et al. (2011). The system includes three language models, a regular 6-gram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998) trained with KenLM (Heafield, 2011), a 4-gram bilingual language model (Niehues et al., 2011) with Kneser-Ney smoothing trained with KenLM and a 9-gram model over Brown clusters (Brown et al., 1992) with Witten-Bell smoothing (Witten and Bell, 1991) trained with SRILM (Stolcke, 2002). 122 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 122–129, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics place all pronouns that should be handled by the classifier, i.e. instances of il and elle aligned to it and instances of ils and elles aligned to they, with special placeholders. At decoding time, if a placeholder is encounte"
W14-3312,W01-1408,0,0.0359546,"et al., 2012; Hardmeier et al., 2013a). In our English–French system we extend Docent to handle pronoun anaphora, and in our English–German system we add partof-speech phrase-distortion models to Docent. For German–English we also have a system based on Moses (Koehn et al., 2007). Again the focus is on word order, this time by using pre- and postreordering. 2 Document-Level Decoding Traditional SMT decoders translate texts as bags of sentences, assuming independence between sentences. This assumption allows efficient algorithms for exploring a large search space based on dynamic programming (Och et al., 2001). Because of the dynamic programming assumptions it is hard to directly include discourse-level and long-distance features into a traditional SMT decoder. In contrast to this very popular stack decoding approach, our decoder Docent (Hardmeier et al., 2012; Hardmeier et al., 2013a) implements a search procedure based on local search. At any stage of the search process, its search state consists of a complete document translation, making it easy for feature models to access the complete document Joakim Nivre with its current translation at any point in time. The search algorithm is a stochastic"
W14-3312,P03-1021,0,0.00912326,"our systems are trained on the same data made available by WMT. The Common crawl data was filtered using the method of Stymne et al. (2013). We use factored models with POS tags as a second output factor for German. The possibility to use language models for different factors has been added to our Docent decoder. Language models include an in-domain news language model, an out-of-domain model trained on the target side of the parallel training data and a POS language model trained on tagged news data. The LMs are trained in the same way as for English–French. All systems are tuned using MERT (Och, 2003). Phrase-tables are filtered using entropy-based pruning (Johnson et al., 2007) as implemented in Moses. All BLEU scores are given for uncased data. 4.1 Pre-Ordered Alignment and Post-Ordered Translation The use of syntactic reordering as a separate preprocessing step has already a long tradition in statistical MT. Handcrafted rules (Collins et al., 2005; Popovi´c and Ney, 2006) or data-driven models (Xia and McCord, 2004; Genzel, 2010; Rottmann and Vogel, 2007; Niehues and Kolss, 2009) for preordering training data and system input have been explored in numerous publications. For certain lang"
W14-3312,popovic-ney-2006-pos,0,0.0838413,"Missing"
W14-3312,2007.tmi-papers.21,0,0.0459927,"a and a POS language model trained on tagged news data. The LMs are trained in the same way as for English–French. All systems are tuned using MERT (Och, 2003). Phrase-tables are filtered using entropy-based pruning (Johnson et al., 2007) as implemented in Moses. All BLEU scores are given for uncased data. 4.1 Pre-Ordered Alignment and Post-Ordered Translation The use of syntactic reordering as a separate preprocessing step has already a long tradition in statistical MT. Handcrafted rules (Collins et al., 2005; Popovi´c and Ney, 2006) or data-driven models (Xia and McCord, 2004; Genzel, 2010; Rottmann and Vogel, 2007; Niehues and Kolss, 2009) for preordering training data and system input have been explored in numerous publications. For certain language pairs, such as German and English, this method can be very effective and often improves the quality of standard SMT systems significantly. Typically, the source language is reordered to better match the syntax of the target language when translating between languages that exhibit consistent word order differences, which are difficult to handle In our experiments, we focus on the translation from English to German. Post-ordering becomes attractive for sever"
W14-3312,W10-1727,1,0.857022,"e-based systems with lexicalized reordering trained on data provided by WMT. Word alignment is performed using fast align (Dyer et al., 2013). For tuning we use newstest2011. Additionally, we also test parallel data from OPUS (Tiedemann, 2012) filtered by a method adopted from Mediani et al. (2011). To contrast our baseline system, we trained a phrase-based model on parallel data that has been aligned on data pre-ordered using the reordering rules for German, which has been restored to the original word order after word alignment and before phrase extraction (similar to (Carpuat et al., 2010; Stymne et al., 2010)). We expect that the word alignment is improved by reducing crossings and long-distance links. However, the translation model as such has the same limitations as the baseline system in terms of long-range distortions. The final system is a two-step model in which we apply translation and language models trained on preordered target language data to perform the first step, which also includes a reordered POS language model. The second step is also treated as a translation problem as in Sudoh et al. (2011), and in our newstest2013 19.3 19.4 18.6 19.5 19.5 19.7 newstest2014 19.1 19.3 18.7 19.3 1"
W14-3312,W13-2229,1,0.877852,"l., 2011). punct nsubjpass prep pobj Domestic meat production is dominated by chicken . La production int´erieure de viande est domin´ee par le poulet . Figure 2: Dependency projection model translations from negative examples extracted from n-best lists generated by a baseline SMT system. 4 English–German For English–German we have two systems, one based on Moses, and one based on Docent. In both cases we have focused on word order, particularly for verbs and particles. Both our systems are trained on the same data made available by WMT. The Common crawl data was filtered using the method of Stymne et al. (2013). We use factored models with POS tags as a second output factor for German. The possibility to use language models for different factors has been added to our Docent decoder. Language models include an in-domain news language model, an out-of-domain model trained on the target side of the parallel training data and a POS language model trained on tagged news data. The LMs are trained in the same way as for English–French. All systems are tuned using MERT (Och, 2003). Phrase-tables are filtered using entropy-based pruning (Johnson et al., 2007) as implemented in Moses. All BLEU scores are give"
W14-3312,2011.mtsummit-papers.36,0,0.175414,"ce between any pair of words in the aligned sets. The network is a binary classifier trained to discriminate positive examples extracted from human-made reference 123 amod nn auxpass by SMT systems with limited reordering capabilities such as phrase-based models. Preordering is often done on the entire training data as well to optimize translation models for the pre-ordered input. Less common is the idea of post-ordering, which refers to a separate step after translating source language input to an intermediate target language with corrupted (source-language like) word order (Na et al., 2009; Sudoh et al., 2011). punct nsubjpass prep pobj Domestic meat production is dominated by chicken . La production int´erieure de viande est domin´ee par le poulet . Figure 2: Dependency projection model translations from negative examples extracted from n-best lists generated by a baseline SMT system. 4 English–German For English–German we have two systems, one based on Moses, and one based on Docent. In both cases we have focused on word order, particularly for verbs and particles. Both our systems are trained on the same data made available by WMT. The Common crawl data was filtered using the method of Stymne et"
W14-3312,tiedemann-2012-parallel,1,0.687825,"st¨ande ein. Der Sturz von Saddam ein leitet solche richtigen Umst¨ande. Table 1: Two examples of pre-ordering outputs. The first two lines are the original English and German sentences and the third line shows the reordered sentence. We use three systems based on Moses to compare the effect of reordering on alignment and translation. All systems are case-sensitive phrase-based systems with lexicalized reordering trained on data provided by WMT. Word alignment is performed using fast align (Dyer et al., 2013). For tuning we use newstest2011. Additionally, we also test parallel data from OPUS (Tiedemann, 2012) filtered by a method adopted from Mediani et al. (2011). To contrast our baseline system, we trained a phrase-based model on parallel data that has been aligned on data pre-ordered using the reordering rules for German, which has been restored to the original word order after word alignment and before phrase extraction (similar to (Carpuat et al., 2010; Stymne et al., 2010)). We expect that the word alignment is improved by reducing crossings and long-distance links. However, the translation model as such has the same limitations as the baseline system in terms of long-range distortions. The"
W14-3312,C04-1073,0,0.0399491,"et side of the parallel training data and a POS language model trained on tagged news data. The LMs are trained in the same way as for English–French. All systems are tuned using MERT (Och, 2003). Phrase-tables are filtered using entropy-based pruning (Johnson et al., 2007) as implemented in Moses. All BLEU scores are given for uncased data. 4.1 Pre-Ordered Alignment and Post-Ordered Translation The use of syntactic reordering as a separate preprocessing step has already a long tradition in statistical MT. Handcrafted rules (Collins et al., 2005; Popovi´c and Ney, 2006) or data-driven models (Xia and McCord, 2004; Genzel, 2010; Rottmann and Vogel, 2007; Niehues and Kolss, 2009) for preordering training data and system input have been explored in numerous publications. For certain language pairs, such as German and English, this method can be very effective and often improves the quality of standard SMT systems significantly. Typically, the source language is reordered to better match the syntax of the target language when translating between languages that exhibit consistent word order differences, which are difficult to handle In our experiments, we focus on the translation from English to German. Po"
W14-3312,P07-2045,0,\N,Missing
W14-3312,W12-3144,0,\N,Missing
W14-3312,2011.iwslt-evaluation.9,0,\N,Missing
W14-3334,C10-1043,0,0.40539,"tion units in the same way as for alignment links. We will use these three measures to get a broader picture of TUs in alignment evaluation. Also in this case, 1−TUER is equivalent to F-measure. TUER(A, G) = 1 − 2|AU ∩ GU | |AU |+ |GU | Ahrenberg (2010) also proposed to measure reorderings. He does this by calculating the percentage of links with crossings of different lengths. To define this he only considers adjacent links in the source using the distance between corresponding target words, which means that his metric becomes a directional measure. Reorderings of alignments was also used by Genzel (2010), who used crossing score, the number of crossing links, to rank reordering rules. This is non-directional and simpler to calculate than Ahrenberg (2010)’s metrics, and implicitly covers length since a long distance reordering leads to a higher number of pairwise crossing links. Birch and Osborne (2011) suggest using squared Kendall τ distance (SKTD), see Eq. 8, where n is the number of links, as a basis of LR-score, an MT metric that takes reordering into account. They found that squaring τ better explained reordering, than using only τ . In this study we will use both, crossing score and SKT"
W14-3334,ahrenberg-etal-2000-evaluation,1,0.732969,"Missing"
W14-3334,P04-1064,0,0.0336358,"ents we use a gold standard that does not make use of distinctions between sure and possible links, as suggested by Fraser and Marcu (2007). With this, we can calculate the standard metrics P(recision) R(ecall) and F(-measure). We will mainly use balanced F-measure, but occasionally also report weighted F-measure. As noted before, 1−AER is equivalent to balanced F when only sure links are used, and will thus not be reported separately. Søgaard and Kuhn (2009) and Søgaard and Wu (2009) suggested working on the translation unit (TU) level, instead of the link level. A translation unit, or cept (Goutte et al., 2004), is defined as a maximally connected subgraph of an alignment. In Figure 1, the twelve links form nine translation units. Søgaard and Wu (2009) suggest the metric TUER, translation unit error rate, shown in Eq. 5, where AU are hypothesized translation units, and GU are gold standard translation units.1 They use TUER to establish lower bounds for the coverage of alignments from different formalisms, not to evaluate SMT. While they only use TUER, it (4) Ayan and Dorr (2006) on the other hand found some evidence for the importance of precision over recall. However, they used much smaller trainin"
W14-3334,ahrenberg-2010-alignment,0,0.150189,"nd Szał, 2012; Dyer et al., 2013). The relation between the two types of evaluation is often quite weak. Sev1 TUER is similar to CPER (Ayan and Dorr, 2006), which measures the error rate of extracted phrases. Due to how phrase extraction handle null links, there are differences, however. 277 is also possible to define Precision, Recall and Fmeasure over translation units in the same way as for alignment links. We will use these three measures to get a broader picture of TUs in alignment evaluation. Also in this case, 1−TUER is equivalent to F-measure. TUER(A, G) = 1 − 2|AU ∩ GU | |AU |+ |GU | Ahrenberg (2010) also proposed to measure reorderings. He does this by calculating the percentage of links with crossings of different lengths. To define this he only considers adjacent links in the source using the distance between corresponding target words, which means that his metric becomes a directional measure. Reorderings of alignments was also used by Genzel (2010), who used crossing score, the number of crossing links, to rank reordering rules. This is non-directional and simpler to calculate than Ahrenberg (2010)’s metrics, and implicitly covers length since a long distance reordering leads to a hi"
W14-3334,W09-0421,1,0.925521,"al., 2007) or parse trees (Xia and McCord, 2004). In general, all these approaches lead to improvements of translation quality. The reordering is Another type of approach to reordering is to only reorder the data in order to improve word alignments, and to restore the original word order before training the SMT system. This type of approach has the advantage that no modifications are needed for the translation input. This approach has also been used both with hand-written rules (Carpuat et al., 2010; Stymne et al., 2010) and with rules based on initial word alignments on non-reordered texts (Holmqvist et al., 2009). For the latter approach a small study of the effect of gd and gdfa symmetrizations was presented, which only showed small variations in quality scores (Holmqvist et al., 2012). Below we present the two tasks that we study in this paper: part-of-speech-based reordering for creating input lattices for SMT and alignmentbased reordering for improving phrase-tables. We evaluate the performance of these tasks in relation to the use of different alignment models and symmetrization heuristics. For these tasks we are mainly interested in the full translation task, for which we report Bleu scores. In"
W14-3334,P06-1002,0,0.0214734,"nd Wu (2009) suggested working on the translation unit (TU) level, instead of the link level. A translation unit, or cept (Goutte et al., 2004), is defined as a maximally connected subgraph of an alignment. In Figure 1, the twelve links form nine translation units. Søgaard and Wu (2009) suggest the metric TUER, translation unit error rate, shown in Eq. 5, where AU are hypothesized translation units, and GU are gold standard translation units.1 They use TUER to establish lower bounds for the coverage of alignments from different formalisms, not to evaluate SMT. While they only use TUER, it (4) Ayan and Dorr (2006) on the other hand found some evidence for the importance of precision over recall. However, they used much smaller training data than Fraser and Marcu (2007). They also suggested using a measure called consistent phrase error-rate (CPER), but found that it was hard to assess the impact of alignment on MT, both with AER and CPER. Lambert et al. (2012) performed a study where they investigated the effect of word alignment on MT using a large number of word alignment indicators. They found that there was a difference between large and small datasets in that alignment precision was more important"
W14-3334,holmqvist-etal-2012-alignment,1,0.91956,"ordering is to only reorder the data in order to improve word alignments, and to restore the original word order before training the SMT system. This type of approach has the advantage that no modifications are needed for the translation input. This approach has also been used both with hand-written rules (Carpuat et al., 2010; Stymne et al., 2010) and with rules based on initial word alignments on non-reordered texts (Holmqvist et al., 2009). For the latter approach a small study of the effect of gd and gdfa symmetrizations was presented, which only showed small variations in quality scores (Holmqvist et al., 2012). Below we present the two tasks that we study in this paper: part-of-speech-based reordering for creating input lattices for SMT and alignmentbased reordering for improving phrase-tables. We evaluate the performance of these tasks in relation to the use of different alignment models and symmetrization heuristics. For these tasks we are mainly interested in the full translation task, for which we report Bleu scores. In addition we also show fuzzy reordering score (FRS), which focuses 281 SMT, Bleu POSReo, FRS POSReo, Bleu AlignReo, FRS AlignReo, Bleu Total .33 −.80 −.64 −.77 −.81 SMT, Bleu POS"
W14-3334,P11-1103,0,0.0961479,"e does this by calculating the percentage of links with crossings of different lengths. To define this he only considers adjacent links in the source using the distance between corresponding target words, which means that his metric becomes a directional measure. Reorderings of alignments was also used by Genzel (2010), who used crossing score, the number of crossing links, to rank reordering rules. This is non-directional and simpler to calculate than Ahrenberg (2010)’s metrics, and implicitly covers length since a long distance reordering leads to a higher number of pairwise crossing links. Birch and Osborne (2011) suggest using squared Kendall τ distance (SKTD), see Eq. 8, where n is the number of links, as a basis of LR-score, an MT metric that takes reordering into account. They found that squaring τ better explained reordering, than using only τ . In this study we will use both, crossing score and SKTD. Figure 1 shows these scores for an example sentence. These two measures only tell us how much reordering there is. To quantify this relative to the gold standard we also report the absolute difference between the number of gold standard crossings and system crossings, which we call Crossdiff. To acco"
W14-3334,J93-2003,0,0.0624236,"A are hypothesized alignment links and G are gold standard links. Another common metric is alignment error rate (AER) (Och and Ney, 2000), which is based on a distinction between sure, S, and possible, P , links in the gold standard. 1−AER is identical to balanced F-measure when the gold standard does not make a distinction between S and P. Word Alignment and SMT Word alignment is the task of relating words in one language to words in the translation in another language, see an example in Figure 1. Word alignment models can be learnt automatically from large corpora of sentence aligned data. Brown et al. (1993) proposed the so-called IBM models, which are still widely used. These five models estimate alignments from corpora using the expectation-maximization algorithm, and each model adds some complexity. Model 4 is commonly used in SMT systems. There have been many later suggestions of alternatives to these models. These are often alternatives to model 2, such as the HMM model (Vogel et al., 1996) and fast align (Dyer et al., 2013). All these generative models produce directional alignments where one word in the source can be linked to many target words (1–m links) but not vice versa. It is general"
W14-3334,N03-1017,0,0.014538,"igned Table 1: Symmetrization strategies for word alignments AT S and AST in two directions these models require external tools (for creating linguistic features) and manually aligned training data, which we do not have for our data sets (besides the data we need for evaluation). Investigating these types of models are outside the scope of our current work. Word alignments are used as an important knowledge source for training SMT systems. In word-based SMT, the parameters of the generative word alignment models are essentially the translation model of the system. In phrase-based SMT (PBSMT) (Koehn et al., 2003), which is among the state-of-the-art systems today, word alignments are used as a basis for extracting phrases and estimating phrase alignment probabilities. Similarly, word alignments are also used for estimating rule probabilities in various kinds of hierarchical and syntactic SMT (Chiang, 2007; Yamada and Knight, 2002; Galley et al., 2004). Intrinsic evaluation of word alignment is generally based on a comparison to a gold standard of human alignments. Based on the gold standard, metrics like precision, recall and F-measure can be calculated for each alignment link, see Eqs. 1– 2, where A"
W14-3334,P10-2033,0,0.0155304,"on, such as part-of-speech tags (Rottmann and Vogel, 2007; Niehues and Kolss, 2009; Genzel, 2010), chunks (Zhang et al., 2007) or parse trees (Xia and McCord, 2004). In general, all these approaches lead to improvements of translation quality. The reordering is Another type of approach to reordering is to only reorder the data in order to improve word alignments, and to restore the original word order before training the SMT system. This type of approach has the advantage that no modifications are needed for the translation input. This approach has also been used both with hand-written rules (Carpuat et al., 2010; Stymne et al., 2010) and with rules based on initial word alignments on non-reordered texts (Holmqvist et al., 2009). For the latter approach a small study of the effect of gd and gdfa symmetrizations was presented, which only showed small variations in quality scores (Holmqvist et al., 2012). Below we present the two tasks that we study in this paper: part-of-speech-based reordering for creating input lattices for SMT and alignmentbased reordering for improving phrase-tables. We evaluate the performance of these tasks in relation to the use of different alignment models and symmetrization h"
W14-3334,2005.iwslt-1.8,0,0.177029,"e been many later suggestions of alternatives to these models. These are often alternatives to model 2, such as the HMM model (Vogel et al., 1996) and fast align (Dyer et al., 2013). All these generative models produce directional alignments where one word in the source can be linked to many target words (1–m links) but not vice versa. It is generally desirable to also allow n–1 and n–m links, and to achieve this it is common practice to perform word alignment in both directions and to symmetrize them using some heuristic. A number of common symmetrization strategies are described in Table 1 (Koehn et al., 2005). There are also other alternatives, such as the refined method (Och and Ney, 2003), or link deletion from the union (Fossum et al., 2008). There is also a wide range of alternative approaches to word alignment. For example, various discriminative models have been proposed in the literature (Liu et al., 2005; Moore, 2005; Taskar et al., 2005). Their advantage is that they may integrate a wide range of features that may lead to improved alignment quality. However, most of |G ∩ A| |A| |G ∩ A| Recall(A, G) = |G| |P ∩ A |+ |S ∩ A| AER = 1 − |S |+ |A| Precision(A, G) = 276 (1) (2) (3) Crossing p =8"
W14-3334,J07-2003,0,0.467625,"s of models are outside the scope of our current work. Word alignments are used as an important knowledge source for training SMT systems. In word-based SMT, the parameters of the generative word alignment models are essentially the translation model of the system. In phrase-based SMT (PBSMT) (Koehn et al., 2003), which is among the state-of-the-art systems today, word alignments are used as a basis for extracting phrases and estimating phrase alignment probabilities. Similarly, word alignments are also used for estimating rule probabilities in various kinds of hierarchical and syntactic SMT (Chiang, 2007; Yamada and Knight, 2002; Galley et al., 2004). Intrinsic evaluation of word alignment is generally based on a comparison to a gold standard of human alignments. Based on the gold standard, metrics like precision, recall and F-measure can be calculated for each alignment link, see Eqs. 1– 2, where A are hypothesized alignment links and G are gold standard links. Another common metric is alignment error rate (AER) (Och and Ney, 2000), which is based on a distinction between sure, S, and possible, P , links in the gold standard. 1−AER is identical to balanced F-measure when the gold standard do"
W14-3334,P05-1066,0,0.119492,"Missing"
W14-3334,P07-2045,0,0.0152871,"68 .370 .455 .514 .486 .392 .444 .500 .545 .524 .452 .445 .507 .548 .495 .450 .503 .537 .584 .525 .515 Link crossings P R F – – – 41060 31660 27245 12101 8122 29429 20671 17053 6718 4146 6718 4547 3044 12764 9779 8340 8277 8197 15829 11585 20099 17481 18934 22086 20439 Crossdiff 0 Table 2: Values for alignment quality indicators for the different alignments, where 2–4, HMM, and fa are alignment models, and symmetrization strategies refer to Table 1 Total 22629 Section 3.2) of 2M sentences during alignment. For symmetrization we used all methods in Table 1, as implemented in the Moses toolkit (Koehn et al., 2007) and in fast align (Dyer et al., 2013). Link level ↓ P R F Based on the automatically aligned gold standard, we calculated all alignment indicators for all settings. The complete results can be found in Table 2, where we have ordered the symmetrization methods with the most sparse, intersection, on top. Overall we can see that while several of the alignment methods create a much higher number of alignment links than the gold standard, they do not produce many more translation units. This is very interesting and indicates why link level statistics may not be accurate enough to predict the perfo"
W14-3334,N13-1073,0,0.516213,"words in the translation in another language, see an example in Figure 1. Word alignment models can be learnt automatically from large corpora of sentence aligned data. Brown et al. (1993) proposed the so-called IBM models, which are still widely used. These five models estimate alignments from corpora using the expectation-maximization algorithm, and each model adds some complexity. Model 4 is commonly used in SMT systems. There have been many later suggestions of alternatives to these models. These are often alternatives to model 2, such as the HMM model (Vogel et al., 1996) and fast align (Dyer et al., 2013). All these generative models produce directional alignments where one word in the source can be linked to many target words (1–m links) but not vice versa. It is generally desirable to also allow n–1 and n–m links, and to achieve this it is common practice to perform word alignment in both directions and to symmetrize them using some heuristic. A number of common symmetrization strategies are described in Table 1 (Koehn et al., 2005). There are also other alternatives, such as the refined method (Och and Ney, 2003), or link deletion from the union (Fossum et al., 2008). There is also a wide r"
W14-3334,W08-0306,0,0.0189954,"l., 1996) and fast align (Dyer et al., 2013). All these generative models produce directional alignments where one word in the source can be linked to many target words (1–m links) but not vice versa. It is generally desirable to also allow n–1 and n–m links, and to achieve this it is common practice to perform word alignment in both directions and to symmetrize them using some heuristic. A number of common symmetrization strategies are described in Table 1 (Koehn et al., 2005). There are also other alternatives, such as the refined method (Och and Ney, 2003), or link deletion from the union (Fossum et al., 2008). There is also a wide range of alternative approaches to word alignment. For example, various discriminative models have been proposed in the literature (Liu et al., 2005; Moore, 2005; Taskar et al., 2005). Their advantage is that they may integrate a wide range of features that may lead to improved alignment quality. However, most of |G ∩ A| |A| |G ∩ A| Recall(A, G) = |G| |P ∩ A |+ |S ∩ A| AER = 1 − |S |+ |A| Precision(A, G) = 276 (1) (2) (3) Crossing p =8 SKDT = 8/66 ≈ 0.65 6 1–1 links 3 multi links 0 null links Figure 1: An example alignment illustrating n–1, 1–m and crossing links. eral o"
W14-3334,D13-1049,0,0.0133298,"seline. These results confirm results from previous studies that link level measures, especially recall and weighted F-measure show some correlation with SMT quality whereas precision does not. 4 In the preordering studies cited above it is often not even stated which alignment model was used. A few authors mention the alignment tool that has been applied but no comparison between different alignment models is performed in any of the papers we are aware of. Li et al. (2007), for example, simply state that they used GIZA++ and gdf symmetrization and that they removed less probable multi links. Lerner and Petrov (2013) use the intersection of HMM alignments and claims that model 4 did not add much value. Genzel (2010) did mention that using a standard model 4 was not successful for his rule learning approach. Instead he used filtered model-1-alignments, which he claims was more successful. However, there are no further analyses or comparisons between the alignments reported in any of these papers. Reordering Tasks for SMT Reordering is an important part of any SMT system. One way to address it is to add reordering models to standard PBSMT systems, for instance lexicalized reordering models (Koehn et al., 20"
W14-3334,J07-3002,0,0.550421,"set of crossing links, like intersected HMM models, are preferred. Unlike SMT performance the desired alignment characteristics are similar for small and large training data for the pre-reordering tasks. Moreover, we confirm previous research showing that the fuzzy reordering score is a useful and cheap proxy for performance on SMT reordering tasks. 1 Introduction Word alignment is a key component in all state-ofthe-art statistical machine translation (SMT) systems, and there has been some work exploring the connection between word alignment quality and translation quality (Och and Ney, 2003; Fraser and Marcu, 2007; Lambert et al., 2012). The standard way to evaluate word alignments in this context is by using metrics like alignment error rate (AER) and F-measure on the link level, and the general conclusion appears to be that translation quality benefits from alignments with high recall (rather than precision), at least for large training data. Although many other ways of measuring alignment 275 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 275–286, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics Symmetrization int: intersection"
W14-3334,P07-1091,0,0.154673,"is a standard PBSMT system trained on WMT13 280 inter gd gdfa gdf union m2 18.1 20.4 20.4 19.4 19.2 m3 19.1 20.9 20.7 19.7 19.6 m4 19.3 20.9 20.8 20.1 19.8 HMM 18.8 20.5 20.5 19.9 19.7 fa 18.9 20.6 20.5 20.0 20.0 always applied on the translation input. It can also be applied on the source side of the training corpora, which sometimes improves the results (Rottmann and Vogel, 2007), but sometimes does not make a difference (Stymne, 2012). When preordering is performed on the translation input, it can be presented to the decoder as a 1-best reordering (Xia and McCord, 2004), as an n-best list (Li et al., 2007), or as a lattice of possible reorderings (Rottmann and Vogel, 2007; Zhang et al., 2007). Table 4: Baseline Bleu scores for different symmetrization heuristics suggesting that they measure similar things. Intuitively it seems important for SMT to match full translation units, but it might be the case that the phrase extraction strategy is robust as long as there are partial matches. There are no significant correlations with link degree or link crossings, except a negative correlation with Crossdiff, which means that it is good to have a similar number of crossings as the baseline. These resul"
W14-3334,N04-1035,0,0.0518221,"r current work. Word alignments are used as an important knowledge source for training SMT systems. In word-based SMT, the parameters of the generative word alignment models are essentially the translation model of the system. In phrase-based SMT (PBSMT) (Koehn et al., 2003), which is among the state-of-the-art systems today, word alignments are used as a basis for extracting phrases and estimating phrase alignment probabilities. Similarly, word alignments are also used for estimating rule probabilities in various kinds of hierarchical and syntactic SMT (Chiang, 2007; Yamada and Knight, 2002; Galley et al., 2004). Intrinsic evaluation of word alignment is generally based on a comparison to a gold standard of human alignments. Based on the gold standard, metrics like precision, recall and F-measure can be calculated for each alignment link, see Eqs. 1– 2, where A are hypothesized alignment links and G are gold standard links. Another common metric is alignment error rate (AER) (Och and Ney, 2000), which is based on a distinction between sure, S, and possible, P , links in the gold standard. 1−AER is identical to balanced F-measure when the gold standard does not make a distinction between S and P. Word"
W14-3334,P08-1112,0,0.0371481,"Missing"
W14-3334,N06-1014,0,0.0456501,"study where they investigated the effect of word alignment on MT using a large number of word alignment indicators. They found that there was a difference between large and small datasets in that alignment precision was more important with small data sets, and recall more important with large data sets. Overall they did not find any indicator that was significant over two language pairs and different corpus sizes. There were more significant indicators for large datasets, however. Most researchers who propose new alignment models perform both a gold standard evaluation and an SMT evaluation (Liang et al., 2006; Ganchev et al., 2008; Junczys-Dowmunt and Szał, 2012; Dyer et al., 2013). The relation between the two types of evaluation is often quite weak. Sev1 TUER is similar to CPER (Ayan and Dorr, 2006), which measures the error rate of extracted phrases. Due to how phrase extraction handle null links, there are differences, however. 277 is also possible to define Precision, Recall and Fmeasure over translation units in the same way as for alignment links. We will use these three measures to get a broader picture of TUs in alignment evaluation. Also in this case, 1−TUER is equivalent to F-measure. T"
W14-3334,W09-3805,0,0.0194029,"s the classic group where metrics are calculated on the alignment link level, which has been used in several studies. In our experiments we use a gold standard that does not make use of distinctions between sure and possible links, as suggested by Fraser and Marcu (2007). With this, we can calculate the standard metrics P(recision) R(ecall) and F(-measure). We will mainly use balanced F-measure, but occasionally also report weighted F-measure. As noted before, 1−AER is equivalent to balanced F when only sure links are used, and will thus not be reported separately. Søgaard and Kuhn (2009) and Søgaard and Wu (2009) suggested working on the translation unit (TU) level, instead of the link level. A translation unit, or cept (Goutte et al., 2004), is defined as a maximally connected subgraph of an alignment. In Figure 1, the twelve links form nine translation units. Søgaard and Wu (2009) suggest the metric TUER, translation unit error rate, shown in Eq. 5, where AU are hypothesized translation units, and GU are gold standard translation units.1 They use TUER to establish lower bounds for the coverage of alignments from different formalisms, not to evaluate SMT. While they only use TUER, it (4) Ayan and Dor"
W14-3334,P05-1057,0,0.0280805,"inks) but not vice versa. It is generally desirable to also allow n–1 and n–m links, and to achieve this it is common practice to perform word alignment in both directions and to symmetrize them using some heuristic. A number of common symmetrization strategies are described in Table 1 (Koehn et al., 2005). There are also other alternatives, such as the refined method (Och and Ney, 2003), or link deletion from the union (Fossum et al., 2008). There is also a wide range of alternative approaches to word alignment. For example, various discriminative models have been proposed in the literature (Liu et al., 2005; Moore, 2005; Taskar et al., 2005). Their advantage is that they may integrate a wide range of features that may lead to improved alignment quality. However, most of |G ∩ A| |A| |G ∩ A| Recall(A, G) = |G| |P ∩ A |+ |S ∩ A| AER = 1 − |S |+ |A| Precision(A, G) = 276 (1) (2) (3) Crossing p =8 SKDT = 8/66 ≈ 0.65 6 1–1 links 3 multi links 0 null links Figure 1: An example alignment illustrating n–1, 1–m and crossing links. eral of these studies only show AER on their gold standard, despite its well-known shortcomings. Even though many studies have shown some relation between translation quality an"
W14-3334,W07-2456,0,0.0307144,"T Reordering Tasks Sara Stymne J¨org Tiedemann Joakim Nivre Uppsala University Department of Linguistics and Philology firstname.lastname@lingfil.uu.se Abstract quality have been proposed, such as working on translation units (Ahrenberg et al., 2000; Ayan and Dorr, 2006; Søgaard and Kuhn, 2009) or using link degree and related measures (Ahrenberg, 2010), these methods have not been used to study the relation between alignment and translation quality, with the exception of Lambert et al. (2012). Word alignment is also used for many other tasks besides translation, including term bank creation (Merkel and Foo, 2007), cross-lingual annotation projection for part-of-speech tagging (Yarowsky et al., 2001), semantic roles (Pado and Lapata, 2005), pronoun anaphora (Postolache et al., 2006), and cross-lingual clustering (T¨ackstr¨om et al., 2012). Even within SMT itself, there are tasks such as reordering that often make crucial use of word alignments. For instance, source language reordering commonly relies on rules learnt automatically from word-aligned data (e.g., Xia and McCord (2004)). As far as we know, no one has studied the impact of alignment quality on these additional tasks, and it seems to be tacit"
W14-3334,W10-1727,1,0.858503,"eech tags (Rottmann and Vogel, 2007; Niehues and Kolss, 2009; Genzel, 2010), chunks (Zhang et al., 2007) or parse trees (Xia and McCord, 2004). In general, all these approaches lead to improvements of translation quality. The reordering is Another type of approach to reordering is to only reorder the data in order to improve word alignments, and to restore the original word order before training the SMT system. This type of approach has the advantage that no modifications are needed for the translation input. This approach has also been used both with hand-written rules (Carpuat et al., 2010; Stymne et al., 2010) and with rules based on initial word alignments on non-reordered texts (Holmqvist et al., 2009). For the latter approach a small study of the effect of gd and gdfa symmetrizations was presented, which only showed small variations in quality scores (Holmqvist et al., 2012). Below we present the two tasks that we study in this paper: part-of-speech-based reordering for creating input lattices for SMT and alignmentbased reordering for improving phrase-tables. We evaluate the performance of these tasks in relation to the use of different alignment models and symmetrization heuristics. For these t"
W14-3334,H05-1011,0,0.0350232,"versa. It is generally desirable to also allow n–1 and n–m links, and to achieve this it is common practice to perform word alignment in both directions and to symmetrize them using some heuristic. A number of common symmetrization strategies are described in Table 1 (Koehn et al., 2005). There are also other alternatives, such as the refined method (Och and Ney, 2003), or link deletion from the union (Fossum et al., 2008). There is also a wide range of alternative approaches to word alignment. For example, various discriminative models have been proposed in the literature (Liu et al., 2005; Moore, 2005; Taskar et al., 2005). Their advantage is that they may integrate a wide range of features that may lead to improved alignment quality. However, most of |G ∩ A| |A| |G ∩ A| Recall(A, G) = |G| |P ∩ A |+ |S ∩ A| AER = 1 − |S |+ |A| Precision(A, G) = 276 (1) (2) (3) Crossing p =8 SKDT = 8/66 ≈ 0.65 6 1–1 links 3 multi links 0 null links Figure 1: An example alignment illustrating n–1, 1–m and crossing links. eral of these studies only show AER on their gold standard, despite its well-known shortcomings. Even though many studies have shown some relation between translation quality and AER or weig"
W14-3334,W09-0435,0,0.31843,"part of the evaluation of MT systems (Birch and Osborne, 2011). We can distinguish two main types of approaches to preordering in SMT, either by using hand-written rules, which often operate on syntactic trees (Collins et al., 2005), or by reordering rules that are learnt automatically based on a word aligned corpus (Xia and McCord, 2004). The latter approach is of interest to us, since it is based on word alignments. There has been much work on automatic learning of reordering rules, which can be based on different levels of annotation, such as part-of-speech tags (Rottmann and Vogel, 2007; Niehues and Kolss, 2009; Genzel, 2010), chunks (Zhang et al., 2007) or parse trees (Xia and McCord, 2004). In general, all these approaches lead to improvements of translation quality. The reordering is Another type of approach to reordering is to only reorder the data in order to improve word alignments, and to restore the original word order before training the SMT system. This type of approach has the advantage that no modifications are needed for the translation input. This approach has also been used both with hand-written rules (Carpuat et al., 2010; Stymne et al., 2010) and with rules based on initial word al"
W14-3334,W12-0704,1,0.823036,"somewhat, the correlations with alignment indicators were stable. SMT Experiments For reference, we first study the impact of alignment on SMT performance. Our SMT system is a standard PBSMT system trained on WMT13 280 inter gd gdfa gdf union m2 18.1 20.4 20.4 19.4 19.2 m3 19.1 20.9 20.7 19.7 19.6 m4 19.3 20.9 20.8 20.1 19.8 HMM 18.8 20.5 20.5 19.9 19.7 fa 18.9 20.6 20.5 20.0 20.0 always applied on the translation input. It can also be applied on the source side of the training corpora, which sometimes improves the results (Rottmann and Vogel, 2007), but sometimes does not make a difference (Stymne, 2012). When preordering is performed on the translation input, it can be presented to the decoder as a 1-best reordering (Xia and McCord, 2004), as an n-best list (Li et al., 2007), or as a lattice of possible reorderings (Rottmann and Vogel, 2007; Zhang et al., 2007). Table 4: Baseline Bleu scores for different symmetrization heuristics suggesting that they measure similar things. Intuitively it seems important for SMT to match full translation units, but it might be the case that the phrase extraction strategy is robust as long as there are partial matches. There are no significant correlations w"
W14-3334,C00-2163,0,0.19044,"stimating phrase alignment probabilities. Similarly, word alignments are also used for estimating rule probabilities in various kinds of hierarchical and syntactic SMT (Chiang, 2007; Yamada and Knight, 2002; Galley et al., 2004). Intrinsic evaluation of word alignment is generally based on a comparison to a gold standard of human alignments. Based on the gold standard, metrics like precision, recall and F-measure can be calculated for each alignment link, see Eqs. 1– 2, where A are hypothesized alignment links and G are gold standard links. Another common metric is alignment error rate (AER) (Och and Ney, 2000), which is based on a distinction between sure, S, and possible, P , links in the gold standard. 1−AER is identical to balanced F-measure when the gold standard does not make a distinction between S and P. Word Alignment and SMT Word alignment is the task of relating words in one language to words in the translation in another language, see an example in Figure 1. Word alignment models can be learnt automatically from large corpora of sentence aligned data. Brown et al. (1993) proposed the so-called IBM models, which are still widely used. These five models estimate alignments from corpora usi"
W14-3334,N12-1052,0,0.053597,"Missing"
W14-3334,J03-1002,0,0.198899,"its, and on the subset of crossing links, like intersected HMM models, are preferred. Unlike SMT performance the desired alignment characteristics are similar for small and large training data for the pre-reordering tasks. Moreover, we confirm previous research showing that the fuzzy reordering score is a useful and cheap proxy for performance on SMT reordering tasks. 1 Introduction Word alignment is a key component in all state-ofthe-art statistical machine translation (SMT) systems, and there has been some work exploring the connection between word alignment quality and translation quality (Och and Ney, 2003; Fraser and Marcu, 2007; Lambert et al., 2012). The standard way to evaluate word alignments in this context is by using metrics like alignment error rate (AER) and F-measure on the link level, and the general conclusion appears to be that translation quality benefits from alignments with high recall (rather than precision), at least for large training data. Although many other ways of measuring alignment 275 Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 275–286, c Baltimore, Maryland USA, June 26–27, 2014. 2014 Association for Computational Linguistics Symmetriz"
W14-3334,W11-2102,0,0.112784,"−.57 .83 −.79 Total .65 −.23 .05 −.11 −.24 Total −.05 −.81 −.71 −.80 −.93 Translation units P R F −.20 .16 −.02 .90 .81 .89 .80 .80 .86 .90 .88 .92 .75 .64 .72 SKTD −.14 −.70 −.60 −.73 −.91 Link crossings P R −.09 .25 .90 .21 .79 .42 .94 .27 .86 −.07 P −.29 .82 .67 .81 .71 F .07 .86 .89 .92 .69 MWU R .59 −.45 −.23 −.37 −.53 F .44 .22 .35 .31 .04 Crossdiff −.63 −.41 −.49 −.38 −.52 Table 5: Pearson correlations between different alignment characteristics and scores for the translation and reordering tasks. Significant correlations are marked with bold (< 0.01). only on the reordering component (Talbot et al., 2011). It compares a system reordering to a reference reordering, by measuring how many chunks that have to be moved to get an identical word order, see Eq. 9, where C is the number of contiguously aligned chunks, and M the number of words. To find the reference ordering we apply the method of Holmqvist et al. (2009), described in Section 4.2, to the gold standard alignment. FRS = 1 − 4.1 C −1 M −1 inter gd gdfa gdf union m2 .577 .555 .540 .439 .442 m3 .575 .559 .540 .499 .492 m4 .581 .570 .559 .542 .544 HMM .596 .589 .579 .560 .563 fa .567 .546 .539 .495 .486 Table 6: Fuzzy reordering scores for p"
W14-3334,W99-0604,0,0.161786,"shown some relation between translation quality and AER or weighted F-measure, it has rarely been investigated thoroughly in its own right, and, as far as we are aware, not for other tasks than SMT. Furthermore, most of these studies considers nothing else but link level agreement. In this paper we take a broader view on alignment quality and explore the effect of other types of quality indicators as well. The relation between word alignment quality and PBSMT has been studied by some researchers. Och and Ney (2000) looked at the impact of IBM and HMM models on the alignment template approach (Och et al., 1999) in terms of AER. They found that AER correlates with human evaluation of sentence level quality, but not with word error rate. Fraser and Marcu (2007) found that there is no correlation between AER and Bleu (Papineni et al., 2002), especially not when the P set is large. They found that a balanced F-measure is a better indicator of Bleu, but that a weighted F-measure is even better (see Eq. 4) mostly with a higher weight for recall than for precision. This weight, however, needs to be optimized for each data set, language pair, and gold standard alignment separately. F(A, G, α) =  α 1−α + Pr"
W14-3334,H05-1010,0,0.0390747,"generally desirable to also allow n–1 and n–m links, and to achieve this it is common practice to perform word alignment in both directions and to symmetrize them using some heuristic. A number of common symmetrization strategies are described in Table 1 (Koehn et al., 2005). There are also other alternatives, such as the refined method (Och and Ney, 2003), or link deletion from the union (Fossum et al., 2008). There is also a wide range of alternative approaches to word alignment. For example, various discriminative models have been proposed in the literature (Liu et al., 2005; Moore, 2005; Taskar et al., 2005). Their advantage is that they may integrate a wide range of features that may lead to improved alignment quality. However, most of |G ∩ A| |A| |G ∩ A| Recall(A, G) = |G| |P ∩ A |+ |S ∩ A| AER = 1 − |S |+ |A| Precision(A, G) = 276 (1) (2) (3) Crossing p =8 SKDT = 8/66 ≈ 0.65 6 1–1 links 3 multi links 0 null links Figure 1: An example alignment illustrating n–1, 1–m and crossing links. eral of these studies only show AER on their gold standard, despite its well-known shortcomings. Even though many studies have shown some relation between translation quality and AER or weighted F-measure, it has"
W14-3334,P03-1021,0,0.0838948,"on translation unit level. Significant correlations are marked with bold (< 0.01). data.2 We trained a German–English system on 2M sentences from Europarl and News Commentary. We used the target side of the parallel corpus and the SRILM toolkit (Stolcke, 2002) to train a 5gram language model. For training the translation model and for decoding we used the Moses toolkit (Koehn et al., 2007). We applied a standard feature set consisting of a language model feature, four translation model features, word penalty, phrase penalty, and distortion cost. For tuning we used minimum error-rate training (Och, 2003). In order to minimize the risk of tuning influencing the results, we used a fixed set of weights for each experiment, tuned on a model 4+gdfa alignment.3 For tuning we used newstest2009 with 2525 sentences, and for testing we used newstest2013 with 3000 sentences. Evaluation was performed using the Bleu metric (Papineni et al., 2002). The same system setup was used for the SMT systems with reordering. Table 4 shows the results on the SMT task. Model 3 and 4 with gd/gdfa symmetrization yield the highest scores. There is a larger difference between systems with different symmetrization than bet"
W14-3334,H05-1108,0,0.469573,"e.lastname@lingfil.uu.se Abstract quality have been proposed, such as working on translation units (Ahrenberg et al., 2000; Ayan and Dorr, 2006; Søgaard and Kuhn, 2009) or using link degree and related measures (Ahrenberg, 2010), these methods have not been used to study the relation between alignment and translation quality, with the exception of Lambert et al. (2012). Word alignment is also used for many other tasks besides translation, including term bank creation (Merkel and Foo, 2007), cross-lingual annotation projection for part-of-speech tagging (Yarowsky et al., 2001), semantic roles (Pado and Lapata, 2005), pronoun anaphora (Postolache et al., 2006), and cross-lingual clustering (T¨ackstr¨om et al., 2012). Even within SMT itself, there are tasks such as reordering that often make crucial use of word alignments. For instance, source language reordering commonly relies on rules learnt automatically from word-aligned data (e.g., Xia and McCord (2004)). As far as we know, no one has studied the impact of alignment quality on these additional tasks, and it seems to be tacitly assumed that alignments that are good for translation are also good for other tasks. In this paper we set out to explore the"
W14-3334,C96-2141,0,0.612207,"f relating words in one language to words in the translation in another language, see an example in Figure 1. Word alignment models can be learnt automatically from large corpora of sentence aligned data. Brown et al. (1993) proposed the so-called IBM models, which are still widely used. These five models estimate alignments from corpora using the expectation-maximization algorithm, and each model adds some complexity. Model 4 is commonly used in SMT systems. There have been many later suggestions of alternatives to these models. These are often alternatives to model 2, such as the HMM model (Vogel et al., 1996) and fast align (Dyer et al., 2013). All these generative models produce directional alignments where one word in the source can be linked to many target words (1–m links) but not vice versa. It is generally desirable to also allow n–1 and n–m links, and to achieve this it is common practice to perform word alignment in both directions and to symmetrize them using some heuristic. A number of common symmetrization strategies are described in Table 1 (Koehn et al., 2005). There are also other alternatives, such as the refined method (Och and Ney, 2003), or link deletion from the union (Fossum et"
W14-3334,P02-1040,0,0.0905907,"studies considers nothing else but link level agreement. In this paper we take a broader view on alignment quality and explore the effect of other types of quality indicators as well. The relation between word alignment quality and PBSMT has been studied by some researchers. Och and Ney (2000) looked at the impact of IBM and HMM models on the alignment template approach (Och et al., 1999) in terms of AER. They found that AER correlates with human evaluation of sentence level quality, but not with word error rate. Fraser and Marcu (2007) found that there is no correlation between AER and Bleu (Papineni et al., 2002), especially not when the P set is large. They found that a balanced F-measure is a better indicator of Bleu, but that a weighted F-measure is even better (see Eq. 4) mostly with a higher weight for recall than for precision. This weight, however, needs to be optimized for each data set, language pair, and gold standard alignment separately. F(A, G, α) =  α 1−α + Precision(A,G) Recall(A,G) −1 3 Word Alignment Quality Indicators We investigate four groups of quality indicators. The first group is the classic group where metrics are calculated on the alignment link level, which has been used i"
W14-3334,C04-1073,0,0.545815,"Lambert et al. (2012). Word alignment is also used for many other tasks besides translation, including term bank creation (Merkel and Foo, 2007), cross-lingual annotation projection for part-of-speech tagging (Yarowsky et al., 2001), semantic roles (Pado and Lapata, 2005), pronoun anaphora (Postolache et al., 2006), and cross-lingual clustering (T¨ackstr¨om et al., 2012). Even within SMT itself, there are tasks such as reordering that often make crucial use of word alignments. For instance, source language reordering commonly relies on rules learnt automatically from word-aligned data (e.g., Xia and McCord (2004)). As far as we know, no one has studied the impact of alignment quality on these additional tasks, and it seems to be tacitly assumed that alignments that are good for translation are also good for other tasks. In this paper we set out to explore the impact of alignment quality on two pre-reordering tasks for SMT. In doing so, we employ a wider range of quality indicators than is customary, and for reference these indicators are used also to assess overall translation quality. To allow an in-depth exploration of the connections between several aspects of word alignment and reordering, we limi"
W14-3334,postolache-etal-2006-transferring,0,0.0614037,"Missing"
W14-3334,P02-1039,0,0.321492,"e outside the scope of our current work. Word alignments are used as an important knowledge source for training SMT systems. In word-based SMT, the parameters of the generative word alignment models are essentially the translation model of the system. In phrase-based SMT (PBSMT) (Koehn et al., 2003), which is among the state-of-the-art systems today, word alignments are used as a basis for extracting phrases and estimating phrase alignment probabilities. Similarly, word alignments are also used for estimating rule probabilities in various kinds of hierarchical and syntactic SMT (Chiang, 2007; Yamada and Knight, 2002; Galley et al., 2004). Intrinsic evaluation of word alignment is generally based on a comparison to a gold standard of human alignments. Based on the gold standard, metrics like precision, recall and F-measure can be calculated for each alignment link, see Eqs. 1– 2, where A are hypothesized alignment links and G are gold standard links. Another common metric is alignment error rate (AER) (Och and Ney, 2000), which is based on a distinction between sure, S, and possible, P , links in the gold standard. 1−AER is identical to balanced F-measure when the gold standard does not make a distinction"
W14-3334,2007.tmi-papers.21,0,0.619227,"eparate tunings for each alignment. While the absolute results varied somewhat, the correlations with alignment indicators were stable. SMT Experiments For reference, we first study the impact of alignment on SMT performance. Our SMT system is a standard PBSMT system trained on WMT13 280 inter gd gdfa gdf union m2 18.1 20.4 20.4 19.4 19.2 m3 19.1 20.9 20.7 19.7 19.6 m4 19.3 20.9 20.8 20.1 19.8 HMM 18.8 20.5 20.5 19.9 19.7 fa 18.9 20.6 20.5 20.0 20.0 always applied on the translation input. It can also be applied on the source side of the training corpora, which sometimes improves the results (Rottmann and Vogel, 2007), but sometimes does not make a difference (Stymne, 2012). When preordering is performed on the translation input, it can be presented to the decoder as a 1-best reordering (Xia and McCord, 2004), as an n-best list (Li et al., 2007), or as a lattice of possible reorderings (Rottmann and Vogel, 2007; Zhang et al., 2007). Table 4: Baseline Bleu scores for different symmetrization heuristics suggesting that they measure similar things. Intuitively it seems important for SMT to match full translation units, but it might be the case that the phrase extraction strategy is robust as long as there are"
W14-3334,H01-1035,0,0.0602033,"nt of Linguistics and Philology firstname.lastname@lingfil.uu.se Abstract quality have been proposed, such as working on translation units (Ahrenberg et al., 2000; Ayan and Dorr, 2006; Søgaard and Kuhn, 2009) or using link degree and related measures (Ahrenberg, 2010), these methods have not been used to study the relation between alignment and translation quality, with the exception of Lambert et al. (2012). Word alignment is also used for many other tasks besides translation, including term bank creation (Merkel and Foo, 2007), cross-lingual annotation projection for part-of-speech tagging (Yarowsky et al., 2001), semantic roles (Pado and Lapata, 2005), pronoun anaphora (Postolache et al., 2006), and cross-lingual clustering (T¨ackstr¨om et al., 2012). Even within SMT itself, there are tasks such as reordering that often make crucial use of word alignments. For instance, source language reordering commonly relies on rules learnt automatically from word-aligned data (e.g., Xia and McCord (2004)). As far as we know, no one has studied the impact of alignment quality on these additional tasks, and it seems to be tacitly assumed that alignments that are good for translation are also good for other tasks."
W14-3334,W09-2303,0,0.023373,"ndicators. The first group is the classic group where metrics are calculated on the alignment link level, which has been used in several studies. In our experiments we use a gold standard that does not make use of distinctions between sure and possible links, as suggested by Fraser and Marcu (2007). With this, we can calculate the standard metrics P(recision) R(ecall) and F(-measure). We will mainly use balanced F-measure, but occasionally also report weighted F-measure. As noted before, 1−AER is equivalent to balanced F when only sure links are used, and will thus not be reported separately. Søgaard and Kuhn (2009) and Søgaard and Wu (2009) suggested working on the translation unit (TU) level, instead of the link level. A translation unit, or cept (Goutte et al., 2004), is defined as a maximally connected subgraph of an alignment. In Figure 1, the twelve links form nine translation units. Søgaard and Wu (2009) suggest the metric TUER, translation unit error rate, shown in Eq. 5, where AU are hypothesized translation units, and GU are gold standard translation units.1 They use TUER to establish lower bounds for the coverage of alignments from different formalisms, not to evaluate SMT. While they only use"
W14-3334,2007.iwslt-1.3,0,0.141624,"20.4 19.4 19.2 m3 19.1 20.9 20.7 19.7 19.6 m4 19.3 20.9 20.8 20.1 19.8 HMM 18.8 20.5 20.5 19.9 19.7 fa 18.9 20.6 20.5 20.0 20.0 always applied on the translation input. It can also be applied on the source side of the training corpora, which sometimes improves the results (Rottmann and Vogel, 2007), but sometimes does not make a difference (Stymne, 2012). When preordering is performed on the translation input, it can be presented to the decoder as a 1-best reordering (Xia and McCord, 2004), as an n-best list (Li et al., 2007), or as a lattice of possible reorderings (Rottmann and Vogel, 2007; Zhang et al., 2007). Table 4: Baseline Bleu scores for different symmetrization heuristics suggesting that they measure similar things. Intuitively it seems important for SMT to match full translation units, but it might be the case that the phrase extraction strategy is robust as long as there are partial matches. There are no significant correlations with link degree or link crossings, except a negative correlation with Crossdiff, which means that it is good to have a similar number of crossings as the baseline. These results confirm results from previous studies that link level measures, especially recall and"
W15-0703,W13-1401,0,0.0146892,"he tool becomes a real help for the human because it selects interesting cases of repetitions and leaves it to the human to evaluate unclear cases. A serious bottleneck in the creation of a system for ranking chiasmus candidates is the lack of annotated data. Chiasmus is not a frequent rhetorical figure. Such rareness is the first reason why there is no huge corpus of annotated chiasmi. It would require annotators to read millions of words in order to arrive at a decent sample. Another difficulty comes from the requirement for qualified annotators when it comes to literature-specific devices. Hammond et al. (2013), for example, do not rely on crowd sourcing when it comes to annotating changing voices. They use first year literature students. Annotating chiasmi is likely to require the same kind of annotators which are not the most easy to hire on crowdsourcing platforms. If we want to create annotations we have to face the following problem: most of the inversions made in natural language are not chiasmi (see the example of River War, Section 2). Thus, the annotation of every inversion in a corpus would be a massive, repetitive and expensive task for human annotators. This also explains why there is no"
W15-0703,R11-2013,0,0.153574,"or the number of words. We can expect that a too long distance between main terms or a huge size difference between clauses is an easy-to-compute false positive characteristic as in this false positive: (15) It is strange that other committees can apparently acquire secretariats and wellequipped secretariats with many staff, but that this is not possible for the Women’ s Committee. In 15, indeed, the too long distance between ‘secretariats’ and ‘Committee’ in the second clause breaks the axial symmetry prescribed by Morier (1961, p.113) The third category of features follows the intuition of Hromada (2011) when he looks for three pairs of Setting the Weights As observed in Section 3, there is no existing set of annotated data. This excludes traditional supervised machine learning to set the weights. So, we proceeded empirically, by observation of our successive results on our tuning set. We make available on the web the results of our trainings. 5 Experiments Corpus We perform experiments on English. We choose a corpus of politics often used in NLP: Europarl.2 From this corpus, we take two extracts of two million words each. One is used as a tuning corpus to test our hypotheses on weigths and f"
W15-0904,W11-1304,0,0.0899407,"Spearman Coefficient Correlation. The number of instances in their final data set, however, might not be enough for evaluation purposes. Moreover, it might not be a trivial task to adapt an identification/extraction system to produce a similar non-compositionality ranking. Korkontzelos and Manandhar (2009) present a data set that comprises 19 non-compositional and 19 compositional instances. In this work the size of the data set is small and compound selection process and the rationale behind decisions about non-compositionality is not expounded. Other related but slightly different works are Biemann and Giesbrecht (2011) who present a set of adjective-noun, verb-subject, and verb-object pairs and their non- compositionality judgments, and McCarthy et al. (2003) who present a set of 116 phrasal verbs and rank their noncompositionality between 0 and 9. Data sets that incorporate conventionalization are rather difficult to come by. The closest are collocation sets which are also scarce in their own right. Most collocation sets that we could find were either commercial or not publicly available. Moreover, since collocation can refer to a wide range of MWEs and human agreement on statistical idiosyncrasy is not hi"
W15-0904,S12-1021,0,0.127999,"t of 1048 noun-noun compounds annotated as non-compositional, compositional, conventionalized and not conventionalized. We build this data set following common trends in previous work while trying to address some of the well known issues such as small number of annotated instances, quality of the annotations, and lack of availability of true negative instances. 1 Joakim Nivre Uppsala University Uppsala, Sweden Introduction The lack of practical data sets that can be used in the training and evaluation of multiword expression (MWE) related systems is a notorious problem (McCarthy et al., 2003; Hermann et al., 2012). It is partly due to the heterogeneous nature of MWEs, partly due to their frequency, and partly due to the unclear boundaries between MWEs and regular phrases. These issues have made the compilation of useful MWE data sets challenging, and any effort to create them invaluable. In this work we present a data set of two-word English noun-noun compounds which are annotated for two properties: non-compositionality and conventionalization. Although non-compositionality Conventionalization meanwhile refers to the situation where a sequence of words that refer to a particular concept is commonly ac"
W15-0904,P09-2017,0,0.0175593,"instances compared to related data sets. 2 Related work The most important related work is that of Reddy et al. (2011), which provides 90 compounds with a mean compositionality score between 0 and 5. They acquired their annotations using Amazon Mechanical Turk from 30 turkers. They detect and discard poor annotations using Spearman Coefficient Correlation. The number of instances in their final data set, however, might not be enough for evaluation purposes. Moreover, it might not be a trivial task to adapt an identification/extraction system to produce a similar non-compositionality ranking. Korkontzelos and Manandhar (2009) present a data set that comprises 19 non-compositional and 19 compositional instances. In this work the size of the data set is small and compound selection process and the rationale behind decisions about non-compositionality is not expounded. Other related but slightly different works are Biemann and Giesbrecht (2011) who present a set of adjective-noun, verb-subject, and verb-object pairs and their non- compositionality judgments, and McCarthy et al. (2003) who present a set of 116 phrasal verbs and rank their noncompositionality between 0 and 9. Data sets that incorporate conventionalizat"
W15-0904,W03-1810,0,0.907806,"asures. We present a set of 1048 noun-noun compounds annotated as non-compositional, compositional, conventionalized and not conventionalized. We build this data set following common trends in previous work while trying to address some of the well known issues such as small number of annotated instances, quality of the annotations, and lack of availability of true negative instances. 1 Joakim Nivre Uppsala University Uppsala, Sweden Introduction The lack of practical data sets that can be used in the training and evaluation of multiword expression (MWE) related systems is a notorious problem (McCarthy et al., 2003; Hermann et al., 2012). It is partly due to the heterogeneous nature of MWEs, partly due to their frequency, and partly due to the unclear boundaries between MWEs and regular phrases. These issues have made the compilation of useful MWE data sets challenging, and any effort to create them invaluable. In this work we present a data set of two-word English noun-noun compounds which are annotated for two properties: non-compositionality and conventionalization. Although non-compositionality Conventionalization meanwhile refers to the situation where a sequence of words that refer to a particular"
W15-0904,I11-1024,0,0.759738,"e: whether or not a compound should be lexicalized due to its non-compositionality. The main contributions of this work can be described as follows: coverage for two major properties of MWEs (non-compositionality and conventionalization); providing both positive and negative instances of non-compositional and conventionalized classes, allowing the evaluation of MWE identification/extraction systems in terms of both true positive and true negative rates; incorporating a larger number of annotated instances compared to related data sets. 2 Related work The most important related work is that of Reddy et al. (2011), which provides 90 compounds with a mean compositionality score between 0 and 5. They acquired their annotations using Amazon Mechanical Turk from 30 turkers. They detect and discard poor annotations using Spearman Coefficient Correlation. The number of instances in their final data set, however, might not be enough for evaluation purposes. Moreover, it might not be a trivial task to adapt an identification/extraction system to produce a similar non-compositionality ranking. Korkontzelos and Manandhar (2009) present a data set that comprises 19 non-compositional and 19 compositional instances"
W15-0904,schneider-etal-2014-comprehensive,0,0.0195629,"t collocation sets that we could find were either commercial or not publicly available. Moreover, since collocation can refer to a wide range of MWEs and human agreement on statistical idiosyncrasy is not high enough, it is hard to find an annotated collocation set. Instead, extraction systems have been used to automatically produce such sets 30 and the outcomes have been commonly evaluated by either manual evaluation (Smadja, 1993), or by ranking the collocation candidates and calculating precision and recall of the extraction system for the set of n highest ranking candidates (Evert, 2005). Schneider et al. (2014) is another related work in which generic MWEs are annotated in a 55Kword English web corpus. Their work covers a broad range of “multiword phenomena” with emphasis on heterogeneity, gappy grouping and expression strength which represents the level of idiomaticity of a MWE. They build a corpus of MWEs without restricting themselves to any syntactic categories and they argue that this can to some extent address the problem of heterogeneity of MWEs. 3 Data Preparation We downloaded English Wikipedia, removed the tags and segmented it into sentences. We then filtered very short and very long sent"
W15-0904,J93-1007,0,0.314006,"y between 0 and 9. Data sets that incorporate conventionalization are rather difficult to come by. The closest are collocation sets which are also scarce in their own right. Most collocation sets that we could find were either commercial or not publicly available. Moreover, since collocation can refer to a wide range of MWEs and human agreement on statistical idiosyncrasy is not high enough, it is hard to find an annotated collocation set. Instead, extraction systems have been used to automatically produce such sets 30 and the outcomes have been commonly evaluated by either manual evaluation (Smadja, 1993), or by ranking the collocation candidates and calculating precision and recall of the extraction system for the set of n highest ranking candidates (Evert, 2005). Schneider et al. (2014) is another related work in which generic MWEs are annotated in a 55Kword English web corpus. Their work covers a broad range of “multiword phenomena” with emphasis on heterogeneity, gappy grouping and expression strength which represents the level of idiomaticity of a MWE. They build a corpus of MWEs without restricting themselves to any syntactic categories and they argue that this can to some extent address"
W15-0905,J90-1003,0,0.515692,"e proportion of MWE and non-MWE instances. An overview of the data set is presented in Table 1. Set original set dev. set test set examples MWE 262 174 88 gold rush, role model, family tree, city center, bow saw, life cycle non-MWE 262 174 88 chess talent, bus types, attack damage, player skill, oil storage, lobby area Table 1: Dataset statistics. 4.2 Evaluation We implement the following two baselines: (1) Multinomial likelihood (Evert, 2005), which calculates the probability of the observed contingency table for a given pair under the null hypothesis of independence. (2) Mutual information (Church and Hanks, 1990), which calculates the mutual dependency of words of a co-occurrence, and has been proved efficient in identification and extraction of MWEs (Pecina, 2010; Evert, 2005). With respect to the range of scores, we set and alter a threshold for multinomial likelihood (M.N.L hereafter) and mutual information (M.I. hereafter). Pairs that obtain a score above the threshold are considered MWE, and pairs that obtain a score below the threshold are considered non-MWE. Figure 1 illustrates the precisionrecall curve for our models and the baselines on the development set. 0.9 0.8 0.7 F1 score 0.6 0.5 0.4 0"
W15-0905,W03-1806,0,0.119161,"Missing"
W15-0905,W14-0802,1,0.801572,"y researched from different perspectives. Various models from rule-based to statistical have been employed to address this problem. Examples of rule-based models are Seretan (2011) and Jacquemin et al. (1997) who base their extraction on linguistic rules and formalism in order to identify and filter MWE candidates, and Baldwin (2005) who aims at extracting verb particle constructions based on their linguistic properties using a chunker and dependency grammar. Examples of statistical models are Pecina (2010), Evert (2005), Lapata and Lascarides (2003), and the early work Xtract (Smadja, 1993). Farahmand and Martins (2014) present a method of extracting MWEs based on their statistical contextual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and use it as a way of identifying lexicalized compounds. There are also hybrid models in the sense that they benefit from both statistical and linguistic information (Seretan and Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There are also bilingual models which are mostly based on the assumption that"
W15-0905,S12-1021,0,0.100959,"this problem. Examples of rule-based models are Seretan (2011) and Jacquemin et al. (1997) who base their extraction on linguistic rules and formalism in order to identify and filter MWE candidates, and Baldwin (2005) who aims at extracting verb particle constructions based on their linguistic properties using a chunker and dependency grammar. Examples of statistical models are Pecina (2010), Evert (2005), Lapata and Lascarides (2003), and the early work Xtract (Smadja, 1993). Farahmand and Martins (2014) present a method of extracting MWEs based on their statistical contextual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and use it as a way of identifying lexicalized compounds. There are also hybrid models in the sense that they benefit from both statistical and linguistic information (Seretan and Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There are also bilingual models which are mostly based on the assumption that a translation of a source language MWE exists in a target language (Smith, 2014; Caseli et al., 2010; Ren et a"
W15-0905,P97-1004,0,0.0448191,"rds collocational weight has never been explicitly and empirically tested. In this work, we present two models that partially, and fully, model collocational weight, and investigate its effects on extraction of MWEs. 3 2 Simplified Hypothesis For a given two-word compound, the head word is more likely to co-occur with the modifier than with synonyms of the modifier. Related work Extraction of MWEs has been widely researched from different perspectives. Various models from rule-based to statistical have been employed to address this problem. Examples of rule-based models are Seretan (2011) and Jacquemin et al. (1997) who base their extraction on linguistic rules and formalism in order to identify and filter MWE candidates, and Baldwin (2005) who aims at extracting verb particle constructions based on their linguistic properties using a chunker and dependency grammar. Examples of statistical models are Pecina (2010), Evert (2005), Lapata and Lascarides (2003), and the early work Xtract (Smadja, 1993). Farahmand and Martins (2014) present a method of extracting MWEs based on their statistical contextual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and us"
W15-0905,E03-1073,0,0.0528022,"synonyms of the modifier. Related work Extraction of MWEs has been widely researched from different perspectives. Various models from rule-based to statistical have been employed to address this problem. Examples of rule-based models are Seretan (2011) and Jacquemin et al. (1997) who base their extraction on linguistic rules and formalism in order to identify and filter MWE candidates, and Baldwin (2005) who aims at extracting verb particle constructions based on their linguistic properties using a chunker and dependency grammar. Examples of statistical models are Pecina (2010), Evert (2005), Lapata and Lascarides (2003), and the early work Xtract (Smadja, 1993). Farahmand and Martins (2014) present a method of extracting MWEs based on their statistical contextual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and use it as a way of identifying lexicalized compounds. There are also hybrid models in the sense that they benefit from both statistical and linguistic information (Seretan and Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There"
W15-0905,W08-2107,0,0.0268133,"Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There are also bilingual models which are mostly based on the assumption that a translation of a source language MWE exists in a target language (Smith, 2014; Caseli et al., 2010; Ren et al., 2009). A similar work to ours is Pearce (2001) who uses WordNet in order to produce anti-collocations from synonyms of the components of a MWE candidate, and decides about “MWEhood” based on these anticollocations. Another similar work is Ramisch et al. (2008) who use WordNet Synsets as one of their resources in order to calculate the entropy between the components of verb particle constructions. 35 Method Following previous work by Manning and Sch¨utze (1999), and Pearce (2001), we define collocational weight -a discriminant property of mainly institutionalized but also lexical MWEs, for noun-noun pairs according to the following hypotheses: Main Hypothesis For a given two-word compound, the head word is more likely to co-occur with the modifier than with synonyms of the modifier, and the modifier is more likely to co-occur with the head than with"
W15-0905,W12-3311,0,0.0867086,"tic properties using a chunker and dependency grammar. Examples of statistical models are Pecina (2010), Evert (2005), Lapata and Lascarides (2003), and the early work Xtract (Smadja, 1993). Farahmand and Martins (2014) present a method of extracting MWEs based on their statistical contextual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and use it as a way of identifying lexicalized compounds. There are also hybrid models in the sense that they benefit from both statistical and linguistic information (Seretan and Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There are also bilingual models which are mostly based on the assumption that a translation of a source language MWE exists in a target language (Smith, 2014; Caseli et al., 2010; Ren et al., 2009). A similar work to ours is Pearce (2001) who uses WordNet in order to produce anti-collocations from synonyms of the components of a MWE candidate, and decides about “MWEhood” based on these anticollocations. Another similar work is Ramisch et al. (2008) who use WordNet Syn"
W15-0905,I11-1024,0,0.0498595,"s In order to test our hypotheses, we implement the two models described above and two baselines, and run a comparative evaluation. We divide our data into two subsets: development and test sets. The evaluation is carried out in two phases. In the first phase we perform model selection and find the optimal parameters for various models on the development set. In the second phase we evaluate the selected models with optimal parameters on the test set, which remains unseen by the models up to this phase. 4.1 Data Although there exist a few data sets for English compounds (Baldwin and Kim, 2010; Reddy et al., 2011), to the best of our knowledge there is no data set with annotations for both MWE and non-MWE classes. We required this for the evaluation of our models therefore we compiled our own data set. We randomly extracted a set of 3000 noun-noun pairs that had the frequency of greater than 10 from across POS-tagged English Wikipedia. We kept only the pairs whose both head and modifier had more than one synonym according to WordNet. In cases were 36 a given compound had different POS tags, we selected the most frequent tags. We asked two computational linguists with background in MWE research to annot"
W15-0905,W09-2907,0,0.188502,"Missing"
W15-0905,P06-1120,0,0.10103,"le constructions based on their linguistic properties using a chunker and dependency grammar. Examples of statistical models are Pecina (2010), Evert (2005), Lapata and Lascarides (2003), and the early work Xtract (Smadja, 1993). Farahmand and Martins (2014) present a method of extracting MWEs based on their statistical contextual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and use it as a way of identifying lexicalized compounds. There are also hybrid models in the sense that they benefit from both statistical and linguistic information (Seretan and Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There are also bilingual models which are mostly based on the assumption that a translation of a source language MWE exists in a target language (Smith, 2014; Caseli et al., 2010; Ren et al., 2009). A similar work to ours is Pearce (2001) who uses WordNet in order to produce anti-collocations from synonyms of the components of a MWE candidate, and decides about “MWEhood” based on these anticollocations. Another similar work is Ramisch et a"
W15-0905,J93-1007,0,0.803931,"has been widely researched from different perspectives. Various models from rule-based to statistical have been employed to address this problem. Examples of rule-based models are Seretan (2011) and Jacquemin et al. (1997) who base their extraction on linguistic rules and formalism in order to identify and filter MWE candidates, and Baldwin (2005) who aims at extracting verb particle constructions based on their linguistic properties using a chunker and dependency grammar. Examples of statistical models are Pecina (2010), Evert (2005), Lapata and Lascarides (2003), and the early work Xtract (Smadja, 1993). Farahmand and Martins (2014) present a method of extracting MWEs based on their statistical contextual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and use it as a way of identifying lexicalized compounds. There are also hybrid models in the sense that they benefit from both statistical and linguistic information (Seretan and Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There are also bilingual models which are mostl"
W15-0905,W14-0801,0,0.0224141,"xtual properties and Hermann et al. (2012) employ distributional semantics to model non-compositionality and use it as a way of identifying lexicalized compounds. There are also hybrid models in the sense that they benefit from both statistical and linguistic information (Seretan and Wehrli, 2006; Dias, 2003). Ramisch (2012) implements a flexible platform that accepts both statistical and deep linguistic criteria in order to extract and filter MWEs. There are also bilingual models which are mostly based on the assumption that a translation of a source language MWE exists in a target language (Smith, 2014; Caseli et al., 2010; Ren et al., 2009). A similar work to ours is Pearce (2001) who uses WordNet in order to produce anti-collocations from synonyms of the components of a MWE candidate, and decides about “MWEhood” based on these anticollocations. Another similar work is Ramisch et al. (2008) who use WordNet Synsets as one of their resources in order to calculate the entropy between the components of verb particle constructions. 35 Method Following previous work by Manning and Sch¨utze (1999), and Pearce (2001), we define collocational weight -a discriminant property of mainly institutionali"
W15-0905,J96-1001,0,\N,Missing
W15-0905,W06-2405,0,\N,Missing
W15-0905,E03-1022,0,\N,Missing
W15-0905,E03-1083,0,\N,Missing
W15-1820,W11-1501,0,0.0734361,"Missing"
W15-1820,P07-2053,0,0.0380532,"Missing"
W15-1820,P81-1022,0,0.432416,"Missing"
W15-1820,nivre-etal-2006-talbanken05,1,0.761551,"ly annotated in the form of tagging and parsing. To the best of our knowledge, there is however no tagger nor parser available trained on Early Modern Swedish text. Since these tools are sensitive to spelling, the tokenised text is therefore normalised to a more modern spelling by use of character-based SMT methods, before tagging and parsing is performed using tools trained for modern Swedish. For tagging, we use HunPOS (Hal´acsy et al., 2007) with a Swedish model based on the Stockholm-Ume˚a corpus, SUC version 2.0 (Ejerhed and K¨allgren, 1997). For parsing, we use MaltParser version 1.7.2 (Nivre et al., 2006a) with a pre-trained model based on the Talbanken section of the Swedish Treebank (Nivre et al., 2006b). After tagging and parsing, the annotations given by the tagger and the parser are projected back to the text in its original spelling, resulting in a tagged and parsed version of the historical text, from which the verbs and their complements are extracted. The complements included for extraction are the following: subject (for passive verbs only, where the subject normally corresponds to the direct object in an active verb construction), direct object, indirect object, prepositional compl"
W15-1820,W12-1010,1,0.45651,"ns are building a database with information on what men and women did for a living in the Early Modern Swedish society, i.e. approximately ˚ 1550–1800 (Agren et al., 2011). This information is currently extracted by researchers manually going through large volumes of text from this time period, searching for relevant text passages describing working activities. In this process, it has been noticed that working activities often are described in the form of verb phrases, such as hugga ved (”chop wood”), s¨alja fisk (”sell fish”) or tj¨ana som piga (”serve as a maid”). Based on this observation, Pettersson et al. (2012) developed a method for automatically extracting verb phrases from historical documents by use of spelling normalisation succeeded by tagging and parsing. Using this approach, it is possible to correctly identify a large proportion of the verbs in Early Modern Swedish text. Due to issues such as differences in word order and significantly longer sentences than in present-day Swedish texts (combined with sentence segmentation problems due to inconsistent use of punctuation), it is however still hard for the parser to extract the correct complements associated with each verb. In this work we pro"
W15-1820,nivre-etal-2006-maltparser,1,\N,Missing
W15-2133,C12-2082,0,0.0306107,"and clitics are not separated from the head words but analyzed with special labels at the syntactic level instead. Therefore, in the annotation scheme of the Uppsala Persian Dependency Treebank, apart from 48 dependency labels for basic relations there are 48 complex dependency labels to cover syntactic relations for words containing unsegmented clitics. Fine-grained annotated data in treebanks normally provides a more complete grammatical analysis which in turn enhances the quality of parsing results. However, complex annotation may not always be beneficial and can impair automatic analysis (Mille et al., 2012; Jelínek, 2014). In this paper, we present different empirical studies where we systematically simplify the annotation schemes for part-of-speech tags and dependency relations within the treebank. This paper is organized as follows: Section 2 briefly presents the Uppsala Persian Dependency Treebank. Section 3 introduces the experimental design. In Section 4, ParsPer is presented and evaluated. Finally, Section 5 concludes the paper. 2 The treebank’s syntactic annotation scheme is based on Stanford Typed Dependencies (STD) (de Marneffe and Manning, 2008) with extensions for Persian. This versi"
W15-2133,nivre-etal-2006-maltparser,1,0.809925,"Missing"
W15-2133,D10-1082,0,0.0767403,"Missing"
W15-2133,ballesteros-nivre-2012-maltoptimizer-system,1,0.899063,"Missing"
W15-2133,C10-1011,1,0.876388,"Missing"
W15-2133,E12-1009,1,0.834294,"Missing"
W15-2133,D12-1133,1,0.898005,"Missing"
W15-2133,W08-1301,0,0.430254,"Missing"
W15-2133,foth-etal-2014-size,0,0.237485,"Missing"
W15-2133,jelinek-2014-improvements,0,0.0200708,"separated from the head words but analyzed with special labels at the syntactic level instead. Therefore, in the annotation scheme of the Uppsala Persian Dependency Treebank, apart from 48 dependency labels for basic relations there are 48 complex dependency labels to cover syntactic relations for words containing unsegmented clitics. Fine-grained annotated data in treebanks normally provides a more complete grammatical analysis which in turn enhances the quality of parsing results. However, complex annotation may not always be beneficial and can impair automatic analysis (Mille et al., 2012; Jelínek, 2014). In this paper, we present different empirical studies where we systematically simplify the annotation schemes for part-of-speech tags and dependency relations within the treebank. This paper is organized as follows: Section 2 briefly presents the Uppsala Persian Dependency Treebank. Section 3 introduces the experimental design. In Section 4, ParsPer is presented and evaluated. Finally, Section 5 concludes the paper. 2 The treebank’s syntactic annotation scheme is based on Stanford Typed Dependencies (STD) (de Marneffe and Manning, 2008) with extensions for Persian. This version of STD has a"
W15-2133,D10-1004,0,0.0612832,"Missing"
W15-2133,H05-1066,0,0.166131,"Missing"
W15-2133,vincze-etal-2010-hungarian,0,\N,Missing
W15-2210,W12-4502,0,0.0553415,"Missing"
W15-2210,Q13-1033,1,0.942576,"e a given dependency tree is, however, typically not unique, and for certain configurations more than one transition is correct. This issue has typically been dealt with by defining a canonical order among the transitions, thereby resolving such ambiguities in a deterministic way. In addition to the determinism, standard oracles also make the assumption that the gold tree can be recovered from the current configuration. Oracles with this behavior are known as static oracles. Recently, much work has been devoted to the development of dynamic oracles that do away with both of these assumptions (Goldberg and Nivre, 2013; Goldberg et al., 2014; G´omez-Rodr´ıguez et al., 2014). Dynamic oracles have been shown to be very successful for training greedy parsers. Since greedy parsers typically suffer from error propagation, dynamic oracles enable the parsers to learn to do “the next best thing” after having made a mistake, resulting in considerable improvements in parsing accuracy. 76 Proceedings of the 14th International Conference on Parsing Technologies, pages 76–86, c Bilbao, Spain; July 22–24, 2015. 2015 Association for Computational Linguistics The underlying idea in our work is that there may be more than a"
W15-2210,W06-2922,0,0.0410773,"e, thereby solving a previously open problem (Nivre, 2009; Nivre et al., 2009). In addition, we provide the first empirical evaluation of non-deterministic oracles for training beam search parsers, as well as the first evaluation with greedy parsers using a nonprojective transition system. 2 Related Work 3 During the last decade, a plethora of transition systems has been described. Early systems, such as ArcEager (Nivre, 2003) and ArcStandard (Nivre, 2004) were restricted to projective structures. Several systems that can accommodate non-projective structures have subsequently been described (Attardi, 2006; G´omez-Rodr´ıguez and Nivre, 2010, inter alia). These systems are, however, restricted to certain subsets of non-projective structures. In contrast, SwapStandard imposes no such restrictions and is able to parse unrestricted nonprojective structures. Dynamic oracles were first introduced by Goldberg and Nivre (2012) for the ArcEager system. They also proposed the standard way of exploiting dynamic oracles for training greedy parsers known as training with exploration. Here, the idea is that sometimes erroneous transitions are predicted during training. The dynamic oracle then comes into play"
W15-2210,Q14-1010,0,0.7143,"is, however, typically not unique, and for certain configurations more than one transition is correct. This issue has typically been dealt with by defining a canonical order among the transitions, thereby resolving such ambiguities in a deterministic way. In addition to the determinism, standard oracles also make the assumption that the gold tree can be recovered from the current configuration. Oracles with this behavior are known as static oracles. Recently, much work has been devoted to the development of dynamic oracles that do away with both of these assumptions (Goldberg and Nivre, 2013; Goldberg et al., 2014; G´omez-Rodr´ıguez et al., 2014). Dynamic oracles have been shown to be very successful for training greedy parsers. Since greedy parsers typically suffer from error propagation, dynamic oracles enable the parsers to learn to do “the next best thing” after having made a mistake, resulting in considerable improvements in parsing accuracy. 76 Proceedings of the 14th International Conference on Parsing Technologies, pages 76–86, c Bilbao, Spain; July 22–24, 2015. 2015 Association for Computational Linguistics The underlying idea in our work is that there may be more than a single decomposition ("
W15-2210,D12-1133,1,0.958284,"on-deterministic oracle, i.e., an oracle that considers all possible transition sequences that can derive the gold dependency tree. We evaluate the hypothesis that transition-based parsers with beam search can be improved by using non-deterministic oracles during training. We do this in the context of the transition system by Nivre (2009), henceforth SwapStandard, which extends the ArcStandard system (Nivre, 2004) with a swap transition to accommodate nonprojective dependency trees. This system has been shown to be very effective with beam search, even rivaling graph-based dependency parsers (Bohnet and Nivre, 2012; Bohnet et al., 2013). Empirically, we find that the utility of non-deterministic oracles for training beam search parsers is rather limited and typically the difference compared to a static oracle is insignificant. However, our experiments also show that the non-deterministic oracles can be beneficial when training greedy parsers, a result that has not previously been shown for nonprojective systems. The main contribution of this paper is the first characterization of a non-deterministic oracle for We study non-deterministic oracles for training non-projective beam search parsers with swap t"
W15-2210,P10-1151,1,0.86374,"Missing"
W15-2210,Q13-1034,1,0.911568,"Missing"
W15-2210,D14-1099,0,0.318189,"Missing"
W15-2210,C10-1011,0,0.0725066,"model is not globally trained, only the choice of the next transition is latent but the basic principle is the same. The feature model we use is primarily based on that of Zhang and Nivre (2011) with the obvious adaptations to the SwapStandard setting. Additional features are taken from other recent work on parsers using the SwapStandard system (Bohnet and Nivre, 2012; Bohnet et al., 2013). Following the line of work presented by Bohnet et al. we also replace the feature mapping function by a hash function which enables the use of negative features and yields a considerable speed improvement (Bohnet, 2010).5 6 Training Experiments In total we experiment with five different oracles. The three static ones, E AGER, L AZY, and M INIMAL, all use a single unique transition sequence for every sentence in the training data. The two non-deterministic oracles, N D -S W and N D -A LL, create latent transition sequences on the fly relying on the current parameters and may change across training iterations. Our main hypothesis is that the latent sequences created by the non-deterministic oracles are easier to learn and generalize better to unseen data, leading to increased accuracy. We train the parser with"
W15-2210,N12-1015,0,0.0556285,"Missing"
W15-2210,P04-1015,0,0.0704285,"on the fly relying on the current parameters and may change across training iterations. Our main hypothesis is that the latent sequences created by the non-deterministic oracles are easier to learn and generalize better to unseen data, leading to increased accuracy. We train the parser with a variant of the structured perceptron (Collins, 2002) and use a beam size of 20. We follow Bohnet et al. (2013) and use the the Passive-Aggressive algorithm (Crammer et al., 2006). We deviate slightly from the previous work and use the Max-Violation framework (Huang et al., 2012) rather than early update (Collins and Roark, 2004), as we found that it required fewer iterations and yielded slightly higher scores, both for static and non-deterministic oracles. Following standard practice, we also apply parameter averaging (Collins, 2002). When training with a static oracle the correct configuration to update against is well-defined, but with a non-deterministic oracle there may be more than one correct configuration and it is unclear against which to update. Yu et al. (2013) suggest to compare with the highest scoring correct configuration at every step but in initial experiments we found that this performed rather poorl"
W15-2210,J93-2004,0,0.0490389,". Yu et al. (2013) suggest to compare with the highest scoring correct configuration at every step but in initial experiments we found that this performed rather poorly. Instead, we apply beam search in a constrained setData sets. We evaluate the oracles on ten treebanks. Specifically, we use the nine treebanks from the SPMRL 2014 Shared Task (Seddah et al., 2014), comprising Arabic, Basque, French, German, Hebrew, Hungarian, Korean, Polish, and Swedish. For these treebanks we use the train/dev/test splits provided by the Shared Task organizers. Additionally, we use the English Penn Treebank (Marcus et al., 1993) converted to Stanford dependencies (de Marneffe et al., 2006) with the standard split, sections 2-21 for training, section 24 for development, and section 23 for test. A breakdown of the characteristics of the training sets of each treebank is shown in Table 1. The 3 It should be noted that in certain cases the number of SW transitions can be reduced even further by swapping tokens that are already in the projective order. The M INIMAL oracle ensures that the number of SW transitions is minimal while still respecting the projective order. 4 Even with 256gb of main memory we were unable to kee"
W15-2210,W02-1001,0,0.171748,"eriment with five different oracles. The three static ones, E AGER, L AZY, and M INIMAL, all use a single unique transition sequence for every sentence in the training data. The two non-deterministic oracles, N D -S W and N D -A LL, create latent transition sequences on the fly relying on the current parameters and may change across training iterations. Our main hypothesis is that the latent sequences created by the non-deterministic oracles are easier to learn and generalize better to unseen data, leading to increased accuracy. We train the parser with a variant of the structured perceptron (Collins, 2002) and use a beam size of 20. We follow Bohnet et al. (2013) and use the the Passive-Aggressive algorithm (Crammer et al., 2006). We deviate slightly from the previous work and use the Max-Violation framework (Huang et al., 2012) rather than early update (Collins and Roark, 2004), as we found that it required fewer iterations and yielded slightly higher scores, both for static and non-deterministic oracles. Following standard practice, we also apply parameter averaging (Collins, 2002). When training with a static oracle the correct configuration to update against is well-defined, but with a non-"
W15-2210,D13-1032,0,0.233361,"Missing"
W15-2210,W09-3811,1,0.827491,"can be thought of as latent and deferred to the machine learning algorithm. This approach has been shown to be successful for a number of tasks, including coreference resolution (Fernandes et al., 2012), semantic parsing (Zhou et al., 2013), and statistical machine translation (Yu et al., 2013), to name a few. the SwapStandard system, based on a thorough analysis of spurious ambiguities. As a side-result, we also arrive at a static oracle that minimizes the number of swap transitions required to parse any non-projective dependency tree, thereby solving a previously open problem (Nivre, 2009; Nivre et al., 2009). In addition, we provide the first empirical evaluation of non-deterministic oracles for training beam search parsers, as well as the first evaluation with greedy parsers using a nonprojective transition system. 2 Related Work 3 During the last decade, a plethora of transition systems has been described. Early systems, such as ArcEager (Nivre, 2003) and ArcStandard (Nivre, 2004) were restricted to projective structures. Several systems that can accommodate non-projective structures have subsequently been described (Attardi, 2006; G´omez-Rodr´ıguez and Nivre, 2010, inter alia). These systems a"
W15-2210,de-marneffe-etal-2006-generating,0,0.12798,"Missing"
W15-2210,W03-3017,1,0.626411,"nalysis of spurious ambiguities. As a side-result, we also arrive at a static oracle that minimizes the number of swap transitions required to parse any non-projective dependency tree, thereby solving a previously open problem (Nivre, 2009; Nivre et al., 2009). In addition, we provide the first empirical evaluation of non-deterministic oracles for training beam search parsers, as well as the first evaluation with greedy parsers using a nonprojective transition system. 2 Related Work 3 During the last decade, a plethora of transition systems has been described. Early systems, such as ArcEager (Nivre, 2003) and ArcStandard (Nivre, 2004) were restricted to projective structures. Several systems that can accommodate non-projective structures have subsequently been described (Attardi, 2006; G´omez-Rodr´ıguez and Nivre, 2010, inter alia). These systems are, however, restricted to certain subsets of non-projective structures. In contrast, SwapStandard imposes no such restrictions and is able to parse unrestricted nonprojective structures. Dynamic oracles were first introduced by Goldberg and Nivre (2012) for the ArcEager system. They also proposed the standard way of exploiting dynamic oracles for tr"
W15-2210,W04-0308,1,0.932282,"in this scenario. On the other hand, it is an open question whether search-based parsers should be trained using static oracles, or whether their performance can be further increased by using a non-deterministic oracle, i.e., an oracle that considers all possible transition sequences that can derive the gold dependency tree. We evaluate the hypothesis that transition-based parsers with beam search can be improved by using non-deterministic oracles during training. We do this in the context of the transition system by Nivre (2009), henceforth SwapStandard, which extends the ArcStandard system (Nivre, 2004) with a swap transition to accommodate nonprojective dependency trees. This system has been shown to be very effective with beam search, even rivaling graph-based dependency parsers (Bohnet and Nivre, 2012; Bohnet et al., 2013). Empirically, we find that the utility of non-deterministic oracles for training beam search parsers is rather limited and typically the difference compared to a static oracle is insignificant. However, our experiments also show that the non-deterministic oracles can be beneficial when training greedy parsers, a result that has not previously been shown for nonprojectiv"
W15-2210,P09-1040,1,0.95981,"can recover from past mistakes and do the next best thing are not applicable in this scenario. On the other hand, it is an open question whether search-based parsers should be trained using static oracles, or whether their performance can be further increased by using a non-deterministic oracle, i.e., an oracle that considers all possible transition sequences that can derive the gold dependency tree. We evaluate the hypothesis that transition-based parsers with beam search can be improved by using non-deterministic oracles during training. We do this in the context of the transition system by Nivre (2009), henceforth SwapStandard, which extends the ArcStandard system (Nivre, 2004) with a swap transition to accommodate nonprojective dependency trees. This system has been shown to be very effective with beam search, even rivaling graph-based dependency parsers (Bohnet and Nivre, 2012; Bohnet et al., 2013). Empirically, we find that the utility of non-deterministic oracles for training beam search parsers is rather limited and typically the difference compared to a static oracle is insignificant. However, our experiments also show that the non-deterministic oracles can be beneficial when training"
W15-2210,P13-1014,1,0.827618,"training. The dynamic oracle then comes into play by guiding the model towards the best possible tree, subject to the mistakes that have already been made. However, search-based parsers model the parsing problem as a structured prediction problem and are trained to predict optimal sequences of transitions for an entire sentence. Training with exploration is thus not applicable. More recent work on dynamic oracles has primarily focused on developing dynamic oracles for other transition systems. Goldberg et al. (2014) present dynamic oracles for the ArcStandard system and the LR-spine parser by Sartorio et al. (2013). The only dynamic oracle for non-projective dependency trees was introduced by G´omez-Rodr´ıguez et al. (2014) for a special case of Attardi’s (2006) system. To date no dynamic oracle has been presented for transition systems that can handle unrestricted non-projective dependencies. Transition System We begin by describing our notation and the SwapStandard system. For simplicity we omit the inclusion of arc labels from this description, although for the experimental evaluation we implement a labeled version of this system. For a more formal description of the system, as well as proofs of soun"
W15-2210,W14-6111,0,0.128336,"Missing"
W15-2210,D13-1112,0,0.090483,"July 22–24, 2015. 2015 Association for Computational Linguistics The underlying idea in our work is that there may be more than a single decomposition (i.e., transition sequence) that can recover the correct output (dependency tree). Rather than selecting a single unique such decomposition, the choice of decomposition can be thought of as latent and deferred to the machine learning algorithm. This approach has been shown to be successful for a number of tasks, including coreference resolution (Fernandes et al., 2012), semantic parsing (Zhou et al., 2013), and statistical machine translation (Yu et al., 2013), to name a few. the SwapStandard system, based on a thorough analysis of spurious ambiguities. As a side-result, we also arrive at a static oracle that minimizes the number of swap transitions required to parse any non-projective dependency tree, thereby solving a previously open problem (Nivre, 2009; Nivre et al., 2009). In addition, we provide the first empirical evaluation of non-deterministic oracles for training beam search parsers, as well as the first evaluation with greedy parsers using a nonprojective transition system. 2 Related Work 3 During the last decade, a plethora of transitio"
W15-2210,D08-1059,0,0.0228064,"Bj¨orkelund Joakim Nivre University of Stuttgart Uppsala University Institute for Natural Language Processing Department of Linguistics and Philology Stuttgart, Germany Uppsala, Sweden anders@ims.uni-stuttgart.de joakim.nivre@lingfil.uu.se Abstract Nevertheless, greedy transition-based parsers still lag behind search-based parsers that explore a larger set of possible transition sequences. Searchbased parsers are typically realized through beam search and trained using global learning, where a discriminative model is trained to score not just single transitions, but a sequence of transitions (Zhang and Clark, 2008). The combination of non-greedy inference and global learning enables search-based parsers to overcome the error propagation problem. However, since the model is globally trained, oracles that can recover from past mistakes and do the next best thing are not applicable in this scenario. On the other hand, it is an open question whether search-based parsers should be trained using static oracles, or whether their performance can be further increased by using a non-deterministic oracle, i.e., an oracle that considers all possible transition sequences that can derive the gold dependency tree. We"
W15-2210,P11-2033,1,0.845113,"extra overhead is negligible in comparison to overall training time. 5 ting to arrive at a single best correct sequence using the current parameters. This sequence is the latent gold sequence and is recomputed for every sentence during every iteration. When we train a greedy parser we fall back to the standard perceptron algorithm using a nondeterministic oracle (Goldberg and Nivre, 2013; Goldberg et al., 2014). Since this model is not globally trained, only the choice of the next transition is latent but the basic principle is the same. The feature model we use is primarily based on that of Zhang and Nivre (2011) with the obvious adaptations to the SwapStandard setting. Additional features are taken from other recent work on parsers using the SwapStandard system (Bohnet and Nivre, 2012; Bohnet et al., 2013). Following the line of work presented by Bohnet et al. we also replace the feature mapping function by a hash function which enables the use of negative features and yields a considerable speed improvement (Bohnet, 2010).5 6 Training Experiments In total we experiment with five different oracles. The three static ones, E AGER, L AZY, and M INIMAL, all use a single unique transition sequence for eve"
W15-2210,C12-1059,1,\N,Missing
W15-3706,J93-1003,0,0.529155,"Missing"
W15-3706,P07-2053,0,0.0276838,"Missing"
W15-3706,P81-1022,0,0.0779013,"Missing"
W15-3706,nivre-etal-2006-talbanken05,1,0.802157,"Missing"
W15-3706,nivre-etal-2006-maltparser,1,\N,Missing
W15-3908,W11-3216,0,0.0177874,"which significantly improves the overall transliteration performance. 1 2 Background Machine transliteration is often modelled as a sequence labelling problem in previous research. Thus, the existing algorithms for sequence labelling all can be used for solving the problem. The classical joint source-channel model (Li et al., 2004) is essentially a Hidden Markov Model (HMM), which allows direct mapping between the transliteration units in source and target languages. Given the source string as the input, when it passes through the joint source-channel, the output is generated simultaneously. Chen et al. (2011) extends the original sourcechannel model into multi-to-multi source-channel model and uses Moses as the decoder. As a popular experimental framework for machine translation, Moses is also applied to build phrase-based transliteration systems in some other related works (Finch and Sumita, 2010). Machine transliteration is treated as character level machine translation without distortion in their approaches. In addition, the use of Conditional Random Fields (CRF) (Lafferty et al., 2001) is another popular approach in previous studies. It is a powerful discriminative sequence labelling model tha"
W15-3908,W10-2406,0,0.0188122,"joint source-channel model (Li et al., 2004) is essentially a Hidden Markov Model (HMM), which allows direct mapping between the transliteration units in source and target languages. Given the source string as the input, when it passes through the joint source-channel, the output is generated simultaneously. Chen et al. (2011) extends the original sourcechannel model into multi-to-multi source-channel model and uses Moses as the decoder. As a popular experimental framework for machine translation, Moses is also applied to build phrase-based transliteration systems in some other related works (Finch and Sumita, 2010). Machine transliteration is treated as character level machine translation without distortion in their approaches. In addition, the use of Conditional Random Fields (CRF) (Lafferty et al., 2001) is another popular approach in previous studies. It is a powerful discriminative sequence labelling model that uses rich local features. However, it is very costly in terms of time complexity during the training process especially combined with the full transliteration task. Qin and Chen (2011) decomposes the Introduction Machine transliteration is an effective approach to process named entities that"
W15-3908,W11-3201,0,0.0190208,"el can be improved further via adding more multilingual resources, using more effective features for reranking and adopting better regression algorithms. Experimental Results and Analysis Table 4 shows the official experimental results. 4.1 Non-Standard Runs Standard Runs Since the test data sets are the same as the ones used in the NEWS transliteration shared tasks of 2011 and 2012, our systems are compared to the evaluated systems in the previous years. For English to Chinese, our system beats all the systems of 2012 (Zhang et al., 2012) but fails to beat the best performing system of 2011 (Zhang et al., 2011) according to ACC. Generally, the substring based system achieves better results than the character based system, which indicates that the CRF model is more effective in identifying phrase boundaries than Moses. For Chinese to English, our system is slightly worse than the best performing systems but still very competitive. We can see that the Chinese character based system yields better results. Compared to pinyin, Chinese characters contain more information that is useful to transliteration. As expected, the backoff systems perform best in both tasks. It is also notable that our systems perf"
W15-3908,N07-1047,0,0.084245,"aining process especially combined with the full transliteration task. Qin and Chen (2011) decomposes the Introduction Machine transliteration is an effective approach to process named entities that are out-of-vocabulary words in many NLP tasks, such as machine translation, corpus alignment and cross-language information retrieval. In this paper, using the experiment data from the NEWS 2015 machine transliteration shared task (Zhang et al., 2015), we develop machine transliteration systems respectively targeting English to Chinese and Chinese to English transliteration tasks. The M2M-aligner (Jiampojamarn et al., 2007) is used to preprocess the training data to obtain the boundaries and alignments of transliteration units between source and target language. We apply a hard-constrained estimation-maximization (EM) algorithm to post-process its outputs, which greatly reduces errors of segmentation and alignment. With the refined outputs, we build phrasebased transliteration systems using Moses (Koehn et al., 2007), a popular statistical machine translation framework. The results are submitted as standard runs. 56 Proceedings of the Fifth Named Entity Workshop, joint with 53rd ACL and the 7th IJCNLP, pages 56–"
W15-3908,W12-4402,0,0.113505,"ause b is never pronounced as v in English. Our multilingual reranking model can be improved further via adding more multilingual resources, using more effective features for reranking and adopting better regression algorithms. Experimental Results and Analysis Table 4 shows the official experimental results. 4.1 Non-Standard Runs Standard Runs Since the test data sets are the same as the ones used in the NEWS transliteration shared tasks of 2011 and 2012, our systems are compared to the evaluated systems in the previous years. For English to Chinese, our system beats all the systems of 2012 (Zhang et al., 2012) but fails to beat the best performing system of 2011 (Zhang et al., 2011) according to ACC. Generally, the substring based system achieves better results than the character based system, which indicates that the CRF model is more effective in identifying phrase boundaries than Moses. For Chinese to English, our system is slightly worse than the best performing systems but still very competitive. We can see that the Chinese character based system yields better results. Compared to pinyin, Chinese characters contain more information that is useful to transliteration. As expected, the backoff sy"
W15-3908,P07-2045,0,0.00804887,"iteration shared task (Zhang et al., 2015), we develop machine transliteration systems respectively targeting English to Chinese and Chinese to English transliteration tasks. The M2M-aligner (Jiampojamarn et al., 2007) is used to preprocess the training data to obtain the boundaries and alignments of transliteration units between source and target language. We apply a hard-constrained estimation-maximization (EM) algorithm to post-process its outputs, which greatly reduces errors of segmentation and alignment. With the refined outputs, we build phrasebased transliteration systems using Moses (Koehn et al., 2007), a popular statistical machine translation framework. The results are submitted as standard runs. 56 Proceedings of the Fifth Named Entity Workshop, joint with 53rd ACL and the 7th IJCNLP, pages 56–60, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics a|ber|nat|hy| a|ber|ne|thy| t|e|xi|do| wi|ll|c|o|x| full task into several subtasks and uses different CRF recognizers. Kuo et al. (2012) uses a twostage CRF system with accessor variety (AV) as an additional feature, which processes segmentation and mapping separately. 3 3.1 阿|伯|内|西| 阿|伯|内|西| 特|克|西|多| 威|尔|科|克|斯|"
W15-3908,P04-1021,0,0.601603,"dels with refined alignments provided by the M2M-aligner. For non-standard runs, we add multilingual resources to the systems designed for the standard runs and build different language specific transliteration systems. Linear regression is adopted to rerank the outputs afterwards, which significantly improves the overall transliteration performance. 1 2 Background Machine transliteration is often modelled as a sequence labelling problem in previous research. Thus, the existing algorithms for sequence labelling all can be used for solving the problem. The classical joint source-channel model (Li et al., 2004) is essentially a Hidden Markov Model (HMM), which allows direct mapping between the transliteration units in source and target languages. Given the source string as the input, when it passes through the joint source-channel, the output is generated simultaneously. Chen et al. (2011) extends the original sourcechannel model into multi-to-multi source-channel model and uses Moses as the decoder. As a popular experimental framework for machine translation, Moses is also applied to build phrase-based transliteration systems in some other related works (Finch and Sumita, 2010). Machine translitera"
W15-3908,W12-4412,0,\N,Missing
W16-0206,P14-5010,0,0.00996659,"Missing"
W16-0206,2005.mtsummit-papers.11,0,\N,Missing
W16-0206,W15-0703,1,\N,Missing
W16-0206,R11-2013,0,\N,Missing
W16-0206,W13-0901,0,\N,Missing
W16-1202,de-marneffe-etal-2014-universal,1,0.894394,"Missing"
W16-1202,dzeroski-etal-2006-towards,0,0.0934909,"Missing"
W16-1202,D07-1013,1,0.650189,"hat those studies have observed. It therefore seems that this explanation is not enough to account for those results. This raises the question of whether this phenomenon actually happened in the study by Nilsson et al. (2007). It would be interesting to know if the effects they observed were affected by this kind of error amplification. It seems that there is still a lot to do to study the impact of different representations on parsing with UD as well as on dependency parsing more generally. We propose to take one step in that direction in this paper. 2.2 Error Analysis for Dependency Parsing McDonald and Nivre (2007) conducted an extensive error analysis on two parsers in order to compare them. They compare the effect of sentence length on the two models, the effect of the structure of the graph (i.e. how close to the root individual arcs are) on the two models as well as the accuracy of the models on different POS tags and on different dependency relations. These comparisons allow them to provide insights into the strengths and weaknesses of each model. Conducting such an error analysis that compares baseline models with their transformed version could provide some further insights into the effects obtai"
W16-1202,nilsson-nivre-2008-malteval,1,0.661102,".85 0.73 1.49 2.89 1.45 1.05 0.36 0.15 3.27 1.87 2.60 0.35 1.40 0.97 0.20 2.88 4.57 0.89 2.37 5.30 4 4.1 Table 1: Data sets: train + development; S= sentence, W=word; A=auxiliary dependency relation. overview of the data used for the experiments. 3.5 Results Software For comparability with previous studies, we used MaltParser (Nivre et al., 2006) with default settings, training on the training set and parsing on the development set for all the languages that we investigated. For enhanced comparability of the results, we used the UD POS tags instead of the language specific POS tags. MaltEval (Nilsson and Nivre, 2008) was used for evaluation. The transformation code has been released as part of the python package oDETTE version 1.02 (DEpendency Treebank Transformation and Evaluation). The package can be used to run the whole pipeline, from transformation to evaluation. It can work on several treebanks in parallel which enables quick experiments. (We trained and parsed the data for the 25 treebanks in 9 minutes on an 8-core machine). 2 https://github.com/mdelhoneux/oDETTE/ archive/v1.0.tar.gz As mentioned before, we converted training data in all treebanks involved, trained a parser with that transformed tr"
W16-1202,P06-1033,1,0.925519,"ion of why parsing accuracy decreases with this approach in the case of UD is left open. 1 2 Introduction Universal Dependencies1 (henceforth UD) (Nivre, 2015) is a recent project that is attempting to harmonize syntactic annotation in dependency treebanks across languages. This is done through the development of annotation guidelines. Some guidelines have been hypothesized to be suboptimal for parsing. In the literature, certain representations of certain constructions have been shown to be better 1 http://universaldependencies.github.io/ docs/ Background 2.1 Tree Transformations for Parsing Nilsson et al. (2006) have shown that modifying coordination constructions and verb groups from their representation in the Prague Dependency Treebank (henceforth PDT) to a representation described in Melˇcuk (1988) (Mel’ˇcuk style, henceforth MS) improves dependency parsing for Czech. The procedure they follow is as follows: 1. Transform the training data. 10 Proceedings of the Workshop on Multilingual and Cross-lingual Methods in NLP, pages 10–19, c San Diego, California, June 17, 2016. 2016 Association for Computational Linguistics 2. Train a model on that transformed data. 3. Parse the test data. 4. Transform"
W16-1202,P07-1122,1,0.749655,"itten with the intent to maximize crosslinguistic parallelism and this constraint has forced the guidelines developers to sometimes choose representations that are known to be worse for parsing (de Marneffe et al., 2014). For that reason, de Marneffe et al. (2014) suggest that those representations could be modified for the purpose of parsing, thus creating a parsing representation. Transforming tree representations for the purpose of parsing is not a new idea. It has been done for constituency parsing for example by Collins (1999) but also for dependency parsing for example by Nilsson et al. (2007). Nilsson et al. (2007) modified the representation of several constructions in several languages and obtained a consistent improvement in parsing accuracy. In this paper, we will investigate the case of the verb group construction and attempt to reproduce the study by Nilsson et al. (2007) on UD treebanks to find out whether or not the alternative representation is useful for parsing with UD. Treebanks have recently been released for a number of languages with the harmonized annotation created by the Universal Dependencies project. The representation of certain constructions in UD are known t"
W16-1202,P81-1022,0,0.756266,"Missing"
W16-1202,C12-1147,0,0.697432,"for Czech. The procedure they follow is as follows: 1. Transform the training data. 10 Proceedings of the Workshop on Multilingual and Cross-lingual Methods in NLP, pages 10–19, c San Diego, California, June 17, 2016. 2016 Association for Computational Linguistics 2. Train a model on that transformed data. 3. Parse the test data. 4. Transform the parsed data back to the original representation (for comparison with the original gold standard). Nilsson et al. (2007) have shown that these same modifications as well as the modification of nonprojective structures helps parsing in four languages. Schwartz et al. (2012) conducted a study over the alternative representations of 6 constructions across 5 parsing models for English and found that some of them are easier to parse than others. Their results were consistent across parsing models. The motivations behind those two types of studies are different. Nilsson et al. (2006) have originally a representation that is more semantically oriented and potentially useful for NLP applications which they therefore wish their output to have, the PDT style, and change it to a representation that is more syntactically oriented, the MS style, because it is easier to pars"
W16-1202,W15-2134,0,0.189699,"nt representations on parsing for the purpose of choosing one representation over the other. Their methodology is therefore different, they evaluate the different representations on their respective gold standard. They argue that accuracy within a representation is a good indicator of the learnability of that representation and they argue that learnability is a good criterion for selecting a syntactic representation among alternatives. In any case, these studies seem to show that such transformations can affect parsing for various languages and for various parsing models. Silveira and Manning (2015) were the first to obtain negative results from such transformations. They attempted to modify certain constructions in a UD treebank to improve parsing for English but failed to show any improvement. Some transformations even decreased parsing accuracy. They observe that when they transform their parsed data back to the original representation, they can amplify parser errors. As a matter of fact, a transformation can be prompted by the presence of only one dependency relation but involve transformations of many 11 surrounding dependency relations. The verb group transformation is such an exam"
W16-1202,nivre-etal-2006-maltparser,1,\N,Missing
W16-1202,J03-4003,0,\N,Missing
W16-2710,W15-3908,1,0.812693,"ying Neural Networks to English-Chinese Named Entity Transliteration Yan Shao, Joakim Nivre Department of Linguistics and Philology Uppsala University {yan.shao, joakim.nivre}@lingfil.uu.se Abstract fed into a recurrent neural network for sequence to sequence transaction. Our systems are trained and evaluated on the official English to Chinese and Chinese to English datasets provided by the NEWS 2016 transliteration shared task (Zhang et al., 2016). We also compare our neural network model with the best performing phrase-based system on English-Chinese transliteration in the 2015 shared task (Shao et al., 2015) that is built with the popular machine translation framework Moses (Koehn et al., 2007). This paper presents the machine transliteration systems that we employ for our participation in the NEWS 2016 machine transliteration shared task. Based on the prevalent deep learning models developed for general sequence processing tasks, we use convolutional neural networks to extract character level information from the transliteration units and stack a simple recurrent neural network on top for sequence processing. The systems are applied to the standard runs for both English to Chinese and Chinese to"
W16-2710,W09-0438,0,0.0748855,"Missing"
W16-2710,W15-3909,0,0.0208755,"neural network from the character level afterwards. A convolutional layer is employed to capture the information encoded in the character sequences. With respect to the transliteration units, the outputs of convolutional layers are 73 Proceedings of the Sixth Named Entity Workshop, joint with 54th ACL, pages 73–77, c Berlin, Germany, August 12, 2016. 2016 Association for Computational Linguistics Input Recurrent Convolutional Max Pooling Output (Softmax) aa l to Figure 1: Architecture of the Neural Network 3.2 selaers et al. (2009) use deep belief networks for Arabic-English transliteration. Finch et al. (2015) augment the traditional phrase-based system with generation probabilities from neural networks as additional features. 3 3.1 Building the Neural Networks Figure 1 shows the architecture of the neural network that we designed for the transliteration task. For the transliteration from English to Chinese, the segmented substrings as the basic transliteration units are directly fed into the input layer as strings of separated letters. Those letters are simply initialised as one-hot vectors. In order to apply the convolutional layer over the transliteration units, all the substrings are padded wit"
W16-2710,N07-1047,0,0.191076,"that uses a different writing system while preserving the pronunciation. Machine transliteration is useful in corpus alignment, cross-language information retrieval and extraction. It is also a good supplement to general machine translation systems for handling out-of-vocabulary-words. In this paper, we present a novel transliteration system that is composed of various types of neural networks. First, we preprocess the training data, pairs of parallel person names, to retrieve segmentations of the transliteration units and their alignments in an unsupervised fashion by using the M2M aligner (Jiampojamarn et al., 2007). We start to build the neural network from the character level afterwards. A convolutional layer is employed to capture the information encoded in the character sequences. With respect to the transliteration units, the outputs of convolutional layers are 73 Proceedings of the Sixth Named Entity Workshop, joint with 54th ACL, pages 73–77, c Berlin, Germany, August 12, 2016. 2016 Association for Computational Linguistics Input Recurrent Convolutional Max Pooling Output (Softmax) aa l to Figure 1: Architecture of the Neural Network 3.2 selaers et al. (2009) use deep belief networks for Arabic-En"
W16-2710,P07-2045,0,0.0113858,"ivre Department of Linguistics and Philology Uppsala University {yan.shao, joakim.nivre}@lingfil.uu.se Abstract fed into a recurrent neural network for sequence to sequence transaction. Our systems are trained and evaluated on the official English to Chinese and Chinese to English datasets provided by the NEWS 2016 transliteration shared task (Zhang et al., 2016). We also compare our neural network model with the best performing phrase-based system on English-Chinese transliteration in the 2015 shared task (Shao et al., 2015) that is built with the popular machine translation framework Moses (Koehn et al., 2007). This paper presents the machine transliteration systems that we employ for our participation in the NEWS 2016 machine transliteration shared task. Based on the prevalent deep learning models developed for general sequence processing tasks, we use convolutional neural networks to extract character level information from the transliteration units and stack a simple recurrent neural network on top for sequence processing. The systems are applied to the standard runs for both English to Chinese and Chinese to English transliteration tasks. Our systems achieve competitive results according to the"
W16-2710,P04-1021,0,0.272489,"r participation in the NEWS 2016 machine transliteration shared task. Based on the prevalent deep learning models developed for general sequence processing tasks, we use convolutional neural networks to extract character level information from the transliteration units and stack a simple recurrent neural network on top for sequence processing. The systems are applied to the standard runs for both English to Chinese and Chinese to English transliteration tasks. Our systems achieve competitive results according to the official evaluation. 1 2 Background The classical joint source-channel model (Li et al., 2004) is one of the early successful approaches for machine transliteration, which is a generative Hidden Markov Model (HMM) that directly maps the source names into target names via passing them through a trained source channel. Later, Conditional Random Fields (CRF) (Lafferty et al., 2001) as a more powerful discriminative model for sequence labelling is adapted for transliteration and yields very competitive results. For the sake of efficiency, the CRF based systems are mostly pipeline models that process segmentation and mapping separately (Kuo et al., 2012). A substantial number of state-of-th"
W16-2710,W12-4412,0,\N,Missing
W16-3806,de-marneffe-etal-2006-generating,0,0.0370918,"Missing"
W17-0203,P81-1022,0,0.663703,"Missing"
W17-0203,D12-1091,0,0.0266379,"Missing"
W17-0203,D14-1082,0,0.153815,"of using these vectors on the accuracy of dependency parsing in different languages versus using more complex parsing architectures. 1 Introduction Greedy transition-based dependency parsing is appealing thanks to its efficiency, deriving a parse tree for a sentence in linear time using a discriminative classifier. Among different methods of classification used in a greedy dependency parser, neural network models capable of using real-valued vector representations of words, called word vectors, have shown significant improvements in both accuracy and speed of parsing. It was first proposed by Chen and Manning (2014) to use word vectors in a 3-layered feed-forward neural network as the core classifier in a transition-based dependency parser. The classifier is trained by the standard back-propagation algorithm. Using a limited number of features defined over a certain number of elements in a parser configuration, they could build an efficient and accurate parser, called the Stanford neural dependency parser. This architecture then was extended by Straka et al. (2015) and Straka et al. (2016). Parsito (Straka et al., 2015) adds a search-based oracle and a set of morphological features to the original archit"
W17-0203,W04-0308,1,0.620067,"odes are positive integers corresponding to linear positions of words in the input sentence. The process 20 Proceedings of the 21st Nordic Conference of Computational Linguistics, pages 20–28, c Gothenburg, Sweden, 23-24 May 2017. 2017 Link¨oping University Electronic Press of parsing starts from an initial configuration and ends with some terminal configuration. The transitions between configurations are controlled by a classifier trained on a history-based feature model which combines features of the partially built dependency tree and attributes of input tokens. The arc-standard algorithm (Nivre, 2004) is among the many different algorithms proposed for moving between configurations. The algorithm starts with the initial configuration in which all words are in B, Σ is empty, and A holds an artificial node 0. It uses three actions Shift, RightArc, and Left-Arc to transition between the configurations and build the parse tree. Shift pushes the head node in the buffer into the stack unconditionally. The two actions Left-Arc and Right-Arc are used to build left and right dependencies, respectively, and are restricted by the fact that the final dependency tree has to be rooted at node 0. tem. Th"
W17-0203,D14-1162,0,0.0896851,": RSV is no better than the word embedding method corresponding to each cell of the table. tors are extracted by a Linux machine running on 12 CPU cores. The free parameters of the word embedding methods, i.e., context type and context size, have been tuned on the development set and the best settings, resulting in the highest parsing accuracies, were then chosen for comparison. It leads us to asymmetric window of length 1 for RSV, GloVe and HPCA, and symmetric window of length 1 for word2vec models, CBOW and SkipGram. The GloVe word vectors are extracted by available implementation of GloVe (Pennington et al., 2014) running for 50 iterations. The HPCA word vectors are extracted by our implementation of the method (Lebret and Collobert, 2014). CBOW and SkipGram word vectors are extracted by available implementation of word2vec (Mikolov et al., 2013) running for 10 iterations, and a negative sampling value of 5. In order to show the validity of the results, we perform a bootstrap statistical significance test (BergKirkpatrick et al., 2012) on the results obtained from each parsing experiment and RSV with the null hypothesis H0 : RSV is no better than the model B, where B can be any of the word embedding me"
W17-0203,de-marneffe-etal-2006-generating,0,0.0226222,"Missing"
W17-0203,W07-2416,0,0.0307782,"Missing"
W17-0203,E14-1051,0,0.443133,"y, and are restricted by the fact that the final dependency tree has to be rooted at node 0. tem. The network is trained by the standard backpropagation algorithm that updates both network weights and vectors used in the input layer. 4 Word Vectors Dense vector representations of words, in this paper known as word vectors, have shown great improvements in natural language processing tasks. An advantage of this representation compared to the traditional one-hot representation is that the word vectors are enriched with information about the distribution of words in different contexts. Following Lebret and Collobert (2014), we propose to extract word vectors from a co-occurrence matrix as follows: First we build a co-occurrence matrix C from a text. The element Ci,j is a maximum likelihood estimation of the probability of seeing word wj in the context of word wi , (i.e., Ci,j = p(wj |wi ). It results in a sparse matrix whose data are massed around zero because of the disproportional contribution of the high frequency words in estimating the co-occurrence probabilities. Each column of C can be seen as a vector in a high-dimensional space whose dimensions correspond to the context words. In practice, we need to r"
W17-0203,L16-1680,0,0.0551771,"Missing"
W17-0203,nivre-etal-2006-maltparser,1,\N,Missing
W17-0203,J93-2004,0,\N,Missing
W17-0203,L16-1262,1,\N,Missing
W17-0205,W12-2510,0,0.0256375,"s often represented as an ‘X’ or a cross like in Figure 1. There are several reasons why NLP should pay attention to chiasmi. First it is a widespread linguistic phenomenon across culture and ages. Because of the Greek etymology of its name, one might believe that chiasmus belongs only to the rhetoricians of the classical period. It is actually a much more ancient and universal figure. Welch (1981) observes it in Talmudic, Ugaritic and even Sumero-Akkadian literature. Contrary to what one Recent research shows a growing interest in the computational analysis of style and rhetorics. Works like Bendersky and Smith (2012) and Booten and Hearst (2016) demonstrate that, with sufficient amounts of data, one can even train a system to recognize quotable sentences. Classical machine learning techniques applied to text can help discover much more than just linguistic structure or semantic content. The techniques applied so far use a lot of data already annotated by internet users, for instance, tumblr sentences with 37 Proceedings of the 21st Nordic Conference of Computational Linguistics, pages 37–45, c Gothenburg, Sweden, 23-24 May 2017. 2017 Link¨oping University Electronic Press linguistic phenomena and that acc"
W17-0205,R11-2013,0,0.118634,"utational linguistics research. Indeed, repetition in language is extremely banal and viewing every repetition in a text as being rhetorical would be absurd. The very first problem in repetitive figure detection in general, in chiasmus detection in particular, is the disproportional number of false positives that the task generates. Dubremetz and Nivre (2015) point out that in 300 pages of historical tale the previous detector (Gawryjolek, 2009) extracts up to 66,000 of the criss-cross patterns (for only one true positive chiasmus to be found). At the opposite end, the more strict detector of Hromada (2011) ends up giving a completely empty output on the same book. The pattern that we have to work on, a pair of repetitions in reverse order, is so frequent and the true positive cases are so rare that it makes it impossible to annotate a corpus for a traditional classification task. Dubremetz and Nivre (2015; 2016) introduce the second shift in the approach to chiasmus detection. Their observation is the same as the one made by Dunn (2013) on metaphora: When documenting chiasmus, the computational linguist ends up in a paradox: linguists have developed reflections on this rhetorical figure but tho"
W17-0205,N16-1134,0,0.0148013,"r a cross like in Figure 1. There are several reasons why NLP should pay attention to chiasmi. First it is a widespread linguistic phenomenon across culture and ages. Because of the Greek etymology of its name, one might believe that chiasmus belongs only to the rhetoricians of the classical period. It is actually a much more ancient and universal figure. Welch (1981) observes it in Talmudic, Ugaritic and even Sumero-Akkadian literature. Contrary to what one Recent research shows a growing interest in the computational analysis of style and rhetorics. Works like Bendersky and Smith (2012) and Booten and Hearst (2016) demonstrate that, with sufficient amounts of data, one can even train a system to recognize quotable sentences. Classical machine learning techniques applied to text can help discover much more than just linguistic structure or semantic content. The techniques applied so far use a lot of data already annotated by internet users, for instance, tumblr sentences with 37 Proceedings of the 21st Nordic Conference of Computational Linguistics, pages 37–45, c Gothenburg, Sweden, 23-24 May 2017. 2017 Link¨oping University Electronic Press linguistic phenomena and that accuracy often declines drastica"
W17-0205,2005.mtsummit-papers.11,0,0.0537171,"said that food should be our medicine and medicine our food. and Therefore, both #sameDepWaWa0 0 #sameDepWbWb penalize instances where the pairwise occurrences have the same role. To the human it was not obvious that they should be differentiated, but apparently this constraint is statistically stronger for the outermost a words. 9 Conclusion Limitations and Future Work An obvious limitation of our study is the small set of true positives on which we base the evaluation. As explained earlier, it is normal to have very few true examples even out of 2 million words of text. The Europarl corpus (Koehn, 2005), being large, consistent, but sometimes noisy, seemed to us convenient by its size and the robustness challenge it represented. Above all, it has a style that is not too specific, like poetry would be. Thus, we can hope that models tuned on this corpus would generalise to other genres (novels, for instance). A good follow-up experiment would therefore be to explore other genres and in this way test the generality of the system. This will be done in future research. References Another line of future research is to extend the approach to other (repetitive) rhetorical figures, such as anadiplosi"
W17-0205,P14-5010,0,0.00968151,"Missing"
W17-0205,W15-0703,1,0.116085,"rd pairs repeated in reverse order is trivial, but identifying the tiny fraction of these that have a rhetorical purpose is not. Figure 1: Schema of a chiasmus Because of its rarity, the chiasmus is not well suited for large-scale annotation efforts. Previous efforts aimed at chiasmus detection have therefore not been able to use (supervised) machine learning for the simple reason that there has been no training data available. These efforts have therefore mainly been based on hand-crafted rules defining categorical distinctions and typically suffering from either low precision or low recall. Dubremetz and Nivre (2015; 2016) proposed a feature-based ranking approach instead, but because they had no annotated data to use for training, they had to resort to tuning feature weights by hand on the training set. However, an important side effect of their work was the release of a small annotated corpus of chiasmi, containing 31 positive instances, a few hundred (annotated) negative instances, and several million unannotated instances assumed to be negative. may think, chiasmus is not an archaic ornament of language and it is used far beyond advertisement or political discourses. It is relevant for good writers o"
W17-0205,W16-0206,1,0.788663,"h figures of speech is one clue (among others) that may help distinguish masterpieces from poorly written texts. Finally, an additional reason for studying chiasmus, which is the focus of this paper, is its rarity. To see just how rare it is, consider Winston Churchill’s River War, a historical narrative counting more than one hundred thousand words. Despite the author’s well-known rhetorical skills, we could only find a single chiasmus in the book: This paper presents the first attempt to use machine learning to tune the weights of a model for chiasmus detection, using the corpus released by Dubremetz and Nivre (2016). To see whether it is possible to learn from this type of corpus at all, we train a log-linear model with the same features as Dubremetz and Nivre (2015) and Dubremetz and Nivre (2016). The results show that the machinelearned model, despite the small number of positive training instances, improves both precision and recall over the hand-tuned system, which is very encouraging. A comparison between the two types of systems reveals that they agree almost perfectly about which features are positive and negative, respectively, and that the difference in performance is therefore due simply to mor"
W17-0205,P11-1029,0,0.0176814,"man annotators. Taken together, these results indicate that we have created a system coherent with the human perception of rhetoric. Our research is transforming a difficult needlein-the-haystack problem into a feasible task and the only concession to do is to accept partial recall. As in old traditional methods (Blum and Mitchell, 1998; Yarowsky, 1995), we wielded the full potential of labeled and unlabeled data. We adapted it to the domain of style and creative language. Detecting chiasmus is a creative manipulation of texts that has potential applications in figurative language processing (Veale, 2011), where information retrieval becomes creative text retrieval. (17) Hippocrates said that food should be our medicine and medicine our food. and Therefore, both #sameDepWaWa0 0 #sameDepWbWb penalize instances where the pairwise occurrences have the same role. To the human it was not obvious that they should be differentiated, but apparently this constraint is statistically stronger for the outermost a words. 9 Conclusion Limitations and Future Work An obvious limitation of our study is the small set of true positives on which we base the evaluation. As explained earlier, it is normal to have v"
W17-0205,W13-0901,0,0.064418,", 2009) extracts up to 66,000 of the criss-cross patterns (for only one true positive chiasmus to be found). At the opposite end, the more strict detector of Hromada (2011) ends up giving a completely empty output on the same book. The pattern that we have to work on, a pair of repetitions in reverse order, is so frequent and the true positive cases are so rare that it makes it impossible to annotate a corpus for a traditional classification task. Dubremetz and Nivre (2015; 2016) introduce the second shift in the approach to chiasmus detection. Their observation is the same as the one made by Dunn (2013) on metaphora: When documenting chiasmus, the computational linguist ends up in a paradox: linguists have developed reflections on this rhetorical figure but those reflections are not the most helpful. Indeed, they never question the concept of criss-cross patterns as an insufficient condition for producing a rhetorical effect. Typically dictionaries and stylistic books (Fontanier, 1827; Dupriez, 2003) will explain why chiasmus should belong to the category of scheme and not of trope. Rabatel (2008) argues why chiasmus has different functions and should therefore be divided into subcategories."
W17-0205,P95-1026,0,0.0806432,"tive or not, although the machine could fine-tune the weights, for example, to account for differential syntactic patterns. An error analysis revealed that false positives were more likely than not to be cases that were considered borderline (or unclear) by human annotators. Taken together, these results indicate that we have created a system coherent with the human perception of rhetoric. Our research is transforming a difficult needlein-the-haystack problem into a feasible task and the only concession to do is to accept partial recall. As in old traditional methods (Blum and Mitchell, 1998; Yarowsky, 1995), we wielded the full potential of labeled and unlabeled data. We adapted it to the domain of style and creative language. Detecting chiasmus is a creative manipulation of texts that has potential applications in figurative language processing (Veale, 2011), where information retrieval becomes creative text retrieval. (17) Hippocrates said that food should be our medicine and medicine our food. and Therefore, both #sameDepWaWa0 0 #sameDepWbWb penalize instances where the pairwise occurrences have the same role. To the human it was not obvious that they should be differentiated, but apparently"
W17-0411,P02-1050,0,0.192339,"Missing"
W17-0411,D11-1006,0,0.0151622,"kim Nivre Dept. of Linguistics and Philology Uppsala University joakim.nivre@lingfil.uu.se Chiao-Ting Fang Dept. of Linguistics and Philology Uppsala University chfa4190@student.uu.se Abstract has made it almost impossible to isolate the influence of typological variables, such as word order or morphosyntactic alignment, from the effect of more or less arbitrary choices in linguistic representations. The absence of cross-linguistically consistent annotation has also been a constant source of noise in the evaluation of cross-lingual learning of syntax (Hwa et al., 2002; Zeman and Resnik, 2008; McDonald et al., 2011). Fortunately, there is now also a growing interest in developing cross-linguistically consistent syntactic annotation, which has led to a number of initiatives and proposals (Zeman et al., 2012; McDonald et al., 2013; Tsarfaty, 2013; de Marneffe et al., 2014). Many of these initiatives have now converged into Universal Dependencies (UD), an open community effort that aims to develop crosslinguistically consistent treebank annotation for many languages and that has so far released 70 treebanks representing 50 languages (Nivre, 2015; Nivre et al., 2016). The basic idea behind the UD scheme is t"
W17-0411,P81-1022,0,0.310657,"Missing"
W17-0411,W09-3811,1,0.685513,"ctic head and the correct label. If parse trees and gold standard trees can be assumed to have the same yield, and if no syntactic relations are excluded, then it reduces to a simple accuracy score, but in general it can be defined as the labeled F1 -score of syntactic relations. To get a better view of the impact of different relation types on the overall LAS, we performed a simple experiment where we trained and evaluated MaltParser (Nivre et al., 2006) on treebanks from the latest UD release (v2.0). The parser used an arc-standard transition system with online reordering and a lazy oracle (Nivre et al., 2009) and an extended feature model that takes all morphological features into account. We selected one treebank per language1 but only included treebanks containing morphological features and at 1 For languages with more than one treebank, we selected the treebank without a suffix except in the case of Ancient Greek and Latin, where we selected the PROIEL treebanks to avoid including poetry. 89 LAS Language Ancient Greek Arabic Basque Bulgarian Catalan Chinese Croatian Czech Danish Dutch English Estonian Finnish French German Gothic Greek Hebrew Hindi Hungarian Indonesian Italian Japanese Korean L"
W17-0411,W06-2920,0,0.0388989,"are biased in favor of analytic languages, where grammatical structure tends to be encoded in free morphemes (function words) rather than in bound morphemes (inflection). We therefore propose an alternative evaluation metric that excludes functional relations from the attachment score. We explore the effect of this change in experiments using a subset of treebanks from release v2.0 of Universal Dependencies. 1 Introduction The last decade has seen a steadily growing interest in multilingual parsing research, inspired by such events as the CoNLL shared tasks on multilingual dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) and the SPMRL shared tasks on parsing morphologically rich languages (Seddah et al., 2013; Seddah et al., 2014). This has led to a number of conjectures about the suitability of different parsing models for languages with different structural characteristics, but it has been surprisingly hard to study the interplay of parsing technology and language typology in a systematic way. To some extent, this is due to datarelated factors such as text genre and training set size, which are hard to control for, but even more important has been the fact that syntactic annotation is n"
W17-0411,de-marneffe-etal-2014-universal,1,0.855207,"Missing"
W17-0411,petrov-etal-2012-universal,0,0.0196613,"n other words, the impact of a single error is doubled in Finnish because of the smaller denominator. Using the attachment score for crosslinguistic comparisons can therefore be quite misleading even if the annotation has been harmonized across languages. 2 Syntactic Relations in UD Annotation in UD consists of a morphological and a syntactic layer. The morphological layer assigns to each word a lemma, a part-of-speech tag and a set of morphological features. The part-of-speech tag comes from a fixed inventory of 17 tags, which is a revised and extended version of the Google universal tagset (Petrov et al., 2012), and the features come from a standardized but extendable inventory based on Interset (Zeman, 2008). The syntactic layer is essentially a dependency tree with labels taken from a set of 37 syntactic relations, What should we do about this? A drastic proposal would be to give up intrinsic evaluation altogether, on the grounds that it will always be bi87 which is a revised version of the universal Stanford dependencies (de Marneffe et al., 2014). metric for syntactic dependencies that is limited to those dependencies that we can expect to find in all or most languages. Besides being less biased"
W17-0411,W11-2927,0,0.0190784,"consequence that the compounding relation is not included in the syntactic evaluation for the latter languages. The relation goeswith, finally, is different from the (other) MWE relations in that it is primarily intended for annotation of orthographic One strategy for dealing with this problem could be to come up with a more comprehensive metric that considers the full grammatical representation and abstracts over different realization patterns and puts morphological features and function words on a more equal footing. Such a metric has been proposed in the context of grammarbased parsing by Dridan and Oepen (2011). In the context of UD, however, this would require a substantial research effort in order to establish correspondences between many languages. And while this is precisely the type of research that UD is meant to enable, it would be premature to assume that we already have the required knowledge. For the time being, we will therefore propose a new 88 FUN MWE CORE aux case cc clf cop det mark compound fixed flat goeswith ccomp csubj iobj nsubj obj xcomp NON - CORE acl advcl advmod amod appos conj dep PUNCT discourse dislocated expl list nmod nummod obl orphan parataxis reparandum root vocative"
W17-0411,W14-6111,0,0.0770221,"Missing"
W17-0411,P13-2103,0,0.0309589,"luence of typological variables, such as word order or morphosyntactic alignment, from the effect of more or less arbitrary choices in linguistic representations. The absence of cross-linguistically consistent annotation has also been a constant source of noise in the evaluation of cross-lingual learning of syntax (Hwa et al., 2002; Zeman and Resnik, 2008; McDonald et al., 2011). Fortunately, there is now also a growing interest in developing cross-linguistically consistent syntactic annotation, which has led to a number of initiatives and proposals (Zeman et al., 2012; McDonald et al., 2013; Tsarfaty, 2013; de Marneffe et al., 2014). Many of these initiatives have now converged into Universal Dependencies (UD), an open community effort that aims to develop crosslinguistically consistent treebank annotation for many languages and that has so far released 70 treebanks representing 50 languages (Nivre, 2015; Nivre et al., 2016). The basic idea behind the UD scheme is to maximize parallelism across languages by focusing on dependency relations between content words, which are more likely to be similar across languages, and to use crosslinguistically valid categories for morphological and syntactic"
W17-0411,I08-3008,0,0.0100072,"ependency Evaluation Joakim Nivre Dept. of Linguistics and Philology Uppsala University joakim.nivre@lingfil.uu.se Chiao-Ting Fang Dept. of Linguistics and Philology Uppsala University chfa4190@student.uu.se Abstract has made it almost impossible to isolate the influence of typological variables, such as word order or morphosyntactic alignment, from the effect of more or less arbitrary choices in linguistic representations. The absence of cross-linguistically consistent annotation has also been a constant source of noise in the evaluation of cross-lingual learning of syntax (Hwa et al., 2002; Zeman and Resnik, 2008; McDonald et al., 2011). Fortunately, there is now also a growing interest in developing cross-linguistically consistent syntactic annotation, which has led to a number of initiatives and proposals (Zeman et al., 2012; McDonald et al., 2013; Tsarfaty, 2013; de Marneffe et al., 2014). Many of these initiatives have now converged into Universal Dependencies (UD), an open community effort that aims to develop crosslinguistically consistent treebank annotation for many languages and that has so far released 70 treebanks representing 50 languages (Nivre, 2015; Nivre et al., 2016). The basic idea b"
W17-0411,zeman-etal-2012-hamledt,0,0.0266497,"Missing"
W17-0411,zeman-2008-reusable,0,0.0243622,"the attachment score for crosslinguistic comparisons can therefore be quite misleading even if the annotation has been harmonized across languages. 2 Syntactic Relations in UD Annotation in UD consists of a morphological and a syntactic layer. The morphological layer assigns to each word a lemma, a part-of-speech tag and a set of morphological features. The part-of-speech tag comes from a fixed inventory of 17 tags, which is a revised and extended version of the Google universal tagset (Petrov et al., 2012), and the features come from a standardized but extendable inventory based on Interset (Zeman, 2008). The syntactic layer is essentially a dependency tree with labels taken from a set of 37 syntactic relations, What should we do about this? A drastic proposal would be to give up intrinsic evaluation altogether, on the grounds that it will always be bi87 which is a revised version of the universal Stanford dependencies (de Marneffe et al., 2014). metric for syntactic dependencies that is limited to those dependencies that we can expect to find in all or most languages. Besides being less biased from a cross-linguistic perspective, such a metric may also be more relevant for downstream languag"
W17-0411,nivre-etal-2006-maltparser,1,\N,Missing
W17-0411,L16-1262,1,\N,Missing
W17-6314,W06-2922,0,0.0299327,"uracy and is significantly better than a system trained with a purely static oracle. 1 Introduction Non-projective sentences are a notorious problem in dependency parsing. Traditional algorithms like those developed by Nivre (2003, 2004) for transition-based parsing only allow the construction of projective trees. These algorithms make use of a stack, a buffer and a set of arcs, and parsing consists of performing a sequence of transitions on these structures. Traditional algorithms have been extended in different ways to allow the construction of non-projective trees (Nivre and Nilsson, 2005; Attardi, 2006; Nivre, 2007; G´omez-Rodr´ıguez and Nivre, 2010). One method proposed by Nivre (2009) is based on the idea of word reordering. This is achieved by adding a transition that swaps two items in the data structures used, enabling the construction of arbitrary non-projective trees while still only adding arcs between adjacent words (after possible reordering). This technique was previously used in the arc-standard transition system (Nivre, 2004). The first contribution of this paper is to show that it can also be combined with the arc-hybrid system 99 Proceedings of the 15th International Conferen"
W17-6314,P09-1040,1,0.921113,"transition systems that satisfy the property of arc-decomposability, meaning that a tree is reachable from a configuration if and only if every arc in the tree is reachable in itself. Based on this result, they defined dynamic oracles for the arc-eager (Nivre, 2003), arc-hybrid (Kuhlmann et al., 2011) and easy-first (Goldberg and Elhadad, 2010) systems. Transition systems that allow non-projective trees are in general not arc-decomposable and therefore require different methods for constructing dynamic oracles (G´omez-Rodr´ıguez and Fern´andez-Gonz´alez, 2015). The online reordering system of Nivre (2009) is furthermore based on the arc-standard system, which is not even arc-decomposable in itself (Goldberg and Nivre, 2013). The second contribution of this paper is to show that we can take advantage of the arcdecomposability of the arc-hybrid transition system and extend the existing dynamic oracle to deal with the added swap transition. The resulting orWe extend the arc-hybrid transition system for dependency parsing with a S WAP transition that enables reordering of the words and construction of non-projective trees. Although this extension potentially breaks the arc-decomposability of the t"
W17-6314,K17-3022,1,0.665096,"Missing"
W17-6314,N10-1115,0,0.0457228,"cle, we need to be able to compute the cost of any transition in any configuration, where cost is usually defined as minimum Hamming loss with respect to the best tree reachable from that configuration. Goldberg and Nivre (2013) showed that this computation is straightforward for transition systems that satisfy the property of arc-decomposability, meaning that a tree is reachable from a configuration if and only if every arc in the tree is reachable in itself. Based on this result, they defined dynamic oracles for the arc-eager (Nivre, 2003), arc-hybrid (Kuhlmann et al., 2011) and easy-first (Goldberg and Elhadad, 2010) systems. Transition systems that allow non-projective trees are in general not arc-decomposable and therefore require different methods for constructing dynamic oracles (G´omez-Rodr´ıguez and Fern´andez-Gonz´alez, 2015). The online reordering system of Nivre (2009) is furthermore based on the arc-standard system, which is not even arc-decomposable in itself (Goldberg and Nivre, 2013). The second contribution of this paper is to show that we can take advantage of the arcdecomposability of the arc-hybrid transition system and extend the existing dynamic oracle to deal with the added swap transi"
W17-6314,W09-3811,1,0.667477,"nor any of its reachable dependents. In the old projective case, the loss was limited to a head and dependents in b|β, but because s0 can potentially be swapped back to the buffer, we again define reachability explicitly through RDEPS(s0 ) (for dependents) Dynamic Oracle Since we use a static oracle for S WAP transitions, these will always have zero cost. The dynamic oracle thus only needs to define costs for the remaining three transitions. To construct the oracle, we start from the old dynamic oracle for the projective 5 This is equivalent to an eager static oracle for S WAP in the sense of Nivre et al. (2009). 101 1 s1 2 s0 3 b [ 1 2 ]Σ 4 [ 3 4 ]B 1 R IGHT ⇒ 2 [ 1 ]Σ 3 4 [ 3 4 ]B S HIFT ⇓ 1 2 [ 1 2 3 ]Σ 3 4 1 s1 [ 4 ]B 2 s0 [ 1 2 ]Σ 4 b 3 [ 4 3 ]B Figure 2: Top left: Configuration with all nodes in projective order and gold tree displayed above the nodes. Top right: Gold arc lost (the red dotted arc) when applying a R IGHT transition from the top left configuration. The arc added by the transition is in blue, it is not in the gold tree. Bottom left: Gold arcs lost (the red dotted arcs) when applying a S HIFT transition from the top left configuration. Bottom right: Configuration where b is higher"
W17-6314,P05-1013,1,0.857982,"tem gives competitive accuracy and is significantly better than a system trained with a purely static oracle. 1 Introduction Non-projective sentences are a notorious problem in dependency parsing. Traditional algorithms like those developed by Nivre (2003, 2004) for transition-based parsing only allow the construction of projective trees. These algorithms make use of a stack, a buffer and a set of arcs, and parsing consists of performing a sequence of transitions on these structures. Traditional algorithms have been extended in different ways to allow the construction of non-projective trees (Nivre and Nilsson, 2005; Attardi, 2006; Nivre, 2007; G´omez-Rodr´ıguez and Nivre, 2010). One method proposed by Nivre (2009) is based on the idea of word reordering. This is achieved by adding a transition that swaps two items in the data structures used, enabling the construction of arbitrary non-projective trees while still only adding arcs between adjacent words (after possible reordering). This technique was previously used in the arc-standard transition system (Nivre, 2004). The first contribution of this paper is to show that it can also be combined with the arc-hybrid system 99 Proceedings of the 15th Interna"
W17-6314,Q13-1033,1,0.961767,"were trained in a static way and were only exposed to configurations resulting from optimal transitions during training. Dynamic oracles define optimal transition sequences for any configuration in which the parser may be. The use of dynamic oracles enables training with exploration of errors, which mitigates the problem of error propagation at prediction time. In order to define a dynamic oracle, we need to be able to compute the cost of any transition in any configuration, where cost is usually defined as minimum Hamming loss with respect to the best tree reachable from that configuration. Goldberg and Nivre (2013) showed that this computation is straightforward for transition systems that satisfy the property of arc-decomposability, meaning that a tree is reachable from a configuration if and only if every arc in the tree is reachable in itself. Based on this result, they defined dynamic oracles for the arc-eager (Nivre, 2003), arc-hybrid (Kuhlmann et al., 2011) and easy-first (Goldberg and Elhadad, 2010) systems. Transition systems that allow non-projective trees are in general not arc-decomposable and therefore require different methods for constructing dynamic oracles (G´omez-Rodr´ıguez and Fern´and"
W17-6314,P15-2042,0,0.0648949,"Missing"
W17-6314,P10-1151,1,0.895825,"Missing"
W17-6314,Q16-1023,0,0.169531,"e attached to its head (3) and therefore makes us lose the arc 3 → 2, as shown in the top right corner. If we instead apply a S HIFT transition, we lose the arc between b (3) and its head (1) as well as the arc 3 → 2, as shown in the bottom left corner. By contrast, a L EFT transition has zero cost, because no arcs are lost so the best tree reachable in the orig4 Experiments We extend the parser we used in de Lhoneux et al. (2017), a greedy transition-based parser that predicts the dependency tree given the raw words of a sentence. That parser is itself an extension of the parser developed by Kiperwasser and Goldberg (2016). It relies on a BiLSTM to learn informative features of words in context and a feed-forward network for predicting the next parsing transition. It learns vector representations of the words as well as characters. Contrary to parsing tradition, it makes no use of part-of-speech tags. We released our system as UUparser 2.0, available at https: //github.com/UppsalaNLP/uuparser. 102 Language A.Greek Arabic Basque English Portuguese We first compare our system, which uses our static-dynamic oracle, with the same system using a static oracle. This is to find out if we can benefit from error explora"
W17-6314,P11-1068,0,0.42275,"Missing"
W17-6314,W03-3017,1,0.84856,"propagation at prediction time. In order to define a dynamic oracle, we need to be able to compute the cost of any transition in any configuration, where cost is usually defined as minimum Hamming loss with respect to the best tree reachable from that configuration. Goldberg and Nivre (2013) showed that this computation is straightforward for transition systems that satisfy the property of arc-decomposability, meaning that a tree is reachable from a configuration if and only if every arc in the tree is reachable in itself. Based on this result, they defined dynamic oracles for the arc-eager (Nivre, 2003), arc-hybrid (Kuhlmann et al., 2011) and easy-first (Goldberg and Elhadad, 2010) systems. Transition systems that allow non-projective trees are in general not arc-decomposable and therefore require different methods for constructing dynamic oracles (G´omez-Rodr´ıguez and Fern´andez-Gonz´alez, 2015). The online reordering system of Nivre (2009) is furthermore based on the arc-standard system, which is not even arc-decomposable in itself (Goldberg and Nivre, 2013). The second contribution of this paper is to show that we can take advantage of the arcdecomposability of the arc-hybrid transition"
W17-6314,W04-0308,1,0.505296,"these structures. Traditional algorithms have been extended in different ways to allow the construction of non-projective trees (Nivre and Nilsson, 2005; Attardi, 2006; Nivre, 2007; G´omez-Rodr´ıguez and Nivre, 2010). One method proposed by Nivre (2009) is based on the idea of word reordering. This is achieved by adding a transition that swaps two items in the data structures used, enabling the construction of arbitrary non-projective trees while still only adding arcs between adjacent words (after possible reordering). This technique was previously used in the arc-standard transition system (Nivre, 2004). The first contribution of this paper is to show that it can also be combined with the arc-hybrid system 99 Proceedings of the 15th International Conference on Parsing Technologies, pages 99–104, c Pisa, Italy; September 20–22, 2017. 2017 Association for Computational Linguistics acle is static with respect to the new transition but remains dynamic for all other transitions. We show experimentally that this static-dynamic oracle gives a significant advantage over the alternative static oracle and results in competitive results for non-projective parsing. 2 • S WAP[(σ|s0 , b|β, A)] = (σ, b|s0"
W17-6314,N07-1050,1,0.664396,"gnificantly better than a system trained with a purely static oracle. 1 Introduction Non-projective sentences are a notorious problem in dependency parsing. Traditional algorithms like those developed by Nivre (2003, 2004) for transition-based parsing only allow the construction of projective trees. These algorithms make use of a stack, a buffer and a set of arcs, and parsing consists of performing a sequence of transitions on these structures. Traditional algorithms have been extended in different ways to allow the construction of non-projective trees (Nivre and Nilsson, 2005; Attardi, 2006; Nivre, 2007; G´omez-Rodr´ıguez and Nivre, 2010). One method proposed by Nivre (2009) is based on the idea of word reordering. This is achieved by adding a transition that swaps two items in the data structures used, enabling the construction of arbitrary non-projective trees while still only adding arcs between adjacent words (after possible reordering). This technique was previously used in the arc-standard transition system (Nivre, 2004). The first contribution of this paper is to show that it can also be combined with the arc-hybrid system 99 Proceedings of the 15th International Conference on Parsing"
W18-6003,D17-1137,0,0.298496,"Missing"
W18-6003,L16-1262,1,0.89472,"Missing"
W18-6003,W05-0406,0,0.430106,"D treebanks, and present recommendations for the annotation of expletives so that more consistent annotation can be achieved in future releases. 1 Introduction Universal Dependencies (UD) is a framework for morphosyntactic annotation that aims to provide useful information for downstream NLP applications in a cross-linguistically consistent fashion (Nivre, 2015; Nivre et al., 2016). Many such applications require an analysis of referring expressions. In co-reference resolution, for example, it is important to be able to separate anaphoric uses of pronouns such as it from non-referential uses (Boyd et al., 2005; Evans, 2001; Uryupina et al., 2016). Accurate translation of pronouns is another challenging problem, sometimes relying on coreference resolution, and where one of the choices is to not translate a pronoun at all. The latter situation occurs for instance when translating from a 2 What is an Expletive? The UD initiative aims to provide a syntactic annotation scheme that can be applied cross18 Proceedings of the Second Workshop on Universal Dependencies (UDW 2018), pages 18–26 c Brussels, Belgium, November 1, 2018. 2018 Association for Computational Linguistics pronoun, and there, identical to"
W18-6003,W17-1505,0,0.0151815,"Gosse Bouma∗◦ Jan Hajic†◦ Dag Haug‡◦ Joakim Nivre•◦ Per Erik Solberg‡◦ Lilja Øvrelid?◦ ∗ University of Groningen, Centre for Language and Cognition Charles University in Prague, Faculty of Mathematics and Physics, UFAL ‡ University of Oslo, Department of Philosophy, Classics, History of Arts and Ideas • Uppsala University, Department of Linguistics and Philology ? University of Oslo, Department of Informatics ◦ Center for Advanced Study at the Norwegian Academy of Science and Letters † Abstract language that has expletives into a language that does not use expletives (Hardmeier et al., 2015; Werlen and Popescu-Belis, 2017). The ParCor co-reference corpus (Guillou et al., 2014) distinguishes between anaphoric, event referential, and pleonastic use of the English pronoun it. Lo´aiciga et al. (2017) train a classifier to predict the different uses of it in English using among others syntactic information obtained from an automatic parse of the corpus. Being able to distinguish referential from non-referential noun phrases is potentially important also for tasks like question answering and information extraction. Applications like these motivate consistent and explicit annotation of expletive elements in treebanks"
W18-6003,guillou-etal-2014-parcor,0,0.0313846,"berg‡◦ Lilja Øvrelid?◦ ∗ University of Groningen, Centre for Language and Cognition Charles University in Prague, Faculty of Mathematics and Physics, UFAL ‡ University of Oslo, Department of Philosophy, Classics, History of Arts and Ideas • Uppsala University, Department of Linguistics and Philology ? University of Oslo, Department of Informatics ◦ Center for Advanced Study at the Norwegian Academy of Science and Letters † Abstract language that has expletives into a language that does not use expletives (Hardmeier et al., 2015; Werlen and Popescu-Belis, 2017). The ParCor co-reference corpus (Guillou et al., 2014) distinguishes between anaphoric, event referential, and pleonastic use of the English pronoun it. Lo´aiciga et al. (2017) train a classifier to predict the different uses of it in English using among others syntactic information obtained from an automatic parse of the corpus. Being able to distinguish referential from non-referential noun phrases is potentially important also for tasks like question answering and information extraction. Applications like these motivate consistent and explicit annotation of expletive elements in treebanks and the UD annotation scheme introduces a dedicated dep"
W18-6003,W15-2501,0,0.0255507,"sal Dependency Treebanks Gosse Bouma∗◦ Jan Hajic†◦ Dag Haug‡◦ Joakim Nivre•◦ Per Erik Solberg‡◦ Lilja Øvrelid?◦ ∗ University of Groningen, Centre for Language and Cognition Charles University in Prague, Faculty of Mathematics and Physics, UFAL ‡ University of Oslo, Department of Philosophy, Classics, History of Arts and Ideas • Uppsala University, Department of Linguistics and Philology ? University of Oslo, Department of Informatics ◦ Center for Advanced Study at the Norwegian Academy of Science and Letters † Abstract language that has expletives into a language that does not use expletives (Hardmeier et al., 2015; Werlen and Popescu-Belis, 2017). The ParCor co-reference corpus (Guillou et al., 2014) distinguishes between anaphoric, event referential, and pleonastic use of the English pronoun it. Lo´aiciga et al. (2017) train a classifier to predict the different uses of it in English using among others syntactic information obtained from an automatic parse of the corpus. Being able to distinguish referential from non-referential noun phrases is potentially important also for tasks like question answering and information extraction. Applications like these motivate consistent and explicit annotation of"
W18-6012,W07-1427,0,0.0164425,"Missing"
W18-6012,C04-1204,0,0.0109514,"a Montemagni Sebastian Schuster? Maria Simi• ∗ Uppsala University, Department of Linguistics and Philology † University of Pavia, Department of Linguistics ‡ University of Turku, Department of Future Technologies  Institute for Computational Linguistics «A. Zampolli» – CNR, Italy ? Stanford University, Department of Linguistics • University of Pisa, Department of Computer Science Abstract and as input to manual validation. Further, enhanced UD graphs are in many respects very similar to semantic dependency representations that encode predicate-argument structures (e.g., Böhmová et al. 2003; Miyao and Tsujii 2004; Oepen and Lønning 2006). While the latter exist only for a small number of languages and are typically either produced by complex hand-written grammars or by manual annotation, basic UD treebanks currently exist for more than 60 languages. Hence, automatic methods capable of predicting enhanced dependencies from UD treebanks, have the potential to drastically increase the availability of semantic dependency treebanks. In this paper, we evaluate a rule-based system developed for English and a data-driven system trained on de-lexicalized Finnish data, for predicting enhanced dependencies on a"
W18-6012,W13-3728,1,0.552289,"ll Swe Ita LSI RBE RBE 660 112 162 0.85 0.85 0.76 0.78 19 15 0 65 2 35 Table 1: Evaluation of predicted enhanced dependencies for Italian and Swedish (RBE = rule-based English system, DDF = data-driven Finnish system, LSI = language-specific Italian system). 3.2 The Data-Driven Finnish System lines but does not yet handle null nodes. It provides an interesting point of comparison for the cross-lingual systems but cannot really be evaluated on the same conditions since it has been developed using data from the Italian treebank. This data-driven approach is adapted from the supervised method of Nyblom et al. (2013) originally developed for Finnish. First, patterns identify candidate relations, which are subsequently classified with a linear SVM, trained on gold standard annotation. The original method does not predict null nodes, and therefore we only discuss added subject relations and coordination below. Added subject relations For any infinitive verb attached to a higher predicate with an xcomp relation, the system adds a subject relation to a core or (dative) oblique dependent of the governing verb. In contrast to the other systems, this system uses external language-specific resources that specify"
W18-6012,oepen-lonning-2006-discriminant,0,0.0444464,"Schuster? Maria Simi• ∗ Uppsala University, Department of Linguistics and Philology † University of Pavia, Department of Linguistics ‡ University of Turku, Department of Future Technologies  Institute for Computational Linguistics «A. Zampolli» – CNR, Italy ? Stanford University, Department of Linguistics • University of Pisa, Department of Computer Science Abstract and as input to manual validation. Further, enhanced UD graphs are in many respects very similar to semantic dependency representations that encode predicate-argument structures (e.g., Böhmová et al. 2003; Miyao and Tsujii 2004; Oepen and Lønning 2006). While the latter exist only for a small number of languages and are typically either produced by complex hand-written grammars or by manual annotation, basic UD treebanks currently exist for more than 60 languages. Hence, automatic methods capable of predicting enhanced dependencies from UD treebanks, have the potential to drastically increase the availability of semantic dependency treebanks. In this paper, we evaluate a rule-based system developed for English and a data-driven system trained on de-lexicalized Finnish data, for predicting enhanced dependencies on a sample of 1,000 sentences"
W18-6012,D17-1009,0,0.0314015,"pe language-specific system. 1 Introduction Universal Dependencies (UD) is a framework for cross-linguistically consistent treebank annotation (Nivre et al., 2016). Its syntactic annotation layer exists in two versions: a basic representation, where words are connected by syntactic relations into a dependency tree, and an enhanced representation, which is a richer graph structure that adds external subject relations, shared dependents in coordination, and predicate-argument relations in elliptical constructions, among other things. Despite the usefulness of enhanced representations (see e.g., Reddy et al. 2017; Schuster et al. 2017), most UD treebanks still contain only basic dependencies1 and therefore cannot be used to train or evaluate systems that output enhanced UD graphs. In this paper, we explore cross-lingual methods for predicting enhanced dependencies given a basic dependencies treebank. If these predictions are accurate enough, they can be used as a first approximation of enhanced representations for the nearly 100 UD treebanks that lack them, 2 Basic and Enhanced Dependencies Basic dependencies are strict surface syntax trees that connect content words with argument and modifier relatio"
W18-6012,L16-1376,1,0.763597,"e been developed, such as the one by Candito et al. (2017) for French, but this is the first attempt to predict enhanced dependencies in a language-independent way. sion of the basic one, this does not hold in general (as shown by the treatment of ellipsis below). The current UD guidelines define five enhancements: 1. 2. 3. 4. 5. Added subject relations in control and raising Null nodes for elided predicates (gapping) Shared heads and dependents in coordination Co-reference in relative clause constructions Modifier relations typed by case markers 3.1 The system is an adaptation of the work by Schuster and Manning (2016), developed for English. It relies on Semgrex (Chambers et al., 2007) patterns to find dependency structures that should be enhanced and applies heuristics-based processing steps corresponding to the five types of enhancement described in Section 2. We briefly discuss the three steps that are relevant to our study. The last two enhancements can in most cases be predicted deterministically from the basic representation and are mainly a practical convenience. We therefore limit our attention to the first three types, illustrated in Figure 1 (a–c). Added subject relations Basic dependencies do no"
W18-6012,N18-1105,1,0.752943,"Missing"
W18-6012,W13-2308,1,0.82118,"enhanced errors attributed to the systems. Feature representation To enable transfer from models trained on Finnish to other languages, we remove lexical and morphological features except universal POS tags and morphological categories that we expect to generalize well: Number, Mood, Tense, VerbForm, Voice. Languagespecific dependency type features are generalized to universal types (e.g., from nmod:tmod to nmod). 3.3 Evaluation The Language-Specific Italian System The language-specific Italian system builds on the rule-based enhancer developed for the Italian Stanford Dependencies Treebank (Bosco et al., 2013, 2014). It has been adapted to predict enhanced dependencies according to the UD guide104 nsubj xcomp obj Om du ... låter pengarna stå kvar till 1971 års slut . nsubj (1) nsubj “If you ... let the money remain [in the account] until the end of 1971.” xcomp nsubj obl E le autorità di Zagabria hanno proibito ai giornalisti di andare a Petrinja ... nsubj nsubj (2) “And the Zagreb authorities have forbidden journalists to go to Petrinja ...” conj conj amod För fysiska personer , dödsbon och familjestiftelser slopas rätten att göra avdrag ... (3) amod “For natural persons, estates and family found"
W18-6304,D14-1179,0,0.101609,"Missing"
W18-6304,P18-1167,0,0.0729323,"chanisms and the traditional word alignment. They find that attention mechanisms not only pay attention to the aligned source tokens but also distribute attention to some unaligned source tokens. In this paper, we perform a more fine-grained investigation of attention mechanisms, focusing on the task of translating ambiguous nouns. We also explore the advanced attention mechanisms in Transformer models (Vaswani et al., 2017). The encoder-decoder attention mechanisms differ in NMT models. Tang et al. (2018b) evaluate different NMT models, but focusing on NMT architectures. Tang et al. (2018a); Domhan (2018) compare different attention mechanisms. However, there is no detailed analysis on attention mechanisms. In this paper, we mainly investigate the encoderdecoder attention mechanisms. More specifically, we explore how attention mechanisms work when translating ambiguous nouns. ambiguous nouns, compared to when translating other words. To test this hypothesis, we compare the attention weight over ambiguous nouns with the attention weight over all words and all nouns. In Section 6, we first compare the two different attention mechanisms. Then, we explore the relation between accuracy and attentio"
W18-6304,N13-1073,0,0.0367842,"are multiple attention functions which compute the attention from the linearly projected vectors in parallel. Then, the context vectors from all the heads are concatenated and fed into the decoder networks. 4 Instead of using NMT models to score the contrastive translations, we use NMT models to translate source sentences and evaluate the translations of the ambiguous nouns directly. We evaluate two popular NMT models with different attention mechanisms. One is RNNS2S with the vanilla attention mechanism, and the other is Transformer with the advanced attention mechanism. We apply fast-align (Dyer et al., 2013) to get the aligned translations of ambiguous nouns. To achieve better alignment, we run fast-align on both training data and test data which includes reference translations and generated translations. However, for some ambiguous nouns, there is no alignment. We call these ambiguous nouns filtered. There are multiple reference translations for 3.2 ContraWSD ContraWSD3 from Rios et al. (2017) consists of contrastive translation sets where the human ref3 Evaluation https://github.com/a-rios/ContraWSD 28 each ambiguous noun in ContraWSD. We additionally add their synonyms4 into the reference tran"
W18-6304,I17-1004,0,0.241437,"find that attentional NMT models perform well in translating ambiguous words with frequent senses,2 while Liu et al. (2018) show that there are plenty of incorrect translations of ambiguous words. In Section 4, we evaluate the translations of ambiguous nouns, using the test set from Rios et al. (2017). In this setting, we expect to get a more accurate picture of the WSD performance of NMT models. In Section 5, we present a fine-grained investigation of attention distributions of different attention mechanisms. We focus on the process of translating the given ambiguous nouns. Previous studies (Ghader and Monz, 2017; Koehn and Knowles, 2017) have shown that attention mechanisms learn to pay attention to some unaligned but useful context tokens for predictions. Thus, we hypothesize that attention mechanisms distribute more attention to context tokens when translating Recent work has shown that the encoderdecoder attention mechanisms in neural machine translation (NMT) are different from the word alignment in statistical machine translation. In this paper, we focus on analyzing encoder-decoder attention mechanisms, in the case of word sense disambiguation (WSD) in NMT models. We hypothesize that attention"
W18-6304,E17-3017,1,0.888864,"Missing"
W18-6304,D13-1176,0,0.268957,"Missing"
W18-6304,W17-3204,0,0.18504,"MT models perform well in translating ambiguous words with frequent senses,2 while Liu et al. (2018) show that there are plenty of incorrect translations of ambiguous words. In Section 4, we evaluate the translations of ambiguous nouns, using the test set from Rios et al. (2017). In this setting, we expect to get a more accurate picture of the WSD performance of NMT models. In Section 5, we present a fine-grained investigation of attention distributions of different attention mechanisms. We focus on the process of translating the given ambiguous nouns. Previous studies (Ghader and Monz, 2017; Koehn and Knowles, 2017) have shown that attention mechanisms learn to pay attention to some unaligned but useful context tokens for predictions. Thus, we hypothesize that attention mechanisms distribute more attention to context tokens when translating Recent work has shown that the encoderdecoder attention mechanisms in neural machine translation (NMT) are different from the word alignment in statistical machine translation. In this paper, we focus on analyzing encoder-decoder attention mechanisms, in the case of word sense disambiguation (WSD) in NMT models. We hypothesize that attention mechanisms pay more attent"
W18-6304,C18-1112,1,0.837026,"decoder. Koehn and Knowles (2017) and Ghader and Monz (2017) investigate the relation between attention mechanisms and the traditional word alignment. They find that attention mechanisms not only pay attention to the aligned source tokens but also distribute attention to some unaligned source tokens. In this paper, we perform a more fine-grained investigation of attention mechanisms, focusing on the task of translating ambiguous nouns. We also explore the advanced attention mechanisms in Transformer models (Vaswani et al., 2017). The encoder-decoder attention mechanisms differ in NMT models. Tang et al. (2018b) evaluate different NMT models, but focusing on NMT architectures. Tang et al. (2018a); Domhan (2018) compare different attention mechanisms. However, there is no detailed analysis on attention mechanisms. In this paper, we mainly investigate the encoderdecoder attention mechanisms. More specifically, we explore how attention mechanisms work when translating ambiguous nouns. ambiguous nouns, compared to when translating other words. To test this hypothesis, we compare the attention weight over ambiguous nouns with the attention weight over all words and all nouns. In Section 6, we first comp"
W18-6304,N03-1017,0,0.098419,"s, we reveal that the first few layers gradually learn to “align” source and target tokens and the last few layers learn to extract features from the related but unaligned context tokens. 1 Introduction Human languages exhibit many different types of ambiguity. Lexical ambiguity refers to the fact that words can have more than one semantic meaning. Dealing with these lexical ambiguities is a challenge for various NLP tasks. Word sense disambiguation (WSD) is recognizing the correct meaning of an ambiguous word, with the help of contextual information. In statistical machine translation (SMT) (Koehn et al., 2003), a system could explicitly take context tokens into account to improve the translation of ambiguous words (Vickrey et al., 2005). By con1 Denotes the encoder-decoder attention mechanism in this paper, unless otherwise specified. 2 More than 2,000 instances in the training set. 26 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 26–35 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64004 at different encoder layers in WSD, while we focus on exploring the attenti"
W18-6304,D18-1458,1,0.879952,"Missing"
W18-6304,N18-1121,0,0.116653,"he contextual information needed for disambiguation. Moreover, how the attention mechanism1 deals with ambiguous words is also not known yet. In this paper, we focus on the question of how encoder-decoder attention mechanisms deal with ambiguous nouns. We explore two different attention mechanisms. One is the vanilla one-layer attention mechanism (Bahdanau et al., 2015; Luong et al., 2015), and the other one is the Transformer attention mechanism (Vaswani et al., 2017). Rios et al. (2017) find that attentional NMT models perform well in translating ambiguous words with frequent senses,2 while Liu et al. (2018) show that there are plenty of incorrect translations of ambiguous words. In Section 4, we evaluate the translations of ambiguous nouns, using the test set from Rios et al. (2017). In this setting, we expect to get a more accurate picture of the WSD performance of NMT models. In Section 5, we present a fine-grained investigation of attention distributions of different attention mechanisms. We focus on the process of translating the given ambiguous nouns. Previous studies (Ghader and Monz, 2017; Koehn and Knowles, 2017) have shown that attention mechanisms learn to pay attention to some unalign"
W18-6304,D15-1166,0,0.635015,"et al., 2015; Luong et al., 2015), each hidden state incorporates contextual information. Hence, NMT models could potentially perform WSD well. However, there are no empirical results to indicate that the hidden states encode the contextual information needed for disambiguation. Moreover, how the attention mechanism1 deals with ambiguous words is also not known yet. In this paper, we focus on the question of how encoder-decoder attention mechanisms deal with ambiguous nouns. We explore two different attention mechanisms. One is the vanilla one-layer attention mechanism (Bahdanau et al., 2015; Luong et al., 2015), and the other one is the Transformer attention mechanism (Vaswani et al., 2017). Rios et al. (2017) find that attentional NMT models perform well in translating ambiguous words with frequent senses,2 while Liu et al. (2018) show that there are plenty of incorrect translations of ambiguous words. In Section 4, we evaluate the translations of ambiguous nouns, using the test set from Rios et al. (2017). In this setting, we expect to get a more accurate picture of the WSD performance of NMT models. In Section 5, we present a fine-grained investigation of attention distributions of different atte"
W18-6304,H05-1097,0,0.135158,"ract features from the related but unaligned context tokens. 1 Introduction Human languages exhibit many different types of ambiguity. Lexical ambiguity refers to the fact that words can have more than one semantic meaning. Dealing with these lexical ambiguities is a challenge for various NLP tasks. Word sense disambiguation (WSD) is recognizing the correct meaning of an ambiguous word, with the help of contextual information. In statistical machine translation (SMT) (Koehn et al., 2003), a system could explicitly take context tokens into account to improve the translation of ambiguous words (Vickrey et al., 2005). By con1 Denotes the encoder-decoder attention mechanism in this paper, unless otherwise specified. 2 More than 2,000 instances in the training set. 26 Proceedings of the Third Conference on Machine Translation (WMT), Volume 1: Research Papers, pages 26–35 c Belgium, Brussels, October 31 - Novermber 1, 2018. 2018 Association for Computational Linguistics https://doi.org/10.18653/v1/W18-64004 at different encoder layers in WSD, while we focus on exploring the attention mechanisms that connect the encoder and the decoder. Koehn and Knowles (2017) and Ghader and Monz (2017) investigate the relat"
W18-6304,W18-1812,0,0.119796,"onstrained WSD task. They create well-designed test sets to evaluate the performance of NMT models in distinguishing different senses of ambiguous words, rather than evaluating the translations of ambiguous words directly. By contrast, Liu et al. (2018) evaluate the translations of ambiguous words but on a common test set. Scoring the contrastive translations is not evaluating the real output of NMT models. In this paper, we directly evaluate the translations generated by NMT models, using ContraWSD as the test set. In NMT, the encoder may encode contextual information into the hidden states. Marvin and Koehn (2018) explore the ability of hidden states ct = αt h (1) where αt is the attention vector at time step t. αt is 27 Predictions Softmax Predictions Softmax Attention αt h ct Multi-head Attention ct st−1 αt h Decoder Networks Encoder hidden states st−1 Decoder Block st−1 n-layer blocks ct Decoder Block Encoder hidden states (a) Vanilla attention mechanism (b) Advanced attention mechanism Figure 1: Different attention mechanisms between encoders and decoders in NMT. erence translations are paired with one or more contrastive variants. Given an ambiguous word in the source sentence, the correct transla"
W18-6304,W17-4702,1,0.910664,"odels could potentially perform WSD well. However, there are no empirical results to indicate that the hidden states encode the contextual information needed for disambiguation. Moreover, how the attention mechanism1 deals with ambiguous words is also not known yet. In this paper, we focus on the question of how encoder-decoder attention mechanisms deal with ambiguous nouns. We explore two different attention mechanisms. One is the vanilla one-layer attention mechanism (Bahdanau et al., 2015; Luong et al., 2015), and the other one is the Transformer attention mechanism (Vaswani et al., 2017). Rios et al. (2017) find that attentional NMT models perform well in translating ambiguous words with frequent senses,2 while Liu et al. (2018) show that there are plenty of incorrect translations of ambiguous words. In Section 4, we evaluate the translations of ambiguous nouns, using the test set from Rios et al. (2017). In this setting, we expect to get a more accurate picture of the WSD performance of NMT models. In Section 5, we present a fine-grained investigation of attention distributions of different attention mechanisms. We focus on the process of translating the given ambiguous nouns. Previous studies"
W18-6304,P16-1162,1,0.577454,"ion and label smoothing (0.1) in all models. We tie the source and target embeddings. The dropout rate of embeddings and Transformer blocks is set to 0.1. The dropout rate of RNNs is 0.2. The attention mechanism in Transformer has 8 heads. We use the training data from the WMT17 shared task.6 We choose newstest2013 as the validation set, and use newstest2014 and newstest2017 as the test sets. All the BLEU scores are measured by SacreBLEU. There are about 5.9 million sentence pairs in the training set after preprocessing with Moses scripts. We learn a joint BPE model with 32,000 subword units (Sennrich et al., 2016). There are 6,330 sentences left after filtering the sentences with segmented ambiguous nouns. We employ the models that have the best perplexity on the validation set for the evaluation. √ √ √ √ √ Table 1: Different groups of translations. Ref. denotes the reference translations. Incor. represents the incorrect senses. No means that there is neither a√ correct nor an incorrect sense of the ambiguous noun. indicates that the translations belong to the reference translations or incorrect senses or neither. Since the alignment learnt by fast-align is not perfect, we also consider the translation"
W19-7713,Q16-1031,0,0.0766628,"monolingual models consistently outperform crosslingual models even with very limited amounts of training data. In addition, there is always a multilingual model that outperforms the best monolingual model. Taken together, these results suggest that the most effective strategy for low-resource parser development may well be to annotate as much data as you can afford in the target language and then add training data from related languages if available. 2 Methodology To be able to compare monolingual, cross-lingual and multilingual models, we adopt the multilingual parsing approach pioneered by Ammar et al. (2016) and deployed on a large scale by Smith et al. (2018a) Language Faroese Danish Norwegian Swedish Upper Sorbian Czech Polish Slovak North Saami Estonian Finnish Hungarian Treebank Train Dev Test OFT 4.9k 2.5k 2.5k DDT 80k Nynorsk 245k Talbanken 67k UFAL 5.8k 2.7k 2.7k PDT 300k LFG 105k SZ 63k SNK 81k Giella 14.3k 2.5k 10k EDT 288k FTB 128k TDT 163k Szeged 20k Table 1: Data sets (UD v2.3) with number of tokens. in the 2018 CoNLL shared task on universal dependency parsing (Zeman et al., 2018). This approach differs from early work on model transfer, which relied on delexicalized models with part"
W19-7713,K17-3022,1,0.923357,"Missing"
W19-7713,W17-6314,1,0.904425,"Missing"
W19-7713,K17-3002,0,0.027734,"g results, especially for closely related languages, the results were mostly based on experiments with gold part-of-speech tags, severely overestimating the accuracy achievable under more realistic conditions (Tiedemann, 2015). We instead use lexicalized models, which do not presuppose part-of-speech tagging or any other preprocessing except tokenization for the target language, and instead rely on word, character and language embeddings. Besides being more realistic in a low-resource setting, this is justified by the reduced importance of part-of-speech tagging for neural dependency parsers (Dozat et al., 2017; Ma et al., 2018; Smith et al., 2018b). 2.1 Languages and Treebanks From Universal Dependencies v2.3 (Nivre et al., 2016; Nivre et al., 2018), we select three language clusters with one low-resource language and three related support languages with larger treebanks: a Scandinavian cluster with Faroese supported by Danish, Norwegian (Nynorsk) and Swedish; a West Slavic cluster with Upper Sorbian supported by Czech, Polish and Slovak; and a Uralic cluster with North Saami supported by Estonian, Finnish and Hungarian. It is worth noting that the support languages are much more closely related to"
W19-7713,P15-2139,0,0.0431756,"ual parsers are more competitive with respect to UAS than LAS, whereas we find that about the same number of target language training tokens is needed to reach cross-lingual performance with respect to both metrics. It is possible but by no means obvious that this difference is also related to the presence or absence of part-of-speech tags. The increasing use of neural networks and distributed representations in syntactic parsing has led to more flexible models for cross-lingual and multilingual learning embeddings that go beyond delexicalized models and their reliance on part-of-speech tags (Duong et al., 2015a; Duong et al., 2015b; Guo et al., 2015a; Guo et al., 2015b). Especially important for our own work is the multilingual model of Ammar et al. (2016) with its use of language embeddings, which were later generalized to treebank embeddings that allow seamless integration of multiple languages as well as heterogeneous treebanks for a single language (de Lhoneux et al., 2017a; Stymne et al., 2018; Smith et al., 2018a). A more recent line of research involves the use of synthetic treebanks (Wang and Eisner, 2016; Wang and Eisner, 2018), an approach recently applied to parser development for one of"
W19-7713,D15-1040,0,0.0165353,"ual parsers are more competitive with respect to UAS than LAS, whereas we find that about the same number of target language training tokens is needed to reach cross-lingual performance with respect to both metrics. It is possible but by no means obvious that this difference is also related to the presence or absence of part-of-speech tags. The increasing use of neural networks and distributed representations in syntactic parsing has led to more flexible models for cross-lingual and multilingual learning embeddings that go beyond delexicalized models and their reliance on part-of-speech tags (Duong et al., 2015a; Duong et al., 2015b; Guo et al., 2015a; Guo et al., 2015b). Especially important for our own work is the multilingual model of Ammar et al. (2016) with its use of language embeddings, which were later generalized to treebank embeddings that allow seamless integration of multiple languages as well as heterogeneous treebanks for a single language (de Lhoneux et al., 2017a; Stymne et al., 2018; Smith et al., 2018a). A more recent line of research involves the use of synthetic treebanks (Wang and Eisner, 2016; Wang and Eisner, 2018), an approach recently applied to parser development for one of"
W19-7713,P15-1119,0,0.0363844,"ect to UAS than LAS, whereas we find that about the same number of target language training tokens is needed to reach cross-lingual performance with respect to both metrics. It is possible but by no means obvious that this difference is also related to the presence or absence of part-of-speech tags. The increasing use of neural networks and distributed representations in syntactic parsing has led to more flexible models for cross-lingual and multilingual learning embeddings that go beyond delexicalized models and their reliance on part-of-speech tags (Duong et al., 2015a; Duong et al., 2015b; Guo et al., 2015a; Guo et al., 2015b). Especially important for our own work is the multilingual model of Ammar et al. (2016) with its use of language embeddings, which were later generalized to treebank embeddings that allow seamless integration of multiple languages as well as heterogeneous treebanks for a single language (de Lhoneux et al., 2017a; Stymne et al., 2018; Smith et al., 2018a). A more recent line of research involves the use of synthetic treebanks (Wang and Eisner, 2016; Wang and Eisner, 2018), an approach recently applied to parser development for one of our target languages, Faroese (Tyers et"
W19-7713,P02-1050,0,0.553513,"Missing"
W19-7713,Q16-1023,0,0.045245,"orwegian (Nynorsk) and Swedish; a West Slavic cluster with Upper Sorbian supported by Czech, Polish and Slovak; and a Uralic cluster with North Saami supported by Estonian, Finnish and Hungarian. It is worth noting that the support languages are much more closely related to the target language in the Scandinavian and West Slavic clusters than in the Uralic cluster. Table 1 lists the treebanks used for each language and the number of tokens in each data set. 2.2 Parser We use UUParser v2.3 (de Lhoneux et al., 2017a; Smith et al., 2018a), which is an adaptation of the transition-based parser of Kiperwasser and Goldberg (2016) specifically for multilingual models. The original parsing architecture relies on a BiLSTM to learn representations of tokens in context and a multilayer perceptron to predict transitions and arc labels based on a few BiLSTM vectors. The multilingually motivated extensions in UUParser include an extended transition system for handling non-projective structures (de Lhoneux et al., 2017b) and a richer representation of input tokens. More specifically, each input token wi in language l is represented by: x = e(w) ◦ BiLSTM(ch1:m ) ◦ e(t) Here x is the concatenation of a word embedding e(w), a cha"
W19-7713,P18-1130,0,0.0273959,"y for closely related languages, the results were mostly based on experiments with gold part-of-speech tags, severely overestimating the accuracy achievable under more realistic conditions (Tiedemann, 2015). We instead use lexicalized models, which do not presuppose part-of-speech tagging or any other preprocessing except tokenization for the target language, and instead rely on word, character and language embeddings. Besides being more realistic in a low-resource setting, this is justified by the reduced importance of part-of-speech tagging for neural dependency parsers (Dozat et al., 2017; Ma et al., 2018; Smith et al., 2018b). 2.1 Languages and Treebanks From Universal Dependencies v2.3 (Nivre et al., 2016; Nivre et al., 2018), we select three language clusters with one low-resource language and three related support languages with larger treebanks: a Scandinavian cluster with Faroese supported by Danish, Norwegian (Nynorsk) and Swedish; a West Slavic cluster with Upper Sorbian supported by Czech, Polish and Slovak; and a Uralic cluster with North Saami supported by Estonian, Finnish and Hungarian. It is worth noting that the support languages are much more closely related to the target langu"
W19-7713,D11-1006,0,0.386572,"uage Faroese Danish Norwegian Swedish Upper Sorbian Czech Polish Slovak North Saami Estonian Finnish Hungarian Treebank Train Dev Test OFT 4.9k 2.5k 2.5k DDT 80k Nynorsk 245k Talbanken 67k UFAL 5.8k 2.7k 2.7k PDT 300k LFG 105k SZ 63k SNK 81k Giella 14.3k 2.5k 10k EDT 288k FTB 128k TDT 163k Szeged 20k Table 1: Data sets (UD v2.3) with number of tokens. in the 2018 CoNLL shared task on universal dependency parsing (Zeman et al., 2018). This approach differs from early work on model transfer, which relied on delexicalized models with part-of-speech tags as pivot features (Zeman and Resnik, 2008; McDonald et al., 2011). Although these models initially gave encouraging results, especially for closely related languages, the results were mostly based on experiments with gold part-of-speech tags, severely overestimating the accuracy achievable under more realistic conditions (Tiedemann, 2015). We instead use lexicalized models, which do not presuppose part-of-speech tagging or any other preprocessing except tokenization for the target language, and instead rely on word, character and language embeddings. Besides being more realistic in a low-resource setting, this is justified by the reduced importance of part-"
W19-7713,L16-1262,1,0.892397,"Missing"
W19-7713,P15-2040,0,0.0175808,"rth Saami 70 60 LAS 50 40 30 20 10 0 0 50 100 500 1000 3000 5000 10000 14000 Number of TL tokens Monolingual Multilingual Cross-lingual Figure 1: Learning curves (LAS) for the monolingual model (blue dashed line) and the best multilingual model (red solid line), compared to the best cross-lingual model (black dotted line). McDonald et al. (2011) and gained further momentum with the advent of cross-linguistically consistent syntactic annotation, which facilitated evaluation (McDonald et al., 2013). Other studies concerned methods for selecting optimal source languages (Søgaard and Wulff, 2012; Rosa and Zabokrtsky, 2015). However, most of the early studies of model transfer relied on evaluation with gold part-of-speech tags on the target side, which was later shown to give over-optimistic results (Tiedemann, 2015). A study of special relevance to our own work is that of Garcia et al. (2018), who specifically study the amount of target language training data needed to outperform cross-lingual model transfer in the context of building a UD treebank for Galician. Drawing on data from 7 other Romance language varieties (Brazilian Portuguese, Catalan, European Portuguese, French, Italian, Romanian and Spanish), th"
W19-7713,K18-2011,1,0.914699,"Missing"
W19-7713,D18-1291,1,0.87468,"Missing"
W19-7713,C12-2115,0,0.0660771,"Cross-lingual Uralic: North Saami 70 60 LAS 50 40 30 20 10 0 0 50 100 500 1000 3000 5000 10000 14000 Number of TL tokens Monolingual Multilingual Cross-lingual Figure 1: Learning curves (LAS) for the monolingual model (blue dashed line) and the best multilingual model (red solid line), compared to the best cross-lingual model (black dotted line). McDonald et al. (2011) and gained further momentum with the advent of cross-linguistically consistent syntactic annotation, which facilitated evaluation (McDonald et al., 2013). Other studies concerned methods for selecting optimal source languages (Søgaard and Wulff, 2012; Rosa and Zabokrtsky, 2015). However, most of the early studies of model transfer relied on evaluation with gold part-of-speech tags on the target side, which was later shown to give over-optimistic results (Tiedemann, 2015). A study of special relevance to our own work is that of Garcia et al. (2018), who specifically study the amount of target language training data needed to outperform cross-lingual model transfer in the context of building a UD treebank for Galician. Drawing on data from 7 other Romance language varieties (Brazilian Portuguese, Catalan, European Portuguese, French, Italia"
W19-7713,P18-2098,1,0.924831,"st+Fin Est+Hun Fin+Hun All Uralic −Target +Target UAS LAS UAS LAS 66.0 58.6 22.4 8.5 68.8 60.1 22.5 7.5 67.3 59.5 19.4 4.9 65.6 57.5 24.7 9.4 64.5 55.3 23.8 8.9 67.0 58.4 20.8 8.0 65.9 57.7 27.1 11.6 65.4 56.4 Table 2: Test set accuracy for target languages (UAS, LAS). −Target = cross-lingual models trained without target language data. +Target = models trained on target language data; monolingual (first row) and multilingual. treebank t that the input comes from. The treebank embedding is used to distinguish data from different languages as well as different treebanks from the same language (Stymne et al., 2018; Smith et al., 2018a). We drop the treebank embedding when training models on a single treebank and otherwise train all models with default settings and no pre-trained embeddings. For cross-lingual and multilingual models, word, character and language embeddings are thus learned jointly for all languages. 2.3 Experimental Setup Within each cluster, we train cross-lingual models on data from every combination of one, two or three support languages (7 models), multilingual models on the same data sets plus target language data (7 models), and a monolingual model only on target language data, fo"
W19-7713,W14-1614,1,0.798006,"Missing"
W19-7713,C14-1175,0,0.0278771,"Missing"
W19-7713,W15-2137,0,0.0687042,"TDT 163k Szeged 20k Table 1: Data sets (UD v2.3) with number of tokens. in the 2018 CoNLL shared task on universal dependency parsing (Zeman et al., 2018). This approach differs from early work on model transfer, which relied on delexicalized models with part-of-speech tags as pivot features (Zeman and Resnik, 2008; McDonald et al., 2011). Although these models initially gave encouraging results, especially for closely related languages, the results were mostly based on experiments with gold part-of-speech tags, severely overestimating the accuracy achievable under more realistic conditions (Tiedemann, 2015). We instead use lexicalized models, which do not presuppose part-of-speech tagging or any other preprocessing except tokenization for the target language, and instead rely on word, character and language embeddings. Besides being more realistic in a low-resource setting, this is justified by the reduced importance of part-of-speech tagging for neural dependency parsers (Dozat et al., 2017; Ma et al., 2018; Smith et al., 2018b). 2.1 Languages and Treebanks From Universal Dependencies v2.3 (Nivre et al., 2016; Nivre et al., 2018), we select three language clusters with one low-resource language"
W19-7713,W18-6017,0,0.0581387,"al model (black dotted line). McDonald et al. (2011) and gained further momentum with the advent of cross-linguistically consistent syntactic annotation, which facilitated evaluation (McDonald et al., 2013). Other studies concerned methods for selecting optimal source languages (Søgaard and Wulff, 2012; Rosa and Zabokrtsky, 2015). However, most of the early studies of model transfer relied on evaluation with gold part-of-speech tags on the target side, which was later shown to give over-optimistic results (Tiedemann, 2015). A study of special relevance to our own work is that of Garcia et al. (2018), who specifically study the amount of target language training data needed to outperform cross-lingual model transfer in the context of building a UD treebank for Galician. Drawing on data from 7 other Romance language varieties (Brazilian Portuguese, Catalan, European Portuguese, French, Italian, Romanian and Spanish), they show that a single-source transfer parser achieves LAS corresponding to about 3,000 tokens of target language training data and UAS corresponding to about 7,000 tokens. However, they also show that careful combination and adaptation of source language data from multiple l"
W19-7713,Q16-1035,0,0.0218461,"embeddings that go beyond delexicalized models and their reliance on part-of-speech tags (Duong et al., 2015a; Duong et al., 2015b; Guo et al., 2015a; Guo et al., 2015b). Especially important for our own work is the multilingual model of Ammar et al. (2016) with its use of language embeddings, which were later generalized to treebank embeddings that allow seamless integration of multiple languages as well as heterogeneous treebanks for a single language (de Lhoneux et al., 2017a; Stymne et al., 2018; Smith et al., 2018a). A more recent line of research involves the use of synthetic treebanks (Wang and Eisner, 2016; Wang and Eisner, 2018), an approach recently applied to parser development for one of our target languages, Faroese (Tyers et al., 2018). Finally, it is worth noting that the superiority of annotating target language data over using cross-lingual methods has also been demonstrated for the related part-of-speech tagging problem, in the context of historical text processing, by Schultz and Kuhn (2016) and Schultz and Ketchik (2019). 5 Conclusion We have compared cross-lingual, multilingual and monolingual parser training for three low-resource languages, supported to different degrees by relat"
W19-7713,D18-1163,0,0.0160156,"nd delexicalized models and their reliance on part-of-speech tags (Duong et al., 2015a; Duong et al., 2015b; Guo et al., 2015a; Guo et al., 2015b). Especially important for our own work is the multilingual model of Ammar et al. (2016) with its use of language embeddings, which were later generalized to treebank embeddings that allow seamless integration of multiple languages as well as heterogeneous treebanks for a single language (de Lhoneux et al., 2017a; Stymne et al., 2018; Smith et al., 2018a). A more recent line of research involves the use of synthetic treebanks (Wang and Eisner, 2016; Wang and Eisner, 2018), an approach recently applied to parser development for one of our target languages, Faroese (Tyers et al., 2018). Finally, it is worth noting that the superiority of annotating target language data over using cross-lingual methods has also been demonstrated for the related part-of-speech tagging problem, in the context of historical text processing, by Schultz and Kuhn (2016) and Schultz and Ketchik (2019). 5 Conclusion We have compared cross-lingual, multilingual and monolingual parser training for three low-resource languages, supported to different degrees by related languages with more r"
W19-7713,I08-3008,0,0.0604233,"mith et al. (2018a) Language Faroese Danish Norwegian Swedish Upper Sorbian Czech Polish Slovak North Saami Estonian Finnish Hungarian Treebank Train Dev Test OFT 4.9k 2.5k 2.5k DDT 80k Nynorsk 245k Talbanken 67k UFAL 5.8k 2.7k 2.7k PDT 300k LFG 105k SZ 63k SNK 81k Giella 14.3k 2.5k 10k EDT 288k FTB 128k TDT 163k Szeged 20k Table 1: Data sets (UD v2.3) with number of tokens. in the 2018 CoNLL shared task on universal dependency parsing (Zeman et al., 2018). This approach differs from early work on model transfer, which relied on delexicalized models with part-of-speech tags as pivot features (Zeman and Resnik, 2008; McDonald et al., 2011). Although these models initially gave encouraging results, especially for closely related languages, the results were mostly based on experiments with gold part-of-speech tags, severely overestimating the accuracy achievable under more realistic conditions (Tiedemann, 2015). We instead use lexicalized models, which do not presuppose part-of-speech tagging or any other preprocessing except tokenization for the target language, and instead rely on word, character and language embeddings. Besides being more realistic in a low-resource setting, this is justified by the red"
W19-7713,K18-2001,1,0.909364,"Missing"
