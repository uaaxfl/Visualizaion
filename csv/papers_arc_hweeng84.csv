2021.findings-emnlp.365,Improved Word Sense Disambiguation with Enhanced Sense Representations,2021,-1,-1,3,0,7312,yang song,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Current state-of-the-art supervised word sense disambiguation (WSD) systems (such as GlossBERT and bi-encoder model) yield surprisingly good results by purely leveraging pre-trained language models and short dictionary definitions (or glosses) of the different word senses. While concise and intuitive, the sense gloss is just one of many ways to provide information about word senses. In this paper, we focus on enhancing the sense representations via incorporating synonyms, example phrases or sentences showing usage of word senses, and sense gloss of hypernyms. We show that incorporating such additional information boosts the performance on WSD. With the proposed enhancements, our system achieves an F1 score of 82.0{\%} on the standard benchmark test dataset of the English all-words WSD task, surpassing all previous published scores on this benchmark dataset."
2021.findings-emnlp.419,Grammatical Error Correction with Contrastive Learning in Low Error Density Domains,2021,-1,-1,3,0,7467,hannan cao,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Although grammatical error correction (GEC) has achieved good performance on texts written by learners of English as a second language, performance on low error density domains where texts are written by English speakers of varying levels of proficiency can still be improved. In this paper, we propose a contrastive learning approach to encourage the GEC model to assign a higher probability to a correct sentence while reducing the probability of incorrect sentences that the model tends to generate, so as to improve the accuracy of the model. Experimental results show that our approach significantly improves the performance of GEC models in low error density domains, when evaluated on the benchmark CWEB dataset."
2021.eacl-main.283,Do Multi-Hop Question Answering Systems Know How to Answer the Single-Hop Sub-Questions?,2021,-1,-1,2,0,10932,yixuan tang,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Multi-hop question answering (QA) requires a model to retrieve and integrate information from multiple passages to answer a question. Rapid progress has been made on multi-hop QA systems with regard to standard evaluation metrics, including EM and F1. However, by simply evaluating the correctness of the answers, it is unclear to what extent these systems have learned the ability to perform multi-hop reasoning. In this paper, we propose an additional sub-question evaluation for the multi-hop QA dataset HotpotQA, in order to shed some light on explaining the reasoning process of QA systems in answering complex questions. We adopt a neural decomposition model to generate sub-questions for a multi-hop question, followed by extracting the corresponding sub-answers. Contrary to our expectation, multiple state-of-the-art multi-hop QA models fail to answer a large portion of sub-questions, although the corresponding multi-hop questions are correctly answered. Our work takes a step forward towards building a more explainable multi-hop QA system."
2020.emnlp-main.599,Feature Adaptation of Pre-Trained Language Models across Languages and Domains with Robust Self-Training,2020,-1,-1,5,0,12946,hai ye,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Adapting pre-trained language models (PrLMs) (e.g., BERT) to new domains has gained much attention recently. Instead of fine-tuning PrLMs as done in most previous work, we investigate how to adapt the features of PrLMs to new domains without fine-tuning. We explore unsupervised domain adaptation (UDA) in this paper. With the features from PrLMs, we adapt the models trained with labeled data from the source domain to the unlabeled target domain. Self-training is widely used for UDA, and it predicts pseudo labels on the target domain data for training. However, the predicted pseudo labels inevitably include noise, which will negatively affect training a robust model. To improve the robustness of self-training, in this paper we present class-aware feature self-distillation (CFd) to learn discriminative features from PrLMs, in which PrLM features are self-distilled into a feature adaptation module and the features from the same class are more tightly clustered. We further extend CFd to a cross-language setting, in which language discrepancy is studied. Experiments on two monolingual and multilingual Amazon review datasets show that CFd can consistently improve the performance of self-training in cross-domain and cross-language settings."
2020.coling-main.227,A Survey of Unsupervised Dependency Parsing,2020,-1,-1,3,0,10470,wenjuan han,Proceedings of the 28th International Conference on Computational Linguistics,0,"Syntactic dependency parsing is an important task in natural language processing. Unsupervised dependency parsing aims to learn a dependency parser from sentences that have no annotation of their correct parse trees. Despite its difficulty, unsupervised parsing is an interesting research direction because of its capability of utilizing almost unlimited unannotated text data. It also serves as the basis for other research in low-resource parsing. In this paper, we survey existing approaches to unsupervised dependency parsing, identify two major classes of approaches, and discuss recent trends. We hope that our survey can provide insights for researchers and facilitate future research on this topic."
2020.coling-main.371,A Co-Attentive Cross-Lingual Neural Model for Dialogue Breakdown Detection,2020,-1,-1,3,0,7315,qian lin,Proceedings of the 28th International Conference on Computational Linguistics,0,"Ensuring smooth communication is essential in a chat-oriented dialogue system, so that a user can obtain meaningful responses through interactions with the system. Most prior work on dialogue research does not focus on preventing dialogue breakdown. One of the major challenges is that a dialogue system may generate an undesired utterance leading to a dialogue breakdown, which degrades the overall interaction quality. Hence, it is crucial for a machine to detect dialogue breakdowns in an ongoing conversation. In this paper, we propose a novel dialogue breakdown detection model that jointly incorporates a pretrained cross-lingual language model and a co-attention network. Our proposed model leverages effective word embeddings trained on one hundred different languages to generate contextualized representations. Co-attention aims to capture the interaction between the latest utterance and the conversation history, and thereby determines whether the latest utterance causes a dialogue breakdown. Experimental results show that our proposed model outperforms all previous approaches on all evaluation metrics in both the Japanese and English tracks in Dialogue Breakdown Detection Challenge 4 (DBDC4 at IWSDS2019)."
2020.acl-main.90,Learning to Identify Follow-Up Questions in Conversational Question Answering,2020,-1,-1,3,1,21468,souvik kundu,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Despite recent progress in conversational question answering, most prior work does not focus on follow-up questions. Practical conversational question answering systems often receive follow-up questions in an ongoing conversation, and it is crucial for a system to be able to determine whether a question is a follow-up question of the current conversation, for more effective answer finding subsequently. In this paper, we introduce a new follow-up question identification task. We propose a three-way attentive pooling network that determines the suitability of a follow-up question by capturing pair-wise interactions between the associated passage, the conversation history, and a candidate follow-up question. It enables the model to capture topic continuity and topic shift while scoring a particular candidate follow-up question. Experiments show that our proposed three-way attentive pooling network outperforms all baseline systems by significant margins."
W19-5002,Learning from the Experience of Doctors: Automated Diagnosis of Appendicitis Based on Clinical Notes,2019,0,0,2,0,23918,steven yuwono,Proceedings of the 18th BioNLP Workshop and Shared Task,0,"The objective of this work is to develop an automated diagnosis system that is able to predict the probability of appendicitis given a free-text emergency department (ED) note and additional structured information (e.g., lab test results). Our clinical corpus consists of about 180,000 ED notes based on ten years of patient visits to the Accident and Emergency (A{\&}E) Department of the National University Hospital (NUH), Singapore. We propose a novel neural network approach that learns to diagnose acute appendicitis based on doctors{'} free-text ED notes without any feature engineering. On a test set of 2,000 ED notes with equal number of appendicitis (positive) and non-appendicitis (negative) diagnosis and in which all the negative ED notes only consist of abdominal-related diagnosis, our model is able to achieve a promising F{\_}0.5-score of 0.895 while ED doctors achieve F{\_}0.5-score of 0.900. Visualization shows that our model is able to learn important features, signs, and symptoms of patients from unstructured free-text ED notes, which will help doctors to make better diagnosis."
P19-1042,Cross-Sentence Grammatical Error Correction,2019,0,1,3,1,20249,shamil chollampatt,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Automatic grammatical error correction (GEC) research has made remarkable progress in the past decade. However, all existing approaches to GEC correct errors by considering a single sentence alone and ignoring crucial cross-sentence context. Some errors can only be corrected reliably using cross-sentence context and models can also benefit from the additional contextual information in correcting other errors. In this paper, we address this serious limitation of existing approaches and improve strong neural encoder-decoder models by appropriately modeling wider contexts. We employ an auxiliary encoder that encodes previous sentences and incorporate the encoding in the decoder via attention and gating mechanisms. Our approach results in statistically significant improvements in overall GEC performance over strong baselines across multiple test sets. Analysis of our cross-sentence GEC model on a synthetic dataset shows high performance in verb tense corrections that require cross-sentence context."
P19-1048,An Interactive Multi-Task Learning Network for End-to-End Aspect-Based Sentiment Analysis,2019,0,8,3,1,10099,ruidan he,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Aspect-based sentiment analysis produces a list of aspect terms and their corresponding sentiments for a natural language sentence. This task is usually done in a pipeline manner, with aspect term extraction performed first, followed by sentiment predictions toward the extracted aspect terms. While easier to develop, such an approach does not fully exploit joint information from the two subtasks and does not use all available sources of training information that might be helpful, such as document-level labeled sentiment corpus. In this paper, we propose an interactive multi-task learning network (IMN) which is able to jointly learn multiple related tasks simultaneously at both the token level as well as the document level. Unlike conventional multi-task learning methods that rely on learning common features for the different tasks, IMN introduces a message passing architecture where information is iteratively passed to different tasks through a shared set of latent variables. Experimental results demonstrate superior performance of the proposed method against multiple baselines on three benchmark datasets."
P19-1610,Improving the Robustness of Question Answering Systems to Question Paraphrasing,2019,0,4,2,0,25903,wee gan,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Despite the advancement of question answering (QA) systems and rapid improvements on held-out test sets, their generalizability is a topic of concern. We explore the robustness of QA models to question paraphrasing by creating two test sets consisting of paraphrased SQuAD questions. Paraphrased questions from the first test set are very similar to the original questions designed to test QA models{'} over-sensitivity, while questions from the second test set are paraphrased using context words near an incorrect answer candidate in an attempt to confuse QA models. We show that both paraphrased test sets lead to significant decrease in performance on multiple state-of-the-art QA models. Using a neural paraphrasing model trained to generate multiple paraphrased questions for a given source question and a set of paraphrase suggestions, we propose a data augmentation approach that requires no human intervention to re-train the models for improved robustness to question paraphrasing."
K19-1056,Effective Attention Modeling for Neural Relation Extraction,2019,0,1,2,0,10107,tapas nayak,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"Relation extraction is the task of determining the relation between two entities in a sentence. Distantly-supervised models are popular for this task. However, sentences can be long and two entities can be located far from each other in a sentence. The pieces of evidence supporting the presence of a relation between two entities may not be very direct, since the entities may be connected via some indirect links such as a third entity or via co-reference. Relation extraction in such scenarios becomes more challenging as we need to capture the long-distance interactions among the entities and other words in the sentence. Also, the words in a sentence do not contribute equally in identifying the relation between the two entities. To address this issue, we propose a novel and effective attention model which incorporates syntactic information of the sentence and a multi-factor attention mechanism. Experiments on the New York Times corpus show that our proposed model outperforms prior state-of-the-art models."
D19-1533,Improved Word Sense Disambiguation Using Pre-Trained Contextualized Word Representations,2019,0,3,2,1,27113,christian hadiwinoto,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Contextualized word representations are able to give different representations for the same word in different contexts, and they have been shown to be effective in downstream natural language processing tasks, such as question answering, named entity recognition, and sentiment analysis. However, evaluation on word sense disambiguation (WSD) in prior work shows that using contextualized word representations does not outperform the state-of-the-art approach that makes use of non-contextualized word embeddings. In this paper, we explore different strategies of integrating pre-trained contextualized word representations and our best strategy achieves accuracies exceeding the best prior published accuracies by significant margins on multiple benchmark WSD datasets."
P18-2092,Exploiting Document Knowledge for Aspect-level Sentiment Classification,2018,15,8,3,1,10099,ruidan he,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Attention-based long short-term memory (LSTM) networks have proven to be useful in aspect-level sentiment classification. However, due to the difficulties in annotating aspect-level data, existing public datasets for this task are all relatively small, which largely limits the effectiveness of those neural models. In this paper, we explore two approaches that transfer knowledge from document-level data, which is much less expensive to obtain, to improve the performance of aspect-level sentiment classification. We demonstrate the effectiveness of our approaches on 4 public datasets from SemEval 2014, 2015, and 2016, and we show that attention-based LSTM benefits from document-level knowledge in multiple ways."
L18-1003,Upping the Ante: Towards a Better Benchmark for {C}hinese-to-{E}nglish Machine Translation,2018,17,1,2,1,27113,christian hadiwinoto,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"There are many machine translation (MT) papers that propose novel approaches and show improvements over their self-defined baselines. The experimental setting in each paper often differs from one another. As such, it is hard to determine if a proposed approach is really useful and advances the state of the art. Chinese-to-English translation is a common translation direction in MT papers, although there is not one widely accepted experimental setting in Chinese-to-English MT. Our goal in this paper is to propose a benchmark in evaluation setup for Chinese-to-English machine translation, such that the effectiveness of a new proposed MT approach can be directly compared to previous approaches. Towards this end, we also built a highly competitive state-of-the-art MT system trained on a large-scale training set. Our system outperforms reported results on NIST OpenMT test sets in almost all papers published in major conferences and journals in computational linguistics and artificial intelligence in the past 11 years. We argue that a standardized benchmark on data and performance is important for meaningful comparison."
D18-1274,Neural Quality Estimation of Grammatical Error Correction,2018,0,14,2,1,20249,shamil chollampatt,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Grammatical error correction (GEC) systems deployed in language learning environments are expected to accurately correct errors in learners{'} writing. However, in practice, they often produce spurious corrections and fail to correct many errors, thereby misleading learners. This necessitates the estimation of the quality of output sentences produced by GEC systems so that instructors can selectively intervene and re-correct the sentences which are poorly corrected by the system and ensure that learners get accurate feedback. We propose the first neural approach to automatic quality estimation of GEC output sentences that does not employ any hand-crafted features. Our system is trained in a supervised manner on learner sentences and corresponding GEC system outputs with quality score labels computed using human-annotated references. Our neural quality estimation models for GEC show significant improvements over a strong feature-based baseline. We also show that a state-of-the-art GEC system can be improved when quality scores are used as features for re-ranking the N-best candidates."
D18-1383,Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification,2018,0,4,3,1,10099,ruidan he,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We consider the cross-domain sentiment classification problem, where a sentiment classifier is to be learned from a source domain and to be generalized to a target domain. Our approach explicitly minimizes the distance between the source and the target instances in an embedded feature space. With the difference between source and target minimized, we then exploit additional information from the target domain by consolidating the idea of semi-supervised learning, for which, we jointly employ two regularizations {---} entropy minimization and self-ensemble bootstrapping {---} to incorporate the unlabeled target data for classifier refinement. Our experimental results demonstrate that the proposed approach can better leverage unlabeled data from the target domain and achieve substantial improvements over baseline methods in various experimental settings."
D18-1456,A Nil-Aware Answer Extraction Framework for Question Answering,2018,0,7,2,1,21468,souvik kundu,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Recently, there has been a surge of interest in reading comprehension-based (RC) question answering (QA). However, current approaches suffer from an impractical assumption that every question has a valid answer in the associated passage. A practical QA system must possess the ability to determine whether a valid answer exists in a given text passage. In this paper, we focus on developing QA systems that can extract an answer for a question if and only if the associated passage contains an answer. If the associated passage does not contain any valid answer, the QA system will correctly return Nil. We propose a novel nil-aware answer span extraction framework that is capable of returning Nil or a text span from the associated passage as an answer in a single step. We show that our proposed framework can be easily integrated with several recently proposed QA models developed for reading comprehension and can be trained in an end-to-end fashion. Our proposed nil-aware answer extraction neural network decomposes pieces of evidence into relevant and irrelevant parts and then combines them to infer the existence of any answer. Experiments on the NewsQA dataset show that the integration of our proposed framework significantly outperforms several strong baseline systems that use pipeline or threshold-based approaches."
C18-1096,Effective Attention Modeling for Aspect-Level Sentiment Classification,2018,0,40,3,1,10099,ruidan he,Proceedings of the 27th International Conference on Computational Linguistics,0,"Aspect-level sentiment classification aims to determine the sentiment polarity of a review sentence towards an opinion target. A sentence could contain multiple sentiment-target pairs; thus the main challenge of this task is to separate different opinion contexts for different targets. To this end, attention mechanism has played an important role in previous state-of-the-art neural models. The mechanism is able to capture the importance of each context word towards a target by modeling their semantic associations. We build upon this line of research and propose two novel approaches for improving the effectiveness of attention. First, we propose a method for target representation that better captures the semantic meaning of the opinion target. Second, we introduce an attention model that incorporates syntactic information into the attention mechanism. We experiment on attention-based LSTM (Long Short-Term Memory) models using the datasets from SemEval 2014, 2015, and 2016. The experimental results show that the conventional attention-based LSTM can be substantially improved by incorporating the two approaches."
C18-1231,A Reassessment of Reference-Based Grammatical Error Correction Metrics,2018,0,1,2,1,20249,shamil chollampatt,Proceedings of the 27th International Conference on Computational Linguistics,0,"Several metrics have been proposed for evaluating grammatical error correction (GEC) systems based on grammaticality, fluency, and adequacy of the output sentences. Previous studies of the correlation of these metrics with human quality judgments were inconclusive, due to the lack of appropriate significance tests, discrepancies in the methods, and choice of datasets used. In this paper, we re-evaluate reference-based GEC metrics by measuring the system-level correlations with humans on a large dataset of human judgments of GEC outputs, and by properly conducting statistical significance tests. Our results show no significant advantage of GLEU over MaxMatch (M2), contradicting previous studies that claim GLEU to be superior. For a finer-grained analysis, we additionally evaluate these metrics for their agreement with human judgments at the sentence level. Our sentence-level analysis indicates that comparing GLEU and M2, one metric may be more useful than the other depending on the scenario. We further qualitatively analyze these metrics and our findings show that apart from being less interpretable and non-deterministic, GLEU also produces counter-intuitive scores in commonly occurring test examples."
W17-7513,"Keynote Lecture 2: Grammatical Error Correction: Past, Present and Future",2017,0,0,1,1,7314,hwee ng,Proceedings of the 14th International Conference on Natural Language Processing ({ICON}-2017),0,None
W17-5037,Connecting the Dots: Towards Human-Level Grammatical Error Correction,2017,26,16,2,1,20249,shamil chollampatt,Proceedings of the 12th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We build a grammatical error correction (GEC) system primarily based on the state-of-the-art statistical machine translation (SMT) approach, using task-specific features and tuning, and further enhance it with the modeling power of neural network joint models. The SMT-based system is weak in generalizing beyond patterns seen during training and lacks granularity below the word level. To address this issue, we incorporate a character-level SMT component targeting the misspelled words that the original SMT-based system fails to correct. Our final system achieves 53.14{\%} F 0.5 score on the benchmark CoNLL-2014 test set, an improvement of 3.62{\%} F 0.5 over the best previous published score."
P17-1036,An Unsupervised Neural Attention Model for Aspect Extraction,2017,25,80,3,1,10099,ruidan he,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Aspect extraction is an important and challenging task in aspect-based sentiment analysis. Existing works tend to apply variants of topic models on this task. While fairly successful, these methods usually do not produce highly coherent aspects. In this paper, we present a novel neural approach with the aim of discovering coherent aspects. The model improves coherence by exploiting the distribution of word co-occurrences through the use of neural word embeddings. Unlike topic models which typically assume independently generated words, word embedding models encourage words that appear in similar contexts to be located close to each other in the embedding space. In addition, we use an attention mechanism to de-emphasize irrelevant words during training, further improving the coherence of aspects. Experimental results on real-life datasets demonstrate that our approach discovers more meaningful and coherent aspects, and substantially outperforms baseline methods on several evaluation tasks."
W16-4214,Automated Anonymization as Spelling Variant Detection,2016,7,0,2,0,23918,steven yuwono,Proceedings of the Clinical Natural Language Processing Workshop ({C}linical{NLP}),0,"The issue of privacy has always been a concern when clinical texts are used for research purposes. Personal health information (PHI) (such as name and identification number) needs to be removed so that patients cannot be identified. Manual anonymization is not feasible due to the large number of clinical texts to be anonymized. In this paper, we tackle the task of anonymizing clinical texts written in sentence fragments and which frequently contain symbols, abbreviations, and misspelled words. Our clinical texts therefore differ from those in the i2b2 shared tasks which are in prose form with complete sentences. Our clinical texts are also part of a structured database which contains patient name and identification number in structured fields. As such, we formulate our anonymization task as spelling variant detection, exploiting patients{'} personal information in the structured fields to detect their spelling variants in clinical texts. We successfully anonymized clinical texts consisting of more than 200 million words, using minimum edit distance and regular expression patterns."
K16-2001,{C}o{NLL} 2016 Shared Task on Multilingual Shallow Discourse Parsing,2016,35,36,2,0,10294,nianwen xue,Proceedings of the {C}o{NLL}-16 shared task,0,"The CoNLL-2016 Shared Task is the second edition of the CoNLL-2015 Shared Task, now on Multilingual Shallow discourse parsing. Similar to the 2015 task, the goal of the shared task is to identify individual discourse relations that are present in natural language text. Given a natural language text, participating teams are asked to locate the discourse connectives (explicit or implicit) and their arguments as well as predicting the sense of the discourse connectives. Based on the success of the previous year, we continued to ask participants to deploy their systems on TIRA, a web-based platform on which participants can run their systems on the test data for evaluation. This evaluation methodology preserves the integrity of the shared task. We have also made a few changes and additions in the 2016 shared task based on the feedback from 2015. The first is that teams could choose to carry out the task on Chinese texts, or English texts, or both. We have also allowed participants to focus on parts of the shared task (rather than the whole thing) as a typical system requires substantial investment of effort. Finally, we have modified the scorer so that it can report results based on partial matches of the arguments. 23 teams participated in this yearxe2x80x99s shared task, using a wide variety of approaches. In this overview paper, we present the task definition, the training and test sets, and the evaluation protocol and metric used during this shared task. We also summarize the different approaches adopted by the participating teams, and present the evaluation results. The evaluation data sets and the scorer will serve as a benchmark for future research on shallow discourse parsing."
J16-2004,Source Language Adaptation Approaches for Resource-Poor Machine Translation,2016,42,8,3,1,35498,pidong wang,Computational Linguistics,0,"Most of the world languages are resource-poor for statistical machine translation; still, many of them are actually related to some resource-rich language. Thus, we propose three novel, language-independent approaches to source language adaptation for resource-poor statistical machine translation. Specifically, we build improved statistical machine translation models from a resource-poor language POOR into a target language TGT by adapting and using a large bitext for a related resource-rich language RICH and the same target language TGT. We assume a small POOR-TGT bitext from which we learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the resource-rich and the resource-poor language. Our work is of importance for resource-poor machine translation because it can provide a useful guideline for people building machine translation systems for resource-poor languages.n n Our experiments for Indonesian/Malay-English translation show that using the large adapted resource-rich bitext yields 7.26 BLEU points of improvement over the unadapted one and 3.09 BLEU points over the original small bitext. Moreover, combining the small POOR-TGT bitext with the adapted bitext outperforms the corresponding combinations with the unadapted bitext by 1.93-3.25 BLEU points. We also demonstrate the applicability of our approaches to other languages and domains."
D16-1193,A Neural Approach to Automated Essay Scoring,2016,17,60,2,1,35593,kaveh taghipour,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
D16-1195,Adapting Grammatical Error Correction Based on the Native Language of Writers with Neural Network Joint Models,2016,26,7,3,1,20249,shamil chollampatt,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
P15-1068,How Far are We from Fully Automatic High Quality Grammatical Error Correction?,2015,20,31,2,0,10020,christopher bryant,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"In this paper, we first explore the role of inter-annotator agreement statistics in grammatical error correction and conclude that they are less informative in fields where there may be more than one correct answer. We next created a dataset of 50 student essays, each corrected by 10 different annotators for all error types, and investigated how both human and GEC system scores vary when different combinations of these annotations are used as the gold standard. Upon learning that even humans are unable to score higher than 75% F0.5, we propose a new metric based on the ratio between human and system performance. We also use this method to investigate the extent to which annotators agree on certain error categories, and find that similar results can be obtained from a smaller subset of just 10 essays."
N15-1035,Semi-Supervised Word Sense Disambiguation Using Word Embeddings in General and Specific Domains,2015,33,54,2,1,35593,kaveh taghipour,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"One of the weaknesses of current supervised word sense disambiguation (WSD) systems is that they only treat a word as a discrete entity. However, a continuous-space representation of words (word embeddings) can provide valuable information and thus improve generalization accuracy. Since word embeddings are typically obtained from unlabeled data using unsupervised methods, this method can be seen as a semi-supervised word sense disambiguation approach. This paper investigates two ways of incorporating word embeddings in a word sense disambiguation setting and evaluates these two methods on some SensEval/SemEval lexical sample and all-words tasks and also a domain-specific lexical sample task. The obtained results show that such representations consistently improve the accuracy of the selected supervised WSD system. Moreover, our experiments on a domainspecific dataset show that our supervised baseline system beats the best knowledge-based systems by a large margin."
K15-2001,The {C}o{NLL}-2015 Shared Task on Shallow Discourse Parsing,2015,42,69,2,0,10294,nianwen xue,Proceedings of the Nineteenth Conference on Computational Natural Language Learning - Shared Task,0,"The CoNLL-2015 Shared Task is on Shallow Discourse Parsing, a task focusing on identifying individual discourse relations that are present in a natural language text. A discourse relation can be expressed explicitly or implicitly, and takes two arguments realized as sentences, clauses, or in some rare cases, phrases. Sixteen teams from three continents participated in this task. For the first time in the history of the CoNLL shared tasks, participating teams, instead of running their systems on the test set and submitting the output, were asked to deploy their systems on a remote virtual machine and use a web-based evaluation platform to run their systems on the test set. This meant they were unable to actually see the data set, thus preserving its integrity and ensuring its replicability. In this paper, we present the task definition, the training and test sets, and the evaluation protocol and metric used during this shared task. We also summarize the different approaches adopted by the participating teams, and present the evaluation results. The evaluation data sets and the scorer will serve as a benchmark for future research on shallow discourse parsing."
K15-1037,One Million Sense-Tagged Instances for Word Sense Disambiguation and Induction,2015,27,16,2,1,35593,kaveh taghipour,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"Supervised word sense disambiguation (WSD) systems are usually the best performing systems when evaluated on standard benchmarks. However, these systems need annotated training data to function properly. While there are some publicly available open source WSD systems, very few large annotated datasets are available to the research community. The two main goals of this paper are to extract and annotate a large number of samples and release them for public use, and also to evaluate this dataset against some word sense disambiguation and induction tasks. We show that the open source IMS WSD system trained on our dataset achieves stateof-the-art results in standard disambiguation tasks and a recent word sense induction task, outperforming several task submissions and strong baselines."
D15-1049,Flexible Domain Adaptation for Automated Essay Scoring Using Correlated Linear Regression,2015,23,29,3,1,28849,peter phandi,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,Most of the current automated essay scoring (AES) systems are trained using manually graded essays from a specific prompt. These systems experience a drop in accuracy when used to grade an essay from a different prompt. Obtaining a large number of manually graded essays each time a new prompt is introduced is costly and not viable. We propose domain adaptation as a solution to adapt an AES system from an initial prompt to a new prompt. We also propose a novel domain adaptation technique that uses Bayesian linear ridge regression. We evaluate our domain adaptation technique on the publicly available Automated Student Assessment Prize (ASAP) dataset and show that our proposed technique is a competitive default domain adaptation algorithm for the AES task.
W14-1701,The {C}o{NLL}-2014 Shared Task on Grammatical Error Correction,2014,29,179,1,1,7314,hwee ng,Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task,0,"The CoNLL-2014 shared task was devoted to grammatical error correction of all error types. In this paper, we give the task definition, present the data sets, and describe the evaluation metric and scorer used in the shared task. We also give an overview of the various approaches adopted by the participating teams, and present the evaluation results. Compared to the CoNLL2013 shared task, we have introduced the following changes in CoNLL-2014: (1) A participating system is expected to detect and correct grammatical errors of all types, instead of just the five error types in CoNLL-2013; (2) The evaluation metric was changed from F1 to F0.5, to emphasize precision over recall; and (3) We have two human annotators who independently annotated the test essays, compared to just one human annotator in CoNLL-2013."
W14-1104,Domain Adaptation with Active Learning for Coreference Resolution,2014,24,4,2,1,38781,shanheng zhao,Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi),0,"In the literature, most prior work on coreference resolution centered on the newswire domain. Although a coreference resolution system trained on the newswire domain performs well on newswire texts, there is a huge performance drop when it is applied to the biomedical domain. In this paper, we present an approach integrating domain adaptation with active learning to adapt coreference resolution from the newswire domain to the biomedical domain. We explore the effect of domain adaptation, active learning, and target domain instance weighting for coreference resolution. Experimental results show that domain adaptation with active learning and target domain instance weighting achieves performance on MEDLINE abstracts similar to a system trained on coreference annotation of only target domain training instances, but with a greatly reduced number of target domain training instances that we need to annotate."
D14-1008,A Constituent-Based Approach to Argument Labeling with Joint Inference in Discourse Parsing,2014,16,22,2,1,6709,fang kong,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Discourse parsing is a challenging task and plays a critical role in discourse analysis. In this paper, we focus on labeling full argument spans of discourse connectives in the Penn Discourse Treebank (PDTB). Previous studies cast this task as a linear tagging or subtree extraction problem. In this paper, we propose a novel constituent-based approach to argument labeling, which integrates the advantages of both linear tagging and subtree extraction. In particular, the proposed approach unifies intra- and intersentence cases by treating the immediately preceding sentence as a special constituent. Besides, a joint inference mechanism is introduced to incorporate global information across arguments into our constituent-based approach via integer linear programming. Evaluation on PDTB shows significant performance improvements of our constituent-based approach over the best state-of-the-art system. It also shows the effectiveness of our joint inference mechanism in modeling global information across arguments."
D14-1013,Combining Punctuation and Disfluency Prediction: An Empirical Study,2014,25,3,3,0,28441,xuancong wang,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Punctuation prediction and disfluency prediction can improve downstream natural language processing tasks such as machine translation and information extraction. Combining the two tasks can potentially improve the efficiency of the overall pipeline system and reduce error propagation. In this work 1 , we compare various methods for combining punctuation prediction (PU) and disfluency prediction (DF) on the Switchboard corpus. We compare an isolated prediction approach with a cascade approach, a rescoring approach, and three joint model approaches. For the cascade approach, we show that the soft cascade method is better than the hard cascade method. We also use the cascade models to generate an n-best list, use the bi-directional cascade models to perform rescoring, and compare that with the results of the cascade models. For the joint model approach, we compare mixedlabel Linear-chain Conditional Random Field (LCRF), cross-product LCRF and 2layer Factorial Conditional Random Field (FCRF) with soft-cascade LCRF. Our results show that the various methods linking the two tasks are not significantly different from one another, although they perform better than the isolated prediction method by 0.5xe2x80x901.5% in the F1 score. Moreover, the clique order of features also shows a marked difference."
D14-1102,System Combination for Grammatical Error Correction,2014,45,24,3,0,325,raymond susanto,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Different approaches to high-quality grammatical error correction have been proposed recently, many of which have their own strengths and weaknesses. Most of these approaches are based on classification or statistical machine translation (SMT). In this paper, we propose to combine the output from a classification-based system and an SMT-based system to improve the correction quality. We adopt the system combination technique of Heafield and Lavie (2010). We achieve an F0.5 score of 39.39% on the test set of the CoNLL-2014 shared task, outperforming the best system in the shared task."
C14-1138,A Beam-Search Decoder for Disfluency Detection,2014,15,3,2,0,28441,xuancong wang,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"In this paper 1 , we present a novel beam-search decoder for disfluency detection. We first propose node-weighted max-margin Markov networks (M3N) to boost the performance on words belonging to specific part-of-speech (POS) classes. Next, we show the importance of measuring the quality of cleaned-up sentences and performing multiple passes of disfluency detection. Finally, we propose using the beam-search decoder to combine multiple discriminative models such as M3N and multiple generative models such as language models (LM) and perform multiple passes of disfluency detection. The decoder iteratively generates new hypotheses from current hypotheses by making incremental corrections to the current sentence based on certain patterns as well as information provided by existing models. It then rescores each hypothesis based on features of lexical correctness and fluency. Our decoder achieves an edit-word F1 score higher than all previous published scores on the same data set, both with and without using external sources of information."
W13-3601,The {C}o{NLL}-2013 Shared Task on Grammatical Error Correction,2013,20,104,1,1,7314,hwee ng,Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task,0,"The CoNLL-2013 shared task was devoted to grammatical error correction. In this paper, we give the task definition, present the data sets, and describe the evaluation metric and scorer used in the shared task. We also give an overview of the various approaches adopted by the participating teams, and present the evaluation results."
W13-3516,Towards Robust Linguistic Analysis using {O}nto{N}otes,2013,41,68,4,0,11322,sameer pradhan,Proceedings of the Seventeenth Conference on Computational Natural Language Learning,0,"Large-scale linguistically annotated corpora have played a crucial role in advancing the state of the art of key natural language technologies such as syntactic, semantic and discourse analyzers, and they serve as training data as well as evaluation benchmarks. Up till now, however, most of the evaluation has been done on monolithic corpora such as the Penn Treebank, the Proposition Bank. As a result, it is still unclear how the state-of-the-art analyzers perform in general on data from a variety of genres or domains. The completion of the OntoNotes corpus, a large-scale, multi-genre, multilingual corpus manually annotated with syntactic, semantic and discourse information, makes it possible to perform such an evaluation. This paper presents an analysis of the performance of publicly available, state-of-the-art tools on all layers and languages in the OntoNotes v5.0 corpus. This should set the benchmark for future development of various NLP components in syntax and semantics, and possibly encourage research towards an integrated system that makes use of the various layers jointly to improve overall performance."
W13-1703,Building a Large Annotated Corpus of Learner {E}nglish: The {NUS} Corpus of Learner {E}nglish,2013,16,147,2,1,25568,daniel dahlmeier,Proceedings of the Eighth Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"We describe the NUS Corpus of Learner English (NUCLE), a large, fully annotated corpus of learner English that is freely available for research purposes. The goal of the corpus is to provide a large data resource for the development and evaluation of grammatical error correction systems. Although NUCLE has been available for almost two years, there has been no reference paper that describes the corpus in detail. In this paper, we address this need. We describe the annotation schema and the data collection and annotation process of NUCLE. Most importantly, we report on an unpublished study of annotator agreement for grammatical error correction. Finally, we present statistics on the distribution of grammatical errors in the NUCLE corpus."
P13-1143,Grammatical Error Correction Using Integer Linear Programming,2013,23,13,2,0,7967,yuanbin wu,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We propose a joint inference algorithm for grammatical error correction. Different from most previous work where different error types are corrected independently, our proposed inference process considers all possible errors in a uni ed framework. We use integer linear programming (ILP) to model the inference process, which can easily incorporate both the power of existing error classi ers and prior knowledge on grammatical error correction. Experimental results on the Helping Our Own shared task show that our method is competitive with state-of-the-art systems."
N13-1050,A Beam-Search Decoder for Normalization of Social Media Text with Application to Machine Translation,2013,33,26,2,1,35498,pidong wang,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Social media texts are written in an informal style, which hinders other natural language processing (NLP) applications such as machine translation. Text normalization is thus important for processing of social media text. Previous work mostly focused on normalizing words by replacing an informal word with its formal form. In this paper, to further improve other downstream NLP applications, we argue that other normalization operations should also be performed, e.g., missing word recovery and punctuation correction. A novel beam-search decoder is proposed to effectively integrate various normalization operations. Empirical results show that our system obtains statistically significant improvements over two strong baselines in both normalization and translation tasks, for both Chinese and English."
D13-1028,Exploiting Zero Pronouns to Improve {C}hinese Coreference Resolution,2013,22,10,2,1,6709,fang kong,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"Coreference resolution plays a critical role in discourse analysis. This paper focuses on exploiting zero pronouns to improve Chinese coreference resolution. In particular, a simplified semantic role labeling framework is proposed to identify clauses and to detect zero pronouns effectively, and two effective methods (refining syntactic parser and refining learning example generation) are employed to exploit zero pronouns for Chinese coreference resolution. Evaluation on the CoNLL-2012 shared task data set shows that zero pronouns can significantly improve Chinese coreference resolution."
W12-2025,{NUS} at the {HOO} 2012 Shared Task,2012,19,19,2,1,25568,daniel dahlmeier,Proceedings of the Seventh Workshop on Building Educational Applications Using {NLP},0,"This paper describes the submission of the National University of Singapore (NUS) to the HOO 2012 shared task. Our system uses a pipeline of confidence-weighted linear classifiers to correct determiner and preposition errors. Our system achieves the highest correction F1 score on the official test set among all 14 participating teams, based on gold-standard edits both before and after revision."
P12-1029,Word Sense Disambiguation Improves Information Retrieval,2012,32,54,2,1,40855,zhi zhong,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Previous research has conflicting conclusions on whether word sense disambiguation (WSD) systems can improve information retrieval (IR) performance. In this paper, we propose a method to estimate sense distributions for short queries. Together with the senses predicted for words in documents, we propose a novel approach to incorporate word senses into the language modeling approach to IR and also exploit the integration of synonym relations. Our experimental results on standard TREC collections show that using the word senses tagged by a supervised WSD system, we obtain significant improvements over a state-of-the-art IR system."
P12-1097,Character-Level Machine Translation Evaluation for Languages with Ambiguous Word Boundaries,2012,17,7,2,1,8468,chang liu,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this work, we introduce the TESLA-CELAB metric (Translation Evaluation of Sentences with Linear-programming-based Analysis -- Character-level Evaluation for Languages with Ambiguous word Boundaries) for automatic machine translation evaluation. For languages such as Chinese where words usually have meaningful internal structure and word boundaries are often fuzzy, TESLA-CELAB acknowledges the advantage of character-level evaluation over word-level evaluation. By reformulating the problem in the linear programming framework, TESLA-CELAB addresses several drawbacks of the character-level metrics, in particular the modeling of synonyms spanning multiple characters. We show empirically that TESLA-CELAB significantly outperforms character-level BLEU in the English-Chinese translation evaluation tasks."
P12-1106,Combining Coherence Models and Machine Translation Evaluation Metrics for Summarization Evaluation,2012,21,21,3,1,40257,ziheng lin,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"An ideal summarization system should produce summaries that have high content coverage and linguistic quality. Many state-of-the-art summarization systems focus on content coverage by extracting content-dense sentences from source articles. A current research focus is to process these sentences so that they read fluently as a whole. The current AESOP task encourages research on evaluating summaries on content, readability, and overall responsiveness. In this work, we adapt a machine translation metric to measure content coverage, apply an enhanced discourse coherence model to evaluate summary readability, and combine both in a trained regression model to evaluate overall responsiveness. The results show significantly improved performance over AESOP 2011 submitted metrics."
N12-1067,Better Evaluation for Grammatical Error Correction,2012,4,117,2,1,25568,daniel dahlmeier,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present a novel method for evaluating grammatical error correction. The core of our method, which we call MaxMatch (M2), is an algorithm for efficiently computing the sequence of phrase-level edits between a source sentence and a system hypothesis that achieves the highest overlap with the gold-standard annotation. This optimal edit sequence is subsequently scored using F1 measure. We test our M2 scorer on the Helping Our Own (HOO) shared task data and show that our method results in more accurate evaluation for grammatical error correction."
D12-1027,Source Language Adaptation for Resource-Poor Machine Translation,2012,21,14,3,1,35498,pidong wang,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"We propose a novel, language-independent approach for improving machine translation from a resource-poor language to X by adapting a large bi-text for a related resource-rich language and X (the same target language). We assume a small bi-text for the resource-poor language to X pair, which we use to learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the resource-rich and the resource-poor language; we then adapt the former to get closer to the latter. Our experiments for Indonesian/Malay--English translation show that using the large adapted resource-rich bi-text yields 6.7 BLEU points of improvement over the unadapted one and 2.6 BLEU points over the original small bi-text. Moreover, combining the small bi-text with the adapted bi-text outperforms the corresponding combinations with the unadapted bi-text by 1.5--3 BLEU points. We also demonstrate applicability to other languages and domains."
D12-1052,A Beam-Search Decoder for Grammatical Error Correction,2012,32,43,2,1,25568,daniel dahlmeier,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"We present a novel beam-search decoder for grammatical error correction. The decoder iteratively generates new hypothesis corrections from current hypotheses and scores them based on features of grammatical correctness and fluency. These features include scores from discriminative classifiers for specific error categories, such as articles and prepositions. Unlike all previous approaches, our method is able to perform correction of whole sentences with multiple and interacting errors while still taking advantage of powerful existing classifier approaches. Our decoder achieves an F1 correction score significantly higher than all previous published scores on the Helping Our Own (HOO) shared task data set."
W11-2841,{NUS} at the {HOO} 2011 Pilot Shared Task,2011,6,5,2,1,25568,daniel dahlmeier,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"This paper describes the submission of the National University of Singapore (NUS) to the Helping Our Own (HOO) Pilot Shared Task. Our system targets spelling, article, and preposition errors in a sequential processing pipeline."
W11-2106,{TESLA} at {WMT} 2011: Translation Evaluation and Tunable Metric,2011,14,16,3,1,25568,daniel dahlmeier,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the submission from the National University of Singapore to the WMT 2011 Shared Evaluation Task and the Tunable Metric Task. Our entry is TESLA in three different configurations: TESLA-M, TESLA-F, and the new TESLA-B."
P11-2028,Automatic Evaluation of {C}hinese Translation Output: Word-Level or Character-Level?,2011,17,14,3,0,11675,maoxi li,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"Word is usually adopted as the smallest unit in most tasks of Chinese language processing. However, for automatic evaluation of the quality of Chinese translation output when translating from other languages, either a word-level approach or a character-level approach is possible. So far, there has been no detailed study to compare the correlations of these two approaches with human assessment. In this paper, we compare word-level metrics with character-level metrics on the submitted output of English-to-Chinese translation systems in the IWSLT'08 CT-EC and NIST'08 EC tasks. Our experimental results reveal that character-level metrics correlate with human assessment better than word-level metrics. Our analysis suggests several key reasons behind this finding."
P11-1092,Grammatical Error Correction with Alternating Structure Optimization,2011,28,60,2,1,25568,daniel dahlmeier,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present a novel approach to grammatical error correction based on Alternating Structure Optimization. As part of our work, we introduce the NUS Corpus of Learner English (NUCLE), a fully annotated one million words corpus of learner English available for research purposes. We conduct an extensive evaluation for article and preposition errors using various feature sets. Our experiments show that our approach outperforms two baselines trained on non-learner text and learner text, respectively. Our approach also outperforms two commercial grammar checking software packages."
P11-1100,Automatically Evaluating Text Coherence Using Discourse Relations,2011,20,91,2,1,40257,ziheng lin,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present a novel model to represent and assess the discourse coherence of text. Our model assumes that coherent text implicitly favors certain types of discourse relation transitions. We implement this model and apply it towards the text ordering ranking task, which aims to discern an original text from a permuted ordering of its sentences. The experimental results demonstrate that our model is able to significantly outperform the state-of-the-art coherence model by Barzilay and Lapata (2005), reducing the error rate of the previous approach by an average of 29% over three data sets against human upper bounds. We further show that our model is synergistic with the previous approach, demonstrating an error reduction of 73% when the features from both models are combined for the task."
P11-1130,Translating from Morphologically Complex Languages: A Paraphrase-Based Approach,2011,31,10,2,0.553923,1636,preslav nakov,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We propose a novel approach to translating from a morphologically complex language. Unlike previous research, which has targeted word inflections and concatenations, we focus on the pairwise relationship between morphologically related words, which we treat as potential paraphrases and handle using paraphrasing techniques at the word, phrase, and sentence level. An important advantage of this framework is that it can cope with derivational morphology, which has so far remained largely beyond the capabilities of statistical machine translation systems. Our experiments translating from Malay, whose morphology is mostly derivational, into English show significant improvements over rivaling approaches based on five automatic evaluation measures (for 320,000 sentence pairs; 9.5 million English word tokens)."
D11-1010,Correcting Semantic Collocation Errors with {L}1-induced Paraphrases,2011,39,48,2,1,25568,daniel dahlmeier,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We present a novel approach for automatic collocation error correction in learner English which is based on paraphrases extracted from parallel corpora. Our key assumption is that collocation errors are often caused by semantic similarity in the first language (L1-language) of the writer. An analysis of a large corpus of annotated learner English confirms this assumption. We evaluate our approach on real-world learner data and show that L1-induced paraphrases outperform traditional approaches based on edit distance, homophones, and WordNet synonyms."
D11-1035,Better Evaluation Metrics Lead to Better Machine Translation,2011,23,28,3,1,8468,chang liu,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"Many machine translation evaluation metrics have been proposed after the seminal BLEU metric, and many among them have been found to consistently outperform BLEU, demonstrated by their better correlations with human judgment. It has long been the hope that by tuning machine translation systems against these new generation metrics, advances in automatic machine translation evaluation can lead directly to advances in automatic machine translation. However, to date there has been no unambiguous report that these new metrics can improve a state-of-the-art machine translation system over its BLEU-tuned baseline.n n In this paper, we demonstrate that tuning Joshua, a hierarchical phrase-based statistical machine translation system, with the TESLA metrics results in significantly better human-judged translation quality than the BLEU-tuned baseline. TESLA-M in particular is simple and performs well in practice on large datasets. We release all our implementation under an open source license. It is our hope that this work will encourage the machine translation community to finally move away from BLEU as the unquestioned default and to consider the new generation metrics when tuning their systems."
D11-1149,A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions,2011,42,40,2,1,4057,wei lu,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus. The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences. Sentences can then be generated based on such grammar rules with a log-linear model. To acquire such grammar rules automatically in an unsupervised manner, we also propose a novel approach with a generative model, which maps from sub-expressions of logical forms to word sequences in natural language sentences. Experiments on benchmark datasets for both English and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation."
W10-1754,{TESLA}: Translation Evaluation of Sentences with Linear-Programming-Based Analysis,2010,23,29,3,1,8468,chang liu,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"We present TESLA-M and TESLA, two novel automatic machine translation evaluation metrics with state-of-the-art performances. TESLA-M builds on the success of METEOR and MaxSim, but employs a more expressive linear programming framework. TESLA further exploits parallel texts to build a shallow semantic representation. We evaluate both on the WMT 2009 shared evaluation task and show that they outperform all participating systems in most tasks."
P10-4014,It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text,2010,22,173,2,1,40855,zhi zhong,Proceedings of the {ACL} 2010 System Demonstrations,0,"Word sense disambiguation (WSD) systems based on supervised learning achieved the best performance in SensEval and SemEval workshops. However, there are few publicly available open source WSD systems. This limits the use of WSD in other applications, especially for researchers whose research interests are not in WSD.n n In this paper, we present IMS, a supervised English all-words WSD system. The flexible framework of IMS allows users to integrate different preprocessing tools, additional features, and different classifiers. By default, we use linear support vector machines as the classifier with multiple knowledge-based features. In our implementation, IMS achieves state-of-the-art results on several SensEval and SemEval tasks."
P10-1113,Joint Syntactic and Semantic Parsing of {C}hinese,2010,30,31,3,0,9182,junhui li,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"This paper explores joint syntactic and semantic parsing of Chinese to further improve the performance of both syntactic and semantic parsing, in particular the performance of semantic parsing (in this paper, semantic role labeling). This is done from two levels. Firstly, an integrated parsing approach is proposed to integrate semantic parsing into the syntactic parsing process. Secondly, semantic information generated by semantic parsing is incorporated into the syntactic parsing model to better capture semantic information in syntactic parsing. Evaluation on Chinese TreeBank, Chinese PropBank, and Chinese NomBank shows that our integrated parsing approach outperforms the pipeline parsing approach on n-best parse trees, a natural extension of the widely used pipeline parsing approach on the top-best parse tree. Moreover, it shows that incorporating semantic role-related information into the syntactic parsing model significantly improves the performance of both syntactic parsing and semantic parsing. To our best knowledge, this is the first research on exploring syntactic parsing and semantic role labeling for both verbal and nominal predicates in an integrated way."
D10-1018,Better Punctuation Prediction with Dynamic Conditional Random Fields,2010,31,54,2,1,4057,wei lu,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"This paper focuses on the task of inserting punctuation symbols into transcribed conversational speech texts, without relying on prosodic cues. We investigate limitations associated with previous methods, and propose a novel approach based on dynamic conditional random fields. Different from previous work, our proposed approach is designed to jointly perform both sentence boundary and sentence type prediction, and punctuation prediction on speech utterances.n n We performed evaluations on a transcribed conversational speech domain consisting of both English and Chinese texts. Empirical results show that our method outperforms an approach based on linear-chain conditional random fields and other previous approaches."
D10-1090,{PEM}: A Paraphrase Evaluation Metric Exploiting Parallel Texts,2010,39,26,3,1,8468,chang liu,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"We present PEM, the first fully automatic metric to evaluate the quality of paraphrases, and consequently, that of paraphrase generation systems. Our metric is based on three criteria: adequacy, fluency, and lexical dissimilarity. The key component in our metric is a robust and shallow semantic similarity measure based on pivot language N-grams that allows us to approximate adequacy independently of lexical similarity. Human evaluation shows that PEM achieves high correlation with human judgments."
C10-1147,Maximum Metric Score Training for Coreference Resolution,2010,24,4,2,1,38781,shanheng zhao,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"A large body of prior research on coreference resolution recasts the problem as a two-class classification problem. However, standard supervised machine learning algorithms that minimize classification errors on the training instances do not always lead to maximizing the F-measure of the chosen evaluation metric for coreference resolution. In this paper, we propose a novel approach comprising the use of instance weighting and beam search to maximize the evaluation metric score on the training corpus during training. Experimental results show that this approach achieves significant improvement over the state-of-the-art. We report results on standard benchmark corpora (two MUC corpora and three ACE corpora), when evaluated using the link-based MUC metric and the mention-based B-CUBED metric."
W09-0412,{NUS} at {WMT}09: Domain Adaptation Experiments for {E}nglish-{S}panish Machine Translation of News Commentary Text,2009,20,5,2,0.553923,1636,preslav nakov,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,"We describe the system developed by the team of the National University of Singapore for English to Spanish machine translation of News Commentary text for the WMT09 Shared Translation Task. Our approach is based on domain adaptation, combining a small in-domain News Commentary bi-text and a large out-of-domain one from the Europarl corpus, from which we built and combined two separate phrase tables. We further combined two language models (in-domain and out-of-domain), and we experimented with cognates, improved tokenization and recasing, achieving the highest lowercased NIST score of 6.963 and the second best lowercased Bleu score of 24.91% for training without using additional external data for English-to-Spanish translation at the shared task."
D09-1036,Recognizing Implicit Discourse Relations in the {P}enn {D}iscourse {T}reebank,2009,20,187,3,1,40257,ziheng lin,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"We present an implicit discourse relation classifier in the Penn Discourse Treebank (PDTB). Our classifier considers the context of the two arguments, word pair information, as well as the arguments' internal constituent and dependency parses. Our results on the PDTB yields a significant 14.1% improvement over the baseline. In our error analysis, we discuss four challenges in recognizing implicit relations in the PDTB."
D09-1042,Natural Language Generation with Tree Conditional Random Fields,2009,24,28,2,1,4057,wei lu,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents an effective method for generating natural language sentences from their underlying meaning representations. The method is built on top of a hybrid tree representation that jointly encodes both the meaning representation as well as the natural language in a tree structure. By using a tree conditional random field on top of the hybrid tree representation, we are able to explicitly model phrase-level dependencies amongst neighboring natural language phrases and meaning representation components in a simple and natural way. We show that the additional dependencies captured by the tree conditional random field allows it to perform better than directly inverting a previously developed hybrid tree semantic parser. Furthermore, we demonstrate that the model performs better than a previous state-of-the-art natural language generation model. Experiments are performed on two benchmark corpora with standard automatic evaluation metrics."
D09-1047,Joint Learning of Preposition Senses and Semantic Roles of Prepositional Phrases,2009,17,23,2,1,25568,daniel dahlmeier,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"The sense of a preposition is related to the semantics of its dominating prepositional phrase. Knowing the sense of a preposition could help to correctly classify the semantic role of the dominating prepositional phrase and vice versa. In this paper, we propose a joint probabilistic model for word sense disambiguation of prepositions and semantic role labeling of prepositional phrases. Our experiments on the PropBank corpus show that jointly learning the word sense and the semantic role leads to an improvement over state-of-the-art individual classifier models on the two tasks."
D09-1141,Improved Statistical Machine Translation for Resource-Poor Languages Using Related Resource-Rich Languages,2009,74,57,2,0.553923,1636,preslav nakov,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"We propose a novel language-independent approach for improving statistical machine translation for resource-poor languages by exploiting their similarity to resource-rich ones. More precisely, we improve the translation from a resource-poor source language X1 into a resource-rich language Y given a bi-text containing a limited number of parallel sentences for X1-Y and a larger bi-text for X2-Y for some resource-rich language X2 that is closely related to X1. The evaluation for Indonesianxe2x86x92English (using Malay) and Spanishxe2x86x92English (using Portuguese and pretending Spanish is resource-poor) shows an absolute gain of up to 1.35 and 3.37 Bleu points, respectively, which is an improvement over the rivaling approaches, while using much less additional data."
2009.iwslt-evaluation.14,The {NUS} statistical machine translation system for {IWSLT} 2009,2009,13,2,4,0.553923,1636,preslav nakov,Proceedings of the 6th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We describe the system developed by the team of the National University of Singapore for the Chinese-English BTEC task of the IWSLT 2009 evaluation campaign. We adopted a state-of-the-art phrase-based statistical machine translation approach and focused on experiments with different Chinese word segmentation standards. In our official submission, we trained a separate system for each segmenter and we combined the outputs in a subsequent re-ranking step. Given the small size of the training data, we further re-trained the system on the development data after tuning. The evaluation results show that both strategies yield sizeable and consistent improvements in translation quality."
P08-1007,{MAXSIM}: A Maximum Similarity Metric for Machine Translation Evaluation,2008,15,66,2,1,17052,yee chan,Proceedings of ACL-08: HLT,1,"We propose an automatic machine translation (MT) evaluation metric that calculates a similarity score (based on precision and recall) of a pair of sentences. Unlike most metrics, we compute a similarity score between items across the two sentences. We then find a maximum weight matching between the items such that each item in one sentence is mapped to at most one item in the other sentence. This general framework allows us to use arbitrary similarity functions between items, and to incorporate different information in our comparison, such as n-grams, dependency relations, etc. When evaluated on data from the ACL-07 MT workshop, our proposed metric achieves higher correlation with human judgements than all 11 automatic MT evaluation metrics that were evaluated during the workshop."
D08-1064,Decomposability of Translation Metrics for Improved Evaluation and Efficient Algorithms,2008,31,43,4,0,3180,david chiang,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"Bleu is the de facto standard for evaluation and development of statistical machine translation systems. We describe three real-world situations involving comparisons between different versions of the same systems where one can obtain improvements in Bleu scores that are questionable or even absurd. These situations arise because Bleu lacks the property of decomposability, a property which is also computationally convenient for various applications. We propose a very conservative modification to Bleu and a cross between Bleu and word error rate that address these issues while improving correlation with human judgments."
D08-1082,A Generative Model for Parsing Natural Language to Meaning Representations,2008,20,121,2,1,4057,wei lu,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we present an algorithm for learning a generative model of natural language sentences together with their formal meaning representations with hierarchical structures. The model is applied to the task of mapping sentences to hierarchical representations of their underlying meaning. We introduce dynamic programming techniques for efficient training and decoding. In experiments, we demonstrate that the model, when coupled with a discriminative reranking technique, achieves state-of-the-art performance when tested on two publicly available corpora. The generative model degrades robustly when presented with instances that are different from those seen in training. This allows a notable improvement in recall compared to previous models."
D08-1105,Word Sense Disambiguation Using {O}nto{N}otes: {A}n Empirical Study,2008,28,21,2,1,40855,zhi zhong,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"The accuracy of current word sense disambiguation (WSD) systems is affected by the fine-grained sense inventory of WordNet as well as a lack of training examples. Using the WSD examples provided through OntoNotes, we conduct the first large-scale WSD evaluation involving hundreds of word types and tens of thousands of sense-tagged examples, while adopting a coarse-grained sense inventory. We show that though WSD systems trained with a large number of examples can obtain a high level of accuracy, they nevertheless suffer a substantial drop in accuracy when applied to a different domain. To address this issue, we propose combining a domain adaptation technique using feature augmentation with active learning. Our results show that this approach is effective in reducing the annotation effort required to adapt a WSD system to a new domain. Finally, we propose that one can maximize the dual benefits of reducing the annotation effort while ensuring an increase in WSD accuracy, by only performing active learning on the set of most frequently occurring word types."
S07-1010,{S}em{E}val-2007 Task 11: {E}nglish Lexical Sample Task via {E}nglish-{C}hinese Parallel Text,2007,7,11,1,1,7314,hwee ng,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"We made use of parallel texts to gather training and test examples for the English lexical sample task. Two tracks were organized for our task. The first track used examples gathered from an LDC corpus, while the second track used examples gathered from a Web corpus. In this paper, we describe the process of gathering examples from the parallel corpora, the differences with similar tasks in previous SENSEVAL evaluations, and present the results of participating systems."
S07-1054,{NUS}-{PT}: Exploiting Parallel Texts for Word Sense Disambiguation in the {E}nglish All-Words Tasks,2007,10,68,2,1,17052,yee chan,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"We participated in the SemEval-2007 coarse-grained English all-words task and fine-grained English all-words task. We used a supervised learning approach with SVM as the learning algorithm. The knowledge sources used include local collocations, parts-of-speech, and surrounding words. We gathered training examples from English-Chinese parallel corpora, SemCor, and DSO corpus. While the fine-grained sense inventory of WordNet was used to train our system employed for the fine-grained English all-words task, our system employed for the coarse-grained English all-words task was trained with the coarse-grained sense inventory released by the task organizers. Our scores (for both recall and precision) are 0.825 and 0.587 for the coarse-grained English all-words task and fine-grained English all-words task respectively. These scores put our systems in the first place for the coarse-grained English all-words task and the second place for the fine-grained English all-words task."
P07-1005,Word Sense Disambiguation Improves Statistical Machine Translation,2007,24,240,2,1,17052,yee chan,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"Recent research presents conflicting evidence on whether word sense disambiguation (WSD) systems can help to improve the performance of statistical machine translation (MT) systems. In this paper, we successfully integrate a state-of-the-art WSD system into a state-of-the-art hierarchical phrase-based MT system, Hiero. We show for the first time that integrating a WSD system improves the performance of a state-ofthe-art statistical MT system on an actual translation task. Furthermore, the improvement is statistically significant."
P07-1007,Domain Adaptation with Active Learning for Word Sense Disambiguation,2007,17,94,2,1,17052,yee chan,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"When a word sense disambiguation (WSD) system is trained on one domain but applied to a different domain, a drop in accuracy is frequently observed. This highlights the importance of domain adaptation for word sense disambiguation. In this paper, we first show that an active learning approach can be successfully used to perform domain adaptation of WSD systems. Then, by using the predominant sense predicted by expectation-maximization (EM) and adopting a count-merging technique, we improve the effectiveness of the original adaptation process achieved by the basic active learning approach."
P07-1027,Learning Predictive Structures for Semantic Role Labeling of {N}om{B}ank,2007,19,32,2,1,8468,chang liu,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"This paper presents a novel application of Alternating Structure Optimization (ASO) to the task of Semantic Role Labeling (SRL) of noun predicates in NomBank. ASO is a recently proposed linear multi-task learning algorithm, which extracts the common structures of multiple tasks to improve accuracy, via the use of auxiliary problems. In this paper, we explore a number of different auxiliary problems, and we are able to significantly improve the accuracy of the NomBank SRL task using this approach. To our knowledge, our proposed approach achieves the highest accuracy published to date on the English NomBank SRL task."
P07-1087,A Unified Tagging Approach to Text Normalization,2007,14,14,4,0,20203,conghui zhu,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"This paper addresses the issue of text normalization, an important yet often overlooked problem in natural language processing. By text normalization, we mean converting xe2x80x98informally inputtedxe2x80x99 text into the canonical form, by eliminating xe2x80x98noisesxe2x80x99 in the text and detecting paragraph and sentence boundaries in the text. Previously, text normalization issues were often undertaken in an ad-hoc fashion or studied separately. This paper first gives a formalization of the entire problem. It then proposes a unified tagging approach to perform the task using Conditional Random Fields (CRF). The paper shows that with the introduction of a small set of tags, most of the text normalization tasks can be performed within the approach. The accuracy of the proposed method is high, because the subtasks of normalization are interdependent and should be performed together. Experimental results on email data cleaning show that the proposed method significantly outperforms the approach of using cascaded models and that of employing independent models."
D07-1057,Identification and Resolution of {C}hinese Zero Pronouns: A Machine Learning Approach,2007,19,65,2,1,38781,shanheng zhao,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"In this paper, we present a machine learning approach to the identification and resolution of Chinese anaphoric zero pronouns. We perform both identification and resolution automatically, with two sets of easily computable features. Experimental results show that our proposed learning approach achieves anaphoric zero pronoun resolution accuracy comparable to a previous state-ofthe-art, heuristic rule-based approach. To our knowledge, our work is the first to perform both identification and resolution of Chinese anaphoric zero pronouns using a machine learning approach."
D07-1085,A Statistical Language Modeling Approach to Lattice-Based Spoken Document Retrieval,2007,23,12,3,0,49357,tee chia,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"Speech recognition transcripts are far from perfect; they are not of sufficient quality to be useful on their own for spoken document retrieval. This is especially the case for conversational speech. Recent efforts have tried to overcome this issue by using statistics from speech lattices instead of only the 1best transcripts; however, these efforts have invariably used the classical vector space retrieval model. This paper presents a novel approach to lattice-based spoken document retrieval using statistical language models: a statistical model is estimated for each document, and probabilities derived from the document models are directly used to measure relevance. Experimental results show that the lattice-based language modeling method outperforms both the language modeling retrieval method using only the 1-best transcripts, as well as a recently proposed lattice-based vector space retrieval method."
W06-1617,Semantic Role Labeling of {N}om{B}ank: A Maximum Entropy Approach,2006,19,46,2,0,49757,zheng jiang,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"This paper describes our attempt at NomBank-based automatic Semantic Role Labeling (SRL). NomBank is a project at New York University to annotate the argument structures for common nouns in the Penn Treebank II corpus. We treat the NomBank SRL task as a classification problem and explore the possibility of adapting features previously shown useful in PropBank-based SRL systems. Various NomBank-specific features are explored. On test section 23, our best system achieves F1 score of 72.73 (69.14) when correct (automatic) syntactic parse trees are used. To our knowledge, this is the first reported automatic NomBank SRL system."
P06-1012,Estimating Class Priors in Domain Adaptation for Word Sense Disambiguation,2006,19,54,2,1,17052,yee chan,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Instances of a word drawn from different domains may have different sense priors (the proportions of the different senses of a word). This in turn affects the accuracy of word sense disambiguation (WSD) systems trained and applied on different domains. This paper presents a method to estimate the sense priors of words drawn from a new domain, and highlights the importance of using well calibrated probabilities when performing these estimations. By using well calibrated probabilities, we are able to estimate the sense priors effectively to achieve significant improvements in WSD accuracy."
I05-3025,A Maximum Entropy Approach to {C}hinese Word Segmentation,2005,2,138,2,0,51005,jin low,Proceedings of the Fourth {SIGHAN} Workshop on {C}hinese Language Processing,0,"We participated in the Second International Chinese Word Segmentation Bakeoff. Specifically, we evaluated our Chinese word segmenter in the open track, on all four corpora, namely Academia Sinica (AS), City University of Hong Kong (CITYU), Microsoft Research (MSR), and Peking University (PKU). Based on a maximum entropy approach, our word segmenter achieved the highest F measure for AS, CITYU, and PKU, and the second highest for MSR. We found that the use of an external dictionary and additional training corpora of different segmentation standards helped to further improve segmentation accuracy. 1 Chinese Word Segmenter The Chinese word segmenter we built is similar to the maximum entropy word segmenter we employed in our previous work (Ng and Low, 2004). Our word segmenter uses a maximum entropy framework (Ratnaparkhi, 1998; Xue and Shen, 2003) and is trained on manually segmented sentences. It classifies each Chinese character given the features derived from its surrounding context. Each Chinese character can be assigned one of four possible boundary tags: s for a character that occurs as a single-character word, b for a character that begins a multi-character (i.e., two or more characters) word, e for a character that ends a multi-character word, and m for a character that is neither the first nor last in a multi-character word. Our implementation used the opennlp maximum entropy package v2.1.0 from sourceforge.1"
W04-3236,{C}hinese Part-of-Speech Tagging: One-at-a-Time or All-at-Once? Word-Based or Character-Based?,2004,11,139,1,1,7314,hwee ng,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,"Chinese part-of-speech (POS) tagging assigns one POS tag to each word in a Chinese sentence. However, since words are not demarcated in a Chinese sentence, Chinese POS tagging requires word segmentation as a prerequisite. We could perform Chinese POS tagging strictly after word segmentation (one-at-a-time approach), or perform both word segmentation and POS tagging in a combined, single step simultaneously (all-atonce approach). Also, we could choose to assign POS tags on a word-by-word basis, making use of word features in the surrounding context (word-based), or on a character-by-character basis with character features (character-based). This paper presents an in-depth study on such issues of processing architecture and feature representation for Chinese POS tagging, within a maximum entropy framework. We found that while the all-at-once, characterbased approach is the best, the one-at-a-time, character-based approach is a worthwhile compromise, performing only slightly worse in terms of accuracy, but taking shorter time to train and run. As part of our investigation, we also built a state-of-the-art Chinese word segmenter, which outperforms the best SIGHAN 2003 word segmenters in the closed track on 3 out of 4 test corpora."
W04-0834,Supervised Word Sense Disambiguation with Support Vector Machines and multiple knowledge sources,2004,10,87,2,1,32794,yoong lee,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
C04-1089,Mining New Word Translations from Comparable Corpora,2004,14,82,2,0,52374,li shao,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"New words such as names, technical terms, etc appear frequently. As such, the bilingual lexicon of a machine translation system has to be constantly updated with these new word translations. Comparable corpora such as news documents of the same period from different news agencies are readily available. In this paper, we present a new approach to mining new word translations from comparable corpora, by using context information to complement transliteration information. We evaluated our approach on six months of Chinese and English Gigaword corpora, with encouraging results."
W03-0423,Named Entity Recognition with a Maximum Entropy Approach,2003,7,176,2,1,131,hai chieu,Proceedings of the Seventh Conference on Natural Language Learning at {HLT}-{NAACL} 2003,0,"The named entity recognition (NER) task involves identifying noun phrases that are names, and assigning a class to each name. This task has its origin from the Message Understanding Conferences (MUC) in the 1990s, a series of conferences aimed at evaluating systems that extract information from natural language texts. It became evident that in order to achieve good performance in information extraction, a system needs to be able to recognize names. A separate subtask on NER was created in MUC-6 and MUC-7 (Chinchor, 1998)."
P03-1028,Closing the Gap: Learning-Based Information Extraction Rivaling Knowledge-Engineering Methods,2003,17,44,2,1,131,hai chieu,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we present a learning approach to the scenario template task of information extraction, where information filling one template could come from multiple sentences. When tested on the MUC-4 task, our learning approach achieves accuracy competitive to the best of the MUC-4 systems, which were all built with manually engineered rules. Our analysis reveals that our use of full parsing and state-of-the-art learning algorithms have contributed to the good performance. To our knowledge, this is the first research to have demonstrated that a learning approach to the full-scale information extraction task could achieve performance rivaling that of the knowledge engineering approach."
P03-1058,Exploiting Parallel Texts for Word Sense Disambiguation: An Empirical Study,2003,19,141,1,1,7314,hwee ng,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"A central problem of word sense disambiguation (WSD) is the lack of manually sense-tagged data required for supervised learning. In this paper, we evaluate an approach to automatically acquire sense-tagged training data from English-Chinese parallel corpora, which are then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task. Our investigation reveals that this method of acquiring sense-tagged data is promising. On a subset of the most difficult SENSEVAL-2 nouns, the accuracy difference between the two approaches is only 14.0%, and the difference could narrow further to 6.5% if we disregard the advantage that manually sense-tagged data have in their sense coverage. Our analysis also highlights the importance of the issue of domain dependence in evaluating WSD programs."
W02-1006,An Empirical Evaluation of Knowledge Sources and Learning Algorithms for Word Sense Disambiguation,2002,27,214,2,1,32794,yoong lee,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"In this paper, we evaluate a variety of knowledge sources and supervised learning algorithms for word sense disambiguation on SENSEVAL-2 and SENSEVAL-1 data. Our knowledge sources include the part-of-speech of neighboring words, single words in the surrounding context, local collocations, and syntactic relations. The learning algorithms evaluated include Support Vector Machines (SVM), Naive Bayes, AdaBoost, and decision tree algorithms. We present empirical results showing the relative contribution of the component knowledge sources and the different learning algorithms. In particular, using all of these knowledge sources and SVM (i.e., a single learning algorithm) achieves accuracy higher than the best official scores on both SENSEVAL-2 and SENSEVAL-1 test data."
P02-1061,Teaching a Weaker Classifier: Named Entity Recognition on Upper Case Text,2002,12,10,2,1,131,hai chieu,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"This paper describes how a machine-learning named entity recognizer (NER) on upper case text can be improved by using a mixed case NER and some unlabeled text. The mixed case NER can be used to tag some unlabeled mixed case text, which are then used as additional training material for the upper case NER. We show that this approach reduces the performance gap between the mixed case NER and the upper case NER substantially, by 39% for MUC-6 and 22% for MUC-7 named entity test data. Our method is thus useful in improving the accuracy of NERs on upper case text, such as transcribed text from automatic speech recognizers where case information is missing."
C02-1025,Named Entity Recognition: A Maximum Entropy Approach Using Global Information,2002,11,225,2,1,131,hai chieu,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper presents a maximum entropy-based named entity recognizer (NER). It differs from previous machine learning-based NERs in that it uses information from the whole document to classify each word, with just one classifier. Previous work that involves the gathering of information from the whole document often uses a secondary classifier, which corrects the mistakes of a primary sentence-based classifier. In this paper, we show that the maximum entropy framework is able to make use of global information directly, and achieves performance that is comparable to the best previous machine learning-based NERs on MUC-6 and MUC-7 test data."
W01-0509,Question Answering Using a Large Text Database: A Machine Learning Approach,2001,0,20,1,1,7314,hwee ng,Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,0,None
J01-4004,A Machine Learning Approach to Coreference Resolution of Noun Phrases,2001,20,801,2,0,53905,wee soon,Computational Linguistics,0,"In this paper, we present a learning approach to coreference resolution of noun phrases in unrestricted text. The approach learns from a small, annotated corpus and the task includes resolving not just a certain type of noun phrase (e.g., pronouns) but rather general noun phrases. It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of organization, person, or other types. We evaluate our approach on common data sets (namely, the MUC-6 and MUC-7 coreference corpora) and obtain encouraging results, in-dicating that on the general noun phrase coreference task, the learning approach holds promise and achieves accuracy comparable to that of nonlearning approaches. Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets."
W00-1316,A Machine Learning Approach to Answering Questions for Reading Comprehension Tests,2000,13,49,1,1,7314,hwee ng,2000 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,"In this paper, we report results on answering questions for the reading comprehension task, using a machine learning approach. We evaluated our approach on the Remedia data set, a common data set used in several recent papers on the reading comprehension task. Our learning approach achieves accuracy competitive to previous approaches that rely on hand-crafted, deterministic rules and algorithms. To the best of our knowledge, this is the first work that reports that the use of a machine learning approach achieves competitive results on answering questions for reading comprehension tests."
W99-0634,Corpus-Based Learning for Noun Phrase Coreference Resolution,1999,15,16,2,0,53905,wee soon,1999 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,None
W99-0502,A Case Study on Inter-Annotator Agreement for Word Sense Disambiguation,1999,0,61,1,1,7314,hwee ng,{SIGLEX}99: Standardizing Lexical Resources,0,"There is a general concern within the field of word sense dusamb~guatmn about the rater-annotator agreement between human annota tors . In thus paper, we examine th~s msue by comparing the agreement rate on a large corpus of more than 30,000 sense-tagged instances Thin corpus us the mtersectmn of the WORDNET Semcor corpus and the DSO corpus, which has been independently tagged by two separate groups of human annotators The contribution of this paper us two-fold First , ~t presents a greedy search algori thm tha t can automatical ly derive coarser sense classes based on the sense tags assigned by two human annotators The resulting derived coarse sense classes achmve a h~gher agreement rate but we s t f l !mamtam as many of the original sense classes as posmble Second, the coarse sense grouping derived by the algorithm, upon verification by human, can potent ial ly serve as a better sense inventory for evaluating automated word sense d~samb~guatmn algori thms Moreover, we examined the derived coarse sense classes and found some interesting groupings of word senses that correspond to human mtmtlve judgment of sense granularity 1 I n t r o d u c t i o n . It us widely acknowledged that word sense d~samblguatmn (WSD) us a central problem m natural language processing In order for computers to be able to understand and process natural language beyond simple keyword matching, the problem of d~samblguatmg word sense, or dlscermng the meamng of a word m context, must be effectively dealt with Advances in WSD v, ill have slgmficant Impact on apphcatlons hke information retrieval and machine translation For natural language subtasks hke part-of-speech tagging or s)ntactm parsing, there are relatlvely well defined and agreed-upon cnterm of what it means to have the correct part of speech or syntactic structure assigned to a word or sentence For instance, the Penn Treebank corpus (Marcus et a l , 1993) pro~ide~ ,t large repo.~tory of texts annotated w~th partof-speech and s}ntactm structure mformatlon Tv.o independent human annotators can achieve a high rate of agreement on assigning part-of-speech tags to words m a g~ven sentence Unfortunately, th~s us not the case for word sense assignment F~rstly, it is rarely the case that any two dictionaries will have the same set of sense defimtmns for a g~ven word Different d~ctlonanes tend to carve up the semantic space m a different way, so to speak Secondly, the hst of senses for a word m a typical dmtmnar~ tend to be rather refined and comprehensive This is especmlly so for the commonly used words which have a large number of senses The sense dustmctmn between the different senses for a commonly used word m a d~ctmnary hke WoRDNET (Miller, 1990) tend to be rather fine Hence, two human annotators may genuinely dusagree m their sense assignment to a word m context The agreement rate between human annotators on word sense assignment us an Important concern for the evaluatmn of WSD algorithms One would prefer to define a dusamblguatlon task for which there us reasonably hlgh agreement between human annotators The agreement rate between human annotators will then form the upper ceiling against whmh to compare the performance of WSD algorithms For instance, the SENSEVAL exerclse has performed a detaded s tudy to find out the raterannotator agreement among ~ts lexicographers taggrog the word senses (Kllgamff, 1998c, Kllgarnff, 1998a, Kflgarrlff, 1998b) 2 A C a s e S t u d y In th i s -paper , we examine the ~ssue of raterannotator agreement by comparing the agreement rate of human annotators on a large sense-tagged corpus of more than 30,000 instances of the most frequently occurring nouns and verbs of Enghsh This corpus is the intersection of the WORDNET Semcor corpus (Miller et a l , 1993) and the DSO corpus (Ng and Lee, 1996, Ng, 1997), which has been independently tagged wlth the refined senses of WORDNET by two separate groups of human annotators The Semcor corpus us a subset of the Brown corpus tagged with ~VoRDNET senses, and consists of more than 670,000 words from 352 text files Sense taggmg was done on the content words (nouns, ~erbs, adjectives and adverbs) m this subset The DSO corpus consists of sentences drawn from the Brown corpus and the Wall Street Journal For each word w from a hst of 191 frequently occurring words of Enghsh (121 nouns and 70 verbs), sentences containing w (m singular or plural form, and m its various reflectional verb form) are selected and each word occurrence w ~s tagged w~th a sense from WoRDNET There ~s a total of about 192,800 sentences in the DSO corpus m which one word occurrence has been sense-tagged m each sentence The intersection of the Semcor corpus and the DSO corpus thus consists of Brown corpus sentences m which a word occurrence w is sense-tagged m each sentence, where w Is one of.the 191 frequently oc,currmg English nouns or verbs Since this common pomon has been sense-tagged by two independent groups of human annotators, ~t serves as our data set for investigating inter-annotator agreement in this paper"
P99-1057,Learning to Recognize Tables in Free Text,1999,4,60,1,1,7314,hwee ng,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"Many real-world texts contain tables. In order to process these texts correctly and extract the information contained within the tables, it is important to identify the presence and structure of tables. In this paper, we present a new approach that learns to recognize tables in free text, including the boundary, rows and columns of tables. When tested on Wall Street Journal news documents, our learning approach outperforms a deterministic table recognition algorithm that identifies table recognition algorithm that identifies tables based on a fixed set of conditions. Our learning approach is also more flexible and easily adaptable to texts in different domains with different table characteristics."
W97-0323,Exemplar-Based Word Sense Disambiguation{''} Some Recent Improvements,1997,18,17,1,1,7314,hwee ng,Second Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we report recent improvements to the exemplar-based learning approach for word sense disambiguation that have achieved higher disambiguation accuracy. By using a larger value of $k$, the number of nearest neighbors to use for determining the class of a test example, and through 10-fold cross validation to automatically determine the best $k$, we have obtained improved disambiguation accuracy on a large sense-tagged corpus first used in cite{ng96}. The accuracy achieved by our improved exemplar-based classifier is comparable to the accuracy on the same data set obtained by the Naive-Bayes algorithm, which was reported in cite{mooney96} to have the highest disambiguation accuracy among seven state-of-the-art machine learning algorithms."
W97-0201,Getting Serious about Word Sense Disambiguation,1997,-1,-1,1,1,7314,hwee ng,"Tagging Text with Lexical Semantics: Why, What, and How?",0,None
P96-1006,Integrating Multiple Knowledge Sources to Disambiguate Word Sense: An Exemplar-Based Approach,1996,22,400,1,1,7314,hwee ng,34th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we present a new approach for word sense disambiguation (WSD) using an exemplar-based learning algorithm. This approach integrates a diverse set of knowledge sources to disambiguate word sense, including part of speech of neighboring words, morphological form, the unordered set of surrounding words, local collocations, and verb-object syntactic relation. We tested our WSD program, named LEXAS, on both a common data set used in previous work, as well as on a large sense-tagged corpus that we separately constructed. LEXAS achieves a higher accuracy on the common data set, and performs better than the most frequent heuristic on the highly ambiguous words in the large corpus tagged with the refined senses of WORDNET."
