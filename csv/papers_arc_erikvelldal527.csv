2021.nodalida-main.4,Large-Scale Contextualised Language Modelling for {N}orwegian,2021,-1,-1,3,0.438391,2619,andrey kutuzov,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"We present the ongoing NorLM initiative to support the creation and use of very large contextualised language models for Norwegian (and in principle other Nordic languages), including a ready-to-use software environment, as well as an experience report for data preparation and training. This paper introduces the first large-scale monolingual language models for Norwegian, based on both the ELMo and BERT frameworks. In addition to detailing the training process, we present contrastive benchmark results on a suite of NLP tasks for Norwegian. For additional background and access to the data, models, and software, please see: http://norlm.nlpl.eu"
2021.nodalida-main.30,Negation in {N}orwegian: an annotated dataset,2021,-1,-1,5,1,2682,petter maehlum,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"This paper introduces NorecNeg {--} the first annotated dataset of negation for Norwegian. Negation cues and their in-sentence scopes have been annotated across more than 11K sentences spanning more than 400 documents for a subset of the Norwegian Review Corpus (NoReC). In addition to providing in-depth discussion of the annotation guidelines, we also present a first set of benchmark results based on a graph-parsing approach."
2021.nodalida-main.41,Multilingual {ELM}o and the Effects of Corpus Sampling,2021,-1,-1,4,0.769231,2707,vinit ravishankar,Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa),0,"Multilingual pretrained language models are rapidly gaining popularity in NLP systems for non-English languages. Most of these models feature an important corpus sampling step in the process of accumulating training data in different languages, to ensure that the signal from better resourced languages does not drown out poorly resourced ones. In this study, we train multiple multilingual recurrent language models, based on the ELMo architecture, and analyse both the effect of varying corpus size ratios on downstream performance, as well as the performance difference between monolingual models for each language, and broader multilingual language models. As part of this effort, we also make these trained models available for public use."
2021.gebnlp-1.8,Using Gender- and Polarity-Informed Models to Investigate Bias,2021,-1,-1,3,0.78125,2743,samia touileb,Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing,0,"In this work we explore the effect of incorporating demographic metadata in a text classifier trained on top of a pre-trained transformer language model. More specifically, we add information about the gender of critics and book authors when classifying the polarity of book reviews, and the polarity of the reviews when classifying the genders of authors and critics. We use an existing data set of Norwegian book reviews with ratings by professional critics, which has also been augmented with gender information, and train a document-level sentiment classifier on top of a recently released Norwegian BERT-model. We show that gender-informed models obtain substantially higher accuracy, and that polarity-informed models obtain higher accuracy when classifying the genders of book authors. For this particular data set, we take this result as a confirmation of the gender bias in the underlying label distribution, but in other settings we believe a similar approach can be used for mitigating bias in the model."
2021.eacl-main.5,"If you{'}ve got it, flaunt it: Making the most of fine-grained sentiment annotations",2021,-1,-1,3,0.972222,2620,jeremy barnes,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Fine-grained sentiment analysis attempts to extract sentiment holders, targets and polar expressions and resolve the relationship between them, but progress has been hampered by the difficulty of annotation. Targeted sentiment analysis, on the other hand, is a more narrow task, focusing on extracting sentiment targets and classifying their polarity. In this paper, we explore whether incorporating holder and expression information can improve target extraction and classification and perform experiments on eight English datasets. We conclude that jointly predicting target and polarity BIO labels improves target extraction, and that augmenting the input text with gold expressions generally improves targeted polarity classification. This highlights the potential importance of annotating expressions for fine-grained sentiment datasets. At the same time, our results show that performance of current models for predicting polar expressions is poor, hampering the benefit of this information in practice."
2021.acl-long.263,Structured Sentiment Analysis as Dependency Graph Parsing,2021,-1,-1,5,0.972222,2620,jeremy barnes,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Structured sentiment analysis attempts to extract full opinion tuples from a text, but over time this task has been subdivided into smaller and smaller sub-tasks, e.g., target extraction or targeted polarity classification. We argue that this division has become counterproductive and propose a new unified framework to remedy the situation. We cast the structured sentiment problem as dependency graph parsing, where the nodes are spans of sentiment holders, targets and expressions, and the arcs are the relations between them. We perform experiments on five datasets in four languages (English, Norwegian, Basque, and Catalan) and show that this approach leads to strong improvements over state-of-the-art baselines. Our analysis shows that refining the sentiment graphs with syntactic dependency information further improves results."
2020.lrec-1.559,{N}or{NE}: Annotating Named Entities for {N}orwegian,2020,-1,-1,5,0,17782,fredrik jorgensen,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper presents NorNE, a manually annotated corpus of named entities which extends the annotation of the existing Norwegian Dependency Treebank. Comprising both of the official standards of written Norwegian (Bokm{\aa}l and Nynorsk), the corpus contains around 600,000 tokens and annotates a rich set of entity types including persons, organizations, locations, geo-political entities, products, and events, in addition to a class corresponding to nominals derived from names. We here present details on the annotation effort, guidelines, inter-annotator agreement and an experimental analysis of the corpus using a neural sequence labeling architecture."
2020.lrec-1.618,A Fine-grained Sentiment Dataset for {N}orwegian,2020,-1,-1,4,0,2622,lilja ovrelid,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We here introduce NoReC{\_}fine, a dataset for fine-grained sentiment analysis in Norwegian, annotated with respect to polar expressions, targets and holders of opinion. The underlying texts are taken from a corpus of professionally authored reviews from multiple news-sources and across a wide variety of domains, including literature, games, music, products, movies and more. We here present a detailed description of this annotation effort. We provide an overview of the developed annotation guidelines, illustrated with examples and present an analysis of inter-annotator agreement. We also report the first experimental results on the dataset, intended as a preliminary benchmark for further experiments."
2020.gebnlp-1.11,"Gender and sentiment, critics and authors: a dataset of {N}orwegian book reviews",2020,-1,-1,3,0.833333,2743,samia touileb,Proceedings of the Second Workshop on Gender Bias in Natural Language Processing,0,"Gender bias in models and datasets is widely studied in NLP. The focus has usually been on analysing how females and males express themselves, or how females and males are described. However, a less studied aspect is the combination of these two perspectives, how female and male describe the same or opposite gender. In this paper, we present a new gender annotated sentiment dataset of critics reviewing the works of female and male authors. We investigate if this newly annotated dataset contains differences in how the works of male and female authors are critiqued, in particular in terms of positive and negative sentiment. We also explore the differences in how this is done by male and female critics. We show that there are differences in how critics assess the works of authors of the same or opposite gender. For example, male critics rate crime novels written by females, and romantic and sentimental works written by males, more negatively."
W19-6205,Multilingual Probing of Deep Pre-Trained Contextual Encoders,2019,-1,-1,4,0.769231,2707,vinit ravishankar,Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing,0,"Encoders that generate representations based on context have, in recent years, benefited from adaptations that allow for pre-training on large text corpora. Earlier work on evaluating fixed-length sentence representations has included the use of {`}probing{'} tasks, that use diagnostic classifiers to attempt to quantify the extent to which these encoders capture specific linguistic phenomena. The principle of probing has also resulted in extended evaluations that include relatively newer word-level pre-trained encoders. We build on probing tasks established in the literature and comprehensively evaluate and analyse {--} from a typological perspective amongst others {--} multilingual variants of existing encoders on probing datasets constructed for 6 non-English languages. Specifically, we probe each layer of a multiple monolingual RNN-based ELMo models, the transformer-based BERT{'}s cased and uncased multilingual variants, and a variant of BERT that uses a cross-lingual modelling scheme (XLM)."
W19-6113,Annotating evaluative sentences for sentiment analysis: a dataset for {N}orwegian,2019,0,2,4,1,2682,petter maehlum,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,This paper documents the creation of a large-scale dataset of evaluative sentences {--} i.e. both subjective and objective sentences that are found to be sentiment-bearing {--} based on mixed-domain professional reviews from various news-sources. We present both the annotation scheme and first results for classification experiments. The effort represents a step toward creating a Norwegian dataset for fine-grained sentiment analysis.
W19-6119,Lexicon information in neural sentiment analysis: a multi-task learning approach,2019,0,4,4,1,2620,jeremy barnes,Proceedings of the 22nd Nordic Conference on Computational Linguistics,0,"This paper explores the use of multi-task learning (MTL) for incorporating external knowledge in neural models. Specifically, we show how MTL can enable a BiLSTM sentiment classifier to incorporate information from sentiment lexicons. Our MTL set-up is shown to improve model performance (compared to a single-task set-up) on both English and Norwegian sentence-level sentiment datasets. The paper also introduces a new sentiment lexicon for Norwegian."
W19-4802,Sentiment Analysis Is Not Solved! Assessing and Probing Sentiment Classification,2019,48,0,3,1,2620,jeremy barnes,Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP,0,"Neural methods for sentiment analysis have led to quantitative improvements over previous approaches, but these advances are not always accompanied with a thorough analysis of the qualitative differences. Therefore, it is not clear what outstanding conceptual challenges for sentiment analysis remain. In this work, we attempt to discover what challenges still prove a problem for sentiment classifiers for English and to provide a challenging dataset. We collect the subset of sentences that an (oracle) ensemble of state-of-the-art sentiment classifiers misclassify and then annotate them for 18 linguistic and paralinguistic phenomena, such as negation, sarcasm, modality, etc. Finally, we provide a case study that demonstrates the usefulness of the dataset to probe the performance of a given sentiment classifier with respect to linguistic phenomena."
W19-4724,One-to-{X} Analogical Reasoning on Word Embeddings: a Case for Diachronic Armed Conflict Prediction from News Texts,2019,14,0,2,0.576119,2619,andrey kutuzov,Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change,0,"We extend the well-known word analogy task to a one-to-X formulation, including one-to-none cases, when no correct answer exists. The task is cast as a relation discovery problem and applied to historical armed conflicts datasets, attempting to predict new relations of type {`}location:armed-group{'} based on data about past events. As the source of semantic information, we use diachronic word embedding models trained on English news texts. A simple technique to improve diachronic performance in such task is demonstrated, using a threshold based on a function of cosine distance to decrease the number of false positives; this approach is shown to be beneficial on two different corpora. Finally, we publish a ready-to-use test set for one-to-X analogy evaluation on historical armed conflicts data."
W19-4725,"Measuring Diachronic Evolution of Evaluative Adjectives with Word Embeddings: the Case for {E}nglish, {N}orwegian, and {R}ussian",2019,-1,-1,6,0,21155,julia rodina,Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change,0,"We measure the intensity of diachronic semantic shifts in adjectives in English, Norwegian and Russian across 5 decades. This is done in order to test the hypothesis that evaluative adjectives are more prone to temporal semantic change. To this end, 6 different methods of quantifying semantic change are used. Frequency-controlled experimental results show that, depending on the particular method, evaluative adjectives either do not differ from other types of adjectives in terms of semantic change or appear to actually be less prone to shifting (particularly, to {`}jitter{'}-type shifting). Thus, in spite of many well-known examples of semantically changing evaluative adjectives (like {`}terrific{'} or {`}incredible{'}), it seems that such cases are not specific to this particular type of words."
W19-4318,Probing Multilingual Sentence Representations With {X}-Probe,2019,36,0,3,0.769231,2707,vinit ravishankar,Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019),0,"This paper extends the task of probing sentence representations for linguistic insight in a multilingual domain. In doing so, we make two contributions: first, we provide datasets for multilingual probing, derived from Wikipedia, in five languages, viz. English, French, German, Spanish and Russian. Second, we evaluate six sentence encoders for each language, each trained by mapping sentence representations to English sentence representations, using sentences in a parallel corpus. We discover that cross-lingually mapped representations are often better at retaining certain linguistic information than representations derived from English encoders trained on natural language inference (NLI) as a downstream task."
L18-1661,{N}o{R}e{C}: The {N}orwegian Review Corpus,2018,-1,-1,1,1,2621,erik velldal,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
D18-1178,Transfer and Multi-Task Learning for Noun{--}Noun Compound Interpretation,2018,30,0,3,1,30331,murhaf fares,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of noun{--}noun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations."
C18-1117,Diachronic word embeddings and semantic shifts: a survey,2018,0,20,4,0.7946,2619,andrey kutuzov,Proceedings of the 27th International Conference on Computational Linguistics,0,"Recent years have witnessed a surge of publications aimed at tracing temporal changes in lexical semantics using distributional methods, particularly prediction-based word embedding models. However, this vein of research lacks the cohesion, common terminology and shared practices of more established areas of natural language processing. In this paper, we survey the current state of academic research related to diachronic word embeddings and semantic shifts detection. We start with discussing the notion of semantic shifts, and then continue with an overview of the existing methods for tracing such time-related shifts with word embedding models. We propose several axes along which these methods can be compared, and outline the main challenges before this emerging subfield of NLP, as well as prospects and possible applications."
W17-2705,Tracing armed conflicts with diachronic word embedding models,2017,0,6,2,0.7946,2619,andrey kutuzov,Proceedings of the Events and Stories in the News Workshop,0,"Recent studies have shown that word embedding models can be used to trace time-related (diachronic) semantic shifts in particular words. In this paper, we evaluate some of these approaches on the new task of predicting the dynamics of global armed conflicts on a year-to-year basis, using a dataset from the conflict research field as the gold standard and the Gigaword news corpus as the training data. The results show that much work still remains in extracting {`}cultural{'} semantic shifts from diachronic word embedding models. At the same time, we present a new task complete with an evaluation set and introduce the {`}anchor words{'} method which outperforms previous approaches on this set."
W17-1810,An open-source tool for negation detection: a maximum-margin approach,2017,12,7,2,0,32024,martine enger,Proceedings of the Workshop Computational Semantics Beyond Events and Roles,0,"This paper presents an open-source toolkit for negation detection. It identifies negation cues and their corresponding scope in either raw or parsed text using maximum-margin classification. The system design draws on best practice from the existing literature on negation detection, aiming for a simple and portable system that still achieves competitive performance. Pre-trained models and experimental results are provided for English."
W17-0808,"Representation and Interchange of Linguistic Annotation. An In-Depth, Side-by-Side Comparison of Three Designs",2017,10,2,6,0,11279,richard castilho,Proceedings of the 11th Linguistic Annotation Workshop,0,"For decades, most self-respecting linguistic engineering initiatives have designed and implemented custom representations for various layers of, for example, morphological, syntactic, and semantic analysis. Despite occasional efforts at harmonization or even standardization, our field today is blessed with a multitude of ways of encoding and exchanging linguistic annotations of these types, both at the levels of {`}abstract syntax{'}, naming choices, and of course file formats. To a large degree, it is possible to work within and across design plurality by conversion, and often there may be good reasons for divergent design reflecting differences in use. However, it is likely that some abstract commonalities across choices of representation are obscured by more superficial differences, and conversely there is no obvious procedure to tease apart what actually constitute contentful vs. mere technical divergences. In this study, we seek to conceptually align three representations for common types of morpho-syntactic analysis, pinpoint what in our view constitute contentful differences, and reflect on the underlying principles and specific requirements that led to individual choices. We expect that a more in-depth understanding of these choices across designs may led to increased harmonization, or at least to more informed design of future representations."
W17-0201,Joint {UD} Parsing of {N}orwegian {B}okm{\\aa}l and Nynorsk,2017,25,1,1,1,2621,erik velldal,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0217,Optimizing a {P}o{S} Tagset for {N}orwegian Dependency Parsing,2017,15,2,3,0,32161,petter hohle,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0237,"Word vectors, reuse, and replicability: Towards a community repository of large-text resources",2017,0,19,4,1,30331,murhaf fares,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
W17-0242,{W}ordnet extension via word embeddings: Experiments on the {N}orwegian {W}ordnet,2017,10,0,2,0,32190,heidi sand,Proceedings of the 21st Nordic Conference on Computational Linguistics,0,None
D17-1194,Temporal dynamics of semantic relations in word embeddings: an application to predicting armed conflict participants,2017,10,1,2,0.7946,2619,andrey kutuzov,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"This paper deals with using word embedding models to trace the temporal dynamics of semantic relations between pairs of words. The set-up is similar to the well-known analogies task, but expanded with a time dimension. To this end, we apply incremental updating of the models with new training texts, including incremental vocabulary expansion, coupled with learned transformation matrices that let us map between members of the relation. The proposed approach is evaluated on the task of predicting insurgent armed groups based on geographical locations. The gold standard data for the time span 1994{--}2010 is extracted from the UCDP Armed Conflicts dataset. The results show that the method is feasible and outperforms the baselines, but also that important work still remains to be done."
W16-0413,Threat detection in online discussions,2016,12,8,3,0,34098,aksel wester,"Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"This paper investigates the effect of various types of linguistic features (lexical, syntactic and semantic) for training classifiers to detect threats of violence in a corpus of YouTube comments. Our results show that combinations of lexical features outperform the use of more complex syntactic and semantic features for this task."
L16-1272,A Corpus of Clinical Practice Guidelines Annotated with the Importance of Recommendations,2016,12,1,2,0.486789,35001,jonathon read,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper we present the Corpus of REcommendation STrength (CREST), a collection of HTML-formatted clinical guidelines annotated with the location of recommendations. Recommendations are labelled with an author-provided indicator of their strength of importance. As data was drawn from many disparate authors, we define a unified scheme of importance labels, and provide a mapping for each guideline. We demonstrate the utility of the corpus and its annotations in some initial measurements investigating the type of language constructions associated with strong and weak recommendations, and experiments into promising features for recommendation classification, both with respect to strong and weak labels, and to all labels of the unified scheme. An error analysis indicates that, while there is a strong relationship between lexical choices and strength labels, there can be substantial variance in the choices made by different authors."
K16-2002,"{OPT}: {O}slo{--}{P}otsdam{--}{T}eesside. Pipelining Rules, Rankers, and Classifier Ensembles for Shallow Discourse Parsing",2016,15,2,6,0,2623,stephan oepen,Proceedings of the {C}o{NLL}-16 shared task,0,"The OPT submission to the Shared Task of the 2016 Conference on Natural Language Learning (CoNLL) implements a xe2x80x98classicxe2x80x99 pipeline architecture, combining binary classification of (candidate) explicit connectives, heuristic rules for non-explicit discourse relations, ranking and xe2x80x98editingxe2x80x99 of syntactic constituents for argument identification, and an ensemble of classifiers to assign discourse senses. With an end-toend performance of 27.77 F1 on the English xe2x80x98blindxe2x80x99 test data, our system advances the previous state of the art (Wang & Lan, 2015) by close to four F1 points, with particularly good results for the argument identification sub-tasks. OPT system results appear more competitive on the new, xe2x80x98blindxe2x80x99 test data than on the xe2x80x98testxe2x80x99 and xe2x80x98developmentxe2x80x99 sections of the Penn Discourse Treebank (PDTB; Prasad et al., 2008), which may indicate reduced over-fitting to specific properties of the venerable Wall Street Journal (WSJ) text underlying the PDTB."
K16-1012,Redefining part-of-speech classes with distributional semantic models,2016,22,0,2,0.721671,2619,andrey kutuzov,Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning,0,"This paper studies how word embeddings trained on the British National Corpus interact with part of speech boundaries. Our work targets the Universal PoS tag set, which is currently actively being used for annotation of a range of languages. We experiment with training classifiers for predicting PoS tags for words based on their embeddings. The results show that the information about PoS affiliation contained in the distributional vectors allows us to discover groups of words with distributional patterns that differ from other words of the same part of speech. n This data often reveals hidden inconsistencies of the annotation process or guidelines. At the same time, it supports the notion of `soft' or `graded' part of speech affiliations. Finally, we show that information about PoS is distributed among dozens of vector components, not limited to only one or two features."
W15-1816,Improving cross-domain dependency parsing with dependency-derived clusters,2015,24,0,2,0,36978,jostein lien,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"This paper describes a semi-supervised approach to improving statistical dependency parsing using dependency-based word clusters. After applying a baseline parser to unlabeled text, clusters are induced using K-means with word features based on the dependency structures. The parser is then re-trained using information about the clusters, yielding improved parsing accuracy on a range of different data sets, including WSJ and the English Web Treebank. We report improved results using both in-domain and out-of-domain data, and also include a comparison with usingn-gramxe2x80x90based Brown clustering."
W14-2516,Predicting Party Affiliations from {E}uropean Parliament Debates,2014,-1,-1,4,0,38668,bjorn hoyland,Proceedings of the {ACL} 2014 Workshop on Language Technologies and Computational Social Science,0,None
lapponi-etal-2014-road,Off-Road {LAF}: Encoding and Processing Annotations in {NLP} Workflows,2014,9,2,2,1,32118,emanuele lapponi,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The Linguistic Annotation Framework (LAF) provides an abstract data model for specifying interchange representations to ensure interoperability among different annotation formats. This paper describes an ongoing effort to adapt the LAF data model as the interchange representation in complex workflows as used in the Language Analysis Portal (LAP), an on-line and large-scale processing service that is developed as part of the Norwegian branch of the Common Language Resources and Technology Infrastructure (CLARIN) initiative. Unlike several related on-line processing environments, which predominantly instantiate a distributed architecture of web services, LAP achives scalability to potentially very large data volumes through integration with the Norwegian national e-Infrastructure, and in particular job sumission to a capacity compute cluster. This setup leads to tighter integration requirements and also calls for efficient, low-overhead communication of (intermediate) processing results with workflows. We meet these demands by coupling the LAF data model with a lean, non-redundant JSON-based interchange format and integration of an agile and performant NoSQL database, allowing parallel access from cluster nodes, as the central repository of linguistic annotation."
W13-5642,{HPC}-ready Language Analysis for Human Beings,2013,-1,-1,2,1,32118,emanuele lapponi,Proceedings of the 19th Nordic Conference of Computational Linguistics ({NODALIDA} 2013),0,None
W12-3804,Factuality Detection on the Cheap: Inferring Factuality for Increased Precision in Detecting Negated Events,2012,19,3,1,1,2621,erik velldal,Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics,0,"This paper describes a system for discriminating between factual and non-factual contexts, trained on weakly labeled data by taking advantage of information implicit in annotations of negated events. In addition to evaluating factuality detection in isolation, we also evaluate its impact on a system for event detection. The two components for factuality detection and event detection form part of a system for identifying negative factual events, or counterfacts, with top-ranked results in the *SEM 2012 shared task."
S12-1041,{U}i{O}1: Constituent-Based Discriminative Ranking for Negation Resolution,2012,8,14,2,0.486789,35001,jonathon read,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper describes the first of two systems submitted from the University of Oslo (UiO) to the 2012 *SEM Shared Task on resolving negation. Our submission is an adaption of the negation system of Velldal et al. (2012), which combines SVM cue classification with SVM-based ranking of syntactic constituents for scope resolution. The approach further extends our prior work in that we also identify factual negated events. While submitted for the closed track, the system was the top performer in the shared task overall."
S12-1042,{U}i{O} 2: Sequence-labeling Negation Using Dependency Features,2012,11,16,2,1,32118,emanuele lapponi,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper describes the second of two systems submitted from the University of Oslo (UiO) to the 2012 *SEM Shared Task on resolving negation. The system combines SVM cue classification with CRF sequence labeling of events and scopes. Models for scopes and events are created using lexical and syntactic features, together with a fine-grained set of labels that capture the scopal behavior of certain tokens. Following labeling, negated tokens are assigned to their respective cues using simple post-processing heuristics. The system was ranked first in the open track and third in the closed track, and was one of the top performers in the scope resolution sub-task overall."
J12-2005,"Speculation and Negation: Rules, Rankers, and the Role of Syntax",2012,47,52,1,1,2621,erik velldal,Computational Linguistics,0,"This article explores a combination of deep and shallow approaches to the problem of resolving the scope of speculation and negation within a sentence, specifically in the domain of biomedical research literature. The first part of the article focuses on speculation. After first showing how speculation cues can be accurately identified using a very simple classifier informed only by local lexical context, we go on to explore two different syntactic approaches to resolving the in-sentence scopes of these cues. Whereas one uses manually crafted rules operating over dependency structures, the other automatically learns a discriminative ranking function over nodes in constituent trees. We provide an in-depth error analysis and discussion of various linguistic properties characterizing the problem, and show that although both approaches perform well in isolation, even better results can be obtained by combining them, yielding the best published results to date on the CoNLL-2010 Shared Task data. The last part of the article describes how our speculation system is ported to also resolve the scope of negation. With only modest modifications to the initial design, the system obtains state-of-the-art results on this task also."
W11-4631,Random Indexing Re-Hashed,2011,16,1,1,1,2621,erik velldal,Proceedings of the 18th Nordic Conference of Computational Linguistics ({NODALIDA} 2011),0,None
W10-3007,Resolving Speculation: {M}ax{E}nt Cue Classification and Dependency-Based Scope Rules,2010,20,29,1,1,2621,erik velldal,Proceedings of the Fourteenth Conference on Computational Natural Language Learning {--} Shared Task,0,"This paper describes a hybrid, two-level approach for resolving hedge cues, the problem of the CoNLL-2010 shared task. First, a maximum entropy classifier is applied to identify cue words, using both syntactic- and surface-oriented features. Second, a set of manually crafted rules, operating on dependency representations and the output of the classifier, is applied to resolve the scope of the hedge cues within the sentence."
C10-1155,Syntactic Scope Resolution in Uncertainty Analysis,2010,21,32,2,0.245098,2622,lilja ovrelid,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"We show how the use of syntactic structure enables the resolution of hedge scope in a hybrid, two-stage approach to uncertainty analysis. In the first stage, a Maximum Entropy classifier, combining surface-oriented and syntactic features, identifies cue words. With a small set of hand-crafted rules operating over dependency representations in stage two, we attain the best overall result (in terms of both combined ranks and average F1) in the 2010 CoNLL Shared Task."
2007.tmi-papers.18,Towards hybrid quality-oriented machine translation {--} on linguistics and probabilities in {MT},2007,-1,-1,2,0.326087,2623,stephan oepen,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
W06-1661,Statistical Ranking in Tactical Generation,2006,19,28,1,1,2621,erik velldal,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we describe and evaluate several statistical models for the task of realization ranking, i.e. the problem of discriminating between competing surface realizations generated for a given input semantics. Three models (and several variants) are trained and tested: an n-gram language model, a discriminative maximum entropy model using structural information (and incorporating the language model as a separate feature), and finally an SVM ranker trained on the same feature set. The resulting hybrid tactical generator is part of a larger, semantic transfer MT system."
2005.mtsummit-papers.15,Maximum Entropy Models for Realization Ranking,2005,18,33,1,1,2621,erik velldal,Proceedings of Machine Translation Summit X: Papers,0,"In this paper we describe and evaluate different statistical models for the task of realization ranking, i.e. the problem of discriminating between competing surface realizations generated for a given input semantics. Three models are trained and tested; an n-gram language model, a discriminative maximum entropy model using structural features, and a combination of these two. Our realization component forms part of a larger, hybrid MT system."
2004.tmi-1.2,Som {\\aa} kapp-ete med trollet? {--} Towards {MRS}-based {N}orwegian-{E}nglish machine translation,2004,11,36,4,0,2623,stephan oepen,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"We present a relatively large-scale initiative in high-quality MT based on semantic transfer, reviewing the motivation for this approach, general architecture and components involved, and preliminary experience from a first round of system integration (to be accompanied by a hands-on system demonstration, if appropriate)."
