2004.jeptalnrecital-long.29,W01-1313,0,0.0501768,"Missing"
2004.jeptalnrecital-long.29,J96-1004,0,0.0172102,"Missing"
2004.jeptalnrecital-long.29,E95-1035,0,0.0350308,"Missing"
2004.jeptalnrecital-long.29,P93-1010,0,0.0527618,"Missing"
2004.jeptalnrecital-long.29,P00-1010,0,0.0665455,"Missing"
2004.jeptalnrecital-long.29,W01-1309,0,0.024082,"Missing"
2004.jeptalnrecital-long.29,W01-1312,0,0.0344104,"Missing"
2010.jeptalnrecital-court.25,W09-3007,0,0.0550101,"Missing"
2010.jeptalnrecital-court.25,doddington-etal-2004-automatic,0,0.0630594,"Missing"
2010.jeptalnrecital-court.25,2009.jeptalnrecital-long.17,0,0.0619111,"Missing"
2010.jeptalnrecital-court.6,tannier-moriceau-2010-fidji,1,0.840409,"Missing"
2010.jeptalnrecital-court.6,C08-1120,0,0.0649711,"Missing"
2011.jeptalnrecital-court.6,N10-1086,0,0.0502098,"Missing"
2011.jeptalnrecital-court.6,levy-andrew-2006-tregex,0,0.0623288,"Missing"
2011.jeptalnrecital-court.6,N10-1048,0,0.0309641,"Missing"
2011.jeptalnrecital-court.6,W03-1605,0,0.0322934,"Missing"
2011.jeptalnrecital-court.9,P06-2022,0,0.0701731,"Missing"
2011.jeptalnrecital-court.9,doddington-etal-2004-automatic,0,0.0347708,"Missing"
2011.jeptalnrecital-court.9,2002.jeptalnrecital-long.22,0,0.0936818,"Missing"
2015.jeptalnrecital-long.5,P10-1052,0,0.039442,"Missing"
2015.jeptalnrecital-long.5,E14-4026,0,0.0580521,"Missing"
2015.jeptalnrecital-long.5,llorens-etal-2012-timen,0,0.06874,"Missing"
2015.jeptalnrecital-long.5,W03-0430,0,0.010542,"Missing"
2015.jeptalnrecital-long.5,moriceau-tannier-2014-french,1,0.851424,"Missing"
2015.jeptalnrecital-long.5,pustejovsky-etal-2010-iso,0,0.245163,"Missing"
2015.jeptalnrecital-long.5,E12-2021,0,0.051131,"Missing"
2015.jeptalnrecital-long.5,strotgen-etal-2014-extending,0,0.0423585,"Missing"
2015.jeptalnrecital-long.5,strotgen-gertz-2012-temporal,0,0.0670179,"Missing"
2015.jeptalnrecital-long.5,W14-3413,0,0.0538301,"Missing"
2015.jeptalnrecital-long.5,S07-1014,0,0.0639399,"Missing"
2015.jeptalnrecital-long.7,P98-1013,0,0.117804,"Missing"
2015.jeptalnrecital-long.7,D13-1178,0,0.024732,"Missing"
2015.jeptalnrecital-long.7,D13-1185,0,0.0242454,"Missing"
2015.jeptalnrecital-long.7,P08-1090,0,0.0662599,"Missing"
2015.jeptalnrecital-long.7,P09-1068,0,0.0811295,"Missing"
2015.jeptalnrecital-long.7,P11-1098,0,0.0366076,"Missing"
2015.jeptalnrecital-long.7,N13-1104,0,0.0238891,"Missing"
2015.jeptalnrecital-long.7,P06-2027,0,0.0225288,"tion Extraction (Shinyama & Sekine, 2006), vise à induire l’équivalent d’un formulaire à partir d’un ensemble de documents représentatifs des informations à extraire, documents typiquement obtenus par le biais de requêtes soumises à un moteur de recherche. Ce courant de recherche s’est ensuite davantage orienté vers l’extraction de relations, avec notamment Kathrin Eichler & Neumann (2008), Rosenfeld & Feldman (2007) et plus récemment Min et al. (2012), que vers l’extraction d’événements. Dans cet article, nous nous plaçons dans la voie tracée initialement par Hasegawa et al. (2004) et Sekine (2006) en considérant la possibilité d’induire des représentations d’événements à partir de textes. Plus globalement, nous cherchons à construire une base de connaissances événementielles à partir de larges corpus journalistiques afin d’offrir des moyens d’accès structurés à ces corpus. Nous nous concentrons dans le cadre du travail présenté dans cet article sur le processus d’induction de schémas d’événements. 2 Objectif Notre objectif global est de modéliser les événements décrits dans un corpus journalistique et d’identifier sans supervision les schémas (ou formulaires) récurrents ainsi que les r"
2015.jeptalnrecital-long.7,D11-1133,0,0.0197495,"Missing"
2015.jeptalnrecital-long.7,E14-1006,0,0.0210968,"Missing"
2015.jeptalnrecital-long.7,C96-1079,0,0.737202,"Missing"
2015.jeptalnrecital-long.7,P04-1053,0,0.0967503,"Missing"
2015.jeptalnrecital-long.7,I11-1081,1,0.901965,"Missing"
2015.jeptalnrecital-long.7,eichler-etal-2008-unsupervised,0,0.029375,"Missing"
2015.jeptalnrecital-long.7,P14-5010,0,0.0075885,"Missing"
2015.jeptalnrecital-long.7,D12-1094,0,0.0364988,"Missing"
2015.jeptalnrecital-long.7,D07-1075,0,0.0741971,"Missing"
2015.jeptalnrecital-long.7,D09-1016,0,0.024886,"Missing"
2015.jeptalnrecital-long.7,I08-1021,0,0.0444661,"Missing"
2015.jeptalnrecital-long.7,P10-1100,0,0.0276145,"Missing"
2015.jeptalnrecital-long.7,P06-2094,0,0.0409422,"Missing"
2015.jeptalnrecital-long.7,N06-1039,0,0.0865828,"Missing"
2015.jeptalnrecital-long.7,H91-1059,0,0.65433,"Missing"
2016.jeptalnrecital-poster.19,S15-2136,0,0.0366591,"Missing"
2016.jeptalnrecital-poster.19,S16-1165,0,0.0233445,"Missing"
2016.jeptalnrecital-poster.19,W06-1623,0,0.0677844,"Missing"
2016.jeptalnrecital-poster.19,P05-1022,0,0.112201,"Missing"
2016.jeptalnrecital-poster.19,deleger-etal-2014-annotation,1,0.887262,"Missing"
2016.jeptalnrecital-poster.19,W02-0109,0,0.0797351,"Missing"
2016.jeptalnrecital-poster.19,P14-5010,0,0.00491923,"Missing"
2016.jeptalnrecital-poster.19,N10-1004,0,0.0484883,"Missing"
2016.jeptalnrecital-poster.19,W11-0419,0,0.0708503,"Missing"
2016.jeptalnrecital-poster.19,Q14-1012,0,0.049267,"Missing"
2017.jeptalnrecital-long.13,P14-1023,0,0.0994656,"Missing"
2017.jeptalnrecital-long.13,D07-1074,0,0.239996,"Missing"
2017.jeptalnrecital-long.13,K16-1026,0,0.0357843,"Missing"
2017.jeptalnrecital-long.13,Q15-1016,0,0.091516,"Missing"
2017.jeptalnrecital-long.13,Q15-1023,0,0.0405613,"Missing"
2017.jeptalnrecital-long.13,P09-1113,0,0.0726146,"Missing"
2017.jeptalnrecital-long.13,Q14-1019,0,0.0635932,"Missing"
2017.jeptalnrecital-long.13,D14-1167,0,0.0489415,"Missing"
2017.jeptalnrecital-long.13,K16-1025,0,0.0395777,"Missing"
2020.jeptalnrecital-deft.11,W18-5614,0,0.0318392,"Missing"
2020.jeptalnrecital-deft.11,N18-1131,0,0.044952,"Missing"
2020.jeptalnrecital-deft.11,N16-1030,0,0.139155,"Missing"
2020.jeptalnrecital-taln.35,D19-1588,0,0.0215614,"Missing"
2020.jeptalnrecital-taln.35,N16-1030,0,0.0893794,"Missing"
2020.jeptalnrecital-taln.35,D17-1018,0,0.0457912,"Missing"
2020.jeptalnrecital-taln.35,P14-2006,0,0.0308576,"Missing"
2020.jeptalnrecital-taln.35,W11-1901,0,0.0594136,"Missing"
2020.jeptalnrecital-taln.35,D17-1035,0,0.0201615,"Missing"
2020.jeptalnrecital-taln.35,Q14-1012,0,0.0453975,"Missing"
2020.jeptalnrecital-taln.35,M95-1002,0,0.272925,"Missing"
2020.jeptalnrecital-taln.35,P15-1137,0,0.0484465,"Missing"
2020.jeptalnrecital-taln.35,N16-1114,0,0.0388283,"Missing"
2020.jeptalnrecital-taln.35,P19-1083,0,0.0606537,"Missing"
2021.jeptalnrecital-deft.3,N19-1423,0,0.0609883,"Missing"
2021.jeptalnrecital-deft.3,N16-1030,0,0.149621,"Missing"
2021.jeptalnrecital-deft.3,2020.acl-main.645,0,0.0773325,"Missing"
2021.jeptalnrecital-deft.3,2020.acl-demos.14,0,0.0274242,"Missing"
2021.jeptalnrecital-deft.3,J81-4005,0,0.69084,"Missing"
2021.jeptalnrecital-deft.3,2020.acl-main.577,0,0.020061,"Missing"
arnulphy-etal-2012-event,P06-2022,0,\N,Missing
arnulphy-etal-2012-event,tannier-etal-2012-evolution,1,\N,Missing
arnulphy-etal-2012-event,2009.jeptalnrecital-long.17,0,\N,Missing
bittar-etal-2012-temporal,W08-2229,0,\N,Missing
bittar-etal-2012-temporal,2009.jeptalnrecital-long.17,1,\N,Missing
bittar-etal-2012-temporal,2009.jeptalnrecital-court.23,0,\N,Missing
C04-1008,W01-1313,0,0.129268,"has started to generate some interest in computational linguistics (Harper et al., 2001), as it is potentially an important component in information extraction or question-answer systems. A few tasks can be distinguished in that respect: Xavier Tannier IRIT, Université Paul Sabatier Toulouse, France tannier@emse.fr as beliefs, or reported speech have an unclear status in that respect. The third task adds another level of complexity: a lot of events described in a text do not have an explicit temporal stamp, and it is not always possible to determine one, even when taking context into account (Filatova and Hovy, 2001). This leads to an approach more suited to the level of underspecification found in texts: annotating relations between events in a symbolic way (e.g. that an event e1 is before another one e2 ). This is the path chosen by (Katz and Arosio, 2001; Setzer, 2001) with human annotators. This, in turn, raises new problems. First, what are the relations best suited to that task, among the many propositions (linguistic or logical) one can find for expressing temporal location ? Then, how can an annotation be evaluated, between annotators, or between a human annotator and an automated system ? Such an"
C04-1008,E95-1035,0,0.0726167,"ts in a symbolic way (e.g. that an event e1 is before another one e2 ). This is the path chosen by (Katz and Arosio, 2001; Setzer, 2001) with human annotators. This, in turn, raises new problems. First, what are the relations best suited to that task, among the many propositions (linguistic or logical) one can find for expressing temporal location ? Then, how can an annotation be evaluated, between annotators, or between a human annotator and an automated system ? Such annotations cannot be easy to determine automatically anyway, and must use some level of discourse modeling (cf. the work of (Grover et al., 1995)). • detecting event descriptions We want to show here the feasibility of such an effort, and we propose a way of evaluating the success or failure of the task. The next section will precise why evaluating this particular task is not a trivial question. Section 3 will explain the method used to extract temporal relations, using also a form of symbolic inference on available temporal information (section 4). Then section 5 discusses how we propose to evaluate the success of the task, before presenting our results (section 6). • finding the date of events described 2 Evaluating annotations • det"
C04-1008,P93-1010,0,0.169329,"• date computation to precise temporal locations of events associated with explicit, yet imprecise, temporal information, such as dates relative to the time of the text (e.g. last Monday). • for each event associated to a temporal adjunct, a temporal relation is established (with a date when possible). • a set of discourse rules is used to establish possible relations between two events appearing consecutively in the text, according to the tenses of the verbs introducing the events. These rules for French are similar to rules for English proposed in (Grover et al., 1995; Song and Cohen, 1991; Kameyama et al., 1993), but 1 We have defined 89 rules, divided in 29 levels. are expressed with Allen relations instead of a set of ad hoc relations (see Table 1 for a subset of the rules). These rules are only applied when no temporal marker indicates a specific relation between the two events. • the last step consists in computing a fixed point on the graph of relations between events recognized in the text, and dates. We used a classical path-consistency algorithm (Allen, 1984). More explanation is given section 4. Allen relations are illustrated Figure 2. In the following (and Table 1) they will be abbreviated"
C04-1008,W01-1315,0,0.409768,"nier IRIT, Université Paul Sabatier Toulouse, France tannier@emse.fr as beliefs, or reported speech have an unclear status in that respect. The third task adds another level of complexity: a lot of events described in a text do not have an explicit temporal stamp, and it is not always possible to determine one, even when taking context into account (Filatova and Hovy, 2001). This leads to an approach more suited to the level of underspecification found in texts: annotating relations between events in a symbolic way (e.g. that an event e1 is before another one e2 ). This is the path chosen by (Katz and Arosio, 2001; Setzer, 2001) with human annotators. This, in turn, raises new problems. First, what are the relations best suited to that task, among the many propositions (linguistic or logical) one can find for expressing temporal location ? Then, how can an annotation be evaluated, between annotators, or between a human annotator and an automated system ? Such annotations cannot be easy to determine automatically anyway, and must use some level of discourse modeling (cf. the work of (Grover et al., 1995)). • detecting event descriptions We want to show here the feasibility of such an effort, and we prop"
C04-1008,P00-1010,0,0.108467,"ults. It means we have made decisions that were not cautious enough, for reasons we still have to analyze. One potential reason is that relations offered to humans are maybe too vague in the wrong places: a lot of information in a text can be asserted to be &quot;strictly before&quot; something else (based on dates for instance), while human annotators can only say that events are &quot;before or meets&quot; some other event; each time this is the case, coherence is only 0.5. It is important to note that there are few points of comparison on this problem. To the best of our knowledge, only (Li et al., 2001) and (Mani and Wilson, 2000) mention having tried this kind of annotation, as a side job for their temporal expressions mark-up systems. The former considers only relations between events within a sentence, and the latter did not evaluate their method. Finally, it is worth remembering that human annotation itself is a difficult task, with potentially a lot of disagreement between annotators. For now, our texts have been annotated by the two authors, with an a posteriori resolution of conflicts. We therefore have no measure of inter-annotator agreement which could serve as an upper bound of the performance of the system,"
C04-1008,W01-1309,0,0.0120867,"hod used to extract temporal relations, using also a form of symbolic inference on available temporal information (section 4). Then section 5 discusses how we propose to evaluate the success of the task, before presenting our results (section 6). • finding the date of events described 2 Evaluating annotations • detecting dates and temporal markers • figuring out the temporal relations between events in a text The first task is not too difficult when looking for dates, e.g. using regular expressions (Wilson et al., 2001), but requires some syntactic analysis in a larger framework (Vazov, 2001; Shilder and Habel, 2001). The second one raises more difficult, ontological questions; what counts as an event is not uncontroversial (Setzer, 2001): attitude reports, such What we want to annotate is something close to the temporal model built by a human reader of a text; as such, it may involve some form of reasoning, based on various cues (lexical or discursive), and may be expressed in several ways. As was noticed by (Setzer, 2001), it is difficult to reach a good agreement between human annotators, as they can express relations between events in different, yet equivalent, ways. For instance, they can say that an"
C04-1008,W01-1312,0,0.0158486,"e why evaluating this particular task is not a trivial question. Section 3 will explain the method used to extract temporal relations, using also a form of symbolic inference on available temporal information (section 4). Then section 5 discusses how we propose to evaluate the success of the task, before presenting our results (section 6). • finding the date of events described 2 Evaluating annotations • detecting dates and temporal markers • figuring out the temporal relations between events in a text The first task is not too difficult when looking for dates, e.g. using regular expressions (Wilson et al., 2001), but requires some syntactic analysis in a larger framework (Vazov, 2001; Shilder and Habel, 2001). The second one raises more difficult, ontological questions; what counts as an event is not uncontroversial (Setzer, 2001): attitude reports, such What we want to annotate is something close to the temporal model built by a human reader of a text; as such, it may involve some form of reasoning, based on various cues (lexical or discursive), and may be expressed in several ways. As was noticed by (Setzer, 2001), it is difficult to reach a good agreement between human annotators, as they can expr"
C04-1008,W01-1305,0,\N,Missing
C04-1008,W01-1314,0,\N,Missing
C14-1114,C10-1037,0,0.0397853,"nce extraction is essential in extractive text summarization. In the unsupervised approach, sentences are scored using term weight and term proximity induced from a document collection (Goldstein et al., 2000). In the supervised approach, training data generated from reference summaries are used to learn classification or ranking models. New sentences are selected based on their confidence value on learned models (Wan et al., 2007). As information comes from documents on the same topic, it should be noticed that it is also important to reduce redundancy in MDS (Carbonell and Goldstein, 1998). Filippova (2010) builds a co-occurrence word graph from a collection of related sentences and generates a generic summary from the graph based on shortest path finding. Her algorithm is a hybrid method between extractive and abstractive approaches to MDS. 3 3.1 Resources and System Overview Corpus and Chronologies For this work, we use a corpus of newswire texts provided by the AFP French news agency. The English AFP corpus is composed of 1.3 million texts that span the 2004-2011 period (511 documents/day in average and 426 millions words). Each document is an XML file containing title, document creation time"
C14-1114,W00-0405,0,0.0707587,"b documents. Similarly, Zhao et al. (2007) use text similarity and time intensity for event clustering on social streams. Kessler et al. (2012) exploit temporal analysis to detect salient dates of an event from raw text. Following this direction, Battistelli et al. (2013) apply sequential pattern mining to select a one-sentence description for each salient date of an event. 2.2 Multidocument Summarization Sentence extraction is essential in extractive text summarization. In the unsupervised approach, sentences are scored using term weight and term proximity induced from a document collection (Goldstein et al., 2000). In the supervised approach, training data generated from reference summaries are used to learn classification or ranking models. New sentences are selected based on their confidence value on learned models (Wan et al., 2007). As information comes from documents on the same topic, it should be noticed that it is also important to reduce redundancy in MDS (Carbonell and Goldstein, 1998). Filippova (2010) builds a co-occurrence word graph from a collection of related sentences and generates a generic summary from the graph based on shortest path finding. Her algorithm is a hybrid method between"
C14-1114,P12-1077,1,0.727246,"Missing"
C14-1114,W04-1013,0,0.029008,"hown in Table 1, our method is close to ML. This result is encouraging as ML requires training data; and on the other hand, our system is not designed to directly solve the task of date selection. As expected, our system beats the unsupervised system DFIDF by a large margin. This superiority shows that the mixture of temporal information and content leads to an improvement on date selection over using only the former. 7.2 Evaluate Summary Generation In order to evaluate timelines as text summaries, we ignore dates and consider all the entries in a timeline as one summary. We use ROUGE metric (Lin, 2004) to evaluate generated timelines against reference summaries. The following baselines are implemented (Table 2): In DFIDF∗ , salient dates are taken from the outputs of the DFIDF system described in previous section. Each salient date is equivalent to a cluster containing all the events happening in that date. We then select the event the most relevant to the query, i.e. the event with the highest Lucene score, as representative of that salient date. Note that consequently, DFIDF∗ makes an assumption, which is not assumed in RaRE, that there is only one event happens in a particular date. The"
C14-1114,N10-1021,0,0.116098,"Missing"
C14-1114,D11-1040,0,0.103633,"Kadhafi and the rebels. Apr 10 2011. The former accepts their peace plan, but the latter refuse, saying Kadhafi and his sons must step down. Apr 12 2011. Britain and France call on their NATO allies to step up operations against Kadhafi’s forces. ... Figure 1: A chronology about “Libya conflict” written by journalists. (Sayyadi et al., 2009). These papers do not consider time, which is an essential dimension of event timelines. Attempts to use temporal information for EDT are significant in the literature. To name but a few, Alonso et al. (2009) apply time-based clustering on search results. Yan et al. (2011) use document timestamps to calculate temporal proximity for timeline generation from web documents. Similarly, Zhao et al. (2007) use text similarity and time intensity for event clustering on social streams. Kessler et al. (2012) exploit temporal analysis to detect salient dates of an event from raw text. Following this direction, Battistelli et al. (2013) apply sequential pattern mining to select a one-sentence description for each salient date of an event. 2.2 Multidocument Summarization Sentence extraction is essential in extractive text summarization. In the unsupervised approach, senten"
D13-1098,P08-1090,0,0.359935,"f temporal relations, but also to decide whether a temporal relation existed or not between two elements, either clinical concepts or temporal expressions. But, as in TempEval, the temporal analysis were only to be performed within a single document. Other works focus on event ordering. For example, Fujiki et al. (2003) and Talukdar et al. (2012) proposed methods for automatic acquisition of event sequences from texts. They did not use temporal information present in texts and extracted sequences of events (e.g. arrest/escape) from sentences which were already arranged in chronological order. Chambers and Jurafsky (2008) proposed a method to learn narrative chains of events related to a protagonist in a single document. The first step consists in detecting narrative relations between events sharing coreferring arguments. Then, a temporal classifier orders partially the connected events with the before relation. Concerning the identification of the reaction relation, to our knowledge, there is no work on the detection of reaction between several documents. Pouliquen et al. (2007), Krestel et al. (2008) and Balahur et al. (2009) focused on the identification of reported speech or opinions in quotations in a doc"
D13-1098,P07-2044,0,0.0213023,"the same sentence or in consecutive sentences and between events and the creation time of documents. In this context, the goal is to identify the type of a temporal relation which is 959 Figure 2: Example of “temporal graph”: Madrid attacks, with many updates of the initial information. Note that articles gathered in this main pool of articles can be posterior to the continuations and reactions to the described event. known to be present. Systems having the best results (accuracy about 0.6) use statistical learning based on temporal features (modality, tense, aspect, etc.) (Mani et al., 2006; Chambers et al., 2007). More recently, Mirroshandel and Ghassem-Sani (2012) proposed a new method for temporal relation extraction by using a bootstrapping method on annotated data and have a better accuracy than state-of-the-art systems. Their method is based on the assumption that similar event pairs in topically related documents are likely to have the same temporal relations. For this work, the authors had already some collections of topically related documents and did not need to identify them. In the 2012 i2b2 challenge (i2b, 2012), the problem was not only to identify the type of temporal relations, but also"
D13-1098,E03-1061,0,0.0415483,"vent pairs in topically related documents are likely to have the same temporal relations. For this work, the authors had already some collections of topically related documents and did not need to identify them. In the 2012 i2b2 challenge (i2b, 2012), the problem was not only to identify the type of temporal relations, but also to decide whether a temporal relation existed or not between two elements, either clinical concepts or temporal expressions. But, as in TempEval, the temporal analysis were only to be performed within a single document. Other works focus on event ordering. For example, Fujiki et al. (2003) and Talukdar et al. (2012) proposed methods for automatic acquisition of event sequences from texts. They did not use temporal information present in texts and extracted sequences of events (e.g. arrest/escape) from sentences which were already arranged in chronological order. Chambers and Jurafsky (2008) proposed a method to learn narrative chains of events related to a protagonist in a single document. The first step consists in detecting narrative relations between events sharing coreferring arguments. Then, a temporal classifier orders partially the connected events with the before relati"
D13-1098,P12-1077,1,0.841401,"Missing"
D13-1098,krestel-etal-2008-minding,0,0.0194484,"nces of events (e.g. arrest/escape) from sentences which were already arranged in chronological order. Chambers and Jurafsky (2008) proposed a method to learn narrative chains of events related to a protagonist in a single document. The first step consists in detecting narrative relations between events sharing coreferring arguments. Then, a temporal classifier orders partially the connected events with the before relation. Concerning the identification of the reaction relation, to our knowledge, there is no work on the detection of reaction between several documents. Pouliquen et al. (2007), Krestel et al. (2008) and Balahur et al. (2009) focused on the identification of reported speech or opinions in quotations in a document, but not on the identification of an event which is the source of a reaction and which can possibly be in another document. As we can see, all these approaches, as well as traditional information extraction approaches, lean on information contained by a single document, and consider an event as a word or a phrase. However, Ahmed et al. (2011) proposed a framework to group temporally and tocipally related news articles into same story clusters in order to reveal the temporal evolu"
D13-1098,P06-1095,0,0.0216086,"vents and times in the same sentence or in consecutive sentences and between events and the creation time of documents. In this context, the goal is to identify the type of a temporal relation which is 959 Figure 2: Example of “temporal graph”: Madrid attacks, with many updates of the initial information. Note that articles gathered in this main pool of articles can be posterior to the continuations and reactions to the described event. known to be present. Systems having the best results (accuracy about 0.6) use statistical learning based on temporal features (modality, tense, aspect, etc.) (Mani et al., 2006; Chambers et al., 2007). More recently, Mirroshandel and Ghassem-Sani (2012) proposed a new method for temporal relation extraction by using a bootstrapping method on annotated data and have a better accuracy than state-of-the-art systems. Their method is based on the assumption that similar event pairs in topically related documents are likely to have the same temporal relations. For this work, the authors had already some collections of topically related documents and did not need to identify them. In the 2012 i2b2 challenge (i2b, 2012), the problem was not only to identify the type of temp"
D13-1098,S07-1014,0,0.0153643,"results are given in Section 5. We also propose an end-user application to this work. When a user reads an article, the system will then be able to provide her with a thread of events having occurred before or after, helping her to contextualize the information she is reading. This application is described in Section 6. 2 Related work The identification of temporal relations between events in texts has been the focus of increasing attention because of its importance in NLP applications such as information extraction, question-answering or summarization. The evaluation campaigns TempEval 2007 (Verhagen et al., 2007) and TempEval 2010 (Verhagen et al., 2010) focused on temporal relation identification, mainly on temporal relations between events and times in the same sentence or in consecutive sentences and between events and the creation time of documents. In this context, the goal is to identify the type of a temporal relation which is 959 Figure 2: Example of “temporal graph”: Madrid attacks, with many updates of the initial information. Note that articles gathered in this main pool of articles can be posterior to the continuations and reactions to the described event. known to be present. Systems havi"
D13-1098,H05-1044,0,0.0254726,"Missing"
D15-1055,S15-2136,0,0.0455595,"Missing"
D15-1055,P11-2023,0,0.0312635,"d with normalized time expressions. We characterize temporal expression recognition in three domains and discuss how the development of an automated temporal expression identification tool may be impacted. For clinical text analysis, we experimented with standard tokenization (provided by TreeTagger (Schmid, 1994)) and a custom tokenization where punctuation marks are always considered as token separators, even in dates such as “10-022010” or “10.04.10”.2 2 For this study, we used two available French corpora with TIMEX3 annotations: the French TimeBank corpus (FTB called news in this paper) (Bittar et al., 2011) which covers the news domain and the AncientTimes corpus (ATC, called historical in this paper) (Strötgen et al., 2014b) which covers the historical domain. To cover a third domain, we developed a corpus using a set of clinical notes where personal identifying information (PII) had been marked and replaced by surrogates (Grouin and Névéol, 2014). This included marking some temporal expressions such as dates, which were replaced by surrogate dates obtained by substracting a fixed number of days to the original dates. Manual review ensured that there were no format or other errors in the reintr"
D15-1055,E12-2021,0,0.0825726,"Missing"
D15-1055,P13-1166,0,0.0682825,"Missing"
D15-1055,S10-1071,0,0.109988,"tations independently. This phase of the annotation process contributed to refining annotation guidelines and creating additional rules to improve on the pre-annotation. Subsequently, the rest of the corpus was divided between annotators, so that each document was annotated independently by two annotators. Final 3 Temporal Expression Extraction and Normalization Rule-based methods were shown to be very efficient for the extraction and normalization of time expressions from news narratives in several languages1 . In the latest SemEval campaign (UzZaman et al., 2013), the rule-based HeidelTime (Strötgen and Gertz, 2010) out performed machine-learning and hybrid counterparts by a large margin. However, statistical systems obtained promising results with respect to temporal entity extraction. Based on these results, we chose to use the state-of-the-art rule-based system HeidelTime as well as an in-house statistical tool relying on the Wapiti (Lavergne et al., 2010) implementation of Conditional Random Fields (CRFs) (Lafferty et al., 2001). Existing HeidelTime settings were used to customize it for the analysis of news and historical narratives in French. In addition, we developed a set of 14 rules to provide a"
D15-1055,strotgen-gertz-2012-temporal,0,0.0601929,"y the availability of the TimeBank corpus (Pustejovsky et al., 2003) used in evaluation campaigns such as TempEval (Verhagen et al., 2007). More recent efforts have extended the initial work on English and addressed other languages such as Chinese (Li et al., 2014), French (Moriceau and Tannier, 2014), Arabic, Italian, Spanish, and Vietnamese (Strötgen et al., 2014a). A study of three domain corpora in English in addition to the newswire domain (SMS, historical narratives and clinical trial abstracts) yielded interesting insight to extend the normalized representation of temporal expressions (Strötgen and Gertz, 2012). This work was then applied to cover historical narratives in an additional seven languages. One key finding was that domain specificity could differ between languages (Strötgen et al., 2014b). This prompts the need to study temporal analysis across domains in a variety of languages in order to adequately characterize each domain and language pairs. The prevalence of temporal references across all types of natural language utterances makes temporal analysis a key issue in Natural Language Processing. This work adresses three research questions: 1/is temporal expression recognition specific to"
D15-1055,P10-1052,0,0.0169474,"rmalization Rule-based methods were shown to be very efficient for the extraction and normalization of time expressions from news narratives in several languages1 . In the latest SemEval campaign (UzZaman et al., 2013), the rule-based HeidelTime (Strötgen and Gertz, 2010) out performed machine-learning and hybrid counterparts by a large margin. However, statistical systems obtained promising results with respect to temporal entity extraction. Based on these results, we chose to use the state-of-the-art rule-based system HeidelTime as well as an in-house statistical tool relying on the Wapiti (Lavergne et al., 2010) implementation of Conditional Random Fields (CRFs) (Lafferty et al., 2001). Existing HeidelTime settings were used to customize it for the analysis of news and historical narratives in French. In addition, we developed a set of 14 rules to provide additional customization for the analysis of clinical narratives in French. The CRF model was developed using part of the clinical corpus as a training set, with domain independant surface and lexical features for the text tokens: • The original token from the text (word form); • Surface features: capitalization of the token (all in upper/lower case"
D15-1055,E14-4026,0,0.05151,"Missing"
D15-1055,strotgen-etal-2014-extending,0,0.0343206,"Missing"
D15-1055,moriceau-tannier-2014-french,1,0.895531,"Missing"
D15-1055,S13-2001,0,0.0366908,"e annotators’ task was then to revise the pre-annotations independently. This phase of the annotation process contributed to refining annotation guidelines and creating additional rules to improve on the pre-annotation. Subsequently, the rest of the corpus was divided between annotators, so that each document was annotated independently by two annotators. Final 3 Temporal Expression Extraction and Normalization Rule-based methods were shown to be very efficient for the extraction and normalization of time expressions from news narratives in several languages1 . In the latest SemEval campaign (UzZaman et al., 2013), the rule-based HeidelTime (Strötgen and Gertz, 2010) out performed machine-learning and hybrid counterparts by a large margin. However, statistical systems obtained promising results with respect to temporal entity extraction. Based on these results, we chose to use the state-of-the-art rule-based system HeidelTime as well as an in-house statistical tool relying on the Wapiti (Lavergne et al., 2010) implementation of Conditional Random Fields (CRFs) (Lafferty et al., 2001). Existing HeidelTime settings were used to customize it for the analysis of news and historical narratives in French. In"
D15-1055,W14-3413,0,0.0238685,"can be done with limited efforts and should cover pre-processing as well as temporal specific tasks. 1 Aurélie Névéol LIMSI-CNRS UPR 3251 Rue John von Neuman 91403 Orsay, France neveol@limsi.fr The clinical domain has been addressed during the 2012 i2b2 challenge (Sun et al., 2013b), with a task on temporal relation extraction from clinical narratives. This task used a corpus of clinical notes in English annotated with temporal information (Sun et al., 2013a) based on ISOTimeML (Pustejovsky et al., 2010). It prompted further work in this domain in English (Jindal and Roth, 2013) and Swedish (Velupillai, 2014), including the release of detailed guidelines for creating temporal annotations of clinical text and a discussion of the clinical domain specificity related to temporal aspects (Styler IV et al., 2014). Finally, clinical TempEval 2015 brought the temporal information extraction tasks of past TempEval campaigns to the clinical domain (Bethard et al., 2015). Introduction References to phenomena occurring in the world and their temporal characterization can be found in natural language utterances across domains, genres and languages. Temporal analysis is a key issue in natural language processin"
D15-1055,S07-1014,0,0.108163,"Missing"
D15-1055,pustejovsky-etal-2010-iso,0,\N,Missing
D15-1055,Q14-1012,0,\N,Missing
de-groc-etal-2014-thematic,W04-3252,0,\N,Missing
de-groc-etal-2014-thematic,baroni-bernardini-2004-bootcat,0,\N,Missing
de-groc-etal-2014-thematic,J03-3001,0,\N,Missing
de-groc-tannier-2014-evaluating,baroni-bernardini-2004-bootcat,0,\N,Missing
de-groc-tannier-2014-evaluating,J03-3001,0,\N,Missing
E17-2117,S15-2136,0,0.04979,"creation time from clinical notes. This work, based on a feature engineering approach, obtained competitive results with the current state-of-theart and led to two main conclusions. First, the use of word embeddings in place of lexical features tends to degrade performance. Second, our feature engineering approach can be applied with comparable results to two different languages, English and French in our case. To follow-up with the first conclusion, we would like to test a more integrated approach for using embeddings, either by turning all features into embeddings as in Yang and Eisenstein (2015) or by adopting a neural network architecture as in Chikka (2016). Concerning the CR task, results are separated by a 10 percent gap (0.65 for the MERLOT corpus and 0.53 for the THYME corpus). Results obtained for the THYME corpus are coherent with those obtained by Tourille et al. (2016) on the Clinical TempEval 2016 evaluation corpus2 . We increased the recall value in comparison to their results (from 0.436 to 0.47) but this measure is still the main point to improve. More globally, the best results of the Clinical TempEval shared task were 0.843 (accuracy) for the DR task and 0.573 (F1-Mea"
E17-2117,S16-1201,0,0.0612921,"Missing"
E17-2117,S16-1165,0,0.0337299,"ustejovsky and Stubbs, 2011) can be apprehended as temporal buckets in which several events may be included. These containers are anchored by temporal expressions, medical events or other concepts. Styler IV et al. (2014) argue that the use of narrative containers instead of classical temporal relations (Allen, 1983) yields better annotation while keeping most of the useful temporal information intact. The concept of narrative container is illustrated in Figure 1 and described further in Pustejovsky and Stubbs (2011). val task related to the topic for the past two years (Bethard et al., 2015; Bethard et al., 2016). Its first track focused on extracting clinical events and temporal expressions, while its second track included DR and CR tasks. Different approaches were implemented by the teams, among which SVM classifiers (Lee et al., 2016; Tourille et al., 2016; Cohan et al., 2016; AAl Abdulsalam et al., 2016) and CRF approaches (Caselli and Morante, 2016; AAl Abdulsalam et al., 2016) for the DR task, and CRF, Convolutional neural networks (Chikka, 2016) and SVM classifiers (Tourille et al., 2016; Lee et al., 2016; AAl Abdulsalam et al., 2016) for the CR task. 3 Corpus Presentation The MERLOT corpus is"
E17-2117,S16-1192,0,0.135986,"in Figure 1 and described further in Pustejovsky and Stubbs (2011). val task related to the topic for the past two years (Bethard et al., 2015; Bethard et al., 2016). Its first track focused on extracting clinical events and temporal expressions, while its second track included DR and CR tasks. Different approaches were implemented by the teams, among which SVM classifiers (Lee et al., 2016; Tourille et al., 2016; Cohan et al., 2016; AAl Abdulsalam et al., 2016) and CRF approaches (Caselli and Morante, 2016; AAl Abdulsalam et al., 2016) for the DR task, and CRF, Convolutional neural networks (Chikka, 2016) and SVM classifiers (Tourille et al., 2016; Lee et al., 2016; AAl Abdulsalam et al., 2016) for the CR task. 3 Corpus Presentation The MERLOT corpus is composed of clinical documents written in French from a Gastroenterology, Hepatology and Nutrition department. These documents have been de-identified (Grouin and Névéol, 2014) and annotated with entities, temporal expressions and relations (Deléger et al., 2014). The THYME corpus is a collection of clinical texts written in English from a cancer department that have been released during the Clinical TempEval campaigns. This corpus contains doc"
E17-2117,W11-0419,0,0.458059,"te, F-91191 France. olivier.ferret@cea.fr Xavier Tannier LIMSI, CNRS Univ. Paris-Sud Université Paris-Saclay xavier.tannier@limsi.fr Aurélie Névéol LIMSI, CNRS Université Paris-Saclay aurelie.neveol@limsi.fr Abstract In the DR task, the objective is to temporally locate EVENT entities according to the Document Creation Time of the document in which they occur. Possible tags are Before, Before-Overlap, Overlap and After. In the CR task, the objective is to identify temporal inclusion relations between pairs of entities (EVENT and/or TIMEX3) formalized as narrative container relations following Pustejovsky and Stubbs (2011). In this context, we build on Tourille et al. (2016) and show how this type of model can be applied for extracting temporal relations from clinical texts similarly in two languages. We experimented more specifically on two corpora: the THYME corpus (Styler IV et al., 2014), a corpus of de-identified clinical notes in English from the Mayo Clinic and the MERLOT corpus (Campillos et al., to appear), a comparable corpus in French from a group of French hospitals. In this paper, we present a method for temporal relation extraction from clinical narratives in French and in English. We experiment o"
E17-2117,S16-1194,0,0.117119,"f classical temporal relations (Allen, 1983) yields better annotation while keeping most of the useful temporal information intact. The concept of narrative container is illustrated in Figure 1 and described further in Pustejovsky and Stubbs (2011). val task related to the topic for the past two years (Bethard et al., 2015; Bethard et al., 2016). Its first track focused on extracting clinical events and temporal expressions, while its second track included DR and CR tasks. Different approaches were implemented by the teams, among which SVM classifiers (Lee et al., 2016; Tourille et al., 2016; Cohan et al., 2016; AAl Abdulsalam et al., 2016) and CRF approaches (Caselli and Morante, 2016; AAl Abdulsalam et al., 2016) for the DR task, and CRF, Convolutional neural networks (Chikka, 2016) and SVM classifiers (Tourille et al., 2016; Lee et al., 2016; AAl Abdulsalam et al., 2016) for the CR task. 3 Corpus Presentation The MERLOT corpus is composed of clinical documents written in French from a Gastroenterology, Hepatology and Nutrition department. These documents have been de-identified (Grouin and Névéol, 2014) and annotated with entities, temporal expressions and relations (Deléger et al., 2014). The TH"
E17-2117,deleger-etal-2014-annotation,1,0.896819,"Missing"
E17-2117,S16-1175,1,0.820831,"SI, CNRS Univ. Paris-Sud Université Paris-Saclay xavier.tannier@limsi.fr Aurélie Névéol LIMSI, CNRS Université Paris-Saclay aurelie.neveol@limsi.fr Abstract In the DR task, the objective is to temporally locate EVENT entities according to the Document Creation Time of the document in which they occur. Possible tags are Before, Before-Overlap, Overlap and After. In the CR task, the objective is to identify temporal inclusion relations between pairs of entities (EVENT and/or TIMEX3) formalized as narrative container relations following Pustejovsky and Stubbs (2011). In this context, we build on Tourille et al. (2016) and show how this type of model can be applied for extracting temporal relations from clinical texts similarly in two languages. We experimented more specifically on two corpora: the THYME corpus (Styler IV et al., 2014), a corpus of de-identified clinical notes in English from the Mayo Clinic and the MERLOT corpus (Campillos et al., to appear), a comparable corpus in French from a group of French hospitals. In this paper, we present a method for temporal relation extraction from clinical narratives in French and in English. We experiment on two comparable corpora, the MERLOT corpus for Frenc"
E17-2117,N15-1069,0,0.0152944,"essions and document creation time from clinical notes. This work, based on a feature engineering approach, obtained competitive results with the current state-of-theart and led to two main conclusions. First, the use of word embeddings in place of lexical features tends to degrade performance. Second, our feature engineering approach can be applied with comparable results to two different languages, English and French in our case. To follow-up with the first conclusion, we would like to test a more integrated approach for using embeddings, either by turning all features into embeddings as in Yang and Eisenstein (2015) or by adopting a neural network architecture as in Chikka (2016). Concerning the CR task, results are separated by a 10 percent gap (0.65 for the MERLOT corpus and 0.53 for the THYME corpus). Results obtained for the THYME corpus are coherent with those obtained by Tourille et al. (2016) on the Clinical TempEval 2016 evaluation corpus2 . We increased the recall value in comparison to their results (from 0.436 to 0.47) but this measure is still the main point to improve. More globally, the best results of the Clinical TempEval shared task were 0.843 (accuracy) for the DR task and 0.573 (F1-Mea"
E17-2117,P14-5010,0,\N,Missing
E17-2117,S16-1193,0,\N,Missing
E17-2117,S16-1195,0,\N,Missing
F12-2014,baroni-bernardini-2004-bootcat,0,0.0452103,"Missing"
F12-2014,E03-1020,0,0.0814685,"Missing"
F12-2014,C04-1194,0,0.0500369,"Missing"
F12-2014,W11-1106,1,0.860763,"Missing"
F12-2014,J03-3001,0,0.0398162,"Missing"
F12-2014,W04-3252,0,0.0319436,"Missing"
F12-2014,P93-1024,0,0.383865,"Missing"
F12-2014,P09-1027,0,0.0674638,"Missing"
F13-2018,W13-0106,0,0.045046,"Missing"
F13-2018,P06-1095,0,0.0447524,"Missing"
F13-2018,C08-3012,0,0.047038,"Missing"
galibert-etal-2010-hybrid,grover-etal-2000-lt,0,\N,Missing
galibert-etal-2010-hybrid,galibert-etal-2010-named,1,\N,Missing
galibert-etal-2010-named,W04-1213,0,\N,Missing
galibert-etal-2010-named,galibert-etal-2010-hybrid,1,\N,Missing
galibert-etal-2010-named,C96-1079,0,\N,Missing
galibert-etal-2010-named,P05-1045,0,\N,Missing
grappy-etal-2010-corpus,cramer-etal-2006-building,0,\N,Missing
grappy-etal-2010-corpus,rosset-petel-2006-ritel,0,\N,Missing
grappy-etal-2010-corpus,varasai-etal-2008-building,0,\N,Missing
L16-1179,piperidis-2012-meta,0,0.0231461,"useum reviews in French. All but the last dataset were released for Subtask 1 (Sentence-level ABSA) and part of the data was annotated at the text level for Subtask 2 (Textlevel ABSA). The French Museum reviews dataset was released for Subtask 3 “Out-of-domain ABSA” where only test and no training data was provided.1 In what follows, we describe the data collection procedure and the annotation guidelines that were developed for the two domains addressed in French. The data and the annotation guidelines are publicly available under a noncommercial, no redistribution license2 through METASHARE (Piperidis, 2012),3 a repository devoted to the sharing and dissemination of language resources, and on the SemEval-2016 ABSA task website.4 2. 2.1. Datasets and Annotation Data Collection French datasets were developed for two of the SemEval2016 ABSA subtasks. For in-domain sentence-level ABSA (Subtask 1) the dataset comprises annotated restaurant reviews while for out-of-domain ABSA (Subtask 3) annotated museum reviews were released. For the first subtask, the restaurant domain, both training and test data was provided. In Subtask 3, the participating teams had the opportunity to test their systems in a prev"
L16-1179,S14-2004,0,0.109863,"Missing"
L16-1179,S15-2082,0,0.162236,"provided. The second dataset is a smaller set of museum reviews for which no training data is available, dedicated to out-of-domain ABSA evaluation. The ABSA task was first introduced for English in the SemEval 2014 evaluation campaign (Pontiki et al., 2014), where restaurant and laptop reviews annotated with aspect terms, categories and their polarity were provided for training and testing ABSA systems. The task was repeated in SemEval 2015 with a different, more unified, framework where aspect categories were defined as combinations of an entity type, an attribute type and a polarity value (Pontiki et al., 2015): (1) The fajitas were delicious, but expensive. {FOOD#QUALITY, TARGET: fajitas}→POSITIVE {FOOD#PRICES, TARGET: fajitas}→NEGATIVE (2) Great for a romantic evening. {AMBIENCE#GENERAL, TARGET: NULL }→ POSITIVE An out-of-domain subtask was also proposed where annotated hotel reviews were provided for testing but no training data was released. In 2016, the SemEval ABSA task became multilingual (Pontiki et al., 2016). New datasets were released for English allowing systems to be tested on the same domains as in previous years (laptops, restaurants and hotels), but datasets were also developed in ne"
L16-1179,S16-1002,1,0.901634,"Missing"
L16-1307,W14-2907,0,0.0454247,"Missing"
L16-1307,P11-1098,0,0.379792,"by the task of template filling. The objective of this task is to assign event roles to individual textual mentions. A template defines a specific type of events (e.g. earthquakes), associated with semantic roles (or slots) hold by entities (for earthquakes, typically their location, date, magnitude and the damages they caused (Jean-Louis et al., 2011)). This kind of structures is comparable to the schemas of (Schank and Abelson, 1977). Schema induction is the task of learning these structures with no supervision from unlabeled texts. We focus here more specifically on event schema induction (Chambers and Jurafsky, 2011; Chambers, 2013; Cheung et al., 2013; Nguyen et al., 2015). The idea is to group entities corresponding to the same role into an event template. Figure 1 illustrates this process. Previous work on event schema induction was evaluated on the MUC-4 corpus (Grishman and Sundheim, 1996). However, this corpus raises two main issues: • It was annotated with templates describing all events with the same set of slots. • It doesn’t contain redundancy. The first issue is clearly a limitation due to the fact that all the considered types of events in the MUC-4 corpus are close to each other while the se"
L16-1307,D13-1185,0,0.223806,"ng. The objective of this task is to assign event roles to individual textual mentions. A template defines a specific type of events (e.g. earthquakes), associated with semantic roles (or slots) hold by entities (for earthquakes, typically their location, date, magnitude and the damages they caused (Jean-Louis et al., 2011)). This kind of structures is comparable to the schemas of (Schank and Abelson, 1977). Schema induction is the task of learning these structures with no supervision from unlabeled texts. We focus here more specifically on event schema induction (Chambers and Jurafsky, 2011; Chambers, 2013; Cheung et al., 2013; Nguyen et al., 2015). The idea is to group entities corresponding to the same role into an event template. Figure 1 illustrates this process. Previous work on event schema induction was evaluated on the MUC-4 corpus (Grishman and Sundheim, 1996). However, this corpus raises two main issues: • It was annotated with templates describing all events with the same set of slots. • It doesn’t contain redundancy. The first issue is clearly a limitation due to the fact that all the considered types of events in the MUC-4 corpus are close to each other while the second issue is mo"
L16-1307,N13-1104,0,0.122402,"Missing"
L16-1307,C96-1079,0,0.58605,"comings. We make use of Wikinews to select the data inside the category Laws & Justice, and query Google search engine to retrieve different documents on the same events. Only Wikinews documents are manually annotated and can be used for evaluation, while the others can be used for unsupervised learning. We detail the methodology used for building the corpus and evaluate some existing systems on this new data. Keywords: Event extraction, corpus creation, unsupervised methods. 1. Introduction ... Information Extraction has been defined by the Message Understanding Conference (MUC) evaluations (Grishman and Sundheim, 1996) and its successors, i.e. the Automatic Content Extraction (ACE) (Doddington et al., 2004) and Text Analysis Conference (TAC) (Ellis et al., 2014) evaluations, specifically by the task of template filling. The objective of this task is to assign event roles to individual textual mentions. A template defines a specific type of events (e.g. earthquakes), associated with semantic roles (or slots) hold by entities (for earthquakes, typically their location, date, magnitude and the damages they caused (Jean-Louis et al., 2011)). This kind of structures is comparable to the schemas of (Schank and Ab"
L16-1307,I11-1081,1,0.894816,"Missing"
L16-1307,P15-1019,1,0.914048,"Missing"
L16-1307,W15-0812,0,0.0138618,"pes to broader domains, such as LIFE, TRANSACTION and JUSTICE, with specific roles for each of them. Moreover, in ACE, mentions of the same entity in a document are also grouped together. In relation to this last issue, the TAC KBP evaluation includes an entity linking task to match different mentions of the same entity across documents through their link to a knowledge base. However, the second issue could not be resolved solely by adding entity linking information. A more in-depth comparison and discussion of the different event annotation schemas can be found in (Aguilar et al., 2014) and (Song et al., 2015). 3. ASTRE Corpus In order to remedy the shortcomings described in the previous section, we propose a corpus with the following Figure 3: Framework for building and using the ASTRE corpus. Figure 3 gives an overview of the framework defined for building and using the ASTRE corpus. A collection of documents was first selected from a Wikinews category in English. The Google search engine was then used to retrieve documents from the Web that were similar to these seed documents, with specific time ranges. These retrieved documents were then used for inducing event schemas. At the same time, the W"
L16-1307,E12-2021,0,0.0198236,"Missing"
L16-1307,doddington-etal-2004-automatic,0,\N,Missing
moriceau-tannier-2014-french,P12-1077,1,\N,Missing
moriceau-tannier-2014-french,S10-1010,0,\N,Missing
moriceau-tannier-2014-french,pustejovsky-etal-2010-iso,0,\N,Missing
moriceau-tannier-2014-french,P11-2023,0,\N,Missing
moriceau-tannier-2014-french,S13-2003,0,\N,Missing
P12-1077,W11-0219,0,0.0587123,"Missing"
P12-1077,I05-1037,0,0.0592621,"Missing"
P12-1077,pustejovsky-etal-2010-iso,0,0.0363039,"nt with respect to the given topic. Each date is presented with a set of relevant sentences. We can see this work as a new, easily evaluable task of “date extraction”, which is an important component of timeline summarization. In what follows, we first review some of the related work in Section 2. Section 3 presents the resources used and gives an overview of the system. The system used for temporal analysis is described in Section 4, and the strategy used for indexing and finding salient dates, as well as the results obtained, are given in Section 51 . 2 Related Work The ISO-TimeML language (Pustejovsky et al., 2010) is a specification language for manual annotation of temporal information in texts, but, to the best of our knowledge, it has not yet actually been used in information retrieval systems. Neverthe1 This work has been partially funded by French National Research Agency (ANR) under project Chronolines (ANR-10CORD-010). We would like to thank the French News Agency (AFP) for providing us with the corpus. 730 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 730–739, c Jeju, Republic of Korea, 8-14 July 2012. 2012 Association for Computational Linguisti"
P12-1077,2004.jeptalnrecital-long.30,0,0.0335375,"pache.org 732 4 Temporal and Linguistic Processing In this section, we describe the linguistic and temporal information extracted during the pre-processing phase and how the extraction is carried out. We rely on the powerful linguistic analyzer XIP (A¨ıtMokhtar et al., 2002), that we adapted for our purposes. 4.1 XIP The linguistic analyzer we use performs a deep syntactic analysis of running text. It takes as input XML files and analyzes the textual content enclosed in the various XML tags in different ways that are specified in an XML guide (a file providing instructions to the parser, see (Roux, 2004) for details). XIP performs complete linguistic processing ranging from tokenization to deep grammatical dependency analysis. It also performs named entity recognition (NER) of the most usual named entity categories and recognizes temporal expressions. Linguistic units manipulated by the parser are either terminal categories or chunks. Each of these units is associated with an attribute-value matrix that contains the unit’s relevant morphological, syntactic and semantic information. Linguistic constituents are linked by oriented and labelled n-ary relations denoting syntactic or semantic prope"
P12-1077,S07-1014,0,0.026926,"cognition Named Entity (NE) Recognition is one of the outputs provided by XIP. NEs are represented as unary relations in the parser output. We used the existing NE recognition module of the English grammar which tags the following NE types: location names, person names and organization names. Ambiguous NE types (ambiguity between type location or organization for country names for instance) are also considered. 4.3 Temporal Analysis A previous module for temporal analysis was developed and integrated into the English grammar (Hag`ege and Tannier, 2008), and evaluated during TempEval campaign (Verhagen et al., 2007). This module was adapted for tagging salient dates. Our goal with temporal analysis is to be able to tag and normalize3 a selected subset of temporal expressions (TEs) which we consider to be relevant for our task. This subset of expressions is described in the following sections. 4.3.1 Absolute Dates Absolute dates are dates that can be normalized without external or contextual knowledge. This is the case, for instance, of “On January 5th 2003”. In these expressions, all information needed for normalization is contained in the linguistic expression. 3 We call normalization the operation of t"
P12-1077,D11-1040,0,0.0395753,"present a system that uses measures of pertinence and novelty to construct timelines that consist of one sentence per date. (Chieu and Lee, 2004) propose a similar system that extracts events relevant to a query from a collection of documents. Important events are those reported in a large number of news articles and each event is constructed according to one single query and represented by a set of sentences. (Swan and Allen, 2000) present an approach to generating graphical timelines that involves extracting clusters of noun phrases and named entities. More recently, (Yan et 731 al., 2011b; Yan et al., 2011a) used a summarizationbased approach to automatically generate timelines, taking into account the evolutionary characteristics of news. 3 Resources and System Overview 3.1 AFP Corpus For this work, we used a corpus of newswire texts provided by the AFP French news agency. The English AFP corpus is composed of 1.3 million texts that span the 2004-2011 period (511 documents/day in average and 426 millions words). Each document is an XML file containing a title, a date of creation (DCT), set of keywords, and textual content split into paragraphs. 3.2 AFP Chronologies AFP “chronologies” (textual"
P15-1019,D13-1185,0,0.698682,"d weakly supervised forms of Information Extraction including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to #2 #3 #4 Attributes [armed:amod] Head man [police:nn] [] [innocent:amod, young:amod] statio"
P15-1019,N13-1104,0,0.493723,"forms of Information Extraction including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to #2 #3 #4 Attributes [armed:amod] Head man [police:nn] [] [innocent:amod, young:amod] station policeman man Triggers"
P15-1019,eichler-etal-2008-unsupervised,0,0.0170829,", 1980), used by early text understanding systems (DeJong, 1982) and more recently by Ferret and Grau (1997). First attempts for applying such processes to schema induction have been made in the fields of Information Extraction (Collier, 1998), Automatic Summarization (Harabagiu, 2004) and event QuestionAnswering (Filatova et al., 2006; Filatova, 2008). More recently, work after (Hasegawa et al., 2004) has developed weakly supervised forms of Information Extraction including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013"
P15-1019,D13-1178,0,0.515493,"tion extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to #2 #3 #4 Attributes [armed:amod] Head man [police:nn] [] [innocent:amod, young:amod] station policeman man Triggers [attack:nsubj, kill:nsubj] [attack:dobj] [kill:dobj] [wound:dobj] Figure 1: Entity representation as tuples of ([attributes], head, [triggers]"
P15-1019,P06-2027,0,0.200404,"e, 2006) tried to overcome this difficulty in another way by exploiting templates induced from representative documents selected by queries. Event schema induction takes root in work on the acquisition from text of knowledge structures, such as the Memory Organization Packets (Schank, 1980), used by early text understanding systems (DeJong, 1982) and more recently by Ferret and Grau (1997). First attempts for applying such processes to schema induction have been made in the fields of Information Extraction (Collier, 1998), Automatic Summarization (Harabagiu, 2004) and event QuestionAnswering (Filatova et al., 2006; Filatova, 2008). More recently, work after (Hasegawa et al., 2004) has developed weakly supervised forms of Information Extraction including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like seman"
P15-1019,P08-1090,0,0.469532,"including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to #2 #3 #4 Attributes [armed:amod] Head man [police:nn] [] [innocent:amod, young:amod] station policeman man Triggers [attack:nsubj, kill:nsubj] [attack:dobj"
P15-1019,D11-1133,0,0.0226058,"rist attacks, entities that are objects of verbs to kill, to attack can be grouped together and characterized by a role 188 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 188–197, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics 2 Related Work #1 Despite efforts made for making template filling as generic as possible, it still depends heavily on the type of events. Mixing generic processes with a restrictive number of domainspecific rules (Freedman et al., 2011) or examples (Grishman and He, 2014) is a way to reduce the amount of effort needed for adapting a system to another domain. The approaches of Ondemand information extraction (Hasegawa et al., 2004; Sekine, 2006) and Preemptive Information Extraction (Shinyama and Sekine, 2006) tried to overcome this difficulty in another way by exploiting templates induced from representative documents selected by queries. Event schema induction takes root in work on the acquisition from text of knowledge structures, such as the Memory Organization Packets (Schank, 1980), used by early text understanding syst"
P15-1019,P09-1068,0,0.508036,"their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to #2 #3 #4 Attributes [armed:amod] Head man [police:nn] [] [innocent:amod, young:amod] station policeman man Triggers [attack:nsubj, kill:nsubj] [attack:dobj] [kill:dobj] [wound:dobj] Fig"
P15-1019,E14-1006,0,0.205916,"Missing"
P15-1019,P11-1098,0,0.573312,"Missing"
P15-1019,E14-1024,0,0.378934,"the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to #2 #3 #4 Attributes [armed:amod] Head man [police:nn] [] [innocent:amod, young:amod] station policeman man Triggers [attack:nsubj, kill:nsubj] [attack:dobj] [kill:dobj] [wound:dobj] Figure 1: Entity representation as tuples of ([attributes], head, [triggers]). events, such as (Frermann et al., 2014), (Pichotta and Mooney, 2014) or (Modi and Titov, 2014). The work we present in this article is in line with Chambers (2013), which will be described in more details in Section 5, together with a quantitative and qualitative comparison. 3 Entity Representation An entity is represented as a triple containing: a head word h, a list A of attribute relations and a list T of trigger relations. Consider the following example: (1) Two armed men attacked the police station and killed a policeman. An innocent young man was also wounded. As illustrated in Figure 1, four entities, equivalent to four separated triples, are generated"
P15-1019,C96-1079,0,0.464628,"ntities. However, elements other than head words contain useful information. For instance, an armed man is more discriminative than man. Our model takes into account this information and precisely represents it using probabilistic topic distributions. We illustrate that such information plays an important role in parameter estimation. Mostly, it makes topic distributions more coherent and more discriminative. Experimental results on benchmark dataset empirically confirm this enhancement. 1 Introduction Information Extraction was initially defined (and is still defined) by the MUC evaluations (Grishman and Sundheim, 1996) and more specifically by the task of template filling. The objective of this task is to assign event roles to individual textual mentions. A template defines a specific type of events (e.g. earthquakes), associated with semantic roles (or slots) hold by entities (for earthquakes, their location, date, magnitude and the damages they caused (Jean-Louis et al., 2011)). Schema induction is the task of learning these templates with no supervision from unlabeled text. We focus here on event schema induction and continue the trend of generative models proposed earlier for this task. The idea is to g"
P15-1019,I08-1021,0,0.123869,"xtraction (Collier, 1998), Automatic Summarization (Harabagiu, 2004) and event QuestionAnswering (Filatova et al., 2006; Filatova, 2008). More recently, work after (Hasegawa et al., 2004) has developed weakly supervised forms of Information Extraction including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All"
P15-1019,P10-1100,0,0.0731721,"ation (Harabagiu, 2004) and event QuestionAnswering (Filatova et al., 2006; Filatova, 2008). More recently, work after (Hasegawa et al., 2004) has developed weakly supervised forms of Information Extraction including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event roles and the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induct"
P15-1019,P04-1053,0,0.0303377,"l Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 188–197, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics 2 Related Work #1 Despite efforts made for making template filling as generic as possible, it still depends heavily on the type of events. Mixing generic processes with a restrictive number of domainspecific rules (Freedman et al., 2011) or examples (Grishman and He, 2014) is a way to reduce the amount of effort needed for adapting a system to another domain. The approaches of Ondemand information extraction (Hasegawa et al., 2004; Sekine, 2006) and Preemptive Information Extraction (Shinyama and Sekine, 2006) tried to overcome this difficulty in another way by exploiting templates induced from representative documents selected by queries. Event schema induction takes root in work on the acquisition from text of knowledge structures, such as the Memory Organization Packets (Schank, 1980), used by early text understanding systems (DeJong, 1982) and more recently by Ferret and Grau (1997). First attempts for applying such processes to schema induction have been made in the fields of Information Extraction (Collier, 1998)"
P15-1019,I11-1081,1,0.884616,"ns more coherent and more discriminative. Experimental results on benchmark dataset empirically confirm this enhancement. 1 Introduction Information Extraction was initially defined (and is still defined) by the MUC evaluations (Grishman and Sundheim, 1996) and more specifically by the task of template filling. The objective of this task is to assign event roles to individual textual mentions. A template defines a specific type of events (e.g. earthquakes), associated with semantic roles (or slots) hold by entities (for earthquakes, their location, date, magnitude and the damages they caused (Jean-Louis et al., 2011)). Schema induction is the task of learning these templates with no supervision from unlabeled text. We focus here on event schema induction and continue the trend of generative models proposed earlier for this task. The idea is to group together entities corresponding to the same role in an event template based on the similarity of the relations that these entities hold with predicates. For example, in a corpus about terrorist attacks, entities that are objects of verbs to kill, to attack can be grouped together and characterized by a role 188 Proceedings of the 53rd Annual Meeting of the Ass"
P15-1019,P06-2094,0,0.118107,"Missing"
P15-1019,P14-5010,0,0.00472954,"policeman. An innocent young man was also wounded. As illustrated in Figure 1, four entities, equivalent to four separated triples, are generated from the text above. Head words are extracted from noun phrases. A trigger relation is composed of a predicate (attack, kill, wound) and a dependency type (subject, object). An attribute relation is composed of an argument (armed, police, young) and a dependency type (adjectival, nominal or verbal modifier). In the relationship to triggers, a head word is argument, but in the relationship to attributes, it is predicate. We use Stanford NLP toolkit (Manning et al., 2014) for parsing and coreference resolution. A head word is extracted if it is a nominal or proper noun and it is related to at least one trigger; pronouns are omitted. A trigger of an head word is extracted if it is a verb or an eventive noun and the head word serves as its subject, object, or preposition. We use the categories noun.EVENT and noun.ACT in WordNet as a list of eventive nouns. A head word can have more than one trigger. These multiple relations can come from a syntactic coordination inside a single sentence, as it is the case in the first sentence of the illustrating example. They c"
P15-1019,N06-1039,0,0.0167643,"Processing, pages 188–197, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics 2 Related Work #1 Despite efforts made for making template filling as generic as possible, it still depends heavily on the type of events. Mixing generic processes with a restrictive number of domainspecific rules (Freedman et al., 2011) or examples (Grishman and He, 2014) is a way to reduce the amount of effort needed for adapting a system to another domain. The approaches of Ondemand information extraction (Hasegawa et al., 2004; Sekine, 2006) and Preemptive Information Extraction (Shinyama and Sekine, 2006) tried to overcome this difficulty in another way by exploiting templates induced from representative documents selected by queries. Event schema induction takes root in work on the acquisition from text of knowledge structures, such as the Memory Organization Packets (Schank, 1980), used by early text understanding systems (DeJong, 1982) and more recently by Ferret and Grau (1997). First attempts for applying such processes to schema induction have been made in the fields of Information Extraction (Collier, 1998), Automatic Summarization (Harabagiu, 2004) and event QuestionAnswering (Filatova"
P15-1019,D12-1094,0,0.0125696,"DeJong, 1982) and more recently by Ferret and Grau (1997). First attempts for applying such processes to schema induction have been made in the fields of Information Extraction (Collier, 1998), Automatic Summarization (Harabagiu, 2004) and event QuestionAnswering (Filatova et al., 2006; Filatova, 2008). More recently, work after (Hasegawa et al., 2004) has developed weakly supervised forms of Information Extraction including schema induction in their objectives. However, they have been mainly applied to binary relation extraction in practice (Eichler et al., 2008; Rosenfeld and Feldman, 2007; Min et al., 2012). In parallel, several approaches were proposed for performing specifically schema induction in already existing frameworks: clause graph clustering (Qiu et al., 2008), event sequence alignment (Regneri et al., 2010) or LDA-based approach relying on FrameNet-like semantic frames (Bejan, 2008). More event-specific generative models were proposed by Chambers (2013) and Cheung et al. (2013). Finally, Chambers and Jurafsky (2008), Chambers and Jurafsky (2009), Chambers and Jurafsky (2011), improved by Balasubramanian et al. (2013), and Chambers (2013) focused specifically on the induction of event"
P15-1019,H91-1059,0,0.0570363,"assification. We then compare our results with previous approaches, more particularly with Chambers (2013), from both quantitative and qualitative points of view (Section 5.4). Finally, Section 5.5 is dedicated to error analysis, with a special emphasis on sources of false positives. 5 5.1 Evaluations Experimental Setups 5.1.1 Datasets The MUC-4 corpus contains 1,700 news articles about terrorist incidents happening in Latin America. The corpus is divided into 1,300 documents In order to compare with related work, we evaluated our method on the Message Understanding Conference (MUC-4) corpus (Sundheim, 1991) using precision, recall and F-score as conventional 191 instrument Heads Triggers bomb explode:nsubj fire hear:dobj explosion place:dobj blow cause:nsubj charge set:dobj KIDNAPPING victim Attributes Heads Triggers several:amod people arrest:dobj other:amod person kidnap:dobj responsible:amod man release:dobj military:amod member kill:dobj young:amod leader identify:prep as BOMBING for the development set and four test sets, each containing 100 documents. We follow the rules in the literature to guarantee comparable results (Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011). The evalua"
P15-1019,W14-1606,0,0.177117,"nd the identification of chains of events for building representations from texts by exploiting coreference resolution or the temporal ordering of events. All this work is also linked to work about the induction of scripts from texts, more or less closely linked to #2 #3 #4 Attributes [armed:amod] Head man [police:nn] [] [innocent:amod, young:amod] station policeman man Triggers [attack:nsubj, kill:nsubj] [attack:dobj] [kill:dobj] [wound:dobj] Figure 1: Entity representation as tuples of ([attributes], head, [triggers]). events, such as (Frermann et al., 2014), (Pichotta and Mooney, 2014) or (Modi and Titov, 2014). The work we present in this article is in line with Chambers (2013), which will be described in more details in Section 5, together with a quantitative and qualitative comparison. 3 Entity Representation An entity is represented as a triple containing: a head word h, a list A of attribute relations and a list T of trigger relations. Consider the following example: (1) Two armed men attacked the police station and killed a policeman. An innocent young man was also wounded. As illustrated in Figure 1, four entities, equivalent to four separated triples, are generated from the text above. Head"
P15-1019,D07-1075,0,0.0392679,"the Message Understanding Conference (MUC-4) corpus (Sundheim, 1991) using precision, recall and F-score as conventional 191 instrument Heads Triggers bomb explode:nsubj fire hear:dobj explosion place:dobj blow cause:nsubj charge set:dobj KIDNAPPING victim Attributes Heads Triggers several:amod people arrest:dobj other:amod person kidnap:dobj responsible:amod man release:dobj military:amod member kill:dobj young:amod leader identify:prep as BOMBING for the development set and four test sets, each containing 100 documents. We follow the rules in the literature to guarantee comparable results (Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011). The evaluation focuses on four template types – ARSON, ATTACK, BOMBING , KIDNAPPING – and four slots – Perpetrator, Instrument, Target, and Victim. Perpetrator is merged from Perpetrator Individual and Perpetrator Organization. The matching between system answers and references is based on head word matching. A head word is defined as the rightmost word of the phrase or as the right-most word of the first ‘of’ if the phrase contains any. Optional templates and slots are ignored when calculating recall. Template types are ignored in evaluation: this means that a"
P15-1019,D09-1016,0,0.0517084,"Missing"
P15-1019,C04-1084,0,\N,Missing
P17-2035,S16-1195,0,0.0149202,"has been offering a shared task related to temporal relation extraction from clinical narratives over the past two years (Bethard et al., 2015, 2016). Relying on the THYME corpus, the task challenged participants to extract EVENT and TIMEX 3 entities and then to extract narrative container relations and document creation time relations. Herein, we focus on the second part of the challenge, temporal relation extraction and more specifically the narrative container relations. Different approaches have been implemented by the participants, including Support Vector Machine (SVM) classifiers (AAl Abdulsalam et al., 2016; Cohan et al., 2016; Lee et al., 2016; Tourille et al., 2016), Conditional Random Fields (CRF) and convolutional neural networks (CNNs) (Chikka, 2016). Beyond the challenges, Leeuwenberg and Moens (2017) propose a model based on a structured perceptron to jointly predict both types of temporal relations. Lin et al. (2016) performs training instance augmentation to increase the number of training examples and implement a SVM based model for containment relation extraction. Dligach et al. (2017) implement models based on CNNs and Long Short-Term Memory Networks (LSTMs) (Hochreiter and Schmidhub"
P17-2035,E17-2118,0,0.5086,"have been implemented by the participants, including Support Vector Machine (SVM) classifiers (AAl Abdulsalam et al., 2016; Cohan et al., 2016; Lee et al., 2016; Tourille et al., 2016), Conditional Random Fields (CRF) and convolutional neural networks (CNNs) (Chikka, 2016). Beyond the challenges, Leeuwenberg and Moens (2017) propose a model based on a structured perceptron to jointly predict both types of temporal relations. Lin et al. (2016) performs training instance augmentation to increase the number of training examples and implement a SVM based model for containment relation extraction. Dligach et al. (2017) implement models based on CNNs and Long Short-Term Memory Networks (LSTMs) (Hochreiter and Schmidhuber, 1997) to extract containment relations from the THYME corpus. From a more general perspective, relation extraction and classification is a task explored by many approaches, from fully unsupervised to fully supervised. Recent years have seen an increasing interest for the use of neural approaches. Introduction Temporal information extraction from clinical health records allows for a fine-grained analysis of patient health history. Providing medical staff with patient timelines could lead to"
P17-2035,P15-1061,0,0.0148876,"fy temporal relations between pairs of entities formalized as narrative container relations. 224 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 224–230 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2035 CONTAINS Recursive neural networks (Socher et al., 2011, 2013) have proved useful for tasks involving longdistance relations, such as semantic relation extraction (Hashimoto et al., 2013; Li et al., 2015). Convolutional networks have also been used (dos Santos et al., 2015; Zeng et al., 2014) and more recently, recurrent networks such as LSTM showed to be more robust for learning long-distance semantic information (Miwa and Bansal, 2016; Xu et al., 2015; Zhou et al., 2016). 3 3.1 CONTAINS CONTAINS The last time the dose was increased was in February 2010 . - TIMEX - EVENT - EVENT - - TIMEX - Figure 1: Examples of intra-sentence narrative container relations. EVENT TIMEX 3 Intra-sentence relations Inter-sentence relations Train Test 49,147 5,791 12,855 4,582 15,503 1,917 4,365 1,565 Table 1: Descriptive statistics about the train and test parts of the THYME corp"
P17-2035,D13-1137,0,0.0126346,"entities and we focus on containment relation extraction where the objective is to identify temporal relations between pairs of entities formalized as narrative container relations. 224 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 224–230 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2035 CONTAINS Recursive neural networks (Socher et al., 2011, 2013) have proved useful for tasks involving longdistance relations, such as semantic relation extraction (Hashimoto et al., 2013; Li et al., 2015). Convolutional networks have also been used (dos Santos et al., 2015; Zeng et al., 2014) and more recently, recurrent networks such as LSTM showed to be more robust for learning long-distance semantic information (Miwa and Bansal, 2016; Xu et al., 2015; Zhou et al., 2016). 3 3.1 CONTAINS CONTAINS The last time the dose was increased was in February 2010 . - TIMEX - EVENT - EVENT - - TIMEX - Figure 1: Examples of intra-sentence narrative container relations. EVENT TIMEX 3 Intra-sentence relations Inter-sentence relations Train Test 49,147 5,791 12,855 4,582 15,503 1,917 4,365"
P17-2035,S15-2136,0,0.16542,"Missing"
P17-2035,N16-1030,0,0.0615328,"Missing"
P17-2035,S16-1192,0,0.0751139,"n the THYME corpus, the task challenged participants to extract EVENT and TIMEX 3 entities and then to extract narrative container relations and document creation time relations. Herein, we focus on the second part of the challenge, temporal relation extraction and more specifically the narrative container relations. Different approaches have been implemented by the participants, including Support Vector Machine (SVM) classifiers (AAl Abdulsalam et al., 2016; Cohan et al., 2016; Lee et al., 2016; Tourille et al., 2016), Conditional Random Fields (CRF) and convolutional neural networks (CNNs) (Chikka, 2016). Beyond the challenges, Leeuwenberg and Moens (2017) propose a model based on a structured perceptron to jointly predict both types of temporal relations. Lin et al. (2016) performs training instance augmentation to increase the number of training examples and implement a SVM based model for containment relation extraction. Dligach et al. (2017) implement models based on CNNs and Long Short-Term Memory Networks (LSTMs) (Hochreiter and Schmidhuber, 1997) to extract containment relations from the THYME corpus. From a more general perspective, relation extraction and classification is a task exp"
P17-2035,S16-1201,0,0.0542222,"Missing"
P17-2035,S16-1194,0,0.0194281,"ed task related to temporal relation extraction from clinical narratives over the past two years (Bethard et al., 2015, 2016). Relying on the THYME corpus, the task challenged participants to extract EVENT and TIMEX 3 entities and then to extract narrative container relations and document creation time relations. Herein, we focus on the second part of the challenge, temporal relation extraction and more specifically the narrative container relations. Different approaches have been implemented by the participants, including Support Vector Machine (SVM) classifiers (AAl Abdulsalam et al., 2016; Cohan et al., 2016; Lee et al., 2016; Tourille et al., 2016), Conditional Random Fields (CRF) and convolutional neural networks (CNNs) (Chikka, 2016). Beyond the challenges, Leeuwenberg and Moens (2017) propose a model based on a structured perceptron to jointly predict both types of temporal relations. Lin et al. (2016) performs training instance augmentation to increase the number of training examples and implement a SVM based model for containment relation extraction. Dligach et al. (2017) implement models based on CNNs and Long Short-Term Memory Networks (LSTMs) (Hochreiter and Schmidhuber, 1997) to extract"
P17-2035,D15-1278,0,0.0130017,"n containment relation extraction where the objective is to identify temporal relations between pairs of entities formalized as narrative container relations. 224 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 224–230 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2035 CONTAINS Recursive neural networks (Socher et al., 2011, 2013) have proved useful for tasks involving longdistance relations, such as semantic relation extraction (Hashimoto et al., 2013; Li et al., 2015). Convolutional networks have also been used (dos Santos et al., 2015; Zeng et al., 2014) and more recently, recurrent networks such as LSTM showed to be more robust for learning long-distance semantic information (Miwa and Bansal, 2016; Xu et al., 2015; Zhou et al., 2016). 3 3.1 CONTAINS CONTAINS The last time the dose was increased was in February 2010 . - TIMEX - EVENT - EVENT - - TIMEX - Figure 1: Examples of intra-sentence narrative container relations. EVENT TIMEX 3 Intra-sentence relations Inter-sentence relations Train Test 49,147 5,791 12,855 4,582 15,503 1,917 4,365 1,565 Table 1: De"
P17-2035,S16-1175,1,0.917526,"xtraction from clinical narratives over the past two years (Bethard et al., 2015, 2016). Relying on the THYME corpus, the task challenged participants to extract EVENT and TIMEX 3 entities and then to extract narrative container relations and document creation time relations. Herein, we focus on the second part of the challenge, temporal relation extraction and more specifically the narrative container relations. Different approaches have been implemented by the participants, including Support Vector Machine (SVM) classifiers (AAl Abdulsalam et al., 2016; Cohan et al., 2016; Lee et al., 2016; Tourille et al., 2016), Conditional Random Fields (CRF) and convolutional neural networks (CNNs) (Chikka, 2016). Beyond the challenges, Leeuwenberg and Moens (2017) propose a model based on a structured perceptron to jointly predict both types of temporal relations. Lin et al. (2016) performs training instance augmentation to increase the number of training examples and implement a SVM based model for containment relation extraction. Dligach et al. (2017) implement models based on CNNs and Long Short-Term Memory Networks (LSTMs) (Hochreiter and Schmidhuber, 1997) to extract containment relations from the THYME corp"
P17-2035,W16-2914,0,0.403651,"elations. Herein, we focus on the second part of the challenge, temporal relation extraction and more specifically the narrative container relations. Different approaches have been implemented by the participants, including Support Vector Machine (SVM) classifiers (AAl Abdulsalam et al., 2016; Cohan et al., 2016; Lee et al., 2016; Tourille et al., 2016), Conditional Random Fields (CRF) and convolutional neural networks (CNNs) (Chikka, 2016). Beyond the challenges, Leeuwenberg and Moens (2017) propose a model based on a structured perceptron to jointly predict both types of temporal relations. Lin et al. (2016) performs training instance augmentation to increase the number of training examples and implement a SVM based model for containment relation extraction. Dligach et al. (2017) implement models based on CNNs and Long Short-Term Memory Networks (LSTMs) (Hochreiter and Schmidhuber, 1997) to extract containment relations from the THYME corpus. From a more general perspective, relation extraction and classification is a task explored by many approaches, from fully unsupervised to fully supervised. Recent years have seen an increasing interest for the use of neural approaches. Introduction Temporal"
P17-2035,E17-2117,1,0.813839,"Missing"
P17-2035,D15-1206,0,0.0113271,"ort Papers), pages 224–230 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2035 CONTAINS Recursive neural networks (Socher et al., 2011, 2013) have proved useful for tasks involving longdistance relations, such as semantic relation extraction (Hashimoto et al., 2013; Li et al., 2015). Convolutional networks have also been used (dos Santos et al., 2015; Zeng et al., 2014) and more recently, recurrent networks such as LSTM showed to be more robust for learning long-distance semantic information (Miwa and Bansal, 2016; Xu et al., 2015; Zhou et al., 2016). 3 3.1 CONTAINS CONTAINS The last time the dose was increased was in February 2010 . - TIMEX - EVENT - EVENT - - TIMEX - Figure 1: Examples of intra-sentence narrative container relations. EVENT TIMEX 3 Intra-sentence relations Inter-sentence relations Train Test 49,147 5,791 12,855 4,582 15,503 1,917 4,365 1,565 Table 1: Descriptive statistics about the train and test parts of the THYME corpus. Data 3.2 Corpus Presentation Preprocessing We preprocessed the corpus using cTAKES (Savova et al., 2010), an open-source natural language processing system for the extraction of in"
P17-2035,P16-1105,0,0.0225042,"ational Linguistics (Short Papers), pages 224–230 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2035 CONTAINS Recursive neural networks (Socher et al., 2011, 2013) have proved useful for tasks involving longdistance relations, such as semantic relation extraction (Hashimoto et al., 2013; Li et al., 2015). Convolutional networks have also been used (dos Santos et al., 2015; Zeng et al., 2014) and more recently, recurrent networks such as LSTM showed to be more robust for learning long-distance semantic information (Miwa and Bansal, 2016; Xu et al., 2015; Zhou et al., 2016). 3 3.1 CONTAINS CONTAINS The last time the dose was increased was in February 2010 . - TIMEX - EVENT - EVENT - - TIMEX - Figure 1: Examples of intra-sentence narrative container relations. EVENT TIMEX 3 Intra-sentence relations Inter-sentence relations Train Test 49,147 5,791 12,855 4,582 15,503 1,917 4,365 1,565 Table 1: Descriptive statistics about the train and test parts of the THYME corpus. Data 3.2 Corpus Presentation Preprocessing We preprocessed the corpus using cTAKES (Savova et al., 2010), an open-source natural language processing system for the"
P17-2035,C14-1220,0,0.00961922,"between pairs of entities formalized as narrative container relations. 224 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 224–230 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2035 CONTAINS Recursive neural networks (Socher et al., 2011, 2013) have proved useful for tasks involving longdistance relations, such as semantic relation extraction (Hashimoto et al., 2013; Li et al., 2015). Convolutional networks have also been used (dos Santos et al., 2015; Zeng et al., 2014) and more recently, recurrent networks such as LSTM showed to be more robust for learning long-distance semantic information (Miwa and Bansal, 2016; Xu et al., 2015; Zhou et al., 2016). 3 3.1 CONTAINS CONTAINS The last time the dose was increased was in February 2010 . - TIMEX - EVENT - EVENT - - TIMEX - Figure 1: Examples of intra-sentence narrative container relations. EVENT TIMEX 3 Intra-sentence relations Inter-sentence relations Train Test 49,147 5,791 12,855 4,582 15,503 1,917 4,365 1,565 Table 1: Descriptive statistics about the train and test parts of the THYME corpus. Data 3.2 Corpus"
P17-2035,W11-0419,0,0.048557,"poral expressions are assigned a Class attribute. Possible values for these attributes are presented in Table 2. 4 Narrative containers can be apprehended as temporal buckets in which several events may be included. These containers are anchored by temporal expressions, medical events or other concepts. Styler IV et al. (2014) argue that the use of narrative containers instead of classical temporal relations (Allen, 1983) yields better annotation while keeping most of the useful temporal information intact. The concept of narrative container is illustrated in Figure 1 and described further in Pustejovsky and Stubbs (2011). Task Description The container relation extraction task can be cast as a 3-class classification problem. For each combination of EVENT and/or TIMEX 3 from left to right, three cases are possible: • the first entity temporally contains the second entity, • the first entity is temporally contained by the second entity, • there is no temporal containment relation between the entities. Intra- and inter-sentence relation detection can be seen as two different tasks with specific features. Intra-sentence relations can benefit from intra-sentential clues such as adverbs (e.g. during) or pronouns (e"
P17-2035,P16-2034,0,0.00384149,"s 224–230 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-2035 CONTAINS Recursive neural networks (Socher et al., 2011, 2013) have proved useful for tasks involving longdistance relations, such as semantic relation extraction (Hashimoto et al., 2013; Li et al., 2015). Convolutional networks have also been used (dos Santos et al., 2015; Zeng et al., 2014) and more recently, recurrent networks such as LSTM showed to be more robust for learning long-distance semantic information (Miwa and Bansal, 2016; Xu et al., 2015; Zhou et al., 2016). 3 3.1 CONTAINS CONTAINS The last time the dose was increased was in February 2010 . - TIMEX - EVENT - EVENT - - TIMEX - Figure 1: Examples of intra-sentence narrative container relations. EVENT TIMEX 3 Intra-sentence relations Inter-sentence relations Train Test 49,147 5,791 12,855 4,582 15,503 1,917 4,365 1,565 Table 1: Descriptive statistics about the train and test parts of the THYME corpus. Data 3.2 Corpus Presentation Preprocessing We preprocessed the corpus using cTAKES (Savova et al., 2010), an open-source natural language processing system for the extraction of information from elect"
P17-2035,D11-1014,0,0.090597,"Missing"
P17-2035,D13-1170,0,0.00329242,"Missing"
P17-2035,E17-1108,0,\N,Missing
paroubek-tannier-2012-rough,chiao-etal-2006-evaluation,0,\N,Missing
paroubek-tannier-2012-rough,villemonte-de-la-clergerie-etal-2008-passage,1,\N,Missing
paroubek-tannier-2012-rough,J93-2004,0,\N,Missing
paroubek-tannier-2012-rough,W08-2319,0,\N,Missing
paroubek-tannier-2012-rough,vilnat-etal-2010-passage,1,\N,Missing
paroubek-tannier-2012-rough,M95-1005,0,\N,Missing
paroubek-tannier-2012-rough,magnini-etal-2008-evaluation,0,\N,Missing
paroubek-tannier-2012-rough,paroubek-etal-2006-data,1,\N,Missing
paroubek-tannier-2012-rough,pak-paroubek-2010-twitter,1,\N,Missing
paroubek-tannier-2012-rough,W10-4233,0,\N,Missing
paroubek-tannier-2012-rough,W05-1517,0,\N,Missing
quintard-etal-2010-question,ayache-etal-2006-equer,1,\N,Missing
quintard-etal-2010-question,bernard-etal-2010-question,1,\N,Missing
S07-1110,C04-1008,1,0.90864,"ce, for the chain “has been taken”, we extract “take” as the semantic head of the verbal chain. The aspect is perfective and the tense of the auxiliary “has” is present. From this information, we deduce that this form is either in present or in past. This is expressed the following way: PRES-OR-PAST(taken). 2.3 Document level Beyond sentence-level, the system is at the first stage of development. We are only able to complete relative dates when it refers to the document creation time, and to infer new relations with the help of composition rules, by saturating the graph of temporal relations (Muller and Tannier, 2004). 3 3.2 XTM does not handle temporal relations between events and durations. In our temporal model, an event can have duration. However, this is not represented by a temporal relation, but by an attribute of the event. Durations included in a larger temporal expression (like in “two days later”) introduce an interval for the temporal relation: AFTER(A, B, interval: two days). Here again no temporal relation is attributed with respect to the duration. Therefore, we had to adapt our system so that it is able to infer at least some relations between events and durations. We used two ways to do so"
S07-1110,W03-1606,1,\N,Missing
S07-1110,S07-1014,0,\N,Missing
S07-1110,W06-0405,0,\N,Missing
S16-1002,L16-1465,1,0.768602,"Missing"
S16-1002,S15-2080,0,0.0503377,"Missing"
S16-1002,klinger-cimiano-2014-usage,0,0.0621363,"Missing"
S16-1002,P15-2128,0,0.0333833,"Missing"
S16-1002,S16-1003,0,0.0786167,"Missing"
S16-1002,S13-2052,0,0.0105895,"Missing"
S16-1002,piperidis-2012-meta,0,0.0160887,"Missing"
S16-1002,S14-2004,1,0.673256,"Missing"
S16-1002,S15-2082,1,0.813624,"Missing"
S16-1002,S14-2009,0,0.0111835,"Missing"
S16-1002,S15-2078,0,0.0105712,"Missing"
S16-1002,D13-1170,0,0.0173861,"Missing"
S16-1002,E12-2021,0,0.0937892,"Missing"
S16-1175,S16-1165,0,0.0431462,"relations. The latter consists of two subtasks. In the Document Creation Time Relation subtask (DR), participants are challenged to identify relations between the events and the document creation time. For the Container Relation subtask (CR), participants have to identity container relations between entities. Participants may submit either a complete system extracting entities and relations or focus on either the entity extraction or relation extraction (using the gold standard entities provided by the organizers). More details about the task and the definition of each subtask can be found in Bethard et al. (2016). In this paper, we present our submission for the CR and DR subtasks based on gold-standard entities (phase 2). Our global approach, which is illustrated in Figure 1, tackles the identification of temporal relations as a set of supervised classification tasks. We submitted two runs, one using plain lexical features and one using word embeddings computed on a large clinical corpus. We obtained scores well above the median scores in both subtasks. The remainder of this paper is organized as follows. Section 2 presents our system for the DR subtask while Section 3 describes our system for the CR"
S16-1175,P05-1022,0,0.0561315,"tistical feature selection. We used the Scikit-learn machine learning library (Pedregosa et al., 2011) for both implementing our classification models and performing statistical feature selection. 4.3 Corpus Preprocessing We applied a four-step preprocessing on the 440 texts that were provided for the subtasks. First, we used NLTK (Loper and Bird, 2002) to segment the texts into sentences with the Punkt Sentence Tokenizer pre-trained model for English provided within the framework. The second step consisted of parsing the resulting sentences. For this task, we used the BLLIP Reranking Parser (Charniak and Johnson, 2005) and a pre-trained biomedical parsing model (McClosky, 2010). In the third step, we lemmatized the corpus using BioLemmatizer (Liu et al., 2012), a tool built for processing the biomedical literature. We used the Part-Of-Speech tags from the previous step as parameters for the lemmatization. The last step consisted in using Metamap (Aronson and Lang, 2010) to detect biomedical events and linking them, after disambiguation, to their related UMLS® (Unified Medical Language System) concept. We chose to keep biomedical entities that had a 1140 span overlapping with at least one entity of the gold"
S16-1175,W02-0109,0,0.0472586,"mbeddings b Table 2: Machine learning algorithms and parameters used for the final submission The machine learning algorithms used for the final submission are presented in Table 2 together with their parameters and the percentage of the feature space kept after statistical feature selection. We used the Scikit-learn machine learning library (Pedregosa et al., 2011) for both implementing our classification models and performing statistical feature selection. 4.3 Corpus Preprocessing We applied a four-step preprocessing on the 440 texts that were provided for the subtasks. First, we used NLTK (Loper and Bird, 2002) to segment the texts into sentences with the Punkt Sentence Tokenizer pre-trained model for English provided within the framework. The second step consisted of parsing the resulting sentences. For this task, we used the BLLIP Reranking Parser (Charniak and Johnson, 2005) and a pre-trained biomedical parsing model (McClosky, 2010). In the third step, we lemmatized the corpus using BioLemmatizer (Liu et al., 2012), a tool built for processing the biomedical literature. We used the Part-Of-Speech tags from the previous step as parameters for the lemmatization. The last step consisted in using Me"
S16-1175,N10-1004,0,0.0122909,"brary (Pedregosa et al., 2011) for both implementing our classification models and performing statistical feature selection. 4.3 Corpus Preprocessing We applied a four-step preprocessing on the 440 texts that were provided for the subtasks. First, we used NLTK (Loper and Bird, 2002) to segment the texts into sentences with the Punkt Sentence Tokenizer pre-trained model for English provided within the framework. The second step consisted of parsing the resulting sentences. For this task, we used the BLLIP Reranking Parser (Charniak and Johnson, 2005) and a pre-trained biomedical parsing model (McClosky, 2010). In the third step, we lemmatized the corpus using BioLemmatizer (Liu et al., 2012), a tool built for processing the biomedical literature. We used the Part-Of-Speech tags from the previous step as parameters for the lemmatization. The last step consisted in using Metamap (Aronson and Lang, 2010) to detect biomedical events and linking them, after disambiguation, to their related UMLS® (Unified Medical Language System) concept. We chose to keep biomedical entities that had a 1140 span overlapping with at least one entity of the gold standard. 5 Results and Discussion In Table 3, we present th"
S16-1175,P06-4018,0,\N,Missing
S16-1175,Q14-1012,0,\N,Missing
S17-2098,S16-1195,0,0.0310096,"to extract containment (CONTAINS) relations between EVENT and/or TIMEX3 as well as Document Creation Time (DCT) relations between EVENT entities and documents in which they are embedded. The novelty of the 2017 edition lies in the difference of domains between train and test corpora. More details about the task and the definition of each subtask can be found in Bethard et al. (2017). The task has been offered by SemEval over the past two years. Concerning the first group of subtasks, different approaches have been implemented by the participants including Conditional Random Fields (CRF) (AAl Abdulsalam et al., 2016; Caselli and Morante, 2016; Chikka, 2016; Cohan et al., 2016; Grouin and Moriceau, 2016; Hansart et al., 2016) and deep learning models (Fries, 2016; Chikka, 2016; Li and Huang, 2016). Similarly, CRF and neural networks models have been used for the second group of subtasks (AAl Abdulsalam et al., 2016; Cohan et al., 597 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 597–602, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association for Computational Linguistics sentence relations that do not span over more than three sentences. By doing so, we ob"
S17-2098,S16-1194,0,0.0219105,"TIMEX3 as well as Document Creation Time (DCT) relations between EVENT entities and documents in which they are embedded. The novelty of the 2017 edition lies in the difference of domains between train and test corpora. More details about the task and the definition of each subtask can be found in Bethard et al. (2017). The task has been offered by SemEval over the past two years. Concerning the first group of subtasks, different approaches have been implemented by the participants including Conditional Random Fields (CRF) (AAl Abdulsalam et al., 2016; Caselli and Morante, 2016; Chikka, 2016; Cohan et al., 2016; Grouin and Moriceau, 2016; Hansart et al., 2016) and deep learning models (Fries, 2016; Chikka, 2016; Li and Huang, 2016). Similarly, CRF and neural networks models have been used for the second group of subtasks (AAl Abdulsalam et al., 2016; Cohan et al., 597 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 597–602, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association for Computational Linguistics sentence relations that do not span over more than three sentences. By doing so, we obtain a manageable training corpus size with less unbalanced c"
S17-2098,S16-1198,0,0.0296996,"n which they are embedded. The novelty of the 2017 edition lies in the difference of domains between train and test corpora. More details about the task and the definition of each subtask can be found in Bethard et al. (2017). The task has been offered by SemEval over the past two years. Concerning the first group of subtasks, different approaches have been implemented by the participants including Conditional Random Fields (CRF) (AAl Abdulsalam et al., 2016; Caselli and Morante, 2016; Chikka, 2016; Cohan et al., 2016; Grouin and Moriceau, 2016; Hansart et al., 2016) and deep learning models (Fries, 2016; Chikka, 2016; Li and Huang, 2016). Similarly, CRF and neural networks models have been used for the second group of subtasks (AAl Abdulsalam et al., 2016; Cohan et al., 597 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 597–602, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association for Computational Linguistics sentence relations that do not span over more than three sentences. By doing so, we obtain a manageable training corpus size with less unbalanced classes while keeping a good coverage. 3 Corpus Preprocessing We preprocessed the corpus"
S17-2098,S16-1190,0,0.0273623,"cument Creation Time (DCT) relations between EVENT entities and documents in which they are embedded. The novelty of the 2017 edition lies in the difference of domains between train and test corpora. More details about the task and the definition of each subtask can be found in Bethard et al. (2017). The task has been offered by SemEval over the past two years. Concerning the first group of subtasks, different approaches have been implemented by the participants including Conditional Random Fields (CRF) (AAl Abdulsalam et al., 2016; Caselli and Morante, 2016; Chikka, 2016; Cohan et al., 2016; Grouin and Moriceau, 2016; Hansart et al., 2016) and deep learning models (Fries, 2016; Chikka, 2016; Li and Huang, 2016). Similarly, CRF and neural networks models have been used for the second group of subtasks (AAl Abdulsalam et al., 2016; Cohan et al., 597 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 597–602, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association for Computational Linguistics sentence relations that do not span over more than three sentences. By doing so, we obtain a manageable training corpus size with less unbalanced classes while keeping a good"
S17-2098,S16-1200,0,0.0644888,"Missing"
S17-2098,S15-2136,0,0.0813531,"Missing"
S17-2098,S17-2093,0,0.0294291,"us editions of the challenge (Bethard et al., 2015, 2016), the first group of subtasks concerns medical event (EVENT) and temporal expression (TIMEX3) extraction from raw text. In a second group of subtasks, participants are challenged to extract containment (CONTAINS) relations between EVENT and/or TIMEX3 as well as Document Creation Time (DCT) relations between EVENT entities and documents in which they are embedded. The novelty of the 2017 edition lies in the difference of domains between train and test corpora. More details about the task and the definition of each subtask can be found in Bethard et al. (2017). The task has been offered by SemEval over the past two years. Concerning the first group of subtasks, different approaches have been implemented by the participants including Conditional Random Fields (CRF) (AAl Abdulsalam et al., 2016; Caselli and Morante, 2016; Chikka, 2016; Cohan et al., 2016; Grouin and Moriceau, 2016; Hansart et al., 2016) and deep learning models (Fries, 2016; Chikka, 2016; Li and Huang, 2016). Similarly, CRF and neural networks models have been used for the second group of subtasks (AAl Abdulsalam et al., 2016; Cohan et al., 597 Proceedings of the 11th International W"
S17-2098,N16-1030,0,0.0591663,"Missing"
S17-2098,S16-1201,0,0.0752453,"Missing"
S17-2098,S16-1197,0,0.0220144,"The novelty of the 2017 edition lies in the difference of domains between train and test corpora. More details about the task and the definition of each subtask can be found in Bethard et al. (2017). The task has been offered by SemEval over the past two years. Concerning the first group of subtasks, different approaches have been implemented by the participants including Conditional Random Fields (CRF) (AAl Abdulsalam et al., 2016; Caselli and Morante, 2016; Chikka, 2016; Cohan et al., 2016; Grouin and Moriceau, 2016; Hansart et al., 2016) and deep learning models (Fries, 2016; Chikka, 2016; Li and Huang, 2016). Similarly, CRF and neural networks models have been used for the second group of subtasks (AAl Abdulsalam et al., 2016; Cohan et al., 597 Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017), pages 597–602, c Vancouver, Canada, August 3 - 4, 2017. 2017 Association for Computational Linguistics sentence relations that do not span over more than three sentences. By doing so, we obtain a manageable training corpus size with less unbalanced classes while keeping a good coverage. 3 Corpus Preprocessing We preprocessed the corpus using cTAKES 3.2.2 (Savova et al.,"
S17-2098,D15-1063,0,0.0303953,"es while keeping a good coverage. 3 Corpus Preprocessing We preprocessed the corpus using cTAKES 3.2.2 (Savova et al., 2010), an open-source natural language processing system for the extraction of information from electronic health records. We extracted sentence and token boundaries, as well as token types and semantic types of the entities that have a span overlap with a least one gold standard EVENT entity of the THYME corpus. This information was added to the set of gold standard attributes available for EVENT entities in the corpus. We also preprocessed the corpus using HeidelTime 2.2.1 (Strötgen and Gertz, 2015), a multilingual domain-sensitive temporal tagger, and used the results to further extend our feature set. 4 4.1 Figure 1: Neural model for EVENT extraction. – – – – EVENT type attribute, EVENT plain lexical form, EVENT position within the document, POS tags of the verbs within the right and left contexts of the considered entity, – EVENT POS tag, – type or class of the other entities that are present within the left and right contexts, – token unigrams and bigrams within a window around the entity. Models Entity Extraction Our approach relies on Long Short-Term Memory Networks (LSTMs) (Hochre"
S17-2098,S16-1175,1,0.858559,"roblem. For each combination E1 – E2 of EVENT and/or TIMEX3 from left to right, three cases are possible: – E1 temporally contains E2, – E1 is temporally contained by E2, – there is no relation between E1 and E2. Intra- and inter-sentence relation detection can be seen as two different tasks with specific features. Intra-sentence relations can benefit from intra-sentential clues such as adverbs (e.g. during) or pronouns (e.g. which) which are not available at the inter-sentence level. Furthermore, past work on the topic seems to indicate that this differentiation improves overall performance (Tourille et al., 2016). We have adopted this approach by building two separate classifiers, one for intra-sentence relations and one for inter-sentence relations. If we were to consider all combinations of entities within documents for inter-sentence relations, it would result in a very large training corpus with very few positive examples. In order to cope with this issue, we limit our experiments to interIntroduction SemEval 2017 Task 12 offers 6 subtasks addressing medical event recognition and temporal reasoning in the clinical domain using the THYME corpus (Styler IV et al., 2014). Similarly to the two previou"
tannier-2012-webannotator,N06-4006,0,\N,Missing
tannier-2012-webannotator,W11-0416,0,\N,Missing
tannier-2012-webannotator,day-etal-2004-callisto,0,\N,Missing
tannier-2012-webannotator,2009.jeptalnrecital-court.23,0,\N,Missing
tannier-2014-extracting,llorens-etal-2012-timen,0,\N,Missing
tannier-2014-extracting,W11-0219,0,\N,Missing
tannier-2014-extracting,S07-1014,0,\N,Missing
tannier-2014-extracting,P12-1077,1,\N,Missing
tannier-2014-extracting,pustejovsky-etal-2010-iso,0,\N,Missing
tannier-2014-extracting,P10-1052,0,\N,Missing
tannier-2014-extracting,strotgen-gertz-2012-temporal,0,\N,Missing
tannier-2014-extracting,tannier-2012-webannotator,1,\N,Missing
tannier-2014-extracting,chang-manning-2012-sutime,0,\N,Missing
tannier-etal-2012-evolution,arnulphy-etal-2012-event,1,\N,Missing
tannier-etal-2012-evolution,day-etal-2004-callisto,0,\N,Missing
tannier-moriceau-2010-fidji,quintard-etal-2010-question,1,\N,Missing
tannier-muller-2008-evaluation,M95-1005,0,\N,Missing
tannier-muller-2008-evaluation,P00-1010,0,\N,Missing
tannier-muller-2008-evaluation,S07-1014,0,\N,Missing
tannier-muller-2008-evaluation,C04-1008,1,\N,Missing
W11-1106,E09-1005,0,0.0271581,"----- ------------- Ranked terms Ranked documents Ranked queries Figure 2: Sample subgraph using ”boxoffice”, ”Grammys” and ”BBC” as seed terms. and improve the system’s overall performance. The manual filtering cost is therefore drastically reduced. Graph modeling and random walks have been applied with success to many different domains of NLP, such as keyword and sentence extraction (Mihalcea and Tarau, 2004), computer-science articles ranking (Nie et al., 2005), web pages ranking (Haveliwala, 2002; Page et al., 1999; Richardson and Domingos, 2002), WordNet-based word sense disambiguation (Agirre and Soroa, 2009) and lexical semantic relatedness (Hughes and Ramage, 2007), or set expansion (Wang and Cohen, 2007). In this paper, we confirm the relevance of this approach to terminology and corpora bootstrapping. Ranking simultaneously Terms, Queries and Documents 3.1 Album Documents Figure 1: Components of the GrawlTCQ algorithm. 3 Beatles Queries The GrawlTCQ bootstrapping algorithm Figure 1 shows the components of the GrawlTCQ algorithm. Starting from user provided seed terms2 , GrawlTCQ iteratively creates queries, finds documents and extracts new terms. We model this bootstrapping procedure with a gr"
W11-1106,baroni-bernardini-2004-bootcat,0,0.0888023,"these resources. In this paper, we present GrawlTCQ1 , a bootstrapping algorithm for building specialized terminology, corpora and queries: from a small set of userprovided terms, GrawlTCQ builds the resources via automated queries to a search engine. The algorithm relies on a graph that encodes the three kinds of entities involved in the procedure (terms, documents and queries) and relations between them. We model the 1 GrawlTCQ stands for Graph RAndom WaLk for Terminology, Corpora and Queries. relevance propagation in our graph by using a random walk with restart algorithm. We use BootCaT (Baroni and Bernardini, 2004) as our baseline because it is a similar algorithm that has been vastly used and validated experimentally in the domain. We have evaluated GrawlTCQ and BootCaT on an AFP (Agence France Presse) English corpus of 57,441 news over 10 categories. Results show that, for corpora building, GrawlTCQ significantly outperforms the BootCaT algorithm. As this is an on-going work, further work is needed to evaluate terminology and query results. The article is structured as follows: in Section 2, we review the related work in terminology and corpora construction using bootstrapping techniques, as well as r"
W11-1106,D07-1061,0,0.0346629,"queries Figure 2: Sample subgraph using ”boxoffice”, ”Grammys” and ”BBC” as seed terms. and improve the system’s overall performance. The manual filtering cost is therefore drastically reduced. Graph modeling and random walks have been applied with success to many different domains of NLP, such as keyword and sentence extraction (Mihalcea and Tarau, 2004), computer-science articles ranking (Nie et al., 2005), web pages ranking (Haveliwala, 2002; Page et al., 1999; Richardson and Domingos, 2002), WordNet-based word sense disambiguation (Agirre and Soroa, 2009) and lexical semantic relatedness (Hughes and Ramage, 2007), or set expansion (Wang and Cohen, 2007). In this paper, we confirm the relevance of this approach to terminology and corpora bootstrapping. Ranking simultaneously Terms, Queries and Documents 3.1 Album Documents Figure 1: Components of the GrawlTCQ algorithm. 3 Beatles Queries The GrawlTCQ bootstrapping algorithm Figure 1 shows the components of the GrawlTCQ algorithm. Starting from user provided seed terms2 , GrawlTCQ iteratively creates queries, finds documents and extracts new terms. We model this bootstrapping procedure with a graph that keeps all links between documents, terms and queri"
W11-1106,W04-3252,0,0.20276,"inations Queries Grammys AND BBC leads to Search engine DOC 1 Ranked documents (-1) DOC 2 (-1) contains Terms Filter and keep N-best Jackson Graph model ------------- ..... ..... ----..... ..... ----..... ..... ----- ------------- Ranked terms Ranked documents Ranked queries Figure 2: Sample subgraph using ”boxoffice”, ”Grammys” and ”BBC” as seed terms. and improve the system’s overall performance. The manual filtering cost is therefore drastically reduced. Graph modeling and random walks have been applied with success to many different domains of NLP, such as keyword and sentence extraction (Mihalcea and Tarau, 2004), computer-science articles ranking (Nie et al., 2005), web pages ranking (Haveliwala, 2002; Page et al., 1999; Richardson and Domingos, 2002), WordNet-based word sense disambiguation (Agirre and Soroa, 2009) and lexical semantic relatedness (Hughes and Ramage, 2007), or set expansion (Wang and Cohen, 2007). In this paper, we confirm the relevance of this approach to terminology and corpora bootstrapping. Ranking simultaneously Terms, Queries and Documents 3.1 Album Documents Figure 1: Components of the GrawlTCQ algorithm. 3 Beatles Queries The GrawlTCQ bootstrapping algorithm Figure 1 shows t"
W15-2603,max-wisniewski-2010-mining,0,0.0242559,"ure work will be to replicate this study on a larger and more diverse corpus of patient records with different disease profiles, so as to confirm our findings and see to what extent text is shared between patient records from different hospital departments. As a follow-up of this study we also plan to address two new main lines of research. First, we intend to develop a more precise surface redundancy measure which takes temporal expressions and terminological variation into account and which is more robust to small changes within large highly similar context. We will use the WiCoPaCo corpus (Max and Wisniewski, 2010) to train models that can automatically identify reformulations, and distinguish those from (error) corrections and updates. Second, we will study redundancy on the level of the patient’s records as a whole, not just on the document level. We intend to develop a measure that uses information on redundancy levels, the number of documents copied, the (temporal) distance of information that has been copied, ... to identify key documents within a patient’s record. To this end we will need a reference set of correctly identified key documents in a set of patient records. This will be carried out by"
W17-4211,N16-1034,0,0.0452228,"ST, Gif-sur-Yvette, F-91191 France. olivier.ferret@cea.fr Xavier Tannier LIMSI, CNRS Univ. Paris-Sud Universit´e Paris-Saclay xavier.tannier@limsi.fr Abstract event detection. It is also an important subtask of larger NLP applications such as document summarization and event schema induction. Several approaches have been used to tackle the different aspects of this task, particularly in an unsupervised fashion, from linguistic pipelines (Filatova et al., 2006; Huang et al., 2016) to topic modeling approaches (Chambers and Jurafsky, 2011; Cheung et al., 2013) and more recently neural networks (Nguyen et al., 2016). While the definition and granularity of an event varies with the task and objectives at hand, most event identification systems exploit mentions to produce type-level representations. We propose to address the unsupervised event extraction task through two subtasks: first, unsupervised event instance extraction and second, event type extraction. This paper will focus on our efforts regarding the first step, e.g. unsupervised event instance extraction. In this perspective, we present a method based on clustering algorithms leveraging news data from different sources. We believe that this firs"
W17-4211,P11-1098,0,0.0795391,"Missing"
W17-4211,N13-1104,0,0.0210226,"aris-Saclay swen.ribeiro@limsi.fr Olivier Ferret CEA, LIST, Gif-sur-Yvette, F-91191 France. olivier.ferret@cea.fr Xavier Tannier LIMSI, CNRS Univ. Paris-Sud Universit´e Paris-Saclay xavier.tannier@limsi.fr Abstract event detection. It is also an important subtask of larger NLP applications such as document summarization and event schema induction. Several approaches have been used to tackle the different aspects of this task, particularly in an unsupervised fashion, from linguistic pipelines (Filatova et al., 2006; Huang et al., 2016) to topic modeling approaches (Chambers and Jurafsky, 2011; Cheung et al., 2013) and more recently neural networks (Nguyen et al., 2016). While the definition and granularity of an event varies with the task and objectives at hand, most event identification systems exploit mentions to produce type-level representations. We propose to address the unsupervised event extraction task through two subtasks: first, unsupervised event instance extraction and second, event type extraction. This paper will focus on our efforts regarding the first step, e.g. unsupervised event instance extraction. In this perspective, we present a method based on clustering algorithms leveraging new"
W17-4211,cybulska-vossen-2014-using,0,0.0277963,"t. We leverage press agency newswire and monolingual word alignment techniques to build meaningful and linguistically varied clusters of articles from the Web in the perspective of a broader event type detection task. We validate our approach on a manually annotated corpus of Web articles. 1 Introduction In the context of news production, an event is the characterization of a significant enough change in a space-time context to be reported as newsworthy content. This definition fits with definitions proposed in other contexts such as the ACE 2005 and TAC KBP Event evaluations or work such as (Cybulska and Vossen, 2014; Mitamura et al., 2015), which generally view each event as “something that happens at a particular place and time”, implying changes in the state of the world and involving participants. In accordance with ontologies about events such as the Simple Event Model (SEM) ontology (van Hage et al., 2011), events can be categorized into different types, for example “elections” or “earthquakes”, gathering multiple real-life instances, for example the “2017 UK General Election” or the “2012 French Presidential Election”. These instances are reported by journalists through varying textual mentions. Ev"
W17-4211,P06-2027,0,0.0413434,"and Aggregation from Newswire and Web Articles Swen Ribeiro LIMSI, CNRS Univ. Paris-Sud Universit´e Paris-Saclay swen.ribeiro@limsi.fr Olivier Ferret CEA, LIST, Gif-sur-Yvette, F-91191 France. olivier.ferret@cea.fr Xavier Tannier LIMSI, CNRS Univ. Paris-Sud Universit´e Paris-Saclay xavier.tannier@limsi.fr Abstract event detection. It is also an important subtask of larger NLP applications such as document summarization and event schema induction. Several approaches have been used to tackle the different aspects of this task, particularly in an unsupervised fashion, from linguistic pipelines (Filatova et al., 2006; Huang et al., 2016) to topic modeling approaches (Chambers and Jurafsky, 2011; Cheung et al., 2013) and more recently neural networks (Nguyen et al., 2016). While the definition and granularity of an event varies with the task and objectives at hand, most event identification systems exploit mentions to produce type-level representations. We propose to address the unsupervised event extraction task through two subtasks: first, unsupervised event instance extraction and second, event type extraction. This paper will focus on our efforts regarding the first step, e.g. unsupervised event instan"
W17-4211,P13-2139,0,0.0605657,"Missing"
W17-4211,P16-1025,0,0.0613311,"Missing"
W17-4211,W15-0809,0,0.0307778,"newswire and monolingual word alignment techniques to build meaningful and linguistically varied clusters of articles from the Web in the perspective of a broader event type detection task. We validate our approach on a manually annotated corpus of Web articles. 1 Introduction In the context of news production, an event is the characterization of a significant enough change in a space-time context to be reported as newsworthy content. This definition fits with definitions proposed in other contexts such as the ACE 2005 and TAC KBP Event evaluations or work such as (Cybulska and Vossen, 2014; Mitamura et al., 2015), which generally view each event as “something that happens at a particular place and time”, implying changes in the state of the world and involving participants. In accordance with ontologies about events such as the Simple Event Model (SEM) ontology (van Hage et al., 2011), events can be categorized into different types, for example “elections” or “earthquakes”, gathering multiple real-life instances, for example the “2017 UK General Election” or the “2012 French Presidential Election”. These instances are reported by journalists through varying textual mentions. Event extraction is a chal"
W17-4211,Q14-1018,0,\N,Missing
W18-5622,S15-2136,0,0.0739526,"Missing"
W18-5622,S17-2093,0,0.0512896,"Missing"
W18-5622,Q17-1010,0,0.193683,"#4, IOB format) and two categorical features (cols. #2 and #3), the partof-speech tag and a chunk label (IOB format). Tool Overview In this section, we present a general overview of YASET. First we describe input data formats (sequences and pre-trained word embeddings). Then we present the input pipeline, the network training phase, the implemented evaluation metrics and the management of its parameters. 4.1 4.2 Word Embeddings YASET supports embeddings in the word2vec (Mikolov et al., 2013b) or Genˇ uˇrek and Sojka, 2010) formats. Other sim (Reh˚ formats of embeddings, for instance FastText (Bojanowski et al., 2017) or Glove (Pennington et al., 2014), must first be converted to either accepted format. Input and Output Data YASET takes CoNLL-like10 formatted files as input. Sequences are separated by empty lines and there must be one token per line. For each token, 10 http://universaldependencies.org/ docs/format.html 195 the maximum number of iterations n and the patience criterion p. Training will stop if the maximum number n is reached or if there are p iterations without performance improvement on the development instances. Users can also set several parameters related to the learning algorithm such a"
W18-5622,W12-2411,0,0.0720674,"Missing"
W18-5622,N18-1131,0,0.0732005,"Missing"
W18-5622,N18-1079,0,0.0142593,"e of the total training set indicated on the first row). Standard errors appear between parentheses. We observe that the performance improves logarithmically with every chunk added in the training data as shown in Table 4. This finding is similar to the observation of Sun et al. (2017) for vision tasks. Further addition of data will slightly improve the performance as the maximum performance plateau is almost reached. 200 overlapping clinical entities at each layer. Ju et al. (2018) present a dynamic end-to-end neural network model capable of handling an undetermined number of nesting levels. Katiyar and Cardie (2018) model the task as an hypergraph whose structure is learned with an LSTM network. Future research will focus on the influence of word embedding models which were shown to significantly impact on performance. Specifically, models taking into account sub-token information (Bojanowski et al., 2017) or emphasizing context (Peters et al., 2018) should be further explored. Moreover, other neural network models for NER such as the ones proposed by Rei et al. (2016) and Ma and Hovy (2016) will be investigated and implemented in YASET. Having a centralized implementation of different NER models will al"
W18-5622,P17-1194,0,0.0178373,"put format and from the output format to the brat format. The tool produces several plots during training for performance analysis. It is implemented in Python and makes use of the TensorFlow library. Both implementations of the Bi-LSTM model suffer from a very long training time which makes them cumbersome to use. YASET offers a faster implementation of the model by allowing mini-batch training and by using the pipeline API of TensorFlow. Rei and Yannakoudakis (2016) released a Python implementation5 of different models presented in their works (Rei and Yannakoudakis, 2016; Rei et al., 2016; Rei, 2017). One major difference with YASET resides in the possibility to use a language modeling objective during training. Recently, Yang and Zhang (2018) introduced NCRF++6 , a tool presented as the neural version of CRF++7 and implemented with PyTorch (Paszke et al., 2017). The tool is very close to YASET, with the possibility to define handcrafted word features and to perform nbest decoding. Another type of neural network model, based on Convolutional Neural Networks (CNNs) for character level representation, is presented in Ma and Hovy (2016). The authors implemented the architecture with PyTorch."
W18-5622,C16-1030,0,0.112027,"., 2012) to the input format and from the output format to the brat format. The tool produces several plots during training for performance analysis. It is implemented in Python and makes use of the TensorFlow library. Both implementations of the Bi-LSTM model suffer from a very long training time which makes them cumbersome to use. YASET offers a faster implementation of the model by allowing mini-batch training and by using the pipeline API of TensorFlow. Rei and Yannakoudakis (2016) released a Python implementation5 of different models presented in their works (Rei and Yannakoudakis, 2016; Rei et al., 2016; Rei, 2017). One major difference with YASET resides in the possibility to use a language modeling objective during training. Recently, Yang and Zhang (2018) introduced NCRF++6 , a tool presented as the neural version of CRF++7 and implemented with PyTorch (Paszke et al., 2017). The tool is very close to YASET, with the possibility to define handcrafted word features and to perform nbest decoding. Another type of neural network model, based on Convolutional Neural Networks (CNNs) for character level representation, is presented in Ma and Hovy (2016). The authors implemented the architecture w"
W18-5622,N16-1030,0,0.193553,"e, we report distributions over 30 runs and different sizes of training datasets. YASET provides stateof-the-art performance on the CoNLL 2003 NER dataset (F1=0.87), MEDPOST corpus (F1=0.97), MERLoT corpus (F1=0.99) and NCBI disease corpus (F1=0.81). We believe that YASET is a versatile and efficient tool that can be used for sequence tagging in biomedical and clinical texts. 1 • a fast and accurate implementation of a state-of-the-art sequence tagging model based on Long Short-Term Memory Networks (LSTMs) (Hochreiter and Schmidhuber, 1997). The architecture is similar to the one described in Lample et al. (2016) and is able to process mini-batches for faster training. Furthermore, YASET supports the use of handcrafted features in combination with word and character embeddings; • an easy-to-use interface based on a central configuration file that is used to setup experiments, with default parameters that are suitable for most sequence tagging tasks; • an evaluation on various biomedical corpora and on the CoNLL 2003 corpus, studying the stability of our model and the effect of training data size. We compare YASET performance with state-of-the-art results published in the literature. Introduction Many"
W18-5622,P16-1112,0,0.0675502,"TM model. The authors intended to make the tool easy to use by providing automatic format conversion from the brat format (Stenetorp et al., 2012) to the input format and from the output format to the brat format. The tool produces several plots during training for performance analysis. It is implemented in Python and makes use of the TensorFlow library. Both implementations of the Bi-LSTM model suffer from a very long training time which makes them cumbersome to use. YASET offers a faster implementation of the model by allowing mini-batch training and by using the pipeline API of TensorFlow. Rei and Yannakoudakis (2016) released a Python implementation5 of different models presented in their works (Rei and Yannakoudakis, 2016; Rei et al., 2016; Rei, 2017). One major difference with YASET resides in the possibility to use a language modeling objective during training. Recently, Yang and Zhang (2018) introduced NCRF++6 , a tool presented as the neural version of CRF++7 and implemented with PyTorch (Paszke et al., 2017). The tool is very close to YASET, with the possibility to define handcrafted word features and to perform nbest decoding. Another type of neural network model, based on Convolutional Neural Netw"
W18-5622,D17-1035,0,0.0682807,"ning. Recently, Yang and Zhang (2018) introduced NCRF++6 , a tool presented as the neural version of CRF++7 and implemented with PyTorch (Paszke et al., 2017). The tool is very close to YASET, with the possibility to define handcrafted word features and to perform nbest decoding. Another type of neural network model, based on Convolutional Neural Networks (CNNs) for character level representation, is presented in Ma and Hovy (2016). The authors implemented the architecture with PyTorch. The code is freely available online8 . The same type of architecture is implemented in the tool released by Reimers and Gurevych (2017). It is implemented with Keras (Chollet et al., 2015) and is freely available online9 . Outside the peer-reviewed scientific environment, many other implementations are freely available online. However, we will not review them in this paper. 3 Neural Network Model There is currently one neural network model implemented in YASET. This model is mostly based on Lample et al. (2016). However, similar architectures are presented in other work (Collobert et al., 2011; Ma and Hovy, 2016; Rei and Yannakoudakis, 2016; Rei et al., 2016). Other network architectures will be implemented in the future. 3.1"
W18-5622,P16-1101,0,0.305832,"in their works (Rei and Yannakoudakis, 2016; Rei et al., 2016; Rei, 2017). One major difference with YASET resides in the possibility to use a language modeling objective during training. Recently, Yang and Zhang (2018) introduced NCRF++6 , a tool presented as the neural version of CRF++7 and implemented with PyTorch (Paszke et al., 2017). The tool is very close to YASET, with the possibility to define handcrafted word features and to perform nbest decoding. Another type of neural network model, based on Convolutional Neural Networks (CNNs) for character level representation, is presented in Ma and Hovy (2016). The authors implemented the architecture with PyTorch. The code is freely available online8 . The same type of architecture is implemented in the tool released by Reimers and Gurevych (2017). It is implemented with Keras (Chollet et al., 2015) and is freely available online9 . Outside the peer-reviewed scientific environment, many other implementations are freely available online. However, we will not review them in this paper. 3 Neural Network Model There is currently one neural network model implemented in YASET. This model is mostly based on Lample et al. (2016). However, similar architec"
W18-5622,E12-2021,0,0.11951,"Missing"
W18-5622,D14-1162,0,0.0823245,"features (cols. #2 and #3), the partof-speech tag and a chunk label (IOB format). Tool Overview In this section, we present a general overview of YASET. First we describe input data formats (sequences and pre-trained word embeddings). Then we present the input pipeline, the network training phase, the implemented evaluation metrics and the management of its parameters. 4.1 4.2 Word Embeddings YASET supports embeddings in the word2vec (Mikolov et al., 2013b) or Genˇ uˇrek and Sojka, 2010) formats. Other sim (Reh˚ formats of embeddings, for instance FastText (Bojanowski et al., 2017) or Glove (Pennington et al., 2014), must first be converted to either accepted format. Input and Output Data YASET takes CoNLL-like10 formatted files as input. Sequences are separated by empty lines and there must be one token per line. For each token, 10 http://universaldependencies.org/ docs/format.html 195 the maximum number of iterations n and the patience criterion p. Training will stop if the maximum number n is reached or if there are p iterations without performance improvement on the development instances. Users can also set several parameters related to the learning algorithm such as the initial learning rate, and gr"
W18-5622,N18-1202,0,0.0648615,"Missing"
W18-5622,P18-4013,0,0.0139859,"ented in Python and makes use of the TensorFlow library. Both implementations of the Bi-LSTM model suffer from a very long training time which makes them cumbersome to use. YASET offers a faster implementation of the model by allowing mini-batch training and by using the pipeline API of TensorFlow. Rei and Yannakoudakis (2016) released a Python implementation5 of different models presented in their works (Rei and Yannakoudakis, 2016; Rei et al., 2016; Rei, 2017). One major difference with YASET resides in the possibility to use a language modeling objective during training. Recently, Yang and Zhang (2018) introduced NCRF++6 , a tool presented as the neural version of CRF++7 and implemented with PyTorch (Paszke et al., 2017). The tool is very close to YASET, with the possibility to define handcrafted word features and to perform nbest decoding. Another type of neural network model, based on Convolutional Neural Networks (CNNs) for character level representation, is presented in Ma and Hovy (2016). The authors implemented the architecture with PyTorch. The code is freely available online8 . The same type of architecture is implemented in the tool released by Reimers and Gurevych (2017). It is im"
