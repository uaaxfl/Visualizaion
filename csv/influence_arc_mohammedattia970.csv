2006.bcs-1.5,W04-1604,0,0.0286353,"ce only valid solutions and avoid spurious solutions, the following considerations and techniques were followed. 1. Using the stem as the base form. Automatic derivation from the root can be risky as it may create stems not used in the language. 2. Non-inclusion of classical words or word senses, as they add only to the size of the lexicon and the level of ambiguity. 3. Observation of the rules governing the combination of words with affixes and clitics, or grammar-lexis specifications, which work as filters for spurious ambiguities (Dichy 2001; Dichy and Fargaly 2003; Dichy and Hassoun 1998; Abbès et al 2004). For example, adjectives, names of places, verbal nouns do not combine with possessive pronouns. Also verbal nouns derived from intransitive verbs do not combine with accusative pronouns. Yet more can be done regarding the filtering of human objects from verbs that allow only non-human objects (Dichy and Fargaly 2003) such as (33), which is still accepted by our system. (33 ﻗﺮأﺗﻬﻢ qara’tu-hum I read them There are also nouns that semantically do not allow the affixation of genitive pronouns, such as (34) which is still not properly handled by our system. (34 آﻴﻤﻴﺎﺋﻲ kimia’i my chemistry 4"
2006.bcs-1.5,C96-1017,0,0.11429,"Missing"
2006.bcs-1.5,C73-2019,0,0.771323,"Missing"
2006.bcs-1.5,W98-1007,0,0.166373,"Missing"
2006.bcs-1.5,W04-1606,0,0.061087,"r forms that are in contemporary usage. Still, it can be proven statistically that Buckwalter included classical terms by showing the Google score for some selected entries found Buckwalter’s morphology in Table 1. # 1 2 3 4 5 10. Word Transliteration Meaning Google ﻗﻠﻌﻂ qal’at sully 8 ﻗﻠﻔﻂ qalfat caulk 9 اﺳﺘﻜﺪ istakadda wear 4 ﻏﻤﻠﺞ ghamlaj fickle 7 اﺋﺘﻜﺎل i’tikal erosion 7 TABLE 1: Google score for entries from Buckwalter morphology Improper spelling relaxation rules. Buckwalter justified the inclusion of these relaxation rules by the fact that they are common in the data analyzed (Buckwalter 2004). We reckon however, that this is not a solid justification because, firstly, we should take into account that Arabic electronic texts are relatively recent, and that not so many authors are well trained in using proofing tools. Secondly, misspelled words should be handled as special cases, or apply rules when the form fails to receive an analysis. Applying the rules globally in this case led to a massive increase in the ambiguity level for correctly spelled words, as shown in (20). Thirdly, misspelling is even common in English. The Google score for the misspelled word “arround”, for example,"
2006.bcs-1.5,2003.mtsummit-semit.5,0,0.806328,"Missing"
2006.bcs-1.5,W02-0509,0,0.41112,"system is reduced without compromising precision. At the end, an evaluation of Xerox, Buckwalter, and our system is conducted, and the performance is compared and analyzed. Keywords: Arabic morphology, morphological ambiguity, Arabic morphological analyzer, Arabic finite state transducer 1. INTRODUCTION Morphological ambiguity in Arabic is a notorious problem that has not been sufficiently addressed (Kiraz 1998). This ambiguity represents hurdles in the way of POS taggers (Freeman 2001) syntactic parsers, and machine translation. Overcoming ambiguity is the major challenge for NLP in Arabic (Kamir et al 2002). Xerox Arabic Finite State Morphology and Buckwalter Arabic Morphological Analyzer are two of the best known, well documented, morphological analyzers for Modern Standard Arabic (MSA). Yet there are significant problems with both systems in design as well as coverage that increase the ambiguity rate. Xerox morphology is root based, yet it has uncurbed generative power that makes it produce forms that are unknown in the language. Buckwalter’s morphology is a stem-based database that lacks the generality and power of a rule-based system. Both systems include a large number classical entries tha"
2006.bcs-1.5,W98-1009,0,0.0886704,"Missing"
attia-etal-2010-automatically,W98-1002,0,\N,Missing
attia-etal-2010-automatically,D08-1030,0,\N,Missing
attia-etal-2010-automatically,W05-0711,0,\N,Missing
attia-etal-2010-automatically,P05-1071,0,\N,Missing
attia-etal-2010-automatically,2007.jeptalnrecital-poster.13,0,\N,Missing
attia-etal-2010-automatically,elkateb-etal-2006-building,0,\N,Missing
attia-etal-2010-automatically,farber-etal-2008-improving,0,\N,Missing
attia-etal-2012-automatic,schluter-van-genabith-2008-treebank,1,\N,Missing
attia-etal-2012-automatic,W04-1602,0,\N,Missing
attia-etal-2012-automatic,J08-1003,1,\N,Missing
attia-etal-2012-automatic,W09-0806,1,\N,Missing
attia-etal-2012-automatic,J05-3003,1,\N,Missing
attia-etal-2012-automatic,P04-1041,1,\N,Missing
attia-etal-2012-automatic,P06-1055,0,\N,Missing
attia-etal-2012-automatic,P07-1031,0,\N,Missing
attia-etal-2012-automatic,W04-3224,0,\N,Missing
C12-1006,P08-1083,0,0.0556977,"Missing"
C12-1006,2006.bcs-1.5,1,0.895801,"N ARABIC:  التوسع المعجمي، اإلثراء المعجمي، القاموس العائم، الكلمات الغير مدرجة في القواميس، الكلمات الغير معروفة،اللغة العربية Proceedings of COLING 2012: Technical Papers, pages 83–96, COLING 2012, Mumbai, December 2012. 83 1 Introduction Due to the complexity and semi-algorithmic nature of Arabic morphology (that employs numerous rules and constraints on inflection, derivation and cliticization), it has been a challenge for computational processing and analysis (Kiraz, 2001; Beesley 2003). A lexicon is an indispensable part of a morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001), and the coverage of the lexical database is a key factor in the coverage of the morphological analyser, and limitations in the lexicon will cascade through to higher levels of processing. Moreover, out of vocabulary words (or OOVs) have impact negatively on the performance of parsers (Attia et al., 2010) and MT applications (Huang et al. 2010). This is why an automatic method for updating a lexical database and dealing with unknown words is crucially important. We present the first attempt, to the best of our knowledge, to address the lemmatization (rather t"
C12-1006,W10-1408,1,0.88539,"Missing"
C12-1006,W11-4417,1,0.749922,"Missing"
C12-1006,N04-4038,0,0.0440034,"Missing"
C12-1006,2003.mtsummit-semit.5,0,0.0230558,"xical extension KEYWORDS IN ARABIC:  التوسع المعجمي، اإلثراء المعجمي، القاموس العائم، الكلمات الغير مدرجة في القواميس، الكلمات الغير معروفة،اللغة العربية Proceedings of COLING 2012: Technical Papers, pages 83–96, COLING 2012, Mumbai, December 2012. 83 1 Introduction Due to the complexity and semi-algorithmic nature of Arabic morphology (that employs numerous rules and constraints on inflection, derivation and cliticization), it has been a challenge for computational processing and analysis (Kiraz, 2001; Beesley 2003). A lexicon is an indispensable part of a morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001), and the coverage of the lexical database is a key factor in the coverage of the morphological analyser, and limitations in the lexicon will cascade through to higher levels of processing. Moreover, out of vocabulary words (or OOVs) have impact negatively on the performance of parsers (Attia et al., 2010) and MT applications (Huang et al. 2010). This is why an automatic method for updating a lexical database and dealing with unknown words is crucially important. We present the first attempt, to the best of our knowledge, to address the lemmatizat"
C12-1006,2010.amta-papers.13,0,0.0136507,"flection, derivation and cliticization), it has been a challenge for computational processing and analysis (Kiraz, 2001; Beesley 2003). A lexicon is an indispensable part of a morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001), and the coverage of the lexical database is a key factor in the coverage of the morphological analyser, and limitations in the lexicon will cascade through to higher levels of processing. Moreover, out of vocabulary words (or OOVs) have impact negatively on the performance of parsers (Attia et al., 2010) and MT applications (Huang et al. 2010). This is why an automatic method for updating a lexical database and dealing with unknown words is crucially important. We present the first attempt, to the best of our knowledge, to address the lemmatization (rather than stemming) of Arabic unknown words. The problem with lemmatizing unknown words is that they cannot be matched against a morphological lexicon. Furthermore, the specific problem with lemmatizing Arabic words is the richness and complexity of Arabic morphological derivational and inflectional processes. For the purposes of this paper, unknown words are words not found by the SA"
C12-1006,E09-2008,0,0.0321446,"inine Mark (1) Second (5) person Third person (5) TABLE 2 – Proclitics, enclitics, prefixes and suffixes with Arabic nouns Similarly a noun stem can be attached to up to three clitics as shown in Table 2. Although Table 2 shows four clitics, we note that the definite article and the genitive (or possessive) pronoun are mutually exclusive. Nominal stems can also be suffixed with bound morphemes that mark the morpho-syntactic features of number, gender and case. a typical noun like ‘ معلمmuEal~im’ ‘teacher’, generates 519 valid forms. 88 We develop a finite state (Beesley and Karttunen, 2003; Hulden, 2009) morphological guesser for Arabic that can analyse unknown words with all possible clitics, morphosyntactic affixes and all relevant alteration operations that include insertion, assimilation, and deletion. Beesley and Karttunen (2003) give some advice on how to create a basic guesser. The core idea of a guesser is to assume that a stem is composed of any arbitrary sequence of non-numeric characters, and this stem can be prefixed and/or suffixed with a predefined set of prefixes, suffixes or clitics. The guesser marks clitic boundaries and tries to return the stem to its default unmarked form,"
C12-1006,P08-2030,0,0.0826632,"n (rather than stemming) of Arabic unknown words. The problem with lemmatizing unknown words is that they cannot be matched against a morphological lexicon. Furthermore, the specific problem with lemmatizing Arabic words is the richness and complexity of Arabic morphological derivational and inflectional processes. For the purposes of this paper, unknown words are words not found by the SAMA morphological analyser (Maamouri et al., 2010) but accepted by the Microsoft Spell Checker. We develop a rule-based finite-state morphological guesser and use a machine learning based disambiguator, MADA (Roth et al., 2008), in a pipeline-based approach to lemmatization. We test our method against a manually created gold standard of 1,310 types (unique words) and show a significant improvement over the baseline. Furthermore, we devise a novel algorithm for weighting and prioritizing new words for inclusion in a lexicon depending on three factors: number of form variations of the lemmas, cumulative frequency of the forms, and the type of POS (part of speech) tag. This paper is structured as follows. The remainder of the introduction provides more details on the complexity of the lemmatization process in Arabic, w"
C12-1006,mohamed-kubler-2010-arabic,0,\N,Missing
C12-2011,W11-4417,1,0.911901,"Missing"
C12-2011,P00-1037,0,0.145659,"Missing"
C12-2011,J92-4003,0,0.0590624,"now use language models trained on different corpora to finally choose the single best correction. We compare the results against the Microsoft Spell Checker in Office 2010, Ayaspell used in OpenOffice, and Google Docs. 4.1 Correction Procedure For automatic spelling correction (or first order ranking) we use n-gram language models. Language modelling assumes that the production of a human language text is characterized by a set of conditional probabilities, , where is the history and is the prediction, so that the probability of a sequence of k words P(w1, …, wk) is formulated as a product (Brown et al., 1992): We use the SRILM toolkit2 (Stolcke et al., 2011) to train 2-, 3- and 4-gram language models on our data sets. As we have two types of candidates, normal words and split words, we use two SRILM tools: disambig and ngram. We use the disambig tool to choose among the normal candidates. Handling split words is done as a posterior step where we use the ngram tool to score the chosen candidate from the first round and the various split-word options. Then the candidate with the least perplexity score is selected. The perplexity of a language model is the reciprocal of the geometric average of the p"
C12-2011,P05-1071,0,0.165899,"Missing"
C12-2011,E09-2008,0,0.0607402,"r, the next step is to generate possible and plausible corrections for that error. For a spelling error and a dictionary , the purpose of the error model is to generate the correction , or list of corrections where ∊ , and are most likely to have been erroneously typed as . In order to do this, the error model generates a list of candidate corrections that bear the highest similarity to the spelling error . We use a finite-state transducer to propose candidate corrections within edit distance 1 and 2 measured by Levenshtein Distance (Levenshtein, 1966) from the misspelled word (Oflazer, 1996; Hulden, 2009b; Norvig, 2009; Mitton, 1996). The transducer works basically as a character-based generator that replaces each character with all possible characters in the alphabet as well as deleting, inserting, and transposing neighbouring characters. There is also the problem of merged (or run-on) words that need to be split, such as >‘ أوأيw>y’ “or any”. Candidate generation using edit distance is a brute-force process that ends up with a huge list of candidates. Given that there are 35 alphabetic letters in Arabic, for a word of length , there will be deletions, − 1 transpositions, 35 replaces, 35 +"
C12-2011,C90-2036,0,0.361216,"Missing"
C12-2011,W06-1648,0,0.17186,"Missing"
C12-2011,P08-2030,0,0.0557039,"nd a corpus of news articles crawled from the Al-Jazeera web site. The Gigaword corpus is a collection of news articles from nine news sources: Agence France-Presse, Xinhua News Agency, An Nahar, Al-Hayat, Al-Quds Al-Arabi, Al-Ahram, Assabah, Asharq Al-Awsat and Ummah Press. Before we start using our available corpora in training the language model, we analyse the data to measure the amount of noise in each subset of the data. In order to do this, we create a list of the most common spelling errors. This list of spelling errors is created by analysing the data using MADA (Habash et al., 2005; Roth et al., 2008) and checking instances where words have been normalized. In this case the original word is considered to be a suboptimal variation of the spelling of the diacritized form. We collect these suboptimal forms and sort them by frequency. 2 http://www.speech.sri.com/projects/srilm/ 108 Then we take the top 100 misspelt forms and see how frequent they are in the different subsets of data in relation to the word count in each data set. The analysis shows that the data has a varying degree of cleanness, ranging from the very clean to the very noisy. Data in the Agence France-Presse (AFP) is the noisi"
C12-2011,J96-1003,0,\N,Missing
C12-2011,shaalan-etal-2012-arabic,1,\N,Missing
C12-2011,I08-2131,0,\N,Missing
diab-etal-2014-tharwa,C12-2029,1,\N,Missing
diab-etal-2014-tharwa,W11-2602,1,\N,Missing
diab-etal-2014-tharwa,2009.mtsummit-caasl.5,1,\N,Missing
diab-etal-2014-tharwa,P02-1040,0,\N,Missing
diab-etal-2014-tharwa,P11-2062,1,\N,Missing
diab-etal-2014-tharwa,N13-1036,1,\N,Missing
diab-etal-2014-tharwa,habash-etal-2012-conventional,1,\N,Missing
diab-etal-2014-tharwa,pasha-etal-2014-madamira,1,\N,Missing
diab-etal-2014-tharwa,P13-2081,1,\N,Missing
diab-etal-2014-tharwa,maamouri-etal-2006-developing,1,\N,Missing
diab-etal-2014-tharwa,W12-2301,1,\N,Missing
diab-etal-2014-tharwa,P00-1056,0,\N,Missing
K17-1043,N16-3003,1,0.913316,"suffixes for each dialect in comparison to MSA. As the tables show, MGR has the most number of prefixes, while GLF has the most number of suffixes. Further, there are certain prefixes and suffixes that are unique to dialects. While the prefix “Al” (the) leads the list of prefixes for all dialects, the prefix H . “b” in LEV and EGY, where it is either a progressive particle or a preposition, is used more frequently than in MSA, where it is used strictly as a preposition. Similarly, the suffix “kn” (your) is more frequent in LEV than any á» 5.1 We used the SVM-based ranking approach proposed by Abdelali et al. (2016), in which they used SVM based ranking to ascertain the best segmentation for Modern Standard Arabic (MSA), which they show to be fast and of high accuracy. The approach involves generating all possible segmentations of a word and then ranking them. The possible segmentations are generated based on possible prefixes and suffixes that are observed during training. For example, if hypothetically we only had the prefixes ð “w” (and) and È “l” (to) other dialect. The Negation suffix  “$” (not) and feminine suffix marker No. 8 11 11 14 19 Top 5 Al,w,l,b,f Al,b,w,m,h Al,b,w,l,E Al,w,b,l,mA Al,w,l,"
K17-1043,habash-etal-2012-conventional,0,0.0821494,"ained for each dialect and the number of words they contain. Dialect Egyptian Levantine Gulf Maghrebi No of Tokens 6,721 6,648 6,844 5,495 Table 1: Dataset size for the different dialects We manually segmented each word in the corpus while preserving the original characters. This decision was made to allow processing real dialectal words in their original form. Table 2 shows segmented examples from the different dialects. 3.1 Segmentation Convention In some research projects, segmentation of DA is done on a CODA’fied version of the text, where CODA is a standardized writing convention for DA (Habash et al., 2012). CODA guidelines provide directions on to how to normalize words, correct spelling and unify writing. Nonetheless, these guidelines are not available for all dialects. In the absence of such guidelines as well as the dynamic nature of the language, we choose to operate directly on the raw text. As in contrast to MSA, where guidelines for spelling are common and standardized, written DA seems to exhibit a lot of diversity, and hence, segmentation systems need to be robust enough to handle all the variants that might be encountered in such texts. Our segmentation convention is closer to stemmin"
K17-1043,W11-4417,1,0.839746,"Missing"
K17-1043,N13-1044,0,0.142459,"val. Though much work has focused on segmenting Modern Standard Arabic (MSA), recent work began to examine dialectal segmentation in some Arabic dialects. Dialectal segmentation is becoming increasingly important due to the ubiquity of social media, where users typically write in their own dialects as opposed to MSA. Dialectal text poses interesting challenges such as lack of spelling standards, pervasiveness of word merging, letter substitution or deletion, and foreign word borrowing. Existing work on dialectal segmentation focused on building resources and tools for each dialect separately (Habash et al., 2013; 2 Background Work on dialectal Arabic is fairly recent compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014; Eldesouki et al., 2016). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghrebi. Few resources for these dialects 432 Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 432–441, c Vancouver, Canada, August 3 - August 4, 2017. 2017 Association for Computational Linguistics are available such as the CALLHO"
K17-1043,W09-0807,0,0.0760766,"Missing"
K17-1043,bouamor-etal-2014-multidialectal,0,0.0679135,"Missing"
K17-1043,N16-1030,0,0.011125,"A+MSA). 5.2 Figure 2: Architecture of our proposed neural network Arabic segmentation model applied to the  word éJ.Ê¯ “qlbh” and output “qlb+h”. o and c are respectively the input gate, forget gate, output gate and cell activation vectors. More interpretation about this architecture can be found in (Graves and Schmidhuber, 2005) and(Lipton et al., 2015). Bi-LSTM-CRF Approach In this subsection we describe the different components of our Arabic segmentation bi-LSTMCRF based model, shown in Figure 2. It is a slight variant of the bi-LSTM-CRF architecture first proposed by Huang et al. (2015), Lample et al. (2016), and Ma and Hovy (2016) 5.2.1 Bi-LSTMs Another extension to the single LSTM networks are the bi-LSTMs (Schuster and Paliwal, 1997). They are also capable of learning long-term dependencies and maintain contextual features from both past and future states. As shown in Figure 2, they are comprised of two separate hidden layers that feed forwards to the same output layer. Recurrent Neural Networks A recurrent neural network (RNN) together with its variants, i.e. LSTM, bi-LSTM, GRU, belong to a family of powerful neural networks that are well suited for modeling sequential data. Over the last sev"
K17-1043,D14-1154,1,0.904598,"Missing"
K17-1043,W16-4828,1,0.82771,"social media, where users typically write in their own dialects as opposed to MSA. Dialectal text poses interesting challenges such as lack of spelling standards, pervasiveness of word merging, letter substitution or deletion, and foreign word borrowing. Existing work on dialectal segmentation focused on building resources and tools for each dialect separately (Habash et al., 2013; 2 Background Work on dialectal Arabic is fairly recent compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014; Eldesouki et al., 2016). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghrebi. Few resources for these dialects 432 Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 432–441, c Vancouver, Canada, August 3 - August 4, 2017. 2017 Association for Computational Linguistics are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), which contains 2,000 parallel sentences in multiple dialects"
K17-1043,P16-1101,0,0.0180724,"itecture of our proposed neural network Arabic segmentation model applied to the  word éJ.Ê¯ “qlbh” and output “qlb+h”. o and c are respectively the input gate, forget gate, output gate and cell activation vectors. More interpretation about this architecture can be found in (Graves and Schmidhuber, 2005) and(Lipton et al., 2015). Bi-LSTM-CRF Approach In this subsection we describe the different components of our Arabic segmentation bi-LSTMCRF based model, shown in Figure 2. It is a slight variant of the bi-LSTM-CRF architecture first proposed by Huang et al. (2015), Lample et al. (2016), and Ma and Hovy (2016) 5.2.1 Bi-LSTMs Another extension to the single LSTM networks are the bi-LSTMs (Schuster and Paliwal, 1997). They are also capable of learning long-term dependencies and maintain contextual features from both past and future states. As shown in Figure 2, they are comprised of two separate hidden layers that feed forwards to the same output layer. Recurrent Neural Networks A recurrent neural network (RNN) together with its variants, i.e. LSTM, bi-LSTM, GRU, belong to a family of powerful neural networks that are well suited for modeling sequential data. Over the last several years, they have ac"
K17-1043,maamouri-etal-2014-developing,0,0.0662827,"Missing"
K17-1043,mohamed-etal-2012-annotating,0,0.12055,"Missing"
K17-1043,P14-2034,0,0.0769493,"Missing"
K17-1043,W14-3601,1,0.936065,"Missing"
K17-1043,pasha-etal-2014-madamira,0,0.10814,"Missing"
K17-1043,W17-1306,1,0.586168,"Missing"
K17-1043,J14-1006,0,0.0520662,"important due to the ubiquity of social media, where users typically write in their own dialects as opposed to MSA. Dialectal text poses interesting challenges such as lack of spelling standards, pervasiveness of word merging, letter substitution or deletion, and foreign word borrowing. Existing work on dialectal segmentation focused on building resources and tools for each dialect separately (Habash et al., 2013; 2 Background Work on dialectal Arabic is fairly recent compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014; Eldesouki et al., 2016). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghrebi. Few resources for these dialects 432 Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 432–441, c Vancouver, Canada, August 3 - August 4, 2017. 2017 Association for Computational Linguistics are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), which contains 2,000 parallel sente"
K17-1043,N12-1006,0,0.0492725,"oming increasingly important due to the ubiquity of social media, where users typically write in their own dialects as opposed to MSA. Dialectal text poses interesting challenges such as lack of spelling standards, pervasiveness of word merging, letter substitution or deletion, and foreign word borrowing. Existing work on dialectal segmentation focused on building resources and tools for each dialect separately (Habash et al., 2013; 2 Background Work on dialectal Arabic is fairly recent compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014; Eldesouki et al., 2016). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghrebi. Few resources for these dialects 432 Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 432–441, c Vancouver, Canada, August 3 - August 4, 2017. 2017 Association for Computational Linguistics are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), wh"
K17-3001,K17-3023,0,0.0375672,"Missing"
K17-3001,P16-1231,1,0.301678,"M Table 1: The supporting data overview: the number of words (M = million; K = thousand) for each language. http://commoncrawl.org/ Except for Ancient Greek, which was gathered from the Perseus Digital Library. 3 http://github.com/CLD2Owners/cld2 4 http://unicode.org/reports/tr15/ 3 verted to Unicode character NO-BREAK SPACE (U+00A0).5 The dimensionality of the word embeddings was chosen to be 100 after thorough discussion – more dimensions may yield better results and are commonly used, but even with just 100, the uncompressed word embeddings for the 45 languages take 135 GiB. Also note that Andor et al. (2016) achieved state-of-the-art results with 64 dimensions. The word embeddings were precomputed using word2vec (Mikolov et al., 2013) with the following options: word2vec -min-count 10 -size 100 -window 10 -negative 5 -iter 2 -threads 16 -cbow 0 -binary 0. The precomputed word embeddings are available on-line (Ginter et al., 2017). 2.3 this shared task, i.e., not included in any previous UD release. The PUD treebank consists of 1000 sentences currently in 18 languages (15 K to 27 K words, depending on the language), which were randomly picked from on-line newswire and Wikipedia;7 usually only a fe"
K17-3001,W06-2920,0,0.0145655,"categorization of the different approaches of the participating systems. Introduction Ten years ago, two CoNLL shared tasks were a major milestone for parsing research in general and dependency parsing in particular. For the first time dependency treebanks in more than ten languages were available for learning parsers. Many of them were used in follow-up work, evaluating parsers on multiple languages became standard, and multiple state-of-the-art, open-source parsers became available, facilitating production of dependency structures to be used in downstream applications. While the two tasks (Buchholz and Marsi, 2006; Nivre et al., 2007) were extremely important in setting the scene for the following years, there were also limitations that complicated application of their results: (1) gold-standard to1 Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 1–19, c 2017 Association for Computational Linguistics Vancouver, Canada, August 3-4, 2017. kenization and part-of-speech tags in the test data moved the tasks away from real-world scenarios, and (2) incompatible annotation schemes made cross-linguistic comparison impossible. CoNLL 2017 has picked"
K17-3001,K17-3017,0,0.147208,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3005,0,0.0752704,"Missing"
K17-3001,K17-3026,0,0.0310687,"E 90.88 82.31 82.46 LyS-FASTPARSE 90.88 82.31 79.14 NAIST SATO 90.88 82.31 82.46 Orange – Deski˜n 90.88 38.81 15.38 UALING 90.88 82.31 82.46 UParse 90.88 82.31 82.46 naistCL 90.88 82.31 82.46 Table 5: Universal POS tags, features and lemmas (ordered by UPOS F1 scores). duce suboptimal results when deployed on a machine different from the one where it was trained. Several teams used the library and may have been affected; for the Uppsala team (de Lhoneux et al., 2017) the issue led to official LAS = 65.11 (23rd place) instead of 69.66 (9th place). In the second case, the ParisNLP system (De La Clergerie et al., 2017) used a wrong method of recognizing the input language, which was not supported in the test data (but unfortunately it was possible to get along with it in development and trial data). Simply crashing could mean that the task moderator would show the team their diagnostic output and they would fix the bug; however, the parser was robust enough to switch to a languageagnostic mode and produced results that were not great, but also not so bad to alert the moderator and make him investigate. Thus the official LAS of the system is 60.02 (27th place) while without the bug it could have been 70.35 ("
K17-3001,K17-3021,0,0.0954088,"emains with participants, and since open sourcing the software underlying a paper is still the exception rather than the rule. To ensure both, TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems in order not to limit the choice of technology stacks and development environments. Once deployed and tested, the virtual machines are archived to preserve the software within. Many participants agreed to share their code so that we decided to collect the respective projects in a kind of open source proceedings at GitHub.14 4.3 by Straka and Strakov´a (2017) as one of the competing systems. Straka and Strakov´a (2017) describe both these versions in more detail. The baseline models were released together with the UD 2.0 training data, one model for each treebank. Because only training and development data were available during baseline model training, we put aside a part of the training data for hyperparameter tuning, and evaluated the baseline model performance on development data. We called this data split baseline model split. The baseline models, the baseline model split, and also UD 2.0 training data with morphology predicted by 10-fold jack"
K17-3001,K17-3022,1,0.891655,"Missing"
K17-3001,K17-3025,0,0.0327614,"Missing"
K17-3001,K17-3024,0,0.050508,"Missing"
K17-3001,K17-3027,0,0.0537913,"Missing"
K17-3001,K17-3014,0,0.0756362,"Missing"
K17-3001,K17-3015,0,0.0745209,"Missing"
K17-3001,K17-3007,0,0.0511894,"Missing"
K17-3001,L16-1262,1,0.869327,"Missing"
K17-3001,W14-6111,0,0.0253686,"Missing"
K17-3001,W17-0411,1,0.831758,"ossible when the system run completed; before that, even the task moderator would not see whether the system was really producing output and not just sitting in an endless loop. Especially given the scale of operations this year, this turned out to be a major obstacle for some participants; TIRA needs to be improved by offering more finegrained process monitoring tools, both for organizers and participants. Content-word Labeled Attachment Score (CLAS) has been proposed as an alternative parsing metric that is tailored to the UD annotation style and more suitable for cross-language comparison (Nivre and Fang, 2017). It differs from LAS in that it only considers relations between content words. Attachment of function words is disregarded because it corresponds to morphological features in other languages (and morphology is not evaluated in this shared task). Furthermore, languages with many function words (e.g., English) have longer sentences than morphologically rich languages (e.g., Finnish), hence a single error in Finnish costs the parser significantly more than an error in English. CLAS also disregards attachment of punctuation. As CLAS is still experimental, we have designated full LAS as our main"
K17-3001,K17-3003,0,0.0845341,"Missing"
K17-3001,W17-0412,1,0.869806,"Missing"
K17-3001,L16-1680,1,0.0475333,"Missing"
K17-3001,K17-3009,1,0.104147,"Missing"
K17-3001,tiedemann-2012-parallel,0,0.0126153,"oses (so that follow-up research is not obstructed). We deliberately did not place upper bounds on data sizes (in contrast to e.g. Nivre et al. (2007)), despite the fact that processing large amounts of data may be difficult for some teams. Our primary objective was to determine the capability of current parsers with the data that is currently available. In practice, the task was formally closed, i.e., we listed the approved data resources so that all participants were aware of their options. However, the selection was rather broad, ranging from Wikipedia dumps over the OPUS parallel corpora (Tiedemann, 2012) to morphological transducers. Some of the resources were proposed by the participating teams. 2.2 Supporting Data To enable the induction of custom embeddings and the use of semi-supervised methods in general, the participants were provided with supporting resources primarily consisting of large text corpora for (nearly) all of the languages in the task, as well as embeddings pre-trained on these corpora. 1 Outside CoNLL, there were several other parsing tasks in the meantime, which naturally also explored previously unadressed aspects—for example SANCL (Petrov and McDonald, 2012) or SPMRL (S"
K17-3001,K17-3016,0,0.0605417,"Missing"
K17-3001,K17-3020,0,0.0375614,"Missing"
K17-3001,K17-3013,0,0.0456211,"Missing"
K17-3001,D07-1096,1,\N,Missing
K17-3001,K17-3002,1,\N,Missing
K17-3001,K17-3019,0,\N,Missing
K17-3001,K17-3012,1,\N,Missing
K17-3001,K17-3006,0,\N,Missing
K17-3001,K17-3010,0,\N,Missing
K17-3001,K17-3018,0,\N,Missing
K17-3001,K17-3028,1,\N,Missing
K17-3001,K17-3011,0,\N,Missing
L16-1567,E14-4027,0,0.0360821,"Missing"
L16-1567,P98-1015,0,0.205197,"Missing"
L16-1567,P08-2053,0,0.0720439,"Missing"
L16-1567,P07-1072,0,0.0340964,"ounds, Saxon genitive, Norman genitive, nouns modified by adjectives derived from nouns, and nouns qualified by prepositions), but eventually found that only 26 of these relations have actual representation in their annotated corpus which are (in order of frequency): part-whole, attribute-holder, possession, theme, measure, agent, temporal, location/space, kinship, source, topic, recipient, purpose, depiction-depicted, is-a (hypernymy), make/produce, associated with, result, instrument, cause, 3574 manner, experiencer, means, influence, frequency, and predicate. Later, Girju et al. (2005) and Girju (2007) developed slightly modified versions of this scheme. Tratz and Hovy (2010) developed their own fine-grained taxonomy of 43 semantic types created mainly by breaking down main semantic categories into subcategories. For example the category of topic is divided into 7 other subcategories including topic of communication, e.g. “travel story”; topic of rules, e.g. “loan terms”; topic of emotion, e.g. “jazz fan”. They mapped their taxonomy to six previous taxonomies and concluded that the relations are ‘fairly similar’. They used five notations for mapping: ≈-approximately equivalent; ⊃/⊂-super/su"
L16-1567,C10-1045,0,0.060889,"Missing"
L16-1567,D07-1116,0,0.223958,"Arabic, construct state, Idafa, annotation, Treebank, syntax, semantics 1. Introduction 1.1. Idafa in Arabic Idafa is an Arabic term that means “annexation” or “addition”. In Arabic grammar, Idafa is a construction that is made up of two nominal parts (nouns, adjectives, proper nouns), where the whole construction serves as a single syntactic unit. The first part, in Arabic “mudaf” (MDF), is an indefinite noun and the second one, “mudaaf elayh” (MDFE), could either be definite or indefinite. Typically, in Idafa constructions (IC) the MDFE defines or specifies the MDF (Boujelben et al., 2011). Habash et al. (2007) highlight the role IC plays in syntactic case realization for nominals in Arabic. Syntactic case marking depends on whether the nominal is indefinite, namely marked with the nunation/tanween diacritic typically expressed as a word final an, un, in, or if the nominal is definite through agglutinating the definite article Al+ as a prefix, or is definite through IC. The case on MDF is sometimes referred to as the construct state. In principle, IC could be recursive with no specific bounds on the number of embeddings or nestings. IC in Arabic is practically a wide construction that covers many li"
L16-1567,P09-2056,0,0.123004,"fferent types of ICs. Accordingly, no distinction is made between noun-noun and quantifier-noun constructions. The phrases ِِﻛﺘﺎﺏب ُ ﺍاﻟﻨﱠﺤْ ﻮ kitAbu Al-naHowi 1 “grammar book” and ﻮﺍاﺿﻴﯿﻊ  ُﻛﻞﱡ ﺍاﻟ َﻤkul~u ِ Al-mawADiyEi “all topics” are rendered with the same syntactic realization, i.e. both are simply labeled (NP (NN NP)) where the words for book and all are labeled the same way as NN. The only attempt we know of to explicitly label ICs on a large scale was in the context of the CATiB dependency annotation effort in which they use the IDF tag, as one of 8 grammatical relation labels (Habash and Roth, 2009). Accordingly, in this paper, we present a typification of the various coarse syntactic constructions of (NP (NN NP)) and (NP (JJ NP)) present in the ATB, corresponding to the syntactic IC linguistic phenomenon, into their various IC types based on the true POS categories of their heads and complements. We present an automatic extraction and classification process which yields three main types that are further divided into 10 syntactic IC subtypes. 1 All the transliteration in this paper is presented using the Buckwalter encoding system www.qamus.com Furthermore, we present our semantic framew"
L16-1567,maamouri-etal-2008-enhancing,0,0.0833316,"Missing"
L16-1567,W04-2609,0,0.0299691,"g precise distinctions between types. This overview of the literature on the semantic classification of compound nouns shows the divergence between theoretical and empirical studies. Theoretical studies tend to use coarse-grained types, as they are inclined more towards generalization, while empirical studies tend to use medium- to fine-grained sets of labels to be more descriptive and more exhaustive of the data they target to annotate. 5.2. Our Annotation Scheme In our work on the semantic annotation of compound nouns (specifically Arabic Idafa), we adopt the 26 taxonomy types designated by Moldovan et al (2004). The reasons we adopt this annotation scheme are: 1) its medium granularity which makes a good compromise between generalizability and applicability; 2) it was designed for English noun phrases which are closer to Arabic IC than the more restricted set of noun-noun compounds; and 3) they use purely semantic notation, i.e. without relying on grammatical functions or lexical interpretation. Lauer’s list of 8 prepositional paraphrases for noun compound has gained popularity in the literature the field since its inception. We argue against the use of prepositions for the purpose of semantic class"
L16-1567,P10-1070,0,0.015536,"es derived from nouns, and nouns qualified by prepositions), but eventually found that only 26 of these relations have actual representation in their annotated corpus which are (in order of frequency): part-whole, attribute-holder, possession, theme, measure, agent, temporal, location/space, kinship, source, topic, recipient, purpose, depiction-depicted, is-a (hypernymy), make/produce, associated with, result, instrument, cause, 3574 manner, experiencer, means, influence, frequency, and predicate. Later, Girju et al. (2005) and Girju (2007) developed slightly modified versions of this scheme. Tratz and Hovy (2010) developed their own fine-grained taxonomy of 43 semantic types created mainly by breaking down main semantic categories into subcategories. For example the category of topic is divided into 7 other subcategories including topic of communication, e.g. “travel story”; topic of rules, e.g. “loan terms”; topic of emotion, e.g. “jazz fan”. They mapped their taxonomy to six previous taxonomies and concluded that the relations are ‘fairly similar’. They used five notations for mapping: ≈-approximately equivalent; ⊃/⊂-super/sub set; ∞-some overlap; ∪-union. The problem with this scheme is the obvious"
L16-1567,C94-2125,0,0.0269024,"Missing"
L18-1015,N16-3003,1,0.699404,"weet-specific POS tags Data Description Dialect Egyptian (EGY) Levantine (LEV) Gulf (GLF) Maghrebi (MGR) POS PROG PART https://catalog.ldc.upenn.edu/LDC2017T07 Buckwalter transliteration is used in the paper 94 tion is that MSA has more noun suffixes and grammatical case endings, while dialects have more progressive particles and negation suffixes. This variance is related more to the linguistic nature of the language rather than the genre. 4. 4.1. would be effective for dialects also, particularly given the overlap between MSA and dialectal Arabic. We used Farasa to determine stem templates (Abdelali et al., 2016). For all the experiments, we trained on the training and dev parts and tested on the test part. As mentioned earlier, we also randomly selected 350 MSA sentences from Arabic Penn Treebank (ATB) and treated MSA as a language variety. Doing so would allow us to observe the divergence of dialects from MSA and the relative effectiveness of using a small dataset compared to much more data. Experiments and Evaluation Experimental Setup For the experiments that we conducted, we used the CRF++ implementation of a CRF sequence labeler with L2 regularization and default value of 10 for the generalizati"
L18-1015,al-sabbagh-girju-2010-mining,0,0.0566271,"Missing"
L18-1015,bouamor-etal-2014-multidialectal,0,0.0463357,"Missing"
L18-1015,J92-4003,0,0.113623,"Missing"
L18-1015,cotterell-callison-burch-2014-multi,0,0.0466115,"Missing"
L18-1015,D14-1154,1,0.889503,"Missing"
L18-1015,W17-1316,1,0.769801,"ur justification for this noticeable disparity is that the POS distribution is affected by the genre. The MSA text is from the formal news domain with a special focus on facts and entities, while the dialects are informal expressions with a focus on events, attitudes, and conversations. Another observaThe words in the dataset were segmented in place without any modification or standardization attempts (ex. CODA (Habash et al., 2012)), and the segmentation guidelines aimed to generate a number of segments that match the correct number of POS tags for a word. We used the POS tagset described by Darwish et al. (2017) which has 18 tags for MSA POS tagging, and we added 2 dialect-specific tags (namely PROG PART, and NEG PART), and 4 tweet-specific tags (namely HASH, EMOT, MENTION, and URL). Table 1 contains description of the newly added tags5 . 4 Example I.JºJK . (bnktb) Segmentation and POS tagging were applied on the original raw text without any correction as suggested by Eldesouki et al. (2017) to overcome the need for standardization of different dialectal writings proposed in CODA by  ®J J.Óð Habash et al. (2012). For example the word ñËñ We used the dialectal Arabic dataset described by Eldesouk"
L18-1015,W05-0708,0,0.819563,"Missing"
L18-1015,P06-1086,0,0.314234,"Missing"
L18-1015,habash-etal-2012-conventional,0,0.027441,"prepositions, numbers, and definite articles appear more frequently in MSA than in dialects, while on the other hand dialects show higher frequency of verbs, pronouns and particles. Our justification for this noticeable disparity is that the POS distribution is affected by the genre. The MSA text is from the formal news domain with a special focus on facts and entities, while the dialects are informal expressions with a focus on events, attitudes, and conversations. Another observaThe words in the dataset were segmented in place without any modification or standardization attempts (ex. CODA (Habash et al., 2012)), and the segmentation guidelines aimed to generate a number of segments that match the correct number of POS tags for a word. We used the POS tagset described by Darwish et al. (2017) which has 18 tags for MSA POS tagging, and we added 2 dialect-specific tags (namely PROG PART, and NEG PART), and 4 tweet-specific tags (namely HASH, EMOT, MENTION, and URL). Table 1 contains description of the newly added tags5 . 4 Example I.JºJK . (bnktb) Segmentation and POS tagging were applied on the original raw text without any correction as suggested by Eldesouki et al. (2017) to overcome the need for"
L18-1015,N13-1044,0,0.508721,"Missing"
L18-1015,N13-1039,0,0.0374619,"Missing"
L18-1015,P08-2030,0,0.65644,"Missing"
L18-1015,W17-1306,1,0.871249,"or MSA POS tagging, and we added 2 dialect-specific tags (namely PROG PART, and NEG PART), and 4 tweet-specific tags (namely HASH, EMOT, MENTION, and URL). Table 1 contains description of the newly added tags5 . 4 Example I.JºJK . (bnktb) Segmentation and POS tagging were applied on the original raw text without any correction as suggested by Eldesouki et al. (2017) to overcome the need for standardization of different dialectal writings proposed in CODA by  ®J J.Óð Habash et al. (2012). For example the word ñËñ We used the dialectal Arabic dataset described by Eldesouki et al. (2017) and Samih et al. (2017b), which includes a set of 350 tweets for four major Arabic dialects that were manually segmented. The size of the dataset is as follows: No of Tweets 350 350 350 350 Description Progressive Part. Table 1: Dialect-specific and tweet-specific POS tags Data Description Dialect Egyptian (EGY) Levantine (LEV) Gulf (GLF) Maghrebi (MGR) POS PROG PART https://catalog.ldc.upenn.edu/LDC2017T07 Buckwalter transliteration is used in the paper 94 tion is that MSA has more noun suffixes and grammatical case endings, while dialects have more progressive particles and negation suffixes. This variance is rel"
L18-1015,K17-1043,1,0.86893,"or MSA POS tagging, and we added 2 dialect-specific tags (namely PROG PART, and NEG PART), and 4 tweet-specific tags (namely HASH, EMOT, MENTION, and URL). Table 1 contains description of the newly added tags5 . 4 Example I.JºJK . (bnktb) Segmentation and POS tagging were applied on the original raw text without any correction as suggested by Eldesouki et al. (2017) to overcome the need for standardization of different dialectal writings proposed in CODA by  ®J J.Óð Habash et al. (2012). For example the word ñËñ We used the dialectal Arabic dataset described by Eldesouki et al. (2017) and Samih et al. (2017b), which includes a set of 350 tweets for four major Arabic dialects that were manually segmented. The size of the dataset is as follows: No of Tweets 350 350 350 350 Description Progressive Part. Table 1: Dialect-specific and tweet-specific POS tags Data Description Dialect Egyptian (EGY) Levantine (LEV) Gulf (GLF) Maghrebi (MGR) POS PROG PART https://catalog.ldc.upenn.edu/LDC2017T07 Buckwalter transliteration is used in the paper 94 tion is that MSA has more noun suffixes and grammatical case endings, while dialects have more progressive particles and negation suffixes. This variance is rel"
L18-1015,W15-1511,0,0.189752,"Missing"
L18-1015,P11-2007,0,0.0736066,"Missing"
L18-1101,baccianella-etal-2010-sentiwordnet,0,0.0887774,"Missing"
L18-1101,W14-3623,0,0.0518071,"Missing"
L18-1101,C16-1251,0,0.0528171,"Missing"
L18-1101,C14-1008,0,0.11537,"Missing"
L18-1101,esuli-sebastiani-2006-sentiwordnet,0,0.0584634,"Missing"
L18-1101,C04-1121,0,0.206222,"Missing"
L18-1101,steinberger-etal-2017-large,0,0.0333011,"Missing"
L18-1101,D14-1181,0,0.00254269,"of neural nets to automatically capture the underlying factors that lead from the input to the output, eliminating the need for feature engineering. 3. Convolutional Neural Networks Convolutional Neural Networks (CNNs) (LeCun et al., 1995) are a powerful deep learning technique because they preserve the spatial structure of the data. They have been shown to produce state-of-the-art results in image processing, computer vision (Krizhevsky et al., 2012) and speech recognition (Graves et al., 2013). In recent years, CNNs have been successfully applied to NLP and document classification problems (Kim, 2014; Johnson and Zhang, 2014). The input to CNNs is a feature map which corresponds to the pixels in an image or words in a sentence or document, or characters in words. This feature map is scanned in CNNs one area at a time by filters, assuming that filters slide, or convolve, around the feature map. The way CNNs adjust their filter weights is through backpropagation, which means that after the forward pass, the network is able to look at the loss function and make a backward pass to update the weights. The CNN layer is followed by a pooling layer that compresses or generalizes over the CNN repr"
L18-1101,P11-1015,0,0.105261,"Missing"
L18-1101,N13-1090,0,0.026573,"Missing"
L18-1101,W04-3253,0,0.10306,"Missing"
L18-1101,S13-2074,0,0.0361896,"Missing"
L18-1101,W02-1011,0,0.0255213,"Missing"
L18-1101,D14-1162,0,0.0773683,"Missing"
L18-1101,perez-rosas-etal-2012-learning,0,0.0374446,"Missing"
L18-1101,remus-etal-2010-sentiws,0,0.0768353,"Missing"
L18-1101,H05-1044,0,0.16501,"Missing"
L18-1414,P11-2062,0,0.0281741,"ssessive Alternation. The GNOME project (Poesio, 2004) aimed to create a corpus to study aspects of discourse and included an animacy taxonomy. The Dutch Cornetto lexical-semantic database (Martin et al., 2005) includes animacy annotation using hierarchical division of categories and subcategories. Orasan and Evans (2007a) described animacy annotation meant for anaphora resolution in English. Thuilier and Danlos (2012) annotated a French corpus for animacy and verb semantic classes. Jena et al. (2013) reported on work to enrich an already available treebank for Hindi with animacy information. Alkuhlani and Habash (2011), Elghamry et al. (2008), and Diab et al. (2014) reported on annotating Arabic data for gender, number and rationality (a hyponym of animacy). 1.1. Animacy Hierarchies Different hierarchies and annotation schemes have been developed for animacy with different levels of granularity, but the common denominator in these hierarchies is the three level taxonomy first proposed by (Silverstein, 1976): human > animate > inanimate More fine-grained details are added to this core hierarchy by classifying ‘human’ according to person (1st, 2nd, and 3rd person) (Dik, 1997), breaking down ‘inanimate’ into ‘"
L18-1414,W10-1411,0,0.0275169,"Missing"
L18-1414,D14-1082,0,0.131657,"Missing"
L18-1414,W08-1301,0,0.198422,"Missing"
L18-1414,de-marneffe-etal-2014-universal,0,0.0660877,"Missing"
L18-1414,diab-etal-2014-tharwa,1,0.839877,"med to create a corpus to study aspects of discourse and included an animacy taxonomy. The Dutch Cornetto lexical-semantic database (Martin et al., 2005) includes animacy annotation using hierarchical division of categories and subcategories. Orasan and Evans (2007a) described animacy annotation meant for anaphora resolution in English. Thuilier and Danlos (2012) annotated a French corpus for animacy and verb semantic classes. Jena et al. (2013) reported on work to enrich an already available treebank for Hindi with animacy information. Alkuhlani and Habash (2011), Elghamry et al. (2008), and Diab et al. (2014) reported on annotating Arabic data for gender, number and rationality (a hyponym of animacy). 1.1. Animacy Hierarchies Different hierarchies and annotation schemes have been developed for animacy with different levels of granularity, but the common denominator in these hierarchies is the three level taxonomy first proposed by (Silverstein, 1976): human > animate > inanimate More fine-grained details are added to this core hierarchy by classifying ‘human’ according to person (1st, 2nd, and 3rd person) (Dik, 1997), breaking down ‘inanimate’ into ‘concrete’ and ‘abstract’ (Martin et al., 2005),"
L18-1414,W13-2320,0,0.277771,"ve of (Zaenen et al., 2004) where animacy annotation was included in two projects: the Paraphrase project and Possessive Alternation. The GNOME project (Poesio, 2004) aimed to create a corpus to study aspects of discourse and included an animacy taxonomy. The Dutch Cornetto lexical-semantic database (Martin et al., 2005) includes animacy annotation using hierarchical division of categories and subcategories. Orasan and Evans (2007a) described animacy annotation meant for anaphora resolution in English. Thuilier and Danlos (2012) annotated a French corpus for animacy and verb semantic classes. Jena et al. (2013) reported on work to enrich an already available treebank for Hindi with animacy information. Alkuhlani and Habash (2011), Elghamry et al. (2008), and Diab et al. (2014) reported on annotating Arabic data for gender, number and rationality (a hyponym of animacy). 1.1. Animacy Hierarchies Different hierarchies and annotation schemes have been developed for animacy with different levels of granularity, but the common denominator in these hierarchies is the three level taxonomy first proposed by (Silverstein, 1976): human > animate > inanimate More fine-grained details are added to this core hier"
L18-1414,O04-2002,0,0.0570902,"es for Arabic and Russian each, along with other languages) annotated according to the scheme described in this paper is made publicly available (https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1983) as part of the CoNLL 2017 Shared Task on Multilingual Parsing (Zeman et al., 2017). Keywords: animacy, Arabic, Russian, Dependency Parsing 1. Introduction The explicit encoding and identification of the animacy of entities in data has been reported to improve NLP tasks such as syntactic function disambiguation (Øvrelid, 2004; Lamers, 2007), anaphora resolution (Orasan and Evans, 2007a; Liang and Wu, 2004; Singh et al., 2014), syntactic parsing (Marton et al., 2011; Ambati et al., 2010; Nivre et al., 2008; Bharati et al., 2008), and disambiguation accuracy in boosting fluency in text generation (Bloem and Bouma, 2013). In human cognition research, animacy is considered as one of the first characterizations made by human beings in their infancy and the last distinction lost in adults with Alzheimer’s disease (Szewczyk and Schriefers, 2010). This is probably why computational representation of languages (particularly where animacy plays a morpho-syntactic function, e.g. Russian, Arabic, and Hind"
L18-1414,P11-1159,0,0.0236412,"annotated according to the scheme described in this paper is made publicly available (https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1983) as part of the CoNLL 2017 Shared Task on Multilingual Parsing (Zeman et al., 2017). Keywords: animacy, Arabic, Russian, Dependency Parsing 1. Introduction The explicit encoding and identification of the animacy of entities in data has been reported to improve NLP tasks such as syntactic function disambiguation (Øvrelid, 2004; Lamers, 2007), anaphora resolution (Orasan and Evans, 2007a; Liang and Wu, 2004; Singh et al., 2014), syntactic parsing (Marton et al., 2011; Ambati et al., 2010; Nivre et al., 2008; Bharati et al., 2008), and disambiguation accuracy in boosting fluency in text generation (Bloem and Bouma, 2013). In human cognition research, animacy is considered as one of the first characterizations made by human beings in their infancy and the last distinction lost in adults with Alzheimer’s disease (Szewczyk and Schriefers, 2010). This is probably why computational representation of languages (particularly where animacy plays a morpho-syntactic function, e.g. Russian, Arabic, and Hindi) needs to provide adequate description and annotation of th"
L18-1414,P13-2017,0,0.0249537,"Missing"
L18-1414,W04-2407,0,0.172649,"Missing"
L18-1414,C08-1081,0,0.0151983,"d in this paper is made publicly available (https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1983) as part of the CoNLL 2017 Shared Task on Multilingual Parsing (Zeman et al., 2017). Keywords: animacy, Arabic, Russian, Dependency Parsing 1. Introduction The explicit encoding and identification of the animacy of entities in data has been reported to improve NLP tasks such as syntactic function disambiguation (Øvrelid, 2004; Lamers, 2007), anaphora resolution (Orasan and Evans, 2007a; Liang and Wu, 2004; Singh et al., 2014), syntactic parsing (Marton et al., 2011; Ambati et al., 2010; Nivre et al., 2008; Bharati et al., 2008), and disambiguation accuracy in boosting fluency in text generation (Bloem and Bouma, 2013). In human cognition research, animacy is considered as one of the first characterizations made by human beings in their infancy and the last distinction lost in adults with Alzheimer’s disease (Szewczyk and Schriefers, 2010). This is probably why computational representation of languages (particularly where animacy plays a morpho-syntactic function, e.g. Russian, Arabic, and Hindi) needs to provide adequate description and annotation of this feature. Contrary to previously preval"
L18-1414,L16-1262,0,0.046359,"Missing"
L18-1414,W03-3017,0,0.025806,"Missing"
L18-1414,W15-2127,0,0.0404713,"Missing"
L18-1414,W04-0210,0,0.332982,"inguistic phenomena, such as case marking, agreement, topicality, argument realization, and structural preferences. It has received formal linguistic investigation in the works of various researchers, most notably (Silverstein, 1976; Dik, 1997; Aissen, 2003; Martin et al., 2005; Dahl, 2008; Bloem and Bouma, 2013; Eckhoff, 2015; Karsdorp et al., 2015). Various projects have targeted animacy annotation, most remarkably was the benchmark initiative of (Zaenen et al., 2004) where animacy annotation was included in two projects: the Paraphrase project and Possessive Alternation. The GNOME project (Poesio, 2004) aimed to create a corpus to study aspects of discourse and included an animacy taxonomy. The Dutch Cornetto lexical-semantic database (Martin et al., 2005) includes animacy annotation using hierarchical division of categories and subcategories. Orasan and Evans (2007a) described animacy annotation meant for anaphora resolution in English. Thuilier and Danlos (2012) annotated a French corpus for animacy and verb semantic classes. Jena et al. (2013) reported on work to enrich an already available treebank for Hindi with animacy information. Alkuhlani and Habash (2011), Elghamry et al. (2008), a"
L18-1414,thuilier-danlos-2012-semantic,0,0.0263183,"arious projects have targeted animacy annotation, most remarkably was the benchmark initiative of (Zaenen et al., 2004) where animacy annotation was included in two projects: the Paraphrase project and Possessive Alternation. The GNOME project (Poesio, 2004) aimed to create a corpus to study aspects of discourse and included an animacy taxonomy. The Dutch Cornetto lexical-semantic database (Martin et al., 2005) includes animacy annotation using hierarchical division of categories and subcategories. Orasan and Evans (2007a) described animacy annotation meant for anaphora resolution in English. Thuilier and Danlos (2012) annotated a French corpus for animacy and verb semantic classes. Jena et al. (2013) reported on work to enrich an already available treebank for Hindi with animacy information. Alkuhlani and Habash (2011), Elghamry et al. (2008), and Diab et al. (2014) reported on annotating Arabic data for gender, number and rationality (a hyponym of animacy). 1.1. Animacy Hierarchies Different hierarchies and annotation schemes have been developed for animacy with different levels of granularity, but the common denominator in these hierarchies is the three level taxonomy first proposed by (Silverstein, 1976"
L18-1414,W03-3023,0,0.154925,"Missing"
L18-1414,W04-0216,0,0.132694,"Missing"
L18-1414,K17-3001,1,0.890717,"Missing"
S18-1155,P10-1089,0,0.0137,"stical and knowledge-driven semantics. This classification depends on whether the assumption is that human knowledge is encapsulated in language man947 Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018), pages 947–952 New Orleans, Louisiana, June 5–6, 2018. ©2018 Association for Computational Linguistics Dataset Training Validation Test comparison of semantic similarity (Joubarne and Inkpen, 2011), information retrieval (Tandon and De Melo, 2010; Klein and Nelson, 2009), lexical disambiguation (Bergsma et al., 2009), improving general purpose NLP classifiers (Bergsma et al., 2010), and improving parsing performance (Pitler et al., 2010). Knowledge-driven approaches to the detection of semantic relations rely on manually constructed lexical and encyclopedic resources, such as ConceptNet (Speer et al., 2017), ImageNet (Russakovsky et al., 2015), WordNet (Miller and Fellbaum, 1998), Wiktionary, Open Mind Common Sense (Singh et al., 2002) and DBpedia (Mendes et al., 2012). In this work we follow a statistical based approach and show the strengths and weakness of the distributional semantics of the word vectors and ngram frequency counts in capturing the different types of"
S18-1155,N16-2002,0,0.012595,"with word embeddings is to formulate semantic relations in arithmetic fashion by creating a vector space in which words with similar contextual embeddings have closer vectors distance (Hinton et al., 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schtze, 2008; Mikolov et al., 2013c). The public availability of word embedding training programs such as word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014) allowed researchers to create models with different parameters and dimensionality sizes for different purposes including capturing semantic relations (Gladkova et al., 2016; Attia et al., 2016). The Google n-gram corpus (Brants and Franz, 2006) is a collection of English word n-grams and their observed counts generated from 1 trillion words of texts from web pages. This corpus has been used in many different applications including estimating word-relatedness (Islam et al., 2012), This paper describes our system submission to the SemEval 2018 Task 10 on Capturing Discriminative Attributes. Given two concepts and an attribute, the task is to determine whether the attribute is semantically related to one concept and not the other. In this work we assume that discri"
S18-1155,N13-1090,0,0.119332,"al application to the Firthian dictum “You shall know a word by the company it keeps” (Firth, 1957) which has become commonsense wisdom in lexical semantics. Features of the statistical model are extracted from unstructured data, such as words embeddings, n-gram counts, or directly from raw data. The basic idea with word embeddings is to formulate semantic relations in arithmetic fashion by creating a vector space in which words with similar contextual embeddings have closer vectors distance (Hinton et al., 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schtze, 2008; Mikolov et al., 2013c). The public availability of word embedding training programs such as word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014) allowed researchers to create models with different parameters and dimensionality sizes for different purposes including capturing semantic relations (Gladkova et al., 2016; Attia et al., 2016). The Google n-gram corpus (Brants and Franz, 2006) is a collection of English word n-grams and their observed counts generated from 1 trillion words of texts from web pages. This corpus has been used in many different applications including estimating word-relatedn"
S18-1155,D14-1162,0,0.0768369,"in lexical semantics. Features of the statistical model are extracted from unstructured data, such as words embeddings, n-gram counts, or directly from raw data. The basic idea with word embeddings is to formulate semantic relations in arithmetic fashion by creating a vector space in which words with similar contextual embeddings have closer vectors distance (Hinton et al., 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schtze, 2008; Mikolov et al., 2013c). The public availability of word embedding training programs such as word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014) allowed researchers to create models with different parameters and dimensionality sizes for different purposes including capturing semantic relations (Gladkova et al., 2016; Attia et al., 2016). The Google n-gram corpus (Brants and Franz, 2006) is a collection of English word n-grams and their observed counts generated from 1 trillion words of texts from web pages. This corpus has been used in many different applications including estimating word-relatedness (Islam et al., 2012), This paper describes our system submission to the SemEval 2018 Task 10 on Capturing Discriminative Attributes. Giv"
S18-1155,C10-1100,0,0.0133334,"depends on whether the assumption is that human knowledge is encapsulated in language man947 Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018), pages 947–952 New Orleans, Louisiana, June 5–6, 2018. ©2018 Association for Computational Linguistics Dataset Training Validation Test comparison of semantic similarity (Joubarne and Inkpen, 2011), information retrieval (Tandon and De Melo, 2010; Klein and Nelson, 2009), lexical disambiguation (Bergsma et al., 2009), improving general purpose NLP classifiers (Bergsma et al., 2010), and improving parsing performance (Pitler et al., 2010). Knowledge-driven approaches to the detection of semantic relations rely on manually constructed lexical and encyclopedic resources, such as ConceptNet (Speer et al., 2017), ImageNet (Russakovsky et al., 2015), WordNet (Miller and Fellbaum, 1998), Wiktionary, Open Mind Common Sense (Singh et al., 2002) and DBpedia (Mendes et al., 2012). In this work we follow a statistical based approach and show the strengths and weakness of the distributional semantics of the word vectors and ngram frequency counts in capturing the different types of discriminative attributes. 2 # of triples 17,547 2,722 2,"
S18-1155,S18-1117,0,0.0412099,"encoded. The two resources are the Google n-gram counts and the Google News Word2Vec. Google n-gram counts. We use the Google 5-gram counts as provided by Google Books ngrams1 (Michel et al., 2011; Lin et al., 2012). Google News Word2Vec. This is a publicly available pre-trained word vector2 , built with the word2vec architecture (Mikolov et al., 2013b) from a news corpus of 100B words (3M vocabulary entries) with 300 dimensions, negative sampling, using continuous bag of words and window size of 5. Task and Data Description The goal of the shared task on Capturing Discriminative Attributes (Krebs et al., 2018) is to detect semantic difference between pairs of concepts, or in other words, determine whether a semantic property differentiates between two possibly related concepts. For example both ‘bear’ and ‘goat’ are animals, but only a ‘bear’ has ‘claws’. Therefore ‘claws’ is considered as a discriminative feature. The shared task data is formatted in triples that represent a ternary relation between two concepts (Word1 , Word2 ) on one hand and an attribute (Word3 ) on the other. Word3 is considered as a discriminative attribute if, and only if, it characterizes Word1 but not Word2 . For example,"
S18-1155,P12-3029,0,0.0122596,"butes. The basic idea with deep learning is to use hidden layers of neural nets to automatically capture the underlying factors that lead from the input to the output, eliminating the need for feature engineering. The system is trained on features extracted from two main publicly available resources that fall within the paradigm of unstructured data as no manual lexical or encyclopedic knowledge is encoded. The two resources are the Google n-gram counts and the Google News Word2Vec. Google n-gram counts. We use the Google 5-gram counts as provided by Google Books ngrams1 (Michel et al., 2011; Lin et al., 2012). Google News Word2Vec. This is a publicly available pre-trained word vector2 , built with the word2vec architecture (Mikolov et al., 2013b) from a news corpus of 100B words (3M vocabulary entries) with 300 dimensions, negative sampling, using continuous bag of words and window size of 5. Task and Data Description The goal of the shared task on Capturing Discriminative Attributes (Krebs et al., 2018) is to detect semantic difference between pairs of concepts, or in other words, determine whether a semantic property differentiates between two possibly related concepts. For example both ‘bear’ a"
S18-1155,mendes-etal-2012-dbpedia,0,0.0548022,"Missing"
shaalan-etal-2012-arabic,J96-1003,0,\N,Missing
shaalan-etal-2012-arabic,C90-2036,0,\N,Missing
shaalan-etal-2012-arabic,P00-1037,0,\N,Missing
shaalan-etal-2012-arabic,W11-4417,1,\N,Missing
shaalan-etal-2012-arabic,I08-2131,0,\N,Missing
shaalan-etal-2012-arabic,W06-1648,0,\N,Missing
W07-0809,W04-1604,0,0.0265993,"and with each other, which makes them even harder to handle in any superficial way. A verb can comprise up four sub-tokens (a conjunction, a complementizer, a verb stem and an object pronoun) as illustrated by Figure 1. Similarly a noun can comprise up to four subtokens. Although Figure 2 shows five sub-tokens but we must note that the definite article and the genitive pronoun are mutually exclusive. Figure 2: Possible sub-tokens in Arabic nouns Moreover there are various rules that govern the combination of words with affixes and clitics. These rules are called grammar-lexis specifications (Abbès et al 2004; Dichy 2001; Dichy and Fargaly 2003). An example of these specifications is a rule that states that adjectives and proper nouns do not combine with possessive pronouns. 3 Development in Finite State Technology Finite state technology has successfully been used in developing morphologies and text processing tools for many natural languages, including Semitic languages. We will explain briefly how finite state technology works, then we will proceed into showing how different tokenization models are implemented. (1) LEXICON Proclitic al@U.Def.On@ LEXICON Root kitab LEXICON Suffix an LEXICON Encl"
W07-0809,N04-4038,0,0.0128613,"ted one after the other. Without sufficient morphological knowledge, it is impossible to detect and mark clitics. In this paper we will show different levels of implementation of the Arabic tokenizer, according to the levels of linguistic depth involved. Arabic Tokenization has been described in various researches and implemented in many solutions as it is a required preliminary stage for further processing. These solutions include morphological analysis (Beesley 2001; Buckwalter 2002), diacritization (Nelken and Shieber 2005), Information Retrieval (Larkey and Connell 2002), and POS Tagging (Diab et al 2004; Habash and Rambow 2005). None of these projects, however, show how multiword expressions are treated, or how ambiguity is filtered out. In our research, tokenization is handled in a rule-based system as an independent process. We show how the tokenizer interacts with other transducers, and how multiword expressions are identified and delimited. We also show how incorrect tokenizations are filtered out, and how undesired tokenizations are marked. All tools in this research are developed in Finite State Technology (Beesley and Karttunen 2003). These tools have been developed to serve an Arabic"
W07-0809,2003.mtsummit-semit.5,0,0.113139,"Missing"
W07-0809,P05-1071,0,0.106207,"other. Without sufficient morphological knowledge, it is impossible to detect and mark clitics. In this paper we will show different levels of implementation of the Arabic tokenizer, according to the levels of linguistic depth involved. Arabic Tokenization has been described in various researches and implemented in many solutions as it is a required preliminary stage for further processing. These solutions include morphological analysis (Beesley 2001; Buckwalter 2002), diacritization (Nelken and Shieber 2005), Information Retrieval (Larkey and Connell 2002), and POS Tagging (Diab et al 2004; Habash and Rambow 2005). None of these projects, however, show how multiword expressions are treated, or how ambiguity is filtered out. In our research, tokenization is handled in a rule-based system as an independent process. We show how the tokenizer interacts with other transducers, and how multiword expressions are identified and delimited. We also show how incorrect tokenizations are filtered out, and how undesired tokenizations are marked. All tools in this research are developed in Finite State Technology (Beesley and Karttunen 2003). These tools have been developed to serve an Arabic Lexical Functional Gramm"
W07-0809,W05-0711,0,0.0172823,"Missing"
W07-0809,W02-1503,0,\N,Missing
W07-0809,W04-0409,0,\N,Missing
W09-0806,Y04-1016,1,0.855487,"Missing"
W09-0806,P04-1041,1,0.939098,"Missing"
W09-0806,H94-1020,0,0.182035,"Missing"
W09-0806,P06-1130,1,0.923805,"Missing"
W09-0806,J08-1003,1,0.88981,"Missing"
W09-0806,P02-1035,0,0.0371649,"Missing"
W09-0806,schluter-van-genabith-2008-treebank,1,0.839624,"Missing"
W09-0806,N04-1013,0,\N,Missing
W09-0806,2006.bcs-1.10,0,\N,Missing
W09-0806,W04-1602,0,\N,Missing
W09-0806,P04-1047,1,\N,Missing
W10-1408,P05-1038,0,0.0366439,"the only edge which is added to the chart at this position is the one corresponding to the rule V BD → UNK-ed. For our English experiments we use the unknown word classes (or signatures) which are used in the Berkeley parser. A signature indicates whether a words contains a digit or a hyphen, if a word starts with a capital letter or ends with one of the following English suffixes (both derivational and inflectional): -s, -ed, -ing, -ion, -er, -est, -ly, -ity, -y and -al. For our French experiments we employ the same signature list as Crabb´e and Candito (2008), which itself was adapted from Arun and Keller (2005). This list consists of (a) conjugation suffixes of reguIn order to use morphological clues for Arabic we go further than just looking at suffixes. We exploit all the richness of the morphology of this language which can be expressed through morphotactics. these indicators are prefixes, suffixes and word templates. A template (Beesley and Karttunen, 2003) is a kind of vocalization mould in which a word fits. In derivational morphology Arabic words are formed through the amalgamation of two tiers, namely, root and template. A root is a sequence of three (rarely two or four) consonants which are"
W10-1408,W98-1007,0,0.0593928,"signature information for French and English is shown in Table 3. Beside each f-score the absolute improvement over the UNKNOWN baseline (Table 2) is given. For both languages there is an improvement at all unknown thresholds. The improvement for English is statistically significant at unknown thresholds 1 and 10.4 The improvement is more marked for French and is statistically significant at all levels. In the next section, we experiment with signature lists for Arabic.5 6 Arabic Signatures Handling Arabic Morphotactics Morphotactics refers to the way morphemes combine together to form words (Beesley, 1998; Beesley and Karttunen, 2003). Generally speaking, morphotactics can be concatenative, with morphemes either prefixed or suffixed to stems, or non-concatenative, with stems undergoing internal alternations to convey morphosyntactic information. Arabic is considered a typical example of a language that employs non-concatenative morphotactics. Arabic words are traditionally classified into three types: verbs, nouns and particles. Adjectives take almost all the morphological forms of, and share the same templatic structures with, nouns. Adjectives, for example, can be definite, and are inflected"
W10-1408,W09-3821,0,0.223368,"Missing"
W10-1408,W09-1008,0,0.0505203,"Missing"
W10-1408,A00-2018,0,0.244617,"61 94.90 92.99 91.56 Table 2: Varying the Unknown Threshold with the Simple Lexical Probability Model of the words in the Arabic and French development sets are unknown, and this is reflected in the drop in parsing performance at these thresholds. 5 Making use of Morphology Unknown words are not all the same. We exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the word’s morphological structure. Affixes have been shown to be useful in part-of-speech tagging (Schmid, 1994; Tseng et al., 2005) and have been used in the Charniak (Charniak, 2000), Stanford (Klein and Manning, 2003) and Berkeley (Petrov et al., 2006) parsers. In this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest. Returning to our toy English example in Figures 1 and 2, and given the input sentence The shares recovered, we would like to use the fact that the un70 known word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule V BD → UNKNOWN. If we specialise the UNKNOWN terminal using information from English morphology, we can do just that, resulting in the"
W10-1408,2008.jeptalnrecital-long.17,0,0.145906,"Missing"
W10-1408,E09-1038,0,0.160992,"Missing"
W10-1408,P08-2015,0,0.0114925,"Missing"
W10-1408,D09-1087,0,0.13706,"Missing"
W10-1408,J98-4004,0,0.381711,"hnique is extended to include morphological information and present parsing results for English and French. In Section 6, we describe the Arabic morphological system and explain how we used heuristic rules to cluster words into word-classes or signatures. We present parsing results for the version of the parser which uses this information. In Section 7, we describe our attempts to automatically determine the signatures for a language and present parsing results for the three languages. Finally, in Section 8, we discuss how this work might be fruitfully extended. 2 Latent Variable PCFG Parsing Johnson (1998) showed that refining treebank categories with parent information leads to more accurate grammars. This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (Klein and Manning, 2003). In PCFG-LAs, first introduced by Matsuzaki et al. (2005), the refined categories are learnt from the treebank using unsupervised techniques. Each base category – and this includes part-of-speech tags – is augmented with an annotation that refines its distributional properties. Following Petrov et al. (2006) latent annotations a"
W10-1408,W04-1602,0,0.0128084,"Missing"
W10-1408,H94-1020,0,0.166217,"Missing"
W10-1408,P05-1010,0,0.1217,"uses this information. In Section 7, we describe our attempts to automatically determine the signatures for a language and present parsing results for the three languages. Finally, in Section 8, we discuss how this work might be fruitfully extended. 2 Latent Variable PCFG Parsing Johnson (1998) showed that refining treebank categories with parent information leads to more accurate grammars. This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (Klein and Manning, 2003). In PCFG-LAs, first introduced by Matsuzaki et al. (2005), the refined categories are learnt from the treebank using unsupervised techniques. Each base category – and this includes part-of-speech tags – is augmented with an annotation that refines its distributional properties. Following Petrov et al. (2006) latent annotations and probabilities for the associated rules are learnt incrementally following an iterative process consisting of the repetition of three steps. 1. Split each annotation of each symbol into n (usually 2) new annotations and create rules with the new annotated symbols. Estimate1 the probabilities of the newly created rules. 2. E"
W10-1408,W05-0711,0,0.0499235,"Missing"
W10-1408,N07-1051,0,0.0697355,"each symbol into n (usually 2) new annotations and create rules with the new annotated symbols. Estimate1 the probabilities of the newly created rules. 2. Evaluate the impact of the newly created annotations and discard the least useful ones. Reestimate probabilities with the new set of annotations. 3. Smooth the probabilities to prevent overfitting. We use our own parser which trains a PCFG-LA using the above procedure and parses using the max1 Estimation of the parameters is performed by running Expectation/Maximisation on the training corpus. 68 rule parsing algorithm (Petrov et al., 2006; Petrov and Klein, 2007). PCFG-LA parsing is relatively language-independent but has been shown to be very effective on several languages (Petrov, 2009). For our experiments, we set the number of iterations to be 5 and we test on sentences less than or equal to 40 words in length. All our experiments, apart from the final one, are carried out on the development sets of our three languages. 3 The Datasets Arabic We use the the Penn Arabic Treebank (ATB) (Bies and Maamouri, 2003; Maamouri and Bies., 2004). The ATB describes written Modern Standard Arabic newswire and follows the style and guidelines of the English Penn"
W10-1408,P06-1055,0,0.487124,"tent Variable PCFG Parsing Johnson (1998) showed that refining treebank categories with parent information leads to more accurate grammars. This was followed by a collection of linguistically motivated propositions for manual or semi-automatic modifications of categories in treebanks (Klein and Manning, 2003). In PCFG-LAs, first introduced by Matsuzaki et al. (2005), the refined categories are learnt from the treebank using unsupervised techniques. Each base category – and this includes part-of-speech tags – is augmented with an annotation that refines its distributional properties. Following Petrov et al. (2006) latent annotations and probabilities for the associated rules are learnt incrementally following an iterative process consisting of the repetition of three steps. 1. Split each annotation of each symbol into n (usually 2) new annotations and create rules with the new annotated symbols. Estimate1 the probabilities of the newly created rules. 2. Evaluate the impact of the newly created annotations and discard the least useful ones. Reestimate probabilities with the new set of annotations. 3. Smooth the probabilities to prevent overfitting. We use our own parser which trains a PCFG-LA using the"
W10-1408,I05-3005,0,0.0234663,"URE UNTagging Accuracy 94.03 91.16 89.06 95.60 94.66 93.61 94.90 92.99 91.56 Table 2: Varying the Unknown Threshold with the Simple Lexical Probability Model of the words in the Arabic and French development sets are unknown, and this is reflected in the drop in parsing performance at these thresholds. 5 Making use of Morphology Unknown words are not all the same. We exploit this fact by examining the effect on parsing accuracy of clustering rare training set words using cues from the word’s morphological structure. Affixes have been shown to be useful in part-of-speech tagging (Schmid, 1994; Tseng et al., 2005) and have been used in the Charniak (Charniak, 2000), Stanford (Klein and Manning, 2003) and Berkeley (Petrov et al., 2006) parsers. In this section, we contrast the effect on parsing accuracy of making use of such information for our three languages of interest. Returning to our toy English example in Figures 1 and 2, and given the input sentence The shares recovered, we would like to use the fact that the un70 known word recovered ends with the past tense suffix -ed to boost the probability of the lexical rule V BD → UNKNOWN. If we specialise the UNKNOWN terminal using information from Engli"
W10-1408,P03-1054,0,\N,Missing
W10-3704,attia-etal-2010-automatically,1,0.604545,"Missing"
W10-3704,deksne-etal-2008-dictionary,0,0.29076,"een applied to bigrams and trigrams, and it becomes more problematic to extract MWEs of more than three words. As a consequence, each approach requires specific resources and is suitable for dealing with only one side of a multifaceted problem. Pecina (2010) evaluates 82 lexical association measures for the ranking of collocation candidates and concludes that it is not possible to select a single best universal measure, and that different measures give different results for different tasks depending on data, language, and the types of MWE that the task is focused on. Similarly, Ramisch et al. (2008) investigate the hypothesis that MWEs can be detected solely by looking at the distinct statistical properties of their individual words and conclude that the association measures can only detect trends and preferences in the co-occurrences of words. A lot of effort has concentrated on the task of 2 Data Resources In this project we use three data resources for extracting MWEs. These resources differ widely in nature, size, structure and the main purpose they are used for. In this section we give a brief introduction to each of these data resources. Wikipedia (WK) is a freely-available multili"
W10-3704,elkateb-etal-2006-building,0,0.0380663,"Missing"
W10-3704,W09-2905,0,0.0428556,"Missing"
W10-3704,W04-0411,0,0.0213009,"ne Translation (Deksne, 2008). There are two basic criteria for identifying MWEs: first, component words exhibit statistically significant co-occurrence, and second, they show a certain level of semantic opaqueness or non-compositionality. Statistically significant cooccurrence can give a good indication of how likely a sequence of words is to form an MWE. This is particularly interesting for statistical techniques which utilize the fact that a large number of MWEs are composed of words that co-occur together more often than can be expected by chance. The compositionality, or decomposability (Villavicencio et al. 2004), of MWEs is also a core issue that presents a challenge for NLP applications because the meaning of the expression is not directly predicted from the meaning of the component words. In this respect, compositionalily varies between phrases that are highly comIntroduction A lexicon of multiword expressions (MWEs) has a significant importance as a linguistic resource because MWEs cannot usually be analyzed literally, or word-for-word. In this paper we apply three approaches to the extraction of Arabic MWEs from multilingual, bilingual, and monolingual data sources. We rely on linguistic informat"
W10-3704,W97-0311,0,0.144125,"two well-known among them are “non-substitutability”, when a word in the expression cannot be substituted by a semantically equivalent word, and “single-word paraphrasability”, when the expression can be paraphrased or translated by a single word. These two indications have been exploited differently by different researchers. Van de Cruys and Moiro´ n (2006) develop an unsupervised method for detecting MWEs using clusters of semantically related words and taking the ratio of the word preference over the cluster preference as an indication of how likely a particular expression is to be an MWE. Melamed (1997) investigates techniques for identifying non-compositional compounds in English-French parallel corpora and emphasises that translation models that take noncompositional compounds into account are more accurate. Moir´on and Tiedemann (2006) use word alignment of parallel corpora to locate the translation of an MWE in a target language and decide whether the original expression is idiomatic or literal. The technique used here is inspired by that of Zarrieß and Kuhn (2009) who rely on the linguistic intuition that if a group of words in one language is translated as a single word in another lang"
W10-3704,vintar-fiser-2008-harvesting,0,0.0593775,"Missing"
W10-3704,W06-2405,0,0.0453337,"expression as a whole is utterly  unrelated to the component words, such as,         !  farasu ’l-nabiyyi, “grasshopper”, lit. “the horse of the Prophet”. automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Arabic MWEs. Boulaknadel et al. (2009) develop a hybrid multiword term extraction tool for Arabic in the “environment” domain. Attia (2006) reports on the semi-automatic extraction of various types of MWEs in Arabic and how they are used in an LFG-based parser. In this paper we report on three different methods for the extraction of MWEs for Arabic, a less resourced language. Our approach is linguistically motivated and can be applied to other languages. 1.2 Related Work A considerable amount of research has focused on the identification and extraction of MWEs. Given the heterogeneity of MWEs, different approaches were devised. Broadly speaking, work on the extraction of MWEs revolves around four approaches: (a) statistical metho"
W10-3704,W09-2904,0,0.321046,"ase”, and those  that show a degree of idiomaticity, such as,          madiynatu ’l-mal¯ ahiy, “amusement park”, lit. “city of amusements”. In extreme cases the meaning of the expression as a whole is utterly  unrelated to the component words, such as,         !  farasu ’l-nabiyyi, “grasshopper”, lit. “the horse of the Prophet”. automatically extracting MWEs for various languages besides English, including Slovene (Vintar and Fiˇser, 2008), Chinese (Duan et al., 2009), Czech (Pecina, 2010), Dutch (Van de Cruys and Moir´on, 2006), Latvian (Deksne, 2008) and German ( Zarrieß and Kuhn, 2009). A few papers, however, focus on Arabic MWEs. Boulaknadel et al. (2009) develop a hybrid multiword term extraction tool for Arabic in the “environment” domain. Attia (2006) reports on the semi-automatic extraction of various types of MWEs in Arabic and how they are used in an LFG-based parser. In this paper we report on three different methods for the extraction of MWEs for Arabic, a less resourced language. Our approach is linguistically motivated and can be applied to other languages. 1.2 Related Work A considerable amount of research has focused on the identification and extraction of MWEs"
W10-3704,W03-1812,0,\N,Missing
W10-3704,boulaknadel-etal-2008-multi,0,\N,Missing
W11-4417,2006.bcs-1.5,1,0.693113,"ttested in contemporary use. The database is built using a corpus of 1,089,111,204 words, a pre-annotation tool, machine learning techniques, and knowledgebased pattern matching to automatically acquire lexical knowledge. Our morphological transducer is evaluated and compared to LDC’s SAMA (Standard Arabic Morphological Analyser). 1 Introduction Due to its complexity, Arabic morphology has always been a challenge for computational processing and a hard testing ground for morphological analysis technologies. A lexicon is a core component of any morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001). The quality and coverage of the lexical database determines the quality and coverage of the morphological analyser, and limitations in the lexicon will cascade through to higher levels of processing. In this paper, we present an approach to automatically construct a corpus-based lexical database for Modern Standard Arabic (MSA), focusing on the 1 http://sourceforge.net/projects/aracomlex/ 125 This paper is structured as follows. In the introduction, we differentiate between MSA, the focus of this research, and Classical Arabic (CA) which is a historical vers"
W11-4417,2003.mtsummit-semit.5,0,0.72348,"exical entries no longer attested in contemporary use. The database is built using a corpus of 1,089,111,204 words, a pre-annotation tool, machine learning techniques, and knowledgebased pattern matching to automatically acquire lexical knowledge. Our morphological transducer is evaluated and compared to LDC’s SAMA (Standard Arabic Morphological Analyser). 1 Introduction Due to its complexity, Arabic morphology has always been a challenge for computational processing and a hard testing ground for morphological analysis technologies. A lexicon is a core component of any morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001). The quality and coverage of the lexical database determines the quality and coverage of the morphological analyser, and limitations in the lexicon will cascade through to higher levels of processing. In this paper, we present an approach to automatically construct a corpus-based lexical database for Modern Standard Arabic (MSA), focusing on the 1 http://sourceforge.net/projects/aracomlex/ 125 This paper is structured as follows. In the introduction, we differentiate between MSA, the focus of this research, and Classical Arabic (CA) which is a hi"
W11-4417,E09-2008,0,0.126089,"technology that makes it especially attractive in dealing with human language morphologies; among these are the ability to handle concatenative and nonconcatenative morphotactics, and the high speed and efficiency in handling large automata of lexicons with their derivations and inflections that can run into millions of paths. The Xerox XFST System (Beesley and Karttunen, 2003) is a well-known finite state compiler, but the disadvantage of this tool is that it is a proprietary software, which limits its use in the larger research community. Fortunately, there is an alternative, namely Foma, (Hulden, 2009), which is an opensource finite-state toolkit that implements the Xerox lexc and xfst utilities. We have developed an opensource morphological analyser for Arabic using the Foma compiler allowing us to share our morphology with third parties. The lexical database, which is being edited and validated, is used to automatically extend and update the morphological analyser, allowing for greater coverage and better capabilities. Arabic words are formed through the amalgamation of two tiers, namely root and pattern. A root is a sequence of three consonants and the pattern is a template of vowels (or"
W11-4417,P08-2030,0,0.204709,"Missing"
W12-6203,P08-1083,0,0.0595532,"Missing"
W12-6203,2006.bcs-1.5,1,0.769027,"n 2 presents the methodology followed in extracting and analysing unknown words. Section 3 provides details on the morphological guesser we have developed to help deal with the problem. Section 4 shows and discusses the testing and evaluation results, and finally Section 5 gives the conclusion. Introduction 1.1 Due to the complex and semi-algorithmic nature of the Arabic morphology, it has always been a challenge for computational processing and analysis (Kiraz, 2001; Beesley 2003; Shaalan et al., 2012). A lexicon is an indispensable part of a morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001), and the coverage of the lexical database is a key factor in the coverage of the morphological analyser. This is why an automatic method for updating a lexical database is crucially important. Previous Work Lemmatization of Arabic words has been addressed in (Roth et al., 2008; Dichy, 2001). Lemmatization of unknown words has been addressed for Slovene in (Erjavec and Džerosk, 2004), for Hebrew in (Adler at al., 2008) and for English, Finnish, Swedish and Swahili in (Lindén, 2008). Lemmatization means the normalization of text data by reducing surface forms t"
W12-6203,W11-4417,1,0.800348,"Missing"
W12-6203,2003.mtsummit-semit.5,0,0.0718035,"in our experiments. Section 2 presents the methodology followed in extracting and analysing unknown words. Section 3 provides details on the morphological guesser we have developed to help deal with the problem. Section 4 shows and discusses the testing and evaluation results, and finally Section 5 gives the conclusion. Introduction 1.1 Due to the complex and semi-algorithmic nature of the Arabic morphology, it has always been a challenge for computational processing and analysis (Kiraz, 2001; Beesley 2003; Shaalan et al., 2012). A lexicon is an indispensable part of a morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001), and the coverage of the lexical database is a key factor in the coverage of the morphological analyser. This is why an automatic method for updating a lexical database is crucially important. Previous Work Lemmatization of Arabic words has been addressed in (Roth et al., 2008; Dichy, 2001). Lemmatization of unknown words has been addressed for Slovene in (Erjavec and Džerosk, 2004), for Hebrew in (Adler at al., 2008) and for English, Finnish, Swedish and Swahili in (Lindén, 2008). Lemmatization means the normalization of text data by reducing su"
W12-6203,P08-2030,0,0.0149749,"on 1.1 Due to the complex and semi-algorithmic nature of the Arabic morphology, it has always been a challenge for computational processing and analysis (Kiraz, 2001; Beesley 2003; Shaalan et al., 2012). A lexicon is an indispensable part of a morphological analyser (Dichy and Farghaly, 2003; Attia, 2006; Buckwalter, 2004; Beesley, 2001), and the coverage of the lexical database is a key factor in the coverage of the morphological analyser. This is why an automatic method for updating a lexical database is crucially important. Previous Work Lemmatization of Arabic words has been addressed in (Roth et al., 2008; Dichy, 2001). Lemmatization of unknown words has been addressed for Slovene in (Erjavec and Džerosk, 2004), for Hebrew in (Adler at al., 2008) and for English, Finnish, Swedish and Swahili in (Lindén, 2008). Lemmatization means the normalization of text data by reducing surface forms to their canonical underlying representations, which, in Arabic, means verbs in their perfective, indicative, 3rd person, masculine, singular forms, such as َﺷ َﻜ َﺮ 20 Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 20–24, c Donostia–San Sebasti´an"
W14-3606,W10-3700,0,0.171412,"Missing"
W14-3606,W11-3806,0,0.0377276,"Missing"
W14-3606,I13-1168,1,0.759475,"Missing"
W14-3606,calzolari-etal-2002-towards,0,0.243725,"ed data, construction of lexicons for specific languages, integration in NLP applications, and the construction of guidelines and best practices. A significant amount of research has focused on the identification and extraction of MWEs (Ramisch et al., 2010; Dubremetz and Nivre, 2014; Attia et al., 2010; Weller and Heid, 2010; Schneider et al., 2014). Description and specifications of MWE lexical resources have been presented for Japanese (Shudo et al. 2011), Italian (Zaninello and Nissim, 2010), Dutch (Grégoire, 2010; Odijk, 2013), and Modern Standard Arabic (Hawwari et al., 2012). Moreover, Calzolari et al. (2002) presented a project that attempted to introduce best practice recommendations for the treatment of MWE in mono- and multi-lingual computational lexicons that incorporate both syntactic and semantic information, but the limitation of their work is that they focus on only two types of MWEs, namely, support verbs and noun compounds. Apart from Schneider et al. (2014), who focused on the language of the social web, none of these projects dealt with informal or dialectal languages, which are rampant in user-generated content (UGC). With the explosion of social media, the language of Web 2.0 is und"
W14-3606,C86-1001,0,0.78221,"Missing"
W14-3606,habash-etal-2012-conventional,1,0.821172,"searchers proposed different typology for this phenomena. Fillmore et al. (1988) proposed three types based on lexical and syntactic familiarity: a) unfamiliar pieces familiarly combined, b) familiar pieces unfamiliarly combined, and c) familiar pieces familiarly combined. Mel&apos;čuk (1989), on the other hand, introduced three different classes: a) complete phraseme, b) semiphraseme, c) and quasi-phraseme. Sag et al. introduced two classes: institutionalized phrases and lexicalized phrases, with lexicalized phrases subdivided into fixed, semi-fixed and syntactically flexible expressions. Ramisch (2012) introduced yet another set of classes: nominal, verbal and adverbial expressions. 4 Annotation of Linguistic Features in MWE In this section, we provide a comprehensive specification of MWE types and the detailed linguistic information, including the phonological, orthographical, syntactic, semantic and pragmatic features. 4.1 From the lexicographic point of view, the legacy three-way division of MWEs proved to be too coarse-grained to cater for the needs of lexicographers who need to identify the large array of sub-types that fall under the umbrella of ‘MWEs’. Atkins and Rundell (2008) empha"
W14-3606,W12-3403,1,0.771196,"searchers proposed different typology for this phenomena. Fillmore et al. (1988) proposed three types based on lexical and syntactic familiarity: a) unfamiliar pieces familiarly combined, b) familiar pieces unfamiliarly combined, and c) familiar pieces familiarly combined. Mel&apos;čuk (1989), on the other hand, introduced three different classes: a) complete phraseme, b) semiphraseme, c) and quasi-phraseme. Sag et al. introduced two classes: institutionalized phrases and lexicalized phrases, with lexicalized phrases subdivided into fixed, semi-fixed and syntactically flexible expressions. Ramisch (2012) introduced yet another set of classes: nominal, verbal and adverbial expressions. 4 Annotation of Linguistic Features in MWE In this section, we provide a comprehensive specification of MWE types and the detailed linguistic information, including the phonological, orthographical, syntactic, semantic and pragmatic features. 4.1 From the lexicographic point of view, the legacy three-way division of MWEs proved to be too coarse-grained to cater for the needs of lexicographers who need to identify the large array of sub-types that fall under the umbrella of ‘MWEs’. Atkins and Rundell (2008) empha"
W14-3606,deksne-etal-2008-dictionary,0,0.0577743,"Missing"
W14-3606,N10-1089,0,0.0248821,"Missing"
W14-3606,zaninello-nissim-2010-creation,0,0.170937,"a paraphrase otherwise. Previous Work There are four main areas of research on MWEs: extraction from structured and unstructured data, construction of lexicons for specific languages, integration in NLP applications, and the construction of guidelines and best practices. A significant amount of research has focused on the identification and extraction of MWEs (Ramisch et al., 2010; Dubremetz and Nivre, 2014; Attia et al., 2010; Weller and Heid, 2010; Schneider et al., 2014). Description and specifications of MWE lexical resources have been presented for Japanese (Shudo et al. 2011), Italian (Zaninello and Nissim, 2010), Dutch (Grégoire, 2010; Odijk, 2013), and Modern Standard Arabic (Hawwari et al., 2012). Moreover, Calzolari et al. (2002) presented a project that attempted to introduce best practice recommendations for the treatment of MWE in mono- and multi-lingual computational lexicons that incorporate both syntactic and semantic information, but the limitation of their work is that they focus on only two types of MWEs, namely, support verbs and noun compounds. Apart from Schneider et al. (2014), who focused on the language of the social web, none of these projects dealt with informal or dialectal langu"
W14-3606,ramisch-etal-2010-mwetoolkit,0,0.0572166,"Missing"
W14-3606,schneider-etal-2014-comprehensive,0,0.0231046,"MWEs where applicable; i) 2 Translation, which includes the MSA and English equivalents, either as an MWE in MSA and English if available or as a paraphrase otherwise. Previous Work There are four main areas of research on MWEs: extraction from structured and unstructured data, construction of lexicons for specific languages, integration in NLP applications, and the construction of guidelines and best practices. A significant amount of research has focused on the identification and extraction of MWEs (Ramisch et al., 2010; Dubremetz and Nivre, 2014; Attia et al., 2010; Weller and Heid, 2010; Schneider et al., 2014). Description and specifications of MWE lexical resources have been presented for Japanese (Shudo et al. 2011), Italian (Zaninello and Nissim, 2010), Dutch (Grégoire, 2010; Odijk, 2013), and Modern Standard Arabic (Hawwari et al., 2012). Moreover, Calzolari et al. (2002) presented a project that attempted to introduce best practice recommendations for the treatment of MWE in mono- and multi-lingual computational lexicons that incorporate both syntactic and semantic information, but the limitation of their work is that they focus on only two types of MWEs, namely, support verbs and noun compoun"
W14-3606,P11-1017,0,0.017754,"nd English if available or as a paraphrase otherwise. Previous Work There are four main areas of research on MWEs: extraction from structured and unstructured data, construction of lexicons for specific languages, integration in NLP applications, and the construction of guidelines and best practices. A significant amount of research has focused on the identification and extraction of MWEs (Ramisch et al., 2010; Dubremetz and Nivre, 2014; Attia et al., 2010; Weller and Heid, 2010; Schneider et al., 2014). Description and specifications of MWE lexical resources have been presented for Japanese (Shudo et al. 2011), Italian (Zaninello and Nissim, 2010), Dutch (Grégoire, 2010; Odijk, 2013), and Modern Standard Arabic (Hawwari et al., 2012). Moreover, Calzolari et al. (2002) presented a project that attempted to introduce best practice recommendations for the treatment of MWE in mono- and multi-lingual computational lexicons that incorporate both syntactic and semantic information, but the limitation of their work is that they focus on only two types of MWEs, namely, support verbs and noun compounds. Apart from Schneider et al. (2014), who focused on the language of the social web, none of these projects"
W14-3606,weller-heid-2010-extraction,0,\N,Missing
W14-3606,W14-0812,0,\N,Missing
W14-3606,W10-3704,1,\N,Missing
W14-3606,N10-1029,1,\N,Missing
W14-3606,J05-1004,0,\N,Missing
W14-3606,W11-0815,0,\N,Missing
W14-3620,W11-4417,1,0.897784,"Missing"
W14-3620,C12-2011,1,0.889852,"Missing"
W14-3620,W98-1007,0,0.126018,"d correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 Arabic Morphology, Orthography and Punctuation Arabic has a rich and complex morphology as it applies both concatenative and nonconcatenative morphotactics (Ratcliffe, 1998; Beesley, 1998; Habash, 2010), yielding a wealth of morphemes that express various morpho148 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 148–154, c October 25, 2014, Doha, Qatar. 2014 Association for Computational Linguistics syntactic features, such as tense, person, number, gender, voice and mood. Arabic has a large array of orthographic variations, leading to what is called ‘typographic errors’ or ‘orthographic variations’ (Buckwalter, 2004a), and sometimes referred to as substandard spellings, or spelling soft errors. These errors are basically related to t"
W14-3620,P00-1037,0,0.189707,"phasis. HASP in its current stage only handles types (a), (b), and (e) errors. We assume that the various error types are too distinct to be treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well."
W14-3620,J92-4003,0,0.249131,"Missing"
W14-3620,W04-1606,0,0.0949575,"Missing"
W14-3620,N12-1067,0,0.0869502,"Missing"
W14-3620,C10-1041,0,0.0666082,"Missing"
W14-3620,P11-1038,0,0.0356615,"treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, wh"
W14-3620,E09-2008,0,0.0856422,"c reported in the literature to date. We enhance the AraComLex Extended dictionary by utilizing the annotated data in the shared task’s training data. We add 776 new valid words to the dictionary and remove 4,810 misspelt words, leading to significant improvement in the dictionary’s ability to make decisions on words. Table 6 shows the dictionary’s performance on the training and development set in the shared task as applied only to non-words and excluding grammatical, semantic and punctuation errors. P F Training 98.84 96.34 97.57 b. Candidate Generation For candidate generation we use Foma (Hulden, 2009), a finite state compiler that is capable of producing candidates from a wordlist (compiled as an FST network) within a certain edit distance from an error word. Foma allows the ranking of candidates according to customizable transformation rules. # 1. 2. 3. 4. 5. 6. 7. This is more akin to the typical spelling correction problem where a word has the wrong letters, rendering it a non-word. We address this problem using two approaches: Dictionary-LM Correction, and Alignment Based Correction. Spelling error detection and correction mainly consists of three phases: a) error detection; b) candida"
W14-3620,P03-1004,0,0.0221444,"k (PATB) tokenization (e.g., ﻝل+  ﺍاﻟﺘﺸﺎﻭوﺭرl+Alt$Awr); (3) Kulick POS tag (e.g., IN+DT+NN). (4) Buckwalter POS tag (e.g., PREP+DET+ NOUN+CASE_DEF_GN) as produced by MADAMIRA; (5) Classes to be predicted: colon_after, comma_after, exclmark_after, period_after, qmark_after, semicolon_after and NA (when no punctuation marks are used); Window Recall Precision F-measure Size 4 36.24 54.09 43.40 5 37.95 59.61 46.37 6 36.65 59.99 45.50 7 34.50 59.53 43.68 Table 3. Yamcha results on the development set For classification, we experiment with Support Vector Machines (SVM) as implemented in Yamcha (Kudo and Matsumoto, 2003) and Conditional Random Field (CRF++) classifiers (Lafferty et al. 2001). In our investigation, we vary the context window size from 4 to 8 and we use all 5 features listed for every word in the window. As Tables 3 and 4 show, we found that window size 5 gives the best f-score by both Yamcha and CRF. When we strip clitics from tokenized tag, reducing it to stems only, the performance of the system improved. Overall CRF yields significantly higher results using the same experimental setup. We assume that the performance advantage of CRF is a result of the way words in the context and their feat"
W14-3620,W06-1648,0,0.0727139,"Missing"
W14-3620,J03-1002,0,0.00635933,"tained by System 1, which is ranked 5th among the 9 systems participating in the shared task. # Experiment R P F 1 System 1 52.98 75.47 62.25 2 System 2 52.99 75.34 62.22 Table 9. Final official results on the test set provided by the Shared Task 2.3.3.2. Alignment-Based Correction We formatted the data for alignment using a window of 4 words: one word to each side (forming the contextual boundary) and two words in the middle. The two words in the middle are split into characters so that character transformations can be observed and learned by the aligner. The alignment tool we use is Giza++ (Och and Ney, 2003). Results are reported in Table 10. # Experiment R P F 1 for all error types 36.05 45.13 37.99 2 excluding punc 32.37 54.65 40.66 3 2 + CRF_punc+norm 46.11 62.02 52.90 Table 10. Results of character-based alignment # Experiment R P F 1 LM+split-1 33.32 73.71 45.89 2 +CRF_punc+split-1 49.74 65.38 56.50 3 + norm+split-1 +CRF_punc+norm +split-1 +CRF_punc+norm +orig_punc+split-1 +CRF_punc+norm +orig_punc+split-2 38.81 69.08 49.70 Although these preliminary results from Alignment are significantly below results yielded from the Dictionary-LM approach, we believe that there are several potential imp"
W14-3620,pasha-etal-2014-madamira,1,0.881036,"Missing"
W14-3620,P08-2030,1,0.874397,"Missing"
W14-3620,O13-5002,0,\N,Missing
W14-3620,shaalan-etal-2012-arabic,1,\N,Missing
W14-3620,W14-3605,0,\N,Missing
W14-3620,zaghouani-etal-2014-large,0,\N,Missing
W14-3620,I08-2131,0,\N,Missing
W14-3620,W13-3601,0,\N,Missing
W15-3216,W14-3620,1,0.803001,"Missing"
W15-3216,C12-2011,1,0.927158,"Missing"
W15-3216,P00-1037,0,0.304702,"Missing"
W15-3216,N12-1067,0,0.038977,". Our tri-gram language model is trained on the Arabic Gigaword Corpus, 5th edition (Parker et al., 2011) and a corpus crawled from Al-Jazeera (Attia et al.; 2012). For the LM disambiguation we use the ‘-fb’ option (forward-backward tracking), and we provide candidates with probability scores collected from the QALB training data. Both of the forward-backward tracking and the probability scores in tandem yield better results than the default values. We evaluate the performance of our system against the gold standard using the MaxMatch (M2) method for evaluating grammatical error correction by Dahlmeier and Ng (2012). Our best f-score is obtained by priming candidates from the training data, adding Al-Jazeera corpus to Gigaword 5, and using the two-pass CRF punctuation prediction. Table 3 and 4 show the results on Alj and L2 development sets respectively. Table 5 shows the results on Alj and L2 test sets. Alhm#20; Allhm#17 ElY#818; Ely#318 # Experiment R P F 1 Baseline (HASP’14) Prime non-word candidates from the training set Include real-word candidates from the training data Prime merge errors from the training set Post-processing Two-pass punctuation correction 3 gram LM and adding Al-Jazeera corpus to"
W15-3216,I08-2131,0,0.199114,"rns punctuation placement, and then it learns to identify punctuation types. 1 Introduction In this paper1 we describe our system for Arabic spelling error detection and correction, HASP2015 (Hybrid Arabic Spelling and Punctuation Corrector). We introduce significant improvements to our previous version HASP2014 (Attia et al., 2014). We participate with HASP-2015 in the QALB-2015 Second Shared Task on Arabic Error Correction (Rozovskaya et al., 2015). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Attia et al., 2012; Alkanhal et al., 2012). Significant contributions were also introduced in the 2014 Shared Task on Arabic Error Correction (Mohit et al., 2014) including (Rozovskaya et al., 2014; Nawar and Ragheb, 2014; Jeblee et al., 2014; and Mubarak and Darwish, 2014). The QALB-‐2015 shared task is an extension of the first QALB shared task (Mohit et al., 2014) that took place in 2014. QALB-‐2014 addressed errors in comments written to Aljazeera articles by native Arabic speakers (Zaghouani et al., 2014). This year&apos;s competition includes two tracks, and, in addition to errors produce"
W15-3216,E09-2008,0,0.0132126,"tionary. 140 4.2 Candidate Generation Correcting spelling errors is ideally treated as a probabilistic problem formulated as (Kernigan, 1990; Norvig, 2009; Brill, and Moore, 2000): ??????! ?(? |?) ?(?) Here ?(?) is the probability that ? is the correct word (or the language model), and ?(? |?) is the probability that ? is typed when ? is intended (the error model or noisy channel model), ??????! is the scoring mechanism that computes the correction c that maximizes the probability. In HASP-2014, we ranked candidates according to their edit distance score using the finite state compiler, foma (Hulden, 2009), but in HASP-2015, we rank candidates according to their probability, (? |?) , as derived from the training data, and we pass candidates along with their probability scores to the language model. Again, the edit distance candidates and their ranking are used when no probability information is available from the training data. The following are some illustrative examples of the statistical information extracted from the training data for the various error types. Non-word errors: An “ ﺍاﻥنthat” &gt;n#7781; <n#1485; |n#29 AlA “ ﺍاﻻbut” <lA#1442; &gt;lA#225 Semantic errors: Alhm “ ﺍاﻟﻬﮭﻢworry” El"
W15-3216,C90-2036,0,0.765073,"Missing"
W15-3216,W14-3617,0,0.0123264,"mprovements to our previous version HASP2014 (Attia et al., 2014). We participate with HASP-2015 in the QALB-2015 Second Shared Task on Arabic Error Correction (Rozovskaya et al., 2015). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Attia et al., 2012; Alkanhal et al., 2012). Significant contributions were also introduced in the 2014 Shared Task on Arabic Error Correction (Mohit et al., 2014) including (Rozovskaya et al., 2014; Nawar and Ragheb, 2014; Jeblee et al., 2014; and Mubarak and Darwish, 2014). The QALB-‐2015 shared task is an extension of the first QALB shared task (Mohit et al., 2014) that took place in 2014. QALB-‐2014 addressed errors in comments written to Aljazeera articles by native Arabic speakers (Zaghouani et al., 2014). This year&apos;s competition includes two tracks, and, in addition to errors produced by native speakers, also includes correction of texts written by learners of Arabic as a foreign language (L2) (Zaghouani et al., 2015). The native track includes Alj-‐train-‐2014, Alj-‐dev-‐2014, Alj-‐ test-‐2014 texts from QALB-‐2014. The L2 track includes L2-‐tra"
W15-3216,W14-3619,0,0.0142221,"unctuation Corrector). We introduce significant improvements to our previous version HASP2014 (Attia et al., 2014). We participate with HASP-2015 in the QALB-2015 Second Shared Task on Arabic Error Correction (Rozovskaya et al., 2015). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Attia et al., 2012; Alkanhal et al., 2012). Significant contributions were also introduced in the 2014 Shared Task on Arabic Error Correction (Mohit et al., 2014) including (Rozovskaya et al., 2014; Nawar and Ragheb, 2014; Jeblee et al., 2014; and Mubarak and Darwish, 2014). The QALB-‐2015 shared task is an extension of the first QALB shared task (Mohit et al., 2014) that took place in 2014. QALB-‐2014 addressed errors in comments written to Aljazeera articles by native Arabic speakers (Zaghouani et al., 2014). This year&apos;s competition includes two tracks, and, in addition to errors produced by native speakers, also includes correction of texts written by learners of Arabic as a foreign language (L2) (Zaghouani et al., 2015). The native track includes Alj-‐train-‐2014, Alj-‐dev-‐2014, Alj-‐ test-‐2014 t"
W15-3216,pasha-etal-2014-madamira,1,0.836583,"Missing"
W15-3216,W14-3622,0,0.0116626,"rid Arabic Spelling and Punctuation Corrector). We introduce significant improvements to our previous version HASP2014 (Attia et al., 2014). We participate with HASP-2015 in the QALB-2015 Second Shared Task on Arabic Error Correction (Rozovskaya et al., 2015). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Attia et al., 2012; Alkanhal et al., 2012). Significant contributions were also introduced in the 2014 Shared Task on Arabic Error Correction (Mohit et al., 2014) including (Rozovskaya et al., 2014; Nawar and Ragheb, 2014; Jeblee et al., 2014; and Mubarak and Darwish, 2014). The QALB-‐2015 shared task is an extension of the first QALB shared task (Mohit et al., 2014) that took place in 2014. QALB-‐2014 addressed errors in comments written to Aljazeera articles by native Arabic speakers (Zaghouani et al., 2014). This year&apos;s competition includes two tracks, and, in addition to errors produced by native speakers, also includes correction of texts written by learners of Arabic as a foreign language (L2) (Zaghouani et al., 2015). The native track includes Alj-‐train-‐2014, Alj-‐dev-‐20"
W15-3216,W15-1614,0,0.233893,"sk on Arabic Error Correction (Mohit et al., 2014) including (Rozovskaya et al., 2014; Nawar and Ragheb, 2014; Jeblee et al., 2014; and Mubarak and Darwish, 2014). The QALB-‐2015 shared task is an extension of the first QALB shared task (Mohit et al., 2014) that took place in 2014. QALB-‐2014 addressed errors in comments written to Aljazeera articles by native Arabic speakers (Zaghouani et al., 2014). This year&apos;s competition includes two tracks, and, in addition to errors produced by native speakers, also includes correction of texts written by learners of Arabic as a foreign language (L2) (Zaghouani et al., 2015). The native track includes Alj-‐train-‐2014, Alj-‐dev-‐2014, Alj-‐ test-‐2014 texts from QALB-‐2014. The L2 track includes L2-‐train-‐2015 and L2-‐dev-‐2015. This data was released for the development of the systems. The systems are scored on blind test sets Alj-‐test-‐2015 and L2-‐test-‐2015. Our system is ranked third and fourth on the Alj and L2, respectively. The shared task data deals with “errors” in the general sense which comprise: a) punctuation errors; b) non-word errors; c) real-word spelling errors; d) grammatical errors (related to case, number and gender); and, e)"
W15-3216,J03-1002,0,0.00924074,"Missing"
W15-3216,W14-3605,0,\N,Missing
W15-3216,zaghouani-etal-2014-large,0,\N,Missing
W15-3216,W13-3601,0,\N,Missing
W16-5306,R13-1001,1,0.898062,"Missing"
W16-5306,W07-0812,1,0.84659,"Missing"
W16-5306,A00-2013,0,0.253792,"Missing"
W16-5306,W02-0509,0,0.259406,"nt clustering (Korenius et al., 2004), keyphrase extraction (El-Shishtawy and Al-Sammak, 2012), and text indexing and classification (Hammouda and Almarimi, 2010). From a lexical point of view, normalization can be conducted at the level of the root, stem or lemma. Lemmatization relates surface forms to their canonical base representations (or dictionary lookup form) (Attia and van Genabith, 2013). It is the inverse of inflection (Plisson et al., 2004), as it renders words to a default and uninflected form, or as is the case with Arabic, a least marked form. A lemma is the common denominator (Kamir et al., 2002) of a set of forms that share the same semantic, morphological and syntactic composition, where it represents the least marked word form without any inflectional affixes. This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 40 Proceedings of the Workshop on Cognitive Aspects of the Lexicon, pages 40–50, Osaka, Japan, December 11-17 2016. License details: http:// In Arabic, a verb lemma is chosen to be the perfective, indicative, 3rd person, masculine, and singular such as Q º $akara1 “to thank”. Whereas a nominal lemma (na"
W16-5306,P16-2090,0,0.0222331,"Missing"
W16-5306,W05-0711,0,0.0438503,"o be trained on a model for vowelization. Vowelization is an important aspect in the Arabic morphological patterns (which are sometimes referred to as vocalic scheme). Our list of 377 unique patterns is reduced to 175 patterns when vowel marks are removed. Automatic vowelization, or diacritic restoration, has been discussed in a number of papers. For example, Bebah et al. (2014) describe a hybrid method for automatic vowelization using the Al-Khalil morphological analyzer and a hidden Markov model (HMM) to disambiguate. Some researchers use purely statistical methods for restoring diacritics (Nelken and Shieber, 2005; Elshafei et al., 2006; Ameur et al., 2015; Rashwan et al., 2011). 2 Related Work Lemmatization has been discussed for morphologically rich languages, such as Setswana (Brits et al., 2005), Croatian (Tadi´c, 2006), Slovene, Serbian, Hungarian, Estonian, Bulgarian and Romanian (in addition to other languages) (Juršiˇc et al., 2007), French (Seddah et al., 2010), Portuguese (da Silva, 2007), Finnish (Korenius et al., 2004), Turkish (Ozturkmenoglu and Alpkocak, 2012) and even English (Balakrishnan and Lloyd-Yemoh, 2014). Plisson et al. (2004) and Juršiˇc et al. (2007) treat lemmatization as a ma"
W16-5306,P08-2030,1,0.808025,"on sets of example pairs (stem and inflected form) with their feature vectors. El-Shishtawy and El-Ghannam (2012) build a rule-based system that exploits Arabic language knowledge in terms of roots, patterns, affixes, and a set of morpho-syntactic rules to generate lemmas for surface word forms. Hybrid normalization. (Hajiˇc, 2000) argues for the use of a dictionary as a source of morphological analyses for training a statistical POS and morphological tagger for inflectionally rich languages, such as Romanian, Czech, or Hungarian. The method was later applied to Arabic (Hajic et al., 2005). (Roth et al., 2008) develop a system (MADA) that uses statistical methods (SVM classifiers) to perform full morpho-syntactic tagging, along with lemmatization (LexChoice), by selecting the best candidate from the list of competing analyses generated by BAMA (Buckwalter, 2004). Statistical normalization. The Stanford Tagger (Toutanova and Manning, 2000) is a Maximum Entropy POS tagger that has been extended for Arabic, but the problem with this tagger is that it does not perform segmentation of Arabic clitics. AMIRA 2.1 (Diab, 2007; Diab, 2009) uses a supervised SVM-based machine learning method for POS tagging,"
W16-5306,W10-1410,0,0.0432904,"Missing"
W16-5306,2006.jeptalnrecital-long.29,0,0.0682393,"eir function as an instrument for decomposing word forms. Roots and patterns are the hidden layers through which Arabic speakers organize, memorize and access the Arabic lexicon. In many NLP tasks, using surface word forms is found to be inefficient as it significantly adds to sparsity, especially in highly inflected languages; thus, some form of normalization is necessary. Normalization in general, and lemmatization in particular, are meant to reduce the variability in word forms by collapsing related words. This has been shown to be beneficial for information retrieval (Larkey et al., 2002; Semmar et al., 2006), parsing (Seddah et al., 2010), summarization (Skorkovská, 2012; ElShishtawy and El-Ghannam, 2014), document clustering (Korenius et al., 2004), keyphrase extraction (El-Shishtawy and Al-Sammak, 2012), and text indexing and classification (Hammouda and Almarimi, 2010). From a lexical point of view, normalization can be conducted at the level of the root, stem or lemma. Lemmatization relates surface forms to their canonical base representations (or dictionary lookup form) (Attia and van Genabith, 2013). It is the inverse of inflection (Plisson et al., 2004), as it renders words to a default an"
W16-5306,W00-1308,0,0.279852,"Missing"
W16-5311,S15-2151,0,0.0148292,"cation of Semantic Relations. We evaluated three methods for semantic classification based on word embeddings: word analogy, linear regression, and multi-task CNNs. In all these methods, we use publicly available pre-trained English word vectors. 2 Related Work Semantic relatedness between single words (excluding phrases, sentences and multilingual parallel data) has been addressed in a number of shared tasks before, including relational similarity in SemEval-2012 (Jurgens et al., 2012), word to sense matching in SemEval-2014 (Jurgens et al., 2014), hyponym-hypernym relations in SemEval-2015 (Bordea et al., 2015), semantic taxonomy (hypernymy) in SemEval-2016 (Bordea et al., 2016), and semantic association in CogALex-2014 (Rapp and Zock, 2014). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 86 Proceedings of the Workshop on Cognitive Aspects of the Lexicon, pages 86–91, Osaka, Japan, December 11-17 2016. License details: http:// The idea of representing words as vectors has been studied for about three decades (Hinton et al., 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schütze, 2008; Mikolov et al."
W16-5311,S16-1168,0,0.0235916,"classification based on word embeddings: word analogy, linear regression, and multi-task CNNs. In all these methods, we use publicly available pre-trained English word vectors. 2 Related Work Semantic relatedness between single words (excluding phrases, sentences and multilingual parallel data) has been addressed in a number of shared tasks before, including relational similarity in SemEval-2012 (Jurgens et al., 2012), word to sense matching in SemEval-2014 (Jurgens et al., 2014), hyponym-hypernym relations in SemEval-2015 (Bordea et al., 2015), semantic taxonomy (hypernymy) in SemEval-2016 (Bordea et al., 2016), and semantic association in CogALex-2014 (Rapp and Zock, 2014). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 86 Proceedings of the Workshop on Cognitive Aspects of the Lexicon, pages 86–91, Osaka, Japan, December 11-17 2016. License details: http:// The idea of representing words as vectors has been studied for about three decades (Hinton et al., 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schütze, 2008; Mikolov et al., 2013b). The interest in word embeddings has intensified recently wi"
W16-5311,S07-1081,0,0.0372437,"antic relation will have similar cosine distance. Linear regression classifiers, including Naive Bayes, Logistic Regression and Support Vector Machines, have been used for the identification of semantic relations. For example, GuoDong et al. (2005) used SVM to extract semantic relationships between entities relying on features extracted from lexical, syntactic, and semantic knowledge. Hatzivassiloglou and McKeown (1997) used a log-linear regression model to predict the similarity of conjoined adjectives. Snow et al. (2004) use a logistic regression classifier for hypernym pair identification. Costello (2007) used Naive Bayes to learn associations between features extracted from WordNet and predict relation membership categories. In our work, we do not use any lexical, syntactic or semantic features, other than the word embeddings and we score similarity using the well known cosine similarity metric. CNNs have also been applied to the task. Zeng et al. (2014) use a convolutional deep neural network (DNN) to extract lexical features learned from word embeddings and then fed into a softmax classifier to predict the relationship between words. Similar approaches have been applied in (Santos et al., 2"
W16-5311,N16-2002,0,0.0163109,"many. For example, while it is relatively easy to predict ‘queen’ as the answer to this query x = king − man + woman, you cannot expect ‘contract’ as the answer to the query x = shoe − boot + lease with the same level of confidence if the relationship is expected to be either synonymy, antonymy, hyponymy, or hypernymy. In this paper we try three different methods for handling semantic classification in the shared task: word analogy, linear regression and multi-task CNN. Using word analogy for identifying semantic relations has been discussed in a number of papers including (Levy et al., 2015; Gladkova et al., 2016; Vylomova et al., 2015). The basic idea is to use vector-oriented reasoning based on the offsets between words (Mikolov et al., 2013b) assuming that pairs of words that share a certain semantic relation will have similar cosine distance. Linear regression classifiers, including Naive Bayes, Logistic Regression and Support Vector Machines, have been used for the identification of semantic relations. For example, GuoDong et al. (2005) used SVM to extract semantic relationships between entities relying on features extracted from lexical, syntactic, and semantic knowledge. Hatzivassiloglou and Mc"
W16-5311,P05-1053,0,0.0185926,"linear regression and multi-task CNN. Using word analogy for identifying semantic relations has been discussed in a number of papers including (Levy et al., 2015; Gladkova et al., 2016; Vylomova et al., 2015). The basic idea is to use vector-oriented reasoning based on the offsets between words (Mikolov et al., 2013b) assuming that pairs of words that share a certain semantic relation will have similar cosine distance. Linear regression classifiers, including Naive Bayes, Logistic Regression and Support Vector Machines, have been used for the identification of semantic relations. For example, GuoDong et al. (2005) used SVM to extract semantic relationships between entities relying on features extracted from lexical, syntactic, and semantic knowledge. Hatzivassiloglou and McKeown (1997) used a log-linear regression model to predict the similarity of conjoined adjectives. Snow et al. (2004) use a logistic regression classifier for hypernym pair identification. Costello (2007) used Naive Bayes to learn associations between features extracted from WordNet and predict relation membership categories. In our work, we do not use any lexical, syntactic or semantic features, other than the word embeddings and we"
W16-5311,P97-1023,0,0.558863,"; Gladkova et al., 2016; Vylomova et al., 2015). The basic idea is to use vector-oriented reasoning based on the offsets between words (Mikolov et al., 2013b) assuming that pairs of words that share a certain semantic relation will have similar cosine distance. Linear regression classifiers, including Naive Bayes, Logistic Regression and Support Vector Machines, have been used for the identification of semantic relations. For example, GuoDong et al. (2005) used SVM to extract semantic relationships between entities relying on features extracted from lexical, syntactic, and semantic knowledge. Hatzivassiloglou and McKeown (1997) used a log-linear regression model to predict the similarity of conjoined adjectives. Snow et al. (2004) use a logistic regression classifier for hypernym pair identification. Costello (2007) used Naive Bayes to learn associations between features extracted from WordNet and predict relation membership categories. In our work, we do not use any lexical, syntactic or semantic features, other than the word embeddings and we score similarity using the well known cosine similarity metric. CNNs have also been applied to the task. Zeng et al. (2014) use a convolutional deep neural network (DNN) to e"
W16-5311,S12-1047,0,0.0318201,"tend to have similar contextual embeddings. This paper describes our system for the CogALex-V Shared Task on Corpus-Based Identification of Semantic Relations. We evaluated three methods for semantic classification based on word embeddings: word analogy, linear regression, and multi-task CNNs. In all these methods, we use publicly available pre-trained English word vectors. 2 Related Work Semantic relatedness between single words (excluding phrases, sentences and multilingual parallel data) has been addressed in a number of shared tasks before, including relational similarity in SemEval-2012 (Jurgens et al., 2012), word to sense matching in SemEval-2014 (Jurgens et al., 2014), hyponym-hypernym relations in SemEval-2015 (Bordea et al., 2015), semantic taxonomy (hypernymy) in SemEval-2016 (Bordea et al., 2016), and semantic association in CogALex-2014 (Rapp and Zock, 2014). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 86 Proceedings of the Workshop on Cognitive Aspects of the Lexicon, pages 86–91, Osaka, Japan, December 11-17 2016. License details: http:// The idea of representing words as vectors has been studied for about thr"
W16-5311,S14-2003,0,0.0171965,"s our system for the CogALex-V Shared Task on Corpus-Based Identification of Semantic Relations. We evaluated three methods for semantic classification based on word embeddings: word analogy, linear regression, and multi-task CNNs. In all these methods, we use publicly available pre-trained English word vectors. 2 Related Work Semantic relatedness between single words (excluding phrases, sentences and multilingual parallel data) has been addressed in a number of shared tasks before, including relational similarity in SemEval-2012 (Jurgens et al., 2012), word to sense matching in SemEval-2014 (Jurgens et al., 2014), hyponym-hypernym relations in SemEval-2015 (Bordea et al., 2015), semantic taxonomy (hypernymy) in SemEval-2016 (Bordea et al., 2016), and semantic association in CogALex-2014 (Rapp and Zock, 2014). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 86 Proceedings of the Workshop on Cognitive Aspects of the Lexicon, pages 86–91, Osaka, Japan, December 11-17 2016. License details: http:// The idea of representing words as vectors has been studied for about three decades (Hinton et al., 1986; Rumelhart et al., 1986; Elman,"
W16-5311,W14-1618,0,0.0310541,"ord 54 . This is built with the GloVe architecture from a corpus of 6B words (400K vocabulary entries) with 300 dimensions, and applying AdaGrad with context size of 20. 4 Experiments and Results In this section we outline the experiments and report the results for the three approaches we tested: word analogy, linear regression and multi-task CNN. The results reported in this section are on the training set for all labels including “FALSE” for Task-1 and “RANDOM” for Task-2. Results on the test set of our selected systems are reported in Section 5. 4.1 Word Analogy In word analogy, similar to Levy et al. (2014), we query the word vector directly to obtain the closest match to the given example using the formula: predicted_word = example_word1 − example_word2 + target_word. We iterate the query over all the examples in the training set and limit the search scope to the vocabulary items within the set (a set is the target word and all potentially related words). Then we take the average of the responses. The results in Table 2 show that this approach does not work as well for this current task. As we will show, the scores are much lower than those of the other approaches we explored here. 4.2 Linear R"
W16-5311,Q15-1016,0,0.0391388,"en words is one-to-many. For example, while it is relatively easy to predict ‘queen’ as the answer to this query x = king − man + woman, you cannot expect ‘contract’ as the answer to the query x = shoe − boot + lease with the same level of confidence if the relationship is expected to be either synonymy, antonymy, hyponymy, or hypernymy. In this paper we try three different methods for handling semantic classification in the shared task: word analogy, linear regression and multi-task CNN. Using word analogy for identifying semantic relations has been discussed in a number of papers including (Levy et al., 2015; Gladkova et al., 2016; Vylomova et al., 2015). The basic idea is to use vector-oriented reasoning based on the offsets between words (Mikolov et al., 2013b) assuming that pairs of words that share a certain semantic relation will have similar cosine distance. Linear regression classifiers, including Naive Bayes, Logistic Regression and Support Vector Machines, have been used for the identification of semantic relations. For example, GuoDong et al. (2005) used SVM to extract semantic relationships between entities relying on features extracted from lexical, syntactic, and semantic knowledge."
W16-5311,N13-1090,0,0.367689,"et al., 2015), semantic taxonomy (hypernymy) in SemEval-2016 (Bordea et al., 2016), and semantic association in CogALex-2014 (Rapp and Zock, 2014). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 86 Proceedings of the Workshop on Cognitive Aspects of the Lexicon, pages 86–91, Osaka, Japan, December 11-17 2016. License details: http:// The idea of representing words as vectors has been studied for about three decades (Hinton et al., 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schütze, 2008; Mikolov et al., 2013b). The interest in word embeddings has intensified recently with the introduction of the new log linear architecture of Mikolov et al. (2013a). This architecture provided an efficient and simplified training methodology that minimizes computational complexity by doing away with the non-linear hidden layer, enabling training on much larger data than were previously possible. The public availability of word embedding training programs such as word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014) allowed researchers to create models with different parameters and dimensionality siz"
W16-5311,D14-1162,0,0.0899215,", 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schütze, 2008; Mikolov et al., 2013b). The interest in word embeddings has intensified recently with the introduction of the new log linear architecture of Mikolov et al. (2013a). This architecture provided an efficient and simplified training methodology that minimizes computational complexity by doing away with the non-linear hidden layer, enabling training on much larger data than were previously possible. The public availability of word embedding training programs such as word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014) allowed researchers to create models with different parameters and dimensionality sizes for different purposes. The evaluation data1 used in the development of the Google Continuous Bag of Words (CBOW) and skip-gram vectors (Mikolov et al., 2013a) focused on semantic similarities and coarse-grained semantic relations in the form of deterministic answers by analogy. These relationships were one-to-one including, for example, capitals (Athens: Greece - Baghdad: Iraq), currencies (India: rupee - Iran: rial), gender (king: queen - man: woman), derivation (amazing: amazingly - safe: safely), and i"
W16-5311,W14-4701,0,0.0286264,"egression, and multi-task CNNs. In all these methods, we use publicly available pre-trained English word vectors. 2 Related Work Semantic relatedness between single words (excluding phrases, sentences and multilingual parallel data) has been addressed in a number of shared tasks before, including relational similarity in SemEval-2012 (Jurgens et al., 2012), word to sense matching in SemEval-2014 (Jurgens et al., 2014), hyponym-hypernym relations in SemEval-2015 (Bordea et al., 2015), semantic taxonomy (hypernymy) in SemEval-2016 (Bordea et al., 2016), and semantic association in CogALex-2014 (Rapp and Zock, 2014). This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ 86 Proceedings of the Workshop on Cognitive Aspects of the Lexicon, pages 86–91, Osaka, Japan, December 11-17 2016. License details: http:// The idea of representing words as vectors has been studied for about three decades (Hinton et al., 1986; Rumelhart et al., 1986; Elman, 1990; Bengio et al., 2003; Kann and Schütze, 2008; Mikolov et al., 2013b). The interest in word embeddings has intensified recently with the introduction of the new log linear architecture of Mikolo"
W16-5311,P15-1061,0,0.025986,"Costello (2007) used Naive Bayes to learn associations between features extracted from WordNet and predict relation membership categories. In our work, we do not use any lexical, syntactic or semantic features, other than the word embeddings and we score similarity using the well known cosine similarity metric. CNNs have also been applied to the task. Zeng et al. (2014) use a convolutional deep neural network (DNN) to extract lexical features learned from word embeddings and then fed into a softmax classifier to predict the relationship between words. Similar approaches have been applied in (Santos et al., 2015) and (Xu et al., 2015). 3 Data Description 3.1 Shared Task Data The shared task organizers provide a training set of 3,054 word pairs for 318 target words. In Task-1, we are given a pair of words and we need to determine if the words are semantically related or not. Some examples of Task-1 are shown in 1. In Task-2 participants are required to detect the type of the relationship: HYPER, PART_OF, SYN, ANT, or RANDOM. 3.2 Pre-Trained Word Vectors In our experiments we experimented with three large-scale, publicly available pre-trained word vectors: 1 http://www.fit.vutbr.cz/ imikolov/rnnlm/word-"
W16-5311,D15-1062,0,0.0222394,"e Bayes to learn associations between features extracted from WordNet and predict relation membership categories. In our work, we do not use any lexical, syntactic or semantic features, other than the word embeddings and we score similarity using the well known cosine similarity metric. CNNs have also been applied to the task. Zeng et al. (2014) use a convolutional deep neural network (DNN) to extract lexical features learned from word embeddings and then fed into a softmax classifier to predict the relationship between words. Similar approaches have been applied in (Santos et al., 2015) and (Xu et al., 2015). 3 Data Description 3.1 Shared Task Data The shared task organizers provide a training set of 3,054 word pairs for 318 target words. In Task-1, we are given a pair of words and we need to determine if the words are semantically related or not. Some examples of Task-1 are shown in 1. In Task-2 participants are required to detect the type of the relationship: HYPER, PART_OF, SYN, ANT, or RANDOM. 3.2 Pre-Trained Word Vectors In our experiments we experimented with three large-scale, publicly available pre-trained word vectors: 1 http://www.fit.vutbr.cz/ imikolov/rnnlm/word-test.v1.txt 87 Word 1"
W16-5311,C14-1220,0,0.030602,"yntactic, and semantic knowledge. Hatzivassiloglou and McKeown (1997) used a log-linear regression model to predict the similarity of conjoined adjectives. Snow et al. (2004) use a logistic regression classifier for hypernym pair identification. Costello (2007) used Naive Bayes to learn associations between features extracted from WordNet and predict relation membership categories. In our work, we do not use any lexical, syntactic or semantic features, other than the word embeddings and we score similarity using the well known cosine similarity metric. CNNs have also been applied to the task. Zeng et al. (2014) use a convolutional deep neural network (DNN) to extract lexical features learned from word embeddings and then fed into a softmax classifier to predict the relationship between words. Similar approaches have been applied in (Santos et al., 2015) and (Xu et al., 2015). 3 Data Description 3.1 Shared Task Data The shared task organizers provide a training set of 3,054 word pairs for 318 target words. In Task-1, we are given a pair of words and we need to determine if the words are semantically related or not. Some examples of Task-1 are shown in 1. In Task-2 participants are required to detect"
W16-5311,P16-1158,0,\N,Missing
W16-5806,P13-2037,0,0.158762,"Missing"
W16-5806,K15-1005,0,0.0606159,"Missing"
W16-5806,W14-3902,0,0.11852,"nguage is sometimes referred to as the ‘host language’, and the embedded language as the ‘guest language’ (Yeh et al., 2013). Code-switching is a wide-spread linguistic phenomenon in modern informal user-generated data, whether spoken or written. With the advent of social media, such as Facebook posts, Twitter It is not necessary for code-switching to occur only between two different languages like Spanish-English (Solorio and Liu, 2008), MandarinTaiwanese (Yu et al., ) and Turkish-German (Özlem Çetinoglu, 2016), but it can also happen between three languages, e.g. Bengali, English and Hindi (Barman et al., 2014), and in some extreme cases between six languages: English, French, German, Italian, Romansh and Swiss German (Volk and Clematide, 2014). Moreover, this phenomenon can occur between two different dialects of the same language as between Modern Standard Arabic (MSA) and Egyptian Dialect (Elfardy and Diab, 2012), or MSA and Moroccan Arabic (Samih and Maier, 50 Proceedings of the Second Workshop on Computational Approaches to Code Switching, pages 50–59, c Austin, TX, November 1, 2016. 2016 Association for Computational Linguistics 2016a; Samih and Maier, 2016b). The current shared task is limite"
W16-5806,W14-5152,0,0.0188575,"lmeyer Mohammed Attia Dept. of Computational Linguistics Dept. of Computer Science Google Inc. University of Houston Heinrich Heine University, New York City Houston, TX, 77004 Düsseldorf, Germany NY, 10011 solorio@cs.uh.edu kallmeyer@phil.hhu.de attia@google.com Abstract tweets, SMS messages, user comments on the articles, blogs, etc., this phenomenon is becoming more pervasive. Code-switching does not only occur across sentences (inter-sentential) but also within the same sentence (intra-sentential), adding a substantial complexity dimension to the automatic processing of natural languages (Das and Gambäck, 2014). This phenomenon is particularly dominant in multilingual societies (Milroy and Muysken, 1995), migrant communities (Papalexakis et al., 2014), and in other environments due to social changes through education and globalization (Milroy and Muysken, 1995). There are also some social, pragmatic and linguistic motivations for code-switching, such as the the intent to express group solidarity, establish authority (Chang and Lin, 2014), lend credibility, or make up for lexical gaps. This paper describes the HHU-UH-G system submitted to the EMNLP 2016 Second Workshop on Computational Approaches to"
W16-5806,W15-3904,0,0.0617735,"Missing"
W16-5806,elfardy-diab-2012-simplified,0,0.0155933,"ter It is not necessary for code-switching to occur only between two different languages like Spanish-English (Solorio and Liu, 2008), MandarinTaiwanese (Yu et al., ) and Turkish-German (Özlem Çetinoglu, 2016), but it can also happen between three languages, e.g. Bengali, English and Hindi (Barman et al., 2014), and in some extreme cases between six languages: English, French, German, Italian, Romansh and Swiss German (Volk and Clematide, 2014). Moreover, this phenomenon can occur between two different dialects of the same language as between Modern Standard Arabic (MSA) and Egyptian Dialect (Elfardy and Diab, 2012), or MSA and Moroccan Arabic (Samih and Maier, 50 Proceedings of the Second Workshop on Computational Approaches to Code Switching, pages 50–59, c Austin, TX, November 1, 2016. 2016 Association for Computational Linguistics 2016a; Samih and Maier, 2016b). The current shared task is limited to two scenarios: a) codeswitching between two distinct languages: SpanishEnglish, b) and two language varieties: MSAEgyptian Dialect. With the massive increase in code-switched writings in user-generated content, it has become imperative to develop tools and methods to handle and process this type of data."
W16-5806,C82-1023,0,0.183927,"Missing"
W16-5806,P16-1101,0,0.00704538,"at of Chang and Lin (2014) in that we use RNNs and word embeddings. The difference is that we use long-shortterm memory (LSTM) with the added advantage of the memory cells that efficiently capture longdistance dependencies. We also combine wordlevel with character-level representation to obtain morphology-like information on words. 3 Model In this section, we will provide a brief description of LSTM, and introduce the different components of our code-switching detection model. The architecture of our system, shown in Figure 1, bears resemblance to the models introduced by Huang et al. (2015), Ma and Hovy (2016), and Collobert et al. (2011). 3.1 Long Short-term Memory A recurrent neural network (RNN) belongs to a family of neural networks suited for modeling sequential data. Given an input sequence x = (x1 , ..., xn ), an RNN computes the output vector yt of each word xt by iterating the following equations from t = 1 to n: Figure 1: System Architecture. where ht is the hidden states vector, W denotes weight matrix, b denotes bias vector and f is the activation function of the hidden layer. Theoretically RNN can learn long distance dependencies, still in practice they fail due the vanishing/exploding"
W16-5806,W15-1608,1,0.900866,"Missing"
W16-5806,N13-1039,0,0.0355151,"Missing"
W16-5806,W14-3905,0,0.049232,"Missing"
W16-5806,P08-2030,0,0.0602839,"Missing"
W16-5806,L16-1658,1,0.835896,"ges, e.g. Bengali, English and Hindi (Barman et al., 2014), and in some extreme cases between six languages: English, French, German, Italian, Romansh and Swiss German (Volk and Clematide, 2014). Moreover, this phenomenon can occur between two different dialects of the same language as between Modern Standard Arabic (MSA) and Egyptian Dialect (Elfardy and Diab, 2012), or MSA and Moroccan Arabic (Samih and Maier, 50 Proceedings of the Second Workshop on Computational Approaches to Code Switching, pages 50–59, c Austin, TX, November 1, 2016. 2016 Association for Computational Linguistics 2016a; Samih and Maier, 2016b). The current shared task is limited to two scenarios: a) codeswitching between two distinct languages: SpanishEnglish, b) and two language varieties: MSAEgyptian Dialect. With the massive increase in code-switched writings in user-generated content, it has become imperative to develop tools and methods to handle and process this type of data. Identification of languages used in the sentence is the first step in doing any kind of text analysis. For example, most data found in social media produced by bilingual people is a mixture of two languages. In order to process or translate this data t"
W16-5806,D08-1102,1,0.820571,"rmance. 1 Introduction Code-switching can be defined as the act of alternating between elements of two or more languages or language varieties within the same utterance. The main language is sometimes referred to as the ‘host language’, and the embedded language as the ‘guest language’ (Yeh et al., 2013). Code-switching is a wide-spread linguistic phenomenon in modern informal user-generated data, whether spoken or written. With the advent of social media, such as Facebook posts, Twitter It is not necessary for code-switching to occur only between two different languages like Spanish-English (Solorio and Liu, 2008), MandarinTaiwanese (Yu et al., ) and Turkish-German (Özlem Çetinoglu, 2016), but it can also happen between three languages, e.g. Bengali, English and Hindi (Barman et al., 2014), and in some extreme cases between six languages: English, French, German, Italian, Romansh and Swiss German (Volk and Clematide, 2014). Moreover, this phenomenon can occur between two different dialects of the same language as between Modern Standard Arabic (MSA) and Egyptian Dialect (Elfardy and Diab, 2012), or MSA and Moroccan Arabic (Samih and Maier, 50 Proceedings of the Second Workshop on Computational Approach"
W16-5806,W14-3903,0,0.0180518,"switching is a wide-spread linguistic phenomenon in modern informal user-generated data, whether spoken or written. With the advent of social media, such as Facebook posts, Twitter It is not necessary for code-switching to occur only between two different languages like Spanish-English (Solorio and Liu, 2008), MandarinTaiwanese (Yu et al., ) and Turkish-German (Özlem Çetinoglu, 2016), but it can also happen between three languages, e.g. Bengali, English and Hindi (Barman et al., 2014), and in some extreme cases between six languages: English, French, German, Italian, Romansh and Swiss German (Volk and Clematide, 2014). Moreover, this phenomenon can occur between two different dialects of the same language as between Modern Standard Arabic (MSA) and Egyptian Dialect (Elfardy and Diab, 2012), or MSA and Moroccan Arabic (Samih and Maier, 50 Proceedings of the Second Workshop on Computational Approaches to Code Switching, pages 50–59, c Austin, TX, November 1, 2016. 2016 Association for Computational Linguistics 2016a; Samih and Maier, 2016b). The current shared task is limited to two scenarios: a) codeswitching between two distinct languages: SpanishEnglish, b) and two language varieties: MSAEgyptian Dialect."
W16-5806,W14-3904,0,0.050393,"Missing"
W16-5806,L16-1667,0,0.022612,"ween elements of two or more languages or language varieties within the same utterance. The main language is sometimes referred to as the ‘host language’, and the embedded language as the ‘guest language’ (Yeh et al., 2013). Code-switching is a wide-spread linguistic phenomenon in modern informal user-generated data, whether spoken or written. With the advent of social media, such as Facebook posts, Twitter It is not necessary for code-switching to occur only between two different languages like Spanish-English (Solorio and Liu, 2008), MandarinTaiwanese (Yu et al., ) and Turkish-German (Özlem Çetinoglu, 2016), but it can also happen between three languages, e.g. Bengali, English and Hindi (Barman et al., 2014), and in some extreme cases between six languages: English, French, German, Italian, Romansh and Swiss German (Volk and Clematide, 2014). Moreover, this phenomenon can occur between two different dialects of the same language as between Modern Standard Arabic (MSA) and Egyptian Dialect (Elfardy and Diab, 2012), or MSA and Moroccan Arabic (Samih and Maier, 50 Proceedings of the Second Workshop on Computational Approaches to Code Switching, pages 50–59, c Austin, TX, November 1, 2016. 2016 Asso"
W17-1306,N16-3003,1,0.794973,"or testing, 75 for development and the remaining 200 for training. The concept We followed in LSTM sequence labeling is that segmentation is one-to-one mapping at the character level where each character is annotated as either beginning a segment (B), continues a previous segment (M), ends a segment (E), or is a segment by itself (S). After the labeling is complete we merge the characters and labels  together, for example @ñËñ®J K. byqwlwA is labeled as “SBMMEBE”, which means that the word is segmented as b+yqwl+wA. We compar results of our two LSTM models (BiLSTM and BiLSTMCRF) with Farasa (Abdelali et al., 2016), an open source segementer for MSA3 , and MADAMIRA for Egyptian dialect. Table 3 shows accuracy for Farasa, MADAMIRA, and both of our models. • ËQK @ñË@ AlwAyrls “the  AlHA$tAj “the hashtag”. h. AJAêË@ AlgTY “the Spelling variation: e.g. ù¢ªË@ cover”, úÎë B l&gt;hly “to Ahly”. wireless”, • Morphological inflection (imperative): e.g.  ¯ fwqwA “wake up”. ø Y $dy “pull”, @ñ¯ñ • Segmentation ambiguity: e.g. éJ Ë lyh meaning mAlnA meaning “our “why” or “to him”, AJËAÓ money” or “what we have”. • Combinations not known to MADAMIRA:  ® ® JÓ mtqflwhA$ “don’t close it”, e.g. AëñÊ @ &gt;wSflkwA “I"
W17-1306,W09-0807,0,0.049808,"instead dual and feminine plural, dropping some articles and preposition in some syntactic constructs, and using only one form yn inof noun and verb suffixes such as áK wn and stead of àð respectively. • Many words do not overlap with MSA as result of language borrowing from other lan guages (Ibrahim, 2006), such as éJ ¯A¿ kAfiyh ñKAK  mi$ “not” Ó  . balA$ “do not”. Code switching is and CK also very common in Arabic dialects (Samih et al., 2016). 2 Related Work Work on dialectal Arabic is fairly new compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghribi. Few resources for these dialects are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), which contains 2,000 parallel sentences in multiple dialects and MSA as well as English translation. • Merging multiple words together by concatenating and dropping letters such as the word  . J J.Ó mbyjlhA$ (he"
W17-1306,bouamor-etal-2014-multidialectal,0,0.121902,"tching is and CK also very common in Arabic dialects (Samih et al., 2016). 2 Related Work Work on dialectal Arabic is fairly new compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghribi. Few resources for these dialects are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), which contains 2,000 parallel sentences in multiple dialects and MSA as well as English translation. • Merging multiple words together by concatenating and dropping letters such as the word  . J J.Ó mbyjlhA$ (he did not go to her), AêÊj which is a concatenation of “mA byjy lhA$”. • Some affixes are altered in form from their MSA counterparts, such as the feminine second person pronoun  k → ú» ky and the second person plural pronoun wn @ð wA instead of àð • In addition, there are the regular discourse features in informal texts, such as the use of emoticons and character repetition for emp"
W17-1306,D14-1154,1,0.858589,"cters embedding and stacks them to build a matrix. This latter is then used as the input to the Bi-directional LSTM. On the last layer, an affine transformation function followed by a CRF computes the probability distribution over all labels Early Stopping We also employ early stopping (Caruana et al., 2000; Graves et al., 2013b) to mitigate overfitting by monitoring the model’s performance on development set. 4 ary respectively. The architecture of our segmentation model, shown in Figure 2, is straightforward. It comprises the following three layers: Dataset We used the dataset described in (Darwish et al., 2014). The data was used in a dialect identification task to distinguish between dialectal Egyptian and MSA. It contains 350 tweets with more than 8,000 words including 3,000 unique words written in Egyptian dialect. The tweets have much dialectal content covering most of dialectal Egyptian phonological, morphological, and syntactic phenomena. It also includes Twitter-specific aspects of the text, such as #hashtags, @mentions, emoticons and URLs. We manually annotated each word in this corpus to provide: CODA-compliant writing (Habash et al., 2012), segmentation, stem, lemma, and POS, also the corr"
W17-1306,W15-3904,0,0.0407118,"Missing"
W17-1306,W16-4828,1,0.865893,"is paper, we show how a segmenter can be trained on only 350 annotated tweets using neural networks without any normalization or reliance on lexical features or linguistic resources. We deal with segmentation as a sequence labeling problem at the character level. We show experimentally that our model can rival state-of-the-art methods that heavily depend on additional resources. 1 The advent of the social networks and the spread of smart phones, yielded the need for dialectaware smart systems and motivated the research in Dialectal Arabic such as dialectal Arabic identification for both text (Eldesouki et al., 2016) and speech (Khurana et al., 2016), morphological analysis (Habash et al., 2013) and machine translation (Sennrich et al., 2016; Sajjad et al., 2013). Due to the rich morphology in Arabic and its dialects, word segmentation is one of the most important processing steps. Word segmentation is considered an integral part for many higher Arabic NLP tasks such as part-of-speech tagging, parsing and machine translation. For example, the Egyp JºÓð “wmktbhA$” meaning: “and tian word AîD . he didn’t write it”) includes four clitics surrounding the the verb (stem) “ktb”, and is rendered after segment"
W17-1306,N16-1030,0,0.164915,"− x + W← −← − h t−1 + b← −) ht = σ(Wx← h t h h h → − ← − → h + W← − h + by yt = W− hy t hy t set of labels. In our case S ={B, M, E, S, WB}, where B is the beginning of a token, M is the middle of a token, E is the end of a token, S is a single character token, and W B is the word boundary. w ~ is the weight vector for weighting the feature vec~ Training and decoding are performed by the tor Φ. Viterbi algorithm. Note that replacing the softmax with CRF at the output layer in neural networks has proved to be very fruitful in many sequence labeling tasks (Ma and Hovy, 2016; Huang et al., 2015; Lample et al., 2016; Samih et al., 2016) More interpretations about these formulas are found in Graves et al. (2013a). A very important element of the recent success of many NLP applications, is the use of characterlevel representations in deep neural networks. This has shown to be effective for numerous NLP tasks (Collobert et al., 2011; dos Santos et al., 2015) as it can capture word morphology and reduce out-of-vocabulary. This approach has also been especially useful for handling languages with rich morphology and large character sets (Kim et al., 2016). We use pre-trained character embeddings to initialize"
W17-1306,P16-1101,0,0.269252,"(ct ) where σ is the logistic sigmoid function, and i, f , o and c are respectively the input gate, forget gate, output gate and cell activation vectors. More interpretation about this architecture can be found in (Lipton et al., 2015). Figure 1 illustrates a single LSTM memory cell (Graves and Schmidhuber, 2005) Arabic Segmentation Model In this section, we will provide a brief description of LSTM, and introduce the different components of our Arabic segmentation model. For all our work, we used the Keras toolkit (Chollet, 2015). The architecture of our model, shown in Figure 2 is similar to Ma and Hovy (2016), Huang et al. (2015), and Collobert et al. (2011) 3.1 Long Short-term Memory A recurrent neural network (RNN) belongs to a family of neural networks suited for modeling sequential data. Given an input sequence x = (x1 , ..., xn ), an RNN computes the output vector yt of each word xt by iterating the following equations from t = 1 to n: 1 Figure 1: A Long Short-Term Memory Cell. 3.2 Bi-directional LSTM Bi-LSTM networks (Schuster and Paliwal, 1997) are extensions to the single LSTM networks. They MADAMIRA release 20160516 2.1 48 are capable of learning long-term dependencies and maintain contex"
W17-1306,maamouri-etal-2014-developing,0,0.0957441,"Missing"
W17-1306,habash-etal-2012-conventional,0,0.430983,"their MSA counterparts, such as the feminine second person pronoun  k → ú» ky and the second person plural pronoun wn @ð wA instead of àð • In addition, there are the regular discourse features in informal texts, such as the use of emoticons and character repetition for emphasis, e.g. úÍððððððñ«X@ AdEwwwwwwwliy “pray for me”. tAtuw “tattoo”, or coinage, such as the negative particles Ég. @P rAjil “man” Ég. P rajul, and vowel shortening, such as AÖß X dayomA “always” from AÖß @X dAyomA. from • Lack of standard orthography. Many of the words in DA do not follow a standard orthographic system (Habash et al., 2012). “cafe” and H t or  s as in Q J» kvyr Õç' tm → ñK tw. • Some morphological patterns that do not exist in MSA, such as the passive pattern AitofaEal, such as QåºK@ Aitokasar “it broke”. 47 For segmentation, Yao and Huang (2016) successfully used a bi-directional LSTM model for segmenting Chinese text. In this paper, we build on their work and extend it in two ways, namely combining bi-LSTM with CRF and applying on Arabic, which is an alphabetic language. Mohamed et al. (2012) built a segmenter based on memory-based learning. The segmenter has been trained on a small corpus of Egyptian"
W17-1306,mohamed-etal-2012-annotating,0,0.411081,"Missing"
W17-1306,N13-1044,0,0.282692,"neural networks without any normalization or reliance on lexical features or linguistic resources. We deal with segmentation as a sequence labeling problem at the character level. We show experimentally that our model can rival state-of-the-art methods that heavily depend on additional resources. 1 The advent of the social networks and the spread of smart phones, yielded the need for dialectaware smart systems and motivated the research in Dialectal Arabic such as dialectal Arabic identification for both text (Eldesouki et al., 2016) and speech (Khurana et al., 2016), morphological analysis (Habash et al., 2013) and machine translation (Sennrich et al., 2016; Sajjad et al., 2013). Due to the rich morphology in Arabic and its dialects, word segmentation is one of the most important processing steps. Word segmentation is considered an integral part for many higher Arabic NLP tasks such as part-of-speech tagging, parsing and machine translation. For example, the Egyp JºÓð “wmktbhA$” meaning: “and tian word AîD . he didn’t write it”) includes four clitics surrounding the the verb (stem) “ktb”, and is rendered after segmentation as “w+m+ktb+hA+$”. The clitics in this word are the coordinate conjunction"
W17-1306,P14-2034,0,0.310795,"Missing"
W17-1306,pasha-etal-2014-madamira,0,0.190181,"Missing"
W17-1306,P13-2001,1,0.858088,"tures or linguistic resources. We deal with segmentation as a sequence labeling problem at the character level. We show experimentally that our model can rival state-of-the-art methods that heavily depend on additional resources. 1 The advent of the social networks and the spread of smart phones, yielded the need for dialectaware smart systems and motivated the research in Dialectal Arabic such as dialectal Arabic identification for both text (Eldesouki et al., 2016) and speech (Khurana et al., 2016), morphological analysis (Habash et al., 2013) and machine translation (Sennrich et al., 2016; Sajjad et al., 2013). Due to the rich morphology in Arabic and its dialects, word segmentation is one of the most important processing steps. Word segmentation is considered an integral part for many higher Arabic NLP tasks such as part-of-speech tagging, parsing and machine translation. For example, the Egyp JºÓð “wmktbhA$” meaning: “and tian word AîD . he didn’t write it”) includes four clitics surrounding the the verb (stem) “ktb”, and is rendered after segmentation as “w+m+ktb+hA+$”. The clitics in this word are the coordinate conjunction “w”, the negation prefix “m”, the object pronoun “hA”, and the post"
W17-1306,W16-5806,1,0.909334,"under lenition, softening of a consonant, or fortition, hardening of a consonant. • Vowel elongation, such as • The use of masculine plural or singular noun forms instead dual and feminine plural, dropping some articles and preposition in some syntactic constructs, and using only one form yn inof noun and verb suffixes such as áK wn and stead of àð respectively. • Many words do not overlap with MSA as result of language borrowing from other lan guages (Ibrahim, 2006), such as éJ ¯A¿ kAfiyh ñKAK  mi$ “not” Ó  . balA$ “do not”. Code switching is and CK also very common in Arabic dialects (Samih et al., 2016). 2 Related Work Work on dialectal Arabic is fairly new compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghribi. Few resources for these dialects are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), which contains 2,000 parallel sentences in multiple"
W17-1306,P16-1162,0,0.049716,"reliance on lexical features or linguistic resources. We deal with segmentation as a sequence labeling problem at the character level. We show experimentally that our model can rival state-of-the-art methods that heavily depend on additional resources. 1 The advent of the social networks and the spread of smart phones, yielded the need for dialectaware smart systems and motivated the research in Dialectal Arabic such as dialectal Arabic identification for both text (Eldesouki et al., 2016) and speech (Khurana et al., 2016), morphological analysis (Habash et al., 2013) and machine translation (Sennrich et al., 2016; Sajjad et al., 2013). Due to the rich morphology in Arabic and its dialects, word segmentation is one of the most important processing steps. Word segmentation is considered an integral part for many higher Arabic NLP tasks such as part-of-speech tagging, parsing and machine translation. For example, the Egyp JºÓð “wmktbhA$” meaning: “and tian word AîD . he didn’t write it”) includes four clitics surrounding the the verb (stem) “ktb”, and is rendered after segmentation as “w+m+ktb+hA+$”. The clitics in this word are the coordinate conjunction “w”, the negation prefix “m”, the object prono"
W17-1306,J14-1006,0,0.025968,"ing some articles and preposition in some syntactic constructs, and using only one form yn inof noun and verb suffixes such as áK wn and stead of àð respectively. • Many words do not overlap with MSA as result of language borrowing from other lan guages (Ibrahim, 2006), such as éJ ¯A¿ kAfiyh ñKAK  mi$ “not” Ó  . balA$ “do not”. Code switching is and CK also very common in Arabic dialects (Samih et al., 2016). 2 Related Work Work on dialectal Arabic is fairly new compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghribi. Few resources for these dialects are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), which contains 2,000 parallel sentences in multiple dialects and MSA as well as English translation. • Merging multiple words together by concatenating and dropping letters such as the word  . J J.Ó mbyjlhA$ (he did not go to her), AêÊj which is a concatenation of"
W17-1306,N12-1006,0,0.0419555,"inine plural, dropping some articles and preposition in some syntactic constructs, and using only one form yn inof noun and verb suffixes such as áK wn and stead of àð respectively. • Many words do not overlap with MSA as result of language borrowing from other lan guages (Ibrahim, 2006), such as éJ ¯A¿ kAfiyh ñKAK  mi$ “not” Ó  . balA$ “do not”. Code switching is and CK also very common in Arabic dialects (Samih et al., 2016). 2 Related Work Work on dialectal Arabic is fairly new compared to MSA. A number of research projects were devoted to dialect identification (Biadsy et al., 2009; Zbib et al., 2012; Zaidan and Callison-Burch, 2014). There are five major dialects including Egyptian, Gulf, Iraqi, Levantine and Maghribi. Few resources for these dialects are available such as the CALLHOME Egyptian Arabic Transcripts (LDC97T19), which was made available for research as early as 1997. Newly developed resources include the corpus developed by Bouamor et al. (2014), which contains 2,000 parallel sentences in multiple dialects and MSA as well as English translation. • Merging multiple words together by concatenating and dropping letters such as the word  . J J.Ó mbyjlhA$ (he did not go to her),"
W18-3212,W18-3219,0,0.0485394,"Missing"
W18-3212,attia-etal-2010-automatically,1,0.861285,"Missing"
W18-3212,W03-0420,0,0.159291,"Missing"
W18-3212,J92-4003,0,0.601548,"le representation of the input words by using word embeddings and a character-based representation (with CNNs). The input sequence is processed with bi-LSTMs, and the output layer is a linear chain CRF. The model uses the following. Word-level embeddings allow the learning algorithms to use large unlabeled data to generalize beyond the seen training data. We explore randomly initialized embeddings based on the seen training data and pre-trained embedding. Brown clusters (BC) Brown clustering is an unsupervised learning method where words are grouped based on the contexts in which they appear (Brown et al., 1992). The assumption is that words that behave in similar ways tend to appear in similar contexts and hence belong to the same cluster. BCs can be learned from large unlabeled texts and have been shown to improve POS tagging (Owoputi et al., 2013; Stratos and Collins, 2015). We test the effectiveness of using Brown clusters in the context of named entity recognition in a DNN model. We train BCs on our crawled code-switched corpus of 380 million words (mentioned above) with 100 Brown Clusters. 1 Our implementation is mostly inspired by the work of Reimers and Gurevych (2017). Named Entity Gazetteer"
W18-3212,N13-1039,0,0.0608435,"Missing"
W18-3212,Q16-1026,0,0.0379796,".com Abstract den Markov Models (HMM) (Bikel et al., 1999), Maximum-Entropy Model (ME) (Bender et al., 2003; Curran and Clark, 2003; Finkel et al., 2005), Support Vector Machines (SVM) (Takeuchi and Collier, 2002), and Conditional Random Fields (CRF) (McCallum and Li, 2003). Standard data sets came from the English MUC-6 (Sundheim, 1995) and the multilingual CoNLL-02 (Tjong Kim Sang, 2002) and 03 (Tjong Kim Sang and De Meulder, 2003) shared tasks. More recent work relies on neural networks. A number of architecture variants have proven to be effective (Huang et al., 2015; Lample et al., 2016; Chiu and Nichols, 2016; Ma and Hovy, 2016; Reimers and Gurevych, 2017). What they have in common is that they use a bidirectional LSTM (bi-LSTM) over vector representations of the input words in order model their left and right contexts. On top of the bi-LSTM, they use a CRF layer to take the final tagging decisions. Other than a softmax layer which would treat tagging decisions independently, the CRF is able to model the linear dependencies between labels. This is essential for NER, where for instance, B-L OCATION cannot be followed by I-P ERSON. The architectures differ in their way of obtaining a vector represen"
W18-3212,D17-1035,0,0.0411367,"Missing"
W18-3212,W03-0424,0,0.250237,"Missing"
W18-3212,W15-3904,0,0.0437138,"Missing"
W18-3212,P05-1045,0,0.196077,"Missing"
W18-3212,W15-1511,0,0.0243402,"e learning algorithms to use large unlabeled data to generalize beyond the seen training data. We explore randomly initialized embeddings based on the seen training data and pre-trained embedding. Brown clusters (BC) Brown clustering is an unsupervised learning method where words are grouped based on the contexts in which they appear (Brown et al., 1992). The assumption is that words that behave in similar ways tend to appear in similar contexts and hence belong to the same cluster. BCs can be learned from large unlabeled texts and have been shown to improve POS tagging (Owoputi et al., 2013; Stratos and Collins, 2015). We test the effectiveness of using Brown clusters in the context of named entity recognition in a DNN model. We train BCs on our crawled code-switched corpus of 380 million words (mentioned above) with 100 Brown Clusters. 1 Our implementation is mostly inspired by the work of Reimers and Gurevych (2017). Named Entity Gazetteers We use a large collec99 Layer Characters CNN Bi-LSTM Dropout Word Emb. Characters Emb. Clustering Emb. Gazetteer Emb. Hyper-Parameters window size number of filters state size dropout rate dimension dimension dimension dimension batch size Value 4 40 100 0.5 300 100 1"
W18-3212,M95-1002,0,0.333938,"Missing"
W18-3212,W02-2029,0,0.263726,"Missing"
W18-3212,N16-1030,0,0.0812034,"odeling sequential data, achieving ground-breaking results in many NLP tasks (e.g., machine translation). Bi-LSTMs (Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) are capable of learning long-term dependencies and maintaining contextual features from both past and future states while avoiding the vanishing/exploding gradients problem. They consist of two separate bidirectional hidden layers that feed forward to the same output layer. CRF is used jointly with bi-LSTMs to avoid the output label independence assumptions of bi-LSTMs and to impose sequence labeling constraints as in Lample et al. (2016). System Description We used a DNN model which is mainly suited for sequence tagging. It is a variant of the bi-LSTM-CRF architecture proposed by Ma and Hovy (2016); Lample et al. (2016); Huang et al. (2015).1 It combines a double representation of the input words by using word embeddings and a character-based representation (with CNNs). The input sequence is processed with bi-LSTMs, and the output layer is a linear chain CRF. The model uses the following. Word-level embeddings allow the learning algorithms to use large unlabeled data to generalize beyond the seen training data. We explore ran"
W18-3212,W02-2024,0,0.35867,"Missing"
W18-3212,P16-1101,0,0.0653533,"iwal, 1997) are capable of learning long-term dependencies and maintaining contextual features from both past and future states while avoiding the vanishing/exploding gradients problem. They consist of two separate bidirectional hidden layers that feed forward to the same output layer. CRF is used jointly with bi-LSTMs to avoid the output label independence assumptions of bi-LSTMs and to impose sequence labeling constraints as in Lample et al. (2016). System Description We used a DNN model which is mainly suited for sequence tagging. It is a variant of the bi-LSTM-CRF architecture proposed by Ma and Hovy (2016); Lample et al. (2016); Huang et al. (2015).1 It combines a double representation of the input words by using word embeddings and a character-based representation (with CNNs). The input sequence is processed with bi-LSTMs, and the output layer is a linear chain CRF. The model uses the following. Word-level embeddings allow the learning algorithms to use large unlabeled data to generalize beyond the seen training data. We explore randomly initialized embeddings based on the seen training data and pre-trained embedding. Brown clusters (BC) Brown clustering is an unsupervised learning method wher"
W18-3212,W03-0430,0,0.336463,"Missing"
W19-4603,J92-4003,0,0.551827,"Missing"
W19-4603,W16-5801,0,0.0290695,"Missing"
W19-4603,P13-2037,0,0.0590321,"Missing"
W19-4603,W16-5812,0,0.0243184,"is relatively less challenging for computational analysis, as each sentence still follows a monolingual model, intrasentential CS poses a bottleneck challenge. It needs a special amount of attention, because it is only this type that involves the lexical and syntactic integration and activation of two language models at the same time. NLP systems trained on monolingual data suffer significantly when trying to process this kind bilingual text or utterance. CS has proved challenging for NLP technologies, not only because current tools are geared toward the processing of one language at a time (AlGhamdi et al., 2016), but also because codeswitched data is typically associated with additional challenges such as the non-conventional orthography, non-canonicity (nonstandard or incomplete) of syntactic structures, and the large number of OOV-words (Çetino˘glu et al., 2016), which suggest the need for larger training data than what is typically used in monolingual models. Unfortunately, shortage of training data has usually been cited as the reason for the under-performance of 19 diglossic code-switching, the shift is more likely to be lexical, morphological, and structural, rather than phonological, unlike th"
W19-4603,C12-2011,1,0.885038,"Missing"
W19-4603,Q16-1026,0,0.0173957,"nsure that we get representations of all the words and reduce the number of OOVs (out of vocabulary words). We find significant improvement using FastText embedding over the traditional word2vec representation (Mikolov et al., 2013). This is probably due to the utilization of sub-word (ex. prefixes or suffixes) information in the former. Character-level CNNs. Although originally designed for image recognition, CNNs have proven effective for various NLP tasks due to their ability to encode character-level representations of words as well as extract sub-word information (Collobert et al., 2011; Chiu and Nichols, 2016; dos Santos and Guimarães, 2015). Bi-LSTM Recurrent neural networks (RNN) are well suited for modeling sequential data, achieving ground-breaking results in many NLP tasks (e.g., machine translation). BiLSTMs (Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) are capable of learning long-term dependencies and maintaining contextual features from both past and future states while avoiding the vanishing/exploding gradients problem. They consist of two separate bidirectional hidden layers that feed forward to the same output layer. Figure 3: DNN Architecture. BCs on our crawled code-"
W19-4603,attia-etal-2010-automatically,1,0.834799,"Missing"
W19-4603,L18-1015,1,0.899707,"Missing"
W19-4603,W14-3901,0,0.0289644,"tagging of CS data and concluded that applying a machine learning framework as a voting mechanism on top of the output of two monolingual POS taggers achieves the best performance. Word-level CS identification for Arabic (along with Spanish–English) has been featured in a couple of shared tasks: the First Shared Task on Language Identification in CodeSwitched Data (Solorio et al., 2014) and the Second Shared Task on Language Identification in Code-Switched Data (Molina et al., 2016), of which Samih et al. (2016) was the winning system, and against which we compare our results in this project. Eskander et al. (2014) studied CS between EA written in Roman script (Arabizi) and English. Habash et al. (2008) created a standard annotation guidelines for CS between MSA and dialects. CS has also been studied in Arabic as a predictor of social influence in the collaborative writing in Wikipedia discussion pages in (Yoder et al., 2017) and it was found that CS is positively associated with the editor’s success in winning an argument. We notice from the literature that in some instances POS tagging has been used to aid with the identification of code-switching points, and in some other instances language identific"
W19-4603,Q17-1010,0,0.0325773,"Missing"
W19-4603,N13-1039,0,0.0935945,"Missing"
W19-4603,C82-1023,0,0.578981,"tactic rules of the two languages involved, sometime adding in or leaving out a determiner, or applying a system of affixation from one language and not the other. 1.2 Definition and Defining Perspectives The definition of CS has varied greatly depending on the different researchers’ attitude and perspectives of the operation involved. While some viewed it as a process where two languages are actively interacting with each other (ultimately creating a new code), other viewed the operation just as two separate languages sitting side-by-side as isolated islands. Following the first perspective, Joshi (1982) defined code-switching as the situation when two languages systematically interact with each other in the production of sentences in a framework which consists of two grammatical systems and a mechanism for switching between the two. Following the second perspective, Muysken (1995) defined CS as “the alternative use by bilinguals of two or more languages in the same conversation”, while other researchers (Auer, 1999; Nilep, 2006) defined it as the “juxtaposition” of elements from two different grammatical systems within the same speech. The juxtaposition definition has been widely cited in th"
W19-4603,N16-1030,0,0.01,"®K A£ É¯ BA« System Description Deep learning and neural nets have been used extensively in the past decade and were shown to significantly outperform traditional (linear) ML models. The proclaimed advantage of deep learning is that it eliminates the need for feature engineering. Yet, there has been a growing interest recently to augment neural nets with more and more linguistic features, which has been shown to boost performance for many tasks. We use a DNN (Deep Neural Network) model mainly suited for sequence tagging and is a variant of the bi-LSTM-CRF architecture (Ma and Hovy, 2016; Lample et al., 2016; Reimers and Gurevych, 2017; Huang et al., 2015). Our implementation is mostly inspired by the work of Reimers and Gurevych (2017). In its basic configuration, it combines a double representation of the input words by using word embeddings and a character-based representation with CNNs (convolutional Neural Networks). The input sequence is processed with bi-LSTMs, and the output layer is a linear chain CRF. We augment this model with various layers to accommodate the different features we want to incorporate. The features used in our model are explained below. 4.1 Translit. / Gloss byHbk Fine"
W19-4603,D17-1035,0,0.0140169,"tem Description Deep learning and neural nets have been used extensively in the past decade and were shown to significantly outperform traditional (linear) ML models. The proclaimed advantage of deep learning is that it eliminates the need for feature engineering. Yet, there has been a growing interest recently to augment neural nets with more and more linguistic features, which has been shown to boost performance for many tasks. We use a DNN (Deep Neural Network) model mainly suited for sequence tagging and is a variant of the bi-LSTM-CRF architecture (Ma and Hovy, 2016; Lample et al., 2016; Reimers and Gurevych, 2017; Huang et al., 2015). Our implementation is mostly inspired by the work of Reimers and Gurevych (2017). In its basic configuration, it combines a double representation of the input words by using word embeddings and a character-based representation with CNNs (convolutional Neural Networks). The input sequence is processed with bi-LSTMs, and the output layer is a linear chain CRF. We augment this model with various layers to accommodate the different features we want to incorporate. The features used in our model are explained below. 4.1 Translit. / Gloss byHbk Fine Tag prog_part Coarse Tag Ve"
W19-4603,P08-2030,0,0.104649,"Missing"
W19-4603,P16-1101,0,0.0119628,".j K. QÒªË@ð J.Ê¯ ®K A£ É¯ BA« System Description Deep learning and neural nets have been used extensively in the past decade and were shown to significantly outperform traditional (linear) ML models. The proclaimed advantage of deep learning is that it eliminates the need for feature engineering. Yet, there has been a growing interest recently to augment neural nets with more and more linguistic features, which has been shown to boost performance for many tasks. We use a DNN (Deep Neural Network) model mainly suited for sequence tagging and is a variant of the bi-LSTM-CRF architecture (Ma and Hovy, 2016; Lample et al., 2016; Reimers and Gurevych, 2017; Huang et al., 2015). Our implementation is mostly inspired by the work of Reimers and Gurevych (2017). In its basic configuration, it combines a double representation of the input words by using word embeddings and a character-based representation with CNNs (convolutional Neural Networks). The input sequence is processed with bi-LSTMs, and the output layer is a linear chain CRF. We augment this model with various layers to accommodate the different features we want to incorporate. The features used in our model are explained below. 4.1 Transli"
W19-4603,W16-5806,1,0.944761,"abels ambiguous unk lang1 lang2 mixed ne other et al. (2016) explored different technique for the POS tagging of CS data and concluded that applying a machine learning framework as a voting mechanism on top of the output of two monolingual POS taggers achieves the best performance. Word-level CS identification for Arabic (along with Spanish–English) has been featured in a couple of shared tasks: the First Shared Task on Language Identification in CodeSwitched Data (Solorio et al., 2014) and the Second Shared Task on Language Identification in Code-Switched Data (Molina et al., 2016), of which Samih et al. (2016) was the winning system, and against which we compare our results in this project. Eskander et al. (2014) studied CS between EA written in Roman script (Arabizi) and English. Habash et al. (2008) created a standard annotation guidelines for CS between MSA and dialects. CS has also been studied in Arabic as a predictor of social influence in the collaborative writing in Wikipedia discussion pages in (Yoder et al., 2017) and it was found that CS is positively associated with the editor’s success in winning an argument. We notice from the literature that in some instances POS tagging has been use"
W19-4603,W16-5805,0,0.0180421,"themselves, but our results show that words still give a stronger signal than POS tags alone. We also notice that Brown Clusters, named entity gazetteers and FastText pre-trained embeddings contribute to incrementally improve the performance of the system. Unfortunately adding information from the spelling word list did not show any improvement on the system, and this is why it is removed from the final system architecture. Now we compare our best model to the state-ofthe-art system of Samih et al. (2016), which won the 2016 Second Shared Task on Language Identification in Code-Switched Data (Molina et al., 2016) on the MSA–EA dataset. We compare the performance of the two systems in terms of f-score accuracy on both the development and test set, in Table 5 and Table 6 respectively. We also include the number of instances and the ratio percentage for each label. As the tables show, the category lang2 constitutes the majority class for both úÍ@ <ilY “to”, which can equally be used as either lang1 or lang2, depending on the context. 6 Conclusion We have presented a neural network system for conducting word-level code-switching identification. Our system outperforms the current stateof-the-art, and we sh"
W19-4603,W15-3904,0,0.0125713,"tions of all the words and reduce the number of OOVs (out of vocabulary words). We find significant improvement using FastText embedding over the traditional word2vec representation (Mikolov et al., 2013). This is probably due to the utilization of sub-word (ex. prefixes or suffixes) information in the former. Character-level CNNs. Although originally designed for image recognition, CNNs have proven effective for various NLP tasks due to their ability to encode character-level representations of words as well as extract sub-word information (Collobert et al., 2011; Chiu and Nichols, 2016; dos Santos and Guimarães, 2015). Bi-LSTM Recurrent neural networks (RNN) are well suited for modeling sequential data, achieving ground-breaking results in many NLP tasks (e.g., machine translation). BiLSTMs (Hochreiter and Schmidhuber, 1997; Schuster and Paliwal, 1997) are capable of learning long-term dependencies and maintaining contextual features from both past and future states while avoiding the vanishing/exploding gradients problem. They consist of two separate bidirectional hidden layers that feed forward to the same output layer. Figure 3: DNN Architecture. BCs on our crawled code-switched corpus of 380 million wo"
W19-4603,N16-1159,0,0.025454,"Missing"
W19-4603,D08-1102,0,0.0258644,"Missing"
W19-4603,D08-1110,0,0.107844,"Missing"
W19-4603,W15-1511,0,0.061289,"Missing"
W19-4603,W15-2902,0,0.0329637,"Missing"
W19-4603,W17-2911,0,0.0157523,"n Language Identification in CodeSwitched Data (Solorio et al., 2014) and the Second Shared Task on Language Identification in Code-Switched Data (Molina et al., 2016), of which Samih et al. (2016) was the winning system, and against which we compare our results in this project. Eskander et al. (2014) studied CS between EA written in Roman script (Arabizi) and English. Habash et al. (2008) created a standard annotation guidelines for CS between MSA and dialects. CS has also been studied in Arabic as a predictor of social influence in the collaborative writing in Wikipedia discussion pages in (Yoder et al., 2017) and it was found that CS is positively associated with the editor’s success in winning an argument. We notice from the literature that in some instances POS tagging has been used to aid with the identification of code-switching points, and in some other instances language identification has been used as an indicator or a feature for POS tagging, showing what (Çetino˘glu et al., 2016) referred to as task inter-relatedness, or the cyclic nature of task dependencies. In our work, we use a POS tagger as a predictor of CS. The POS tagger used has been trained specifically on CS data. 3 Token Count"
W19-4613,N16-3003,0,0.155495,"3.4 The definite article dilemma Our segmentation convention matches with (Aliwy, 2012; Mohamed, 2018; Habash et al., 2012) where clitics are split from words and the of notion of clitics is aligned as the syntactic units that can be assigned a POS tag and can occupy a node on the syntactic tree. It is also similar to the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) with the exception of the definite article where we consider it as a clitic while in the ATB it is taken as a definiteness marker. However, the segmentation scheme adopted here is significantly different from that of Farasa (Abdelali et al., 2016; Samih et al., 2017a,b; Eldesouki et al., 2017) in a number of ways. While Farasa segments all clitics as we do, they also split a number of additional morphemes as follows: Arabic has only one determiner, the definite article È@ Al “the”. However, different conventions conflicted on whether to consider it as a morphological marker or a syntactic unit (clitic). While all other clitics have some free-form counterparts of their own category, e.g. ð wa “and” (a bound Õç' vum~a “then” (a free conjunc “in” (a bound preposition), and ú¯ conjunction), tion), H. bi fiy “in” (a free preposition), the"
W19-4613,N13-1044,0,0.0589632,"Missing"
W19-4613,C12-2011,1,0.809523,"Missing"
W19-4613,D14-1082,0,0.0138041,"evaluate both systems on the MSA and EG test sets. • Word length and position within a word • First and last two characters of the current word Our segmenter is part of a dependency tree parser for Arabic. Computational implementation within the Dependency Grammars framework has been realized in the creation of dependency treebanks, such as the Prague Dependency Treebank (Hajiˇc et al., 2001), the Stanford Dependencies (De Marneffe and Manning, 2008) and Universal Dependencies (Nivre et al., 2016; McDonald et al., 2013), and the development of dependency parsers, such as the Stanford parser (Chen and Manning, 2014), the inductive dependency parser (Nivre et al., 2004) and the MaltParser (Nivre et al., 2007). A dependency parser complies with the Dependency Grammar formalisms. Within the Dependency Grammar, dependency relations can be represented either in a relational format or in a graph format. In a relational format, the representation is a triple which shows the relation between a pair of words. The head of the dependency relation is given as the first argument and the dependent as the second. This relationship is represented as follows: Model trained on segmentation data from MSA MSA+EG , nsubj(Qå"
W19-4613,W08-1301,0,0.018631,"re we build two models, one using the MSA data alone, and the other using MSA data combined with the Egyptian (EG) dialectal segmentation training data, and we evaluate both systems on the MSA and EG test sets. • Word length and position within a word • First and last two characters of the current word Our segmenter is part of a dependency tree parser for Arabic. Computational implementation within the Dependency Grammars framework has been realized in the creation of dependency treebanks, such as the Prague Dependency Treebank (Hajiˇc et al., 2001), the Stanford Dependencies (De Marneffe and Manning, 2008) and Universal Dependencies (Nivre et al., 2016; McDonald et al., 2013), and the development of dependency parsers, such as the Stanford parser (Chen and Manning, 2014), the inductive dependency parser (Nivre et al., 2004) and the MaltParser (Nivre et al., 2007). A dependency parser complies with the Dependency Grammar formalisms. Within the Dependency Grammar, dependency relations can be represented either in a relational format or in a graph format. In a relational format, the representation is a triple which shows the relation between a pair of words. The head of the dependency relation is"
W19-4613,N04-4038,0,0.265107,"Missing"
W19-4613,mohamed-etal-2012-annotating,0,0.056944,"Missing"
W19-4613,P14-2034,0,0.0228092,"Missing"
W19-4613,W12-2301,0,0.161946,"s, conjunctions, pronouns and particles) with separate part of speech functions, but happen  A® K ©K. P AK. HñË@ ú Î« Eal~i al-Suwt bi-&gt;arbaE niqaT “Raise volume by-five points”. Type of attached argument: numeric value 5. Local directions: 121 • 3.3 Ï@  J.Ë@ á  K. é¯AÖ ÉÒªË@ð I cases, partcularly when the noun is preceded by a vocative particle, e.g. úæJ  AK yA sisi “O, Sisi”. al-masafap bayn al-bayt wa-al-Eamal “distance between home and-work”. Type of attached argument: location 3.4 The definite article dilemma Our segmentation convention matches with (Aliwy, 2012; Mohamed, 2018; Habash et al., 2012) where clitics are split from words and the of notion of clitics is aligned as the syntactic units that can be assigned a POS tag and can occupy a node on the syntactic tree. It is also similar to the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) with the exception of the definite article where we consider it as a clitic while in the ATB it is taken as a definiteness marker. However, the segmentation scheme adopted here is significantly different from that of Farasa (Abdelali et al., 2016; Samih et al., 2017a,b; Eldesouki et al., 2017) in a number of ways. While Farasa segments all clitic"
W19-4613,W03-3017,0,0.111092,"74 tokens) and includes news articles (covering politics, sports, entertainment, business, health, sci-tech, arts), Wikipedia articles web articles (including blogs, forums, reviews). 3. Run the dialectal and standard segmenters on the dialect test set, evaluate how many words are shared with the dialect and MSA, and check the impact on the POS tagger. Hopefully the output of the model with dialectal data will have more shared lexicon with the Arabic standard dataset and improved POS tagging score. 6 System Description In our experiments we use an arc-eager transition based dependency parser (Nivre, 2003) with a model trained using a linear SVM architecture similar to the one in Yamada and Matsumoto 1 edit distance / (len(substr1)+len(substr2)/2) * 100 As implemented in the SequenceMatcher in the difflib library 2 125 Similarly, in the graph representation the dependency arc points from the head category to the dependent category, and the relation (or grammatical function) is realized as a label on the arc as shown in Figure 5. (2003). When experimenting with morphological features, we add the morphological attributes for both stack-top and buffer-top tokens. Features: • A window of +/- 3 char"
W19-4613,P05-1071,0,0.173713,"Missing"
W19-4613,W04-2407,0,0.0164447,"Missing"
W19-4613,L16-1262,0,0.0311102,"Missing"
W19-4613,W17-1306,1,0.857369,"e dilemma Our segmentation convention matches with (Aliwy, 2012; Mohamed, 2018; Habash et al., 2012) where clitics are split from words and the of notion of clitics is aligned as the syntactic units that can be assigned a POS tag and can occupy a node on the syntactic tree. It is also similar to the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) with the exception of the definite article where we consider it as a clitic while in the ATB it is taken as a definiteness marker. However, the segmentation scheme adopted here is significantly different from that of Farasa (Abdelali et al., 2016; Samih et al., 2017a,b; Eldesouki et al., 2017) in a number of ways. While Farasa segments all clitics as we do, they also split a number of additional morphemes as follows: Arabic has only one determiner, the definite article È@ Al “the”. However, different conventions conflicted on whether to consider it as a morphological marker or a syntactic unit (clitic). While all other clitics have some free-form counterparts of their own category, e.g. ð wa “and” (a bound Õç' vum~a “then” (a free conjunc “in” (a bound preposition), and ú¯ conjunction), tion), H. bi fiy “in” (a free preposition), the definite article is"
W19-4613,K17-1043,1,0.828339,"e dilemma Our segmentation convention matches with (Aliwy, 2012; Mohamed, 2018; Habash et al., 2012) where clitics are split from words and the of notion of clitics is aligned as the syntactic units that can be assigned a POS tag and can occupy a node on the syntactic tree. It is also similar to the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) with the exception of the definite article where we consider it as a clitic while in the ATB it is taken as a definiteness marker. However, the segmentation scheme adopted here is significantly different from that of Farasa (Abdelali et al., 2016; Samih et al., 2017a,b; Eldesouki et al., 2017) in a number of ways. While Farasa segments all clitics as we do, they also split a number of additional morphemes as follows: Arabic has only one determiner, the definite article È@ Al “the”. However, different conventions conflicted on whether to consider it as a morphological marker or a syntactic unit (clitic). While all other clitics have some free-form counterparts of their own category, e.g. ð wa “and” (a bound Õç' vum~a “then” (a free conjunc “in” (a bound preposition), and ú¯ conjunction), tion), H. bi fiy “in” (a free preposition), the definite article is"
W19-4613,W03-3023,0,0.118407,"Missing"
W19-4639,W18-3930,0,0.112038,"Missing"
W19-4639,W16-4818,0,0.0429729,"Missing"
W19-4639,E17-2068,0,0.0808269,"Missing"
W19-4639,W14-3601,1,0.945204,"Missing"
W19-4639,C18-1113,0,0.0919411,"Missing"
W19-4639,K17-1043,1,0.900152,"Missing"
W19-4639,L16-1658,1,0.898269,"Missing"
W19-4639,P11-2007,0,0.0851928,"Missing"
W19-4639,J14-1006,0,0.163523,"2016). The wide spread of dialectal use has increased the richness and diversity of the language, requiring greater complexity in dealing with it. Non-standard orthography, increased borrowing and coinage of new terms, and code switching are just a few among a long list of new challenges researchers have to deal with. Studying language varieties in particular is associated with important applications such as Dialect Identification (DID), Machine Translation (MT), and other text mining tasks. Performing DID can be achieved using a variety of features, such as character n-grams (Darwish, 2014; Zaidan and Callison-Burch, 2014; Malmasi et al., 2015), and a myriad of techniques, such as 2 System descriptions For both SubTask 1 and SubTask 2, we employed a hybrid system that incorporates different classifiers and components such DNNs and heuristics to perform sentence level dialectal Arabic identification. The classification strategy is built as a cascaded voting system that tags each sequence based on the decisions from two other underlying classifiers. DNNs: This model uses both Bidirectional Long Short Term Memory (Bi-LSTM) and Convolutional Neural Network (CNN) architectures to jointly learn both word-level and c"
