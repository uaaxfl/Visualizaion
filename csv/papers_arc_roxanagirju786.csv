S18-1057,{UIUC} at {S}em{E}val-2018 Task 1: Recognizing Affect with Ensemble Models,2018,0,1,2,0,28788,abhishek narwekar,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"Our submission to the SemEval-2018 Task1: Affect in Tweets shared task competition is a supervised learning model relying on standard lexicon features coupled with word embedding features. We used an ensemble of diverse models, including random forests, gradient boosted trees, and linear models, corrected for training-development set mismatch. We submitted the system{'}s output for subtasks 1 (emotion intensity prediction), 2 (emotion ordinal classification), 3 (valence intensity regression) and 4 (valence ordinal classification), for English tweets. We placed 25th, 19th, 24th and 15th in the four subtasks respectively. The baseline considered was an SVM (Support Vector Machines) model with linear kernel on the lexicon and embedding based features. Our system{'}s final performance measured in Pearson correlation scores outperformed the baseline by a margin of 2.2{\%} to 14.6{\%} across all tasks."
N16-1047,Psycholinguistic Features for Deceptive Role Detection in Werewolf,2016,7,3,2,0,34680,codruta girlea,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
W15-0806,Detecting Causally Embedded Structures Using an Evolutionary Algorithm,2015,-1,-1,2,0,9098,chen li,"Proceedings of the The 3rd Workshop on {EVENTS}: Definition, Detection, Coreference, and Representation",0,None
W14-4920,Interactive Annotation for Event Modality in Modern Standard and {E}gyptian {A}rabic Tweets,2014,21,0,2,1,38353,rania alsabbagh,Proceedings of {LAW} {VIII} - The 8th Linguistic Annotation Workshop,0,"We present an interactive procedure to annotate a large-scale corpus of Modern Standard and Egyptian Arabic tweets for event modality that comprises obligation, permission, commitment, ability, and volition. The procedure splits up the annotation process into a series of simplified questions, dispenses with the requirement of expert linguistic knowledge, and captures nested modality triggers and their attributes semi-automatically."
W14-4322,In-depth Exploitation of Noun and Verb Semantics to Identify Causation in Verb-Noun Pairs,2014,22,6,2,1,38446,mehwish riaz,Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue ({SIGDIAL}),0,"Recognition of causality is important to achieve natural language discourse understanding. Previous approaches rely on shallow linguistic features. In this work, we propose to identify causality in verbnoun pairs by exploiting deeper semantics of nouns and verbs. Particularly, we acquire and employ three novel types of knowledge: (1) semantic classes of nouns with a high and low tendency to encode causality along with information regarding metonymies, (2) data-driven semantic classes of verbal events with the least tendency to encode causality, and (3) tendencies of verb frames to encode causality. Using these knowledge sources, we achieve around 15% improvement in Fscore over a supervised classifier trained using linguistic features."
W14-0820,Unsupervised Construction of a Lexicon and a Repository of Variation Patterns for {A}rabic Modal Multiword Expressions,2014,19,3,2,1,38353,rania alsabbagh,Proceedings of the 10th Workshop on Multiword Expressions ({MWE}),0,We present an unsupervised approach to build a lexicon of Arabic Modal Multiword Expressions (AM-MWEs) and a repository of their variation patterns. These novel resources are likely to boost the automatic identification and extraction of AM-MWEs 1 .
W14-0707,Recognizing Causality in Verb-Noun Pairs via Noun and Verb Semantics,2014,20,20,2,1,38446,mehwish riaz,Proceedings of the {EACL} 2014 Workshop on Computational Approaches to Causality in Language ({CA}to{CL}),0,"Several supervised approaches have been proposed for causality identification by relying on shallow linguistic features. However, such features do not lead to improved performance. Therefore, novel sources of knowledge are required to achieve progress on this problem. In this paper, we propose a model for the recognition of causality in verb-noun pairs by employing additional types of knowledge along with linguistic features. In particular, we focus on identifying and employing semantic classes of nouns and verbs with high tendency to encode cause or non-cause relations. Our model incorporates the information about these classes to minimize errors in predictions made by a basic supervised classifier relying merely on shallow linguistic features. As compared with this basic classifier our model achieves 14.74% (29.57%) improvement in F-score (accuracy), respectively."
C14-1144,3arif: A Corpus of Modern Standard and {E}gyptian {A}rabic Tweets Annotated for Epistemic Modality Using Interactive Crowdsourcing,2014,16,2,2,1,38353,rania alsabbagh,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"We present 3arif 1 , a large-scale corpus of Modern Standard and Egyptian Arabic tweets annotated for epistemic modality 2 . To create 3arif , we design an interactive crowdsourcing annotation procedure that splits up the annotation process into a series of simplified questions, dispenses with the requirement for expert linguistic knowledge and captures nested modality triggers and their attributes semiautomatically."
W13-4004,Toward a Better Understanding of Causality between Verbal Events: Extraction and Analysis of the Causal Power of Verb-Verb Associations,2013,22,21,2,1,38446,mehwish riaz,Proceedings of the {SIGDIAL} 2013 Conference,0,"The identification of causal relations between verbal events is important for achieving natural language understanding. However, the problem has proven notoriously difficult since it is not clear which types of knowledge are necessary to solve this challenging problem close to human level performance. Instead of employing a large set of features proved useful in other NLP tasks, we split the problem in smaller sub problems. Since verbs play a very important role in causal relations, in this paper we harness, explore, and evaluate the predictive power of causal associations of verb-verb pairs. More specifically, we propose a set of knowledge-rich metrics to learn the likelihood of causal relations between verbs. Employing these metrics, we automatically generate a knowledge base (KBc) which identifies three categories of verb pairs: Strongly Causal, Ambiguous, and Strongly Non-causal. The knowledge base is evaluated empirically. The results show that our metrics perform significantly better than the state-of-the-art on the task of detecting causal verbal events."
I13-1047,Using the Semantic-Syntactic Interface for Reliable {A}rabic Modality Annotation,2013,18,9,3,1,38353,rania alsabbagh,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"We introduce a novel modality scheme where triggers are words and phrases that convey modality meanings and subcategorize for clauses and verbal phrases. This semanticsyntactic working definition of modality enables us to design practical and replicable annotation guidelines and procedures that alleviate some shortcomings of current purely semantic modality annotation schemes and yield high inter-annotator agreement rates. We use this scheme to annotate a tweet-based Arabic corpus for modality information. This novel language resource, being the first, initiates NLP research on Arabic modality."
al-sabbagh-girju-2012-yadac,{YADAC}: Yet another Dialectal {A}rabic Corpus,2012,5,37,2,1,38353,rania alsabbagh,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"This paper presents the first phase of building YADAC â a multi-genre Dialectal Arabic (DA) corpus â that is compiled using Web data from microblogs (i.e. Twitter), blogs/forums and online knowledge market services in which both questions and answers are user-generated. In addition to introducing two new genres to the current efforts of building DA corpora (i.e. microblogs and question-answer pairs extracted from online knowledge market services), the paper highlights and tackles several new issues related to building DA corpora that have not been handled in previous studies: function-based Web harvesting and dialect identification, vowel-based spelling variation, linguistic hypercorrection and its effect on spelling variation, unsupervised Part-of-Speech (POS) tagging and base phrase chunking for DA. Although the algorithms for both POS tagging and base-phrase chunking are still under development, the results are promising."
al-sabbagh-girju-2010-mining,Mining the Web for the Induction of a Dialectical {A}rabic Lexicon,2010,7,21,2,1,38353,rania alsabbagh,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper describes the first phase of building a lexicon of Egyptian Cairene Arabic (ECA) â one of the most widely understood dialects in the Arab World â and Modern Standard Arabic (MSA). Each ECA entry is mapped to its MSA synonym, Part-of-Speech (POS) tag and top-ranked contexts based on Web queries; and thus each entry is provided with basic syntactic and semantic information for a generic lexicon compatible with multiple NLP applications. Moreover, through their MSA synonyms, ECA entries acquire access to MSA available NLP tools and resources which are considerably available. Using an associationist approach based on the correlations between word co-occurrence patterns in both dialects, we change the direction of the acquisition process from parallel to circular to overcome a bottleneck of current research on Arabic dialects, namely the lack of parallel corpora, and to alleviate accuracy rates for using unrelated Web documents which are more frequently available. Manually evaluated for 1,000 word entries by two native speakers of the ECA-MSA varieties, the proposed approach achieves a promising F-measured performance rate of 70.9{\%}. In discussion to the proposed algorithm, different semantic issues are highlighted for upcoming phases of the induction of a more comprehensive ECA-MSA lexicon."
D10-1007,Summarizing Contrastive Viewpoints in Opinionated Text,2010,26,121,3,0.25478,12388,michael paul,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a two-stage approach to summarizing multiple contrastive viewpoints in opinionated text. In the first stage, we use an unsupervised probabilistic approach to model and extract multiple viewpoints in text. We experiment with a variety of lexical and syntactic features, yielding significant performance gains over bag-of-words feature sets. In the second stage, we introduce Comparative LexRank, a novel random walk formulation to score sentences and pairs of sentences from opposite viewpoints based on both their representativeness of the collection as well as their contrastiveness with each other. Experimental results show that the proposed approach can generate informative summaries of viewpoints in opinionated text."
W09-1111,Mining the Web for Reciprocal Relationships,2009,19,7,2,0.25478,12388,michael paul,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL}-2009),0,"In this paper we address the problem of identifying reciprocal relationships in English. In particular we introduce an algorithm that semi-automatically discovers patterns encoding reciprocity based on a set of simple but effective pronoun templates. Using a set of most frequently occurring patterns, we extract pairs of reciprocal pattern instances by searching the web. Then we apply two unsupervised clustering procedures to form meaningful clusters of such reciprocal instances. The pattern discovery procedure yields an accuracy of 97%, while the clustering procedures indicate accuracies of 91% and 82%. Moreover, the resulting set of 10,882 reciprocal instances represent a broad-coverage resource."
W09-1115,Investigating Automatic Alignment Methods for Slide Generation from Academic Papers,2009,10,10,2,0,47054,brandon beamer,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL}-2009),0,"In this paper we investigate the task of automatic generation of slide presentations from academic papers, focusing initially on slide to paper alignment. We compare and evaluate four different alignment systems which utilize various combinations of methods used widely in other alignment and question answering approaches, such as TF-IDF term weighting and query expansion. Our best aligner achieves an accuracy of 75% and our findings show that for this application, average TF-IDF scoring performs more poorly than a simpler method based on the number of matched terms, and query expansion degrades aligner performance."
R09-1061,Topic Modeling of Research Fields: An Interdisciplinary Perspective,2009,9,18,2,0.25478,12388,michael paul,Proceedings of the International Conference {RANLP}-2009,0,"This paper addresses the problem of scientific research analysis. We use the topic model Latent Dirichlet Allocation [2] and a novel classifier to classify research papers based on topic and language. Moreover, we show various insightful statistics and correlations within and across three research fields: Linguistics, Computational Linguistics, and Education. In particular, we show how topics change over time within each field, what relations and influences exist between topics within and across fields, as well as what trends can be established for some of the worldxe2x80x99s natural languages. Finally, we talk about trend prediction and topic suggestion as future extensions of this research."
R09-1069,Identifying Semantic Relations in Context: Near-misses and Overlaps,2009,21,0,2,0,8356,alla rozovskaya,Proceedings of the International Conference {RANLP}-2009,0,"This paper addresses the problem of semantic relation identification for a set of relations difficult to differentiate: near-misses and overlaps. Based on empirical observations on a fairly large dataset of such examples we provide an analysis and a taxonomy of such cases. Using this taxonomy we create various contingency sets of relations. These semantic categories are automatically identified by training and testing three state-of-the-art semantic classifiers employing various feature sets. The results show that in order to identify such near-misses and overlaps accurately, a semantic relation identification system needs to go beyond the ontological information of the two nouns and rely heavily on contextual and pragmatic knowledge."
J09-2003,The Syntax and Semantics of Prepositions in the Task of Automatic Interpretation of Nominal Phrases and Compounds: A Cross-Linguistic Study,2009,64,19,1,1,28789,roxana girju,Computational Linguistics,0,"In this article we explore the syntactic and semantic properties of prepositions in the context of the semantic interpretation of nominal phrases and compounds. We investigate the problem based on cross-linguistic evidence from a set of six languages: English, Spanish, Italian, French, Portuguese, and Romanian. The focus on English and Romance languages is well motivated. Most of the time, English nominal phrases and compounds translate into constructions of the form N P N in Romance languages, where the P (preposition) may vary in ways that correlate with the semantics. Thus, we present empirical observations on the distribution of nominal phrases and compounds and the distribution of their meanings on two different corpora, based on two state-of-the-art classification tag sets: Lauer's set of eight prepositions and our list of 22 semantic relations. A mapping between the two tag sets is also provided. Furthermore, given a training set of English nominal phrases and compounds along with their translations in the five Romance languages, our algorithm automatically learns classification rules and applies them to unseen test instances for semantic interpretation. Experimental results are compared against two state-of-the-art models reported in the literature."
D09-1146,Cross-Cultural Analysis of Blogs and Forums with Mixed-Collection Topic Models,2009,20,70,2,0.25478,12388,michael paul,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents preliminary results on the detection of cultural differences from people's experiences in various countries from two perspectives: tourists and locals. Our approach is to develop probabilistic models that would provide a good framework for such studies. Thus, we propose here a new model, ccLDA, which extends over the Latent Dirichlet Allocation (LDA) (Blei et al., 2003) and cross-collection mixture (ccMix) (Zhai et al., 2004) models on blogs and forums. We also provide a qualitative and quantitative analysis of the model on the cross-cultural data."
2009.mtsummit-plenaries.4,Panel Summary: Educating and Assessing the Human Translator in an Age of Technology,2009,-1,-1,2,0,47476,patricia phillipsbatoma,Proceedings of Machine Translation Summit XII: Plenaries,0,None
J08-4006,Book Review: Mathematical Linguistics by Andr{\\'a}s Kornai,2008,-1,-1,2,0,6614,richard sproat,Computational Linguistics,0,None
W07-1527,Experiments with an Annotation Scheme for a Knowledge-rich Noun Phrase Interpretation System,2007,23,5,1,1,28789,roxana girju,Proceedings of the Linguistic Annotation Workshop,0,"This paper presents observations on our experience with an annotation scheme that was used in the training of a state-of-the-art noun phrase semantic interpretation system. The system relies on cross-linguistic evidence from a set of five Romance languages: Spanish, Italian, French, Portuguese, and Romanian. Given a training set of English noun phrases in context along with their translations in the five Romance languages, our algorithm automatically learns a classification function that is later on applied to unseen test instances for semantic interpretation. As training and test data we used two text collections of different genre: Europarl and CLUVI. The training data was annotated with contextual features based on two state-of-the-art classification tag sets."
S07-1003,{S}em{E}val-2007 Task 04: Classification of Semantic Relations between Nominals,2007,14,148,1,1,28789,roxana girju,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"The NLP community has shown a renewed interest in deeper semantic analyses, among them automatic recognition of relations between pairs of words in a text. We present an evaluation task designed to provide a framework for comparing different approaches to classifying semantic relations between nominals in a sentence. This is part of SemEval, the 4th edition of the semantic evaluation event previously known as SensEval. We define the task, describe the training/test data and their creation, list the participating systems and discuss their results. There were 14 teams who submitted 15 systems."
S07-1085,{UIUC}: A Knowledge-rich Approach to Identifying Semantic Relations between Nominals,2007,11,29,6,0,47054,brandon beamer,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes a supervised, knowledge-intensive approach to the automatic identification of semantic relations between nominals in English sentences. The system employs different sets of new and previously used lexical, syntactic, and semantic features extracted from various knowledge sources. At SemEval 2007 the system achieved an F-measure of 72.4% and an accuracy of 76.3%."
P07-1072,Improving the Interpretation of Noun Phrases with Cross-linguistic Information,2007,16,31,1,1,28789,roxana girju,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"This paper addresses the automatic classification of semantic relations in noun phrases based on cross-linguistic evidence from a set of five Romance languages. A set of novel semantic and contextual Englishxe2x80x90 Romance NP features is derived based on empirical observations on the distribution of the syntax and meaning of noun phrases on two corpora of different genre (Europarl and CLUVI). The features were employed in a Support Vector Machines algorithm which achieved an accuracy of 77.9% (Europarl) and 74.31% (CLUVI), an improvement compared with two state-of-the-art models reported in the literature."
J06-1005,Automatic Discovery of Part-Whole Relations,2006,41,226,1,1,28789,roxana girju,Computational Linguistics,0,"An important problem in knowledge discovery from text is the automatic extraction of semantic relations. This paper presents a supervised, semantically intensive, domain independent approach for the automatic detection of part-whole relations in text. First an algorithm is described that identifies lexico-syntactic patterns that encode part-whole relations. A difficulty is that these patterns also encode other semantic relations, and a learning method is necessary to discriminate whether or not a pattern contains a part-whole relation. A large set of training examples have been annotated and fed into a specialized learning system that learns classification rules. The rules are learned through an iterative semantic specialization (ISS) method applied to noun phrase constituents. Classification rules have been generated this way for different patterns such as genitives, noun compounds, and noun phrases containing prepositional phrases to extract part-whole relations from them. The applicability of these rules has been tested on a test corpus obtaining an overall average precision of 80.95% and recall of 75.91%. The results demonstrate the importance of word sense disambiguation for this task. They also demonstrate that different lexico-syntactic patterns encode different semantic information and should be treated separately in the sense that different clarification rules apply to different patterns."
W04-2609,Models for the Semantic Classification of Noun Phrases,2004,19,105,5,0.455793,16607,dan moldovan,Proceedings of the Computational Lexical Semantics Workshop at {HLT}-{NAACL} 2004,0,"This paper presents an approach for detecting semantic relations in noun phrases. A learning algorithm, called semantic scattering, is used to automatically label complex nominals, genitives and adjectival noun phrases with the corresponding semantic relation."
W04-2610,Support Vector Machines Applied to the Classification of Semantic Relations in Nominalized Noun Phrases,2004,18,20,1,1,28789,roxana girju,Proceedings of the Computational Lexical Semantics Workshop at {HLT}-{NAACL} 2004,0,The discovery of semantic relations in text plays an important role in many NLP applications. This paper presents a method for the automatic classification of semantic relations in nominalized noun phrases. Nominalizations represent a subclass of NP constructions in which either the head or the modifier noun is derived from a verb while the other noun is an argument of this verb. Especially designed features are extracted automatically and used in a Support Vector Machine learning model. The paper presents preliminary results for the semantic classification of the most representative NP patterns using four distinct learning models.
W04-0841,{SVM} classification of {F}rame{N}et semantic roles,2004,0,4,2,0.455793,16607,dan moldovan,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
W03-1207,Discovery of Manner Relations and Their Applicability to Question Answering,2003,5,4,1,1,28789,roxana girju,Proceedings of the {ACL} 2003 Workshop on Multilingual Summarization and Question Answering,0,"The discovery of semantic relations from text becomes increasingly important for applications such as Question Answering, Information Extraction, Summarization, Text Understanding and others. This paper presents a method for the automatic discovery of manner relations using a Naive Bayes learning algorithm. The method was tested on the UPenn Treebank2 corpus, and the targeted manner relations were detected with a precision of 64.44% and a recall of 68.67%."
W03-1210,Automatic Detection of Causal Relations for Question Answering,2003,11,230,1,1,28789,roxana girju,Proceedings of the {ACL} 2003 Workshop on Multilingual Summarization and Question Answering,0,"Causation relations are a pervasive feature of human language. Despite this, the automatic acquisition of causal information in text has proved to be a difficult task in NLP. This paper provides a method for the automatic detection and extraction of causal relations. We also present an inductive learning approach to the automatic discovery of lexical and semantic constraints necessary in the disambiguation of causal relations that are then used in question answering. We devised a classification of causal questions and tested the procedure on a QA system."
N03-1011,Learning Semantic Constraints for the Automatic Discovery of Part-Whole Relations,2003,10,184,1,1,28789,roxana girju,Proceedings of the 2003 Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"The discovery of semantic relations from text becomes increasingly important for applications such as Question Answering, Information Extraction, Text Summarization, Text Understanding, and others. The semantic relations are detected by checking selectional constraints. This paper presents a method and its results for learning semantic constraints to detect part-whole relations. Twenty constraints were found. Their validity was tested on a 10,000 sentence corpus, and the targeted part-whole relations were detected with an accuracy of 83%."
P01-1037,The Role of Lexico-Semantic Feedback in Open-Domain Textual Question-Answering,2001,14,72,7,0.357143,13772,sanda harabagiu,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents an open-domain textual Question-Answering system that uses several feedback loops to enhance its performance. These feedback loops combine in a new way statistical results with syntactic, semantic or pragmatic information derived from texts and lexical databases. The paper presents the contribution of each feedback loop to the overall performance of 76% human-assessed precise answers."
P00-1071,The Structure and Performance of an Open-Domain Question Answering System,2000,5,152,5,0,16607,dan moldovan,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"This paper presents the architecture, operation and results obtained with the LASSO Question Answering system developed in the Natural Language Processing Laboratory at SMU. To find answers, the system relies on a combination of syntactic and semantic techniques. The search for the answer is based on a novel form of indexing called paragraph indexing. A score of 55.5% for short answers and 64.5% for long answers was achieved at the TREC-8 competition."
A00-1037,Domain-Specific Knowledge Acquisition from Text,2000,9,24,2,0,16607,dan moldovan,Sixth Applied Natural Language Processing Conference,0,"In many knowledge intensive applications, it is necessary to have extensive domain-specific knowledge in addition to general-purpose knowledge bases. This paper presents a methodology for discovering domain-specific concepts and relationships in an attempt to extend WordNet. The method was tested on five seed concepts selected from the financial domain: interest rate, stock market, inflation, economic growth, and employment."
