2020.coling-demos.4,P19-1428,1,0.88528,"Missing"
2020.coling-main.317,N19-1423,0,0.0140882,"Missing"
2020.coling-main.317,P19-1428,1,0.876822,"Missing"
2020.coling-main.317,W02-0109,0,0.389487,"gorithm reached in both walks is part of a possible pipeline, and the ∗ and remaining algorithms are discarded. After this process is completed, any random path between Tin ∗ Tout is guaranteed to produce a valid pipeline that meets the user requirements. At the moment of writing, the computational prototype includes a total of 133 algorithms with suitable annotations3 . The source code for these algorithms has been semi-automatically generated via code introspection from popular machine learning frameworks such as Scikit-learn (Pedregosa et al., 2011), keras (Chollet and others, 2015), NLTK (Loper and Bird, 2002), Gensim (Khosrovian et al., 2008), and Pytorch (Paszke et al., 2019), and some manual implementations, such as searching terms in knowledge bases like Wikipedia and WordNet (Miller, 1995). Type annotations enable the seamless and automatic discovery of pipelines that, for example, use NLTK for tokenization, Gensim to convert tokens to word embeddings, Scikit-learn for dimensionality reduction and then a Keras-based neural network for classification (see Figure 1). 3.2 Sampling and Optimization Process Given graph GA built as described in Section 3.1 for a specific machine problem, our proposa"
2020.nlpcovid19-2.22,W13-2322,0,0.0457363,"but can provide precise answers to specific questions given enough supervised data. For example, identifying domain-specific entities such as symptoms, medication and treatments, and semantic relations between them. Learning to recognize this type of information in natural language, even academic language, is a challenging task, given the large number of varieties in which the same semantic fact can be stated. In this context, different annotation models have been designed to capture the semantic meaning in different domains and levels of discourse. Token-level annotation models, such as AMR (Banarescu et al., 2013), capture fine-grained semantic relations between elements in a natural language sentence, independently of domain, which means that only general-purpose relations can be recognized. In contrast, domain-specific annotation models can capture more detailed relations, such as 1 https://www.kaggle.com/ allen-institute-for-ai/ CORD-19-research-challenge subject is-a Concept is-a Concept subject in-context Concept ,, Action has-property Concept in-context Con Concept 1 Phylogenetic studies have shown that 2019-nCoV and SARS-CoV belong to the subgenus Sarbecovirus, but they are distantly related 5-8"
2020.nlpcovid19-2.22,2020.emnlp-demos.18,0,0.0430334,"y organize, normalize and link the existing information. A recent initiative is the COVID-19 Open Research Dataset (CORD-19), published by the Allen Institute for AI (Lo et al., 2020), which makes available a large corpus of scientific papers on COVID-19 and related topics. At the moment of writing, it contains 76, 674 scientific articles. The corpus has been used as part of a Kaggle challenge1 , which focused mainly on unsupervised tasks related to organizing and categorizing the different aspects of the whole COVID-19 situation. Based on these resources, computational tools, e.g., SciSight (Hope et al., 2020), SciFact (Wadden et al., 2020), and similar (Bras et al., 2020), have been created to enable the interactive visualization and exploration of the scientific literature and the discovery of connections between the available methods, symptoms, interventions, etc. Unsupervised approaches are a natural strategy for dealing with large, unlabeled corpora, while supervised approaches have the caveat of requiring training examples to be manually annotated, but can provide precise answers to specific questions given enough supervised data. For example, identifying domain-specific entities such as symp"
2020.nlpcovid19-2.22,W19-1910,1,0.818633,"Missing"
2020.nlpcovid19-2.22,E12-2021,0,0.0661023,"Missing"
2020.nlpcovid19-2.22,2020.emnlp-main.609,0,0.0605926,"Missing"
C10-2004,P09-2040,1,0.692104,"r work is the need to detect and explore the challenges raised by opinion QA (OQA), as compared to factual QA. To this aim, we analyze the improvements that can be brought at the different steps of the OQA process: question treatment (identification of expected polarity – EPT, expected source – ES and expected target –ET-), opinion retrieval (at the level of one and three-sentences long snippets, using topic-related words or using paraphrases), opinion analysis (using topic detection and anaphora resolution). This preliminary research is motivated by the conclusions drawn by previous studies (Balahur et al., 2009). Our purpose is to verify if the inclusion of new elements and methods - source and target detection (using semantic role labeling (SRL)), topic detection (using Latent Semantic Analysis), paraphrasing and joint topic-sentiment analysis (classification of the opinion expressed only in sentences related to the topic), followed by anaphora resolution (using a system whose performance is not optimal), affects the results of the system and how. Our contribution to this respect is the identification of the challenges related to OQA compared to traditional QA. A further contribution consists in add"
C10-2004,strapparava-valitutti-2004-wordnet,0,0.0237405,"em employing SVM ML on unigram and bigram features trained on the NTCIR MOAT 7 data and an unsupervised lexiconbased system. In order to compute the features for each of the unigrams and bigrams, we compute the tf-idf scores. The unsupervised system uses the Opinion Finder lexicon to filter out subjective sentences – that contain more than two subjective words or a subjective word and a valence shifter (obtained from the General Inquirer resource). Subsequently, it accounts for the presence of opinionated words from four different lexicons – MicroWordNet (Cerini et al., 2007), WordNet Affect (Strapparava and Valitutti, 2004) Emotion Triggers (Balahur and Montoyo, 2008) and General Inquirer (Stone et al., 1966). For the joint topic-polarity analysis, we first employ LSA to determine the words that are strongly associated to the topic, as described in Section 5.2 (second list item). Consequently, we compute the polarity of the sentences that contain at least one topic word and the question target. 5.4 Filtering using SR Finally, answers are filtered using the Semrol system for SR labeling described in (Moreda, 2008). Subsequently, we filter all snippets with the required target and source as agent or patient. Semro"
C10-2004,H05-1116,0,0.234201,"Missing"
C10-2004,H05-1044,0,0.0333943,"respectively, to which the traditional QA systems had to be adapted. Some participating systems treated opinionated questions as “other” and thus they did not employ opinion specific methods. However, systems that performed better in the “squishy list” questions than in the “rigid list” implemented additional components to classify the polarity of the question and of the extracted answer snippet. The Alyssa system (Shen et al, 2007) uses a Support Vector Machines (SVM) classifier trained on the MPQA corpus (Wiebe et al., 2005), English NTCIR3 data and rules based on the subjectivity lexicon (Wilson et al., 2005). (Varma et al., 2008) performed query analysis to detect the polarity of the question using defined rules. Furthermore, they filter opinion from fact retrieved snippets using a classifier based on Naïve Bayes with unigram features, assigning for each sentence a score that is a linear combination between the opinion and the polarity scores. The PolyU (Venjie et al., 2008) system determines the sentiment orientation of the sentence using the Kullback-Leibler divergence measure with the two estimated language models for the positive versus negative categories. The QUANTA (Li et al., 2008) system"
C10-2004,W03-1017,0,0.067012,"of questions and a collection of documents, an automatic NLP system is employed to retrieve the answer to the queries in Natural Language (NL). Research focused on building factoid QA systems has a long tradition; however, it is only recently that researchers have started to focus on the development of OQA systems. (Stoyanov et al., 2005) and (Pustejovsky and Wiebe, 2006) studied the peculiarities of opinion questions. (Cardie et al., 2003) employed opinion summarization to support a MultiPerspective QA system, aiming at identifying the opinion-oriented answers for a given set of questions. (Yu and Hatzivassiloglou, 2003) separated opinions from facts and summarized them as answer to opinion questions. (Kim and Hovy, 2005) identified opinion holders, which are a key component in retrieving the correct answers to opinion questions. Due to the realized importance of blog data, recent years have also marked the beginning of NLP research focused on the development of opinion QA systems and the organization of international conferences encouraging the creation of effective QA systems both for fact and subjective texts. The TAC 20082 QA track proposed a collection 2 http://www.nist.gov/tac/ of factoid and opinion qu"
N09-3013,W07-1421,0,0.0129391,"In this evaluation the important aspects were grammaticality, non-redundancy, structure and coherence, readability, and overall responsiveness. Although our participating systems obtained good F-measure values, in other scores, especially in grammaticality and non-redundancy, the results achieved were very low. Focusing all our efforts in improving the first approach, OpSum-1, non-redundancy and grammaticality verification had to be performed. In this approach, we wanted to test how much of the redundant information would be possible to remove by using a Textual Entailment system similar to (Iftene and Balahur-Dobrescu, 2007), without it affecting the quality of the remaining data. As input for the TE system, we considered the snippets retrieved from the original blog posts. We applied the entailment verification on each of the possible pairs, taking in turn all snippets as Text and Hypothesis with all other snippets as Hypothesis and Text, respectively. Thus, as output, we obtained the list of snippets from which we eliminated those that are entailed by any of the other snippets. We further eliminated those snippets which had a high entailment score with any of the remaining snippets. SYSTEM F-MEASURE Best system"
N09-3013,C04-1200,0,0.055791,"al, previous work in opinion mining includes document level sentiment classification using supervised (Chaovalit and Zhou, 2005) and unsupervised methods (Turney, 2002), machine learning techniques and sentiment classification considering rating scales (Pang, Lee and Vaithyanathan, 2002), and scoring of features (Dave, Lawrence and Pennock, 2003). Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques (Riloff and Wiebe, 2003), finding strength of opinions (Wilson, Wiebe and Hwa, 2004), summing up orientations of opinion words in a sentence (Kim and Hovy, 2004), and identifying opinion holders (Stoyanov and Cardie, 2006). Finally, fine grained, feature-based opinion summarization is defined in (Hu and Liu, 2004). 2 Figure 1. Examples of target, question and snippet * Elena Lloret is funded by the FPI program (BES-200716268) from the Spanish Ministry of Science and Innovation, under the project TEXT-MESS (TIN-2006-15265) 1 http://ir.dcs.gla.ac.uk/test_collections/access_to_data.html Opinion Summarization System In order to tackle the OSP task, we considered the use of two different methods for opinion mining and summarization, differing mainly with r"
N09-3013,W02-1011,0,0.0155383,"Missing"
N09-3013,W03-1014,0,0.0166609,"tage, based on polarity – DLSIUAES (Balahur et al., 2008) - or on separating information rich clauses - italica (Cruz et al., 2008). In general, previous work in opinion mining includes document level sentiment classification using supervised (Chaovalit and Zhou, 2005) and unsupervised methods (Turney, 2002), machine learning techniques and sentiment classification considering rating scales (Pang, Lee and Vaithyanathan, 2002), and scoring of features (Dave, Lawrence and Pennock, 2003). Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques (Riloff and Wiebe, 2003), finding strength of opinions (Wilson, Wiebe and Hwa, 2004), summing up orientations of opinion words in a sentence (Kim and Hovy, 2004), and identifying opinion holders (Stoyanov and Cardie, 2006). Finally, fine grained, feature-based opinion summarization is defined in (Hu and Liu, 2004). 2 Figure 1. Examples of target, question and snippet * Elena Lloret is funded by the FPI program (BES-200716268) from the Spanish Ministry of Science and Innovation, under the project TEXT-MESS (TIN-2006-15265) 1 http://ir.dcs.gla.ac.uk/test_collections/access_to_data.html Opinion Summarization System In o"
N09-3013,W06-0302,0,0.371095,"level sentiment classification using supervised (Chaovalit and Zhou, 2005) and unsupervised methods (Turney, 2002), machine learning techniques and sentiment classification considering rating scales (Pang, Lee and Vaithyanathan, 2002), and scoring of features (Dave, Lawrence and Pennock, 2003). Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques (Riloff and Wiebe, 2003), finding strength of opinions (Wilson, Wiebe and Hwa, 2004), summing up orientations of opinion words in a sentence (Kim and Hovy, 2004), and identifying opinion holders (Stoyanov and Cardie, 2006). Finally, fine grained, feature-based opinion summarization is defined in (Hu and Liu, 2004). 2 Figure 1. Examples of target, question and snippet * Elena Lloret is funded by the FPI program (BES-200716268) from the Spanish Ministry of Science and Innovation, under the project TEXT-MESS (TIN-2006-15265) 1 http://ir.dcs.gla.ac.uk/test_collections/access_to_data.html Opinion Summarization System In order to tackle the OSP task, we considered the use of two different methods for opinion mining and summarization, differing mainly with respect to the use of the optional text snippets provided. Our"
N09-3013,strapparava-valitutti-2004-wordnet,0,0.0590536,"Missing"
N09-3013,P02-1053,0,0.00585365,"pos/neg sentiment, pos/neg opinion) to account for the presence of positive opinions or negative ones - CLASSY (Conroy and Schlessinger, 2008); CCNU (He et al.,2008); LIPN (Bossard et al., 2008); IIITSum08 (Varma et al., 2008) -, efficient methods were proposed focusing on the retrieval and filtering stage, based on polarity – DLSIUAES (Balahur et al., 2008) - or on separating information rich clauses - italica (Cruz et al., 2008). In general, previous work in opinion mining includes document level sentiment classification using supervised (Chaovalit and Zhou, 2005) and unsupervised methods (Turney, 2002), machine learning techniques and sentiment classification considering rating scales (Pang, Lee and Vaithyanathan, 2002), and scoring of features (Dave, Lawrence and Pennock, 2003). Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques (Riloff and Wiebe, 2003), finding strength of opinions (Wilson, Wiebe and Hwa, 2004), summing up orientations of opinion words in a sentence (Kim and Hovy, 2004), and identifying opinion holders (Stoyanov and Cardie, 2006). Finally, fine grained, feature-based opinion summarization is defined in (Hu and Liu,"
nica-etal-2004-enriching,J98-1006,0,\N,Missing
nica-etal-2004-enriching,C02-1112,0,\N,Missing
nica-etal-2004-enriching,N01-1011,0,\N,Missing
nica-etal-2004-enriching,P95-1026,0,\N,Missing
nica-etal-2004-enriching,P97-1009,0,\N,Missing
nica-etal-2004-enriching,P96-1006,0,\N,Missing
nica-etal-2004-enriching,H92-1045,0,\N,Missing
nica-etal-2004-enriching,W01-0703,0,\N,Missing
P09-2040,H05-1116,0,0.157923,"Missing"
P09-2040,H05-1044,0,0.0248885,"Missing"
R09-1004,H05-1116,0,0.458556,"eries in Natural Language. The main difference between QA and Information Retrieval (IR) is that in the first one, the system is supposed to output the exact answer snippet, whereas in the second task whole paragraphs or even documents are retrieved. Research in building factoid QA systems has a long tradition; however, it is only recently that studies have started to focus on the creation and development of opinion QA systems. Recent years have seen the growth of interest in this field, both by the research and publishing of studies on the requirements and peculiarities of opinion QA systems [4] as well as the organization of international conferences that promote the creation of effective QA systems both for general and subjective texts, such as the Text Analysis Conference (TAC)1. Last year’s TAC 2008 Opinion QA track proposed a mixed setting of factoid and opinion questions (so called “rigid list” and “squishy list”), to which the traditional systems had to be adapted. Participating systems employed different resources, techniques and methods to overcome the newly introduced difficulties related to opinion mining and polarity classification. The Alyssa system [5], which performed"
R09-1004,H05-1044,0,0.0272199,"hniques and methods to overcome the newly introduced difficulties related to opinion mining and polarity classification. The Alyssa system [5], which performed better in the “squishy list” questions than in the 1 http://www.nist.gov/tac/ 18 International Conference RANLP 2009 - Borovets, Bulgaria, pages 18–22 “rigid list” questions, had additional components implemented for classifying the polarity of the question and of the extracted answer snippet, using a Support Vector Machines (SVM) classifier trained on the MPQA corpus [6], English NTCIR2 data and rules based on the subjectivity lexicon [7]. Another system introducing new modules to tackle opinion is [8]. They perform query analysis to detect the polarity of the question using defined rules. They filter opinion from fact retrieved snippets using a classifier based on Naïve Bayes with unigram features, assigning for each sentence a score that is a linear combination between the opinion and the polarity scores. The PolyU [9] system determines the sentiment orientation of the sentence and it uses the Kullback-Leibler divergence measure with the two estimated language models for the positive versus negative categories. The UOFL syst"
R11-1032,molina-etal-2002-word,0,0.026448,"icates proposed sense. The VAC format is as follows: VAC [AC value sense#1, AC value sense#2, AC value sense#n]. And the V [VAC] format is: V [VACDomains, VAC-Emotions, VAC-WordNet Taxonomies, VAC-SUMO, VAC-Frequency Senses] In VAC we also define a vector built with the frequency values of SemCor corpus for each lemma. Then we conduct a voting process with five AC values. If in an exceptional situation we 236 obtain a tie or disjoin senses, the proposed sense will be the most frequent. We have chosen this option because of empirical studies have demonstrated that MFS works better than others (Molina et al., 2002). 4 Evaluations and Analysis In this section our purpose is to confirm the hypothesis presented in Section 1. We have evaluated this method with two different test corpus, Senseval-2 on “English All words” task and Semeval-2 on “English All words on Specific Domain” task. Moreover, we have compared our results with the participating systems of the aforementioned competitions. The goal of these experiments is to demonstrate how the sense frequencies combined with RST can improve the original RST results. 4.1 After doing these experiments we were able to determine which dimension worked better."
R11-1032,magnini-cavaglia-2000-integrating,0,0.292568,"analyze the tasks of NLP from different dimensions. Among all of these resources, ISR-WN has the highest quantity of semantic dimensions aligned, so it is a suitable resource to run our proposal. Next, we present a brief description of ISR-WN. 2.1 Integration of Semantic Resources based on WordNet (ISR-WN) Integration of Semantic Resources based on WordNet (ISR-WN) (Gutiérrez et al., 2010b) is a new resource that allows the integration of several semantic resources mapped to WN. In ISR-WN, WordNet is used as a core to link several resources such as: SUMO (Niles, 2001), WordNet Domains (WND) (Magnini and Cavaglia, 2000) and WordNet Affect (WNA) (Strapparava and Valitutti, 2004). As (Gutiérrez et al., 2010a) describe, the integrator resource provides a software capable to navigate inside the semantic network. In order to apply the multidimensionality that this resource provides, we have analyzed related NLP approaches that take into account semantic dimensionality. Addressed to context analysis we have studied (Magnini et al., 2008), (Vázquez et al., 2004) and (Buscaldi et al., 2005). In these works WSD is performed using the WND resource (domain dimension). (Zouaq et al., 2009), (Villarejo et al., 2005) amon"
R11-1032,strapparava-valitutti-2004-wordnet,0,0.182598,"et al., 2010a) apply several dimensions at once. Next, we present the RST method which is able to work with different resources based on WordNet. 2.2 Relevant Semantic Trees (RST) The RST method is able to find the correct senses of each word using Relevant Semantic Trees from different resources. This approach can be used with many resources mapped to WN as we have mentioned above. In order to measure the association between concepts according to a multidimensional perspective in each sentence, RST uses an Association Ratio (AR) modification based on the proposal presented by Vázquez et al. (2004). 3 WSD Method We propose an unsupervised knowledge-based method that uses the original RST technique including senses frequency of SemCor4 corpus 2 http://multiwordnet.fbk.eu/ 3 http://www.lsi.upc.es/~nlp/meaning/meaning.html 4 234 http://www.cse.unt.edu/~rada/downloads.html#semcor and using a voting process to find the right senses. The voting process involves MFS (Most Frequent Sense), RST over WND, WNA, WN taxonomy and SUMO. Adding this new information we are able to improve the previous results obtained by the original RST and we also improve the MFS results in Semeval-2 competition. Spec"
R11-1032,P04-1036,0,0.0883344,"Missing"
R11-1032,E09-1005,0,0.0796437,"Missing"
R11-1032,J98-1001,0,0.11335,"Missing"
R11-1032,S10-1095,0,\N,Missing
R11-1032,S01-1027,0,\N,Missing
R11-1032,S10-1013,0,\N,Missing
R11-1032,S07-1016,0,\N,Missing
R11-1032,atserias-etal-2006-freeling,0,\N,Missing
R19-1032,buitelaar-etal-2006-ontology,0,0.0594456,"ng process. that can be crosschecked in the future. The rest of the paper is organized as follows to facilitate a detailed description of our proposal: Section 2 describes the proposed architecture of a general framework for knowledge discovery. In Section 3 we present an application of LETO to a specific knowledge discovery problem combining Twitter and IMDB. Finally, in Section 4 we present the main conclusions of the research and outline possible future works. cus on extracting knowledge and exploiting the semi-structured format of web resources , e.g, ARTEQUAKT (Alani et al., 2003), SOBA (Buitelaar et al., 2006) and WEB-&gt;KB (Craven et al., 2000). In order to extract relevant knowledge from natural language text, NLP techniques have been introduced in systems such as OPTIMA (Kim et al., 2008) and ISODLE (Weber and Buitelaar, 2006). Natural language features can be used to build rule-based systems (e.g., OntoLT (Buitelaar and Sintek, 2004)) or systems based on statistical or probabilistic models trained on NLP corpora, such as LEILA (Suchanek et al., 2006) or Text2Onto (Cimiano and V¨olker, 2005). Some systems address the issue of inferring more abstract knowledge from the extracted facts, often using"
R19-1032,W06-0503,0,0.0672063,"e future works. cus on extracting knowledge and exploiting the semi-structured format of web resources , e.g, ARTEQUAKT (Alani et al., 2003), SOBA (Buitelaar et al., 2006) and WEB-&gt;KB (Craven et al., 2000). In order to extract relevant knowledge from natural language text, NLP techniques have been introduced in systems such as OPTIMA (Kim et al., 2008) and ISODLE (Weber and Buitelaar, 2006). Natural language features can be used to build rule-based systems (e.g., OntoLT (Buitelaar and Sintek, 2004)) or systems based on statistical or probabilistic models trained on NLP corpora, such as LEILA (Suchanek et al., 2006) or Text2Onto (Cimiano and V¨olker, 2005). Some systems address the issue of inferring more abstract knowledge from the extracted facts, often using unsupervised techniques to discover inherent structures. Relevant examples of this approach are OntoGain (Drymonas et al., 2010), ASIUM (Faure and Poibeau, 2000) and BOEMIE (Castano et al., 2007). Most of the mentioned systems focus on one iteration of the extraction process. However, more recent approaches, like NELL (Mitchell et al., 2018), attempt to learn continuously from a stream of web data, and increase over time both the amount and the qu"
R19-1032,P10-1040,0,0.00902433,"n the level of reliability and completeness of unstructured sources. 278     Structured Data Processing Converting to Internal Format Adding Tags and Metadata Structured documents Semantic networks Databases  read input formats  write output ontolgy   Mapping    origin domain   complexity  Structural Level: The data tokens extracted from the original source are processed as a group to find an underlying structure. Techniques implemented in this stage include Latent Semantic Analysis (LSA) (Hofmann, 2017), Principal Components Analysis (PCA) (Guo et al., 2002), Word Embeddings (Turian et al., 2010) and clustering techniques. The output of this stage is either a graph, a correlation matrix, or some statistical description that represents the underlying structure of the data tokens that were previously extracted. Knowledge Discovery Data Sources Tagging Figure 3: A schema of the Structured Data Module, and a representation of the processes that occur in each of the two main tasks performed by this module. Social networks Web pages Extraction of Data Tokens (sensors)  sentiments  entities  events  opinions  Deﬁnition of Structures  Sensory Level  matrices  graphs  statistics  Cre"
R19-1105,P04-1035,0,0.00696098,", description, tag, etc.). The SNN learns to represent natural text in a manner which resembles the entity extraction process. Note that no natural text is associated to the label of the relation. Hence, in order for the SNN to accurately predict that relation r(e1 , e2 ) is true for a specific pair of entities e1 , e2 , but false for another pair of entities, the “list” of pairs of entities 4 Experimental Analysis To analyze the behavior of the SNN, we selected a classic NLP problem and a suitable knowledge base. The selected problem is opinion mining in movie reviews, using the dataset from Pang and Lee (2004). The corpus contains 1000 positive and 1000 negative movie reviews written in English. For building the knowledge base, raw data from IMDB2 was processed obtaining a graph representation with 2 classes (Person and Movie), 11 relations and a total 27,044,985 tuples. Table 1 summarizes the statistics of the knowledge base. The SNN obtained from the IMDB knowledge base has the structure shown in figure 3. The input 2 908 https://datasets.imdbws.com Classes Instances Person Movie 2 854 359 2 361 769 Indicators dense ReLU Person Relations actor actress archive footage archive sound cinematographer"
R19-1105,D15-1036,0,0.0128242,"k is trained to predict, given a word wi ’s embedding, the probability that some other word wj appears in a small window centered around wi . In this sense, word embeddings can be seen as a generalization of corpus-based metrics, whereby the best representation is learned from the data, rather than handcrafted. Even though word embeddings don’t explicitly model specific semantic relations (such as hypernymy, or synonymy), it has been shown that several interesting semantic relations get encoded in specific directions in the embedding space, enabling the solution of analogue inference queries (Schnabel et al., 2015). 3 Semantic Neural Networks We define a Semantic Neural Network (SNN) as an artificial neural network architecture that encodes knowledge. Two main semantic elements are encoded from the Knowledge Base. First, the graph structure of the Knowledge Base (i.e. entity classes and their relations) is directly represented in the architecture of a SNN. Second from a Knowledge Base KB, the information about which instances belong to which entity classes and their specific relations are encoded into the weights of the SNN. By design, the architecture of the SNN is built to represent each specific enti"
R19-1105,P15-1125,0,0.0236105,"ase for entity embedding. For example, embeddings can be designed such that a particular direction dr is associated with each particular relation of the knowledge base, such that ei + dr ≈ ej whenever ei and ej are related by r. These formulations allow a semantic meaning to be attached to a particular algebraic operation and properties, and enable a whole new field of study that finds the “meaning” of, say, other directions d which are orthogonal to or linearly dependent on a specific relation. Entity embeddings have been extended to encode also the hierarchical structure of knowledge bases (Hu et al., 2015) and mixed with word embeddings for tasks such as entity disambiguation (Yamada et al., 2016). Word and entity embeddings in general are promising approaches to deal with learning semantic representations of data. Moreover, recent research deals with finding ways to exploit the structure of these representations to explain why a specific answer is output by a neural network. Being able to explain neural networks is a first step towards designing accountable machine learning systems that humans can trust for solving the most 906 Problem (L) (1) (5) Training Instances (4) Select Knowledge Class"
S01-1032,P96-1006,0,0.0460256,"sambiguated with the first sense of WordNet (even if it is a polysemous one). Nouns with Specification Marks The second phase consist of noun classification, and has been performed by the SM method described previously. Verbs and adjectives with Maximum Entropy The third and final phase, the verbs and adjectives disambiguation, has been performed by the ME method. The SENSEVAL-2 training data has been used in order to obtain the classification functions to be applied on the test data. The set of features defined for ME training is described below and it is based on features selection made in {Ng and Lee, 1996) and (Escudero et al., 2000). The set of features corresponds to words around the word to classify and POS labels at positions related to the target word in each sentence: wo, w_b w_2, W-3, W+b W+2, W+3, (w-2, W-I), (W-I, W+I), (w+b W+2), (w-3,w-2,w-d, (w-2, w_bw+I), (w-bw+I,W+2), (w+I, W+2,W+3), P-3, P-2, P-1, P+I, P+2, P+3· Each Wi is the lemma of the word at position i in the context (in collocations, at least one of the words must be a content word). Each Pi is the POS label at position i. Other set of features consists of a surrounding nouns selection. This selection is doing by means of"
S01-1032,W01-0704,1,0.761259,"eights of each feature, and Z(x) is a constant to ensure that the sum of probabilities for each possible class in this context is equal to 1. f (x c) c! 132 = { 1 if d =?and cp(x) =true 0 otherwise (1) K IT p(c!x) = _1_ a{i(x,c} Z(x) i=l 4 Maximum Entropy(ME) modeling is a framework for integrating information from many heterogeneous information sources for classification. ME probability models were successfully applied to some NLP tasks such as POS tagging or sentence boundary detection (Ratnaparkhi, 1998). The WSD system presented in this paper is based on conditional ME probability models (Saiz-Noeda et al., 2001). It implements a supervised learning method consisting of the building of word sense classifiers through training on a semantically tagged corpus. A classifier obtained by means of a ME technique consists of a set of parameters or coefficients estimated by means of an optimization procedure. Each coefficient is associated to one feature observed in training data. A feature is a function that gives a measure for some characteristic in a context associated to a class. The main purpose is to obtain the probability distribution that maximizes the entropy, that is, maximum ignorance is assumed and"
S01-1032,A97-1011,0,\N,Missing
S07-1072,P97-1023,0,0.0206586,"nce bag of word counts collected from the World Wide Web. Our hypothesis is that words which tend to cooccur across many documents with a given emotion are highly probable to express this emotion. The rest of the paper is organized as follows. In Section 2 we review some of the related work, in Section 3 we describe our web-based emotion classification approach for which we show a walk-through example in Section 4. A discussion of the obtained results can be found in Section 5 and finally we conclude in Section 6. 2 Related work Our approach for emotion classification is based on the idea of (Hatzivassiloglou and McKeown, 1997) and is similar to those of (Turney, 2002) and (Turney and Littman, 2003). According to Hatzivassiloglou and McKeown (1997), adjectives with the same polarity tended to appear together. For example the negative adjectives “corrupt and brutal” co334 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 334–337, c Prague, June 2007. 2007 Association for Computational Linguistics occur very often. The idea of tracing polarity through adjective cooccurrence is adopted by Turney (2002) for the binary (positive and negative) classification of text reviews. They"
S07-1072,W06-0301,0,0.00661716,"web as a source of information. For instance, (Taboada et al., 2006) extracted from the web co-occurrences of adverbs, adjectives, nouns and verbs. Gamon and Aue (2005) were looking for adjectives that did not co-occur at sentence level. (Baroni and Vegnaduzzo, 2004) and (Grefenstette et al., 2004) gathered subjective adjectives from the web calculating the Mutual Information score. Other important works on sentiment analysis are those of (Wilson et al., 2005) and (Wiebe et al., 2005; Wilson and Wiebe, 2005), who used linguistic information such as syntax and negations to determine polarity. Kim and Hovy (2006) integrated verb information from FrameNet and incorporated it into semantic role labeling. 3 Web co-occurrences In order to determine the emotions of a headline, we measure the Pointwise Mutual Information (MI) of ei and cwj as hits(ei ,cwj ) , where ei ∈ M I(ei , cwj ) = log2 hits(ei )hits(cw j) {anger, disgust, f ear, joy, sadness, surprise} and cwj are the content words of the headline j. For each headline, we have six MI scores which indicate the presence of the emotion. MI is used in our experiments because it provides information about the independence of an emotion and a bag of words."
S07-1072,P02-1053,0,0.0620945,"pothesis is that words which tend to cooccur across many documents with a given emotion are highly probable to express this emotion. The rest of the paper is organized as follows. In Section 2 we review some of the related work, in Section 3 we describe our web-based emotion classification approach for which we show a walk-through example in Section 4. A discussion of the obtained results can be found in Section 5 and finally we conclude in Section 6. 2 Related work Our approach for emotion classification is based on the idea of (Hatzivassiloglou and McKeown, 1997) and is similar to those of (Turney, 2002) and (Turney and Littman, 2003). According to Hatzivassiloglou and McKeown (1997), adjectives with the same polarity tended to appear together. For example the negative adjectives “corrupt and brutal” co334 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 334–337, c Prague, June 2007. 2007 Association for Computational Linguistics occur very often. The idea of tracing polarity through adjective cooccurrence is adopted by Turney (2002) for the binary (positive and negative) classification of text reviews. They take two adjectives, for instance “excelle"
S07-1072,W05-0408,0,0.0103099,"AR operator and considers only those documents that contain the adjectives within a specific proximity. In our approach, as far as the majority of the query words appear in the documents, the frequency count is considered. • queries: The queries of Turney (2002) are made up of a pair of adjectives, and in our approach the query contains the content words of the headline and an emotion. There are other emotion classification approaches that use the web as a source of information. For instance, (Taboada et al., 2006) extracted from the web co-occurrences of adverbs, adjectives, nouns and verbs. Gamon and Aue (2005) were looking for adjectives that did not co-occur at sentence level. (Baroni and Vegnaduzzo, 2004) and (Grefenstette et al., 2004) gathered subjective adjectives from the web calculating the Mutual Information score. Other important works on sentiment analysis are those of (Wilson et al., 2005) and (Wiebe et al., 2005; Wilson and Wiebe, 2005), who used linguistic information such as syntax and negations to determine polarity. Kim and Hovy (2006) integrated verb information from FrameNet and incorporated it into semantic role labeling. 3 Web co-occurrences In order to determine the emotions of"
S07-1072,W05-0308,0,0.023899,"nts with a given emotion are highly probable to express the same emotion. 1 Introduction The subjective analysis of a text is becoming important for many Natural Language Processing (NLP) applications such as Question Answering, Information Extraction, Text Categorization among others (Shanahan et al., 2006). The resolution of this problem can lead to a complete, realistic and coherent analysis of the natural language, therefore major attention is drawn to the opinion, sentiment and emotion analysis, and to the identification of beliefs, thoughts, feelings and judgments (Quirk et al., 1985), (Wilson and Wiebe, 2005). The aim of the Affective Text task is to classify a set of news headlines into six types of emotions: “anger”, “disgust”, “fear”, “joy”, “sadness” and “surprise”. In order to be able to conduct such multi-category analysis, we believe that first we need a comprehensive theory of what a human emotion is, and then we need to understand how the emotion is expressed and transmitted within the natural language. These aspects rise the need of syntactic, semantic, textual and pragmatic analysis of a text (Polanyi and Zaenen, 2006). However, some of the major drawbacks in this field are related to t"
S07-1072,H05-1044,0,0.118174,"es, and in our approach the query contains the content words of the headline and an emotion. There are other emotion classification approaches that use the web as a source of information. For instance, (Taboada et al., 2006) extracted from the web co-occurrences of adverbs, adjectives, nouns and verbs. Gamon and Aue (2005) were looking for adjectives that did not co-occur at sentence level. (Baroni and Vegnaduzzo, 2004) and (Grefenstette et al., 2004) gathered subjective adjectives from the web calculating the Mutual Information score. Other important works on sentiment analysis are those of (Wilson et al., 2005) and (Wiebe et al., 2005; Wilson and Wiebe, 2005), who used linguistic information such as syntax and negations to determine polarity. Kim and Hovy (2006) integrated verb information from FrameNet and incorporated it into semantic role labeling. 3 Web co-occurrences In order to determine the emotions of a headline, we measure the Pointwise Mutual Information (MI) of ei and cwj as hits(ei ,cwj ) , where ei ∈ M I(ei , cwj ) = log2 hits(ei )hits(cw j) {anger, disgust, f ear, joy, sadness, surprise} and cwj are the content words of the headline j. For each headline, we have six MI scores which ind"
S07-1073,S07-1012,0,0.086371,"to among others. The question is which one of these referents we are actually looking for and interested in. Presently, to be able to answer to this question, we have to skim the content of the documents and retrieve the correct answers on our own. To automate this process, the named entities can be disambiguated and the different underlying meanings of the name can be found. On the basis of this information, the web pages can be clustered together and organized in a hierarchical structure which can ease the documents’ browsing. This is also the objective of the Web People Search (WePS) task (Artiles et al., 2007). What makes the WePS task even more challenging is the fact that in contrast to WSD where the number of senses of a word are predefined, in WePS we do not know the exact number of different individuals. For the resolution of the WePS task, we have developed a web page clustering approach using the title and the body content of the web pages. In addition, we group together the documents that share many location, person and organization names, as well as those that point out to the same sub-links. The rest of the paper is organized as follows. In Section 2 we describe various approaches for nam"
S07-1073,P98-1012,0,0.126325,"Missing"
S07-1073,W03-0405,0,0.0526802,"Missing"
S07-1073,N04-3008,0,0.0236952,"anization) are considered. Therefore, in our approach we use person, organization and location names in order to construct a social similarity network between two documents. Another unsupervised clustering technique for name discrimination of web pages is that of Pedersen and Kulkarni (2007). They used contextual vectors derived from bigrams, and measured the impact of several association measures. During the evaluation, some names were easily discriminable compared to others categories for which was even difficult to find and obtain discriminative feature. We worked with their unigram model (Purandare and Pedersen, 2004) to cluster the web pages using the text content between the title tags. 3 Web Person Disambiguation Our web people clustering approach is presented in Figure 1 and consists of the following steps: • name matching: the location, person and organization names in the body texts are identified with the GATE1 system (Cunningham, 2005). Each named entity of a document is matched with its corresponding named entity category from the rest of the web pages. This information is used to calculate the social semantic similarity of the person, the location and the organization names. Our hypothesis is tha"
S07-1073,C98-1012,0,\N,Missing
S10-1099,esuli-sebastiani-2006-sentiwordnet,0,0.261312,"Missing"
S10-1099,H05-1043,0,0.0208921,"h similar orientation tend to cooccur in documents. Thus, the author computes the Pointwise Mutual Information score between seed words and new words on the basis of the number of AltaVista hits returned when querying the seed word and the word to be classified with the “NEAR” operator. In our work in (Balahur and Montoyo, 2008a), we compute the polarity of new words using “polarity anchors” (words whose polarity is known beforehand) and Normalized Google Distance (Cilibrasi and Vitanyi, 2006) scores. Another approach that uses the polarity of the local context for computing word polarity is (Popescu and Etzioni, 2005), who use a weighting function of the words around the context to be classified. 4 The OpAL system at SemEval 2010 Task 18 In the SemEval 2010 Task 18, the participants were given a set of contexts in Chinese, in which 14 dynamic sentiment ambiguous adjectives are selected. They are: 大|big, 小|small, 多|many, 少 |few, 高|high, 低|low, 厚|thick, 薄|thin, 深|deep, 浅|shallow, 重|heavy, 轻 |light, 巨大|huge, 重大 |grave. The task was to automatically classify the polarity of these adjectives, i.e. to detect whether their sense in the context is positive or negative. The contexts were given in two forms: as plai"
S10-1099,strapparava-valitutti-2004-wordnet,0,0.0438742,"e task of sentiment analysis, considered a step further to subjectivity analysis, is more complex than the latter, because it involves an extra step: the classification of the retrieved opinion words according to their polarity. There are a series of techniques that were used to obtain lexicons of subjective words – e.g. the Opinion Finder lexicon (Wilson et al., 2005) and opinion words with associated polarity. (Hu and Liu, 2004) start with a set of seed adjectives (“good” and “bad”) and apply synonymy and antonymy relations in WordNet. A similar approach was used in building WordNet Affect (Strapparava and Valitutti, 2004), starting from a larger set of seed affective words, classified according to the six basic categories of emotion (joy, sadness, fear, surprise, anger and disgust) and expanding the lexicon using paths in WordNet. Another related method was used in the creation of SentiWordNet (Esuli and Sebastiani, 2005), using a set of seed words whose polarity was known and expanded using gloss similarity. The collection of appraisal terms in (Whitelaw et al., 2005), the terms also have polarity assigned. MicroWNOp (Cerini et al., 2007), another lexicon containing opinion words with their associated polarit"
S10-1099,P02-1053,0,0.00437132,"rity assigned. MicroWNOp (Cerini et al., 2007), another lexicon containing opinion words with their associated polarity, was built on the basis of a set of terms extracted from the General Inquirer lexicon and subsequently adding all the synsets in WordNet where these words appear. Other methods built sentiment lexicons using the local context of words. (Pang et al., 2002) built a lexicon of sentiment words with associated polarity value, starting with a set of classified seed adjectives and using conjunctions (“and”) disjunctions (“or”, “but”) to deduce orientation of new words in a corpus. (Turney, 2002) classifies words according to their polarity on the basis of the idea that terms with similar orientation tend to cooccur in documents. Thus, the author computes the Pointwise Mutual Information score between seed words and new words on the basis of the number of AltaVista hits returned when querying the seed word and the word to be classified with the “NEAR” operator. In our work in (Balahur and Montoyo, 2008a), we compute the polarity of new words using “polarity anchors” (words whose polarity is known beforehand) and Normalized Google Distance (Cilibrasi and Vitanyi, 2006) scores. Another"
S10-1099,J94-2004,0,0.0226976,"e SemEval 2010 Task 18 – Disambiguation of Sentiment Ambiguous Adjectives (Wu and Jin, 2010). In the following sections, we first present state-of-the art approaches towards polarity classification of opinions, subsequently describing our approach in the SemEval task. Finally, we present the results we obtained in the evaluation and our plans for future work. 444 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 444–447, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics 3 State of the Art Subjectivity analysis is defined by (Wiebe, 1994) as the “linguistic expression of somebody’s opinions, sentiments, emotions, evaluations, beliefs and speculations”. Sentiment analysis, on the other hand, is defined as the task of extracting, from a text, the opinion expressed on an object (product, person, topic etc.) and classifying it as positive, negative or neutral. The task of sentiment analysis, considered a step further to subjectivity analysis, is more complex than the latter, because it involves an extra step: the classification of the retrieved opinion words according to their polarity. There are a series of techniques that were u"
S10-1099,H05-1044,0,0.0603862,"valuations, beliefs and speculations”. Sentiment analysis, on the other hand, is defined as the task of extracting, from a text, the opinion expressed on an object (product, person, topic etc.) and classifying it as positive, negative or neutral. The task of sentiment analysis, considered a step further to subjectivity analysis, is more complex than the latter, because it involves an extra step: the classification of the retrieved opinion words according to their polarity. There are a series of techniques that were used to obtain lexicons of subjective words – e.g. the Opinion Finder lexicon (Wilson et al., 2005) and opinion words with associated polarity. (Hu and Liu, 2004) start with a set of seed adjectives (“good” and “bad”) and apply synonymy and antonymy relations in WordNet. A similar approach was used in building WordNet Affect (Strapparava and Valitutti, 2004), starting from a larger set of seed affective words, classified according to the six basic categories of emotion (joy, sadness, fear, surprise, anger and disgust) and expanding the lexicon using paths in WordNet. Another related method was used in the creation of SentiWordNet (Esuli and Sebastiani, 2005), using a set of seed words whose"
S10-1099,S10-1014,0,0.0205965,"different product characteristics. Especially in this context, opinion mining systems are confronted with a difficult problem: the fact that the adjectives used to express opinion have different polarities depending on the characteristic they are mentioned with. For example, “high price” is negative, while “high resolution” is positive. Therefore, specialized methods have to be employed to correctly determine the contextual polarity of such words and thus accurately assign polarity to the opinion. This is the aim of the SemEval 2010 Task 18 – Disambiguation of Sentiment Ambiguous Adjectives (Wu and Jin, 2010). In the following sections, we first present state-of-the art approaches towards polarity classification of opinions, subsequently describing our approach in the SemEval task. Finally, we present the results we obtained in the evaluation and our plans for future work. 444 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 444–447, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics 3 State of the Art Subjectivity analysis is defined by (Wiebe, 1994) as the “linguistic expression of somebody’s opinions, sentiments, emotions, eva"
S10-1099,H05-2017,0,\N,Missing
S10-1099,W02-1011,0,\N,Missing
S12-1090,strapparava-valitutti-2004-wordnet,0,0.29921,"Missing"
S12-1090,S12-1051,0,0.0370788,"t features we can highlight the resource ISR-WN1 used to extract semantic relations among words and the use of different algorithms to establish semantic and lexical similarities. In order to establish which features are the most appropriate to improve STS results we participated with three runs using different set of features. Our best approach reached the position 18 of 89 runs, obtaining a general correlation coefficient up to 0.72. 1. Introduction SemEval 2012 competition for evaluating Natural Language Processing (NLP) systems presents a new task called Semantic Textual Similarity (STS) (Agirre et al., 2012). In STS the participating systems must examine the degree of semantic equivalence between two sentences. The goal of this task is to create a unified framework for the evaluation of semantic textual similarity modules and to characterize their impact on NLP applications. STS is related to Textual Entailment (TE) and Paraphrase tasks. The main difference is that STS assumes bidirectional graded equivalence between the pair of textual snippets. In the case of TE the equivalence is directional (e.g. a student is a person, but a person is not necessarily a student). In addition, STS differs from"
S12-1090,R11-1032,1,0.854378,"Missing"
S12-1090,W11-1718,1,0.898834,"Missing"
S12-1090,S10-1095,0,\N,Missing
S12-1090,atserias-etal-2006-freeling,0,\N,Missing
S13-1015,P98-1013,0,0.369014,"Missing"
S13-1015,S12-1090,1,0.671145,"Missing"
S13-1015,S10-1095,1,0.898861,"Missing"
S13-1015,S12-1060,0,0.0546278,"Missing"
S13-1015,strapparava-valitutti-2004-wordnet,0,0.0975125,"Missing"
S13-1015,W05-1203,0,\N,Missing
S13-1015,C98-1013,0,\N,Missing
S13-1015,S12-1051,0,\N,Missing
S13-1015,atserias-etal-2006-freeling,0,\N,Missing
S13-2016,S10-1095,1,0.840859,"Missing"
S13-2016,R11-1032,1,0.860392,"xist an antonym before, 2 otherwise. 100 if exist an antonym before, 3 otherwise. 100 if exist an antonym before, 8 otherwise. 100 if exist an antonym before, 10 otherwise. 100 if exist an antonym before, 5 otherwise. 100 if exist an antonym before, 13 otherwise. 100 if exist an antonym before, 60 otherwise. 100 if exist an antonym before, 13 otherwise. 100 if exist an antonym before, 60 otherwise. 100 Table 1. Most frequents relations with their weight. 3.2 minimal semantic distance across WordNet (Miller et al., 2006) resource (this resource is involved into the integrator resource, ISR-WN (Gutiérrez et al., 2011a; 2010a); ???????? the minimal semantic distance between two words; ??? represents the minimal semantic distance between two senses collections; ? is a collection of synsets that represents the minimal path between two synsets using BFS; ??? obtains semantic relation types between two synsets; W is a functions that apply the rules described in Table 1. The maximum and average distance is calculated in a similar fashion but using the maximum and average instead of the minimum. 3.3 Semantic Alignment First, the two sentences are pre-processed with Freeling 2.2 and the words are classified accor"
S13-2016,O97-1002,0,0.35042,"Missing"
S13-2016,P94-1019,0,\N,Missing
S13-2016,J06-1003,0,\N,Missing
S13-2016,N04-3012,0,\N,Missing
S13-2042,E09-1005,0,0.515751,"Missing"
S13-2042,magnini-cavaglia-2000-integrating,0,0.0503253,"Missing"
S13-2042,H05-1052,0,0.175752,"Missing"
S13-2042,S10-1095,1,0.897655,"Missing"
S13-2042,R11-1032,1,0.849888,"Missing"
S13-2042,W11-1718,1,0.894239,"Missing"
S13-2042,S13-2040,0,0.205348,"Missing"
S13-2042,strapparava-valitutti-2004-wordnet,0,0.322549,"Missing"
S13-2042,P10-1023,0,\N,Missing
S13-2073,E09-1005,0,0.0207488,"ds are identified on the sentiment repositories (see Table 4) as positive or negative, in relation to their respective graph, a weight value of 1 (in a range [0 … 1] ) is assigned. ? represents the maximum quantity of words in the current graph. After that, a graph-based ranking algorithm is applied in order to structurally raise the graph vertexes’ voting power. Once the reinforcement values are applied, the proposed ranking algorithm is able to increase the significance of the words related to these empowered vertices. The PageRank (Brin and Page, 1998) adaptation, which was popularized by (Agirre and Soroa, 2009) in Word Sense Disambiguation thematic, and which has obtained relevant results, was an inspiration to us in our work. The main idea behind this algorithm is that, for each edge between ? i and ? j in graph ?, a vote is made from ? i to ? j. As a result, the relevance of ? j is increased. On top of that, the vote strength from ? to ? depends on ?? ′? relevance. The philosophy behind 445 it is that, the more important the vertex is, the more strength the voter would have. Thus, PageRank is generated by applying a random walkthrough from the internal interconnection of ?, where the final relevan"
S13-2073,baccianella-etal-2010-sentiwordnet,0,0.173184,"Missing"
S13-2073,strapparava-valitutti-2004-wordnet,0,0.052977,"ine-grained opinion mining (Balahur, 2011). In order to build sentiment resources, several studies have been conducted. One of the first is the relevant work by (Hu and Liu, 2004) using lexicon expansion techniques by adding synonymy and antonym relations provided by WordNet (Fellbaum, 1998; Miller et al., 1990) Another one is the research described by (Hu and Liu, 2004; Liu et al., 2005) which obtained an Opinion Lexicon compounded by a list of positive and negative opinion words or sentiment words for English (around 6800 words). A similar approach has been used for building WordNet-Affect (Strapparava and Valitutti, 2004) which expands six basic categories of emotion; thus, increasing the lexicon paths in WordNet. Nowadays, many sentiment and opinion messages are provided by Social Media. To deal with the informalities presented in these sources, it is necessary to have intermediary systems that improve the level of understanding of the messages. The following section offers a description of this phenomenon and a tool to track it. 2.1 Text normalization Several informal features are present in opinions extracted from Social Media texts. Some research has been conducted in the field of lexical normalization for"
S13-2073,W13-1613,1,0.782197,"tool for Web 2.0 texts with an aim to transform noisy and informal words into their canonical form. That way, they can be easily processed by NLP tools and applications. TENOR works by identifying out-of-vocabulary (OOV) words such as slang, informal lexical variants, expressive lengthening, or contractions using a dictionary lookup and replacing them by matching formal candidates in a word lattice using phonetic and lexical edit distances. 2.2 Construction of our own Sentiment Resource Having analyzed the examples of SA described in section 2, we proposed building our own sentiment resource (Gutiérrez et al., 2013) by adding lexical and informal patterns to obtain classifiers that can deal with Task 2b of Semeval-2013. We proposed the use of a method named RA-SR (using Ranking Algorithms to build Sentiment Resources) 444 (Gutiérrez et al., 2013) to build sentiment word inventories based on senti-semantic evidence obtained after exploring text with annotated sentiment polarity information. Through this process, a graph-based algorithm is used to obtain auto-balanced values that characterize sentiment polarities, a well-known technique in Sentiment Analysis. This method consists of three key stages: (I) B"
S13-2073,C00-1044,0,\N,Missing
S13-2073,W06-0301,0,\N,Missing
S13-2073,atserias-etal-2006-freeling,0,\N,Missing
S13-2083,baccianella-etal-2010-sentiwordnet,0,0.323213,"on et al., 2013). The proposal system includes three phases: data preprocessing, contextual word polarity detection and message classification. The preprocessing phase comprises treatment of emoticon, slang terms, lemmatization and POS-tagging. Word polarity detection is carried out taking into account the sentiment associated with the context in which it appears. For this, we use a new contextual sentiment classification method based on coarse-grained word sense disambiguation, using WordNet (Miller, 1995) and a coarse-grained sense inventory (sentiment inventory) built up from SentiWordNet (Baccianella et al., 2010). Finally, the overall sentiment is determined using a rule-based classifier. As it may be observed, the results obtained for Twitter and SMS sentiment classification are good considering that our proposal is unsupervised. 1 Introduction The explosion of Web 2.0 has marked a new age for the human society. The huge use of Social Media such as Facebook1 , MySpace2 , LinkedIn3 and Twitter4 , offers a place for people to share information in real time. Twitter is one of the most popular 1 https://www.facebook.com 2 http://www.myspace.com/ 3 http://www.linkedin.com 4 https://www.twitter.com/ Andr´e"
S13-2083,esuli-sebastiani-2006-sentiwordnet,0,0.0889395,"012)5 . Through the twitter applications, users shared opinions about personalities, politicians, products, companies, events, etc. This has been attracting the attention of different research communities interested in analyzing its content and motivated many natural language tasks, such as sentiment analysis, emotions detection, opinions retrieval, product recommendation or opinion summarization. One of the most popular sentiment analysis tasks is polarity classification. This task is a new field that classifies opinion texts as positive, negative or neutral (Pang et al., 2002; Turney, 2002; Esuli and Sebastiani, 2006; Wilson et al., 2006; Wiegand et al., 2010). Determining polarity might seem an easy task, as many words have some polarity by themselves. However, words do not always express the same sentiment, and in most cases the polarity of a word depends on the context in which the word is used. So, terms that clearly denote negative feelings can be neutral, or even positive, depending on their context. Hence, sentiment analysis systems should include semantic-level analysis in order to solve word ambiguity and correctly capture the meaning of each word according to its context. Also, complex linguisti"
S13-2083,P97-1023,0,0.284735,"positive, negative and objective senses. 6 http://en.wikipedia.org/wiki/List Once all senses were classified in a five sentiment sense class, we create a coarse sense inventory based on this classification. This inventory is defined in the following manner: For each word in SentiWordNet we grouped its senses with the same sentiment class in a single sense (coarse-sense), in case of objective senses these are kept separated. 2.3 Contextual Word Polarity Detection Much work on sentiment analysis have been directed to determine the polarity of opinion using anotated lexicons with prior polarity (Hatzivassiloglou and McKeown, 1997; Kamps and Marx, 2002; Turney, 2002). However a word can modify your prior polarity in relation to the context within which it is invoked. For example the word “earthquake” is used with negative meaning in the sentence : “Selling the company caused an earthquake amount the employees”. Whereas it is used in an neutral meaning in the sentence: “An earthquake is the result of a sudden release of energy in the Earth’s crust that creates seismic waves”. For this reason, our system uses a coarse-grained WSD method for obtaining the contextual polarity of all words in tweets. The selected disambigua"
S13-2083,C00-1072,0,0.11137,"e word “earthquake” is used with negative meaning in the sentence : “Selling the company caused an earthquake amount the employees”. Whereas it is used in an neutral meaning in the sentence: “An earthquake is the result of a sudden release of energy in the Earth’s crust that creates seismic waves”. For this reason, our system uses a coarse-grained WSD method for obtaining the contextual polarity of all words in tweets. The selected disambiguation method (Anaya-S´anchez et al., 2006) was developed for the traditional WSD task. In this WSD method, the senses are represented as topic signatures (Lin and Hovy, 2000) built from the repository of concepts of WordNet. The disambiguation process starts from a clustering distribution of all possible senses of the ambiguous words by applying the Extended Star clustering algorithm (Gil-Garc´ıa et al., 2003). Such a clustering tries to identify cohesive groups of word senses, which are assumed to represent different meanings for the set of words. Resource SWN HP 310 HN 938 P 2242 N 2899 O 109035 Table 1: Senses highly positive, highly negative, positive, negative and objective distributions. of emoticons 7 http://www.noslang.com/dictionary/ 503 Then, clusters th"
S13-2083,W02-1011,0,0.0379666,"exceeds 500 million (as of May 2012)5 . Through the twitter applications, users shared opinions about personalities, politicians, products, companies, events, etc. This has been attracting the attention of different research communities interested in analyzing its content and motivated many natural language tasks, such as sentiment analysis, emotions detection, opinions retrieval, product recommendation or opinion summarization. One of the most popular sentiment analysis tasks is polarity classification. This task is a new field that classifies opinion texts as positive, negative or neutral (Pang et al., 2002; Turney, 2002; Esuli and Sebastiani, 2006; Wilson et al., 2006; Wiegand et al., 2010). Determining polarity might seem an easy task, as many words have some polarity by themselves. However, words do not always express the same sentiment, and in most cases the polarity of a word depends on the context in which the word is used. So, terms that clearly denote negative feelings can be neutral, or even positive, depending on their context. Hence, sentiment analysis systems should include semantic-level analysis in order to solve word ambiguity and correctly capture the meaning of each word accordi"
S13-2083,P02-1053,0,0.0827499,"n (as of May 2012)5 . Through the twitter applications, users shared opinions about personalities, politicians, products, companies, events, etc. This has been attracting the attention of different research communities interested in analyzing its content and motivated many natural language tasks, such as sentiment analysis, emotions detection, opinions retrieval, product recommendation or opinion summarization. One of the most popular sentiment analysis tasks is polarity classification. This task is a new field that classifies opinion texts as positive, negative or neutral (Pang et al., 2002; Turney, 2002; Esuli and Sebastiani, 2006; Wilson et al., 2006; Wiegand et al., 2010). Determining polarity might seem an easy task, as many words have some polarity by themselves. However, words do not always express the same sentiment, and in most cases the polarity of a word depends on the context in which the word is used. So, terms that clearly denote negative feelings can be neutral, or even positive, depending on their context. Hence, sentiment analysis systems should include semantic-level analysis in order to solve word ambiguity and correctly capture the meaning of each word according to its cont"
S13-2083,W10-3111,1,0.826914,"hared opinions about personalities, politicians, products, companies, events, etc. This has been attracting the attention of different research communities interested in analyzing its content and motivated many natural language tasks, such as sentiment analysis, emotions detection, opinions retrieval, product recommendation or opinion summarization. One of the most popular sentiment analysis tasks is polarity classification. This task is a new field that classifies opinion texts as positive, negative or neutral (Pang et al., 2002; Turney, 2002; Esuli and Sebastiani, 2006; Wilson et al., 2006; Wiegand et al., 2010). Determining polarity might seem an easy task, as many words have some polarity by themselves. However, words do not always express the same sentiment, and in most cases the polarity of a word depends on the context in which the word is used. So, terms that clearly denote negative feelings can be neutral, or even positive, depending on their context. Hence, sentiment analysis systems should include semantic-level analysis in order to solve word ambiguity and correctly capture the meaning of each word according to its context. Also, complex linguistic processing is needed to deal with problems"
S13-2083,S13-2052,0,0.0613701,"Missing"
S13-2106,W12-0705,0,\N,Missing
S14-2128,S13-1005,0,0.0668371,"Missing"
S14-2128,O97-1002,0,0.36924,"Missing"
S14-2128,padro-stanilovsky-2012-freeling,0,0.0139048,"emphasize some cases which were used in different tasks.  All brackets were removed.  The abbreviations were expanded to their respective meanings. It was applied using a list of the most common abbreviations in English, with 819 and Spanish with 473. Phrases like “The G8” and “The Group of Eight” are detected as identical.  Deletion of hyphen to identify words forms. For example, “well-studied” was replaced by “well studied”. Example taken from line 13 of MSRpar corpus in test set of Semeval STS 2012 (Agirre, et al., 2012).  The sentences were tokenized and POStagged using Freeling 3.0 (Padró and Stanilovsky, 2012).  All contractions were expanded. For example: n&apos;t, &apos;mand &apos;s. In the case of &apos;s was replaced with “is” or “of”, “Tom&apos;s bad” to “Tom is bad” and “Tom&apos;s child” by ""Child of Tom"". (Only for English tasks).  Punctuation marks were removed from the tokens except for the decimal point in numbers.  Stop words were removed. We used a list of the most common stop words. (28 for English and 48 for Spanish).  The words were mapped to the most common sense of WordNet 3.0. (Only for Spanish task).  A syntactic tree was built for every sentence using Freeling 3.0. 1 The windows is the number of interm"
S14-2128,P94-1019,0,0.516923,"Missing"
S14-2129,E06-1027,0,0.0377617,"and intensity. Regarding research carried out for linguistic patterns identification and its polarity in texts, it is worth mentioning works on: adjectives (Hatzivassiloglou and McKeown, 1997) (Wiebe, 2000); adjectives and verbs (Turney, 2002) (Wilson, et al., 2005) (Takamura, et al., 2007); and also verbs and names (Esuli and Sebastini, 2006). WordNet (Fellbaum, 1998) has also been used for the collection of opinion adjectives and verbs (Kim and Hovy, 2005) to determine the semantic orientation of the terms depending on their notes (Esuli and Sebastiani, 2005), for the adjective extraction (Andreevskaia and Bergler, 2006) or opinion mining (Esuli and Sebastiani, 2007). Inspired on Hidden Markov models (Baum and Petrie, 1966) and following the idea that words combinations are finite in an evaluation text, we decided to create a finite automata in graph form to represent all these relations extracted from a training corpus. For the creation of this automata we utilised different resources, such as WordNet and OpinionFinder Subjectivity Lexicon. Also, different extracted patterns based on (Cazabón, 1973) were applied. This paper is structured as follows: In section 1.1 is described the task 4 of SemEval2014 (Pont"
S14-2129,P07-1054,0,0.0193781,"linguistic patterns identification and its polarity in texts, it is worth mentioning works on: adjectives (Hatzivassiloglou and McKeown, 1997) (Wiebe, 2000); adjectives and verbs (Turney, 2002) (Wilson, et al., 2005) (Takamura, et al., 2007); and also verbs and names (Esuli and Sebastini, 2006). WordNet (Fellbaum, 1998) has also been used for the collection of opinion adjectives and verbs (Kim and Hovy, 2005) to determine the semantic orientation of the terms depending on their notes (Esuli and Sebastiani, 2005), for the adjective extraction (Andreevskaia and Bergler, 2006) or opinion mining (Esuli and Sebastiani, 2007). Inspired on Hidden Markov models (Baum and Petrie, 1966) and following the idea that words combinations are finite in an evaluation text, we decided to create a finite automata in graph form to represent all these relations extracted from a training corpus. For the creation of this automata we utilised different resources, such as WordNet and OpinionFinder Subjectivity Lexicon. Also, different extracted patterns based on (Cazabón, 1973) were applied. This paper is structured as follows: In section 1.1 is described the task 4 of SemEval2014 (Pontiki, et al., 2014) where this system was presen"
S14-2129,esuli-sebastiani-2006-sentiwordnet,0,0.269826,"Missing"
S14-2129,P97-1023,0,0.0968674,"ntoyo, rafael}@dlsi.ua.es sentiments in texts that require special attention.” (Gutiérrez, et al., 2014). Sentiment Analysis or “Subjectivity Analysis” in (Liu, 2010) is defined as the computational treatment of opinions, sentiments and emotions expressed in a text. In order to automatically treat the subjectivity, we need lexical resources that allow the detection and evaluation of the affective/ subjective charges in texts, its polarity and intensity. Regarding research carried out for linguistic patterns identification and its polarity in texts, it is worth mentioning works on: adjectives (Hatzivassiloglou and McKeown, 1997) (Wiebe, 2000); adjectives and verbs (Turney, 2002) (Wilson, et al., 2005) (Takamura, et al., 2007); and also verbs and names (Esuli and Sebastini, 2006). WordNet (Fellbaum, 1998) has also been used for the collection of opinion adjectives and verbs (Kim and Hovy, 2005) to determine the semantic orientation of the terms depending on their notes (Esuli and Sebastiani, 2005), for the adjective extraction (Andreevskaia and Bergler, 2006) or opinion mining (Esuli and Sebastiani, 2007). Inspired on Hidden Markov models (Baum and Petrie, 1966) and following the idea that words combinations are finit"
S14-2129,I05-2011,0,0.0228474,"ically treat the subjectivity, we need lexical resources that allow the detection and evaluation of the affective/ subjective charges in texts, its polarity and intensity. Regarding research carried out for linguistic patterns identification and its polarity in texts, it is worth mentioning works on: adjectives (Hatzivassiloglou and McKeown, 1997) (Wiebe, 2000); adjectives and verbs (Turney, 2002) (Wilson, et al., 2005) (Takamura, et al., 2007); and also verbs and names (Esuli and Sebastini, 2006). WordNet (Fellbaum, 1998) has also been used for the collection of opinion adjectives and verbs (Kim and Hovy, 2005) to determine the semantic orientation of the terms depending on their notes (Esuli and Sebastiani, 2005), for the adjective extraction (Andreevskaia and Bergler, 2006) or opinion mining (Esuli and Sebastiani, 2007). Inspired on Hidden Markov models (Baum and Petrie, 1966) and following the idea that words combinations are finite in an evaluation text, we decided to create a finite automata in graph form to represent all these relations extracted from a training corpus. For the creation of this automata we utilised different resources, such as WordNet and OpinionFinder Subjectivity Lexicon. Al"
S14-2129,S14-2004,0,0.03348,"006) or opinion mining (Esuli and Sebastiani, 2007). Inspired on Hidden Markov models (Baum and Petrie, 1966) and following the idea that words combinations are finite in an evaluation text, we decided to create a finite automata in graph form to represent all these relations extracted from a training corpus. For the creation of this automata we utilised different resources, such as WordNet and OpinionFinder Subjectivity Lexicon. Also, different extracted patterns based on (Cazabón, 1973) were applied. This paper is structured as follows: In section 1.1 is described the task 4 of SemEval2014 (Pontiki, et al., 2014) where this system was presented. Section 2 presents the description of the automata and how it was built. The polarity assignation method using the trained automata is 722 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 722–726, Dublin, Ireland, August 23-24, 2014. described in section 3. Finally, in section 4 and 5 are shown the results and conclusions, respectively. 1.1 Task Description The SemEval2014 task 4 (Pontiki, et al., 2014) was divided into four subtasks: 4.1 Aspect term extraction; 4.2 Aspect term polarity; 4.3 Aspect category detection;"
S14-2129,P02-1053,0,0.0312937,"ion.” (Gutiérrez, et al., 2014). Sentiment Analysis or “Subjectivity Analysis” in (Liu, 2010) is defined as the computational treatment of opinions, sentiments and emotions expressed in a text. In order to automatically treat the subjectivity, we need lexical resources that allow the detection and evaluation of the affective/ subjective charges in texts, its polarity and intensity. Regarding research carried out for linguistic patterns identification and its polarity in texts, it is worth mentioning works on: adjectives (Hatzivassiloglou and McKeown, 1997) (Wiebe, 2000); adjectives and verbs (Turney, 2002) (Wilson, et al., 2005) (Takamura, et al., 2007); and also verbs and names (Esuli and Sebastini, 2006). WordNet (Fellbaum, 1998) has also been used for the collection of opinion adjectives and verbs (Kim and Hovy, 2005) to determine the semantic orientation of the terms depending on their notes (Esuli and Sebastiani, 2005), for the adjective extraction (Andreevskaia and Bergler, 2006) or opinion mining (Esuli and Sebastiani, 2007). Inspired on Hidden Markov models (Baum and Petrie, 1966) and following the idea that words combinations are finite in an evaluation text, we decided to create a fin"
S14-2129,H05-1044,0,0.42261,"z, et al., 2014). Sentiment Analysis or “Subjectivity Analysis” in (Liu, 2010) is defined as the computational treatment of opinions, sentiments and emotions expressed in a text. In order to automatically treat the subjectivity, we need lexical resources that allow the detection and evaluation of the affective/ subjective charges in texts, its polarity and intensity. Regarding research carried out for linguistic patterns identification and its polarity in texts, it is worth mentioning works on: adjectives (Hatzivassiloglou and McKeown, 1997) (Wiebe, 2000); adjectives and verbs (Turney, 2002) (Wilson, et al., 2005) (Takamura, et al., 2007); and also verbs and names (Esuli and Sebastini, 2006). WordNet (Fellbaum, 1998) has also been used for the collection of opinion adjectives and verbs (Kim and Hovy, 2005) to determine the semantic orientation of the terms depending on their notes (Esuli and Sebastiani, 2005), for the adjective extraction (Andreevskaia and Bergler, 2006) or opinion mining (Esuli and Sebastiani, 2007). Inspired on Hidden Markov models (Baum and Petrie, 1966) and following the idea that words combinations are finite in an evaluation text, we decided to create a finite automata in graph f"
S14-2129,N07-1037,0,\N,Missing
S14-2129,atserias-etal-2006-freeling,0,\N,Missing
S14-2129,S13-2073,1,\N,Missing
S14-2130,S12-1090,1,0.886071,"Missing"
S14-2130,S13-2073,1,0.871126,"Missing"
S14-2130,S13-2053,0,0.116044,"ch is (Turney, 2002), which classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents. There are a large quantity of approaches to deal with SA, and basically most of them are based on word bags and/or annotated corpora as knowledge base. Based on this information the SA systems are able to apply different types of evaluation techniques such as machine learning or statistic formulas to predict the correct classification. As part of machine learning approaches we would like to mention those works such as (Go et al., 2009), (Mohammad et al., 2013) and others that were based on feature vectors and which cover a wide range settings of SA. As a starting point, we based this work on the (Mohammad et al., 2013) approach, adding This paper describes a system submitted to SemEval-2014 Task 4B: Sentiment Analysis in Twitter, by the team UMCC DLSI Sem integrated by researchers of the University of Matanzas, Cuba and the University of Alicante, Spain. The system adopts a cascade classification process that uses two classifiers, K-NN using the lexical Levenshtein metric and a Dagging model trained over attributes extracted from annotated corpora"
S14-2130,padro-stanilovsky-2012-freeling,0,0.0555938,"Missing"
S14-2130,W02-1011,0,0.0181017,"Missing"
S14-2130,P02-1053,0,0.012914,"Missing"
S14-2137,C10-3014,0,0.0115435,"corpus. PageRank algorithm (Page et al., 1999) was adapted to be used on graphs with positive and negative edges, in order to obtain the semantic orientation of words. Despite the wide range of existing proposals for resources construction, the results achieved with them are far from expected. As we have already seen, in aspect based sentiment analysis, the polarity of a word is heavily dependent on the domain; and general propose sentiment resource such as General Inquirer (Stone et al., 1966), WordNet-Affect(Strapparava and Valitutti, 2004), SentiWordNet(Baccianella et al., 2010) or HowNet (Dong et al., 2010) do not capture this dependency. On the other hand, the human annotators can not create specific sentiment resources for each new product launched to market. Therefore, propose methods to create these resources is a challenging task. In this paper we address this task, presenting a framework for building domain-dependent sentiment resource. Our proposal is compounded of four phases. (See figure 1). Firstly, review pages about the product of interest can be retrieved from different websites, for instance, Ciao, Epinions and Cnet (in this work we only use reviews from Ciao). This reviews are par"
S14-2137,S13-2073,1,0.888625,"Missing"
S14-2137,P97-1023,0,0.0328977,"t sentiment resource for Laptop domain applying LSA. The second phase obtains the words related by means of some dependency relation with the aspect, and later, the polarity of these words are obtained from induced polarity lexicon and combined for computing overall aspect polarity. 2.1 Domain-Dependent Polarity Lexicon The use of sentiment resource has been proven to be useful to build, train, and evaluate systems for sentiment analysis (Guti´errez et al., 2013; Balahur, 2011). In order to build sentiment resource, several approach has been presented. In one of the first works, presented by (Hatzivassiloglou and McKeown, 1997), was proposed to take into ac6 774 https://docs.python.org/2/library/xml.html LSAscore (li , lj ) = < vi , vj > k vi k · k vj k (1) Finally, the polarity lexicon contains lemmas li and its positive and negative scores. This values are computed using LSAscore (li , tpos ) and LSAscore (li , tneg ) respectively. The table 1 show some top positive and negative words computed with this strategy. Positive sturdy superb durable sexy powerfull robust affordable suuupeerrr lighweight unbreakable Figure 1: Building domain-dependent sentiment resource. Subsequently, the samples are preprocessed, applyi"
S14-2137,baccianella-etal-2010-sentiwordnet,0,0.0359778,"of adjectives, observed in a review corpus. PageRank algorithm (Page et al., 1999) was adapted to be used on graphs with positive and negative edges, in order to obtain the semantic orientation of words. Despite the wide range of existing proposals for resources construction, the results achieved with them are far from expected. As we have already seen, in aspect based sentiment analysis, the polarity of a word is heavily dependent on the domain; and general propose sentiment resource such as General Inquirer (Stone et al., 1966), WordNet-Affect(Strapparava and Valitutti, 2004), SentiWordNet(Baccianella et al., 2010) or HowNet (Dong et al., 2010) do not capture this dependency. On the other hand, the human annotators can not create specific sentiment resources for each new product launched to market. Therefore, propose methods to create these resources is a challenging task. In this paper we address this task, presenting a framework for building domain-dependent sentiment resource. Our proposal is compounded of four phases. (See figure 1). Firstly, review pages about the product of interest can be retrieved from different websites, for instance, Ciao, Epinions and Cnet (in this work we only use reviews fr"
S14-2137,padro-stanilovsky-2012-freeling,0,0.0253973,"Missing"
S14-2137,S14-2004,0,0.447952,"making a final decision. The most important benefit of having that amount of user-generated content on hand, specifically product’s reviews, is that, these data can be explored by a computer system to obtain information about products and their features. The task of aspect-based sentiment analysis (Liu, 2012) is a fine-grained level of Sentiment Analysis (Pang and Lee, 2008). This aim to identify the aspects (e.g., battery, screen, food, service, size, weight, time-life) of given target entities In this paper we present our contribution to SemEval-2014 Task 4: Aspect Based Sentiment Analysis (Pontiki et al., 2014), Subtask 2: Aspect Term Polarity for Laptop domain. The most outstanding feature in this contribution is the automatic building of a domain-depended sentiment resource using Latent Semantic Analysis. We induce, for each term, two real scores that indicate its use in positive and negative contexts in the domain of interest. The aspect term polarity classification is carried out in two phases: opinion words extraction and polarity classification. The opinion words related with an aspect are obtained using dependency relations. These relations are provided by the Stanford Parser1 . Finally, the"
S14-2137,strapparava-valitutti-2004-wordnet,0,0.118844,"Missing"
W04-0859,J96-1002,0,0.0145378,"Missing"
W04-0859,H93-1021,0,0.110297,"Missing"
W04-0859,magnini-cavaglia-2000-integrating,0,0.0589769,"Missing"
W04-0859,W00-0804,0,0.0167167,"ystem: Heuristic of Hypernym, Heuristic of Definition, Heuristic of Common Specification Mark, Heuristic of Gloss Hypernym, Heuristic of Hyponym and Heuristic of Gloss Hyponym. 2.3 Relevant Domains This is an unsupervised WSD method based on the WordNet Domains lexical resource (Magnini and Cavaglia, 2000). The underlying working hypothesis is that domain labels, such as ARCHITECTURE, SPORT and MEDICINE provide a natural way to establish semantic relations between word senses, that can be used during the disambiguation process. This resource has already been used on Word Sense Disambiguation (Magnini and Strapparava, 2000), but it has not made use of glosses information. So our approach make use of a new lexical resource obtained from glosses information named Relevant Domains. First step is to obtain the Relevant Domains resource from WordNet glosses. For this task is necessary a previous part-of-speech tagging of WordNet glosses (each gloss has associated a domain label). So we extract all nouns, verbs, adjectives and adverbs from glosses and assign them their associated domain label. With this information and using the Association Ratio formula (w=word,D=domain label), in (1), we obtain the Relevant Domains"
W04-0859,C02-1115,1,0.878235,"Missing"
W04-0860,J96-1002,0,0.00583013,"Missing"
W04-0860,S01-1021,0,0.0282556,"Missing"
W04-0860,H93-1021,0,0.107768,"Missing"
W04-0860,magnini-cavaglia-2000-integrating,0,0.069106,"Missing"
W04-0860,W00-0804,0,0.0318479,"Missing"
W04-0860,H93-1061,0,0.0319406,"Missing"
W04-0860,S01-1032,1,0.888815,"Missing"
W04-0860,C02-1115,1,0.898812,"Missing"
W04-0860,J01-2002,0,0.0585865,"Missing"
W04-0861,W04-0828,1,0.681474,"Missing"
W04-0861,W04-0837,1,0.823382,"Missing"
W04-0861,P94-1013,0,0.0414439,"Catalonia. The integration was carried out by the TALP group.   Naive Bayes (NB) is the well–known Bayesian algorithm that classifies an example by choosing the class that maximizes the product, over all features, of the conditional probability of the class given the feature. The provider of this module is IXA. Conditional probabilities were smoothed by Laplace correction.  Decision List (DL) are lists of weighted classification rules involving the evaluation of one single feature. At classification time, the algorithm applies the rule with the highest weight that matches the test example (Yarowsky, 1994). The provider is IXA and they also applied smoothing to generate more robust decision lists.  In the Vector Space Model method (cosVSM), each example is treated as a binary-valued feature vector. For each sense, one centroid vector is obtained from training. Centroids are compared with the vectors representing test examples, using the cosine similarity function, and the closest centroid is used to classify the example. No smoothing is required for this method provided by IXA. 2 The WSD Modules Support Vector Machines (SVM) find the hyperplane (in a high dimensional feature space) that separa"
W07-1703,P98-1012,0,0.0460838,"wering system. According to the obtained results, the precision of the ontology is high, 20 but still suffers in coverage. A similar approach for the population of the CyC Knowledge Base (KB) was presented in (Shah et al., 2006). They used information from the Web and other electronically available text corpora to gather facts about particular named entities, to validate and finally to add them to the CyC KB. In this paper, we present a new text semantic similarity approach for fine-grained person name categorization and discrimination which is similar to those of (Pedersen et al., 2005) and (Bagga and Baldwin, 1998), but instead of simple word co-occurrences, we consider the whole text segment and relate the deduced semantic information of Latent Semantic Analysis (LSA) to trace the text cohesion between thousands of sentences containing named entities which belong to different fine-grained categories or individuals. Our method is based on the word sense discrimination hypothesis of Miller and Charles (1991) according to which words with similar meaning are used in similar context, hence in our approach we assume that the same person or the same fine-grained person category appears in the similar context"
W07-1703,C02-1130,0,0.0876544,"Missing"
W07-1703,W02-1111,0,0.0797503,"Missing"
W07-1703,J98-1004,0,0.0891578,"Missing"
W07-1703,E06-1003,0,0.040534,"Missing"
W07-1703,C98-1012,0,\N,Missing
W09-4304,P08-1036,0,0.0427134,"er identifying possible opinion text spans. The useful features to locate opinion quotations within a text included location within the paragraph and document, and the type of words they contained. Similarly, in [19] the relevant features and opinion words with their polarity (whether a positive or a negative sentiment) are identified, and then, after detecting all valid feature-opinion pairs, a summary is produced, but focusing only in movie reviews. Normally, online reviews also contain numerical ratings that users insert when providing their personal opinions about a product or service. In [20] a Multi-Aspect Sentiment model is proposed. This statistical model uses aspect ratings to discover the corresponding topics and extract fragments of text. Our work differs from the ones abovementioned since we take into account the posts written in real blogs, to further build a summary of the most relevant opinions contained in them, based on their polarity. 4. Corpus collection and labeling The corpus we employed in this study is a collection of 51 blogs extracted from the Web. This is a limited dataset which allows for a preliminary study in the field; however, in our future work we would"
W09-4304,strapparava-valitutti-2004-wordnet,0,0.052812,"arity (among positive and negative) and a numerical value corresponding to the polarity strength (the higher the negative score, the more negative the sentence and similarly, the higher the positive score, the more positive the sentence). Given that we are faced with the task of classifying opinion in a general context, we employed a simple, yet efficient approach, presented in [25]. At the present moment, there are different lexicons for affect detection and opinion mining. In order to have a more extensive database of affect-related terms, in the following experiments we used WordNet Affect [22], SentiWordNet [23], MicroWNOp [24]. Each of the employed resources were mapped to four categories, which were given different scores: positive (1), negative (-1), high positive (4) and high negative (-4). As shown in [25], these values performed better than the usual assignment of only positive (1) and negative (-1) values. First, the score of each of the blog posts was computed as sum of the values of the words identified; a positive score leads to the classification of the post as positive, whereas a final negative score leads to the system classifying the post as negative. Subsequently, we"
W09-4304,D07-1114,0,0.0219916,"mary. In general, this would avoid spending much of their time reading all the reviews to find what they are looking for, as the system offers them summaries of pros and cons of a topic. This would be one of the possible ways to exploit the huge amount of data the Web offers. 2. Motivation and contribution The explosive increase in Web communication has attracted interest in technologies for automatically mining personal opinions from different kinds of Web documents, such as product reviews, blogs or forums. These technologies would benefit users who seek reviews on certain consumer products [11]. In fact, at the time of taking a decision, more and more people search for subjective information expressed on the Web on their matter of interest and base their final decision on the information found [12]. Not less important is also the fact that people interested in news and how they are reflected in the world wide opinion often use both newspaper sources, as well as blogs, in order to follow the development of news and the corresponding opinion. For this reason, we believe opinion summarization could represent a useful tool, on the one hand to help users to take decisions quickly and, on"
W09-4304,C08-1019,0,0.0197155,"ion The evaluation of summaries is a difficult task. On the one hand, automatic systems for evaluating summaries require reference summaries written by humans, and this is a very time-consuming task. Moreover, different humans would produce diverse summaries, resulting in several possible correct summaries as gold standard, making this fact another problem for the evaluation. In [26] it was shown how the result for a summary changed depending on which human summary was taken as reference for comparison with the automatic one. This problem was also presented in [27] and [28]. More recently, in [29] they stated the need of performing a more qualitative evaluation rather than a quantitative one, since summaries must contain relevant information, but at the same time, they should have an acceptable quality in order to be useful for other tasks or applications. In the DUC 4 and TAC conferences, summaries are evaluated manually taking into account several linguistic quality criteria, such as grammaticality or structure and coherence, for example. In this paper, we have adopted a similar approach for evaluating the generated summaries. We focus more on the quality of the summaries rather than"
W09-4304,W00-0408,0,\N,Missing
W09-4304,W97-0704,0,\N,Missing
W09-4304,P08-1000,0,\N,Missing
W09-4304,esuli-sebastiani-2006-sentiwordnet,0,\N,Missing
W10-1801,esuli-sebastiani-2006-sentiwordnet,0,0.556445,"ter of interest and base their final decision on the information found. At the same time, when using a product, people often write reviews on it, so that others can have a better idea of the performance of that product before purchasing it. Therefore, on the one hand, the growing volume of opinion information available on the Web allows for better and more informed decisions of the users. On the other hand, the amount of data to be analyzed requires the development of specialized NLP systems that automatically extract, classify and summarize the data available on the Web on different topics. (Esuli and Sebastiani, 2006) define OM as a recent discipline at the crossroads of Information Retrieval and Computational Linguistics, which is concerned not with the topic a document is about, but with the opinion it expresses. Research in this field has proven the task to be very difficult, due to the high semantic variability of affective language. Different authors have addressed the problem of extracting and classifying opinion from different perspectives and at different levels, depending on a series of factors which can be level of interest (overall/specific), querying formula (“Nokia E65”/”Why do people buy Noki"
W10-1801,W06-3808,0,0.0711775,"Missing"
W10-1801,C00-1044,0,0.107286,"Missing"
W10-1801,C04-1200,0,0.0132842,"cation on customer feedback data (Gamon, Aue, Corston-Oliver, Ringger, 2005), comparative experiments (Cui, Mittal and Datar, 2006). Other research has been conducted in analysing sentiment at a sentence level using bootstrapping techniques (Riloff, Wiebe, 2003), considering gradable adjectives (Hatzivassiloglou, Wiebe, 2000), semisupervised learning with the initial training some strong patterns and then applying NB or self-training (Wiebe and Riloff, 2005) finding strength of opinions (Wolson, Wiebe, Hwa, 2004) sum up orientations of opinion words in a sentence (or within some word window) (Kim and Hovy, 2004), (Wilson and Wiebe, 2004), determining the semantic orientation of words and phrases (Turney and Littman, 2003), identifying opinion holders (Stoyanov and Cardie, 2006), comparative sentence and relation extraction and feature-based opinion mining and summarization (Turney, 2002). Finally, finegrained, feature-based opinion summarization is defined in (Hu and Liu, 2004) and researched in (Turney, 2002) or (Pang and Lee, 2002). All these approaches concentrate on finding and classifying the polarity of opinion words, which are mostly adjectives, without taking into account modifiers or the con"
W10-1801,P06-2079,0,0.15122,"Missing"
W10-1801,W02-1011,0,0.0175676,"Missing"
W10-1801,W03-1014,0,0.0393085,"ur and Montoyo, 2008), who centered the idea of subjectivity around that of private states, and set the benchmark for subjectivity analysis as the recognition of opinion-oriented language in order to distinguish it from objective language and giving a method to annotate a corpus depending on these two aspects – MPQA (Wiebe, Wilson and Cardie, 2005). Furthermore, authors show that this initial discrimination is crucial for the sentiment task, as part of Opinion Information Retrieval (last three editions of the TREC Blog tracks 3 competitions, the TAC 2008 competition4), Information Extraction (Riloff and Wiebe, 2003) and Question Answering (Stoyanov et al., 2004) systems. Once this discrimination is done, or in the case of texts containing only or mostly subjective language (such as e-reviews), opinion mining becomes a polarity classification task. Our work takes into consideration this initial discrimination, but we also add a deeper level of emotion annotation. Since expressions of emotion are also highly related to opinions, related work also includes customer review classification at a document level, sentiment classification using unsupervised methods (Turney, 2002), Machine Learning techniques (Pang"
W10-1801,strapparava-valitutti-2004-wordnet,0,0.37642,"Missing"
W10-1801,W06-0302,0,0.0192034,"cted in analysing sentiment at a sentence level using bootstrapping techniques (Riloff, Wiebe, 2003), considering gradable adjectives (Hatzivassiloglou, Wiebe, 2000), semisupervised learning with the initial training some strong patterns and then applying NB or self-training (Wiebe and Riloff, 2005) finding strength of opinions (Wolson, Wiebe, Hwa, 2004) sum up orientations of opinion words in a sentence (or within some word window) (Kim and Hovy, 2004), (Wilson and Wiebe, 2004), determining the semantic orientation of words and phrases (Turney and Littman, 2003), identifying opinion holders (Stoyanov and Cardie, 2006), comparative sentence and relation extraction and feature-based opinion mining and summarization (Turney, 2002). Finally, finegrained, feature-based opinion summarization is defined in (Hu and Liu, 2004) and researched in (Turney, 2002) or (Pang and Lee, 2002). All these approaches concentrate on finding and classifying the polarity of opinion words, which are mostly adjectives, without taking into account modifiers or the context in general. Our work, on the other hand, represents the first step towards achieving a contextual comprehension of the linguistic roots of emotion expression. 5 the"
W10-1801,R09-1004,1,0.922555,"containing personal judgments. At the moment, NLP tools and methods for analyzing objective information have a better performance than the new ones the research community is creating for managing the subjective content. The survey called “The State of the Blogosphere 2009”, published by Technorati 1 , demonstrates that users are blogging more than ever. Furthermore, in contrast to the general idea about bloggers, each day it is more and more the number of professionals who decide to use this means of communication, contradicting the common belief about the predominance of an informal editing (Balahur et al., 2009). Due to the growing interest in this text type, the subjective data of the Web is increasing on a daily basis, becoming a reflection of people’s opinion about a wide range of topics. (Cui, Mittal and Datar, 2006). Blogs represent an important source of real-time, unbiased information, useful for the development of many applications for concrete purposes. Given the proved importance of automatically processing this data, a new task has appeared in NLP task, dealing with the treatment of subjective data: Sentiment Analysis (SA). The main objective of this paper is to present EmotiBlog (Boldrini"
W10-1801,W09-4304,1,0.885646,"containing personal judgments. At the moment, NLP tools and methods for analyzing objective information have a better performance than the new ones the research community is creating for managing the subjective content. The survey called “The State of the Blogosphere 2009”, published by Technorati 1 , demonstrates that users are blogging more than ever. Furthermore, in contrast to the general idea about bloggers, each day it is more and more the number of professionals who decide to use this means of communication, contradicting the common belief about the predominance of an informal editing (Balahur et al., 2009). Due to the growing interest in this text type, the subjective data of the Web is increasing on a daily basis, becoming a reflection of people’s opinion about a wide range of topics. (Cui, Mittal and Datar, 2006). Blogs represent an important source of real-time, unbiased information, useful for the development of many applications for concrete purposes. Given the proved importance of automatically processing this data, a new task has appeared in NLP task, dealing with the treatment of subjective data: Sentiment Analysis (SA). The main objective of this paper is to present EmotiBlog (Boldrini"
W10-1801,J96-2004,0,0.0222684,"Missing"
W10-1801,H05-1045,0,0.0151555,"nsert for each element the source and topic. An example of annotation can be: &lt;phenomenon 6.1 Creation of training models For the OM and polarity classification task, we first extracted the Named Entities contained in the annotations using Lingpipe and united through a “_” all the tokens pertaining to the NE. All the annotations of punctuation signs that had a specific meaning together were also united under a single punctuation sign. Subsequently, we processed the annotated data, using Minipar. We compute, for each word in a sentence, a series of features (some of these features are used in (Choi et al., 2005): • the part of speech (POS) • capitalization (if all letters are in capitals, if only the first letter is in capitals, and if it is a NE or not) • opinionatedness/intensity/emotion - if the word is annotated as opinion word, its polarity, i.e. 1 and -1 if the word is positive or negative, respectively and 0 if it is not an opinion word, its intensity (1.2 or 3) and 0 if it is not a subjective word, its emotion (if it has, none otherwise) • syntactic relatedness with other opinion word – if it is directly dependent of an opinion word or modifier (0 or 1), plus the polarity/intensity and emotio"
W10-1801,P02-1053,0,0.0173461,"Information Extraction (Riloff and Wiebe, 2003) and Question Answering (Stoyanov et al., 2004) systems. Once this discrimination is done, or in the case of texts containing only or mostly subjective language (such as e-reviews), opinion mining becomes a polarity classification task. Our work takes into consideration this initial discrimination, but we also add a deeper level of emotion annotation. Since expressions of emotion are also highly related to opinions, related work also includes customer review classification at a document level, sentiment classification using unsupervised methods (Turney, 2002), Machine Learning techniques (Pang and Lee, 2002), scoring of features (Dave, Lawrence and Pennock, 2003), using PMI, syntactic relations 3 3 http://trec.nist.gov/data/blog.html 4 http://www.nist.gov/tac/ and other attributes with SVM (Mullena and Collier, 2004), sentiment classification considering rating scales (Pang and Lee, 2002), supervised and unsupervised methods (Chaovalit and Zhou, 2005) and semisupervised learning (Goldberg and Zhou, 2006). Research in classification at a document level included sentiment classification of reviews (Ng, Dasgupta and Arifin, 2006), sentiment classific"
W10-1801,J94-2004,0,0.0597722,"been supported by Ministerio de Ciencia e Innovación- Spanish Government (grant no. TIN2009-13391-C0401), and Conselleria d&apos;EducaciónGeneralitat Valenciana (grant no. PROMETEO/2009/119 and ACOMP/2010/288). 1 http://technorati.com/ 1 Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 1–10, c Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguistics can be reflected in text through expressions of emotions beliefs, views (a way of considering something) 2 and opinions, generally denominated “private states” (Uspensky, 1973), not open to verification (Wiebe, 1994). We performed a series of experiments focused on demonstrating that EmotiBlog represents a step forward to previous research in this field; its use allows a finer-grained and more precise learning of subjectivity expression models. Starting form (Wiebe, Wilson and Cardie, 2005) we created an annotation schema able to capture a wide range and key elements, which give subjectivity, moving a step forward the mere polarity recognition. In particular, the experiments concern expressions of emotion, as a finer-grained analysis of affect in text and a subsequent task to opinion mining (OM) and class"
W10-1801,W04-3253,0,\N,Missing
W10-1801,balahur-etal-2010-sentiment,1,\N,Missing
W10-1801,S07-1013,0,\N,Missing
W10-1801,W06-2915,0,\N,Missing
W10-3111,D09-1020,0,0.0238775,"inguistic phenomenon. In this section, we present the limits of negation modeling in sentiment analysis. Earlier in this paper, we stated that negation modeling depends on the knowledge of polar expressions. However, the recognition of genuine polar expressions is still fairly brittle. Many polar expressions, such as disease are ambiguous, i.e. they have a polar meaning in one context (Sentence 12) but do not have one in another (Sentence 13). 12. He is a disease to every team he has gone to. 13. Early symptoms of the disease are headaches, fevers, cold chills and body pain. In a pilot study (Akkaya et al., 2009), it has already been shown that applying subjectivity word sense disambiguation in addition to the featurebased negation modeling approach of Wilson et al. (2005) results in an improvement of performance in polarity classification. Another problem is that some polar opinions are not lexicalized. Sentence 14 is a negative pragmatic opinion (Somasundaran and Wiebe, 2009) which can only be detected with the help of external world knowledge. 67 14. The next time I hear this song on the radio, I’ll throw my radio out of the window. Moreover, the effectiveness of specific negation models can only b"
W10-3111,D08-1083,0,0.59404,"a more abstract level of representation being verb frames. The advantage of a more abstract level of representation is that it more accurately represents the meaning of the text it describes. Apart from that, Shaikh et al. (2007) design a model for sentence-level classification rather than for headlines or complex noun phrases. The approach by Moilanen and Pulman (2007) is not compared against another established classification method whereas the approach by Shaikh et al. (2007) is evaluated against a non-compositional rule-based system which it outperforms. 3.3.2 Shallow Semantic Composition Choi and Cardie (2008) present a more lightweight approach using compositional semantics towards classifying the polarity of expressions. Their working assumption is that the polarity of a phrase can be computed in two steps: An example rule, such as: P olarity([NP1]− [IN] [NP2]− ) = + (3) may be applied to expressions, such as − [lack]− NP1 [of]IN [crime]NP2 in rural areas. The advantage of these rules is that they restrict the scope of negation to specific constituents rather than using the scope of the entire target expression. Such inference rules are very reminiscent of polarity modification features (Wilson e"
W10-3111,R09-1034,0,0.0161424,"outperforms the (plain) rule-based method. 3.3.3 Scope Modeling In sentiment analysis, the most prominent work examining the impact of different scope models for negation is (Jia et al., 2009). The scope detection method that is proposed considers: • static delimiters • dynamic delimiters • heuristic rules focused on polar expressions Static delimiters are unambiguous words, such as because or unless marking the beginning of another clause. Dynamic delimiters are, however, 4 It is probably due to the latter, that these rules have been successfully re-used in subsequent works, most prominently Klenner et al. (2009). • the assessment of polarity of the constituents 64 ambiguous, e.g. like and for, and require disambiguation rules, using contextual information such as their pertaining part-of-speech tag. These delimiters suitably account for various complex sentence types so that only the clause containing the negation is considered. The heuristic rules focus on cases in which polar expressions in specific syntactic configurations are directly preceded by negation words which results in the polar expression becoming a delimiter itself. Unlike Choi and Cardie (2008), these rules require a proper parse and"
W10-3111,D09-1131,0,0.0065067,"lexicalized, such as flaw-less, and are consequently to be found a polarity lexicon, this phenomenon does not need to be accounted for in sentiment analysis. However, since this process is (at least theoretically) productive, fairly uncommon words, such as not-so-nice, anti-war or offensiveless which are not necessarily contained in lexical resources, may emerge as a result of this process. Therefore, a polarity classifier should also be able to decompose words and carry out negation modeling within words. There are only few works addressing this particular aspect (Moilanen and Pulman, 2008; Ku et al., 2009) so it is not clear how much impact this type of negation has on an overall polarity classification and what complexity of morphological analysis is really necessary. We argue, however, that in synthetic languages where negation may regularly be realized as an affix rather than an individual word, such an analysis is much more important. • the entire sentence 3.5 Negation in Various Languages • a simple negation scope using a fixed window size (similar to the negation feature in (Wilson et al., 2005)) The proposed method consistently outperforms the simpler methods proving that the incorporati"
W10-3111,D09-1017,0,0.0443385,"ruction. 10. Peter mag den Kuchen nicht. Peter likes the cake not. ‘Peter does not like the cake.’ 11. Der Kuchen ist nicht k¨ostlich. The cake is not delicious. ‘The cake is not delicious.’ These items show that, clearly, some more extensive cross-lingual examination is required in order to be able to make statements of the general applicability of specific negation models. 3.6 Bad and Not Good are Not the Same The standard approach of negation modeling suggests to consider a negated polar expression, such as not bad, as an unnegated polar expression with the opposite polarity, such as good. Liu and Seneff (2009) claim, however, that this is an oversimplification of language. Not bad and good may have the same polarity but they differ in their respective polar strength, i.e. not bad is less positive than good. That is why, Liu and Seneff (2009) suggest a compositional model in which for individual adjectives and adverbs (the latter include negations) a prior rating score encoding their intensity and polarity is estimated from pros and cons of on-line reviews. Moreover, compositional rules for polar phrases, such as adverb-adjective or negation-adverb-adjective are defined exclusively using the scores"
W10-3111,W09-1105,0,0.0426758,"hod consistently outperforms the simpler methods proving that the incorporation of linguistic insights into negation modeling is meaningful. Even on polarity document retrieval, i.e. a more coarse-grained classification task where contextual disambiguation usually results in a less significant improvement, the proposed method also outperforms the other scopes examined. There have only been few research efforts in sentiment analysis examining the impact of scope modeling for negation in contrast to other research areas, such as the biomedical domain (Huang and Lowe, 2007; Morante et al., 2008; Morante and Daelemans, 2009). This is presumably due to the fact that only for the biomedical domain, publicly available corpora containing annotation for the scope of negation exist (Szarvas et al., 2008). The 65 Current research in sentiment analysis mainly focuses on English texts. Since there are significant structural differences among the different languages, some particular methods may only capture the idiosyncratic properties of the English language. This may also affect negation modeling. The previous section already stated that the need for morphological analyses may differ across the different languages. Moreo"
W10-3111,D08-1075,0,0.0762849,"005)) The proposed method consistently outperforms the simpler methods proving that the incorporation of linguistic insights into negation modeling is meaningful. Even on polarity document retrieval, i.e. a more coarse-grained classification task where contextual disambiguation usually results in a less significant improvement, the proposed method also outperforms the other scopes examined. There have only been few research efforts in sentiment analysis examining the impact of scope modeling for negation in contrast to other research areas, such as the biomedical domain (Huang and Lowe, 2007; Morante et al., 2008; Morante and Daelemans, 2009). This is presumably due to the fact that only for the biomedical domain, publicly available corpora containing annotation for the scope of negation exist (Szarvas et al., 2008). The 65 Current research in sentiment analysis mainly focuses on English texts. Since there are significant structural differences among the different languages, some particular methods may only capture the idiosyncratic properties of the English language. This may also affect negation modeling. The previous section already stated that the need for morphological analyses may differ across"
W10-3111,P06-2079,0,0.0191036,"ion, e.g. it does not matter whether a classifier cannot model a negation if the text to be classified contains twenty polar opinions and only one or two contain a negation. Another advantage of these machine learning approaches on coarsegrained classification is their usage of higher order n-grams. Imagine a labeled training set of documents contains frequent bigrams, such as not appealing or less entertaining. Then a feature set using higher order n-grams implicitly contains negation modeling. This also partially explains the effectiveness of bigrams and trigrams for this task as stated in (Ng et al., 2006). The dataset used for the experiments in (Pang et al., 2002; Ng et al., 2006) has been established as a popular benchmark dataset for sentiment analysis and is publicly available1 . 3.2 Incorporating Negation in Models that Include Knowledge of Polar Expressions - Early Works The previous subsection suggested that appropriate negation modeling for sentiment analysis requires the awareness of polar expressions. One way of obtaining such expressions is by using a 1 http://www.cs.cornell.edu/people/ pabo/movie-review-data 62 polarity lexicon which contains a list of polar expressions and for eac"
W10-3111,P04-1035,0,0.019708,"sk dealing with the automatic detection and classification of opinions expressed in text written in natural language. Subjectivity is defined as the linguistic expression of somebody’s opinions, sentiments, emotions, evaluations, beliefs and speculations (Wiebe, 1994). Subjectivity is opposed to objectivity, which is the expression of facts. It is important to make the distinction between subjectivity detection and sentiment analysis, as they are two separate tasks in natural language processing. Sentiment analysis can be dependently or independently done from subjectivity detection, although Pang and Lee (2004) state that subjectivity detection performed prior to the sentiment analysis leads to better results in the latter. Although research in this area has started only recently, the substantial growth in subjective information on the world wide web in the past years has made sentiment analysis a task on which constantly growing efforts have been concentrated. The body of research published on sentiment analysis has shown that the task is difficult, not only due to the syntactic and semantic variability of language, but also because it involves the extraction of indirect or implicit assessments of"
W10-3111,W02-1011,0,0.0170526,"m these examples, modeling negation is a difficult yet important aspect of sentiment analysis. 3 The Survey In this survey, we focus on work that has presented novel aspects for negation modeling in sentiment analysis and we describe them chronologically. 3.1 Negation and Bag of Words in Supervised Machine Learning Several research efforts in polarity classification employ supervised machine-learning algorithms, like Support Vector Machines, Na¨ıve Bayes Classifiers or Maximum Entropy Classifiers. For these algorithms, already a low-level representation using bag of words is fairly effective (Pang et al., 2002). Using a bag-of-words representation, the supervised classifier has to figure out by itself which words in the dataset, or more precisely feature set, are polar and which are not. One either considers all words occurring in a dataset or, as in the case of Pang et al. (2002), one carries out a simple feature selection, such as removing infrequent words. Thus, the standard bag-of-words representation does not contain any explicit knowledge of polar expressions. As a consequence of this simple level of representation, the reversal of the polarity type of polar expressions as it is caused by a ne"
W10-3111,P09-1026,0,0.00780997,"r meaning in one context (Sentence 12) but do not have one in another (Sentence 13). 12. He is a disease to every team he has gone to. 13. Early symptoms of the disease are headaches, fevers, cold chills and body pain. In a pilot study (Akkaya et al., 2009), it has already been shown that applying subjectivity word sense disambiguation in addition to the featurebased negation modeling approach of Wilson et al. (2005) results in an improvement of performance in polarity classification. Another problem is that some polar opinions are not lexicalized. Sentence 14 is a negative pragmatic opinion (Somasundaran and Wiebe, 2009) which can only be detected with the help of external world knowledge. 67 14. The next time I hear this song on the radio, I’ll throw my radio out of the window. Moreover, the effectiveness of specific negation models can only be proven with the help of corpora containing those constructions or the type of language behaviour that is reflected in the models to be evaluated. This presumably explains why rare constructions, such as negations using connectives (Sentence 6 in §2), modals (Sentence 7 in §2) or other phenomena presented in the conceptual model of Polanyi and Zaenen (2004), have not y"
W10-3111,W08-0606,0,0.042933,"more coarse-grained classification task where contextual disambiguation usually results in a less significant improvement, the proposed method also outperforms the other scopes examined. There have only been few research efforts in sentiment analysis examining the impact of scope modeling for negation in contrast to other research areas, such as the biomedical domain (Huang and Lowe, 2007; Morante et al., 2008; Morante and Daelemans, 2009). This is presumably due to the fact that only for the biomedical domain, publicly available corpora containing annotation for the scope of negation exist (Szarvas et al., 2008). The 65 Current research in sentiment analysis mainly focuses on English texts. Since there are significant structural differences among the different languages, some particular methods may only capture the idiosyncratic properties of the English language. This may also affect negation modeling. The previous section already stated that the need for morphological analyses may differ across the different languages. Moreover, the complexity of scope modeling may also be language dependent. In English, for example, modeling the scope of a negation as a fixed window size of words following the occ"
W10-3111,J94-2004,0,0.0714206,"arious computational approaches modeling negation in sentiment analysis. We will, in particular, focus on aspects, such as level of representation used for sentiment analysis, negation word detection and scope of negation. We will also discuss limits and challenges of negation modeling on that task. 1 Introduction Sentiment analysis is the task dealing with the automatic detection and classification of opinions expressed in text written in natural language. Subjectivity is defined as the linguistic expression of somebody’s opinions, sentiments, emotions, evaluations, beliefs and speculations (Wiebe, 1994). Subjectivity is opposed to objectivity, which is the expression of facts. It is important to make the distinction between subjectivity detection and sentiment analysis, as they are two separate tasks in natural language processing. Sentiment analysis can be dependently or independently done from subjectivity detection, although Pang and Lee (2004) state that subjectivity detection performed prior to the sentiment analysis leads to better results in the latter. Although research in this area has started only recently, the substantial growth in subjective information on the world wide web in t"
W10-3111,H05-1044,0,0.619923,"on is thought to be negated if the negation word immediately precedes it. In an extension of this work (Kennedy and Inkpen, 2006) a parser is considered for scope computation. Unfortunately, no precise description of how the parse is used for scope modeling is given in that work. Neither is there a comparison of these two scope models measuring their respective impacts. Final results show that modeling negation is important and relevant, even in the case of such simple methods. The consideration of negation words is more important than that of diminishers. 3.2.2 Features for Negation Modeling Wilson et al. (2005) carry out more advanced negation modeling on expression-level polarity classification. The work uses supervised machine learning where negation modeling is mostly encoded as features using polar expressions. The features for negation modeling are organized in three groups: • negation features • shifter features • polarity modification features Negation features directly relate to negation expressions negating a polar expression. One feature checks whether a negation expression occurs in a fixed window of four words preceding the polar expression. The other feature accounts for a polar predica"
W10-3111,C08-1135,0,0.0112467,"and negation words. Its advantage is that polarity is treated compositionally and is interpreted as a continuum rather than a binary classification. This approach reflects its meaning in a more suitable manner. 3.7 Using Negations in Lexicon Induction Many classification approaches illustrated above depend on the knowledge of which natural lan66 guage expressions are polar. The process of acquiring such lexical resources is called lexicon induction. The observation that negations co-occur with polar expressions has been used for inducing polarity lexicons on Chinese in an unsupervised manner (Zagibalov and Carroll, 2008). One advantage of negation is that though the induction starts with just positive polar seeds, the method also accomplishes to extract negative polar expressions since negated mentions of the positive polar seeds co-occur with negative polar expressions. Moreover, and more importantly, the distribution of the co-occurrence between polar expressions and negations can be exploited for the selection of those seed lexical items. The model presented by Zagibalov and Carroll (2008) relies on the observation that a polar expression can be negated but it occurs more frequently without the negation. T"
W10-3111,J09-3003,0,\N,Missing
W10-3111,P08-2028,0,\N,Missing
W11-1707,W02-1011,0,0.01046,"t is present. 2 State of the Art In Artificial Intelligence (AI), the term affective computing was first introduced by Picard (1995). Previous approaches to spot affect in text include the use of models simulating human reactions according to their needs and desires (Dyer, 1987), fuzzy logic (Subasic and Huettner, 2000), lexical affinity based on similarity of contexts – the basis for the construction of WordNet Affect (Strapparava and Valitutti, 2004) or SentiWordNet (Esuli and Sebastiani, 2005), detection of affective keywords (Riloff et al., 2003) and machine learning using term frequency (Pang et al., 2002; Riloff and Wiebe, 2003), or term discrimination (Danisman and Alpkocak, 2008). Other proposed methods include the creation of syntactic patterns and rules for cause-effect modeling (Mei Lee et al., 2009). Significantly different proposals for emotion detection in text are given in the work by (Liu et al, 2003) and the recently proposed framework of sentic computing (Cambria et al., 2009), whose scope is to model affective reaction based on commonsense knowledge. For a survey on the affect models and their affective computing applications, see (Calvo and D’Mello, 2010). 3 Motivation and Contr"
W11-1707,W03-1014,0,0.0274408,"te of the Art In Artificial Intelligence (AI), the term affective computing was first introduced by Picard (1995). Previous approaches to spot affect in text include the use of models simulating human reactions according to their needs and desires (Dyer, 1987), fuzzy logic (Subasic and Huettner, 2000), lexical affinity based on similarity of contexts – the basis for the construction of WordNet Affect (Strapparava and Valitutti, 2004) or SentiWordNet (Esuli and Sebastiani, 2005), detection of affective keywords (Riloff et al., 2003) and machine learning using term frequency (Pang et al., 2002; Riloff and Wiebe, 2003), or term discrimination (Danisman and Alpkocak, 2008). Other proposed methods include the creation of syntactic patterns and rules for cause-effect modeling (Mei Lee et al., 2009). Significantly different proposals for emotion detection in text are given in the work by (Liu et al, 2003) and the recently proposed framework of sentic computing (Cambria et al., 2009), whose scope is to model affective reaction based on commonsense knowledge. For a survey on the affect models and their affective computing applications, see (Calvo and D’Mello, 2010). 3 Motivation and Contribution The tasks of emot"
W11-1707,W04-3205,0,0.0153876,"Missing"
W11-1707,W03-0404,0,\N,Missing
W11-1707,S07-1013,0,\N,Missing
W11-1718,esuli-sebastiani-2006-sentiwordnet,0,0.147593,"cessing (NLP), one of the most used resources for WSD and other tasks is WordNet (WN) (Fellbaum, 1998). WN is a lexical dictionary with word senses and descriptions. In order to enrich the WN resource, it has been linked with different lexical resources such as WordNet Domains (WND) (Magnini and Cavaglia, 2000) a lexical resource containing the domains of the synsets in WordNet, SUMO (Niles, 2001) an ontology relating the concepts in WordNet, WordNet Affect (WNA) an extension of WN where different synsets are annotated with one of the six basic emotions proposed by Ekman (1999), SentiWordNet (Esuli and Sebastiani, 2006) a lexical resource where each synset is annotated with polarity, Semantic Classes (SC) (Izquierdo et al., 2007) a set of Base Level Concepts (BLC) based on WN, etc. The usage of these resources allows the tackling of NLP tasks from different points of view, depending on the resource used. Our approach proposes using different semantic dimensions according to different resources. In order to achieve this, we use the Integration of Semantic Resources based on WordNet, which we explain in the next section and the Semantic Classes (SC). 140 2.1 Integration of Semantic Resources based on WordNet ("
W11-1718,magnini-cavaglia-2000-integrating,0,0.472925,"Missing"
W11-1718,C00-1044,0,0.0930602,"Missing"
W11-1718,W06-0301,0,0.200395,"tual information such as descriptions, lists of characteristics or instructions to opinionated information such as reviews, emotions or feelings. This heterogeneity has motivated that dealing with the identification and extraction of opinions and sentiments in texts require special attention. In fact, the development of different tools to help government information analysts, companies, political parties, economists, etc to automatically get feelings from news and forums is a challenging task (Wiebe et al., 2005). Many researchers such as Balahur et al., (2010), Hatzivassiloglou et al.(2000), Kim and Hovy (2006), Wiebe et al. (2005) and many others have been working in this way and related areas. 2 Related works Related to Opinion Analysis task we can find many points of view. Some researchers say that adjectives combined with semantic characteristics provide vital information to the performance of Opinion Analysis (Hatzivassiloglou et al., 2000). Others like Zubaryeva and Savoy (2010) assume 1 http://research.nii.ac.jp/ntcir/ntcir-ws8/meeting/ 139 Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 139–145, c 24 June, 2011, Portland"
W11-1718,S10-1095,0,\N,Missing
W11-1718,S01-1027,0,\N,Missing
W11-1722,esuli-sebastiani-2006-sentiwordnet,0,0.0197341,"w.nist.gov/tac/ http://ir.dcs.gla.ac.uk/test collections/access to data.html 169 The first step we took in our approach was to determine the opinionated sentences, assign each of them a polarity (positive or negative) and a numerical value corresponding to the polarity strength (the higher the negative score, the more negative the sentence and vice versa). In our first approximation (OMaprox1), we employed a simple, yet efficient method, presented in Balahur et al. (Balahur et al., 2009). As lexicons for affect detection, we used WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), and MicroWNOp (Cerini et al., 2007). Each of the resources we employed were mapped to four categories, which were given different scores: positive (1), negative (-1), high positive (4) and high negative (-4). First, the score of each of the blog posts was computed as the sum of the values of the words that were identified. Subsequently, we performed sentence splitting4 and classified the sentences we thus obtained according to their polarity, by adding the individual scores of the affective words identified. In the second approach (OMaprox2), we first filter out the sentences that are associ"
W11-1722,W04-1013,0,0.00255888,"ntences that share the same vocabulary but in fact they are not relevant to the summary. In order to avoid this, once we had identified all the most similar sentences to each nugget, we carried out a manual analysis to discard cases like this. Having created the extended set of nuggets, we grouped all of them pertaining to the same topic, and considered it a gold-standard summary. Now, the average number of nuggets per topic is 53, which we have increased by twice the number of original nuggets provided at TAC. Further on, our summaries are compared against this new gold-standard using ROUGE (Lin, 2004). This tool computes the number of different kinds of overlap n-grams between an automatic summary and a human-made summary. For our evaluation, we compute ROUGE-1 (unigrams), ROUGE-2 (bigrams), ROUGE-SU4 (it measures the overlap of skip-bigrams between a candidate summary and a set of reference summaries with a maximum skip distance of 4), and ROUGE-L (Longest Common Subsequence between two texts). The results and discussion are next provided. 4.4 Results and Discussion This section contains the results obtained for our OQA&S approach and all the sub-approaches tested. IRpN refers to the leng"
W11-1722,strapparava-valitutti-2004-wordnet,0,0.0280595,"Example of target, question, and snippet. 2 4 www.nist.gov/tac/ http://ir.dcs.gla.ac.uk/test collections/access to data.html 169 The first step we took in our approach was to determine the opinionated sentences, assign each of them a polarity (positive or negative) and a numerical value corresponding to the polarity strength (the higher the negative score, the more negative the sentence and vice versa). In our first approximation (OMaprox1), we employed a simple, yet efficient method, presented in Balahur et al. (Balahur et al., 2009). As lexicons for affect detection, we used WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), and MicroWNOp (Cerini et al., 2007). Each of the resources we employed were mapped to four categories, which were given different scores: positive (1), negative (-1), high positive (4) and high negative (-4). First, the score of each of the blog posts was computed as the sum of the values of the words that were identified. Subsequently, we performed sentence splitting4 and classified the sentences we thus obtained according to their polarity, by adding the individual scores of the affective words identified. In the second approach (OMaprox2), we fir"
W11-1722,W03-1017,0,0.318913,"ed data, as defined in the TAC 2008 “Opinion Summarization pilot”1 . Given the performance improvements obtained, we conclude that the approaches we proposed for these three components are adequate. 2 Related Work Research focused on building factoid QA systems has a long tradition, however, it is only recently that studies have started to focus on the creation and development of opinion QA systems. Example of this can be (Stoyanov et al., 2004) who took advantage of opinion summarization to support Multi-Perspective QA system, aiming at extracting opinion-oriented information of a question. (Yu and Hatzivassiloglou, 2003) separated opinions from facts and summarized them as answer to opinion questions. Apart from these studies, specialized competitions for systems dealing with opinion retrieval and QA have been organized in the past few years. The TAC 2008 Opinion Summarization Pilot track proposed a mixed setting of factoid and opinion questions. 1 http://www.nist.gov/tac/2008/summarization/ Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 168–174, c 24 June, 2011, Portland, Oregon, USA 2011 Association for Computational Linguistics It is"
W11-1722,W02-0406,0,\N,Missing
W13-1613,E09-1005,0,0.473465,"ords are identified on the sentiment repositories (see Table 2) as positive or negative, in relation to their respective graph, a weight value of 1 (in a range [0 … 1] ) is assigned. represents the maximum quantity of words in the current graph. Thereafter, a graph-based ranking algorithm is applied in order to structurally raise the graph vertexes’ voting power. Once the reinforcement values are applied, the proposed ranking algorithm is able to increase the significance of the words related to these empowered vertices. The PageRank (Brin and Page, 1998) adaptation, which was popularized by (Agirre and Soroa, 2009) in Word Sense Disambiguation thematic, and the one that has obtained relevant results, was an inspiration to us in this work. The main idea behind this algorithm is that, for each edge between "" i and "" j in graph , a vote is made from "" i to "" j. As a result, the relevance of "" j is increased. On top of that, the vote strength from & to ' depends on "" ′ relevance. The philosophy behind it is that, the more important the vertex is, the more strength the voter would have. Thus, PageRank is generated by applying a random walkthrough from the internal interconnection of 96 , where the final rele"
W13-1613,W06-0301,0,0.24569,"and Opinion Mining, is the subjectivity term proposed by (Wiebe, 1994). This author defines it as “linguistic expression of somebody’s opinions, sentiments, emotions, evaluations, beliefs and speculations”. Another important aspect opposed to subjectivity is the objectivity, which constitute a fact expression (Balahur, 2011). Other interesting terms also proposed by (Wiebe et al., 2005) considers, private state, theses terms involve opinions, beliefs, thoughts, feelings, emotions, goals, evaluations and judgments. Many researchers such as (Balahur et al., 2010; Hatzivassiloglou et al., 2000; Kim and Hovy, 2006; Wiebe et al., 2005) and many others have been working in this way and related areas. To build systems able to lead SA challenges it is necessary to achieve sentiment resources previously developed. These resources could be annotated corpora, affective semantic structures, and sentiment dictionaries. In this paper we propose a method that uses annotated corpora where phrases are annotated as Positive, Negative, Objective and Neutral, to achieve new resources for subjectivity analysis involving words dictionaries with their associated polarity. The next section shows different sentiment and af"
W13-1613,W02-1011,0,0.0205986,"d Sebastiani, 2006)). The main idea that encouraged its construction has been that “terms with similar glosses in WordNet tend to have similar polarity”. Another popular lexicon is MicroWNOp (Cerini et al., 2007). It contains opinion words with their associated polarity. It has been built on the basis of a set of terms extracted from the General Inquirer1 (Stone et al., 1996). The problem is that these resources do not consider the context in which the words appear. Some methods tried to overcome this critique and built sentiment lexicons using the local context of words. We can mentioned to (Pang et al., 2002) whom built a lexicon with associated polarity value, starting with a set of classified seed adjectives and using conjunctions (“and”) disjunctions (“or”, “but”) to deduce orientation of new words in a corpus. (Turney, 2002) classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents. On the contrary in (Balahur and Montoyo, 2008b), is computed the polarity of new words using “polarity anchors” (words whose polarity is known beforehand) and Normalized Google Distance (Cilibrasi and Vitányi, 2007) scores using as training exam"
W13-1613,H05-1043,0,0.0276493,"ea that terms with similar orientation tend to co-occur in documents. On the contrary in (Balahur and Montoyo, 2008b), is computed the polarity of new words using “polarity anchors” (words whose polarity is known beforehand) and Normalized Google Distance (Cilibrasi and Vitányi, 2007) scores using as training examples opinion words extracted from “pros and cons reviews” from the same domain. This research achieved the lexical resource Emotion Triggers (Balahur and Montoyo, 2008a). Another approach that uses the polarity of the local context for computing word polarity is the one presented by (Popescu and Etzioni, 2005), who use a weighting function of the words around the context to be classified. All described resources have been obtained manually or semi-automatically. Therefore, we 1 focus our target in archiving automatically new sentiment resources supported over some of aforementioned resources. In particular, we will offer contributions related with methods to build sentiment lexicons using the local context of words. 3 values. Corpora 95 Phrase 1 W1 W2 W3 W4 Positve Phrases Phrase 2 W1 W5 W3 W2 Phrase 1 W5 W6 W8 W9 Phrase 2 W6 W8 W9 W7 Phrase 3 W3 W4 W5 W6 W7 Phrase 3 W6 W9 W10 W11 W1 (I) Weight =1"
W13-1613,strapparava-valitutti-2004-wordnet,0,0.869665,"s (“good” and “bad”) and reinforce the semantic knowledge applying a expanding the lexicon with synonymy and antonymy relations provided by WordNet (Miller et al., 1990). As result of Hu and Liu researches an Opinion Lexicon is obtained with around 6800 positive 94 Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 94–99, c Atlanta, Georgia, 14 June 2013. 2013 Association for Computational Linguistics and negative English words (Hu and Liu, 2004; Liu et al., 2005). A similar approach has been used in building WordNet-Affect (Strapparava and Valitutti, 2004). In this case the building method starting from a larger of seed affective words set. These words are classified according to the six basic categories of emotion (joy, sadness, fear, surprise, anger and disgust), are also expanded increase the lexicon using paths in WordNet. Other widely used in SA has been SentiWordNet resource (Esuli and Sebastiani, 2006)). The main idea that encouraged its construction has been that “terms with similar glosses in WordNet tend to have similar polarity”. Another popular lexicon is MicroWNOp (Cerini et al., 2007). It contains opinion words with their associat"
W13-1613,P02-1053,0,0.00688335,"nion words with their associated polarity. It has been built on the basis of a set of terms extracted from the General Inquirer1 (Stone et al., 1996). The problem is that these resources do not consider the context in which the words appear. Some methods tried to overcome this critique and built sentiment lexicons using the local context of words. We can mentioned to (Pang et al., 2002) whom built a lexicon with associated polarity value, starting with a set of classified seed adjectives and using conjunctions (“and”) disjunctions (“or”, “but”) to deduce orientation of new words in a corpus. (Turney, 2002) classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents. On the contrary in (Balahur and Montoyo, 2008b), is computed the polarity of new words using “polarity anchors” (words whose polarity is known beforehand) and Normalized Google Distance (Cilibrasi and Vitányi, 2007) scores using as training examples opinion words extracted from “pros and cons reviews” from the same domain. This research achieved the lexical resource Emotion Triggers (Balahur and Montoyo, 2008a). Another approach that uses the polarity of the local"
W13-1613,J94-2004,0,\N,Missing
W13-1613,C00-1044,0,\N,Missing
W13-1613,H05-2017,0,\N,Missing
W13-1613,atserias-etal-2006-freeling,0,\N,Missing
W13-1613,esuli-sebastiani-2006-sentiwordnet,0,\N,Missing
Y09-2019,esuli-sebastiani-2006-sentiwordnet,0,0.0298509,"ing to the polarity strength (the higher the negative score, the more negative the sentence and similarly, the higher the positive score, the more positive the sentence). Given that we are faced with the task of classifying opinion in a general context, we employed a simple, yet efficient approach, presented in (Balahur et al., 2009c). At the present moment, there are different lexicons for affect detection and opinion mining. In order to have a more extensive database of affect-related terms, in the following experiments we used WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOp (Cerini et al., 2007). Each of the employed resources were mapped to four categories, which were given different scores: positive (1), negative (-1), high positive (4) and high negative (-4). As shown in (Balahur et al., 2009c), these values performed better than the usual assignment of only positive (1) and negative (-1) values. First, the score of each of the blog posts was computed as sum of the values of the words identified; a positive score leads to the classification of the post as positive, whereas a final negative score leads to the system classifying the post as negative."
Y09-2019,I05-2047,0,0.0342729,"e present our experimental results and discuss the main issues (sec. 4); and finally, we conclude the paper and give pointers to future work. ? Special thanks to the EMM team for supporting this research. We also thank Ester Boldrini for her annotations of the corpus used in the experiments presented. Copyright 2009 by Alexandra Balahur, Mijail Kabadjov, Josef Steinberger, Ralf Steinberger, and Andr´es Montoyo 23rd Pacific Asia Conference on Language, Information and Computation, pages 606–613 606 2 Related Work Whilst there is abundant literature on text summarization (Kabadjov et al., 2009; Hovy, 2005; Erkan and Radev, 2004; Gong and Liu, 2002) and sentiment analysis (Balahur et al., 2009a; Pang and Lee, 2008; Riloff et al., 2005), there is still limited work at the intersection of these two areas (Stoyanov and Cardie, 2006). Initial research in opinion mining concentrated on news texts. Wiebe (1994) defines subjectivity based on Quirks idea of “private states” (states that are not open to verification) and distinguishes between objectivity and subjectivity on this criteria. Consequently, based on this definition, the Multi-Perspective Question Answering (MPQA) annotation schema and corpus"
Y09-2019,W04-1013,0,0.0209929,"Missing"
Y09-2019,N03-1020,0,0.178486,"Missing"
Y09-2019,P04-1035,0,0.0245929,"ivate states” (states that are not open to verification) and distinguishes between objectivity and subjectivity on this criteria. Consequently, based on this definition, the Multi-Perspective Question Answering (MPQA) annotation schema and corpus were created over news texts, distinguishing between the subjective/objective speech, as well as the polarity of text spans (Wiebe et al., 2005). Subsequently, different authors show that this initial discrimination is crucial for the sentiment task, improving results obtained when using only polarity classification for sentence-level opinion mining (Pang and Lee, 2004), as part of Opinion Information Retrieval (last three editions of the TREC Blog tracks, the TAC 2008 competition), Information Extraction (Riloff et al., 2005) and Question Answering (QA) (Stoyanov et al., 2004) systems. Once this discrimination is done, or in the case of texts containing only or mostly subjective language (such as e-reviews), opinion mining becomes a polarity classification task. 3 Opinion Summarization In our opinion summarization experiments we adopt a standard approach by employing in tandem a sentiment classification system and a text summarizer. The output of the former"
Y09-2019,strapparava-valitutti-2004-wordnet,0,0.0944072,"e and negative) and a numerical value corresponding to the polarity strength (the higher the negative score, the more negative the sentence and similarly, the higher the positive score, the more positive the sentence). Given that we are faced with the task of classifying opinion in a general context, we employed a simple, yet efficient approach, presented in (Balahur et al., 2009c). At the present moment, there are different lexicons for affect detection and opinion mining. In order to have a more extensive database of affect-related terms, in the following experiments we used WordNet Affect (Strapparava and Valitutti, 2004), SentiWordNet (Esuli and Sebastiani, 2006), MicroWNOp (Cerini et al., 2007). Each of the employed resources were mapped to four categories, which were given different scores: positive (1), negative (-1), high positive (4) and high negative (-4). As shown in (Balahur et al., 2009c), these values performed better than the usual assignment of only positive (1) and negative (-1) values. First, the score of each of the blog posts was computed as sum of the values of the words identified; a positive score leads to the classification of the post as positive, whereas a final negative score leads to t"
Y09-2019,J94-2004,0,0.0670595,"Copyright 2009 by Alexandra Balahur, Mijail Kabadjov, Josef Steinberger, Ralf Steinberger, and Andr´es Montoyo 23rd Pacific Asia Conference on Language, Information and Computation, pages 606–613 606 2 Related Work Whilst there is abundant literature on text summarization (Kabadjov et al., 2009; Hovy, 2005; Erkan and Radev, 2004; Gong and Liu, 2002) and sentiment analysis (Balahur et al., 2009a; Pang and Lee, 2008; Riloff et al., 2005), there is still limited work at the intersection of these two areas (Stoyanov and Cardie, 2006). Initial research in opinion mining concentrated on news texts. Wiebe (1994) defines subjectivity based on Quirks idea of “private states” (states that are not open to verification) and distinguishes between objectivity and subjectivity on this criteria. Consequently, based on this definition, the Multi-Perspective Question Answering (MPQA) annotation schema and corpus were created over news texts, distinguishing between the subjective/objective speech, as well as the polarity of text spans (Wiebe et al., 2005). Subsequently, different authors show that this initial discrimination is crucial for the sentiment task, improving results obtained when using only polarity c"
Y09-2019,W06-0302,0,\N,Missing
