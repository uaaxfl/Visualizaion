1992.tmi-1.22,J90-2002,0,0.30839,"Missing"
1992.tmi-1.22,P92-1023,1,0.855639,"Missing"
1992.tmi-1.22,1991.mtsummit-papers.5,1,0.660372,"Missing"
1992.tmi-1.22,C92-1055,1,0.878856,"Missing"
1992.tmi-1.22,A88-1019,0,0.024448,"Missing"
1992.tmi-1.22,O92-1001,1,0.678738,"Missing"
1992.tmi-1.22,C88-2133,1,0.722414,"Missing"
1992.tmi-1.22,W89-0210,1,0.899906,"Missing"
1992.tmi-1.22,C92-2067,1,0.882008,"Missing"
1993.tmi-1.1,J85-2002,0,0.0669228,"Missing"
1993.tmi-1.1,J90-2002,0,0.244347,"Missing"
1993.tmi-1.1,P92-1023,1,0.839638,"Missing"
1993.tmi-1.1,1991.mtsummit-papers.5,1,0.753056,"Missing"
1993.tmi-1.1,J85-2001,0,0.0738276,"Missing"
1993.tmi-1.1,C90-3044,0,0.0812757,"Missing"
1993.tmi-1.1,C88-2133,1,0.80376,"Missing"
1993.tmi-1.1,1992.tmi-1.22,1,0.880778,"Missing"
1993.tmi-1.1,C92-2067,1,0.871632,"Missing"
1993.tmi-1.1,J90-2001,0,0.0391341,"Missing"
1995.tmi-1.27,P92-1023,1,0.904648,"Missing"
1995.tmi-1.27,1993.tmi-1.1,1,0.886475,"Missing"
1995.tmi-1.27,1991.mtsummit-papers.5,1,0.877469,"Missing"
1995.tmi-1.27,C92-1055,1,0.847887,"Missing"
1995.tmi-1.27,J95-3002,1,0.885172,"Missing"
1995.tmi-1.27,C86-1155,0,0.205041,"Missing"
1995.tmi-1.27,O92-1001,1,0.587733,"Missing"
1995.tmi-1.27,O90-1004,1,0.928765,"Missing"
1995.tmi-1.27,C88-2133,1,0.742335,"Missing"
1995.tmi-1.27,1992.tmi-1.22,1,0.795453,"Missing"
1995.tmi-1.27,C92-2067,1,0.911438,"Missing"
1997.mtsummit-papers.14,1993.tmi-1.1,1,0.754634,"Missing"
1997.mtsummit-papers.14,O95-1003,1,0.889363,"Missing"
1997.mtsummit-papers.14,1995.tmi-1.27,1,0.851543,"Missing"
1999.mtsummit-1.29,P91-1017,0,0.101364,"Missing"
1999.mtsummit-1.29,C92-2067,1,0.871478,"Missing"
1999.mtsummit-1.29,1995.tmi-1.27,1,0.861954,"Missing"
1999.mtsummit-1.29,O96-2004,1,0.900403,"Missing"
2018.ijclclp-2.4,P02-1040,0,0.148065,"Missing"
2020.acl-main.92,P14-5010,0,0.00690191,"Missing"
2021.acl-short.121,P16-1154,0,0.0863315,"Missing"
2021.acl-short.121,D17-1084,0,0.0330225,"Missing"
2021.acl-short.121,Q15-1042,0,0.0631939,"Missing"
2021.acl-short.121,P14-1026,0,0.080211,"Missing"
2021.eacl-main.51,N19-1423,0,0.0388713,"len)” is neutral. Besides, we also seek to determine whether BERT is also able to learn the antonymous predicate “right( ⋅,⋅ )”, and judge that the hypothesis “right(Mary,John)” is entailed by the above premise. 2.1 Entity Names and Datasets The arguments of the above binary predicates “left(⋅,⋅)” and “right(⋅,⋅)” actually can be the names of any objects. However, in this paper, we simply trained BERT with personal names. To avoid dividing a personal name into sub-words, we collected 1,696 male and female first names which appear in the vocabulary of the pre-trained “BERTBase, Uncased” model (Devlin et al., 2019). These names were randomly partitioned into three sets: િ ܂, િ ܄and િ۳ . The subscripts  ܂,  ܄and ۳ indicate these name sets will be used for Training, Validation and Evaluation respectively. Sets િ܂ and િ ܄, which consist of 1,356 and 170 names respectively, are used to generate the training and validation datasets for fine-tuning BERT; and Set િ۳ , consisting of 170 names, is used to generate a dataset for evaluating the performance of BERT in understanding the predicates with personal names. Furthermore, we also seek to ascertain whether the BERT model trained by the predicates"
2021.eacl-main.51,D15-1075,0,0.0429363,"ish. The results show that the learning process of BERT is very slow. However, the efficiency of learning can be greatly improved (data reduction by a factor of 1,500) if task-related features are added. This suggests that domain knowledge greatly helps when conducting NLI with neural networks. 1 Introduction Entailment judgment (Dagan et al., 2006; Marelli et al., 2014a) is a common test for natural language inference (NLI) (Camburu et al., 2018; Conneau et al., 2018) as it possesses the simplest form in related tasks such as question and answering (Bowman and Zhu, 2019). Also, SNLI dataset (Bowman et al., 2015) is frequently adopted for NLI evaluation because it is the first corpus to show the power of neural networks for the task that specifically targets NLI. Recently, BERT (Devlin et al., 2019), XLNet (Yang et al., 2019), and RoBERTa (Liu et al., 2019) have all shown excellent performances on SNLI, surpassing even human performance (Gong et al., 2017). However, Tsuchiya (2018) and Gururangan et al. (2018) show that SNLI contains hidden bias. Also, deep neural networks (DNNs) have been shown to predominantly capture the statistical irregularities that go unnoticed by humans (Poliak et al., 2018);"
2021.eacl-main.51,N18-2017,0,0.0476075,"Missing"
2021.eacl-main.51,W19-4828,0,0.0294197,"Missing"
2021.eacl-main.51,L18-1239,0,0.0461657,"Missing"
2021.eacl-main.51,marelli-etal-2014-sick,0,0.0412688,"y learn to conduct natural language inference (NLI) without utilizing hidden dataset bias; and how efficiently it can learn if it could. This is done via creating a simple entailment judgment case which involves only binary predicates in plain English. The results show that the learning process of BERT is very slow. However, the efficiency of learning can be greatly improved (data reduction by a factor of 1,500) if task-related features are added. This suggests that domain knowledge greatly helps when conducting NLI with neural networks. 1 Introduction Entailment judgment (Dagan et al., 2006; Marelli et al., 2014a) is a common test for natural language inference (NLI) (Camburu et al., 2018; Conneau et al., 2018) as it possesses the simplest form in related tasks such as question and answering (Bowman and Zhu, 2019). Also, SNLI dataset (Bowman et al., 2015) is frequently adopted for NLI evaluation because it is the first corpus to show the power of neural networks for the task that specifically targets NLI. Recently, BERT (Devlin et al., 2019), XLNet (Yang et al., 2019), and RoBERTa (Liu et al., 2019) have all shown excellent performances on SNLI, surpassing even human performance (Gong et al., 2017)."
2021.eacl-main.51,P19-1334,0,0.0403029,"Missing"
2021.eacl-main.51,C18-1198,0,0.0279284,"Missing"
2021.eacl-main.51,N18-1101,0,0.0699585,"Missing"
2021.eacl-main.51,D18-1259,0,0.0279486,"entailment about fifteen years ago. This task continued until 2011 (Bentivogli et al., 2011). Afterwards, conducting inference with BERT was studied in (Clark et al., 2019; Zellers et al., 2019; Tenney et al., 2019; Aken et al., 2019; Coenen et al., 2019; Michel et al., 2019). On the other hand, various corpora have been created for conducting NLI for different purposes: SICK (Marelli et al., 2014b), SNLI (Bowman et al., 2015), MNLI (Willams et al., 2018), MPE (Lai et al., 2017), JOCI (Zhang et al., 2017), XNLI (Conneau et al., 2018), and SciTail (Khot et al., 2018). Corpora such as HOTPOTQA (Yang et al., 2018), Breaking-NLI (Glockner et al., 2018), CommonSense QA (Talmor et al., 2019), DROP (Dua et al., 2019) and ROPES (Lin et al., 2019) have also been created recently to evaluate more diverse and difficult NLI cases. However, all those Conclusion This paper is the first quantitative study on whether BERT could really learn to conduct NLI without implicitly utilizing hidden dataset bias, and how quickly it does so if it could. We conduct experiments to evaluate the capability of BERT on making inference without hidden bias, and show that BERT learns NLI inefficiently even for a simple case. We furt"
2021.eacl-main.51,P19-1472,0,0.0462564,"Missing"
2021.rocling-1.5,N19-1423,0,0.0523954,"Missing"
2021.rocling-1.5,D19-1170,0,0.0393739,"Missing"
2021.rocling-1.5,D19-1630,0,0.0309004,"Missing"
2021.rocling-1.5,O11-1010,0,0.0572486,"Missing"
2021.rocling-1.5,P19-1334,0,0.0473568,"Missing"
2021.rocling-1.5,W13-3819,0,0.0645537,"Missing"
2021.rocling-1.5,D19-1258,0,0.0248831,"Missing"
2021.rocling-1.5,S18-2023,0,0.0652759,"Missing"
2021.rocling-1.5,D16-1264,0,0.116042,"Missing"
C02-1009,P91-1022,0,0.732929,"Missing"
C02-1009,P91-1023,0,0.0992475,"Missing"
C02-1009,C00-2163,0,0.0295805,"Missing"
C02-1009,C96-2141,0,0.09642,"Missing"
C02-1009,P93-1002,0,0.652098,"Missing"
C02-1009,P94-1012,0,0.640497,"Missing"
C02-1009,P93-1001,0,0.0686879,"Missing"
C02-1009,J93-1004,0,\N,Missing
C02-1009,J93-2003,0,\N,Missing
C02-1009,P91-1017,0,\N,Missing
C10-1132,W02-1001,0,0.0630204,"Missing"
C10-1132,I05-3017,0,0.628415,"character-based models are much more robust on OOV words than word-based approaches do, as the vocabulary size of characters is a closed set (versus the open set of that of words). Furthermore, among those character-based approaches, the generative model and the discriminative one complement each other in handling in-vocabulary (IV) words and OOV words. Therefore, a characterbased joint model is proposed to combine them. This proposed joint approach has achieved good balance between IV word recognition and OOV word identification. The experiments of closed tests on the second SIGHAN Bakeoff (Emerson, 2005) show that the joint model significantly outperforms the baseline models of both generative and discriminative approaches. Moreover, statistical significance tests also show that the joint model is significantly better than all those state-of-the-art systems reported in the literature and achieves the best F-score in four of the five corpora tested. 2 Character-Based Models for CWS The goal of CWS is to find the corresponding word sequence for a given character sequence. Character-based model is to find out the corresponding tags for given character sequence. 2.1 Character-Based Discriminative"
C10-1132,P03-1035,0,0.0950296,"probability of the given input and its associated label sequence, while the discriminative model learns the posterior probability directly. Generative models often do not perform well because they make strong independence assumptions between features and labels. However, (Toutanova, 2006) shows that generative models can also achieve very similar or better performance than the corresponding discriminative models if they have a structure that avoids unrealistic independence assumptions. In terms of the above dimensions, methods for CWS can be classified as: 1) The word-based generative model (Gao et al., 2003; Zhang et al., 2003), which is a wellknown approach and has been used in many successful applications; 2) The word-based discriminative model (Zhang and Clark, 2007), which generates word candidates with both word and character features and is the only word-based model that adopts the discriminative approach； 3) The character-based discriminative model (Xue, 2003; Peng et al., 2004; Tseng et al., 2005; Jiang et al., 2008), which has become the dominant method as it is robust on OOV words and is capable of handling a range of different features, and it has been adopted in many previous works;"
C10-1132,P08-1102,0,0.750786,"y have a structure that avoids unrealistic independence assumptions. In terms of the above dimensions, methods for CWS can be classified as: 1) The word-based generative model (Gao et al., 2003; Zhang et al., 2003), which is a wellknown approach and has been used in many successful applications; 2) The word-based discriminative model (Zhang and Clark, 2007), which generates word candidates with both word and character features and is the only word-based model that adopts the discriminative approach； 3) The character-based discriminative model (Xue, 2003; Peng et al., 2004; Tseng et al., 2005; Jiang et al., 2008), which has become the dominant method as it is robust on OOV words and is capable of handling a range of different features, and it has been adopted in many previous works; 1173 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1173–1181, Beijing, August 2010 4) The character-based generative model (Wang et al., 2009), which adopts a charactertag-pair-based n-gram model and achieves comparable results with the popular characterbased discriminative model. In general, character-based models are much more robust on OOV words than word-based approa"
C10-1132,W04-3236,0,0.227271,"nce this tagging approach treats characters as basic units, the vocabulary size of those possible character-tag-pairs is limited. Therefore, this method is robust to OOV words and could possess a high recall of OOV words (ROOV). Although the dependency between adjacent tags/labels can be addressed, the dependency between adjacent characters within a word cannot be directly modeled under this framework. Lower recall of IV words (RIV) is thus usually accompanied (Wang et al., 2009). In this work, the character-based discriminative model is implemented by adopting the feature templates given by (Ng and Low, 2004), but excluding those ones that are forbidden by the closed test regulation of SIGHAN (e.g., Pu(C0): whether C0 is a punctuation). Those feature templates adopted are listed below: (a ) Cn (n = −2, −1, 0,1, 2); (b) Cn Cn +1 (n = −2, −1, 0,1); (c) C−1C1 For example, when we consider the third character “奥” in the sequence “北京奥运会”, template (a) results in the features as following: C-2=北, C-1=京, C0=奥, C1=运, C2=会, and template (b) generates the features as: C-2C-1=北京, C-1C0=京奥, C0C1=奥运, C1C2=运会, and template (c) gives the feature C-1C1=京运. 2.2 Character-Based Generative Model To incorporate the d"
C10-1132,C04-1081,0,0.0724455,"responding discriminative models if they have a structure that avoids unrealistic independence assumptions. In terms of the above dimensions, methods for CWS can be classified as: 1) The word-based generative model (Gao et al., 2003; Zhang et al., 2003), which is a wellknown approach and has been used in many successful applications; 2) The word-based discriminative model (Zhang and Clark, 2007), which generates word candidates with both word and character features and is the only word-based model that adopts the discriminative approach； 3) The character-based discriminative model (Xue, 2003; Peng et al., 2004; Tseng et al., 2005; Jiang et al., 2008), which has become the dominant method as it is robust on OOV words and is capable of handling a range of different features, and it has been adopted in many previous works; 1173 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1173–1181, Beijing, August 2010 4) The character-based generative model (Wang et al., 2009), which adopts a charactertag-pair-based n-gram model and achieves comparable results with the popular characterbased discriminative model. In general, character-based models are much more r"
C10-1132,W06-1668,0,0.0215273,"airs is limited, the characterbased models can tolerate out-of-vocabulary (OOV) words and have become the dominant technique for CWS in recent years. On the other hand, statistical approaches can also be classified as either adopting a generative model or adopting a discriminative model. The generative model learns the joint probability of the given input and its associated label sequence, while the discriminative model learns the posterior probability directly. Generative models often do not perform well because they make strong independence assumptions between features and labels. However, (Toutanova, 2006) shows that generative models can also achieve very similar or better performance than the corresponding discriminative models if they have a structure that avoids unrealistic independence assumptions. In terms of the above dimensions, methods for CWS can be classified as: 1) The word-based generative model (Gao et al., 2003; Zhang et al., 2003), which is a wellknown approach and has been used in many successful applications; 2) The word-based discriminative model (Zhang and Clark, 2007), which generates word candidates with both word and character features and is the only word-based model tha"
C10-1132,I05-3027,0,0.699833,"Missing"
C10-1132,O03-4002,0,0.779486,"han the corresponding discriminative models if they have a structure that avoids unrealistic independence assumptions. In terms of the above dimensions, methods for CWS can be classified as: 1) The word-based generative model (Gao et al., 2003; Zhang et al., 2003), which is a wellknown approach and has been used in many successful applications; 2) The word-based discriminative model (Zhang and Clark, 2007), which generates word candidates with both word and character features and is the only word-based model that adopts the discriminative approach； 3) The character-based discriminative model (Xue, 2003; Peng et al., 2004; Tseng et al., 2005; Jiang et al., 2008), which has become the dominant method as it is robust on OOV words and is capable of handling a range of different features, and it has been adopted in many previous works; 1173 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1173–1181, Beijing, August 2010 4) The character-based generative model (Wang et al., 2009), which adopts a charactertag-pair-based n-gram model and achieves comparable results with the popular characterbased discriminative model. In general, character-based mod"
C10-1132,W03-1730,0,0.139802,"e given input and its associated label sequence, while the discriminative model learns the posterior probability directly. Generative models often do not perform well because they make strong independence assumptions between features and labels. However, (Toutanova, 2006) shows that generative models can also achieve very similar or better performance than the corresponding discriminative models if they have a structure that avoids unrealistic independence assumptions. In terms of the above dimensions, methods for CWS can be classified as: 1) The word-based generative model (Gao et al., 2003; Zhang et al., 2003), which is a wellknown approach and has been used in many successful applications; 2) The word-based discriminative model (Zhang and Clark, 2007), which generates word candidates with both word and character features and is the only word-based model that adopts the discriminative approach； 3) The character-based discriminative model (Xue, 2003; Peng et al., 2004; Tseng et al., 2005; Jiang et al., 2008), which has become the dominant method as it is robust on OOV words and is capable of handling a range of different features, and it has been adopted in many previous works; 1173 Proceedings of t"
C10-1132,zhang-etal-2004-interpreting,0,0.050023,"the proposed joint model among Although Table 5 has shown that the proposed those approaches that have been implemented. joint (joint-plus) model outperforms all the However, it would be interesting to know if the baselines mentioned above, we want to know joint (and joint-plus) model also outperforms if the difference is statistically significant those previous state-of-the-art systems. enough to make such a claim. Since there is The systems that performed best for at least only one testing set for each training corpus, one corpus in the second SIGHAN Bakeoff are the bootstrapping technique (Zhang et al., 2004) first selected for comparison. This category is adopted to conduct the tests: Giving an includes (Asahara et al., 2005) (denoted as 7 Statistical Significance Tests 1179 Asahara05) and (Tseng et al., 2005) 4 (Tseng05). (Asahara et al., 2005) achieves the best result in the AS corpus, and (Tseng et al., 2005) performs best in the remaining three corpora. Besides, those systems that are reported to exceed the above two systems are also selected. This category includes (Zhang et al., 2006) (Zhang06), (Zhang and Clark, 2007) (Z&C07) and (Jiang et al., 2008) (Jiang08). They are briefly summarized"
C10-1132,P07-1106,0,0.62793,"ften do not perform well because they make strong independence assumptions between features and labels. However, (Toutanova, 2006) shows that generative models can also achieve very similar or better performance than the corresponding discriminative models if they have a structure that avoids unrealistic independence assumptions. In terms of the above dimensions, methods for CWS can be classified as: 1) The word-based generative model (Gao et al., 2003; Zhang et al., 2003), which is a wellknown approach and has been used in many successful applications; 2) The word-based discriminative model (Zhang and Clark, 2007), which generates word candidates with both word and character features and is the only word-based model that adopts the discriminative approach； 3) The character-based discriminative model (Xue, 2003; Peng et al., 2004; Tseng et al., 2005; Jiang et al., 2008), which has become the dominant method as it is robust on OOV words and is capable of handling a range of different features, and it has been adopted in many previous works; 1173 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1173–1181, Beijing, August 2010 4) The character-based generat"
C10-1132,P06-2123,0,\N,Missing
C10-1132,Y09-2047,1,\N,Missing
C12-1101,P96-1041,0,0.0862461,"Missing"
C12-1101,I05-3017,0,0.294898,"Missing"
C12-1101,P03-1035,0,0.0745001,"Missing"
C12-1101,W10-4127,0,0.0542028,"Missing"
C12-1101,W10-4128,0,0.0243565,"Missing"
C12-1101,W10-4141,0,0.0240683,"Missing"
C12-1101,P08-1102,0,0.144855,"e with prefix/suffix. For example, “造影术” (radiography) is an OOV word with suffix “术” (technique), while the word “造影” (radiograph) is contained in the dictionary. However, it is wrongly split into “造影” and “术”, since the longest word in the dictionary is preferred. This problem will be our future work. 6 Related work The word-based generative model (Gao et al., 2003; Zhang et al., 2003) is a classical approach for CWS. However, this approach needs an additional module to recognize OOV words. Therefore, the character-based discriminative model (Xue, 2003; Low et al., 2005; Zhang et al., 2006; Jiang et al., 2008; Zhao et al., 2010) has become the main stream due to its capability in handling OOV words. However, the character-based discriminative model cannot give satisfactory performance for IV words. Wang et al. (2010) thus proposed a generative model to fix this problem. Afterwards, they 1665 further proposed an integrated model to integrate generative and discriminative approaches, as these two approaches complement each other. On the other hand, dictionary information has been utilized in the discriminative approach in the previous works of (Low et al., 2005; Zhao et al., 2010). However, they foc"
C12-1101,W04-3250,0,0.0766166,"Missing"
C12-1101,I05-3025,0,0.642104,". 1 2 1654 Several factors that might affect the performance of the new model are studied in this paper: including the context information, the OOV coverage rate of the dictionary, and the weight of the new factor in the model. We evaluated our final system on the CIPS-SIGHAN-2010 Bakeoff data. The obtained results not only convincingly demonstrate the effectiveness of the proposed model for cross-domain CWS, but also achieve the best performance on 3 out of 4 domains in the open test. Afterwards, the proposed enhanced generative model is integrated with another enhanced discriminative model (Low et al., 2005) to further improve the performance, and achieves the best performance on all the tested corpora. The remainder of this paper is organized as: Section 2 discusses how to incorporate dictionary information and section 3 describes the proposed models. Empirical results and error analysis are presented in section 4 and 5. Section 6 reviews the related work. 2 Dictionary related features 2.1 Word-ID or Word-Matching-Indicator? Given a dictionary, there are two kinds of features that can be utilized: word-ID, which are binary features that fire only when the word matches one specific word entry, an"
C12-1101,W04-3236,0,0.0593811,"Missing"
C12-1101,C10-2139,0,0.490364,"lated work. 2 Dictionary related features 2.1 Word-ID or Word-Matching-Indicator? Given a dictionary, there are two kinds of features that can be utilized: word-ID, which are binary features that fire only when the word matches one specific word entry, and Word-MatchingIndicator (e.g. TM defined in Section 2.3), which checks the relationship between the assigned position tag of the current character and the dictionary words within local context. Since the statistics of OOV words can never be learnt from the training corpus, the approaches that adopt word-ID as features (Zhang and Clark, 2007; Sun, 2010; Zhang and Clark, 2011) cannot really utilize the information of the OOV words kept in the dictionary. On the contrary, the wordmatching-indicator is applicable for both IV and OOV words kept in the dictionary. This feature thus provides valuable information for those OOV words covered by the dictionary. Therefore, based on the positions of those dictionary matching words, two dictionary-related features (i.e., Dictionary Coverage Status and Tag Matching Status, to be specified later) are proposed in this paper, and they will be incorporated into the character-based generative model. 2.2 Dict"
C12-1101,D11-1090,0,0.0749426,"generative and discriminative approaches, as these two approaches complement each other. On the other hand, dictionary information has been utilized in the discriminative approach in the previous works of (Low et al., 2005; Zhao et al., 2010). However, they focus on improving the in-domain word segmentation accuracy, while we investigate how the domain invariant feature (based on dictionary information) helps for cross-domain tasks. Besides, the effect of varying OOV words coverage rates is studied in this paper for the first time. In addition to dictionary feature, Zhao and Kit (2007; 2008), Sun and Xu (2011) too, also adopted the accessor variety feature to gain better generalization ability. Since this feature can be extracted from unlabelled corpora, it is suitable to be adopted for domain adaptation. Again, all their works focus on in-domain performance. Other works that focus on in-domain performance also include (Zhang and Clark, 2007), (Fu et al., 2008), (Jiang et al., 2008), (Lin, 2009), (Xiong et al., 2009), and (Zhang and Clark, 2011). Last, (Ben-David et al., 2007) pointed out that a good feature representation for domain adaptation should minimize the difference between its distributio"
C12-1101,P12-1027,0,0.20558,"Missing"
C12-1101,Y09-2047,1,0.845539,"me that the dictionary matching words are {“大学”, “大学生”}: if the tag assigned to „学‟ is “M”, then TM 2 will be “Following-Longest-Word”; if it is “E”, then TM 2 will be “Only-FollowingShorter-Word”; if it is “B” or “S”, TM 2 would be “Not-Following-Any-Word”. Therefore, this candidate-feature is associated with each candidate of the position-tag. However, if no dictionary word covers this character, then TM 2 will be set to “Inapplicable” regardless of which tag is assigned to „学‟ (i.e., we do not want to disturb the original model in this case). 3 3.1 Proposed models Enhanced generative model Wang et al. (2009) proposed a character-based generative model for CWS, which is able to handle the dependency of character-bigrams within words and thus give a good balance for the performance of IV words and OOV words. Their approach adopts the character-tag-pair trigram model, and obtains the desired position-tag sequence t1 n as follows: 1657 t1n  arg max  P ([c, t ]i |[c, t ]ii 12 ) n t1n (1) i 1 where [c, t ]1n is the associated character-tag-pair sequence for the given character sequence c1n . To alleviate the data sparseness problem, we pre-convert the given character string into its corresponding"
C12-1101,C10-1132,1,0.914569,"ch are features (d) and (e) in the following list) to the widely adopted primitive templates described in (Ng and Low, 2004), and used them to enhance the original discriminative model (Xue, 2003): (a ) Cn (n  2, 1, 0,1, 2); (b) Cn Cn 1 (n  2, 1, 0,1); (d ) MWL0 , t &apos;0 ; (e) Cn t &apos;0 (n  1, 0,1). (c ) C1C1 ; Let W denote the longest dictionary word that covers c0, then MWL0 denotes the length of W, and t &apos;0 denotes the corresponding tag of c0 in W. Since the enhanced generative model cannot utilize the features from future context, which is a common drawback of generative approaches (Wang et al., 2010), following the approach of (Wang et al., 2011), we further integrate the enhanced generative model with the above enhanced discriminative model via log-linear interpolation, shown as follows: Score(ti )    [  log P ([u , t ]i |[u , t ]ii 12 )  (1   ) log P (TM i |MWLi , DCi , uii 2 )]  (1   )  log( P (ti |uii22 , MWLi , t &apos;i ) (5) Where  and  are two weighting coefficients to be decided from the development set, and 0   ,   1.0 . 4 Experiments All experiments are conducted on the corpora provided by SIGHAN-2005 (Emerson, 2005) and CIPS-SIGHAN-20106 (Zhao and Liu, 2010)."
C12-1101,O03-4002,0,0.405225,"Missing"
C12-1101,W03-1730,0,0.54596,"Missing"
C12-1101,P06-2123,0,0.389657,"e uncovered terms are with prefix/suffix. For example, “造影术” (radiography) is an OOV word with suffix “术” (technique), while the word “造影” (radiograph) is contained in the dictionary. However, it is wrongly split into “造影” and “术”, since the longest word in the dictionary is preferred. This problem will be our future work. 6 Related work The word-based generative model (Gao et al., 2003; Zhang et al., 2003) is a classical approach for CWS. However, this approach needs an additional module to recognize OOV words. Therefore, the character-based discriminative model (Xue, 2003; Low et al., 2005; Zhang et al., 2006; Jiang et al., 2008; Zhao et al., 2010) has become the main stream due to its capability in handling OOV words. However, the character-based discriminative model cannot give satisfactory performance for IV words. Wang et al. (2010) thus proposed a generative model to fix this problem. Afterwards, they 1665 further proposed an integrated model to integrate generative and discriminative approaches, as these two approaches complement each other. On the other hand, dictionary information has been utilized in the discriminative approach in the previous works of (Low et al., 2005; Zhao et al., 2010"
C12-1101,P07-1106,0,0.591488,"ection 6 reviews the related work. 2 Dictionary related features 2.1 Word-ID or Word-Matching-Indicator? Given a dictionary, there are two kinds of features that can be utilized: word-ID, which are binary features that fire only when the word matches one specific word entry, and Word-MatchingIndicator (e.g. TM defined in Section 2.3), which checks the relationship between the assigned position tag of the current character and the dictionary words within local context. Since the statistics of OOV words can never be learnt from the training corpus, the approaches that adopt word-ID as features (Zhang and Clark, 2007; Sun, 2010; Zhang and Clark, 2011) cannot really utilize the information of the OOV words kept in the dictionary. On the contrary, the wordmatching-indicator is applicable for both IV and OOV words kept in the dictionary. This feature thus provides valuable information for those OOV words covered by the dictionary. Therefore, based on the positions of those dictionary matching words, two dictionary-related features (i.e., Dictionary Coverage Status and Tag Matching Status, to be specified later) are proposed in this paper, and they will be incorporated into the character-based generative mode"
C12-1101,J11-1005,0,0.0410802,"2 Dictionary related features 2.1 Word-ID or Word-Matching-Indicator? Given a dictionary, there are two kinds of features that can be utilized: word-ID, which are binary features that fire only when the word matches one specific word entry, and Word-MatchingIndicator (e.g. TM defined in Section 2.3), which checks the relationship between the assigned position tag of the current character and the dictionary words within local context. Since the statistics of OOV words can never be learnt from the training corpus, the approaches that adopt word-ID as features (Zhang and Clark, 2007; Sun, 2010; Zhang and Clark, 2011) cannot really utilize the information of the OOV words kept in the dictionary. On the contrary, the wordmatching-indicator is applicable for both IV and OOV words kept in the dictionary. This feature thus provides valuable information for those OOV words covered by the dictionary. Therefore, based on the positions of those dictionary matching words, two dictionary-related features (i.e., Dictionary Coverage Status and Tag Matching Status, to be specified later) are proposed in this paper, and they will be incorporated into the character-based generative model. 2.2 Dictionary Coverage Status L"
C12-1101,zhang-etal-2004-interpreting,0,0.0599932,"Missing"
C12-1101,I08-4017,0,0.262701,"Missing"
C12-1101,W10-4126,0,\N,Missing
C14-1039,P12-2005,0,0.048869,"Missing"
C14-1039,P05-1033,0,0.234968,"Missing"
C14-1039,2011.eamt-1.28,0,0.0246839,"ame time, all matched TM phrase-pairs are dynamically merged into the phrase table. Moreover, this is the first unified framework for integrating TM into SMT at decoding when the TM database and the SMT training set are different. Although some previous works of the second and third categories can be also applied when the TM database and the SMT training set are different, they did not explicitly focus on and test this case. Last, since the example-based machine translation (EBMT, [Nagao, 1984]) is similar to that of using TM, some approaches (Watanabe and Sumita, 2003; Smith and Clark, 2009; Dandapat et al., 2011; 2012; Phillips, 2011) also combined EBMT with SMT. It would be interesting to compare our approaches with theirs in the future. 6 Conclusion Combining TM and SMT can greatly improve the translation performance and reduce human postediting effort. In comparison with those previous approaches, our work makes the following contributions: (1) Dynamically merge the matched TM phrase-pairs into the SMT phrase table to meet the real application; (2) Propose an improved integrated model to distinguish the original SMT phrase-pairs from the newly-added ones extracted from TM; (3) Adopt a simple but e"
C14-1039,W12-0106,0,0.0374585,"Missing"
C14-1039,N13-3003,0,0.0324372,"Missing"
C14-1039,P10-1064,0,0.441066,"Missing"
C14-1039,C10-2043,0,0.430716,"Missing"
C14-1039,2011.mtsummit-papers.52,0,0.0532933,"Missing"
C14-1039,W04-3250,0,0.264782,"Missing"
C14-1039,N03-1017,0,0.0143902,"ted as SMT) are adopted as our two baseline systems. Following (Wang et al., 2013), for TM, the word-based fuzzy match score is adopted as the similarity measure; also, for the phrasebased SMT system, the same Moses toolkit (Koehn et al., 2007) and the same set of following features are adopted: the phrase translation model, the language model, the distance-based reordering model, the lexicalized reordering model and the word penalty. The system configurations are as follows: GIZA++ (Och and Ney, 2003) is used to obtain the bidirectional word alignments. Afterwards, “intersection” refinement (Koehn et al., 2003) is adopted to extract phrase-pairs. We use SRI Language Model 401 New TM Database SMT Training Set #Sentences 130,953 130,953 #Chn. Words 1,808,992 1,814,524 #Chn. VOC. 30,164 29,792 #Eng. Words 1,811,413 1,815,615 #Eng. VOC. 30,807 30,516 Table 1: Corpus Statistics for In-Domain Tests Intervals #Sentences #Words W/S [0.9, 1.0) 147 2,431 16.5 [0.8, 0.9) 255 3,438 13.5 [0.7, 0.8) 244 3,299 13.5 [0.6, 0.7) 355 4,674 13.2 [0.5, 0.6) 488 6,125 12.6 [0.4, 0.5) 514 7,525 14.6 [0.3, 0.4) 419 7,082 16.9 (0.0, 0.3) 154 4,074 26.5 (0.0, 1.0) 2,576 38,648 15.0 Table 2: Corpus Statistics for In-Domain Te"
C14-1039,2010.jec-1.4,0,0.62381,"thermore, the proposed approaches are significantly better than the TM, the SMT and previous integration works for both in-domain and cross-domain tests. 1 Introduction Since the translation memory (TM) system and the statistical machine translation (SMT) system complement each other in those matched sub-segments and unmatched sub-segments (Wang et al., 2013), combining them can improve the output quality significantly, especially when high-similarity fuzzy matches are available. Therefore, combining TM and SMT is drawing more and more attention in recent years (He et al., 2010a; 2010b; 2011; Koehn and Senellart, 2010; Zhechev and van Genabith, 2010; Ma et al., 2011; Dara et al., 2013; Wang et al., 2013). Those previous works on combining TM and SMT can be classified into four categories: (1) selecting the better translation sentence from TM and SMT (He et al., 2010a; 2010b; Dara et al., 2013); (2) incorporating TM matched sub-segments into SMT in a pipelined manner (Koehn and Senellart, 2010; He et al., 2011; Ma et al., 2011); (3) only enhancing the SMT phrase table with new TM phrase-pairs (Biçici and Dymetman, 2008; Simard and Isabelle, 2009); and (4) incorporating the associated TM information with eac"
C14-1039,P11-1124,0,0.56858,"Missing"
C14-1039,P03-1021,0,0.0168466,"Missing"
C14-1039,J03-1002,0,0.00500548,"this work, the translation memory system (denoted as TM) and the phrase-based machine translation system (denoted as SMT) are adopted as our two baseline systems. Following (Wang et al., 2013), for TM, the word-based fuzzy match score is adopted as the similarity measure; also, for the phrasebased SMT system, the same Moses toolkit (Koehn et al., 2007) and the same set of following features are adopted: the phrase translation model, the language model, the distance-based reordering model, the lexicalized reordering model and the word penalty. The system configurations are as follows: GIZA++ (Och and Ney, 2003) is used to obtain the bidirectional word alignments. Afterwards, “intersection” refinement (Koehn et al., 2003) is adopted to extract phrase-pairs. We use SRI Language Model 401 New TM Database SMT Training Set #Sentences 130,953 130,953 #Chn. Words 1,808,992 1,814,524 #Chn. VOC. 30,164 29,792 #Eng. Words 1,811,413 1,815,615 #Eng. VOC. 30,807 30,516 Table 1: Corpus Statistics for In-Domain Tests Intervals #Sentences #Words W/S [0.9, 1.0) 147 2,431 16.5 [0.8, 0.9) 255 3,438 13.5 [0.7, 0.8) 244 3,299 13.5 [0.6, 0.7) 355 4,674 13.2 [0.5, 0.6) 488 6,125 12.6 [0.4, 0.5) 514 7,525 14.6 [0.3, 0.4) 4"
C14-1039,P02-1040,0,0.0894804,"Missing"
C14-1039,2009.mtsummit-papers.14,0,0.886927,"more attention in recent years (He et al., 2010a; 2010b; 2011; Koehn and Senellart, 2010; Zhechev and van Genabith, 2010; Ma et al., 2011; Dara et al., 2013; Wang et al., 2013). Those previous works on combining TM and SMT can be classified into four categories: (1) selecting the better translation sentence from TM and SMT (He et al., 2010a; 2010b; Dara et al., 2013); (2) incorporating TM matched sub-segments into SMT in a pipelined manner (Koehn and Senellart, 2010; He et al., 2011; Ma et al., 2011); (3) only enhancing the SMT phrase table with new TM phrase-pairs (Biçici and Dymetman, 2008; Simard and Isabelle, 2009); and (4) incorporating the associated TM information with each source phrase to guide the SMT decoding (Wang et al., 2013). However, all previous works mentioned above only focus on the case in which the TM database and the SMT training set share the same data-set. Nonetheless, in real applications, the TM database will deviate from the SMT training set when time goes by, because the TM database will be dynamically enlarged when more translations are generated by the human translator. Therefore, this paper will concentrate on a more realistic case, in which the TM database and the SMT trainin"
C14-1039,2006.amta-papers.25,0,0.0872782,"Missing"
C14-1039,W10-3806,0,0.705605,"Missing"
C14-1039,D13-1050,0,0.0152337,"e training set (out). Therefore, the factor ( test set will possess a different probability distribution in comparison with that from the training set. However, the development set is not big enough (only a few hundreds sentence-pairs at each interval) to re-train all TM factors of the proposed model. Therefore, we simply add the following h1 feature to reflect the tendency of having high translation consistency in the development set: (   ) { Where  and  denote the source phrase, the target candidate, respectively. Furthermore, various source synonyms might generate the same translation (Zhu et al., 2013). Therefore, even SCM≠Same, we still favor the SMT phrase-pair candidate which exactly matches TM target phrase. For example, if source words are synonyms such as “需要” (want) and “要” (want), “如 果” (if) and “若” (if), “立即” (at once) and “马上” (at once), the target translations would be the same. Therefore, the issue of having high translation consistency in the technical domain is also applied. We thus further add the following h2 feature to reflect the tendency of having high translation consistency in this case (“High” and “Low” are grouped into “Other” for the SCM): (   ) { Afterwards, the a"
C14-1039,P07-2045,0,\N,Missing
C14-1039,P13-1002,1,\N,Missing
C16-2032,D14-1058,0,0.260867,"n knowledge, so the researcher can focus on the task of understanding and reasoning. (3) The body part of MWP (which mentions the given information for solving the problem) consists of only a few sentences. The understanding and reasoning procedure thus could be checked more efficiently. (4) The MWP solver has its own applications such as Computer Math Tutor and Helper for Math in Daily Life. According to the approaches used to identify entities, quantities, and to decide operands and operations, previous MWP solvers can be classified as: (1) Rule-based approaches (Mukherjee and Garain, 2008; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015), in which all related decisions are done via a statistical classifier; and (3) Mixed approach (Roy and Roth, 2015), which identifies entities and quantities with rules, yet, decides operands and operations via statistical classifiers. The main problem of the rule-based approaches is that a wide coverage rule-set is difficult and expensive to construct. Also, it is awkward in resolving ambiguity problem. In contrast, the main problems of the purely statisti"
C16-2032,O15-3002,1,0.785672,"on of the MWP. Consider the example shown in Figure 2, the IE will first select all qualified quantities which match “quan(?q, #, rose)” and with a “pick” verb-tag, and then performs a “Sum” operation on them. The irrelevant quantity “quan(q4, #, rose)” in that example is pruned out as its verb-tag is “drop”, not “pick”. The answer is then obtained by summing those quantities q1, q2 and q3. 2.4 Explanation Generation The EG is responsible for explaining the associated reasoning steps in fluent natural language based on the reasoning chain generated from IE. A math operation oriented approach (Huang et al., 2015) is adopted to explain how the answer is obtained. It first converts the given reasoning chain into its corresponding Explanation Tree, which represents the associated operations and operands for solving the MWP. After that, a specific template is used to generate the explanation text for each kind of operation. Consider the example shown in Figure 3, the explanation text “36 roses + 32 roses + 35 roses = 103 roses. ∴103 roses were picked in total.” will be generated to explain that the obtained answer is a summation of “36 roses”, “32 roses” and “35 roses”. 153 3 Experiments Our System UIUC A"
C16-2032,P14-1026,0,0.155123,"ons the given information for solving the problem) consists of only a few sentences. The understanding and reasoning procedure thus could be checked more efficiently. (4) The MWP solver has its own applications such as Computer Math Tutor and Helper for Math in Daily Life. According to the approaches used to identify entities, quantities, and to decide operands and operations, previous MWP solvers can be classified as: (1) Rule-based approaches (Mukherjee and Garain, 2008; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015), in which all related decisions are done via a statistical classifier; and (3) Mixed approach (Roy and Roth, 2015), which identifies entities and quantities with rules, yet, decides operands and operations via statistical classifiers. The main problem of the rule-based approaches is that a wide coverage rule-set is difficult and expensive to construct. Also, it is awkward in resolving ambiguity problem. In contrast, the main problems of the purely statistics-based approaches are that the performance deteriorates significantly when the MWP is complicated, and they are sensit"
C16-2032,P14-5010,0,0.00293601,". 151 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pages 151–155, Osaka, Japan, December 11-17 2016. Figure 1: The block diagram of the MWP Solver semantic (such as co-reference) information (in the context), which can be used to identify the desired operand, filter out irrelevant and perform inference to solve MWPs. 2 System Architecture The block diagram of our English MWP solver is shown in Figure 1 (Lin et al., 2015). The sentences in a MWP are analyzed by the Language Analyzer (LA) module (i.e., Stanford CoreNLP suite (Manning et al., 2014)) to obtain corresponding linguistic representation (i.e., dependency trees and coreference chains). Then, the Solution Type Classifier (STC), which is an SVM classifier adopting linear kernel functions, determines the solution type for each question in the MWP. According to the given solution type, the Logic Form Converter (LFC) transforms the linguistic representation into logic forms. Afterwards, based on the logic forms, the Inference Engine (IE) generates the answer for each question. Finally, the Explanation Generator (EG) module generates the explanation text to explain how the answer i"
C16-2032,D15-1202,0,0.0600096,"ld be checked more efficiently. (4) The MWP solver has its own applications such as Computer Math Tutor and Helper for Math in Daily Life. According to the approaches used to identify entities, quantities, and to decide operands and operations, previous MWP solvers can be classified as: (1) Rule-based approaches (Mukherjee and Garain, 2008; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015), in which all related decisions are done via a statistical classifier; and (3) Mixed approach (Roy and Roth, 2015), which identifies entities and quantities with rules, yet, decides operands and operations via statistical classifiers. The main problem of the rule-based approaches is that a wide coverage rule-set is difficult and expensive to construct. Also, it is awkward in resolving ambiguity problem. In contrast, the main problems of the purely statistics-based approaches are that the performance deteriorates significantly when the MWP is complicated, and they are sensitive to the irrelevant information (Hosseini et al., 2014). A meaning-based1 statistical framework (Lin et al., 2015) is thus proposed"
C16-2032,Q15-1001,0,0.120841,"ion for solving the problem) consists of only a few sentences. The understanding and reasoning procedure thus could be checked more efficiently. (4) The MWP solver has its own applications such as Computer Math Tutor and Helper for Math in Daily Life. According to the approaches used to identify entities, quantities, and to decide operands and operations, previous MWP solvers can be classified as: (1) Rule-based approaches (Mukherjee and Garain, 2008; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015), in which all related decisions are done via a statistical classifier; and (3) Mixed approach (Roy and Roth, 2015), which identifies entities and quantities with rules, yet, decides operands and operations via statistical classifiers. The main problem of the rule-based approaches is that a wide coverage rule-set is difficult and expensive to construct. Also, it is awkward in resolving ambiguity problem. In contrast, the main problems of the purely statistics-based approaches are that the performance deteriorates significantly when the MWP is complicated, and they are sensitive to the irreleva"
C16-2032,O15-1007,1,\N,Missing
C18-1035,W17-5310,0,0.0146148,"h intra-sentence attention (Parikh et al., 2015) (9) Binary Tree-LSTM + Structured Attention & Composition + dual-attention (Zhao et al., 2016) (10) 300D Full tree matching NTI-SLSTM-LSTM w/ global attention (Munkhdalai and Yu, 2016) (11) 300D Syntactic Tree-LSTM (Chen et al., 2017a) Human Performance (Gong et al., 2017) Our model Training Acc. 84.4 99.7 Test Acc. 83.3 89.2 85.3 92.0 89.5 82.1 83.2 83.5 86.1 86.3 90.5 86.8 87.7 87.2 88.5 87.3 92.9 97.2 90.3 87.8 87.7 87.4 77.6 78.2 Table 1. Performance on SNLI Model Matched Test Acc. Mismatched (1)BiLSTM (Williams et al., 2018) (2) Inner Att (Balazs et al., 2017) 67.0 72.1 67.6 72.1 (3) ESIM (Williams et al., 2018) (4) Gated-Att BiLSTM (Chen et al., 2017b) (5) Shortcut-Stacked encoder (Nie & Bansal, 2017) (6) DIIN (Gong et al., 2017) (7) Inner Att (ensemble) (Balazs et al., 2017) (8) Gated-Att BiLSTM (ensemble) (Chen et al., 2017b) (9) DIIN (ensemble) (Gong et al., 2017) Human Performance (Gong et al., 2017) Our model 72.3 73.2 74.6 78.8 72.2 74.9 80.0 88.5 75.1 72.1 73.6 73.6 77.8 72.8 74.9 78.7 89.2 74.7 Table 2. Performance on MultiNLI 3.2 Details of training In order to initialize the words in the triplets, we used 300 dimensional Glove embedding"
C18-1035,H05-1079,0,0.176455,"Missing"
C18-1035,D15-1075,0,0.295914,"006), information extraction (Romano et al., 2006), machine translation (Pado et al., 2009), automatic text summarization (Harabagiu et al., 2007) and so on. Some evaluations about this task have been organized in the past decades, such as the PASCAL Recognizing Textual Entailment (RTE) Challenge (Dagan et al., 2005), SemEval-2014 (Marelli et al., 2014) and RITE (Shima et al., 2011). Many previous approaches adopt statistical frameworks (Heilman et al., 2010; Kouylekov and Magnini, 2005). However, neural network approaches have emerged after Stanford Natural Language Inference (SNLI) dataset (Bowman et al., 2015) was released. Most of them adopt an increasingly complicated network structure to represent text passages, and then predict the relationship between them (Bowman et al., 2016; Liu et al., 2016b). However, P might include extra words which are not directly related to H. Actually, only the words in P that are associated with the words in H should be paid attention to. Those relevant words should be emphasized more while the irrelevant words should be less weighted during decision making. Therefore, some approaches (Parikh et al., 2016; Chen et al., 2017a) adopt attention mechanism to implicitly"
C18-1035,P16-1139,0,0.217963,"bout this task have been organized in the past decades, such as the PASCAL Recognizing Textual Entailment (RTE) Challenge (Dagan et al., 2005), SemEval-2014 (Marelli et al., 2014) and RITE (Shima et al., 2011). Many previous approaches adopt statistical frameworks (Heilman et al., 2010; Kouylekov and Magnini, 2005). However, neural network approaches have emerged after Stanford Natural Language Inference (SNLI) dataset (Bowman et al., 2015) was released. Most of them adopt an increasingly complicated network structure to represent text passages, and then predict the relationship between them (Bowman et al., 2016; Liu et al., 2016b). However, P might include extra words which are not directly related to H. Actually, only the words in P that are associated with the words in H should be paid attention to. Those relevant words should be emphasized more while the irrelevant words should be less weighted during decision making. Therefore, some approaches (Parikh et al., 2016; Chen et al., 2017a) adopt attention mechanism to implicitly align the words between two passages to yield a better performance. This idea is very similar to how human make the entailment judgment, and the result shows that it is very"
C18-1035,P17-1152,0,0.22122,"ral Language Inference (SNLI) dataset (Bowman et al., 2015) was released. Most of them adopt an increasingly complicated network structure to represent text passages, and then predict the relationship between them (Bowman et al., 2016; Liu et al., 2016b). However, P might include extra words which are not directly related to H. Actually, only the words in P that are associated with the words in H should be paid attention to. Those relevant words should be emphasized more while the irrelevant words should be less weighted during decision making. Therefore, some approaches (Parikh et al., 2016; Chen et al., 2017a) adopt attention mechanism to implicitly align the words between two passages to yield a better performance. This idea is very similar to how human make the entailment judgment, and the result shows that it is very effective for performing natural language inference on SNLI corpus in which most words in H can find their corresponding ones in P.  This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http:// creativecommons.org/licenses/by/4.0/ 414 Proceedings of the 27th International Conference on Computational Linguistics, pages 414–425 Sant"
C18-1035,W17-5307,0,0.116303,"ral Language Inference (SNLI) dataset (Bowman et al., 2015) was released. Most of them adopt an increasingly complicated network structure to represent text passages, and then predict the relationship between them (Bowman et al., 2016; Liu et al., 2016b). However, P might include extra words which are not directly related to H. Actually, only the words in P that are associated with the words in H should be paid attention to. Those relevant words should be emphasized more while the irrelevant words should be less weighted during decision making. Therefore, some approaches (Parikh et al., 2016; Chen et al., 2017a) adopt attention mechanism to implicitly align the words between two passages to yield a better performance. This idea is very similar to how human make the entailment judgment, and the result shows that it is very effective for performing natural language inference on SNLI corpus in which most words in H can find their corresponding ones in P.  This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http:// creativecommons.org/licenses/by/4.0/ 414 Proceedings of the 27th International Conference on Computational Linguistics, pages 414–425 Sant"
C18-1035,P06-1114,0,0.0404474,"ke the judgment more interpretable. Experimental results show that the performance of our approach is better than most of the approaches that use tree structures, and is comparable to other stateof-the-art approaches. 1 Introduction Natural language inference (NLI) refers to the following task: given a text passage P (Premise) (which might have more than one sentence) and a text passage H (Hypothesis), whether we can infer H from P, i.e., identifying a specific relationship among entailment, neutral and contradiction. It has many applications such as question answering (Bhaskar et al., 2013; Harabagiu and Hickl, 2006), information extraction (Romano et al., 2006), machine translation (Pado et al., 2009), automatic text summarization (Harabagiu et al., 2007) and so on. Some evaluations about this task have been organized in the past decades, such as the PASCAL Recognizing Textual Entailment (RTE) Challenge (Dagan et al., 2005), SemEval-2014 (Marelli et al., 2014) and RITE (Shima et al., 2011). Many previous approaches adopt statistical frameworks (Heilman et al., 2010; Kouylekov and Magnini, 2005). However, neural network approaches have emerged after Stanford Natural Language Inference (SNLI) dataset (Bowm"
C18-1035,N10-1145,0,0.104047,"Missing"
C18-1035,S14-2055,0,0.0126783,"rresponding cell in Figure 4. Similarly, the corresponding cell for (nsubj, sits, man) of P and (vmod, man, sitting) of H shows a darker color, which also meets human judgment. This clearly shows that the alignment weights between these two triplet sets reflect the human interpretation closely. 4 Related Work Early approaches for natural language inference usually adopted statistical models such as SVM (Joachims, 1998), CRF (Hatoriet et al., 2009) and so on, which employed hand-crafted features, and utilized various external resources and specialized sub-components such as negation detection (Lai and Hockenmaier, 2014; Levy et al., 2013). Besides, all the adopted datasets are very small. After the SNLI corpus (Bowman et al., 2015) was released, a lot of work about natural language inference based on neural networks have been published in recent years (Bowman et al., 2016; Liu et al., 2016; Liu et al., 2016b; Munkhdalai and Yu, 2016; Mou et al., 2015; Sha et al., 2016). Basically, those neural network based approaches could be classified into 2 categories: (1) Merely computing the passage-embedding without introducing alignment (between the words in the sentences), and then comparing these passage-embedding"
C18-1035,P16-1098,0,0.0395729,"Missing"
C18-1035,P16-2022,0,0.135815,"t of this corpus, it selects half of the genres to create in-domain (matched) and outdomain (mismatched) development/test sets. Since the test set labels of this corpus are not released, the test performance is obtained through submission to Kaggle.com6. 4 https://nlp.stanford.edu/projects/snli/ http://www.nyu.edu/projects/bowman/multinli/ 6 Matched : https://www.kaggle.com/c/multinli-matched-open-evaluation ; Mismatched: https://www.kaggle.com/c/multinlimismatched-open-evaluation 5 419 Model (1) LSTM (Bowman et al., 2015) (2) Classifier (Bowman et al., 2015) (3) 300D tree-based CNN encoders (Mou et al., 2016) (4) 300D SPINN-PI encoders (Bowman et al. 2016) (5) 100D LSTMs w/ word-by-word attention (Rocktaschel et al., 2015) (6) 300D mLSTM word-by-word attention model (Wang & Jiang, 2016) (7) 200D decomposable attention model (Parikh et al., 2015) (8) 200D decomposable attention model with intra-sentence attention (Parikh et al., 2015) (9) Binary Tree-LSTM + Structured Attention & Composition + dual-attention (Zhao et al., 2016) (10) 300D Full tree matching NTI-SLSTM-LSTM w/ global attention (Munkhdalai and Yu, 2016) (11) 300D Syntactic Tree-LSTM (Chen et al., 2017a) Human Performance (Gong et al.,"
C18-1035,W17-5308,0,0.0266904,"0) 300D Full tree matching NTI-SLSTM-LSTM w/ global attention (Munkhdalai and Yu, 2016) (11) 300D Syntactic Tree-LSTM (Chen et al., 2017a) Human Performance (Gong et al., 2017) Our model Training Acc. 84.4 99.7 Test Acc. 83.3 89.2 85.3 92.0 89.5 82.1 83.2 83.5 86.1 86.3 90.5 86.8 87.7 87.2 88.5 87.3 92.9 97.2 90.3 87.8 87.7 87.4 77.6 78.2 Table 1. Performance on SNLI Model Matched Test Acc. Mismatched (1)BiLSTM (Williams et al., 2018) (2) Inner Att (Balazs et al., 2017) 67.0 72.1 67.6 72.1 (3) ESIM (Williams et al., 2018) (4) Gated-Att BiLSTM (Chen et al., 2017b) (5) Shortcut-Stacked encoder (Nie & Bansal, 2017) (6) DIIN (Gong et al., 2017) (7) Inner Att (ensemble) (Balazs et al., 2017) (8) Gated-Att BiLSTM (ensemble) (Chen et al., 2017b) (9) DIIN (ensemble) (Gong et al., 2017) Human Performance (Gong et al., 2017) Our model 72.3 73.2 74.6 78.8 72.2 74.9 80.0 88.5 75.1 72.1 73.6 73.6 77.8 72.8 74.9 78.7 89.2 74.7 Table 2. Performance on MultiNLI 3.2 Details of training In order to initialize the words in the triplets, we used 300 dimensional Glove embedding (Pennington et al., 2014). For the relation vectors (the dimension is set to 20), we use a standard normal distribution to randomly initialize th"
C18-1035,D16-1244,0,0.179938,"d after Stanford Natural Language Inference (SNLI) dataset (Bowman et al., 2015) was released. Most of them adopt an increasingly complicated network structure to represent text passages, and then predict the relationship between them (Bowman et al., 2016; Liu et al., 2016b). However, P might include extra words which are not directly related to H. Actually, only the words in P that are associated with the words in H should be paid attention to. Those relevant words should be emphasized more while the irrelevant words should be less weighted during decision making. Therefore, some approaches (Parikh et al., 2016; Chen et al., 2017a) adopt attention mechanism to implicitly align the words between two passages to yield a better performance. This idea is very similar to how human make the entailment judgment, and the result shows that it is very effective for performing natural language inference on SNLI corpus in which most words in H can find their corresponding ones in P.  This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http:// creativecommons.org/licenses/by/4.0/ 414 Proceedings of the 27th International Conference on Computational Linguistics,"
C18-1035,D14-1162,0,0.08582,"We define ^ : = ( , , ⋯ , ) and ^ : = (ℎ , ℎ , ⋯ , ℎ ) be two sets of RHD triplets, while and ℎ denote the RHD triplet and the RHD triplet in P and H, respectively; also, m and n indicate the number of associated triplets in P and H, respectively. We then instantiate the Input Layer with the corresponding word-embeddings and rel-embedding of RHD triplets (For conciseness, we will let rel/head/dep denote both the original meaning and the corresponding embedding interchangeably from now on). Each ℎ , ∈ is a word embedding of dimension which is initialized with pre-trained GloVe word embedding (Pennington et al., 2014), while ∈ is a relation embedding vector of dimension and is initialized randomly with a standard normal distribution (Please note, only will be tuned later during training). Each triplet-embedding will be presented as a triplet which contains three embedding corresponding to rel, head and dep respectively. 2.2 Network Architecture 2.2.1 Triplet Embedding Layer As we fix the value of word embedding during training, in order to obtain better relation/word embedding representations to compare for this task, we use a simple feed-forward structure to adapt the three parts of the triplet to the tas"
C18-1035,N15-2020,0,0.0529031,"Missing"
C18-1035,N16-1170,0,0.022258,"leased, the test performance is obtained through submission to Kaggle.com6. 4 https://nlp.stanford.edu/projects/snli/ http://www.nyu.edu/projects/bowman/multinli/ 6 Matched : https://www.kaggle.com/c/multinli-matched-open-evaluation ; Mismatched: https://www.kaggle.com/c/multinlimismatched-open-evaluation 5 419 Model (1) LSTM (Bowman et al., 2015) (2) Classifier (Bowman et al., 2015) (3) 300D tree-based CNN encoders (Mou et al., 2016) (4) 300D SPINN-PI encoders (Bowman et al. 2016) (5) 100D LSTMs w/ word-by-word attention (Rocktaschel et al., 2015) (6) 300D mLSTM word-by-word attention model (Wang & Jiang, 2016) (7) 200D decomposable attention model (Parikh et al., 2015) (8) 200D decomposable attention model with intra-sentence attention (Parikh et al., 2015) (9) Binary Tree-LSTM + Structured Attention & Composition + dual-attention (Zhao et al., 2016) (10) 300D Full tree matching NTI-SLSTM-LSTM w/ global attention (Munkhdalai and Yu, 2016) (11) 300D Syntactic Tree-LSTM (Chen et al., 2017a) Human Performance (Gong et al., 2017) Our model Training Acc. 84.4 99.7 Test Acc. 83.3 89.2 85.3 92.0 89.5 82.1 83.2 83.5 86.1 86.3 90.5 86.8 87.7 87.2 88.5 87.3 92.9 97.2 90.3 87.8 87.7 87.4 77.6 78.2 Table 1. Pe"
C18-1035,N18-1101,0,0.0590292,"in two different directions). We then concatenate them and use a multi-layer perceptron classifier Q (it has two hidden layers with Relu activation and a softmax output layer) to generate the final overall judgment vector ˆ (as shown in Eq. (8)), where ˆ ∈ (C equals the number of classes) are the scores for each class. The predicted class can be got by setting = argmax ˆ . When we train the model, we use multi-class cross-entropy loss with dropout regularization (Srivastava et al., 2014). ˆ = ([ 3 3.1 ; ]) (8) Experiments Dataset We adopt both SNLI (Bowman et al., 2015) corpus4 and MultiNLI (Williams et al., 2018) corpus5 to test the performance. They are briefly introduced as follows. SNLI - It contains 570k sentence pairs. The sentence pairs in this corpus are labelled with one of the following relationships: entailment, contradiction, neutral and “-”, where “-” means that it lacks of consensus from human annotators. In our experiments, we follow Bowman et al. (2015) to delete those sentence pairs labelled with “-“. Consequently, we end up with 549,367 pairs for training, 9,842 pairs for development and 9,824 pairs for testing. MultiNLI - This corpus has 433k sentence pairs, which are collected from"
C18-1035,C16-1212,0,0.0431901,"Missing"
C18-1035,S14-2044,0,0.0646143,"Missing"
C88-2133,J85-2002,0,\N,Missing
C92-1055,1991.mtsummit-papers.5,0,0.188791,"Missing"
C92-1055,A88-1019,0,0.0868826,"Missing"
C92-1055,C88-2133,1,0.36043,"Missing"
C92-2067,P92-1023,1,0.884729,"Missing"
C92-2067,C92-1055,1,0.857115,"Missing"
C92-2067,C90-2037,0,0.0611507,"Missing"
C92-2067,O90-1004,1,0.916307,"Missing"
C92-2067,W89-0210,1,0.929735,"Missing"
C92-2067,C88-2133,1,\N,Missing
C94-1023,C92-1055,1,0.812734,"Missing"
C94-1023,O92-1001,1,\N,Missing
C94-1023,H89-2048,0,\N,Missing
J13-2001,P02-1051,0,0.0195841,"features), from which a NE translation dictionary was then constructed. Kumano et al. (2004) proposed a method to extract English–Chinese NE pairs from a content-aligned corpus. This approach tries to ﬁnd the correspondences between bilingual NE groups based on the similarity in their order of appearance in each document. Additionally, an abridged version of our work has been presented in our ACL-10 paper (Chen, Zong, and Su 2010). Among those symmetric approaches, only Huang, Vogel, and Waibel and Chen, Zong, and Su adopt the expansion strategy, described below. For the asymmetric strategy, Al-Onaizan and Knight (2002) proposed an algorithm to translate NEs from Arabic to English using monolingual and bilingual resources. Given an Arabic NE, they used transliteration models (including a phonetic-based and a spelling-based model), a bilingual dictionary, and an English news corpus to ﬁrst generate a list of English candidates, which were then re-scored by a Web resource. 261 Computational Linguistics Volume 39, Number 2 Moore (2003) developed an approach to learning phrase translations from a parallel corpus based on a sequence of cost models. A maximum entropy model for NE alignment was presented in Feng, L"
J13-2001,J96-1002,0,0.0681675,"Missing"
J13-2001,A97-1029,0,0.027549,"del, combined with semi-supervised learning, offers signiﬁcant improvement for semi-automatically updating the NE recognition model and the NE translation table. Additionally, the impact is greater when less time is available for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prio"
J13-2001,W02-2002,0,0.0287446,"ditionally, the impact is greater when less time is available for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prior work on the use of bilingual NE alignment for NE recognition, Huang and Vogel (2004) used an iterative process to extract a smaller but cleaner NE translation dictionary and t"
J13-2001,J93-2003,0,0.037461,"Missing"
J13-2001,W02-2004,0,0.0461628,"Missing"
J13-2001,M98-1017,0,0.129819,"the alignment-baseline model, because information from the aligned sentence is utilized more effectively. Results demonstrate that the proposed joint model, combined with semi-supervised learning, offers signiﬁcant improvement for semi-automatically updating the NE recognition model and the NE translation table. Additionally, the impact is greater when less time is available for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global i"
J13-2001,P98-1036,0,0.283962,"the alignment-baseline model, because information from the aligned sentence is utilized more effectively. Results demonstrate that the proposed joint model, combined with semi-supervised learning, offers signiﬁcant improvement for semi-automatically updating the NE recognition model and the NE translation table. Additionally, the impact is greater when less time is available for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global i"
J13-2001,W03-1501,0,0.0609135,"Missing"
J13-2001,P10-1065,1,0.755665,"Missing"
J13-2001,M98-1001,0,0.0275264,"proposed joint model gains more from the learning process in comparison with the alignment-baseline model, because information from the aligned sentence is utilized more effectively. Results demonstrate that the proposed joint model, combined with semi-supervised learning, offers signiﬁcant improvement for semi-automatically updating the NE recognition model and the NE translation table. Additionally, the impact is greater when less time is available for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore,"
J13-2001,W04-3248,0,0.0155113,"Missing"
J13-2001,P05-1045,0,0.0262696,"Missing"
J13-2001,J05-4005,0,0.021018,"Missing"
J13-2001,W03-1502,0,0.0097625,"ce and the target, Huang, Vogel, and Waibel (2003) proposed to ﬁrst identify the NEs in both the source and target, and then enlarge the obtained NE candidate sets for both languages before conducting alignment. Based on the observation that NE boundaries are frequently identiﬁed incorrectly, the enlarging procedure is done by treating the original recognition results as anchors and then increasing the number of candidates by expanding or shrinking the boundaries of those originally recognized NEs in both languages. Our approach also adopts the expansion strategy. It differs from the works of Huang et al. (2003) and others in several ways, however. First, in all the alignment papers mentioned here, the adopted probabilities are directly used as features for log-linear combination or ME training without derivation. In contrast, our work fully derives a probabilistic joint model, for both identiﬁcation and alignment, in a principled way. Second, unlike previous approaches that discard the information of initially identiﬁed NE anchors after the anchors have been expanded, our approach uses this information in the ﬁnal selection process. Third, we propose new features, such as translation mode and its ra"
J13-2001,P06-2055,0,0.0224415,"Missing"
J13-2001,P06-1027,0,0.0129572,"the NE recognition model and the NE translation table. Additionally, the impact is greater when less time is available for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prior work on the use of bilingual NE alignment for NE recognition, Huang and Vogel (2004) used an iterative p"
J13-2001,P06-1141,0,0.0115211,"hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prior work on the use of bilingual NE alignment for NE recognition, Huang and Vogel (2004) used an iterative process to extract a smaller but cleaner NE translation dictionary and then used the dictionary to improve the monolingual NE annotation quality. Ji and Grishman (2007) adopted several heuristic rules for using bilingual-text information to correct NE recognition errors. In aligning bilingual NEs from two given NE lists, the NE translation model is usually adopted. Typically, an NE is either transliterated or semantically translated. For transliteration, Knight a"
J13-2001,W03-0317,0,0.0328476,"veral heuristic rules for using bilingual-text information to correct NE recognition errors. In aligning bilingual NEs from two given NE lists, the NE translation model is usually adopted. Typically, an NE is either transliterated or semantically translated. For transliteration, Knight and Graehl (1998) were pioneers in adopting the probabilistic model to align the components within an NE pair. Since then, similar approaches have been applied to various language pairs such as English/Arabic (Stalls and Knight 1998), English/Chinese (Chen et al. 1998b; Wan and Verspoor 1998; Lin and Chen 2002; Lee and Chang 2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260 Chen, Zong, and Su A Joint Model to Identify and Align Bilingual Named Entities Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li, Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account for personal names. In contrast, research on automatic NE semantic translation is less common. Zhan"
J13-2001,Y03-1035,0,0.0485385,"Missing"
J13-2001,P07-1016,0,0.016498,"c model to align the components within an NE pair. Since then, similar approaches have been applied to various language pairs such as English/Arabic (Stalls and Knight 1998), English/Chinese (Chen et al. 1998b; Wan and Verspoor 1998; Lin and Chen 2002; Lee and Chang 2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260 Chen, Zong, and Su A Joint Model to Identify and Align Bilingual Named Entities Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li, Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account for personal names. In contrast, research on automatic NE semantic translation is less common. Zhang et al. (2005) proposed a phrase-based context-dependent joint probability model for semantic translation, which is similar to phrase-level translation models in statistical MT (Zong and Seligman 2005; Hu, Zong, and Xu 2006). Chen, Yang, and Lin (2003) and Chen et al. (2006) studied formulation and transformation rules for English–Chinese NEs"
J13-2001,P04-1021,0,0.0144383,"Missing"
J13-2001,W09-2208,0,0.0128217,"s languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prior work on the use of bilingual NE alignment for NE recognition, Huang and Vogel (2004) used an iterative process to extract a smaller but cleaner NE translation dictionary and then used the dictionary to improve the monolingual NE annotation quality. Ji and Grishman (2007) adopted several heuristic rules for using bilingual-text information to correc"
J13-2001,W02-2017,0,0.0341124,"n (2007) adopted several heuristic rules for using bilingual-text information to correct NE recognition errors. In aligning bilingual NEs from two given NE lists, the NE translation model is usually adopted. Typically, an NE is either transliterated or semantically translated. For transliteration, Knight and Graehl (1998) were pioneers in adopting the probabilistic model to align the components within an NE pair. Since then, similar approaches have been applied to various language pairs such as English/Arabic (Stalls and Knight 1998), English/Chinese (Chen et al. 1998b; Wan and Verspoor 1998; Lin and Chen 2002; Lee and Chang 2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260 Chen, Zong, and Su A Joint Model to Identify and Align Bilingual Named Entities Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li, Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account for personal names. In contrast, research on automatic NE semantic translation"
J13-2001,W03-0430,0,0.0133557,"automatically updating the NE recognition model and the NE translation table. Additionally, the impact is greater when less time is available for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prior work on the use of bilingual NE alignment for NE recognition, Huang and Vogel (2004)"
J13-2001,M98-1021,0,0.0350359,"Missing"
J13-2001,E03-1035,0,0.0483518,"t performance. One way to alleviate this error propagation problem is to jointly perform NE recognition and alignment. Such a combined approach is usually infeasible, however, due to the high computational cost of evaluating alignment scores for a large number2 of NE pair candidates. In order to make the problem computationally tractable, a sequential approach is usually used to ﬁrst identify NEs and then align them. Two such kinds of sequential strategies that alleviate the error propagation problem have been proposed. The ﬁrst strategy, named asymmetry alignment (Al-Onaizan and Knight 2002; Moore 2003; Feng, Lv, and Zhou 2004; Lee, Chang, and Jang 2006), identiﬁes NEs only on the source side and then ﬁnds their corresponding NEs on the target side. Although this approach avoids the NE recognition errors resulting from the target side, which would otherwise be brought into the alignment process, the NE recognition errors from the source side continue to affect alignment. To further reduce the errors from the source side, the second strategy, denoted symmetry alignment (Huang, Vogel, and Waibel 2003), expands the NE candidate sets in both languages before conducting the alignment. This is ac"
J13-2001,P03-1021,0,0.0341531,"Missing"
J13-2001,J03-1002,0,0.0235233,"Missing"
J13-2001,C02-1099,0,0.011184,"ight and Graehl (1998) were pioneers in adopting the probabilistic model to align the components within an NE pair. Since then, similar approaches have been applied to various language pairs such as English/Arabic (Stalls and Knight 1998), English/Chinese (Chen et al. 1998b; Wan and Verspoor 1998; Lin and Chen 2002; Lee and Chang 2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260 Chen, Zong, and Su A Joint Model to Identify and Align Bilingual Named Entities Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li, Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account for personal names. In contrast, research on automatic NE semantic translation is less common. Zhang et al. (2005) proposed a phrase-based context-dependent joint probability model for semantic translation, which is similar to phrase-level translation models in statistical MT (Zong and Seligman 2005; Hu, Zong, and Xu 2006). Chen, Yang, and Lin (2003) and Chen et al. (2006) stu"
J13-2001,I05-1040,0,0.054327,"Missing"
J13-2001,P09-1016,0,0.0494324,"Missing"
J13-2001,C04-1089,0,0.0435839,"spelling-based model), a bilingual dictionary, and an English news corpus to ﬁrst generate a list of English candidates, which were then re-scored by a Web resource. 261 Computational Linguistics Volume 39, Number 2 Moore (2003) developed an approach to learning phrase translations from a parallel corpus based on a sequence of cost models. A maximum entropy model for NE alignment was presented in Feng, Lv, and Zhou (2004). Lee, Chang, and Jang (2006) proposed to align bilingual NEs in a bilingual corpus by incorporating a statistical model with multiple sources. Turning to comparable corpora, Shao and Ng (2004) presented a hybrid method to mine new translations from Chinese–English comparable corpora, combining both transliteration and context information. Sproat, Tao, and Zhai (2006) investigated the Chinese–English NE transliteration equivalence within comparable corpora. Although these asymmetry strategies can prevent NE recognition errors on the target side from affecting alignment, errors on the source side continue to propagate to later stages. To reduce error propagation from both the source and the target, Huang, Vogel, and Waibel (2003) proposed to ﬁrst identify the NEs in both the source a"
J13-2001,P06-1010,0,0.0141249,"Missing"
J13-2001,W98-1005,0,0.0525921,"used the dictionary to improve the monolingual NE annotation quality. Ji and Grishman (2007) adopted several heuristic rules for using bilingual-text information to correct NE recognition errors. In aligning bilingual NEs from two given NE lists, the NE translation model is usually adopted. Typically, an NE is either transliterated or semantically translated. For transliteration, Knight and Graehl (1998) were pioneers in adopting the probabilistic model to align the components within an NE pair. Since then, similar approaches have been applied to various language pairs such as English/Arabic (Stalls and Knight 1998), English/Chinese (Chen et al. 1998b; Wan and Verspoor 1998; Lin and Chen 2002; Lee and Chang 2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260 Chen, Zong, and Su A Joint Model to Identify and Align Bilingual Named Entities Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li, Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account f"
J13-2001,O03-5001,0,0.0770014,"Missing"
J13-2001,P98-2220,0,0.0385865,"quality. Ji and Grishman (2007) adopted several heuristic rules for using bilingual-text information to correct NE recognition errors. In aligning bilingual NEs from two given NE lists, the NE translation model is usually adopted. Typically, an NE is either transliterated or semantically translated. For transliteration, Knight and Graehl (1998) were pioneers in adopting the probabilistic model to align the components within an NE pair. Since then, similar approaches have been applied to various language pairs such as English/Arabic (Stalls and Knight 1998), English/Chinese (Chen et al. 1998b; Wan and Verspoor 1998; Lin and Chen 2002; Lee and Chang 2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260 Chen, Zong, and Su A Joint Model to Identify and Align Bilingual Named Entities Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li, Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account for personal names. In contrast, research on automatic NE se"
J13-2001,W02-2035,0,0.0470152,"lable for labeling seed data. 7. Related Work There is signiﬁcant work on identifying NEs within monolingual texts across languages, such as English (Chinchor 1998; Mikheev, Grover, and Moens 1998; Borthwick 1999) and Chinese (Chen et al. 1998a; Sun, Zhou, and Gao 2003), to name a few. Various approaches to identifying NEs have also been proposed, such as hidden Markov models (Bikel et al. 1997; Bikel, Schwartz, and Weischedel 1999), conditional random ﬁelds (McCallum and Li 2003; Jiao et al. 2006), modiﬁed transformation-based learning (Black and Vasilakopoulos 2002), boosting (Collins 2002; Wu et al. 2002), AdaBoost (Carreras, Marquez, and Padro 2002), and adopting semi-supervised learning (Wong and Ng 2007; Liao and Veeramachaneni 2009). Furthermore, features including local information (e.g., token, part-of-speech) and global information (e.g., label consistency, context features) from monolingual resources have been adopted (Krishman and Manning 2006; Zhou and Su 2006). In prior work on the use of bilingual NE alignment for NE recognition, Huang and Vogel (2004) used an iterative process to extract a smaller but cleaner NE translation dictionary and then used the dictionary to improve the mo"
J13-2001,I05-1053,0,0.0214147,"2003; Lee, Chang, and Jang 2003; Gao, Wong, and Lam 2004; 260 Chen, Zong, and Su A Joint Model to Identify and Align Bilingual Named Entities Pervouchine, Li, and Lin 2009), English/Japanese (Knight and Graehl 1998; Tsuji 2002), and English/Korean (Lee and Choi 1997; Oh and Choi 2002, 2005). Moreover, Li, Zhang, and Su (2004), and Li et al. (2007) presented a joint source channel model for transliteration, and automated the semantic transliteration process, which takes origin and gender into account for personal names. In contrast, research on automatic NE semantic translation is less common. Zhang et al. (2005) proposed a phrase-based context-dependent joint probability model for semantic translation, which is similar to phrase-level translation models in statistical MT (Zong and Seligman 2005; Hu, Zong, and Xu 2006). Chen, Yang, and Lin (2003) and Chen et al. (2006) studied formulation and transformation rules for English–Chinese NEs. They adopted a frequency-based approach for extracting key words of NEs with or without dictionary assistance and constructed transformation rules from the bilingual NE corpus. Their studies focused on transformation rules with particular attention to distinguishing t"
J13-2001,zhang-etal-2004-interpreting,0,0.0234046,"Missing"
J13-2001,I08-4017,0,0.024645,"Missing"
J13-2001,M98-1004,0,\N,Missing
J13-2001,M98-1012,0,\N,Missing
J13-2001,M98-1014,0,\N,Missing
J13-2001,C98-1036,0,\N,Missing
J13-2001,C98-2215,0,\N,Missing
J13-2001,J98-4003,0,\N,Missing
J13-2001,P02-1062,0,\N,Missing
J95-3002,J93-1002,0,0.393453,"mode. Notice that the last formula in Equation 9 corresponds to the rightmost derivation sequence in a generalized LR parser with left and right contexts taken into account (Su et al. 1991). Such a formulation is particularly useful for a generalized LR parsing algorithm, in which context-sensitive processing power is desirable. Although the context-sensitive model in the above equation provides the ability to deal with intralevel context-sensitivity, it fails to catch inter-level correlation. In addition, the formulation of Equation 9 will result in the normalization problem (Suet al. 1991; Briscoe and Carroll 1993) when various syntactic trees have different number of nodes. An alternative formulation, which compacts the highly correlated phrase levels into a single one, was proposed by S u e t al. (1991) to resolve the normalization problem. For instance, for the syntactic tree in Figure 2, the syntactic score for the modified formulation is expressed as follows: Ssyn(Treex) ~ P(Ls, L7,L6 I L5) x P(L5 [L4) x P(L4,L3 I L2) x P(L2 ILl) ~, P(L8 ]L5) × P(L5 ]L4) x P(L4 ]L2) x P(L2 ]L1). (12) Each pair of phrase levels in the above equation corresponds to a change in the LR parser&apos;s stack before and after a"
J95-3002,J92-4003,0,0.014661,"example, in groups of adjectives, nouns, conjunction constructs, prepositional phrases in English, the estimated scores will be affected by such differences. In other words, we use context symbols explicitly and directly to evaluate the probabilities of a substructure instead of using the parsing state to implicitly encode past history, which may fail to provide a sufficient characterization of the left context. In addition, explicitly using the left context symbols allows easy use of smoothing techniques, such as deleted interpolation (Bahl, Jelinek, and Mercer 1983), clustering techniques (Brown et al. 1992), and model refinement techniques (Lin, Chiang, and Su 1994) to estimate the probabilities more reliably by changing the window sizes of the context and weighting the various estimates dynamically. This kind of improvement is desirable when the training data is limited. Furthermore, Briscoe and Carroll (1993) use the geometric mean of the probabilities, not their product, as the preference score, to avoid biasing their procedure in favor of parse trees that have a smaller number of nodes (i.e., a smaller number of rules being applied.) The geometric mean, however, fails to fit into the probabi"
J95-3002,P92-1023,1,0.930582,"Missing"
J95-3002,1991.mtsummit-papers.5,0,0.743418,"nd reduce the number of parameters is described in Section 6. Finally, we discuss our conclusions and describe the direction of future work. 2. A Unified Probabilistic Score Function Linguistic knowledge, including knowledge of lexicon, syntax, and semantics, is essential for resolving syntactic ambiguities. To integrate various knowledge sources in a uniform formulation, a unified probabilistic scoring function was proposed by Su et al. (1991). This scoring function has been successfully applied to resolve ambiguity problems in an English-to-Chinese machine translation system (BehaviorTran) (Chen et al. 1991) and a spoken language processing system (Su, Chiang, and Lin 1991; 1992). The unified probabilistic scoring function derived for the syntactic disambiguation task is summarized in the following sections. 2.1 Definition An illustration of syntactic ambiguities for an input sentence W (= w~ = {wl, w2. . . . . Wn}) is shown in Figure 1, where wi (i = 1, n) stands for the ith word of the input sentence. In this figure, LeXk (1 &lt; k ~ m) stands for the kth lexical sequence out of M possible sequences. Synj,k (1 ~ j &lt; Nk) is the jth alternative syntactic structure corresponding to LeXk, and Nk is th"
J95-3002,C92-1055,1,0.824448,"Missing"
J95-3002,C94-1023,1,0.893801,"Missing"
J95-3002,C88-2133,1,0.836514,"Missing"
J95-3002,W89-0210,1,0.944037,"Missing"
L16-1466,P98-1013,0,0.179619,"s corpus is that having a bilingual semantic corpus with refined semantic role information is expected to bring significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropB"
L16-1466,P13-2074,0,0.0152896,"tes the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006) in our treebank to reduce span-crossing, and then t"
L16-1466,W05-0620,0,0.0423719,"Missing"
L16-1466,2007.tmi-papers.10,0,0.0892051,"Missing"
L16-1466,J02-3001,0,0.199086,"are the two most commonly used semantic resources in Semantic Role Labeling (SRL) and SMT tasks. FrameNet is based on a theory of meaning called Frame Semantics (Fillmore, 1982). The basic idea is that the meanings of most words can best be understood on the basis of their semantic frames, which describe the types of events, relations, and the participants involved. In FrameNet, most sentences are selected manually from British National Corpus and then assigned with their associated frames based on the frame semantics theory. FrameNet was first adopted in the SRL task by Gildea and Jurafsky (Gildea and Jurafsky, 2002). However it has not been widely used in SMT tasks. On the other hand, PropBank has been widely used in both SRL and SMT since CoNLL-2005 (Carreras and M`arquez, 2005). It annotates the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Re"
L16-1466,W00-1205,0,0.569462,"information is expected to bring significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropBank are the two most commonly used semantic resources in Semantic Role Labeling"
L16-1466,C10-1081,0,0.123286,"quez, 2005). It annotates the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006) in our treebank to re"
L16-1466,J93-2004,0,0.0536242,"Missing"
L16-1466,W04-2705,0,0.0359129,"ng significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropBank are the two most commonly used semantic resources in Semantic Role Labeling (SRL) and SMT tasks. FrameNet"
L16-1466,J05-1004,0,0.0875404,"gual semantic corpus with refined semantic role information is expected to bring significant benefit to the task of Statistical Machine Translation (SMT). Since the semantic constituent is less variant during translation in comparison with the syntactic constituent (Fung et al., 2007), it should lessen the data sparseness problem of translation patterns, which often occur in syntactic SMT. Researchers have paid attention to constructing semantic resources in the last 20 years. And many useful and high-quality semantic resources have been built, such as FrameNet (Baker et al., 1998), PropBank (Palmer et al., 2005), Academia Sinica Treebank (Huang et al., 2000), NomBank (Meyers et al., 2004) , VerbNet (Schuler, 2005), HowNet (Dong and Dong, 2003), etc. However, each of them only serves its own purpose. Therefore, they are different from each other in many details, such as annotation types (e.g., frame sets in FrameNet, shared semantic arguments in PropBank) and annotation methods (e.g., adding a layer of predicate-argument information to syntactic structures in PropBank, and labeling semantic information on each node as Sinica Treebank does). Currently, FrameNet and PropBank are the two most commonly us"
L16-1466,P06-1055,0,0.226841,"Missing"
L16-1466,1995.tmi-1.27,1,0.192568,"Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006) in our treebank to reduce span-crossing, and then transform the DST into its corresponding case tree. Also, we label all the tree nodes of the DST (not only nouns and verbs but also clauses, adjectives, adverbs, interjections, etc.) with our semantic case labels. We tailor the Sinica case set (Huang et al., 2000) to share the same case set in both Chinese and English case trees, an"
L16-1466,2009.eamt-1.30,0,0.0244656,"(Carreras and M`arquez, 2005). It annotates the Penn TreeBank with predicate argument structures, and uses shared arguments as semantic labels. But it only labels a part of the nodes in the constituency tree. Therefore, it cannot clearly represent the relation between clauses or the relation between various arguments (e.g., the semantic relation in phrase “everyday [Modifier] life [Head word]” or between clauses “I come back [Result], because of the rain)[Reason]” are not represented ). In previous work, researches had brought semantic relation labeling and tree flattening into the SMT task (Wu and Fung, 2009; Liu and Gildea, 2010; Bazrafshan and Gildea, 2013). However, most of those existing Treebanks are: (1) not in bilingual form (e.g., Sinica Treebank etc.), (2) in bilingual form but the translation direction of the corpus is not from English to Chinese(e.g., PropBank), or (3) annotation coverage is not fine enough (e.g. PropBank). Therefore, inspired by the work of Su et al. (1995), we build this corpus to meet our requirements. Since the compatibility during tree translation is an important issue for tree-based SMT, we adopt the Deep Syntactic Tree (DST) structure (Mel´ˇcuk and Wanner, 2006)"
N16-3014,D14-1058,0,0.622321,", operations, etc.) with a logic inposed tag-based approach provides the flexiference engine. (2) Rule-based approaches without bility for annotating an extracted math quantilogic inference (Charniak, 1968 and 1969; Gelb, ty with its associated syntactic and semantic 1971; Ballard, 1979; Biermann and Ballard, 1980; information, which can be used to identify the Biermann et al., 1982; Fletcher, 1985; Dellarosa, desired operand and filter out irrelevant quantities. The proposed approach is thus less sen1986; Bakman, 2007; Liguda and Pfeiffer, 2012; sitive to the irrelevant information and could Hosseini et al., 2014), which apply rules (usually provide the answer more precisely. Also, it defined as schemata) to get the answer without a can handle much more problem types other logic inference engine. (3) Purely statistic-based than addition and subtraction. approaches (Kushman et al., 2014; Roy et al., 2015), which use statistical models to identify enti1 Introduction ties, quantities, operations, and get the answer The math word problem (MWP) (Mukherjee and without conducting language analysis or inference. The main problem of the rule-based approaches Garain, 2008) is frequently chosen to study natural l"
N16-3014,P14-1026,0,0.403762,"rd, 1979; Biermann and Ballard, 1980; information, which can be used to identify the Biermann et al., 1982; Fletcher, 1985; Dellarosa, desired operand and filter out irrelevant quantities. The proposed approach is thus less sen1986; Bakman, 2007; Liguda and Pfeiffer, 2012; sitive to the irrelevant information and could Hosseini et al., 2014), which apply rules (usually provide the answer more precisely. Also, it defined as schemata) to get the answer without a can handle much more problem types other logic inference engine. (3) Purely statistic-based than addition and subtraction. approaches (Kushman et al., 2014; Roy et al., 2015), which use statistical models to identify enti1 Introduction ties, quantities, operations, and get the answer The math word problem (MWP) (Mukherjee and without conducting language analysis or inference. The main problem of the rule-based approaches Garain, 2008) is frequently chosen to study natural language understanding due to the following rea- mentioned above is that the coverage rate problem sons: (1) Since the answer for the MWP cannot be is serious, as rules with wide coverage are difficult extracted by simply performing keyword/pattern and expensive to construct. A"
N16-3014,P14-5010,0,0.00567341,". The LFC extracts the related facts from the given linguistic information and then represents those facts as the first-order logic (FOL) predicates/functions (Russel and Norvig, 2009). It also transforms each question into a FOL-like utility function according to the suggested solution type. The IE then derives new facts according to inference rules and old facts provided by the LFC. It is also responsible for providing utilities to perform math operations on related facts to get the answer. Detailed description of each module is given below. 2.1 Language Analysis The Stanford CoreNLP suite (Manning et al., 2014) is adopted as our LA, which enables a list of annotators to generate the necessary linguistic information. The list includes: tokenization, sentence splitting, POS tagging, lemmatization, named entity recognition, parsing and co-reference resolution. The generated linguistic representation mainly depicts the syntactic relations between its words. To solve MWPs, it is crucial to know the relations between various entities. Dependency relation and co-reference resolution will provide such information. 2.2 Solution Type Identification The STC will select a math operation (that LFC should adopt t"
N16-3014,O15-3002,1,0.829932,"e to help the IE to find the solutions. For example, “verb(q1, pick)&nsubj(q1, Fred)” is the associated auxiliary facts of “quan(q1, #, lime)=36”. Those auxiliary facts are our proposed tags to make the system less sensitive to the irrelevant information. They also provide the flexibility of handling various kinds of possible questions. 69 Figure 2: Logic form and logic inference of a Sum operation 2.5 Explanation Generation Based on the reasoning chain generated from the IE (an example is shown in Figure 3), a math operation oriented approach is adopted to explain how the answer is obtained (Huang et al., 2015). A specific template is used to generate the explanation text for each kind of operation. Consider the example given in Figure 2, the template for “Sum” operation would be “Totally verb Child_1 + Child_2 + Child_3 + ...+ Child_n = Parent.”. According to that template and the reasoning chain shown in Figure 3, The EG will generate the explanation text “Totally pick 36 limes + 32 limes + 35 limes = 103 limes”, which explains that the obtained answer is a summation of “36 limes”, “32 limes” and “35 limes”. Figure 3: The reasoning Chain from the Inference Engine 3 Demonstration Outline are transf"
N18-1060,Q13-1005,0,0.0513372,"identified with predefined lexicosyntactic patterns and ad-hoc rules. Reusing the patterns/rules designed for Chinese in another language is thus difficult even if it is possible. In this paper, we adopt the framework proposed by Lin et al. (2015) to solve English MWPs (for its potential in solving difficult/complex MWPs and providing more human comprehensible explanations). Additionally, we make the following improvements: (1) A new statistical model is proposed to select operands for arithmetic operations, and its model parameters can be automatically learnt via weakly supervised learning (Artzi and Zettlemoyer, 2013). (2) A new informative and robust feature-set is proposed to select the desired arithmetic operation. (3) We show the proposed approach significantly outperforms other existing systems on the common benchmark datasets reported in the literature. (4) A noisy dataset with Figure 2: The diagram of MeSys framework more irrelevant quantities in MWPs is created and released. It could be used to check if an approach really understands what a given MWP looks for. (5) An experiment is conducted to compare various approaches on this new dataset. The superior performance of our system demonstrates that"
N18-1060,D14-1058,0,0.085641,"his quantity). Statistical models are proposed to select the operator and operands. A noisy dataset is designed to assess if a solver solves MWPs mainly via understanding or mechanical pattern matching. Experimental results show that our approach outperforms existing systems on both benchmark datasets and the noisy dataset, which demonstrates that the proposed approach understands the meaning of each quantity in the text more. 1 Introduction The math word problem (MWP) (see Figure 1) is frequently chosen to study natural language understanding and simulate human problem solving (Bakman, 2007; Hosseini et al., 2014; Liang et al., 2016) for the following reasons: (1) the answer to the MWP cannot be simply extracted by performing keyword/pattern matching. It thus shows the merit of understanding and inference. Math Word Problem Mike takes 88 minutes to walk to school. If he rides a bicycle to school, it would save him 64 minutes. How much time did Mike save? Solution 88 – 64 = 22 Figure 1: An example of math word problem. (2) An MWP usually possesses less complicated syntax and requires less amount of domain knowledge, so the researchers can focus on the task of understanding and reasoning. (3) The body p"
N18-1060,O15-3002,1,0.776112,"ted via inference, it would be difficult to explain how the answer is obtained in a human comprehensible way. Therefore, the categories (2), (3) and (4a) belong to the less favored direct translation approach2 (Pape, 2004). In contrast, the approaches of (4b) can avoid the problems mentioned above. However, among them, Mitra and Baral (2016) merely handled Addition and Subtraction. Only the meaning-based framework proposed by Lin et al. (2015) can handle general MWPs via understanding and reasoning. Therefore, it is possible to explain how the answer is obtained in a human comprehensible way (Huang et al., 2015). However, although their design looks promising, only a few Chinese MWPs had been tested and performance was not evaluated. Accordingly, it is hard to make a fair comparison between their approach and other state-of-the-art methods. In addition, in their prototype system, the desired operands of arithmetic operations are identified with predefined lexicosyntactic patterns and ad-hoc rules. Reusing the patterns/rules designed for Chinese in another language is thus difficult even if it is possible. In this paper, we adopt the framework proposed by Lin et al. (2015) to solve English MWPs (for i"
N18-1060,D17-1084,0,0.538361,"-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does not check the entity-attribute consistency between each quantity and the target of the given question; and (b) With understanding (Lin et al., 2015; Mitra and Baral, 2016; Roy and Roth, 2017), which also checks the entity-attribute consistency while solving the problem. 1 It is a survey paper which reviews most of the rule-based approaches before 2008. 652 Proceedings of NAACL-HLT 2018, pages 652–662 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics However, a widely covered rule-set is difficult to construct for"
N18-1060,Q15-1042,0,0.826744,"of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does not check the entity-attribute consistency between each quantity and the target of the given question; and (b) With understanding (Lin et al., 2015; Mitra and Baral, 2016; Roy and Roth, 2017), which also checks the entity-attribute consistency while solving the problem. 1 It is a survey paper which reviews most of the rule-based approaches before 2008. 652 Proceedings of NAACL-HLT 2018, pages 652–662 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics However, a widely covered rule-set is difficu"
N18-1060,P14-1026,0,0.595033,"ning procedures thus could be more efficiently checked. (4) The MWP solver has its own applications such as Computer Math Tutor (for students in primary school) and Helper for Math in Daily Life (for adults who are not good in solving mathematics related real problems). According to the approaches used to identify entities, quantities, and to select operations and operands, previous MWP solvers can be classified into: (1) Rule-based approaches (Mukherjee and Garain, 20081; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al.,"
N18-1060,P17-1015,0,0.475697,"th in Daily Life (for adults who are not good in solving mathematics related real problems). According to the approaches used to identify entities, quantities, and to select operations and operands, previous MWP solvers can be classified into: (1) Rule-based approaches (Mukherjee and Garain, 20081; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does not check the entity-attribute consistency between each quantity and the target of the given question; and (b) With understanding (Lin et al., 2015; Mitra a"
N18-1060,P14-5010,0,0.00345625,". It could be used to check if an approach really understands what a given MWP looks for. (5) An experiment is conducted to compare various approaches on this new dataset. The superior performance of our system demonstrates that the proposed meaning-based approach has good potential in handling difficult/complex MWPs. 2 System Description The adopted meaning-based framework (Lin et al., 2015) is a pipeline with following four stages (see Figure 2): (1) Language Analysis, (2) Solution Type Identification, (3) Logic Form Transformation and (4) Logic Inference. We use the Stanford CoreNLP suite (Manning et al., 2014) as the language analysis module. The other three modules are briefly described below. Last, we adopt the weakly supervised learning (Artzi and Zettlemoyer, 2013; Kushman et al., 2014) to automatically learn the model parameters without manually annotating each MWP with the adopted solution type and selected operands benchmark. 2.1 Solution Type Identification (STI) After language analysis, each MWP is assigned with a specific solution type (such as Addition, Multiplication, etc.) which indicates the stereotype math operation pattern that should be adopted to solve this problem. We classify th"
N18-1060,P16-1202,0,0.744341,"., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does not check the entity-attribute consistency between each quantity and the target of the given question; and (b) With understanding (Lin et al., 2015; Mitra and Baral, 2016; Roy and Roth, 2017), which also checks the entity-attribute consistency while solving the problem. 1 It is a survey paper which reviews most of the rule-based approaches before 2008. 652 Proceedings of NAACL-HLT 2018, pages 652–662 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics However, a widely covered rule-set is difficult to construct for the rule-based approach. Also, it is awkward in resolving ambiguity problem. In contrast, the performance of purely statistics-based approaches deteriorates significantly when the MWP includes either irrelevant"
N18-1060,D15-1202,0,0.0908128,"sions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does not check the entity-attribute consistency between each quantity and the target of the given question; and (b) With understanding (Lin et al., 2015; Mitra and Baral, 2016; Roy and Roth, 2017), which also checks the entity-attribute consistency while solving the problem. 1 It is a survey paper which reviews most of the rule-based approaches before 2008. 652 Proceedings of NAACL-HLT 2018, pages 652–662 c New Orleans, Louisiana, June 1 - 6, 2018. 2018 Association for Computational Linguistics However, a wi"
N18-1060,N16-3011,0,0.0213897,"ise into an MWP (a). (a.1) is created by associating an irrelevant quantity to a new subject (i.e., Mary). Here the ellipse symbol “…” denotes unchanged text. (a.2) is obtained by associating an irrelevant quantity to a new entity (i.e., books). In addition, we also change modifiers (such as yellow, red, …) to add new noisy sentence (not shown here). Since the noisy dataset is not designed to assess the lexicon coverage rate of a solver, we reuse the words in the original dataset as much as possible while adding new subjects, entities and modifiers. 136 MWPs that both Illinois Math Solver 12 (Roy and Roth, 2016) and our system can correctly solve are selected from the AI2 and IL datasets. This subset is denoted as OSS (Original Sub-Set). Afterwards, based on the 136 MWPs of OSS, we create a noisy dataset of 396 MWPs by adding irrelevant quantities. This noisy dataset is named as NDS 13. Table 1 lists the size of MWPs, Perplexities (PP), and the average numbers of quantities in each MWP of these two datasets. 4 Experimental Results and Discussion We compare our approach with (Roy and Roth, 2015) and (Roy and Roth, 2017) because they achieved the state-of-the-art performance on the IL dataset. In the a"
N18-1060,Q15-1001,0,0.0677289,"ould be more efficiently checked. (4) The MWP solver has its own applications such as Computer Math Tutor (for students in primary school) and Helper for Math in Daily Life (for adults who are not good in solving mathematics related real problems). According to the approaches used to identify entities, quantities, and to select operations and operands, previous MWP solvers can be classified into: (1) Rule-based approaches (Mukherjee and Garain, 20081; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does"
N18-1060,D15-1135,0,0.143388,"m with the given sentence. Since no semantic analysis is conducted, the performance is quite limited. In more recent researches (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Roy and Roth, 2017), quantities in an MWP were associated with attributes extracted from their contexts. Based on the attributes, several statistical classifiers were used to select operands and determine operators to solve multi-step MWPs. Since the physical meaning of each quantity is not explicitly considered in getting the answer, the reasoning process cannot be explained in a human comprehensible way. Besides, Shi et al. (2015) attacked the number word problem, which only deal with numbers, with a semantic parser. Mitra and Baral (2016) mapped MWPs into three types of problems, including Part-Whole, Change and Comparison. Each problem was associated with a generic formula. They used a log-linear model to determine how to instantiate the formula with quantities and solve the only one Unknown variable. They achieved the best performance on the AI2 dataset. However, their approach cannot handle Multiplication or Division related MWPs. Recently, DNN-based approaches (Ling et al, 2017; Wang et al, 2017) have emerged. How"
N18-1060,I17-3017,0,0.0217225,"Missing"
N18-1060,D16-1029,0,0.0199809,"The MWP solver has its own applications such as Computer Math Tutor (for students in primary school) and Helper for Math in Daily Life (for adults who are not good in solving mathematics related real problems). According to the approaches used to identify entities, quantities, and to select operations and operands, previous MWP solvers can be classified into: (1) Rule-based approaches (Mukherjee and Garain, 20081; Hosseini et al., 2014), which make all related decisions based on a set of rules; (2) Purely statistics-based approaches (Kushman et al., 2014; Roy et al., 2015; Zhou et al., 2015; Upadhyay et al., 2016), in which all related decisions are done via a statistical classifier; (3) DNNbased approaches (Ling et al., 2017; Wang et al., 2017), which map the given text into the corresponding math operation/equation via a DNN; and (4) Mixed approaches, which identify entities and quantities with rules, yet, decide operands and operations via statistical/DNN classifiers. This category can be further divided into two subtypes: (a) Without understanding (Roy and Roth, 2015; Koncel-Kedziorski et al., 2015; Huang et al., 2017; Shrivastava et al., 2017), which does not check the entity-attribute consistency"
N18-1060,D17-1088,0,0.752061,"Missing"
N18-1060,D15-1096,0,0.144033,"Missing"
O15-1006,D14-1058,0,0.0383711,"Missing"
O15-1006,P14-1026,0,0.0420504,"Missing"
O15-1006,Q13-1005,0,0.0382782,"Missing"
O15-1006,strassel-etal-2010-darpa,0,\N,Missing
O15-1006,Q15-1001,0,\N,Missing
O15-1006,D09-1082,0,\N,Missing
O15-1006,A83-1031,0,\N,Missing
O15-1006,D09-1122,0,\N,Missing
O15-1006,D08-1097,0,\N,Missing
O15-1006,W02-1811,0,\N,Missing
O15-1006,C02-1049,1,\N,Missing
O15-1006,O07-4005,0,\N,Missing
O15-1006,W14-2401,0,\N,Missing
O15-1006,J14-1002,0,\N,Missing
O15-1006,P01-1052,0,\N,Missing
O15-1006,J80-2001,0,\N,Missing
O15-1006,O04-2005,0,\N,Missing
O15-1006,D14-1100,0,\N,Missing
O15-1006,D13-1160,0,\N,Missing
O15-1006,O14-3003,0,\N,Missing
O15-1006,O15-3002,1,\N,Missing
O15-1006,O15-1007,1,\N,Missing
O15-1006,I05-7001,0,\N,Missing
O15-1007,strassel-etal-2010-darpa,0,0.406118,"Missing"
O15-1007,W98-1435,0,0.273025,"Missing"
O15-1007,W98-1426,0,\N,Missing
O15-1007,O15-1006,1,\N,Missing
O15-1007,O15-3001,1,\N,Missing
O15-3001,Q13-1005,0,0.0366724,"Missing"
O15-3001,J80-2001,0,0.282248,"Missing"
O15-3001,I05-7001,0,0.0671535,"Missing"
O15-3001,C02-1049,1,0.531032,"Missing"
O15-3001,J14-1002,0,0.0592436,"Missing"
O15-3001,D09-1122,0,0.0349179,"Missing"
O15-3001,D14-1058,0,0.0703962,"Missing"
O15-3001,D14-1100,0,0.0359364,"Missing"
O15-3001,O07-4005,0,0.0225363,"Missing"
O15-3001,O15-3002,1,0.871096,"Missing"
O15-3001,P14-1026,0,0.0768712,"Missing"
O15-3001,W03-1726,1,0.635445,"Missing"
O15-3001,P01-1052,0,0.14657,"Missing"
O15-3001,strassel-etal-2010-darpa,0,0.425543,"Missing"
O15-3001,O04-2005,0,0.102625,"Missing"
O15-3001,W02-1811,0,0.0479075,"Missing"
O15-3001,D09-1082,0,0.0271275,"Missing"
O15-3001,Q15-1001,0,\N,Missing
O15-3001,A83-1031,0,\N,Missing
O15-3001,D08-1097,0,\N,Missing
O15-3001,W14-2401,0,\N,Missing
O15-3001,D13-1160,0,\N,Missing
O15-3001,O14-3003,0,\N,Missing
O15-3001,O15-1007,1,\N,Missing
O15-3002,W98-1426,0,0.293173,"Missing"
O15-3002,strassel-etal-2010-darpa,0,0.407081,"Missing"
O15-3002,O15-1006,1,\N,Missing
O15-3002,O15-3001,1,\N,Missing
O16-1031,D14-1058,0,0.0450783,"Missing"
O16-1031,O15-3001,1,0.892213,"Missing"
O16-1031,N16-3014,1,0.881816,"Missing"
O16-1031,P14-1026,0,0.0651902,"Missing"
O16-1031,Q15-1001,0,0.0271679,"Missing"
O16-1031,D15-1202,0,0.0211141,"Missing"
O16-1031,2007.mtsummit-papers.71,0,0.152827,"Missing"
O16-1031,J05-1004,0,0.0759298,"Missing"
O16-1031,J07-3004,0,0.123106,"Missing"
O16-1031,W07-1522,0,0.0869205,"Missing"
O16-1031,D07-1078,0,0.025265,"Missing"
O16-1031,N10-1016,0,0.0233187,"Missing"
O16-1031,burchardt-etal-2006-salsa,0,0.110692,"Missing"
O16-1031,basile-etal-2012-developing,0,0.0541651,"Missing"
O16-1031,mille-wanner-2010-syntactic,0,0.0530564,"Missing"
O16-1031,D15-1135,0,0.0352356,"Missing"
O16-1031,Q15-1042,0,0.0229697,"Missing"
O16-1031,W00-1205,0,0.244554,"Missing"
O16-1031,I05-7001,0,0.0691437,"Missing"
O16-1031,O14-3003,1,0.845921,"Missing"
O16-1031,O09-3002,0,0.105151,"Missing"
O16-1031,N16-1136,0,0.0215744,"Missing"
O16-1031,P16-1084,0,0.0251462,"Missing"
O90-1004,J83-3004,0,\N,Missing
O90-1004,J82-3004,0,\N,Missing
O90-1004,C88-2133,1,\N,Missing
O90-1004,P85-1037,0,\N,Missing
O90-1004,W89-0210,1,\N,Missing
O92-1003,C92-1055,1,\N,Missing
O96-2004,J90-2002,0,0.165173,"Missing"
O96-2004,P91-1022,0,0.0578868,"Missing"
O96-2004,P91-1034,0,0.309966,"Missing"
O96-2004,J92-4003,0,0.04021,"Missing"
O96-2004,J93-2003,0,0.0108973,"Missing"
O96-2004,P92-1023,1,0.878151,"Missing"
O96-2004,1993.tmi-1.1,1,0.836015,"Missing"
O96-2004,O93-1001,0,0.033738,"Missing"
O96-2004,1991.mtsummit-papers.5,1,0.837657,"Missing"
O96-2004,C92-1019,0,0.0375107,"Missing"
O96-2004,1995.tmi-1.21,0,0.0372442,"Missing"
O96-2004,C92-1055,1,0.908756,"Missing"
O96-2004,W96-0110,1,0.772453,"Missing"
O96-2004,A88-1019,0,0.0364854,"Missing"
O96-2004,P89-1010,0,0.0953846,"Missing"
O96-2004,J88-1003,0,0.106962,"Missing"
O96-2004,P91-1017,0,0.0549019,"Missing"
O96-2004,W93-0301,0,0.024465,"Missing"
O96-2004,P91-1023,0,0.10041,"Missing"
O96-2004,H91-1026,0,0.0712648,"Missing"
O96-2004,1992.tmi-1.9,0,0.0240794,"Missing"
O96-2004,W95-0104,0,0.171046,"Missing"
O96-2004,P96-1010,0,0.0350819,"Missing"
O96-2004,O95-1003,1,0.880135,"Missing"
O96-2004,C86-1155,0,0.0572587,"Missing"
O96-2004,P93-1003,0,0.0311541,"Missing"
O96-2004,O90-1004,1,0.886783,"Missing"
O96-2004,1995.mtsummit-1.1,0,0.0661145,"Missing"
O96-2004,P91-1036,0,0.046454,"Missing"
O96-2004,J96-1001,0,0.0671118,"Missing"
O96-2004,C88-2133,1,0.857523,"Missing"
O96-2004,W89-0210,1,0.772508,"Missing"
O96-2004,O89-1010,1,0.789011,"Missing"
O96-2004,O91-1009,1,0.877556,"Missing"
O96-2004,P94-1033,1,0.911183,"Missing"
O96-2004,1995.tmi-1.27,1,0.922468,"Missing"
O96-2004,P94-1012,0,0.0746985,"Missing"
O96-2004,1995.tmi-1.28,0,0.0789894,"Missing"
O96-2004,P95-1026,0,0.0265523,"Missing"
O96-2004,J93-1004,0,\N,Missing
O96-2004,J90-1003,0,\N,Missing
O96-2004,C92-2070,0,\N,Missing
O96-2004,A94-1006,0,\N,Missing
O96-2004,C92-2067,1,\N,Missing
O96-2004,J93-1002,0,\N,Missing
O96-2004,P94-1013,0,\N,Missing
O96-2004,O93-1006,1,\N,Missing
O96-2004,O93-1004,1,\N,Missing
O96-2004,O92-1003,1,\N,Missing
O96-2004,J95-3002,1,\N,Missing
O96-2004,O92-1001,1,\N,Missing
O97-1009,O97-4005,1,\N,Missing
O97-1009,O93-1009,1,\N,Missing
O97-1009,J96-1001,0,\N,Missing
O97-1009,J90-1003,0,\N,Missing
O97-1009,O92-1001,1,\N,Missing
O97-1009,J93-1007,0,\N,Missing
O97-1009,C90-3010,0,\N,Missing
O97-1009,P94-1033,1,\N,Missing
O97-1009,O91-1009,1,\N,Missing
O97-1009,O88-1003,1,\N,Missing
O97-1009,W95-0109,1,\N,Missing
O97-3001,J96-1001,0,\N,Missing
O97-3001,C96-2184,0,\N,Missing
O97-3001,1995.tmi-1.28,0,\N,Missing
O97-3001,J90-2002,0,\N,Missing
O97-3001,P91-1022,0,\N,Missing
O97-3001,J92-4003,0,\N,Missing
O97-3001,P91-1034,0,\N,Missing
O97-3001,P91-1023,0,\N,Missing
O97-3001,H91-1026,0,\N,Missing
O97-3001,P89-1010,0,\N,Missing
O97-3001,P94-1033,1,\N,Missing
O97-3001,P94-1012,0,\N,Missing
O97-3001,O93-1006,1,\N,Missing
O97-3001,O91-1009,1,\N,Missing
O97-3001,Y96-1018,0,\N,Missing
O97-3001,O96-2004,1,\N,Missing
O97-4005,O93-1009,1,\N,Missing
O97-4005,J96-1001,0,\N,Missing
O97-4005,J96-3004,0,\N,Missing
O97-4005,J90-1003,0,\N,Missing
O97-4005,J93-1007,0,\N,Missing
O97-4005,P94-1033,1,\N,Missing
O97-4005,O93-1004,1,\N,Missing
O97-4005,W95-0109,1,\N,Missing
O97-4005,O92-1003,1,\N,Missing
O97-4005,O97-1009,1,\N,Missing
O99-3002,J81-2002,0,\N,Missing
O99-3002,E95-1031,0,\N,Missing
O99-3002,J83-3002,0,\N,Missing
O99-3002,A92-1027,0,\N,Missing
O99-3002,A92-1026,0,\N,Missing
O99-3002,C94-2149,0,\N,Missing
O99-3002,J87-1004,0,\N,Missing
O99-3002,J93-1002,0,\N,Missing
O99-3002,P89-1013,0,\N,Missing
O99-3002,P95-1037,0,\N,Missing
O99-3002,J95-3002,1,\N,Missing
P10-1065,P02-1051,0,0.161199,"tion In trans-lingual language processing tasks, such as machine translation and cross-lingual information retrieval, named entity (NE) translation is essential. Bilingual NE alignment, which links source NEs and target NEs, is the first step to train the NE translation model. Since NE alignment can only be conducted after its associated NEs have first been identified, the including-rate of the first recognition stage significantly limits the final alignment performance. To alleviate the above error accumulation problem, two strategies have been proposed in the literature. The first strategy (Al-Onaizan and Knight, 2002; Moore, 2003; Feng et al., 2004; Lee et al., 2006) identifies NEs only on the source side and then finds their corresponding NEs on the target side. In this way, it avoids the NE recognition errors which would otherwise be Keh-Yih Su Behavior Design Corporation Hsinchu, Taiwan, R.O.C. bdc.kysu@gmail.com brought into the alignment stage from the target side; however, the NE errors from the source side still remain. To further reduce the errors from the source side, the second strategy (Huang et al., 2003) expands the NE candidate-sets in both languages before conducting the alignment, which is"
P10-1065,zhang-etal-2004-interpreting,0,0.0439186,"Missing"
P10-1065,J96-1002,0,0.013354,"ttp://www.speech.sri.com/projects/srilm/ as the main data at Table 2. The second one (named type-sensitive) would also evaluate the associated NE type of each NE, and is given within parentheses in Table 2. A large degradation is observed when NE type is also taken into account. The highlighted entries are those that are statistically better 6 than that of the baseline system. 4.3 ME Approach with Primitive Features Although the proposed model has been derived above in a principled way, since all these proposed features can also be directly integrated with the well-known maximum entropy (ME) (Berger et al., 1996) framework without making any assumptions, one might wonder if it is still worth to deriving a model after all the related features have been proposed. To show that not only the features but also the adopted model contribute to the performance improvement, an ME approach is tested as follows for comparison. It directly adopts all those primitive features mentioned above as its inputs (including internal component mapping, initial and final NE type, NE bigram-based string, and left/right distance), without involving any related probability factors derived within the proposed model. This ME meth"
P10-1065,W03-1501,0,0.28829,"Missing"
P10-1065,W04-3248,0,0.0708686,"tasks, such as machine translation and cross-lingual information retrieval, named entity (NE) translation is essential. Bilingual NE alignment, which links source NEs and target NEs, is the first step to train the NE translation model. Since NE alignment can only be conducted after its associated NEs have first been identified, the including-rate of the first recognition stage significantly limits the final alignment performance. To alleviate the above error accumulation problem, two strategies have been proposed in the literature. The first strategy (Al-Onaizan and Knight, 2002; Moore, 2003; Feng et al., 2004; Lee et al., 2006) identifies NEs only on the source side and then finds their corresponding NEs on the target side. In this way, it avoids the NE recognition errors which would otherwise be Keh-Yih Su Behavior Design Corporation Hsinchu, Taiwan, R.O.C. bdc.kysu@gmail.com brought into the alignment stage from the target side; however, the NE errors from the source side still remain. To further reduce the errors from the source side, the second strategy (Huang et al., 2003) expands the NE candidate-sets in both languages before conducting the alignment, which is done by treating the original r"
P10-1065,W03-1502,0,0.0592741,"o, and P  RCNE |CNE , CType, CS , RType  are Monolingual Candidate Certainty Factors (Section 3.2) used to assign preference to each selected RCNE and RENE , based on the initially recognized NEs (which act as anchors). transliteration NTL n2 1   CNE, CType , CS,  P  MIC , RType, RCNE, RENE  [ENE, EType], ES    P  MIC RType, RCNE, RENE   P  RCNE |CNE, CType, CS, RType NTL (3) In the above equation, the mappings between internal components are trained from the syllable/word alignment of NE pairs of different NE types. In more detail ， for transliteration, the model adopted in (Huang et al., 2003), which first Romanizes Chinese characters and then transliterates them into English characters, is 633 tributions. The corresponding weighting coefficients are obtained using the well-known Minimum Error Rate Training (Och, 2003; commonly abbreviated as MERT) algorithm by minimizing the number of associated errors in the development set. used for P(cpn n  |TLn , ew[ n ] , RType) . For translation, conditional probability is directly used for P (cpn n  |TS n , ew[ n ] , RType) . Lastly, the bilingual type re-assignment factor P  RType |CNE , ENE , CType, EType  proposed in Eq (2) is deri"
P10-1065,P06-2055,0,0.0901131,"Missing"
P10-1065,E03-1035,0,\N,Missing
P10-1065,P03-1021,0,\N,Missing
P13-1002,W09-0437,0,0.0323477,"Missing"
P13-1002,P11-1124,0,0.702859,"Missing"
P13-1002,P10-1064,0,0.595665,"Missing"
P13-1002,2011.mtsummit-papers.52,0,0.597744,"Missing"
P13-1002,P03-1021,0,0.0314314,"Missing"
P13-1002,J03-1002,0,0.00987415,"Missing"
P13-1002,W04-3250,0,0.22636,"Missing"
P13-1002,P02-1040,0,0.0859264,"Missing"
P13-1002,J82-2005,0,0.795373,"Missing"
P13-1002,N03-1017,0,0.162764,"er to the corresponding TM information associated with each phrase at SMT decoding. On a Chinese–English TM database, our experiments show that the proposed integrated Model-III is significantly better than either the SMT or the TM systems when the fuzzy match score is above 0.4. Furthermore, integrated Model-III achieves overall 3.48 BLEU points improvement and 2.62 TER points reduction in comparison with the pure SMT system. Besides, the proposed models also outperform previous approaches significantly. 1 Introduction Statistical machine translation (SMT), especially the phrase-based model (Koehn et al., 2003), has developed very fast in the last decade. For certain language pairs and special applications, SMT output has reached an acceptable level, especially in the domains where abundant parallel corpora are available (He et al., 2010). However, SMT is rarely applied to professional translation because its output quality is still far from satisfactory. Especially, there is no guarantee that a SMT system can produce translations in a consistent manner (Ma et al., 2011). In contrast, translation memory (TM), which uses the most similar translation sentence (usually above a certain fuzzy match thres"
P13-1002,2009.mtsummit-papers.14,0,0.497295,"is4 associated5”, and “an1 object2 that3 is4 associated5 with6”, etc. And it is hard to tell which one should be adopted in the merging stage. Thirdly, the pipeline approach does not utilize the SMT probabilistic information in deciding whether a matched TM phrase should be adopted or not, and which target phrase should be selected when we have multiple candidates. Therefore, the possible improvements resulted from those pipeline approaches are quite limited. On the other hand, instead of directly merging TM matched phrases into the source sentence, some approaches (Biçici and Dymetman, 2008; Simard and Isabelle, 2009) simply add the longest matched pairs into SMT phrase table, and then associate them with a fixed large probability value to favor the corresponding TM target phrase at SMT decoding. However, since only one aligned target phrase will be added for each matched source phrase, they share most drawbacks with the pipeline approaches mentioned above and merely achieve similar performance. To avoid the drawbacks of the pipeline approach (mainly due to making a hard decision before decoding), we propose several integrated models to completely make use of TM information during decoding. For each TM sou"
P13-1002,2010.jec-1.4,0,0.375723,"is very repetitive. In general, for those matched segments1, TM provides more reliable results than SMT does. One reason is that the results of TM have been revised by human according to the global context, but SMT only utilizes local context. However, for those unmatched segments, SMT is more reliable. Since TM and SMT complement each other in those matched and unmatched segments, the output quality is expected to be raised significantly if they can be combined to supplement each other. In recent years, some previous works have incorporated TM matched segments into SMT in a pipelined manner (Koehn and Senellart, 2010; Zhechev and van Genabith, 2010; He et al., 2011; Ma et al., 2011). All these pipeline approaches translate the sentence in two stages. They first determine whether the extracted TM sentence pair should be adopted or not. Most of them use fuzzy match score as the threshold, but He et al. (2011) and Ma et al. (2011) use a classifier to make the judgment. Afterwards, they merge the relevant translations of matched segments into the source sentence, and then force the SMT system to only translate those unmatched segments at decoding. There are three obvious drawbacks for the above pipeline appro"
P13-1002,2006.amta-papers.25,0,0.113287,"Missing"
P13-1002,W10-3806,0,0.576925,"Missing"
P13-1002,C08-1144,0,0.0494857,"Missing"
P13-1002,D10-1091,0,\N,Missing
P13-1002,P07-2045,0,\N,Missing
P92-1023,1991.mtsummit-papers.5,1,0.662722,"Missing"
P92-1023,C92-1055,1,0.845801,"Missing"
P92-1023,P89-1010,0,0.0460634,"Missing"
P92-1023,J88-1003,0,0.103846,"Missing"
P92-1023,C88-2133,1,0.473437,"Missing"
P92-1023,W89-0210,1,0.718786,"Missing"
P92-1023,W89-0209,0,0.0729408,"Missing"
P92-1023,O90-1004,1,0.830235,"Missing"
P92-1023,J83-3004,0,0.0897881,"Missing"
P92-1023,J90-1003,0,\N,Missing
P92-1023,A88-1019,0,\N,Missing
P92-1023,J90-2002,0,\N,Missing
P94-1033,C90-3010,0,0.0803364,"Missing"
P94-1033,O88-1003,1,0.898595,"Missing"
P94-1033,J90-1003,0,0.235669,"Missing"
P94-1033,O92-1001,1,0.790122,"Missing"
P94-1033,O91-1009,1,0.6179,"Missing"
P94-1033,O93-1009,1,0.601924,"Missing"
P94-1033,C92-3150,0,\N,Missing
P94-1034,1993.tmi-1.1,1,0.778544,"Missing"
P94-1034,1991.mtsummit-papers.5,1,0.75975,"Missing"
P94-1034,1993.tmi-1.17,0,0.0226445,"Missing"
P94-1034,J93-2004,0,0.0292908,"Missing"
W10-4133,P08-1102,0,0.037602,"in performance, we use an additional semi-supervised learning procedure to incorporate the unlabeled corpus. The final performance on the closed track for the simplified-character text shows that our system achieves comparable results with other state-of-the-art systems. 1 Introduction The character-based tagging approach (Xue, 2003) has become the dominant technique for Chinese word segmentation (CWS) as it can tolerate out-of-vocabulary (OOV) words. In the last few years, this method has been widely adopted and further improved in many previous works (Tseng et al., 2005; Zhang et al., 2006; Jiang et al., 2008). Among various character-based tagging approaches, the character-based joint model (Wang et al., 2010) achieves a good balance between in-vocabulary (IV) words recognition and OOV words identification. In this work, we adopt the character-based joint model as our basic system, which combines a character-based discriminative model and a character-based generative model. The generative module holds a robust performance on IV words, while the discriminative module can handle the extra features easily and enhance the OOV words segmentation. However, the performance of out-of-domain text is still"
W10-4133,I05-3027,0,0.092844,"model. To further improve the crossdomain performance, we use an additional semi-supervised learning procedure to incorporate the unlabeled corpus. The final performance on the closed track for the simplified-character text shows that our system achieves comparable results with other state-of-the-art systems. 1 Introduction The character-based tagging approach (Xue, 2003) has become the dominant technique for Chinese word segmentation (CWS) as it can tolerate out-of-vocabulary (OOV) words. In the last few years, this method has been widely adopted and further improved in many previous works (Tseng et al., 2005; Zhang et al., 2006; Jiang et al., 2008). Among various character-based tagging approaches, the character-based joint model (Wang et al., 2010) achieves a good balance between in-vocabulary (IV) words recognition and OOV words identification. In this work, we adopt the character-based joint model as our basic system, which combines a character-based discriminative model and a character-based generative model. The generative module holds a robust performance on IV words, while the discriminative module can handle the extra features easily and enhance the OOV words segmentation. However, the pe"
W10-4133,Y09-2047,1,0.808331,"here tk is a member of {Begin, Middle, End, Single} (abbreviated as B, M, E and S from now on) to indicate the corresponding position of character ck in its associated word. For example, the word “ 北京市 (Beijing City)” will be assigned with the corresponding tags as: “ 北 /B (North) 京/M (Capital) 市/E (City)”. This discriminative module can flexibly incorporate extra features and it is implemented with the ME package 1 given by Zhang Le. All training experiments are done with Gaussian prior 1.0 and 200 iterations. The character-based generative module is a character-tag-pair-based trigram model (Wang et al., 2009) and can be expressed as below: n P ([c, t ]1n ) ≈ ∏ P([c, t ]i [c, t ]ii −−12 ). (2) i =1 In our experiments, SRI Language Modeling Toolkit 2 (Stolcke, 2002) is used to train the generative trigram model with modified Kneser-Ney smoothing (Chen and Goodman, 1998). The character-based joint model combines the above discriminative module and the generative module with log-linear interpolation as follows: Score(tk ) = α × log( P ([c, t ]k [c, t ]kk −−12 )) + (1 − α ) × log( P(tk tk −1 , ckk−+22 )) (3) Where the parameter α (0.0 ≤ α ≤ 1.0) is the weight for the generative model. Score(tk) will be"
W10-4133,C10-1132,1,0.778035,"Missing"
W10-4133,O03-4002,0,0.533507,"se Word Segmentation system for the closed track of CIPS-SIGHAN Word Segmentation Bakeoff 2010. This system adopts a character-based joint approach, which combines a character-based generative model and a character-based discriminative model. To further improve the crossdomain performance, we use an additional semi-supervised learning procedure to incorporate the unlabeled corpus. The final performance on the closed track for the simplified-character text shows that our system achieves comparable results with other state-of-the-art systems. 1 Introduction The character-based tagging approach (Xue, 2003) has become the dominant technique for Chinese word segmentation (CWS) as it can tolerate out-of-vocabulary (OOV) words. In the last few years, this method has been widely adopted and further improved in many previous works (Tseng et al., 2005; Zhang et al., 2006; Jiang et al., 2008). Among various character-based tagging approaches, the character-based joint model (Wang et al., 2010) achieves a good balance between in-vocabulary (IV) words recognition and OOV words identification. In this work, we adopt the character-based joint model as our basic system, which combines a character-based disc"
W10-4133,P06-2123,0,\N,Missing
W89-0210,J85-2002,0,0.0444794,"Missing"
W89-0210,C88-2133,1,0.796217,"Missing"
W89-0210,J83-1005,0,0.239789,"Missing"
W95-0109,O91-1004,0,0.0364039,"Missing"
W95-0109,W93-0305,0,0.039408,"Missing"
W95-0109,O92-1003,1,0.855666,"Missing"
W95-0109,A88-1019,0,0.0631748,"Missing"
W95-0109,J90-1003,0,0.0886567,"Missing"
W95-0109,O92-1001,1,0.902238,"Missing"
W95-0109,P94-1033,1,0.910482,"Missing"
W95-0109,O93-1009,1,0.803702,"Missing"
W96-0110,J81-1001,0,0.496881,"y natural language processing tasks, e.g., machine translation, systems usually require to apply several kinds of knowledge to analyze input sentence and represent the analyzed results in terms of a deep structure which identify the thematic roles (cases) of constituents and the senses of words. However, ambiguity and uncertainty exist at the different levels of analysis. To resolve the ambiguity and uncertainty, the related knowledge sources should be properly represented and integrated. Conventional approaches to case identification usually need a lot of human efforts to encode ad hoc rules [1,2,3]. Such a rule-based system is, in general, very expensive to construct and difficult to maintain. In contrast, a statistics-oriented corpus-based approach achieves disambiguation by using a parameterized model, in which the parameters are estimated and tuned from a training corpus. In such a way, the system can be easily scaled up and well trained based on the well-established theories. However, statistical approaches reported in the literature [4,5,6,7] usually use only surface level information, e.g., collocations and word associations, without taking structure information, such as syntax an"
W96-0110,P91-1017,0,0.398958,"properly represented and integrated. Conventional approaches to case identification usually need a lot of human efforts to encode ad hoc rules [1,2,3]. Such a rule-based system is, in general, very expensive to construct and difficult to maintain. In contrast, a statistics-oriented corpus-based approach achieves disambiguation by using a parameterized model, in which the parameters are estimated and tuned from a training corpus. In such a way, the system can be easily scaled up and well trained based on the well-established theories. However, statistical approaches reported in the literature [4,5,6,7] usually use only surface level information, e.g., collocations and word associations, without taking structure information, such as syntax and thematic role, into consideration. In general, the structure features that 113 characterize long-distance dependency, can provide more relevant correlation information between words. Therefore, word association information can be trained and applied more effectively by considering the structural features. In many tasks, such as natural language understanding and machine translation, deep-structure information other than word sense is often required. Ne"
W96-0110,1992.tmi-1.9,0,0.408785,"properly represented and integrated. Conventional approaches to case identification usually need a lot of human efforts to encode ad hoc rules [1,2,3]. Such a rule-based system is, in general, very expensive to construct and difficult to maintain. In contrast, a statistics-oriented corpus-based approach achieves disambiguation by using a parameterized model, in which the parameters are estimated and tuned from a training corpus. In such a way, the system can be easily scaled up and well trained based on the well-established theories. However, statistical approaches reported in the literature [4,5,6,7] usually use only surface level information, e.g., collocations and word associations, without taking structure information, such as syntax and thematic role, into consideration. In general, the structure features that 113 characterize long-distance dependency, can provide more relevant correlation information between words. Therefore, word association information can be trained and applied more effectively by considering the structural features. In many tasks, such as natural language understanding and machine translation, deep-structure information other than word sense is often required. Ne"
W96-0110,C92-2070,0,0.520009,"properly represented and integrated. Conventional approaches to case identification usually need a lot of human efforts to encode ad hoc rules [1,2,3]. Such a rule-based system is, in general, very expensive to construct and difficult to maintain. In contrast, a statistics-oriented corpus-based approach achieves disambiguation by using a parameterized model, in which the parameters are estimated and tuned from a training corpus. In such a way, the system can be easily scaled up and well trained based on the well-established theories. However, statistical approaches reported in the literature [4,5,6,7] usually use only surface level information, e.g., collocations and word associations, without taking structure information, such as syntax and thematic role, into consideration. In general, the structure features that 113 characterize long-distance dependency, can provide more relevant correlation information between words. Therefore, word association information can be trained and applied more effectively by considering the structural features. In many tasks, such as natural language understanding and machine translation, deep-structure information other than word sense is often required. Ne"
W96-0110,C92-1055,1,0.720959,"Missing"
W96-0110,J95-3002,1,0.617083,"Missing"
W96-0110,1991.mtsummit-papers.5,0,0.620898,"h is specified by the case subtrees v-i,i simplified model, called case dependent (CD) model, is implemented in this paper. In the casedependent model, the sense of a word is assumed to depend on its case role, part-of-speech and the (co) word itself. Thus, the word sense score in this model, denoted by Sse,,e , is approximated as follows: S sense (C°)(S,,i,nI ) = f l P(Si,mlCi,m &apos; t k,m ,Win)&quot; ra=l 3. The Baseline System 3.1 Experimental Setup A. Corpora: 3,000 sentences in English, extracted from computer manuals and related documents, are collected and are parsed by the BehaviorTran system [10], which is a commercialized Englishto-Chinese machine translation system developed by Behavior Design Corporation (BDC). The correct part-of-speech, parse trees and normal forms for the collected sentences are verified by linguistic experts. The corpus is then randomly partitioned into the training set of 2,200 sentences and the testing set of the remaining 8,00 sentences to eliminate possible systematic biases. The average number of words per sentence for the training set and the testing set are 13.9 and 13.8, respectively. On the average, there are 34.2 alternative parse trees per sentence f"
W96-0110,W96-0110,1,0.0530913,"ese Dictionary of Contemporary English. For those words which are not included in the Longman dictionary, their sense are defined according to the system dictionary of the BehaviorTran system. In total, there are 12,627 distinct senses for those 4,522 words. C. Phrase Structure Rules: The grammar is composed of 1,088 phrase structure rules, expressed in terms of 35 terminal symbols (parts of speech) and 95 nonterminal symbols. D. Case Set: In the current system, the case set includes a total number of 50 cases, which are designed for the next generation BehaviorTran MT system. Please refer to [11] for the details of the case set. To evaluate the performance of the proposed case identification models, the recall rate and the precision rate of case assignment, defined in the following equations, are used. 121 recall ~- No of matched case trees specified by the model Total no of case trees specified by the linguistic experts precision ~- No of matched case treesspecified by the model Total no of case trees specified by the model where a case tree specified by the model is said to match with the correct one if the corresponding cases of the case tree are fully identical to those of the cor"
Y09-2047,I05-3017,0,0.182258,"apability to handle OOV words, because it also regards the character as a unit. Also, since the generative form is adopted, the dependency between adjacent characters is now directly (and separately) modeled for each class (within-words and between-words), which will give sharper preference when the history of assignment is given. In contrast, the adhesion between adjacent characters is not explicitly modeled in the character-based discriminative approach, and is thus not used to assign tags. 3 Experiments and Results We carried out our experiments on the data provided by SIGHAN Bakeoff 2005 (Emerson, 2005). To make a comparison with the baseline and previous work, only the closed tests3 are F 3 F According to Sighan Bakeoff 2005 regulation, the closed test could only use the training data directly provided. Any other data or information is forbidden, including the knowledge of characters set, punctuation and so on. 830 conducted. The metrics Precision (P), Recall (R), F-measure (F), Recall of OOV (ROOV) and Recall of IV (RIV) are used to evaluate the segmentation results. The balanced F-measure is F=2PR/(P+R). 3.1 Word-Based Generative Model and Character-Based Discriminative Model We first ext"
Y09-2047,P03-1035,0,0.193082,"is the first task, which aims to find the corresponding word sequence from the given Chinese character sequence. Among various approaches for CWS, statistical methods have been increasingly applied in the past two decades. According to the basic unit adopted to extract features, statistical approaches could be classified as either a word-based approach or a character-based approach. Besides, the word segmentation problem could also be formulated as either a generative model or a discriminative model. In terms of the above classification, the time-honored word-based model (Zhang et al., 2003; Gao et al., 2003) will be called as the word-based generative approach, while the wellknown character-based tagging model (Xue, 2003; Ng and Low, 2004; Tseng et al., 2005) will be named as the character-based discriminative approach. Also, the word “model” will be loosely exchanged with the word “approach” when there is no confusion. ∗ The research work has been partially funded by the Natural Science Foundation of China under grant No.60736014, 60723005 and 90820303, the National Key Technology R&D Program under grant No. 2006BAH03B02, the Hi-Tech Research and Development Program (863 Program) of China under"
Y09-2047,W04-3236,0,0.0756136,"ches for CWS, statistical methods have been increasingly applied in the past two decades. According to the basic unit adopted to extract features, statistical approaches could be classified as either a word-based approach or a character-based approach. Besides, the word segmentation problem could also be formulated as either a generative model or a discriminative model. In terms of the above classification, the time-honored word-based model (Zhang et al., 2003; Gao et al., 2003) will be called as the word-based generative approach, while the wellknown character-based tagging model (Xue, 2003; Ng and Low, 2004; Tseng et al., 2005) will be named as the character-based discriminative approach. Also, the word “model” will be loosely exchanged with the word “approach” when there is no confusion. ∗ The research work has been partially funded by the Natural Science Foundation of China under grant No.60736014, 60723005 and 90820303, the National Key Technology R&D Program under grant No. 2006BAH03B02, the Hi-Tech Research and Development Program (863 Program) of China under grant No. 2006AA010108-4, and also supported by the China-Singapore Institute of Digital Media as well. The authors thank Behavior De"
Y09-2047,C04-1081,0,0.371661,"Missing"
Y09-2047,P98-2206,0,0.0843937,"Missing"
Y09-2047,I05-3027,0,0.656992,"istical methods have been increasingly applied in the past two decades. According to the basic unit adopted to extract features, statistical approaches could be classified as either a word-based approach or a character-based approach. Besides, the word segmentation problem could also be formulated as either a generative model or a discriminative model. In terms of the above classification, the time-honored word-based model (Zhang et al., 2003; Gao et al., 2003) will be called as the word-based generative approach, while the wellknown character-based tagging model (Xue, 2003; Ng and Low, 2004; Tseng et al., 2005) will be named as the character-based discriminative approach. Also, the word “model” will be loosely exchanged with the word “approach” when there is no confusion. ∗ The research work has been partially funded by the Natural Science Foundation of China under grant No.60736014, 60723005 and 90820303, the National Key Technology R&D Program under grant No. 2006BAH03B02, the Hi-Tech Research and Development Program (863 Program) of China under grant No. 2006AA010108-4, and also supported by the China-Singapore Institute of Digital Media as well. The authors thank Behavior Design Corporation for"
Y09-2047,O03-4002,0,0.931721,"ious approaches for CWS, statistical methods have been increasingly applied in the past two decades. According to the basic unit adopted to extract features, statistical approaches could be classified as either a word-based approach or a character-based approach. Besides, the word segmentation problem could also be formulated as either a generative model or a discriminative model. In terms of the above classification, the time-honored word-based model (Zhang et al., 2003; Gao et al., 2003) will be called as the word-based generative approach, while the wellknown character-based tagging model (Xue, 2003; Ng and Low, 2004; Tseng et al., 2005) will be named as the character-based discriminative approach. Also, the word “model” will be loosely exchanged with the word “approach” when there is no confusion. ∗ The research work has been partially funded by the Natural Science Foundation of China under grant No.60736014, 60723005 and 90820303, the National Key Technology R&D Program under grant No. 2006BAH03B02, the Hi-Tech Research and Development Program (863 Program) of China under grant No. 2006AA010108-4, and also supported by the China-Singapore Institute of Digital Media as well. The authors"
Y09-2047,W03-1730,0,0.307963,"d segmentation (CWS) is the first task, which aims to find the corresponding word sequence from the given Chinese character sequence. Among various approaches for CWS, statistical methods have been increasingly applied in the past two decades. According to the basic unit adopted to extract features, statistical approaches could be classified as either a word-based approach or a character-based approach. Besides, the word segmentation problem could also be formulated as either a generative model or a discriminative model. In terms of the above classification, the time-honored word-based model (Zhang et al., 2003; Gao et al., 2003) will be called as the word-based generative approach, while the wellknown character-based tagging model (Xue, 2003; Ng and Low, 2004; Tseng et al., 2005) will be named as the character-based discriminative approach. Also, the word “model” will be loosely exchanged with the word “approach” when there is no confusion. ∗ The research work has been partially funded by the Natural Science Foundation of China under grant No.60736014, 60723005 and 90820303, the National Key Technology R&D Program under grant No. 2006BAH03B02, the Hi-Tech Research and Development Program (863 Progr"
Y09-2047,P07-1106,0,0.122583,"rst identify the OOV candidates and then integrate them into the system. Their system achieves the best result in the AS corpus in Sighan Bakeoff 2005 contest. Tseng et al. (2005) add the information of word-prefixes and word-suffixes to overcome the drawbacks of character-based approaches, and they get the best results in the remaining three corpora in that contest. Afterwards, Zhang et al. (2006) use a sub-word tagging approach to utilize the sub-word information. All of them adopt the character-based discriminative approaches. The only state-of-the-art word-based model proposed recently is Zhang and Clark (2007), which uses Perceptron, a discriminative method. The comparison between those models mentioned above is given in Table 4. It shows that the proposed model achieves a good balance between those IV words and OOV words, and also competitive results. Table 4: Segmentation results of different Models AS Asahara Zhang (CRF) Our model Zhang & Clark MSR Tseng Zhang (CRF) Our model Zhang & Clark 5 R 0.952 0.956 0.958 N/A R 0.962 0.972 0.974 N/A P 0.951 0.947 0.938 N/A P 0.966 0.969 0.967 N/A F 0.952 0.951 0.948 0.946 F 0.964 0.971 0.971 0.972 ROOV 0.696 0.649 0.518 N/A ROOV 0.717 0.712 0.568 N/A RIV 0"
Y09-2047,P06-2123,0,\N,Missing
Y09-2047,C98-2201,0,\N,Missing
Y09-2047,I05-3018,0,\N,Missing
Y13-1010,C04-1081,0,0.0638947,"Missing"
Y13-1010,P03-1021,0,0.056177,"Missing"
Y13-1010,I08-4017,0,0.0530928,"Missing"
Y13-1010,zhao-etal-2010-large,0,0.0146567,"n many other cases such as “医学奖” (medicine-prize) and “一等奖” (first-prize)). Corpus PKU AS CITYU MSR qs 0.996 0.993 0.997 0.992 ql 0.977 0.970 0.976 0.970 qr 0.923 0.899 0.919 0.898 qf 0.686 0.662 0.653 0.662 Table 3: The matching rates of various tagging bias factors in the training set Corpus PKU AS CITYU MSR qs 0.457 0.374 0.515 0.299 ql 0.135 0.083 0.148 0.060 qr 0.135 0.082 0.149 0.060 qf 0.002 0.004 0.008 0.0003 Table 4: Unseen ratios for qs , ql , qr and qf in the testing set 5.2 Required context is frequently unobserved for testing instances However, according to the empirical study of Zhao et al., (2010), the OOV rate can be linearly reduced only with an exponential increasing of 123 PACLIC-27 corpus size, roughly due to Zipf’s law; and ngram is expected to also follow this pattern (Marco, 2009). Therefore, the sparseness problem gets more serious for the n-gram with a larger “n” (i.e., with wider context) because its number of possible distinct types would become much greater. As a consequence, there will be much more unseen bigrams than unseen unigrams in the testing set (Of course, unseen trigrams will be even more). Table 4 shows the unseen ratios for qs, ql, qr and qf in the testing set."
Y13-1010,W03-1730,0,0.0321201,"for performance comparison, we will focus on the second category to investigate how to use suffix related features in this paper. Generally speaking, Chinese suffixes are very productive and many words can be formed in this way. For example, the word “旅行者” (traveler) is composed of a stem (“旅行”, travel) and a suffix (“ 者”, -er). Although the character and character co-occurrence features (adopted in most current approaches) are able to partially characterize the internal structure of words (Sun, 2010), and some OOV words are indeed correctly handled when compared to pure wordbased approaches (Zhang et al., 2003; Gao et al., 2005), suffix related errors still remain as an important type of errors. Therefore, it is natural to expect that suffixes can be explicitly utilized to provide further help. Furthermore, prefix/suffix related features were claimed to be useful for CWS in some previous works (Tseng et al., 2005; Zhang et al., 2006). However, in their works, the prefix/suffix features are just a part of adopted features. The performances before and after adopting prefix/suffix features are never directly compared. So we could not know how much improvement actually results from those prefix/suffix"
Y13-1010,I05-3027,0,0.380437,"a suffix (“ 者”, -er). Although the character and character co-occurrence features (adopted in most current approaches) are able to partially characterize the internal structure of words (Sun, 2010), and some OOV words are indeed correctly handled when compared to pure wordbased approaches (Zhang et al., 2003; Gao et al., 2005), suffix related errors still remain as an important type of errors. Therefore, it is natural to expect that suffixes can be explicitly utilized to provide further help. Furthermore, prefix/suffix related features were claimed to be useful for CWS in some previous works (Tseng et al., 2005; Zhang et al., 2006). However, in their works, the prefix/suffix features are just a part of adopted features. The performances before and after adopting prefix/suffix features are never directly compared. So we could not know how much improvement actually results from those prefix/suffix related features. Besides, those features have only been adopted under discriminative approaches (Xue, 2003; Peng, 2004). We would also like to know whether the suffix related features would be effective for the generative approach (Wang et al., 2009; Wang et al., 2010). In comparison with the discriminative"
Y13-1010,I05-3025,0,0.0961974,"Missing"
Y13-1010,Y09-2047,1,0.863998,"were claimed to be useful for CWS in some previous works (Tseng et al., 2005; Zhang et al., 2006). However, in their works, the prefix/suffix features are just a part of adopted features. The performances before and after adopting prefix/suffix features are never directly compared. So we could not know how much improvement actually results from those prefix/suffix related features. Besides, those features have only been adopted under discriminative approaches (Xue, 2003; Peng, 2004). We would also like to know whether the suffix related features would be effective for the generative approach (Wang et al., 2009; Wang et al., 2010). In comparison with the discriminative model, the generative model has the drawback that it cannot utilize trailing context in selecting the position tag (i.e. Beginning, Middle, End and Single) (Xue, 2003) of the current character. Therefore, incorporating suffix information of the next character is supposed to be a promising supplement for the generative approach. So the real benefit of using suffixes is checked for the generative model first. To make use of the suffix information more completely, a novel quantitative tagging bias feature is first proposed to replace the"
Y13-1010,P12-1027,0,0.0229162,"Missing"
Y13-1010,zhang-etal-2004-interpreting,0,0.0611807,"Missing"
Y13-1010,C10-1132,1,0.787266,"Missing"
Y13-1010,P07-1106,0,0.0563439,"Missing"
Y13-1010,O03-4002,0,0.857807,"improvement can hardly be achieved by incorporating suffix related features into those widely adopted surface features, which is against the commonly believed supposition. Error analysis reveals that the main problem behind this surprising finding is the conflict between the degree of reliability and the coverage rate of suffix related features. 1 Introduction As words are the basic units for text analysis, Chinese word segmentation (CWS) is critical for many Chinese NLP tasks such as parsing and machine translation. Although steady improvements have been observed in previous CWS researches (Xue, 2003; Zhang and Clark, 2007; Wang et al., 2012; Sun et al., 2012), their performances are only acceptable for invocabulary (IV) words and are still far from satisfactory for those out-of-vocabulary (OOV) words. According to the Zipf's law (Zipf, 1949), which states that the frequency of a word is inversely proportional to its rank in the frequency table for a given corpus, it is unlikely to cover all the words of a language in the training corpus. OOV words are thus inevitable in real applications. To further improve the performance for OOV words, various approaches have been proposed. Most of the"
Y13-1010,I05-3017,0,0.0274704,"zing suffixes Nonetheless, we cannot distinguish suffixes from those non-suffixes by just checking each character because whether a character is a suffix highly depends on the context. For example, the character ‘化’ is a suffix in the word “初始化” (initial-ize). However, it becomes a prefix when it comes to the word “化纤” (chemical-fibre). Also, whether a character is a suffix varies with different annotation standards adopted by various corpora. For example, the character ‘ 厂 ’ (factory) is a suffix in words such as “服装厂” (clothing-factory) in the PKU corpus provided by the SIGHAN 2005 Bakeoff (Emerson, 2005). Nevertheless, it is regarded as a single-character 1 119 Extracting suffix information http://zh.wikipedia.org/wiki/%E8%A9%9E%E7%B6%B4 PACLIC-27 word in similar occasions in the MSR corpus. For these two reasons, suffixes cannot be directly recognized by simply locating some prespecified characters prepared by the linguist. 2.2 2.3 Adopting tagging bias information There are two drawbacks to adopt the above suffix-like list: (1) The associated context that is required to decide whether a character should be regarded as a suffix is either completely not taken into account (in previous approac"
Y13-1010,C10-2139,0,0.0143333,"on, and Computation pages 118－125 PACLIC-27 SIGHAN closed test (Emerson, 2005), which is widely adopted for performance comparison, we will focus on the second category to investigate how to use suffix related features in this paper. Generally speaking, Chinese suffixes are very productive and many words can be formed in this way. For example, the word “旅行者” (traveler) is composed of a stem (“旅行”, travel) and a suffix (“ 者”, -er). Although the character and character co-occurrence features (adopted in most current approaches) are able to partially characterize the internal structure of words (Sun, 2010), and some OOV words are indeed correctly handled when compared to pure wordbased approaches (Zhang et al., 2003; Gao et al., 2005), suffix related errors still remain as an important type of errors. Therefore, it is natural to expect that suffixes can be explicitly utilized to provide further help. Furthermore, prefix/suffix related features were claimed to be useful for CWS in some previous works (Tseng et al., 2005; Zhang et al., 2006). However, in their works, the prefix/suffix features are just a part of adopted features. The performances before and after adopting prefix/suffix features a"
Y13-1010,D11-1090,0,0.190672,"Missing"
Y13-1010,C12-1101,1,0.81007,"Missing"
Y13-1010,P06-2123,0,\N,Missing
Y13-1010,P11-1141,0,\N,Missing
Y13-1010,W10-4101,0,\N,Missing
