1997.iwpt-1.5,C96-1029,0,0.0676389,") and ( L e) ) . T he second problem concerns redundancy: when an ambiguity affects major feature values such a s category, the r esult is a set of structures as for ( L b) : the ambiguity between the verb and the noun involves in this example two completely different linguistic structures. But there are also ambiguities less interconnected wit h other part s of t he structure ( e. g. ( Ld) ) .In t hese cases, a c ommon subpart of t he structure can b e fact orised. This is particularly useful for the representation and t he implementation of some descriptive tools such as lexical rules ( see [Bredekamp96] ) . A n efficient ambiguity r epresentation must take into account t he interconnection between t he different sub part s of t he structure and allow a factorisation avoiding r edundancy. 2.2 Different Representations T he disjuncti ve representation of ambiguity remains t he most natural ( see [Karttunen98 4] , [Kay85] or [Kasper90]). However, t hi s approach has several drawbacks. First of all, if an ambiguity affects more t han one atomic value, t hen a classical disjunction can only represent variation between complete structures. In other words, such a representation doesn&apos;t allow the d"
1997.iwpt-1.5,J90-1002,0,0.0246011,"nd allow a factorisation avoiding r edundancy. 2.2 Different Representations T he disjuncti ve representation of ambiguity remains t he most natural ( see [Karttunen98 4] , [Kay85] or [Kasper90]). However, t hi s approach has several drawbacks. First of all, if an ambiguity affects more t han one atomic value, t hen a classical disjunction can only represent variation between complete structures. In other words, such a representation doesn&apos;t allow the description of the relations existing between t he features. In t he same way, several approaches ( see [Maxwell91] [Nakazawa88] , [Ramsay90] , [Dawar90] or [J ohnson90]) propose to rewrit e disjunctions as conjunctions ( and negations). Thi s method, in spite of t he fact t hat it can allow efficient implementations of some ambiguities, presents t he same drawback. A partial solution , concerning in particular t he redundancy problem, can be proposed wit h t he use of named disjunctions (not ed hereafter ND; also called distributed disjunctions) . Thi s approach has been described by [D6rre90] and u sed in several works ( see [Krieger93] , [Gerdemann95] or [Blache9 6] ) . The disjunction here only concerns the variable part of a structure (th"
1997.iwpt-1.5,C90-2018,0,0.348245,"ural language processing at very different levels: it can be very local ( e.g. limited to a feature value) or conversely affect entire syntactic structures. But the general disambiguating process remains the same and rely in particular on contextual information. Unfortunately, there exists very few solutions providing a general account of such a process with a direct and efficient implementation. In this paper, we propose an approach allowing a general and homogeneous representation of ambiguity and disambiguation relations. This approach constitutes an extension of named d isju nctions ( cf. [Dorre90] ) and allows a direct implementation of relations controlling the disambiguation. This paper is threefold. In the first part, we approach the question of the representation and we situate our method among the most representative ones. We describe in particular the advantages and drawbacks of named disjunctions and show how different phenomena can be described within such a paradigm. In the second part, we propose an analysis of the disambiguating process itself and describe some of the control relations existing between the different parts of the linguistic structure. We integrate the represe"
1997.iwpt-1.5,1995.iwpt-1.13,0,0.136863,"e features. In t he same way, several approaches ( see [Maxwell91] [Nakazawa88] , [Ramsay90] , [Dawar90] or [J ohnson90]) propose to rewrit e disjunctions as conjunctions ( and negations). Thi s method, in spite of t he fact t hat it can allow efficient implementations of some ambiguities, presents t he same drawback. A partial solution , concerning in particular t he redundancy problem, can be proposed wit h t he use of named disjunctions (not ed hereafter ND; also called distributed disjunctions) . Thi s approach has been described by [D6rre90] and u sed in several works ( see [Krieger93] , [Gerdemann95] or [Blache9 6] ) . The disjunction here only concerns the variable part of a structure (this allows t he information factorisation) . A ND binds several disjunctive formulae with an index (the name of the disjunction) . These formulae are ordered and have t he same arity. T he variation is controlled by a covariancy mechanism enforcing the 2 simultaneous variation of the ND values: when one disjunct in a ND is chosen (i. e. int erpret ed to true), all the disjuncts occurring at the same rank int o the other ND formulae also have to be true. Several NDs can occur in the same structure. Figure"
1997.iwpt-1.5,P90-1022,0,0.0627837,"Missing"
1997.iwpt-1.5,P84-1008,0,0.768531,"Missing"
1997.iwpt-1.5,J96-3001,0,0.0212543,"s to a well formedness verification. In case of incoherence, backtracking is applied and another model is elaborated (i.e. another value is choosen). This method can be improved by some t echniques (cf. [Maxwell91] ), but the basic mechanism remains a kind of generate-and-test device: the first feature instantiation leads to the choice of an entire structure which has t o be validat ed during the parse. 3.1 Fundamental Needs A natural solution consists in delaying the evaluation of the structure consist ency. We highlight here two t echniques used in our approach: selection constraints ( cf. [Pulman96] ) and coroutining ( cf. [van Noord94] , [Blache96]). [Pulman96] represents ambiguities with fixed- arity lists. They are controlled by an agreement-like device between two categories, one being controlled by the other. These lists can be interpreted as disjunctions (not expanded int o a normal form) and their evaluation requires contextual information. The problem is that this mechanism can only be represented by a phrase-structure rules, and not at a general level. This is problematic in two respects : it is a context-sensiti ve mechanism and it only works for formalisms using phrase-structu"
1997.iwpt-1.5,J90-3004,0,0.0256962,"e structure and allow a factorisation avoiding r edundancy. 2.2 Different Representations T he disjuncti ve representation of ambiguity remains t he most natural ( see [Karttunen98 4] , [Kay85] or [Kasper90]). However, t hi s approach has several drawbacks. First of all, if an ambiguity affects more t han one atomic value, t hen a classical disjunction can only represent variation between complete structures. In other words, such a representation doesn&apos;t allow the description of the relations existing between t he features. In t he same way, several approaches ( see [Maxwell91] [Nakazawa88] , [Ramsay90] , [Dawar90] or [J ohnson90]) propose to rewrit e disjunctions as conjunctions ( and negations). Thi s method, in spite of t he fact t hat it can allow efficient implementations of some ambiguities, presents t he same drawback. A partial solution , concerning in particular t he redundancy problem, can be proposed wit h t he use of named disjunctions (not ed hereafter ND; also called distributed disjunctions) . Thi s approach has been described by [D6rre90] and u sed in several works ( see [Krieger93] , [Gerdemann95] or [Blache9 6] ) . The disjunction here only concerns the variable part of a s"
1997.iwpt-1.5,C94-1039,0,0.235789,"Missing"
2000.iwpt-1.30,P98-1019,1,0.799761,"categories which cannot be repeated in a phrase. • Requirement (noted ⇒) Cooccurrency between sets of categories. • Exclusion (noted ¥&gt;) Restriction of cooccurrence between sets of categories. Linear precedence constraints. • Linearity (noted -&lt; ) • Dependency ( noted ""-+) Dependency relations between categories. It 1s interesting to notice that properties can be expressed over sets of categories, allowing then to represent contextual information. 3. Parsing as Constraint Satisfaction The parsing process (1) takes as input the set of elementary trees (in fact unary quai trees, as described in [Blache98] ) that can be associated to the sentence and (2) builds all the characterizations of this input. A characterization is then defined over a set of categories by p + (the set of satisfied properties) and p- ( the set of unsatisfied properties) . The following example describes a rammar of the NP in french. Properties of the (5) Det --&lt; AP Properties of the Properties of the (5) Det --&lt; Adv (1) Const = { Det, N, A P, Sup} (2) Oblig = { N, A P} (3) N{com} ⇒ Det (4) Det --&lt; N NP: (6) Det --&lt; Sup (8) N --&lt; Sup (9) AP � Sup (10) Det ._ N ( 1 1) A P ._ N ( 12) Sup ._ N AP: (1) Const = {Adj, Adv} (2)"
2000.iwpt-1.30,P90-1005,0,0.0505554,"Missing"
2002.jeptalnrecital-long.18,P98-1019,1,0.893208,"Missing"
2002.jeptalnrecital-long.18,C90-2018,0,0.0309063,"Missing"
2003.jeptalnrecital-poster.5,P90-1003,0,0.0680403,"Missing"
2003.jeptalnrecital-poster.5,J00-2002,0,0.0542976,"Missing"
2004.jeptalnrecital-long.21,C02-1104,1,0.812732,"Missing"
2005.jeptalnrecital-long.10,C02-1104,1,0.891677,"Missing"
2005.jeptalnrecital-long.10,W01-1808,0,0.0605913,"Missing"
2005.jeptalnrecital-long.10,P01-1034,0,0.0449199,"Missing"
2005.jeptalnrecital-long.10,P02-1018,0,0.057001,"Missing"
2005.jeptalnrecital-long.10,C02-1071,0,0.0471869,"Missing"
2005.jeptalnrecital-long.10,W04-0312,0,0.030615,"Missing"
2005.jeptalnrecital-long.10,2004.jeptalnrecital-long.32,0,0.191784,"Missing"
2006.jeptalnrecital-long.31,sekine-etal-2002-extended,0,0.0265427,"Missing"
2006.jeptalnrecital-poster.5,2005.jeptalnrecital-long.10,1,0.849297,"Missing"
2006.jeptalnrecital-poster.5,J98-4004,0,0.0605984,"Missing"
2006.jeptalnrecital-poster.5,1997.iwpt-1.18,0,0.16361,"Missing"
2006.jeptalnrecital-poster.5,2004.jeptalnrecital-long.32,0,0.102777,"Missing"
2007.jeptalnrecital-poster.26,ayache-etal-2006-equer,0,0.0379865,"Missing"
2007.jeptalnrecital-poster.26,P00-1037,0,0.12319,"Missing"
2007.jeptalnrecital-poster.26,P02-1019,0,0.0414782,"Missing"
2008.jeptalnrecital-long.29,E03-1085,0,0.433503,"Missing"
2008.jeptalnrecital-long.29,C94-1097,0,0.121014,"Missing"
2008.jeptalnrecital-long.29,paroubek-etal-2006-data,0,0.185621,"Missing"
2008.jeptalnrecital-long.29,P80-1024,0,0.803855,"Missing"
2008.jeptalnrecital-long.29,2005.jeptalnrecital-court.22,1,0.842262,"Missing"
2009.jeptalnrecital-long.28,E03-1085,0,0.0635458,"Missing"
2010.jeptalnrecital-long.9,P06-1008,1,0.894319,"Missing"
2010.jeptalnrecital-long.9,N09-1039,0,0.0308443,"Missing"
2015.jeptalnrecital-court.25,C08-1085,0,0.0799074,"Missing"
2015.jeptalnrecital-court.25,W12-4903,1,0.876586,"Missing"
2015.jeptalnrecital-court.25,E12-2021,0,0.0926265,"Missing"
2015.jeptalnrecital-court.25,P13-4001,0,0.0245754,"Missing"
2015.jeptalnrecital-long.20,P06-1035,0,0.0801228,"Missing"
2015.jeptalnrecital-long.20,petrov-etal-2012-universal,0,0.0535155,"Missing"
2020.aacl-main.26,J03-2004,0,0.54055,"enon of logical metonymy can be explained in terms of the thematic fit, that is, the degree of compatibility between the verb and one of its arguments (the direct object, in this case). On the one hand, a low thematic fit between an event-selecting verb and an entity-denoting argument triggers the recovery of a covert event, while on the other hand, the recovered event is often the best fitting one, given the information available in the sentence. Research in NLP on logical metonymy initially focused on the problem of covert event retrieval, which was tackled by means of probabilistic models (Lapata and Lascarides, 2003; Shutova, 2009), or by using Distributional Semantic Models (DSMs) that identify the candidate covert event with the one that has the highest thematic fit with the arguments in the sentence (Zarcone et al., 2012). Following the psycholinguistic works by McElree et al. (2001) and Traxler et al. (2002), which reported increased reading times and longer fixations in eye-tracking for the metonymic sentences, Zarcone et al. (2013) proposed a distributional model of the thematic fit between verb and object, and showed that it accurately reproduces the differences between the experimental conditions"
2020.aacl-main.26,Q17-1010,0,0.0114471,"s computed as the similarity score of its corresponding lexical vector ~e with the prototype vector. As we did the probabilistic model, we discard the metonymic verb from this computation. 3 The verb E representing the preferred interpretation of the metonymy is the verb e maximizing the following equation: E = argmaxe P (e)P (o|e)P (s|e) We test two variations of this model, TF-add and TF-prod, which differ for the filler selection update function. Statistics were extracted from Wikipedia 2018, and the vectors were the publiclyavailable Wikipedia embeddings 4 trained with the FastText model (Bojanowski et al., 2017). The verb-filler association score is the Local Mutual Information (Evert, 2008). Similarly, the scores for the subject fillers are defined as: We computed the statistics from a 2018 dump of the English Wikipedia, parsed with the Stanford CoreNLP toolkit (Manning et al., 2014). Dataset MC TR L&L CE Coverage 19/30 (pairs) 21/36 (pairs) 151/174 (items) 195/285 (items) Table 2: Coverage for the probabilistic model. sbj LM I(s, e) = f (e ←−− s)log2 3.3.2 Logical Metonymy as Thematic Fit Distributional models of logical metonymy assume that the event recovery task can be seen as a thematic fit tas"
2020.aacl-main.26,W11-0607,1,0.906684,"Missing"
2020.aacl-main.26,S17-1021,1,0.940651,"nts and their typical participants (see McRae and Matsuki (2009) for an overview) and claims that words act like cues to access event knowledge, incrementally modulating sentence comprehension. The results obtained in a probe recognition experiment by Zarcone et al. (2014), in line with this explanation, suggest that speakers interpret logical metonymies by inferring the most likely event the sentences could refer to, given the contextual cues. Previous research in NLP on logical metonymy has often been influenced by such theoretical explanation (Zarcone and Pad´o, 2011; Zarcone et al., 2012; Chersoni et al., 2017). In our contribution, we propose a general comparison of different classes of computational models for logical metonymy. To begin with, we tested two approaches that have been previously introduced in the literature on the topic: probabilistic and distributional models (Zarcone et al., 2012). We also examined the Structured Distributional Model (SDM) by Chersoni et al. (2019), which represents sentence meaning with a combination of formal structures and distributional embeddings to dynamically integrate knowledge about events and their typical participants, as they are activated by lexical it"
2020.aacl-main.26,2021.ccl-1.108,0,0.0624012,"Missing"
2020.aacl-main.26,P14-5010,0,0.00429667,"Missing"
2020.aacl-main.26,N19-1423,0,0.363105,"ransformer language models into a contrastive study on 1 Notice however that the evidence is not uncontroversial: Delogu et al. (2017) report that coercion costs largely reflect word surprisal, without any specific effect of type shift in the early processing measures. 224 Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing, pages 224–234 c December 4 - 7, 2020. 2020 Association for Computational Linguistics logical metonymy. Transformers (Vaswani et al., 2017; Devlin et al., 2019) are the dominant class of NLP systems in the last few years, since they are able to generate “dynamic” representations for a target word depending on the sentence context. As the interpretation of logical metonymy is highly sensitive to context, we deem that the contextual representations built by Transformers might be able to integrate the covert event that is missing in the surface form of the sentence. All models are evaluated on their capability of assigning the correct interpretation to a metonymic sentence, that is, recovering the verb that refers to the correct interpretation. This tas"
2020.aacl-main.26,N18-1202,0,0.00848065,"ly-elaborated compositional model. The authors recently introduced a more up-to-date and refined version of their sentence comprehension model (Chersoni et al., 2019), but it has not been tested on the logical metonymy task so far. 2.2 Transformer Models in NLP The traditional approach in Distributional Semantics has been the building of a single, stable vector representation for each word type in the corpus (Turney and Pantel, 2010; Lenci, 2018). Lately, a new generation of embeddings has emerged, in which each occurrence of a word in a specific sentence context gets a unique representation (Peters et al., 2018). The most recent systems typically rely on an LSTM or a Transformer architecture for getting word representations: they are trained on large amounts of textual data and the word vectors are learned as a function of the internal states of the encoder, such that a word in different sentence contexts determines different activation states and is represented by a different vector. Thus, embeddings generated by these new models are said to be contextualized, as opposed to the static vectors generated by the earlier frameworks, and they aim at modeling the specific sense assumed by the word in cont"
2020.aacl-main.26,Q15-1032,0,0.0700545,"Missing"
2020.aacl-main.26,D17-1068,1,0.651403,"Missing"
2020.aacl-main.26,W16-2518,0,0.285284,"Missing"
2020.aacl-main.26,P09-3001,0,0.0413085,"be explained in terms of the thematic fit, that is, the degree of compatibility between the verb and one of its arguments (the direct object, in this case). On the one hand, a low thematic fit between an event-selecting verb and an entity-denoting argument triggers the recovery of a covert event, while on the other hand, the recovered event is often the best fitting one, given the information available in the sentence. Research in NLP on logical metonymy initially focused on the problem of covert event retrieval, which was tackled by means of probabilistic models (Lapata and Lascarides, 2003; Shutova, 2009), or by using Distributional Semantic Models (DSMs) that identify the candidate covert event with the one that has the highest thematic fit with the arguments in the sentence (Zarcone et al., 2012). Following the psycholinguistic works by McElree et al. (2001) and Traxler et al. (2002), which reported increased reading times and longer fixations in eye-tracking for the metonymic sentences, Zarcone et al. (2013) proposed a distributional model of the thematic fit between verb and object, and showed that it accurately reproduces the differences between the experimental conditions in the data fro"
2020.aacl-main.26,W13-0216,1,0.861246,"Missing"
2020.aacl-main.26,W12-1707,0,0.0210505,"Missing"
2020.coling-main.431,W19-5946,0,0.0121673,"generic metaclasses or the most frequently used. For example, several works are based on the DAMSL tagset reduced to 5 classes (statements, questions, backchannels, fillers and disruptions) (Ang et al., 2005). Some other works, such as the reference one (Stolcke et al., 2000) or the recent state of the art described in (Chen et al., 2018), use a tagset reduced to the 5 most frequent tags (statement, backchannel, opinion, abandoned, agreement). Reducing the tagset can also be done for adjusting the classification to the needs of a specific domain dialog system. This is for example the case in (Anakina and Kruijff-Korbayova, 2019), describing communication in the context of robot-assisted disaster response. In this work, a specific set of ISO metaclasses adapted to the needs of the system is proposed, clustering the 20 most useful dialogue acts into 8 metaclasses (Contact, Inform, Affirmative, Request, Question, Confirm, Disconfirm, Negative). The features: The second question to be answered for DA classification is that of the features used by the classifiers. Most works use low-level features, such as n-grams of characters and words, length of the utterance, etc. (Stolcke et al., 2000; Kim et al., 2016; Sennrich et a"
2020.coling-main.431,L18-1307,0,0.0150719,"use low-level features, such as n-grams of characters and words, length of the utterance, etc. (Stolcke et al., 2000; Kim et al., 2016; Sennrich et al., 2017). These features are usually complemented by distributional information such as word embeddings (Chen et al., 2018; Kumar et al., 2017; Tran et al., 2017; Chakravarty et al., 2019), which can be weighted with TF-IDF (Joulin et al., 2017; Raheja and Tetreault, 2019). In several studies, this information is also complemented by linguistic features such as prosody or morpho-syntactic information (Shriberg et al., 1998; Stolcke et al., 2000; Bothe et al., 2018; Tran et al., 2017). Related works: Many different approaches have been tested for DA classification. The following table summarizes the main results recently obtained in this task, indicating the type of classification technique, the dataset and the accuracy. Two of these studies represent the state of the art for the MRDA an the SwDA datasets. In a recent paper, (Chen et al., 2018) has proposed a new approach based on CRF-Attentive Structured Network. This technique relies on a hierarchical representation distinguishing three levels (words, utterances, conversation), integrating a 4916 Auth"
2020.coling-main.431,bunt-etal-2012-iso,0,0.464594,"uman or the machine) leading the dialogue. In such situations, recognizing dialogue acts (DA) becomes extremely useful as a preliminary step of the understanding process: associating speaker’s utterances to DAs makes it possible to identify very efficiently the type of information they bear and the knowledge to be conveyed. Many works on dialogue act classification have been done for a long time (Stolcke et al., 2000). The first question consists in defining the set of relevant dialogue acts for the system. Different generic DA annotation schemes have been proposed, including an ISO standard (Bunt et al., 2012; Bunt et al., 2017). In addition, several dialogue corpora have been annotated and made available, among which two are particularly used: Switchboard Dialog Act Corpus, (SwDA) (Jurafsky et al., 1997) and Meeting Recorder Dialog Act (MRDA) (Shriberg et al., 2004). These datasets have allowed to train different classifiers. In these works, two preliminary questions arise: the identification of the dialogue acts to be classified and the features on which the classifier must be based. In most cases, the classification task targets a limited set of classes (corresponding to very general DAs such a"
2020.coling-main.431,W17-7404,0,0.308085,") leading the dialogue. In such situations, recognizing dialogue acts (DA) becomes extremely useful as a preliminary step of the understanding process: associating speaker’s utterances to DAs makes it possible to identify very efficiently the type of information they bear and the knowledge to be conveyed. Many works on dialogue act classification have been done for a long time (Stolcke et al., 2000). The first question consists in defining the set of relevant dialogue acts for the system. Different generic DA annotation schemes have been proposed, including an ISO standard (Bunt et al., 2012; Bunt et al., 2017). In addition, several dialogue corpora have been annotated and made available, among which two are particularly used: Switchboard Dialog Act Corpus, (SwDA) (Jurafsky et al., 1997) and Meeting Recorder Dialog Act (MRDA) (Shriberg et al., 2004). These datasets have allowed to train different classifiers. In these works, two preliminary questions arise: the identification of the dialogue acts to be classified and the features on which the classifier must be based. In most cases, the classification task targets a limited set of classes (corresponding to very general DAs such as statement, questio"
2020.coling-main.431,E17-2068,0,0.0485851,"metaclasses (Contact, Inform, Affirmative, Request, Question, Confirm, Disconfirm, Negative). The features: The second question to be answered for DA classification is that of the features used by the classifiers. Most works use low-level features, such as n-grams of characters and words, length of the utterance, etc. (Stolcke et al., 2000; Kim et al., 2016; Sennrich et al., 2017). These features are usually complemented by distributional information such as word embeddings (Chen et al., 2018; Kumar et al., 2017; Tran et al., 2017; Chakravarty et al., 2019), which can be weighted with TF-IDF (Joulin et al., 2017; Raheja and Tetreault, 2019). In several studies, this information is also complemented by linguistic features such as prosody or morpho-syntactic information (Shriberg et al., 1998; Stolcke et al., 2000; Bothe et al., 2018; Tran et al., 2017). Related works: Many different approaches have been tested for DA classification. The following table summarizes the main results recently obtained in this task, indicating the type of classification technique, the dataset and the accuracy. Two of these studies represent the state of the art for the MRDA an the SwDA datasets. In a recent paper, (Chen et"
2020.coling-main.431,W13-3214,0,0.0269537,"Missing"
2020.coling-main.431,N16-1062,0,0.0137328,"nd discussion of the results. 2 Dialog act classification Dialogue acts (DAs) correspond to communicative functions describing the illocutionary force (speaker’s intention) that can be associated with utterances in the discourse. DA classification consists in associating to each segment of the discourse (that can be a turn, an inter-pausal unit or a segment returned by a speech recognition system) a label corresponding to the communicative function. DA classification is a classical problem for which many propositions have been done (Stolcke et al., 2000; Ang et al., 2005; Tavafi et al., 2013; Lee and Dernoncourt, 2016; Chen et al., 2018; Kumar et al., 2017; Raheja and Tetreault, 2019). Two preliminary questions must be addressed in this task before a classification technique can be applied: the choice of the tagset, and the identification of the features used by the classifiers. We propose in this section to quickly address these issues before presenting the main results available in the literature. The DA tagset: The study of dialogue acts has led to several annotation schemes. Among these, the Dialogue Act Markup in Several Layers (DAMSL) (Core and Allen, 1997), which served as a basis for the annotation"
2020.coling-main.431,2007.sigdial-1.30,0,0.109228,"Missing"
2020.coling-main.431,N19-1373,0,0.0667891,"acts (DAs) correspond to communicative functions describing the illocutionary force (speaker’s intention) that can be associated with utterances in the discourse. DA classification consists in associating to each segment of the discourse (that can be a turn, an inter-pausal unit or a segment returned by a speech recognition system) a label corresponding to the communicative function. DA classification is a classical problem for which many propositions have been done (Stolcke et al., 2000; Ang et al., 2005; Tavafi et al., 2013; Lee and Dernoncourt, 2016; Chen et al., 2018; Kumar et al., 2017; Raheja and Tetreault, 2019). Two preliminary questions must be addressed in this task before a classification technique can be applied: the choice of the tagset, and the identification of the features used by the classifiers. We propose in this section to quickly address these issues before presenting the main results available in the literature. The DA tagset: The study of dialogue acts has led to several annotation schemes. Among these, the Dialogue Act Markup in Several Layers (DAMSL) (Core and Allen, 1997), which served as a basis for the annotation of two reference corpora, SwDA and MRDA, cited above. More recently"
2020.coling-main.431,W04-2319,0,0.108503,"the type of information they bear and the knowledge to be conveyed. Many works on dialogue act classification have been done for a long time (Stolcke et al., 2000). The first question consists in defining the set of relevant dialogue acts for the system. Different generic DA annotation schemes have been proposed, including an ISO standard (Bunt et al., 2012; Bunt et al., 2017). In addition, several dialogue corpora have been annotated and made available, among which two are particularly used: Switchboard Dialog Act Corpus, (SwDA) (Jurafsky et al., 1997) and Meeting Recorder Dialog Act (MRDA) (Shriberg et al., 2004). These datasets have allowed to train different classifiers. In these works, two preliminary questions arise: the identification of the dialogue acts to be classified and the features on which the classifier must be based. In most cases, the classification task targets a limited set of classes (corresponding to very general DAs such as statement, question etc.) and features remain at a low level (n-grams of words, characters, word embeddings, etc.). The performance of these classifiers is generally very good. However, the proposed task (i.e. the targeted tagset) remains often too general for"
2020.coling-main.431,J00-3003,0,0.215421,"Missing"
2020.coling-main.431,W13-4017,0,0.0236583,"to the presentation and discussion of the results. 2 Dialog act classification Dialogue acts (DAs) correspond to communicative functions describing the illocutionary force (speaker’s intention) that can be associated with utterances in the discourse. DA classification consists in associating to each segment of the discourse (that can be a turn, an inter-pausal unit or a segment returned by a speech recognition system) a label corresponding to the communicative function. DA classification is a classical problem for which many propositions have been done (Stolcke et al., 2000; Ang et al., 2005; Tavafi et al., 2013; Lee and Dernoncourt, 2016; Chen et al., 2018; Kumar et al., 2017; Raheja and Tetreault, 2019). Two preliminary questions must be addressed in this task before a classification technique can be applied: the choice of the tagset, and the identification of the features used by the classifiers. We propose in this section to quickly address these issues before presenting the main results available in the literature. The DA tagset: The study of dialogue acts has led to several annotation schemes. Among these, the Dialogue Act Markup in Several Layers (DAMSL) (Core and Allen, 1997), which served as"
2020.coling-main.431,E17-1041,0,0.0145978,"ds of the system is proposed, clustering the 20 most useful dialogue acts into 8 metaclasses (Contact, Inform, Affirmative, Request, Question, Confirm, Disconfirm, Negative). The features: The second question to be answered for DA classification is that of the features used by the classifiers. Most works use low-level features, such as n-grams of characters and words, length of the utterance, etc. (Stolcke et al., 2000; Kim et al., 2016; Sennrich et al., 2017). These features are usually complemented by distributional information such as word embeddings (Chen et al., 2018; Kumar et al., 2017; Tran et al., 2017; Chakravarty et al., 2019), which can be weighted with TF-IDF (Joulin et al., 2017; Raheja and Tetreault, 2019). In several studies, this information is also complemented by linguistic features such as prosody or morpho-syntactic information (Shriberg et al., 1998; Stolcke et al., 2000; Bothe et al., 2018; Tran et al., 2017). Related works: Many different approaches have been tested for DA classification. The following table summarizes the main results recently obtained in this task, indicating the type of classification technique, the dataset and the accuracy. Two of these studies represent"
2020.coling-main.431,W16-3647,0,0.0249881,"emains often too general for an optimal use in a dialog system. Moreover, and this is a recurring problem in this type of approach, it is sometimes difficult to interpret the results and understand precisely the relative impact of the different features on the model. In this paper, we address the question of DA classification for helping comprehension and dialogue supervision in the context of task-oriented dialogue systems. Several works have shown the importance of DAs for guiding dialogues, in particular in the context of adaptive and socially-aware systems used for training social skills (Zhao et al., 2016). In such cases, the dialogue system plays the role of a person to whom information must be transmitted (Ochs et al., 2018b). The targeted information, the semantic context, as well as the way the information should be transmitted are known in advance by the system. We are then in the situation where the most difficult task for the system is to generate an appropriate reaction to the way the human has delivered the information: appropriate feedbacks, clarification questions, surprise, emotional reactions, etc. This is the reason why DA classification plays an important role, more than a classi"
2020.lrec-1.85,L16-1507,1,0.880974,"Missing"
2021.starsem-1.1,J10-4006,1,0.542773,"mitations of TLM S as models of GEK. Our results are relevant for researchers interested in assessing the linguistic abilities of TLM S, as well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that differ only for one element, which can be either a typical or atypical filler of a given role in the event described by"
2021.starsem-1.1,W15-1106,0,0.0158776,"rchers interested in assessing the linguistic abilities of TLM S, as well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that differ only for one element, which can be either a typical or atypical filler of a given role in the event described by the tuple (cf. Table 1). The dataset includes tuples of different lengt"
2021.starsem-1.1,N15-1003,0,0.0147145,"rchers interested in assessing the linguistic abilities of TLM S, as well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that differ only for one element, which can be either a typical or atypical filler of a given role in the event described by the tuple (cf. Table 1). The dataset includes tuples of different lengt"
2021.starsem-1.1,W16-4102,1,0.847282,"port) and the other sentence expressing a plausible but less typical one (The mechanic is checking the report), and the task is to assign a higher thematic fit/typicality score to the former. Notice that the two sentences differ only for one argument, and that the “atypical” one might, however, be a common filler with respect to the verb target role (e.g., report is a typical patient for check, it is just less plausible in combination with mechanic as an agent). Several models have tried to tackle the “dynamic” version of the thematic fit task, either based on classical distributional spaces (Chersoni et al., 2016, 2019) or on more sophisticated neural network architectures (Tilk et al., 2016; Hong et al., 2018). On the evaluation side, those works made use of the experimental materials of the study by Lenci (2011), which are, however, limited to agentverb-patient triples. The recently-introduced DTFit dataset (Vassallo et al., 2018) is, in comparison, larger in size and provides more variety of fillers and roles (including instruments, locations and time). Other studies introduced larger datasets, but focused on more specific notions of event plausibility (e.g. the plausibility depending on the physic"
2021.starsem-1.1,S18-2002,0,0.0120126,"report), and the task is to assign a higher thematic fit/typicality score to the former. Notice that the two sentences differ only for one argument, and that the “atypical” one might, however, be a common filler with respect to the verb target role (e.g., report is a typical patient for check, it is just less plausible in combination with mechanic as an agent). Several models have tried to tackle the “dynamic” version of the thematic fit task, either based on classical distributional spaces (Chersoni et al., 2016, 2019) or on more sophisticated neural network architectures (Tilk et al., 2016; Hong et al., 2018). On the evaluation side, those works made use of the experimental materials of the study by Lenci (2011), which are, however, limited to agentverb-patient triples. The recently-introduced DTFit dataset (Vassallo et al., 2018) is, in comparison, larger in size and provides more variety of fillers and roles (including instruments, locations and time). Other studies introduced larger datasets, but focused on more specific notions of event plausibility (e.g. the plausibility depending on the physical properties of the participants) (Wang et al., 2018; Porada et al., 2019; Ko et al., 2019). Contri"
2021.starsem-1.1,S17-1021,1,0.855068,"optimal generalization abilities. 1 Introduction People can discriminate between typical (e.g., A cop arrested a thief ) and atypical events (e.g., A thief arrested a cop) and exploit this ability in online sentence processing to anticipate the upcoming linguistic input. Brains have been claimed to be “prediction machines” (Clark, 2013) and psycholinguistic research has shown that a crucial ingredient 1 Proceedings of the 10th Conference on Lexical and Computational Semantics, pages 1–11 August 5–6, 2021, Bangkok, Thailand (online) ©2021 Association for Computational Linguistics from corpora (Chersoni et al., 2017, 2021). Language Models are trained to make predictions given a context, and thus, they can also be viewed as models of GEK. This approach is promising if one considers the success of recent Transformer-based Language Models (henceforth TLM S), which are trained on huge corpora and contain a massive number of parameters. Even if these models receive extensive training and have been shown to capture linguistic properties (Jawahar et al., 2019; Goldberg, 2019), it is not obvious whether they acquire the aspects of GEK that have been modeled explicitly in previous approaches. To the best of our"
2021.starsem-1.1,2020.lrec-1.700,1,0.716625,"well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that differ only for one element, which can be either a typical or atypical filler of a given role in the event described by the tuple (cf. Table 1). The dataset includes tuples of different lengths, and the typicality of a given argument depends on its interaction"
2021.starsem-1.1,N19-1349,0,0.0169179,"2016; Hong et al., 2018). On the evaluation side, those works made use of the experimental materials of the study by Lenci (2011), which are, however, limited to agentverb-patient triples. The recently-introduced DTFit dataset (Vassallo et al., 2018) is, in comparison, larger in size and provides more variety of fillers and roles (including instruments, locations and time). Other studies introduced larger datasets, but focused on more specific notions of event plausibility (e.g. the plausibility depending on the physical properties of the participants) (Wang et al., 2018; Porada et al., 2019; Ko et al., 2019). Contributions: 1. we propose a methodology to adapt TLM S to the dynamic estimation of thematic fit, using a dataset that contains several types of argument combinations differing for their typicality; 2. we present a comprehensive evaluation of various TLM S on this task, performed by comparing them to a strong distributional baseline; 3. we conduct further analysis aimed at identifying the potential limitations of TLM S as models of GEK. Our results are relevant for researchers interested in assessing the linguistic abilities of TLM S, as well as those working on applications involving TLM"
2021.starsem-1.1,W11-0607,1,0.831728,"2011) have shown that humans are able to combine and dynamically update their expectations during sentence processing: for example, their expectations given the sequence The barber cut the differ from the ones given The lumberjack cut the , since the integration of knowledge “cued” by the agent argument with the verb will lead to the activation of different event scenarios. In Distributional Semantics, sophisticated models of the GEK have been proposed to make predictions on upcoming arguments by integrating the cues coming from the verb and the previously-realized arguments in the sentence (Lenci, 2011; Chersoni et al., 2019). Since such knowledge is acquired from both first-hand and linguistic experience (McRae and Matsuki, 2009), an important assumption of this literature is that, at least for its ”linguistic subset”, the GEK can be modeled with distributional information extracted Given the recent success of Transformers Language Models (TLMs), we decided to test them on a benchmark for the dynamic estimation of thematic fit. The evaluation of these models was performed in comparison with SDM, a framework specifically designed to integrate events in sentence meaning representations, and"
2021.starsem-1.1,2021.ccl-1.108,0,0.0279667,"Missing"
2021.starsem-1.1,N19-1423,0,0.016492,"the models that we used, we decided to disregard its tuple and the respective typical/atypical counterpart. For this reason, the final results only take in consideration a subset of the original datasets, which varies from model to model. Additionally, we computed a baseline for each Transformer model, where the model is prevented from attending to the other tokens in the sequence when making predictions. 3.2.2 Transformer-based Language Models We experimented with four TLM S to test how different architectures, training objectives, and sizes of the training corpus affect performance.3 BERT (Devlin et al., 2019) consists of a series of stacked Transformer encoders. It was trained using both a masked language modeling objective (i.e., 2 https://fasttext.cc/docs/en/ english-vectors.html 3 For all experiments involving TLM S, we use pre-trained models available in the HuggingFace’s Python library Transformers (Wolf et al., 2019). 4 Coverage SDM BERT-base(line) BERT-large ROBERTA-large GPT-2 medium AgentDTFit 105/134 0.58 0.46 (0.1) 0.53 0.64 PatientDTFit 323/402 0.62 0.59 (0.06) 0.64 0.64 0.63 InstrumentDTFit 31/100 0.58 0.52 (0.08) 0.53 0.5 0.5 TimeDTFit 89/100 0.58 0.63 (0.06) 0.64 0.66 0.66 LocationD"
2021.starsem-1.1,P07-1028,0,0.0615047,"a strong distributional baseline; 3. we conduct further analysis aimed at identifying the potential limitations of TLM S as models of GEK. Our results are relevant for researchers interested in assessing the linguistic abilities of TLM S, as well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that diffe"
2021.starsem-1.1,N18-2049,0,0.347046,"ral network architectures (Tilk et al., 2016; Hong et al., 2018). On the evaluation side, those works made use of the experimental materials of the study by Lenci (2011), which are, however, limited to agentverb-patient triples. The recently-introduced DTFit dataset (Vassallo et al., 2018) is, in comparison, larger in size and provides more variety of fillers and roles (including instruments, locations and time). Other studies introduced larger datasets, but focused on more specific notions of event plausibility (e.g. the plausibility depending on the physical properties of the participants) (Wang et al., 2018; Porada et al., 2019; Ko et al., 2019). Contributions: 1. we propose a methodology to adapt TLM S to the dynamic estimation of thematic fit, using a dataset that contains several types of argument combinations differing for their typicality; 2. we present a comprehensive evaluation of various TLM S on this task, performed by comparing them to a strong distributional baseline; 3. we conduct further analysis aimed at identifying the potential limitations of TLM S as models of GEK. Our results are relevant for researchers interested in assessing the linguistic abilities of TLM S, as well as thos"
2021.starsem-1.1,2020.coling-main.109,0,0.0529502,"Missing"
2021.starsem-1.1,P19-1071,0,0.0142322,"dberg, 2019), it is not obvious whether they acquire the aspects of GEK that have been modeled explicitly in previous approaches. To the best of our knowledge, Transformers have never been tested on dynamic thematic fit modeling, nor their performance has been compared with traditional distributional models. Our current work is addressing this issue. 2020). Performance in the thematic fit task is typically measured with the correlation between the output scores of the model and human-elicited typicality judgments for verb-argument pairs (McRae et al., 1998; Ferretti et al., 2001; Pad´o, 2007; Zhang et al., 2019; Marton and Sayeed, 2021). In the simplest and most common version of this task, the typicality of verb argument-pairs is evaluated in isolation. Thematic fit is instead a dynamic concept: The expectations for an argument in a given verb role do not depend just on the verb, but also on the compositional combination with the other arguments in the sentence (Bicknell et al., 2010). To check the ability of computational models to account for the compositional update of argument expectations, Lenci (2011) framed the problem as a binary classification task: A system is presented a sentence pair, w"
2021.starsem-1.1,D19-6015,0,0.0193332,"ctures (Tilk et al., 2016; Hong et al., 2018). On the evaluation side, those works made use of the experimental materials of the study by Lenci (2011), which are, however, limited to agentverb-patient triples. The recently-introduced DTFit dataset (Vassallo et al., 2018) is, in comparison, larger in size and provides more variety of fillers and roles (including instruments, locations and time). Other studies introduced larger datasets, but focused on more specific notions of event plausibility (e.g. the plausibility depending on the physical properties of the participants) (Wang et al., 2018; Porada et al., 2019; Ko et al., 2019). Contributions: 1. we propose a methodology to adapt TLM S to the dynamic estimation of thematic fit, using a dataset that contains several types of argument combinations differing for their typicality; 2. we present a comprehensive evaluation of various TLM S on this task, performed by comparing them to a strong distributional baseline; 3. we conduct further analysis aimed at identifying the potential limitations of TLM S as models of GEK. Our results are relevant for researchers interested in assessing the linguistic abilities of TLM S, as well as those working on applicat"
2021.starsem-1.1,2020.aacl-main.26,1,0.745247,"ected by these variations by design, since its predictions are based on semantic roles derived from the syntactic analysis of the sentence, which is explicitly provided to the model. 6 designed for this task, DTFit. Results show that TLM S scores positively correlate with human judgments. However, they do not significantly outperform the distributional prototype-based model (SDM) that we selected for comparison. This confirms the ability of SDM to dynamically update the semantic representation of a sentence, which was recently shown for the challenging task of logical metonymy interpretation (Rambelli et al., 2020). However, we decided to go beyond the simple evaluation against human judgments. We carried out several additional small-scale experiments with the specific aim to understand which factors could affect the predictions of TLM S. The results suggest that models are often too dependent on what they observe during training and lack some key aspects of human event knowledge. In particular, we observed that, in some cases, they are unable to compose all elements of the input to make predictions, and they tend to rely more on salient local associations between words. However, further analysis is nee"
2021.starsem-1.1,D17-1068,1,0.776185,"ilities of TLM S, as well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that differ only for one element, which can be either a typical or atypical filler of a given role in the event described by the tuple (cf. Table 1). The dataset includes tuples of different lengths, and the typicality of a given argument de"
2021.starsem-1.1,W16-2518,0,0.014262,"ing the linguistic abilities of TLM S, as well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that differ only for one element, which can be either a typical or atypical filler of a given role in the event described by the tuple (cf. Table 1). The dataset includes tuples of different lengths, and the typicality o"
2021.starsem-1.1,D16-1017,0,0.0195321,"ic is checking the report), and the task is to assign a higher thematic fit/typicality score to the former. Notice that the two sentences differ only for one argument, and that the “atypical” one might, however, be a common filler with respect to the verb target role (e.g., report is a typical patient for check, it is just less plausible in combination with mechanic as an agent). Several models have tried to tackle the “dynamic” version of the thematic fit task, either based on classical distributional spaces (Chersoni et al., 2016, 2019) or on more sophisticated neural network architectures (Tilk et al., 2016; Hong et al., 2018). On the evaluation side, those works made use of the experimental materials of the study by Lenci (2011), which are, however, limited to agentverb-patient triples. The recently-introduced DTFit dataset (Vassallo et al., 2018) is, in comparison, larger in size and provides more variety of fillers and roles (including instruments, locations and time). Other studies introduced larger datasets, but focused on more specific notions of event plausibility (e.g. the plausibility depending on the physical properties of the participants) (Wang et al., 2018; Porada et al., 2019; Ko e"
2021.starsem-1.1,E09-1094,0,0.0557104,"stributional baseline; 3. we conduct further analysis aimed at identifying the potential limitations of TLM S as models of GEK. Our results are relevant for researchers interested in assessing the linguistic abilities of TLM S, as well as those working on applications involving TLM S, such as text generation. 2 Related Work In its classical form, the thematic fit estimation task consists in comparing a candidate argument or filler (e.g., wine) with the typical fillers of a given verb role (e.g., agent, patient, etc.), either in the form of exemplars previously attested in a corpus (Erk, 2007; Vandekerckhove et al., 2009; Erk et al., 2010) or in the form of a vector-based prototype (Baroni and Lenci, 2010; Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015a,b; Sayeed et al., 2016; Santus et al., 2017; Chersoni et al., 2020). Additionally, recent studies explored the use of masked language modeling with BERT for scoring the candidate arguments (Metheniti et al., 3 3.1 Experimental Settings Dataset The DTFit (Vassallo et al., 2018) dataset has been specifically designed for the evaluation of dynamic 2 thematic fit. 1 The dataset contains pairs of tuples that differ only for one element, which"
blache-etal-2008-creating,W99-0302,0,\N,Missing
blache-etal-2010-otim,bigi-etal-2010-automatic,1,\N,Missing
C02-1104,C90-2004,1,0.78346,"Missing"
C02-1104,W01-1820,1,0.883361,"Missing"
C02-1104,P01-1024,0,0.054928,"Missing"
C02-1104,1995.iwpt-1.15,0,0.0913783,"Missing"
C02-1104,P01-1045,0,0.0638288,"Missing"
C02-1104,P90-1005,0,0.0688542,"escribe the parsing technique and the different approaches used for shallow and deep parsing. We address in particular in this section some complexity aspects illustrating the properties of the parsing techniques and we propose an evaluation over a corpus. In the third part, we illustrate the respective characteristics of the different approaches in describing for the same example the consequences of tuning the parse granularity. We conclude in presenting some perspectives for such a technique. 1 Property Grammars The notion of constraints is of deep importance in linguistics, see for example Maruyama (1990), Pollard (1994), Sag (1999). Recent theories (from the constraint-based paradigm to the principle and parameters one) rely on this notion. One of the main interests in using constraints comes from the fact that it becomes possible to represent any kind of information (very general as well as local or contextual one) by means of a unique device. We present in this section a formalism, called Property Grammars, described in Bès (1999) or Blache (2001), that makes it possible to conceive and represent all linguistic information in terms of constraints over linguistic objects. In this approach, c"
C10-2008,W10-1829,1,0.907692,"(Allwood, 2005), both integrating McNeill’s gesture description (McNeill05). The following structure encodes the description of gesture phases, phrases (representing different semiotic types), the hand shape as well as its orientation, the gesture space, and the possible contact with bodies or objects. A last feature also describes the movement itself: trajectory, quality (fast, normal or slow) and amplitude (small, medium and large). M OVEMENT A MPLITUDE Amplitude_Type Q UALITY quality_Type Application We have experimented this modeling in the complete annotation of a multimodal corpus (see (Blache, 2010)). In this project, a complete TFS model has been first designed, covering all the different domains (prosody, syntax, gestures, discourse, etc.). From this model, the annotations have been created, leading to a 3-hours corpus of narrative dialogs, fully transcribed. The corpus is fully annotated for some domains (phonetics, prosody and syntax) and partly for others (gestures, discourse, disfluencies, specific phenomena). The result is one of the first large annotated multimodal corpus. 3 Graphs for Multimodal Annotation Graphs are frequently used in the representation of complex information,"
C10-2008,bird-etal-2000-atlas,0,0.0941573,"Missing"
C10-2008,J00-2002,0,0.0943733,"Missing"
C10-2008,W07-1524,0,0.0556121,"Missing"
C10-2008,W07-1501,0,0.0839278,"Missing"
C10-2008,wittenburg-etal-2006-elan,0,\N,Missing
C10-2008,W09-3004,0,\N,Missing
C90-2004,P81-1022,0,0.0701136,"Missing"
C90-2004,P86-1006,0,0.0324644,"Missing"
C90-2004,C86-1050,0,0.0749267,"Missing"
C90-2004,C88-1066,0,\N,Missing
C90-2004,J85-4001,0,\N,Missing
C90-2004,P83-1015,0,\N,Missing
C92-1016,C90-2004,1,0.897457,"Missing"
C92-1016,E91-1011,0,\N,Missing
C92-1016,E91-1030,0,\N,Missing
C92-1016,P83-1021,0,\N,Missing
C92-1016,P84-1008,0,\N,Missing
C98-1019,1997.iwpt-1.5,1,0.813033,"Missing"
C98-1019,C90-2018,0,0.756509,"Missing"
C98-1019,1995.iwpt-1.13,0,0.0634997,"Missing"
C98-1019,C96-1076,0,0.109186,"Missing"
C98-1019,P84-1008,0,0.166324,"Missing"
C98-1019,C94-1039,0,0.06464,"Missing"
C98-1019,J92-4004,0,0.0637519,"Missing"
C98-1019,J96-4005,0,\N,Missing
D16-1205,N09-1003,0,0.141123,"Missing"
D16-1205,J10-4006,1,0.880419,"sts that verbs activate expectations on their typical argument nouns and vice versa (McRae et al., 1998; McRae et al., 2005) and nouns do the same with other nouns occurring as co-arguments in the same events (Hare et al., 2009; Bicknell et al., 2010). Experimental subjects seem to exploit a rich event knowledge to activate or inhibit dynamically the representations of the potential arguments. This phenomenon, generally referred to as thematic fit (McRae et al., 1998), supports the idea of a mental lexicon arranged as a web of mutual expectations. Some past works in computational linguistics (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Greenberg et al., 2015) modeled thematic fit estimations by means of dependencybased or of thematic roles-based DSMs. However, these semantic spaces are built similarly to traditional DSMs as they split verb arguments into separate vector dimensions. By using syntactic-semantic links, they encode the relation between an event and each of its participants, but they do not encode directly the relation between participants co-occurring in the same event. Another trend of studies in the NLP community aimed at the introduction of richer contextual features i"
D16-1205,J90-1003,0,0.591713,"ical association measure. 4 4.1 Evaluation Corpus and DSMs We trained our DSMs on the RCV1 corpus, which contains approximately 150 million words (Lewis et al., 2004). The corpus was tagged with the tagger described in Dell’Orletta (2009) and dependencyparsed with DeSR (Attardi et al., 2009). RCV1 was chosen for two reasons: i) to show that our joint context-based representation can deal with data 1969 sparseness even with a training corpus of limited size; ii) to allow a comparison with the results reported by Melamud et al. (2014). All DSMs adopt Positive Pointwise Mutual Information (PPMI; Church and Hanks (1990)) as a context weighting scheme and vary according to three main parameters: i) type of contexts; ii) number of dimensions; iii) application of Singular Value Decomposition (SVD; see Landauer et al. (1998)). For what concerns the first parameter, we developed three types of DSMs: a) traditional bag-ofwords DSMs, where the features are content words co-occurring with the target in a window of width 2; b) dependency-based DSMs, where the features are words in a direct dependency relation with the target; c) joint context-based DSMs, using the joint features described in the previous section. The"
D16-1205,N15-1003,0,0.0186207,"nouns and vice versa (McRae et al., 1998; McRae et al., 2005) and nouns do the same with other nouns occurring as co-arguments in the same events (Hare et al., 2009; Bicknell et al., 2010). Experimental subjects seem to exploit a rich event knowledge to activate or inhibit dynamically the representations of the potential arguments. This phenomenon, generally referred to as thematic fit (McRae et al., 1998), supports the idea of a mental lexicon arranged as a web of mutual expectations. Some past works in computational linguistics (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Greenberg et al., 2015) modeled thematic fit estimations by means of dependencybased or of thematic roles-based DSMs. However, these semantic spaces are built similarly to traditional DSMs as they split verb arguments into separate vector dimensions. By using syntactic-semantic links, they encode the relation between an event and each of its participants, but they do not encode directly the relation between participants co-occurring in the same event. Another trend of studies in the NLP community aimed at the introduction of richer contextual features in DSMs, mostly based on word windows. The first example was the"
D16-1205,J15-4004,0,0.051174,"l. (2014) have proposed the Probabilistic Distributional Similarity (PDS), based on the intuition that two words, w1 and w2 , are similar if they are likely to occur in each other’s contexts. PDS assigns a high similarity score when both p(w1 |contexts of w2 ) and p(w2 | contexts of w1 ) are high. We tried to test variations of this measure with our representation, but we were not able to achieve satisfying results. Therefore, we report here only the scores with the cosine. 4.3 Datasets The DSMs are evaluated on two test sets: VerbSim (Yang and Powers, 2006) and the verb subset of SimLex-999 (Hill et al., 2015). The former includes 130 verb pairs, while the latter includes 222 verb pairs. Both datasets are annotated with similarity judgements, so we measured the Spearman correlation between them and the scores assigned by the model. The VerbSim dataset allows for comparison with Melamud et al. (2014), since they also evaluated their model on this test set, achieving a Spearman correlation score of 0.616 and outperforming all the baseline methods. The verb subset of SimLex-999, at the best of our knowledge, has never been used as a benchmark dataset for verb similarity. The SimLex dataset is known fo"
D16-1205,W11-0607,1,0.892111,"expectations on their typical argument nouns and vice versa (McRae et al., 1998; McRae et al., 2005) and nouns do the same with other nouns occurring as co-arguments in the same events (Hare et al., 2009; Bicknell et al., 2010). Experimental subjects seem to exploit a rich event knowledge to activate or inhibit dynamically the representations of the potential arguments. This phenomenon, generally referred to as thematic fit (McRae et al., 1998), supports the idea of a mental lexicon arranged as a web of mutual expectations. Some past works in computational linguistics (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Greenberg et al., 2015) modeled thematic fit estimations by means of dependencybased or of thematic roles-based DSMs. However, these semantic spaces are built similarly to traditional DSMs as they split verb arguments into separate vector dimensions. By using syntactic-semantic links, they encode the relation between an event and each of its participants, but they do not encode directly the relation between participants co-occurring in the same event. Another trend of studies in the NLP community aimed at the introduction of richer contextual features in DSMs, mostl"
D16-1205,W14-1619,0,0.128219,"measure such proximity, even though other measures have been proposed (Weeds et al., 2004; Santus et al., 2016). Most of DSMs adopt a bag-of-words approach, that is they turn a text span (i.e., a word window or a parsed sentence) into a set of words and they register separately the co-occurrence of each word with a given target. The problem with this approach is that valuable information concerning word interrelations in a context gets lost, because words co-occurring with a target are treated as independent features. This is why works like Ruiz-Casado et al. (2005), Agirre et al. (2009) and Melamud et al. (2014) proposed to introduce richer contexts in distributional spaces, by using entire word windows as features. These richer contexts proved to be helpful to semantically represent verbs, which are characterized by highly context-sensitive meanings, and complex argument structures. In fact, two verbs may share independent words as features despite being very dissimilar from the semantic point of view. For instance kill and heal share the same object nouns in The doctor healed the patient and the The poison killed the patient, but are highly different if we consider their joint dependencies as a sin"
D16-1205,Y16-2021,1,0.794205,"pus. 1 Introduction Distributional Semantic Models (DSMs) rely on the Distributional Hypothesis (Harris, 1954; Sahlgren, 2008), stating that words occurring in similar contexts have similar meanings. On such theoretical grounds, word co-occurrences extracted from corpora are used to build semantic representations in the form of vectors, which have become very popular in the NLP community. Proximity between word vectors is taken as an index of meaning similarity, and vector cosine is generally adopted to measure such proximity, even though other measures have been proposed (Weeds et al., 2004; Santus et al., 2016). Most of DSMs adopt a bag-of-words approach, that is they turn a text span (i.e., a word window or a parsed sentence) into a set of words and they register separately the co-occurrence of each word with a given target. The problem with this approach is that valuable information concerning word interrelations in a context gets lost, because words co-occurring with a target are treated as independent features. This is why works like Ruiz-Casado et al. (2005), Agirre et al. (2009) and Melamud et al. (2014) proposed to introduce richer contexts in distributional spaces, by using entire word windo"
D16-1205,C04-1146,0,0.156904,"Missing"
D16-1205,N15-1050,0,\N,Missing
D17-1068,W16-2506,0,0.0164198,"ler vectors for that verb-specific role. Differently from Baroni and Lenci, the core and novel aspect of our proposal, described in the following subsections, is that we do not simply measure the correlation between all the features of candidate and prototype vectors (as vector cosine would do on unsorted vectors), but rather we rank and filter the features, computing the weighted overlap with a rank-based similarity measure inspired by AP Syn, a recent proposal by Santus 5 For an overview on the limitations of vector cosine, see: Li and Han (2013); Dinu et al. (2015); Schnabel et al. (2015); Faruqui et al. (2016); Santus et al. (2016a). 6 An early proposal going in this direction is the predication theory by Kintsch (2001), which exploited Latent Semantic Analysis to select only the vector features that are appropriate for predicate-argument composition. 7 See also the so-called ’strong version’ of the Distributional Hypothesis (Miller and Charles, 1991; Lenci, 2008). 650 et al. (2016a,b,c) which has shown interesting results in synonymy detection and similarity estimation. As we will show in the next sections, the new metric assigns high scores to candidate fillers sharing many salient contexts with"
D17-1068,W15-1106,0,0.649512,"redictor variable allowing to disambiguate between possible structural analyses.1 More in general, thematic fit is considered as a key factor in a variety of studies concerned with structural ambiguity (Vandekerckhove et al., 2009). Starting from the work of Erk et al. (2010), several distributional semantic methods have been proposed to compute the extent to which nouns fulfill the requirements of verb-specific thematic roles, and their performances have been evaluated against human-generated judgments (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Sayeed et al., 2015, 2016; Greenberg et al., 2015a,b). Most research on thematic fit estimation has focused on count-based vector representations (as distinguished from prediction-based vectors).2 Indeed, in their comparison between highdimensional explicit vectors and low-dimensional neural embeddings, Baroni et al. (2014) found that thematic fit estimation is the only benchmark on which prediction models are lagging behind stateof-the-art performance. This is consistent with Sayeed et al. (2016)’s observation that “thematic fit modeling is particularly sensitive to linguistic detail and interpretability of the vector space”. The present wo"
D17-1068,P14-1023,0,0.20658,"several distributional semantic methods have been proposed to compute the extent to which nouns fulfill the requirements of verb-specific thematic roles, and their performances have been evaluated against human-generated judgments (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Sayeed et al., 2015, 2016; Greenberg et al., 2015a,b). Most research on thematic fit estimation has focused on count-based vector representations (as distinguished from prediction-based vectors).2 Indeed, in their comparison between highdimensional explicit vectors and low-dimensional neural embeddings, Baroni et al. (2014) found that thematic fit estimation is the only benchmark on which prediction models are lagging behind stateof-the-art performance. This is consistent with Sayeed et al. (2016)’s observation that “thematic fit modeling is particularly sensitive to linguistic detail and interpretability of the vector space”. The present work sets itself among the unsupervised approaches to thematic fit estimation. By relying on explicit and interpretable count-based vector representations, we propose a simple, cognitively-inspired, and efficient thematic fit model using information extracted from dependency-pa"
D17-1068,N15-1003,0,0.495651,"redictor variable allowing to disambiguate between possible structural analyses.1 More in general, thematic fit is considered as a key factor in a variety of studies concerned with structural ambiguity (Vandekerckhove et al., 2009). Starting from the work of Erk et al. (2010), several distributional semantic methods have been proposed to compute the extent to which nouns fulfill the requirements of verb-specific thematic roles, and their performances have been evaluated against human-generated judgments (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Sayeed et al., 2015, 2016; Greenberg et al., 2015a,b). Most research on thematic fit estimation has focused on count-based vector representations (as distinguished from prediction-based vectors).2 Indeed, in their comparison between highdimensional explicit vectors and low-dimensional neural embeddings, Baroni et al. (2014) found that thematic fit estimation is the only benchmark on which prediction models are lagging behind stateof-the-art performance. This is consistent with Sayeed et al. (2016)’s observation that “thematic fit modeling is particularly sensitive to linguistic detail and interpretability of the vector space”. The present wo"
D17-1068,J10-4006,1,0.0718801,"tensively used in sentence comprehension studies on constraint-based models, mainly as a predictor variable allowing to disambiguate between possible structural analyses.1 More in general, thematic fit is considered as a key factor in a variety of studies concerned with structural ambiguity (Vandekerckhove et al., 2009). Starting from the work of Erk et al. (2010), several distributional semantic methods have been proposed to compute the extent to which nouns fulfill the requirements of verb-specific thematic roles, and their performances have been evaluated against human-generated judgments (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Sayeed et al., 2015, 2016; Greenberg et al., 2015a,b). Most research on thematic fit estimation has focused on count-based vector representations (as distinguished from prediction-based vectors).2 Indeed, in their comparison between highdimensional explicit vectors and low-dimensional neural embeddings, Baroni et al. (2014) found that thematic fit estimation is the only benchmark on which prediction models are lagging behind stateof-the-art performance. This is consistent with Sayeed et al. (2016)’s observation that “thematic fit modeling is particularl"
D17-1068,W11-0607,1,0.856257,"ce comprehension studies on constraint-based models, mainly as a predictor variable allowing to disambiguate between possible structural analyses.1 More in general, thematic fit is considered as a key factor in a variety of studies concerned with structural ambiguity (Vandekerckhove et al., 2009). Starting from the work of Erk et al. (2010), several distributional semantic methods have been proposed to compute the extent to which nouns fulfill the requirements of verb-specific thematic roles, and their performances have been evaluated against human-generated judgments (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Sayeed et al., 2015, 2016; Greenberg et al., 2015a,b). Most research on thematic fit estimation has focused on count-based vector representations (as distinguished from prediction-based vectors).2 Indeed, in their comparison between highdimensional explicit vectors and low-dimensional neural embeddings, Baroni et al. (2014) found that thematic fit estimation is the only benchmark on which prediction models are lagging behind stateof-the-art performance. This is consistent with Sayeed et al. (2016)’s observation that “thematic fit modeling is particularly sensitive t"
D17-1068,P07-1028,0,0.0834578,"ning a performance comparable to Lenci (2011). Related Work Erk et al. (2010) were, at the best of our knowledge, the first authors to measure the correlation between human-elicited thematic fit ratings and the scores assigned by a syntax-based Distributional Semantic Model (DSM). More specifically, their gold standard consisted of the human judgments collected by McRae et al. (1998) and Pad´o (2007). The plausibility of each verb-filler pair was computed as the similarity between new candidate nouns and previously attested exemplars for each specific verb-role pairing (as already proposed in Erk (2007)). Baroni and Lenci (2010) evaluated their Distributional Memory (henceforth DM)4 framework on the same datasets, adopting an approach to the task that has become dominant in the literature: for each verb role, they built a prototype vector by averaging the dependency-based vectors of its most typical fillers. The higher the similarity of a noun with a role prototype, the higher its plausibility as a filler for that role. Lenci (2011) has later extended the model to account for the dynamic update of the expectations on an argument, depending on how another role is filled. By using the same DM"
D17-1068,J10-4007,0,0.269326,"Missing"
D17-1068,W16-2518,0,0.70671,"have been evaluated against human-generated judgments (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Sayeed et al., 2015, 2016; Greenberg et al., 2015a,b). Most research on thematic fit estimation has focused on count-based vector representations (as distinguished from prediction-based vectors).2 Indeed, in their comparison between highdimensional explicit vectors and low-dimensional neural embeddings, Baroni et al. (2014) found that thematic fit estimation is the only benchmark on which prediction models are lagging behind stateof-the-art performance. This is consistent with Sayeed et al. (2016)’s observation that “thematic fit modeling is particularly sensitive to linguistic detail and interpretability of the vector space”. The present work sets itself among the unsupervised approaches to thematic fit estimation. By relying on explicit and interpretable count-based vector representations, we propose a simple, cognitively-inspired, and efficient thematic fit model using information extracted from dependency-parsed corpora. The key features of our proposal are a) prototypical representations of verb-specific thematic roles, based on feature weighting and filtering of second order cont"
D17-1068,D15-1036,0,0.0134542,"of the most typical filler vectors for that verb-specific role. Differently from Baroni and Lenci, the core and novel aspect of our proposal, described in the following subsections, is that we do not simply measure the correlation between all the features of candidate and prototype vectors (as vector cosine would do on unsorted vectors), but rather we rank and filter the features, computing the weighted overlap with a rank-based similarity measure inspired by AP Syn, a recent proposal by Santus 5 For an overview on the limitations of vector cosine, see: Li and Han (2013); Dinu et al. (2015); Schnabel et al. (2015); Faruqui et al. (2016); Santus et al. (2016a). 6 An early proposal going in this direction is the predication theory by Kintsch (2001), which exploited Latent Semantic Analysis to select only the vector features that are appropriate for predicate-argument composition. 7 See also the so-called ’strong version’ of the Distributional Hypothesis (Miller and Charles, 1991; Lenci, 2008). 650 et al. (2016a,b,c) which has shown interesting results in synonymy detection and similarity estimation. As we will show in the next sections, the new metric assigns high scores to candidate fillers sharing many"
D17-1068,D16-1017,0,0.762572,"s they computed the scores also for the instruments and for the locations of the Ferretti datasets (Ferretti et al., 2001). Greenberg et al. (2015a,b) further developed the TypeDM and the role-based models, investigating the effects of verb polysemy on human thematic fit judgments and introducing a hierarchical agglomerative clustering algorithm into the prototype creation process. Their goal was to cluster together typical fillers into multiple prototypes, corresponding to different verb senses, and their results showed constant improvements of the performance of the DM-based model. Finally, Tilk et al. (2016) presented two neural network architectures for generating probability distributions over selectional preferences for each thematic role. Their models took advantage of supervised training on two role-labeled corpora to optimize the distributional representation for thematic fit modeling, and managed to obtain significant improvements over the other systems on almost all the evaluation datasets. They also evaluated their model on the task of composing and updating verb argument expectations, obtaining a performance comparable to Lenci (2011). Related Work Erk et al. (2010) were, at the best of"
D17-1068,E09-1094,0,0.123359,"rlap Enrico Santus1 , Emmanuele Chersoni2 , Alessandro Lenci3 and Philippe Blache2 enrico santus@sutd.edu.sg emmanuelechersoni@gmail.com alessandro.lenci@unipi.it philippe.blache@univ-amu.fr 1 Singapore University of Technology and Design 2 Aix-Marseille University 3 University of Pisa Abstract has been extensively used in sentence comprehension studies on constraint-based models, mainly as a predictor variable allowing to disambiguate between possible structural analyses.1 More in general, thematic fit is considered as a key factor in a variety of studies concerned with structural ambiguity (Vandekerckhove et al., 2009). Starting from the work of Erk et al. (2010), several distributional semantic methods have been proposed to compute the extent to which nouns fulfill the requirements of verb-specific thematic roles, and their performances have been evaluated against human-generated judgments (Baroni and Lenci, 2010; Lenci, 2011; Sayeed and Demberg, 2014; Sayeed et al., 2015, 2016; Greenberg et al., 2015a,b). Most research on thematic fit estimation has focused on count-based vector representations (as distinguished from prediction-based vectors).2 Indeed, in their comparison between highdimensional explicit"
D17-1068,Y16-2021,1,0.913379,"rb-specific role. Differently from Baroni and Lenci, the core and novel aspect of our proposal, described in the following subsections, is that we do not simply measure the correlation between all the features of candidate and prototype vectors (as vector cosine would do on unsorted vectors), but rather we rank and filter the features, computing the weighted overlap with a rank-based similarity measure inspired by AP Syn, a recent proposal by Santus 5 For an overview on the limitations of vector cosine, see: Li and Han (2013); Dinu et al. (2015); Schnabel et al. (2015); Faruqui et al. (2016); Santus et al. (2016a). 6 An early proposal going in this direction is the predication theory by Kintsch (2001), which exploited Latent Semantic Analysis to select only the vector features that are appropriate for predicate-argument composition. 7 See also the so-called ’strong version’ of the Distributional Hypothesis (Miller and Charles, 1991; Lenci, 2008). 650 et al. (2016a,b,c) which has shown interesting results in synonymy detection and similarity estimation. As we will show in the next sections, the new metric assigns high scores to candidate fillers sharing many salient contexts with the verb-specific rol"
D17-1068,L16-1723,1,0.934831,"rb-specific role. Differently from Baroni and Lenci, the core and novel aspect of our proposal, described in the following subsections, is that we do not simply measure the correlation between all the features of candidate and prototype vectors (as vector cosine would do on unsorted vectors), but rather we rank and filter the features, computing the weighted overlap with a rank-based similarity measure inspired by AP Syn, a recent proposal by Santus 5 For an overview on the limitations of vector cosine, see: Li and Han (2013); Dinu et al. (2015); Schnabel et al. (2015); Faruqui et al. (2016); Santus et al. (2016a). 6 An early proposal going in this direction is the predication theory by Kintsch (2001), which exploited Latent Semantic Analysis to select only the vector features that are appropriate for predicate-argument composition. 7 See also the so-called ’strong version’ of the Distributional Hypothesis (Miller and Charles, 1991; Lenci, 2008). 650 et al. (2016a,b,c) which has shown interesting results in synonymy detection and similarity estimation. As we will show in the next sections, the new metric assigns high scores to candidate fillers sharing many salient contexts with the verb-specific rol"
D17-1068,J90-1003,0,\N,Missing
D17-1068,Q15-1016,0,\N,Missing
F12-2023,P06-1008,1,0.87755,"Missing"
F12-2023,candito-etal-2010-statistical,0,0.0762432,"Missing"
F12-2023,W07-1501,0,0.0675547,"Missing"
F12-2023,C94-1097,0,0.0450991,"Missing"
F13-1017,Y11-1017,1,0.879304,"Missing"
F13-1017,N01-1021,0,0.778927,"Missing"
F13-1017,W12-4903,1,0.879631,"Missing"
F14-2026,J05-3002,0,0.125834,"Missing"
F14-2026,P10-1095,0,0.0600952,"Missing"
F14-2026,I05-2004,0,0.0963342,"Missing"
L16-1245,C08-1085,0,0.0780084,"Missing"
L16-1245,E12-2021,0,0.0574362,"Missing"
L16-1245,P13-4001,0,0.0319782,"Missing"
L16-1245,W12-4903,1,0.837408,"uncts of different types, as well as enumerations. Other kinds of errors come, classically, from ambiguous attachments. Some of the errors concern the labelling. For example VPinf introduced by a Prep should be encoded as a PP plus a VPinf. 4.1. Text Selector The Text Selector is a tool helping in the selection of the texts, on the form of HTML files each containing 10 texts to evaluate. Each unit presents the book description and the text, segmented into sentences. It also proposes an evaluation form (containing check boxes and drop-down lists), 5 Our previous study on morpho-syntax effects (Blache and Rauzy, 2012) included 10000 tokens). 1548 and the list of unknown words, to be manually tagged. This interface (see figure 6) makes it possible to easily correct different types of errors, including sentence segmentation as well as metadata. Using autonomous HTML files makes easier the distribution of the revision work between several annotators. It does not require any particular environment (files being edited directly in a browser), neither a connection to a server. The revision tool relies on an adaptation of a TiddlyWiki6 enriched with scripts for adding extra information to the texts. 4.3. Tree edit"
L16-1370,F12-2023,1,0.843497,"ic characteristics of various languages using the complete grammar (independently of the formalism, constituents or dependencies). On the other hand, it is possible to compare some specific properties, in accordance with established practices in typology. For example, a classical typology consists in studying the verb/arguments relations and their linearity. We propose to induce from the treebanks some properties used to settle typologies. This properties are identified in the frame of Property Grammar. Our tool focuses on 4 types of properties governing syntactic components, as described in (Blache and Rauzy, 2012). Linearity : two components (A,B) have a linearity relation when the occurrence order of these two components is always the same. Requirement : two components (A,B) have a requirement relation when the presence of one requires the presence of the other. Exclusion : two components (A,B) have an exclusion relation when they do not occur together. Unicity : a component A has an unicity property if it never occurs several times in the RHS of the rules with a same LHS. We note a property as a 4-tuple p =< C, rel, A, B > where C is the context (i.e. the LHS component), rel one of the relations (pre"
L16-1370,de-marneffe-etal-2014-universal,0,0.0514428,"Missing"
L16-1370,petrov-etal-2012-universal,0,0.0413342,": we find in a same branch the romance languages (es, it and fr), two of the germanic languages (de, sv) — English is grouped with the romance languages before joining the germanic branch — or the two uralic languages (fi, hu) (see table 3 for language families and features). 3. (1) (2) Experiment This experiment relies on the first version of the Universal Dependency Treebank (Nivre et al., 2015), a family of dependency treebanks for 10 languages (Czech, German, English, Spanish, Finnish, French, Irish, Hungarian, Italian and Swedish) using an unique tagset : 17 Part-Of-Speech tags based on (Petrov et al., 2012), and 40 standardized dependencies relations described in (de Marneffe et al., 2014). As all languages use a common tagset, we can compare the properties extracted from each treebank and define a similarity between two languages based on the proportion of common properties. We build a hierarchical clustering of the 10 languages of the Universal Dependency Treebank (using the hclust function of R). The figure 5 shows the resulting dendrograms either using all types of properties or only the linearity properties (precede). If the first clustering, using all properties does not allow to bring out"
L18-1467,bigi-2012-sppas-tool,0,0.0287881,"Missing"
L18-1467,P16-4012,0,0.0298413,"Missing"
L18-1467,sloetjes-wittenburg-2008-annotation,0,0.0480382,"Missing"
P06-1008,W06-2304,1,0.877141,"Missing"
P06-1008,W98-0509,0,\N,Missing
P98-1019,1997.iwpt-1.5,1,0.882886,"Missing"
P98-1019,C90-2018,0,0.721968,"Missing"
P98-1019,1995.iwpt-1.13,0,0.0650774,"Missing"
P98-1019,C96-1076,0,0.187062,"Missing"
P98-1019,P84-1008,0,0.172744,"Missing"
P98-1019,C94-1039,0,0.064503,"Missing"
P98-1019,J92-4004,0,0.0644227,"Missing"
P98-1019,J96-4005,0,\N,Missing
S17-1021,J10-4006,1,0.83231,"et al. (2001) for the reading times at the type-shifted noun (both conditions engendered significantly longer reading times than the preferred condition). k most salient subjects of V (e.g., the cosine between the vector of author and the centroid vector of the most salient objects of write); finally, θO,S is the cosine between the vector of O and the centroid vector built out of the k most salient direct objects occurring in events whose subject is S (e.g., the cosine between the vector of book and the prototype vector of the most salient objects of events whose subject is author). Following Baroni and Lenci (2010), we used LMI scores to identify the most salient fillers of each target-specific syntactic slot and we fixed k = 20. • σe is the salience score of the triple s, and it corresponds to the sum of the activation scores of i.) the full event represented by the triple and of ii.) the sub-events corresponding to all the partial combinations of the verb and its arguments. Each activation score is the conditional probability of the event given a lexical item in the test tuple. p-values LOW TYP MET X σ ei LOW TYP 0.31 Table 2: Results of the pairwise post-hoc comparisons for the three conditions on th"
S17-1021,W16-4102,1,0.734343,"ctures, with contributions from the context; iii.) Control is responsible for relating language to joint action and social interaction. Similarly to your book (= eating). The event retrieval cannot be explained in terms of qualia structures, as it is unlikely that the lexical entry for book includes something related to eating-events. 2 It should be pointed out that, unlike relevance theory which conceives world knowledge and linguistic knowledge as separate modules, GEK includes both linguistic and extralinguistic information. 3 A previous version of this model has already been introduced in Chersoni et al. (2016a), the main difference being the way the complexity score component based on Memory was computed (see section 5 and 6 of the 2016 paper). Moreover, the model was applied to a different task (i.e., the computation of context-sensitive argument typicality). 169 enriched forms of compositionality (Jackendoff, 1997), both being instances of the same general model of sentence processing. MUC, we argue that the comprehension of a sentence is an incremental process driven by the goal of constructing a coherent semantic representation of the event the speaker intends to communicate. Our model rests o"
S17-1021,D16-1205,1,0.887106,"Missing"
S17-1021,P09-3001,0,0.470032,"ent combination, it is read faster and it is more difficult to inhibit in a probe recognition task. The authors explained their results in the light of the words-ascues paradigm (Elman, 2009, 2014), which claims that the words in the mental lexicon are cues to event knowledge modulating language comprehension in an incremental fashion. Research in computational semantics has focused on two different aspects of the phenomenon: the first one is the retrieval of the covert event, which has been approached by means of either probabilistic methods (Lapata and Lascarides, 2003; Lapata et al., 2003; Shutova, 2009) or of distributional similarity-based thematic fit estimations (Zarcone et al., 2012), whereas the second aspect concerns modeling the experimental data about processing costs. Zarcone et al. (2013) showed that a distributional model of verb-object thematic fit can reproduce the reading times differences in the experimental conditions found by McElree et al. (2001) and Traxler et al. (2002). Their merits notwithstanding, a limit of the former studies is that they did not try to build a single model to account for both aspects involved in logical metonymy. The goal of this paper is twofold. Fi"
S17-1021,W13-0216,1,0.836998,"Missing"
S17-1021,J03-2004,0,0.65244,"he covert event is typical for that specific argument combination, it is read faster and it is more difficult to inhibit in a probe recognition task. The authors explained their results in the light of the words-ascues paradigm (Elman, 2009, 2014), which claims that the words in the mental lexicon are cues to event knowledge modulating language comprehension in an incremental fashion. Research in computational semantics has focused on two different aspects of the phenomenon: the first one is the retrieval of the covert event, which has been approached by means of either probabilistic methods (Lapata and Lascarides, 2003; Lapata et al., 2003; Shutova, 2009) or of distributional similarity-based thematic fit estimations (Zarcone et al., 2012), whereas the second aspect concerns modeling the experimental data about processing costs. Zarcone et al. (2013) showed that a distributional model of verb-object thematic fit can reproduce the reading times differences in the experimental conditions found by McElree et al. (2001) and Traxler et al. (2002). Their merits notwithstanding, a limit of the former studies is that they did not try to build a single model to account for both aspects involved in logical metonymy."
S17-1021,W12-1707,0,0.305975,"Missing"
seinturier-etal-2012-ontological,W07-1501,0,\N,Missing
seinturier-etal-2012-ontological,W10-1829,1,\N,Missing
sitbon-etal-2008-evaluating,sekine-etal-2002-extended,0,\N,Missing
sitbon-etal-2008-evaluating,C02-1109,0,\N,Missing
sitbon-etal-2008-evaluation,J90-1003,0,\N,Missing
sitbon-etal-2008-evaluation,P06-1036,0,\N,Missing
sitbon-etal-2008-evaluation,W04-2117,0,\N,Missing
van-rullen-blache-2002-evaluation,W01-1820,1,\N,Missing
vanrullen-etal-2006-constraint,gendner-etal-2002-protocol,0,\N,Missing
vanrullen-etal-2006-constraint,vilnat-etal-2004-ongoing,0,\N,Missing
vanrullen-etal-2006-constraint,van-rullen-blache-2002-evaluation,1,\N,Missing
W03-3004,P90-1003,0,0.00938256,"determiner both in the signal thanks to a temporal indexing and in the sentence. Such a multiple anchoring makes it possible to refer in di erent ways to the same object. The implementation of interaction constraints controlling the interface between the linguistic domains relies on such anchoring. More precisely, it consists in expressing relations (typically cooccurrency) between objects coming from di erent domains and speci ed by means of a characterization (i.e. a set of properties) and an anchor. The following example shows an interaction constraints implementing a relation described in [Bear90]. It stipulates that no major breaks can separate two juxtaposed sisters connected with a complementation relation ( ). In such a constraint, an object simply has to be located and described by means of a characterization (that can be represented with any formalism). ; 2 (1) 3 33 cat c1 6 7 &quot; 6 # 7 66 7 7 7 6 t1 , t2 64anch temp 577 6 6 77 6 pos i, j 6 77 6 62 7 6 37 6 77 6char 2 6 cat c&quot; 7 6 # 77 66 6 777 temp t3 , t4 64 6 577 6 anch 6 7 4 55 pos k, l 4 dom synt 22 dep c2 ; 2 6, 3 3 cat break 6 7 &quot; 6 # 7 77 6char 6 temp t2 , t3 4anch 55 4 dom pros 2 pos j, k c1 Interaction constraints can rep"
W03-3004,W01-1820,1,0.897136,"Missing"
W03-3004,J00-2002,0,0.0715965,"Missing"
W06-2304,J98-4004,0,0.0155187,"t solutions have been experimented, depending on the kind of material to be parsed or the kind of application: in some cases, superficial information such as bracketing is enough whereas in other situations, the system needs more details. The question of robustness, and more generally the parsing strategy, is addressed differently according to these parameters. Classically, three families of solutions are proposed: - - Implementing recovering mechanisms, triggering specific treatments in case of error (cf. [Boulier05]) Controlling the parsing process by means of probabilistic information (cf. [Johnson98]) Controlling deep parsers by means of shallow parsing techniques (cf. [Crysmann02], [UszKoreit02], [Marimon02]) The last kind of control mechanism consists in adapting the system to the material to be parsed. This can be done in different ways: - Reducing the complexity of the output Controlling the parsing strategy Training and adapting the system to the type of input - In the first case, the idea consists in building structures with little information, even underspecified (which means the possibility of building partial structures). We find in this family the different shallow parsing techn"
W06-2304,P90-1005,0,0.0629583,"al or non grammatical input. We give in the remaining of the section a brief overview of GP characteristics We propose in this paper a parsing technique relying on a constraint-based framework being both efficient and robust without need to modify the underlying formalism or the process. The notion of constraints is used in many different ways in NLP systems. They can be a very basic filtering process as proposed by Constraint Grammars (see [Karlsson90]) or can be part to an actual theory as with HPSG (see [Sag03]), the Optimality Theory (see [Prince03]) or Constraint Dependency Grammars (cf. [Maruyama90]). Our approach is very different: all information is represented by means of constraints; they do not stipulate requirements on the syntactic structure (as in the above cited approaches) but represent directly syntactic knowledge. In this approach, robustness is intrinsic to the formalism in the sense that what is built is not a structure of the input (for example under the form of a tree) but a description of its properties. The parsing mechanism can then be seen as a satisfaction process instead of a derivational one. Moreover, it becomes possible, whatever the form of the input, to give it"
W06-2304,W00-0726,0,0.139644,"Missing"
W06-2304,W05-1501,0,0.0665552,"Missing"
W06-2304,C02-1071,0,\N,Missing
W06-2304,C90-3030,0,\N,Missing
W06-2304,P02-1056,0,\N,Missing
W06-2304,P03-1014,0,\N,Missing
W09-3033,W07-1501,0,\N,Missing
W10-1829,E03-1085,0,0.0395083,"Missing"
W10-1829,bigi-etal-2010-automatic,1,0.844107,"Missing"
W10-1829,J96-2004,0,0.355665,"Missing"
W10-1829,paroubek-etal-2006-data,0,0.0687118,"Missing"
W10-1829,2008.jeptalnrecital-long.29,1,\N,Missing
W12-4903,Y11-1017,1,0.930386,"ribe in this paper a pilot study aiming at developing a high-level resource enriching a treebank with physiological data and complexity measures. This work have been done for French, with several objectives : (1) building a new large resource for French, freely available, associating syntactic information, eye-tracking data and difficulty prediction at different levels (tokens, chunks and phrases) (2) validating a difficulty model for French in the line of what has been done for other languages (Demberg and Keller, 2008), (Boston et al., 2008) relying on a robust surprisal index described in (Blache and Rauzy, 2011). This pilot study, on top of building a new resource, had important side-effects. First, this work led us to examine carefully the question of data analysis. In particular, we found that working with larger units (syntactic chunks) instead of tokens makes it possible to take into consideration the entire set of data. In other words, it is not anymore necessary to eliminate data that are usually considered for different reasons as problematic (tokens ending lines, before punctuations, etc.). This result is important for several reasons. First, it avoids the use of truncated data (which is prob"
W12-4903,N01-1021,0,0.617136,"del applied incrementally, estimating at each word the integration costs. Such models rely on high-level linguistic information, capable of bringing together syntactic and lexical semantic information, as well as integrating frequency information. In such cases, difficulty estimation is done manually, the validation applied only to few examples. Recently, the development of probabilistic NLP techniques opened a new way in difficulty estimation. The idea consists in using the probability of the integration of a word into a partial parse as a predictor for human difficulty. The Surprisal index (Hale, 2001) implements this proposal: the mechanism consists in evaluating at each word the difference between probability of the set of trees before the word and that integrating the word. Several works such as (Demberg and Keller, 2008) have shown that Surprisal can be a predictor for reading time and, as a consequence, for language processing difficulty. The interest in these experiments is that, 22 thanks to automatic difficulty evaluation, it becomes possible to work on larger amounts of data, offering the possibility to study language in more natural contexts. We present in the remaining of this se"
W12-4903,P10-1021,0,0.0176491,"0 subjects. The results of this study show that unlexicalized surprisal can predict reading times, whereas the lexicalized formulation does not. However, (Monsalve et al., 2012) pointed out recently that when using independent sentences, both lexicalized and unlexicalized surprisal measures are significant predictors of reading time (measures done with corpus of around 2,500 words and 54 participants). These different studies focus on lexical and syntactic effects. In a complementary direction, (Pynte et al., 2009) analyzed the influence of superficial lexical semantics on fixation duration. (Mitchell et al., 2010) integrates this parameter into Surprisal. This work shows the effect of semantic costs in addition to syntactic surprisal for reading time prediction. It also addresses in a specific way the question of modeling: experimental studies usually use linear mixed effect models, including random effects (e.g. participants characteristics) and fixed ones (e.g. word frequency). In these approaches, many different parameters are brought together. As authors pointed out, the use of a unique measure for predicting complexity is preferable than a set of factors, not only for simplicity, but also because"
W12-4903,E12-1041,0,0.058892,"gion (all the fixations, including those when going back into a region that has already been read). In the experiment, (Demberg and Keller, 2008) eliminates from the original corpus several data: first and last tokens of each line, token followed by a punctuation, region of 4 words with no fixations and words with zero value for FFD and FPD . Finally, this experiment retains a total of 200,684 data points, which means 20,068 tokens read by 10 subjects. The results of this study show that unlexicalized surprisal can predict reading times, whereas the lexicalized formulation does not. However, (Monsalve et al., 2012) pointed out recently that when using independent sentences, both lexicalized and unlexicalized surprisal measures are significant predictors of reading time (measures done with corpus of around 2,500 words and 54 participants). These different studies focus on lexical and syntactic effects. In a complementary direction, (Pynte et al., 2009) analyzed the influence of superficial lexical semantics on fixation duration. (Mitchell et al., 2010) integrates this parameter into Surprisal. This work shows the effect of semantic costs in addition to syntactic surprisal for reading time prediction. It"
W14-0501,P06-1008,1,0.765812,". Many studies have focused on the identification of specific parameters that can lead to a simplification or on the contrary to a complexification of the processing (e.g. the different difficulty models proposed in (Gibson, 2000), (Warren and Gibson, 2002), (Hawkins, 2001) ). Similarly, different simplification factors can be identified, such as the notion of activation, relying on syntactic priming effects making it possible to predict (or activate) a word (Vasishth, 2003). Several studies have shown that complexity factors are cumulative (Keller, 2005), but can be offset by simplification (Blache et al., 2006). It is therefore necessary to adopt a global point of view of language processing, explaining the interplay between positive and negative cumulativity, in other words compensation effects. From the computational point of view, some models can account more or less explicitly for these phenomena. This is the case of the Surprisal index (Hale, 2001), offering for each word an assessment of its integration costs into the syntactic structure. This evaluation is done starting from the probability of the possible solutions. On their side, symbolic approaches also provide an estimation of the activat"
W14-0501,F13-1017,1,0.727352,"en positive and negative cumulativity, in other words compensation effects. From the computational point of view, some models can account more or less explicitly for these phenomena. This is the case of the Surprisal index (Hale, 2001), offering for each word an assessment of its integration costs into the syntactic structure. This evaluation is done starting from the probability of the possible solutions. On their side, symbolic approaches also provide an estimation of the activation degree, depending on the number and weight of syntactic relations to the current word (Blache et al., 2006); (Blache, 2013). These approaches are based on the classical idea that language processing is incremental and occurs word by word. There are however several experimental evidences showing that a higher level of processing is used by human subjects. Eyetracking data show for example that fixations are done by chunks, not by words (Rauzy and Blache, 2012). Similarly, EEG experiments have shown that processing multiword expressions (for example idioms) relies on global mechanisms (VespigAcknowledgments This work, carried out within the Labex BLRI (ANR-11-LABX-0036), has benefited from support from the French go"
W14-0501,N01-1021,0,0.111855,"n of activation, relying on syntactic priming effects making it possible to predict (or activate) a word (Vasishth, 2003). Several studies have shown that complexity factors are cumulative (Keller, 2005), but can be offset by simplification (Blache et al., 2006). It is therefore necessary to adopt a global point of view of language processing, explaining the interplay between positive and negative cumulativity, in other words compensation effects. From the computational point of view, some models can account more or less explicitly for these phenomena. This is the case of the Surprisal index (Hale, 2001), offering for each word an assessment of its integration costs into the syntactic structure. This evaluation is done starting from the probability of the possible solutions. On their side, symbolic approaches also provide an estimation of the activation degree, depending on the number and weight of syntactic relations to the current word (Blache et al., 2006); (Blache, 2013). These approaches are based on the classical idea that language processing is incremental and occurs word by word. There are however several experimental evidences showing that a higher level of processing is used by huma"
W14-0501,W12-4903,1,0.855256,"his evaluation is done starting from the probability of the possible solutions. On their side, symbolic approaches also provide an estimation of the activation degree, depending on the number and weight of syntactic relations to the current word (Blache et al., 2006); (Blache, 2013). These approaches are based on the classical idea that language processing is incremental and occurs word by word. There are however several experimental evidences showing that a higher level of processing is used by human subjects. Eyetracking data show for example that fixations are done by chunks, not by words (Rauzy and Blache, 2012). Similarly, EEG experiments have shown that processing multiword expressions (for example idioms) relies on global mechanisms (VespigAcknowledgments This work, carried out within the Labex BLRI (ANR-11-LABX-0036), has benefited from support from the French government, managed by the French National Agency for Research (ANR), under the project title Investments of the Future A*MIDEX (ANR-11-IDEX-0001-02). Short biography Philipe Blache is Senior Researcher at CNRS (Aix-Marseille University, France). He is the Director of the BLRI (Brain and Language Research Institute), federating 6 research l"
W16-4102,J10-4006,1,0.953047,"ding times in a test set extracted from the Dundee Corpus (Kennedy et al., 2003). Their results showed that the semantic component improves the predictions, compared to models based only on syntactic information. Building on the work of Mitchell et al. (2010) and Mitchell (2011), Sayeed et al. (2015) tested a similar model on a multimodal language corpus (the AMI Meeting corpus; see Carletta (2007)), being able to predict spoken word pronunciation duration. A totally different perspective was adopted by Lenci (2011): starting from the method for thematic fit estimations that was introduced in Baroni and Lenci (2010), the author presented a compositional distributional model for reproducing the expectation update on the filler of the patient slot of a verb, depending on how the agent slot had been saturated (for example, if the agent of the verb to check is journalist, likely patients will be things that journalists typically check, such as source, spelling etc.). Lenci tried to model explicitly the process through which we modify our predictions on upcoming linguistic input on the basis of our event knowledge: the saturation of an argument slot imposes new semantic constraints on the other positions yet"
W16-4102,F13-1017,1,0.875421,"future, we plan to extend our experimentations to a wider range of psycholinguistic datasets, in order to see how the model can deal with a larger number of complexity sources and linguistic structures. Hopefully, future extensions of this model will also present a more global notion of complexity and will integrate information coming from different linguistic domains. It would be interesting, for example, to combine the predictions of our model of semantic complexity with constraint-based frameworks for the estimation of syntactic difficulty, such as Blache’s Property Grammars (Blache, 2011; Blache, 2013), and to see how they correlate with experimental data. There are many other aspects in language processing that, at the moment, our model leaves aside. Future extensions, in our view, should also account for the role played by attention,12 since several linguistic devices (prosodic cues, non-canonical syntactic structures etc.) can be used to signal informationally relevant parts of the message to the listeners/readers, helping them in the allocation of processing resources and thus influencing complexity (Hagoort, 2016). At the best of our knowledge, such issues have still to be convincingly"
W16-4102,D16-1205,1,0.917059,"- IN, etc.),7 and values are distributional vectors of dependent lexemes.8 The latter can be conceived as “out-of-context” distributional vector encoding of lexical items. Any type of distributional representation can be used to this purpose (e.g., explicit vectors, low-dimensionality dense embeddings, etc.). The following is a representation of an event e ∈ GEK, extracted from the sentence The student reads the book.: −−−−−→ −−→ −−→ (2) [EV EN T NSUBJ:student HEAD:read DOBJ:book] Unlike previous syntax-based DSMs, we extract from corpora syntactic joint contexts, besides single dependencies (Chersoni et al., 2016). A syntactic joint context includes the whole set of dependencies of a given lexical head, which we assume as a surface representation of an event. Each event in GEK may be cued by several lexical items, as part of their semantic content, albeit with different strength depending on their statistical distribution. For instance, the event in (2) is cued by the noun student, the verb read, and the noun book. We assume GEK to be hierarchically structured, according to various levels of event schematicity. In fact, all events in GEK can be underspecified. Without any need to add in GEK any specifi"
W16-4102,P13-2152,0,0.0128344,"task on the Bicknell dataset (Bicknell et al., 2010). 2 Related work Some of the previous works applying Distributional Semantic Models (henceforth DSMs) to sentence processing focused on the problem of computing a semantic surprisal index for the words of the sentence, on the basis of what Hale (2001) has proposed for syntax, and defined as the negative logarithm of the probability of a word given its previous linguistic context. The higher the surprisal of a word, the lower its predictability, and high surprisal values have been shown to correlate with an increase in processing difficulty (Frank et al., 2013; Smith and Levy, 2013). Mitchell et al. (2010) proposed a model to compute surprisal, based on the product of a trigram language model and of a semantic component, based in turn on the weighted dot product of the semantic vector of a target word and of a history vector, representing its prior context. The authors interpolated their model with the output of an incremental parser and they evaluated it on the task of predicting word reading times in a test set extracted from the Dundee Corpus (Kennedy et al., 2003). Their results showed that the semantic component improves the predictions, compa"
W16-4102,N01-1021,0,0.310494,"en the different objects of the construction itself. 13 In the following sections, we will present a global distributional semantic complexity score combining event activation and unification costs. As a first evaluation of our framework, we will use the semantic complexity score in a difficulty estimation task on the Bicknell dataset (Bicknell et al., 2010). 2 Related work Some of the previous works applying Distributional Semantic Models (henceforth DSMs) to sentence processing focused on the problem of computing a semantic surprisal index for the words of the sentence, on the basis of what Hale (2001) has proposed for syntax, and defined as the negative logarithm of the probability of a word given its previous linguistic context. The higher the surprisal of a word, the lower its predictability, and high surprisal values have been shown to correlate with an increase in processing difficulty (Frank et al., 2013; Smith and Levy, 2013). Mitchell et al. (2010) proposed a model to compute surprisal, based on the product of a trigram language model and of a semantic component, based in turn on the weighted dot product of the semantic vector of a target word and of a history vector, representing i"
W16-4102,W11-0607,1,0.900623,"he output of an incremental parser and they evaluated it on the task of predicting word reading times in a test set extracted from the Dundee Corpus (Kennedy et al., 2003). Their results showed that the semantic component improves the predictions, compared to models based only on syntactic information. Building on the work of Mitchell et al. (2010) and Mitchell (2011), Sayeed et al. (2015) tested a similar model on a multimodal language corpus (the AMI Meeting corpus; see Carletta (2007)), being able to predict spoken word pronunciation duration. A totally different perspective was adopted by Lenci (2011): starting from the method for thematic fit estimations that was introduced in Baroni and Lenci (2010), the author presented a compositional distributional model for reproducing the expectation update on the filler of the patient slot of a verb, depending on how the agent slot had been saturated (for example, if the agent of the verb to check is journalist, likely patients will be things that journalists typically check, such as source, spelling etc.). Lenci tried to model explicitly the process through which we modify our predictions on upcoming linguistic input on the basis of our event know"
W16-4102,P10-1021,0,0.225822,"al., 2010). 2 Related work Some of the previous works applying Distributional Semantic Models (henceforth DSMs) to sentence processing focused on the problem of computing a semantic surprisal index for the words of the sentence, on the basis of what Hale (2001) has proposed for syntax, and defined as the negative logarithm of the probability of a word given its previous linguistic context. The higher the surprisal of a word, the lower its predictability, and high surprisal values have been shown to correlate with an increase in processing difficulty (Frank et al., 2013; Smith and Levy, 2013). Mitchell et al. (2010) proposed a model to compute surprisal, based on the product of a trigram language model and of a semantic component, based in turn on the weighted dot product of the semantic vector of a target word and of a history vector, representing its prior context. The authors interpolated their model with the output of an incremental parser and they evaluated it on the task of predicting word reading times in a test set extracted from the Dundee Corpus (Kennedy et al., 2003). Their results showed that the semantic component improves the predictions, compared to models based only on syntactic informati"
W16-4102,P15-1074,0,0.782809,"m language model and of a semantic component, based in turn on the weighted dot product of the semantic vector of a target word and of a history vector, representing its prior context. The authors interpolated their model with the output of an incremental parser and they evaluated it on the task of predicting word reading times in a test set extracted from the Dundee Corpus (Kennedy et al., 2003). Their results showed that the semantic component improves the predictions, compared to models based only on syntactic information. Building on the work of Mitchell et al. (2010) and Mitchell (2011), Sayeed et al. (2015) tested a similar model on a multimodal language corpus (the AMI Meeting corpus; see Carletta (2007)), being able to predict spoken word pronunciation duration. A totally different perspective was adopted by Lenci (2011): starting from the method for thematic fit estimations that was introduced in Baroni and Lenci (2010), the author presented a compositional distributional model for reproducing the expectation update on the filler of the patient slot of a verb, depending on how the agent slot had been saturated (for example, if the agent of the verb to check is journalist, likely patients will"
W17-6803,J10-4006,1,0.660569,"their structural roles, which are computed later. For example, the difference between typical agents and typical patients, according to this account, would not be included in the representation of an event. In the last few years, a related issue has been debated in the field of distributional semantics, i.e. whether there is any added value in using structured representations of linguistic contexts over bag-ofwords ones (e.g., contexts represented as co-occurrence windows). While structured models have been shown to outperform the latter in a number of semantic tasks (Pad´o and Lapata, 2007; Baroni and Lenci, 2010; Levy and Goldberg, 2014), some bag-of-word models proved to be extremely competitive, at least under certain parameter settings (Baroni et al., 2014). A recent paper by Lapesa and Evert (2017) explicitly addressed the question of whether using structured distributional semantic models is worth the effort, by comparing the performance of syntax-based and window-based distributional models on four different tasks. The authors showed that, even after extensive parameter tuning, the former have a significant advantage only in one task out of four (i.e., noun clustering). Interestingly, in the di"
W17-6803,W16-4102,1,0.853824,"was measured as the cosine similarity between its vector, and the context-vector obtained by averaging the vectors of the preceding words. Ettinger and colleagues tested their method on the sentences used in the ERP study by Federmeier and Kutas (1999), in which three different conditions were defined, and they observed that the context-target similarity scores across conditions were following the same pattern of the N400 amplitudes of the original experiment. Thus, this work shows how data on N400 variations can be modeled even by means of vectors with minimal or no syntactic information. 2 Chersoni et al. (2016) presented a research work testing a similar method on the Bicknell dataset. However, their model does not really update argument expectations on the basis of other arguments, computing instead a global score of semantic coherence for the entire event representation, on the basis of the mutual typicality between all the participants. 3 Experiments Rationale. Baroni and Lenci (2010) computed the thematic fit for a candidate f iller (e.g., policeman) in an argument slot (e.g., agent) of an input lexical item (e.g., arrest) as the similarity score between the vector of the candidate f iller and a"
W17-6803,P13-4006,0,0.0270416,"of the Wacky (Baroni et al., 2009) corpus. Both were parsed with the Maltparser (Nivre and Hall, 2005). From this concatenation, we built a dependency-based DSMs, where the tuples are weighted by means of Positive Local Mutual Information (PLMI, Evert (2004)). Given the cooccurrence count Otrf of the target t, the syntactic relation r and the filler f , we computed the expected count Etrf (i.e., the simple joint probability of indipendent variables, corresponding to the product of the probabilities of the single events).4 4 The DSM were built by means of the scripts of the DISSECT framework (Dinu et al., 2013) The PLMI for each target-relation-filler tuple is computed as follows:  LM I(t, r, f ) = log Otrf Etrf  ∗ Otrf P LM I(t, r, f ) = max(LM I(t, r, f ), 0) (3) (4) Our DSM contains 28,817 targets (i.e., all nouns and verbs with frequency above 1000 in the training corpora), and all syntactic relations were included.5 We also built a window-based DSM to extract cooccurrence information for the BOW model, counting only the co-occurrences between the nouns and the verbs of the list above within a word window of width 2. Prototypes The prototypes of all models were built out of the vectors of the"
W17-6803,N15-1003,0,0.287639,"tional information coming from the agent and from the predicate of an agent-verb-patient triple (e.g., butcher–cut–meat), generating a prototype vector which represents the expectations on the patient filler, given the agent filler. The triples of the Bicknell dataset (Bicknell et al., 2010), which were used for the first time to evaluate such a model, are still today, at the best of our knowledge, the only existing gold standard for this type of task. Although the ‘structured-approach’ to thematic fit was influential for a number of other works (Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015; Sayeed et al., 2016; Santus et al., 2017), the task of modeling the update of the argument expectations has received relatively little attention. An exception is the work by Tilk et al. (2016), who trained a neural network on a role-labeled corpus in order to optimize the distributional representation for thematic fit estimation. Their model was also tested on the task of the composition and update of argument expectations, where it was able to achieve a performance comparable to Lenci (2011) on the triples of the Bicknell dataset.2 Notice that both the models of Lenci (2011) and Tilk et al."
W17-6803,E17-2063,0,0.0110316,"n of an event. In the last few years, a related issue has been debated in the field of distributional semantics, i.e. whether there is any added value in using structured representations of linguistic contexts over bag-ofwords ones (e.g., contexts represented as co-occurrence windows). While structured models have been shown to outperform the latter in a number of semantic tasks (Pad´o and Lapata, 2007; Baroni and Lenci, 2010; Levy and Goldberg, 2014), some bag-of-word models proved to be extremely competitive, at least under certain parameter settings (Baroni et al., 2014). A recent paper by Lapesa and Evert (2017) explicitly addressed the question of whether using structured distributional semantic models is worth the effort, by comparing the performance of syntax-based and window-based distributional models on four different tasks. The authors showed that, even after extensive parameter tuning, the former have a significant advantage only in one task out of four (i.e., noun clustering). Interestingly, in the discussion they leave open the question of whether their results can generalize to linguistically challenging task such as the prediction of thematic fit ratings. In this paper, we specifically in"
W17-6803,W11-0607,1,0.786635,"lity by means of a Local Mutual Information score (Evert, 2004) computed between verb, arguments and syntactic relations. The basic assumption is that the higher the distributional similarity of a candidate argument with a role prototype, the higher its predictability as a filler for that role will be. As a gold standard, the authors used the human-elicited thematic fit ratings collected by McRae et al. (1998) and Pad´o (2007), and they evaluated the performance by measuring the correlation between these ratings and the scores generated by the model (as already proposed by Erk et al. (2010)). Lenci (2011) later extended this ‘structured-approach’ to account for the dynamic update of the expectations on an argument, which depends on how other roles in the sentences are filled. For instance, given the agent butcher the expected patient of the verb cut is likely to be meat, while given the agent coiffeur the expected patient of the same verb is likely to be hair. By means of the same DM tensor, this study tested an additive and a multiplicative model (Mitchell and Lapata, 2010) to compose the distributional information coming from the agent and from the predicate of an agent-verb-patient triple ("
W17-6803,P14-2050,0,0.0132482,"which are computed later. For example, the difference between typical agents and typical patients, according to this account, would not be included in the representation of an event. In the last few years, a related issue has been debated in the field of distributional semantics, i.e. whether there is any added value in using structured representations of linguistic contexts over bag-ofwords ones (e.g., contexts represented as co-occurrence windows). While structured models have been shown to outperform the latter in a number of semantic tasks (Pad´o and Lapata, 2007; Baroni and Lenci, 2010; Levy and Goldberg, 2014), some bag-of-word models proved to be extremely competitive, at least under certain parameter settings (Baroni et al., 2014). A recent paper by Lapesa and Evert (2017) explicitly addressed the question of whether using structured distributional semantic models is worth the effort, by comparing the performance of syntax-based and window-based distributional models on four different tasks. The authors showed that, even after extensive parameter tuning, the former have a significant advantage only in one task out of four (i.e., noun clustering). Interestingly, in the discussion they leave open t"
W17-6803,J07-2002,0,0.0547974,"Missing"
W17-6803,D17-1068,1,0.772801,"from the predicate of an agent-verb-patient triple (e.g., butcher–cut–meat), generating a prototype vector which represents the expectations on the patient filler, given the agent filler. The triples of the Bicknell dataset (Bicknell et al., 2010), which were used for the first time to evaluate such a model, are still today, at the best of our knowledge, the only existing gold standard for this type of task. Although the ‘structured-approach’ to thematic fit was influential for a number of other works (Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015; Sayeed et al., 2016; Santus et al., 2017), the task of modeling the update of the argument expectations has received relatively little attention. An exception is the work by Tilk et al. (2016), who trained a neural network on a role-labeled corpus in order to optimize the distributional representation for thematic fit estimation. Their model was also tested on the task of the composition and update of argument expectations, where it was able to achieve a performance comparable to Lenci (2011) on the triples of the Bicknell dataset.2 Notice that both the models of Lenci (2011) and Tilk et al. (2016) necessarily rely on the hypothesis"
W17-6803,W16-2518,0,0.0126561,"g from the agent and from the predicate of an agent-verb-patient triple (e.g., butcher–cut–meat), generating a prototype vector which represents the expectations on the patient filler, given the agent filler. The triples of the Bicknell dataset (Bicknell et al., 2010), which were used for the first time to evaluate such a model, are still today, at the best of our knowledge, the only existing gold standard for this type of task. Although the ‘structured-approach’ to thematic fit was influential for a number of other works (Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015; Sayeed et al., 2016; Santus et al., 2017), the task of modeling the update of the argument expectations has received relatively little attention. An exception is the work by Tilk et al. (2016), who trained a neural network on a role-labeled corpus in order to optimize the distributional representation for thematic fit estimation. Their model was also tested on the task of the composition and update of argument expectations, where it was able to achieve a performance comparable to Lenci (2011) on the triples of the Bicknell dataset.2 Notice that both the models of Lenci (2011) and Tilk et al. (2016) necessarily r"
W17-6803,D16-1017,0,0.0643391,"nt filler, given the agent filler. The triples of the Bicknell dataset (Bicknell et al., 2010), which were used for the first time to evaluate such a model, are still today, at the best of our knowledge, the only existing gold standard for this type of task. Although the ‘structured-approach’ to thematic fit was influential for a number of other works (Sayeed and Demberg, 2014; Sayeed et al., 2015; Greenberg et al., 2015; Sayeed et al., 2016; Santus et al., 2017), the task of modeling the update of the argument expectations has received relatively little attention. An exception is the work by Tilk et al. (2016), who trained a neural network on a role-labeled corpus in order to optimize the distributional representation for thematic fit estimation. Their model was also tested on the task of the composition and update of argument expectations, where it was able to achieve a performance comparable to Lenci (2011) on the triples of the Bicknell dataset.2 Notice that both the models of Lenci (2011) and Tilk et al. (2016) necessarily rely on the hypothesis that the arguments are structurally distinct, since they are trained either on argument tuples containing fine-grained dependency information, or on se"
W17-6803,P14-1023,0,\N,Missing
W18-4603,J10-4006,1,0.767075,"lous ones, and in particular, they have never been tested on the task of modeling their differences in processing complexity. In this paper, we compare two different models of thematic fit by testing their ability of identifying violations of selectional restrictions in two datasets from the experimental studies. 1 Introduction In recent years, Distributional Semantic Models (henceforth DSMs) have been at the core of one of the most active research areas in NLP, and have been applied to a wide variety of tasks. Among these, distributional modeling of selectional preferences (Erk et al., 2010; Baroni and Lenci, 2010) has been quite popular in computational psycholinguistics, since the similarity estimated by DSMs works very well for predicting the thematic fit between an argument and a verb. That is to say, the more the argument vector is similar to some kind of vector representation of the ideal filler of the verb slot (it can be either an abstract prototype, or a cluster of exemplars), the more the argument will satisfy the semantic requirements of the slot. The notion of thematic fit, as it has been proposed by the recent psycholinguistic research 1 , is related to, but not totally equivalent to the cl"
W18-4603,W16-4102,1,0.810858,"ince the former refers to a gradient compatibility between verb and role, whereas the latter conceives such compatibility as as boolean constraint evaluated on discrete semantic features (Lebani and Lenci, 2018). The distributional models of thematic fit have been evaluated by comparing the plausibility scores produced by the models with human-elicited judgements (Erk et al., 2010; Baroni and Lenci, 2010; Greenberg et al., 2015; Santus et al., 2017), showing significant correlations. Moreover, they have been used to predict the composition and the update of argument expectations (Lenci, 2011; Chersoni et al., 2016), and for modeling reading times of experimental studies on complement coercion (Zarcone et al., 2013). However, an issue regarding their evaluation has not been addressed yet, i.e. their ability of capturing different levels of implausibility. 2 Our processing system is sensitive to minimal variations in predictability between highly unpredictable word combinations, and such sensitivity has been shown to have an influence on reading times (Smith and Levy, 2013). Moreover, word combinations that are simply rare and/or unlikely and word combinations that are semantically deviant have been shown"
W18-4603,P13-4006,0,0.0327901,"ompared two different models of thematic fit. B&L2010 is a ’classical’ model of thematic fit, and it consists of a direct reimplementation of Baroni and Lenci (2010): since we are scoring sentences which differ for the degree of typicality of the verb-object combination, the scores assigned by this model will be the thematic fit scores θ of the object of each sentence given the verb and the patient role. In Equation 3, t is the target verb and c is a word occurring as an object (obj) of t: − −c |obj, → θ=→ t 3 (3) We used the scripts of the DISSECT framework to build the distributional space (Dinu et al., 2013). As context words, we took into account only the 20K words of our target list, in order to limit the size of the distributional space. 5 Obviously, including all the syntactic relations would have hugely increased the dimensionality of the vector space. Therefore, we took into account only the following relations: subject, direct and indirect object, prepositional complement. For each relation, we also considered its inverse: for example, the target apple-v has a dimension eat-v:obj-1, meaning that apple occurs as a direct object of eat-v. 6 In the literature, 20 is a common choice for the nu"
W18-4603,J10-4007,0,0.0667553,"Missing"
W18-4603,N15-1003,0,0.204835,"The notion of thematic fit, as it has been proposed by the recent psycholinguistic research 1 , is related to, but not totally equivalent to the classical notion of selectional preferences, since the former refers to a gradient compatibility between verb and role, whereas the latter conceives such compatibility as as boolean constraint evaluated on discrete semantic features (Lebani and Lenci, 2018). The distributional models of thematic fit have been evaluated by comparing the plausibility scores produced by the models with human-elicited judgements (Erk et al., 2010; Baroni and Lenci, 2010; Greenberg et al., 2015; Santus et al., 2017), showing significant correlations. Moreover, they have been used to predict the composition and the update of argument expectations (Lenci, 2011; Chersoni et al., 2016), and for modeling reading times of experimental studies on complement coercion (Zarcone et al., 2013). However, an issue regarding their evaluation has not been addressed yet, i.e. their ability of capturing different levels of implausibility. 2 Our processing system is sensitive to minimal variations in predictability between highly unpredictable word combinations, and such sensitivity has been shown to"
W18-4603,W11-0607,1,0.920445,"references, since the former refers to a gradient compatibility between verb and role, whereas the latter conceives such compatibility as as boolean constraint evaluated on discrete semantic features (Lebani and Lenci, 2018). The distributional models of thematic fit have been evaluated by comparing the plausibility scores produced by the models with human-elicited judgements (Erk et al., 2010; Baroni and Lenci, 2010; Greenberg et al., 2015; Santus et al., 2017), showing significant correlations. Moreover, they have been used to predict the composition and the update of argument expectations (Lenci, 2011; Chersoni et al., 2016), and for modeling reading times of experimental studies on complement coercion (Zarcone et al., 2013). However, an issue regarding their evaluation has not been addressed yet, i.e. their ability of capturing different levels of implausibility. 2 Our processing system is sensitive to minimal variations in predictability between highly unpredictable word combinations, and such sensitivity has been shown to have an influence on reading times (Smith and Levy, 2013). Moreover, word combinations that are simply rare and/or unlikely and word combinations that are semantically"
W18-4603,nivre-etal-2006-maltparser,0,0.0505108,"the other hand, we have full coverage for the Pylkk¨anen dataset. DSM We built a dependency-based DSM by using the data in the BNC corpus (Leech, 1992) and in the Wacky corpus (Baroni et al., 2009). Both the corpora were POS-tagged with the Tree Tagger (Schmid, 23 Verb and Role Agent of to play Agent of to arrest Patient of to eat Patient of to shoot Fillers actor, gamer, violinist cop, policeman, superhero pizza, sandwich, ice-cream enemy, soldier, prey Table 1: Verb roles and examples of fillers extracted by means of a corresponding syntactic relation. 1994) and parsed with the Maltparser (Nivre et al., 2006). 3 We extracted all the dependencies for the 20K most frequent words in the corpora, including the words of our datasets. Every co-occurrence between a target word and another context word in a given syntactic relation was weighted by means of Positive Local Mutual Information (Evert, 2004). 4 Given a target t, a relation r and a context word c occurring in the relation r with the target (e.g. t = bark, r = sbj, c = dog), we computed both their cooccurrence Otrc , and the expected co-occurrence Etrc under the assumption of statistical independence. The Positive Local Mutual Information (hence"
W18-4603,D17-1068,1,0.844114,"it, as it has been proposed by the recent psycholinguistic research 1 , is related to, but not totally equivalent to the classical notion of selectional preferences, since the former refers to a gradient compatibility between verb and role, whereas the latter conceives such compatibility as as boolean constraint evaluated on discrete semantic features (Lebani and Lenci, 2018). The distributional models of thematic fit have been evaluated by comparing the plausibility scores produced by the models with human-elicited judgements (Erk et al., 2010; Baroni and Lenci, 2010; Greenberg et al., 2015; Santus et al., 2017), showing significant correlations. Moreover, they have been used to predict the composition and the update of argument expectations (Lenci, 2011; Chersoni et al., 2016), and for modeling reading times of experimental studies on complement coercion (Zarcone et al., 2013). However, an issue regarding their evaluation has not been addressed yet, i.e. their ability of capturing different levels of implausibility. 2 Our processing system is sensitive to minimal variations in predictability between highly unpredictable word combinations, and such sensitivity has been shown to have an influence on r"
W18-4603,C94-1027,0,0.25286,"Missing"
W18-4603,W11-1301,0,0.0188244,"ns, and such sensitivity has been shown to have an influence on reading times (Smith and Levy, 2013). Moreover, word combinations that are simply rare and/or unlikely and word combinations that are semantically deviant have been shown to have different consequences on processing complexity (Paczynski and Kuperberg, 2012; Warren et al., 2015). This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/ 1 See McRae and Matsuki (2009) for an overview. 2 A partial exception is the study on semantic deviance by Vecchi et al. (2011). However, they focus on the acceptability of adjectival phrases, rather than on selectional preferences. 20 Proceedings of the Workshop on Linguistic Complexity and Natural Language Processing, pages 20–29 Santa Fe, New Mexico, USA, August 25, 2018. From this point of view, thematic fit models represent an interesting alternative to the traditional probabilistic ones: they use distributional information about typical arguments to create an abstract representation of the ”ideal” filler of the argument slot, and thus they are more capable of generalizing to the unseen. In other words, it does n"
W18-4603,W13-0216,1,0.863802,"Missing"
W19-3312,W16-4102,1,0.845153,"similar distributional behaviour like Caused-Motion and Dative. As for frames, there has been some work on using distributional similarity between vectors for their unsupervised induction (Ustalov et al., 2018), for comparing frames across languages (Sikos and Pad´o, 2018), and even for the automatic identification of the semantic relations holding between them (Botschen et al., 2017). Modeling sentence comprehension A trend in computational semantics regards the application of DSMs to sentence processing (Mitchell et al., 2010; Lenci, 2011; Sayeed et al., 2015; Johns and Jones, 2015, i.a.). Chersoni et al. (2016, 2017) propose a Distributional Model of sentence comprehension inspired by the general principles of the Memory, Unification and Control framework (Hagoort, 2013, 2015). The memory component includes events in GEK with feature structures containing information directly extracted from parsed sentences in corpora: attributes are syntactic dependencies, while values are distributional vectors of dependent lexemes. Then, they model semantic composition as an event construction and update function F, whose aim is to build a coherent semantic representation by integrating the GEK cued by the lingu"
W19-3312,S17-1021,1,0.872718,"Missing"
W19-3312,P98-1013,0,0.190996,"ic University giulia.rambelli@phd.unipi.it emmanuelechersoni@gmail.com Philippe Blache Aix-Marseille University blache@lpl-aix.fr Chu-Ren Huang The Hong Kong Polytechnic University churen.huang@polyu.edu.hk Alessandro Lenci University of Pisa alessandro.lenci@unipi.it Abstract Obj1 Obj2]). It is worth stressing that, even if the concept of construction is based on the idea that linguistic properties actually emerge from language use, CxG theories have typically preferred to model the semantic content of constructions in terms of hand-made, formal representations like those of Frame Semantics (Baker et al., 1998). This leaves open the issue of how semantic representations can be learned from empirical evidence, and how do they relate to the usage-based nature of Cxs. In fact, for a usage-based model of grammar based on a strong syntax-semantics parallelism, it would be desirable to be grounded on a framework allowing to learn the semantic content of Cxs from language use. In this paper, we propose a new type of semantic representation of Construction Grammar that combines constructions with the vector representations used in Distributional Semantics. We introduce a new framework, Distributional Constr"
W19-3312,J10-4006,1,0.660784,"riples and identify frames as clustered triples. Of course, a limit of this approach is that it only uses subject and object arguments, while frames are generally associated with a wider variety of roles. Lebani and Lenci (2018) instead provide a distributional representation of verb-specific semantic roles as clusters of features automatically induced from corpora. In this paper, we assume that at least some aspects of semantic roles can be derived from combining (e.g., with summation) the distributional vectors of their most prototypical fillers, following an approach widely explored in DS (Baroni and Lenci, 2010; Erk et al., 2010; Sayeed et al., −−−→ 2016; Santus et al., 2017). For instance, the buyer role in the COMMERCIAL TRANSACTION frame can be taken as a vector encoding the properties of the typical nouns filling this role. We are aware that this solution is just an approximation of the content of frames elements. How to satisfactorily characterize semantic frames and roles using DS is in fact still an open research question. 3.3  ditransitive-cx  commercial-transaction-fr     −−−→     BUYER buyer       − − − →   *SELLER seller +      −−−→   SEM    GOODS goods"
W19-3312,W19-2913,0,0.0656285,"Missing"
W19-3312,W17-2618,0,0.0139057,"between linguistic items represented in a vector space. For example, Busso et al. (2018) built a semantic space for several Italian argument constructions and then computed the similarity of their vectors, observing that some Cxs have similar distributional behaviour like Caused-Motion and Dative. As for frames, there has been some work on using distributional similarity between vectors for their unsupervised induction (Ustalov et al., 2018), for comparing frames across languages (Sikos and Pad´o, 2018), and even for the automatic identification of the semantic relations holding between them (Botschen et al., 2017). Modeling sentence comprehension A trend in computational semantics regards the application of DSMs to sentence processing (Mitchell et al., 2010; Lenci, 2011; Sayeed et al., 2015; Johns and Jones, 2015, i.a.). Chersoni et al. (2016, 2017) propose a Distributional Model of sentence comprehension inspired by the general principles of the Memory, Unification and Control framework (Hagoort, 2013, 2015). The memory component includes events in GEK with feature structures containing information directly extracted from parsed sentences in corpora: attributes are syntactic dependencies, while values"
W19-3312,W11-0607,1,0.805924,"ed the similarity of their vectors, observing that some Cxs have similar distributional behaviour like Caused-Motion and Dative. As for frames, there has been some work on using distributional similarity between vectors for their unsupervised induction (Ustalov et al., 2018), for comparing frames across languages (Sikos and Pad´o, 2018), and even for the automatic identification of the semantic relations holding between them (Botschen et al., 2017). Modeling sentence comprehension A trend in computational semantics regards the application of DSMs to sentence processing (Mitchell et al., 2010; Lenci, 2011; Sayeed et al., 2015; Johns and Jones, 2015, i.a.). Chersoni et al. (2016, 2017) propose a Distributional Model of sentence comprehension inspired by the general principles of the Memory, Unification and Control framework (Hagoort, 2013, 2015). The memory component includes events in GEK with feature structures containing information directly extracted from parsed sentences in corpora: attributes are syntactic dependencies, while values are distributional vectors of dependent lexemes. Then, they model semantic composition as an event construction and update function F, whose aim is to build a"
W19-3312,J15-1004,0,0.0290206,"ugust 1st, 2019 2019 Association for Computational Linguistics has never formulated a systematic proposal for deriving representations of constructional meaning from corpus data. Previous literature has mostly focused either on the automatic identification of constructions on the basis of their formal features, or on modeling the meaning of a specific CxG. connection with usage-based theoretical frameworks. To the best of our knowledge, existing attempts of linking DS with models of grammar have rather targeted formal theories like Montague Grammar and Categorial Grammar (Baroni et al., 2014; Grefenstette and Sadrzadeh, 2015). To sum up, both CxG and DS share the assumption that linguistic structures naturally emerge from language usage, and that a representation of both form and meaning of any linguistic item can be modeled through its distributional statistics, and more generally, with the quantitative information derived from corpus data. However, these two models still live in parallel worlds. On the one hand, CxG is a model of grammar in search for a consistent usage-based model of meaning, and, conversely, DS is a computational framework to build semantic representations in search for an empirically adequate"
W19-3312,W19-0129,0,0.0233673,"umption that constructional meanings for argument Cxs arise from the meaning of high frequency verbs that co-occur with them (Goldberg, 1999; Casenhiser and Goldberg, 2005; Barak and Goldberg, 2017), they compute distributional vectors for CxS as the centroids of the vectors of their typical verbs, and use them to model the psycholinguistic data about construction priming in Johnson and Goldberg (2013). This representation of construction meaning has also been applied to study valency coercion by Busso et al. (2018). Following a parallel research line on probing tasks for distributed vectors, Kann et al. (2019) investigate whether word and sentence embeddings encode the grammatical distinctions necessary for inferring the idiosyncratic frame-selectional properties of verbs. Their findings show that, at least 112 3.1 Constructions construction always involve a possession interpretation (more precisely the transfer of something to somebody), represented in the TRANSFER frame. Differently from standard SBCG formalization of Cxs, we add the distributional feature DSVECTOR into the semantic layer in order to integrate lexical distributional representations. The semantic structure of a lexical item can be"
W19-3312,P10-1021,0,0.0386834,"uctions and then computed the similarity of their vectors, observing that some Cxs have similar distributional behaviour like Caused-Motion and Dative. As for frames, there has been some work on using distributional similarity between vectors for their unsupervised induction (Ustalov et al., 2018), for comparing frames across languages (Sikos and Pad´o, 2018), and even for the automatic identification of the semantic relations holding between them (Botschen et al., 2017). Modeling sentence comprehension A trend in computational semantics regards the application of DSMs to sentence processing (Mitchell et al., 2010; Lenci, 2011; Sayeed et al., 2015; Johns and Jones, 2015, i.a.). Chersoni et al. (2016, 2017) propose a Distributional Model of sentence comprehension inspired by the general principles of the Memory, Unification and Control framework (Hagoort, 2013, 2015). The memory component includes events in GEK with feature structures containing information directly extracted from parsed sentences in corpora: attributes are syntactic dependencies, while values are distributional vectors of dependent lexemes. Then, they model semantic composition as an event construction and update function F, whose aim"
W19-3312,D17-1068,1,0.851266,"of this approach is that it only uses subject and object arguments, while frames are generally associated with a wider variety of roles. Lebani and Lenci (2018) instead provide a distributional representation of verb-specific semantic roles as clusters of features automatically induced from corpora. In this paper, we assume that at least some aspects of semantic roles can be derived from combining (e.g., with summation) the distributional vectors of their most prototypical fillers, following an approach widely explored in DS (Baroni and Lenci, 2010; Erk et al., 2010; Sayeed et al., −−−→ 2016; Santus et al., 2017). For instance, the buyer role in the COMMERCIAL TRANSACTION frame can be taken as a vector encoding the properties of the typical nouns filling this role. We are aware that this solution is just an approximation of the content of frames elements. How to satisfactorily characterize semantic frames and roles using DS is in fact still an open research question. 3.3  ditransitive-cx  commercial-transaction-fr     −−−→     BUYER buyer       − − − →   *SELLER seller +      −−−→   SEM    GOODS goods         − − − − →    MONEY money     −−→ PLACE shop F"
W19-3312,P15-1074,0,0.0159296,"rity of their vectors, observing that some Cxs have similar distributional behaviour like Caused-Motion and Dative. As for frames, there has been some work on using distributional similarity between vectors for their unsupervised induction (Ustalov et al., 2018), for comparing frames across languages (Sikos and Pad´o, 2018), and even for the automatic identification of the semantic relations holding between them (Botschen et al., 2017). Modeling sentence comprehension A trend in computational semantics regards the application of DSMs to sentence processing (Mitchell et al., 2010; Lenci, 2011; Sayeed et al., 2015; Johns and Jones, 2015, i.a.). Chersoni et al. (2016, 2017) propose a Distributional Model of sentence comprehension inspired by the general principles of the Memory, Unification and Control framework (Hagoort, 2013, 2015). The memory component includes events in GEK with feature structures containing information directly extracted from parsed sentences in corpora: attributes are syntactic dependencies, while values are distributional vectors of dependent lexemes. Then, they model semantic composition as an event construction and update function F, whose aim is to build a coherent semantic re"
W19-3312,W16-2518,0,0.0248713,"Missing"
W19-3312,W16-1803,1,0.770156,"DING frame In a similar way, events can instantiate an abstract construction dynamically, according to the context. The different lexicalization of the AGENT and the RECIPIENT in the ditransitive construction causes a different selection of the THEME. For example, the fact that the sentence fragment The teacher gives students ... could be completed as in (2) expresses a distributional restriction that can be encoded as an event capturing the co-occurrences 115 tive meaning cannot be decomposed. In computational semantics, a large literature has been aiming at modeling idiomaticity using DSMs. Senaldi et al. (2016) carried out an idiom type identification task representing Italian V-NP and V-PP Cxs as vectors. They observed that the vectors of VN and AN idioms are less similar to the vectors of lexical variants of these expressions with respect to the vectors of compositional constructions. (Cordeiro et al., 2019) realized a framework for predict compound compositionality using DSMs, evaluating to what extent they capture idiomaticity compared to human judgments. Results revealed a high agreement between the models and human predictions, suggesting that they are able to incorporate information about idi"
W19-3312,W18-3813,0,0.0668121,"Missing"
W19-3312,P18-2010,0,0.0640524,"h i     SYN CAT 1 V       n o     LIN 2 ≺ 1 ≺ 3 ≺ 4  FORM   PROPERTIES   n L    L o   3; 3 4 ADJ 1     D E   ARG - ST 2 NPx[subj] , 3 NPy[obl] , 4 NPz[obj]              transfer-fr     *    +      AGENT x FRAMES         RECIPIENT y   SEM             THEME z        −−−−−−−−→  DS - VECTOR Figure 1: Description of read verb ditransitive Figure 2: Description of ditransitive Cx  ata (2015) use distributional representations to induce embeddings for predicates and their arguments. Ustalov et al. (2018) propose a different methodology for unsupervised semantic frame induction. They build embeddings as the concatenations of subject-verb-object triples and identify frames as clustered triples. Of course, a limit of this approach is that it only uses subject and object arguments, while frames are generally associated with a wider variety of roles. Lebani and Lenci (2018) instead provide a distributional representation of verb-specific semantic roles as clusters of features automatically induced from corpora. In this paper, we assume that at least some aspects of semantic roles can be derived fr"
W19-3312,D15-1295,0,0.0438303,"Missing"
Y11-1017,C00-1017,0,0.0381915,"Missing"
Y11-1017,N01-1021,0,0.351282,"her many different complexity parameters in order to take into account a large variety of phenomena. Moreover, it still remains necessary to develop and validate generic computational models dealing with unrestricted linguistic material, in particular spoken languages. Among the different parameters involved in its definition, the evaluation of the difficulty human subjects encounter in language production or perception plays a major role. In the literature, one of the most frequently used approaches relies on surprisal effects that can occur when integrating a new word to the structure (cf. (Hale, 2001)): roughly speaking, surprisal is high when the probability for a word to occur in a specific context is low. This parameter is evaluated as the negative logarithm of the probability of a word wt to appear in its context, taking into account the sequence w1 ...wt−1 . Surprisal is evaluated as a function of the probabilities of the possible parses when integrating the word wt . When using a probabilistic grammar, evaluating surprisal consists in measuring the difference between the probability of all parses spanning the sequence w1 ...wt−1 and those spanning w1 ...wt : Copyright 2011 by Philipp"
Y11-1017,C94-1097,0,0.0172921,"Missing"
Y11-1017,P10-1021,0,0.0569083,"ating surprisal consists in measuring the difference between the probability of all parses spanning the sequence w1 ...wt−1 and those spanning w1 ...wt : Copyright 2011 by Philippe Blache and St´ephane Rauzy 25th Pacific Asia Conference on Language, Information and Computation, pages 160–167 160 SIt = − log P (w1 ...wt ) P (w1 ...wt−1 ) (1) Surprisal has been shown by different studies as being correlated with difficulty. This has been demonstrated experimentally, in particular by several works relying on eye-tracking in reading tasks (cf. (Boston et al., 2011), (Demberg and Keller, 2008) or (Mitchell et al., 2010)). These last studies use results from the Dundee corpus (see (Kennedy et al., 2003)) from which some short extracts have been chosen (20 texts read by 10 subjects). This corpus has been analyzed, surprisal values calculated and put in perspective with eye-tracking data. Results show a correlation between difficulty parameters (in particular reading time) and surprisal indexes. One of the problems is that surprisal evaluation is sensible to the syntactic formalism. Moreover, from a computational point of view, surprisal also depends on the characteristics of the parser used in the evaluation."
Y16-2021,N09-1003,0,0.387296,"Missing"
Y16-2021,J10-4006,1,0.894609,"Missing"
Y16-2021,P14-1023,0,0.703018,"shown to outperform Vector Cosine in most settings, except when the latter metric is applied on a PPMI-SVD reduced matrix (Bullinaria and Levy, 2012), against which APSyn still obtains competitive performances. The results are also discussed in relation to the state-of-the-art DSMs, as reported in Hill et al. (2015). In such comparison, the best settings of our models outperform the word embeddings in almost all datasets. A pilot study was also carried out to investigate whether APSyn is scalable. Results prove its high performance also when calculated on large corpora, such as those used by Baroni et al. (2014). On top of the performance, APSyn seems not to be subject to some of the biases that affect Vector Cosine. Finally, considering the debate about the ability of DSMs to calculate genuine similarity as opposed to word relatedness (Turney, 2001; Agirre et al., 2009; Hill et al., 2015), we test the ability of the models to quantify genuine semantic similarity. 2 2.1 Background DSMs, Measures of Association and Dimensionality Reduction Count-based DSMs are built in an unsupervised way. Starting from large preprocessed corpora, a matrix M(m×n) is built, in which each row is a vector representing a"
Y16-2021,J90-1003,0,0.702972,"of the Distributional Hypothesis (DH), which claims that words occurring in the same contexts tend to have similar meanings (Harris, 1954; Firth, 1957; Sahlgren, 2008). Such hypothesis provides the theoretical ground for Distributional Semantic Models (DSMs), which represent word meaning by means of high-dimensional vectors encoding corpus-extracted co-occurrences between targets and their linguistic contexts (Turney and Pantel, 2010). Traditional DSMs initialize vectors with cooccurrence frequencies. Statistical measures, such as Positive Pointwise Mutual Information (PPMI) or its variants (Church and Hanks, 1990; Bullinaria and Levy, 2012; Levy et al., 2015), have been adopted to normalize these values. Also, these models have exploited the power of dimensionality reduction techniques, such as Singular Value Decomposition (SVD; Landauer and Dumais, 1997) and Random Indexing (Sahlgren, 2005). These ﬁrst-generation models are currently referred to as count-based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013). More commonly known as word"
Y16-2021,W16-2506,0,0.162529,"ting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013). More commonly known as word embeddings, these secondgeneration models learn meaning representations through neural network training: the vectors dimensions are set to maximize the probability for the contexts that typically occur with the target word. Vector Cosine is generally adopted by both types of models as a similarity measure. However, this metric has been found to suffer from several problems (Li and Han, 2013; Faruqui et al., 2016), such as a bias towards features with higher values and the inability of considering how many features are actually shared by the vectors. Finally, Cosine is affected by the hubness effect (Dinu et al., 2014; Schn30th Pacific Asia Conference on Language, Information and Computation (PACLIC 30) Seoul, Republic of Korea, October 28-30, 2016 229 abel et al., 2015), i.e. the fact that words with high frequency tend to be universal neighbours. Even though other measures have been proposed in the literature (Deza and Deza, 2009), Vector Cosine is still by far the most popular one (Turney and Pantel"
Y16-2021,J15-4004,0,0.0945737,", 2010). However, in a recent paper of Santus et al. (2016b), the authors have claimed that Vector Cosine is outperformed by APSyn (Average Precision for Synonymy), a metric based on the extent of the intersection between the most salient contexts of two target words. The measure, tested on a window-based DSM, outperformed Vector Cosine on the ESL and on the TOEFL datasets. In the present work, we perform a systematic evaluation of APSyn, testing it on the most popular test sets for similarity estimation - namely WordSim-353 (Finkelstein et al., 2001), MEN (Bruni et al., 2014) and SimLex-999 (Hill et al., 2015). For comparison, Vector Cosine is also calculated on several countbased DSMs. We implement a total of twenty-eight models with different parameters settings, each of which differs according to corpus size, context window width, weighting scheme and SVD application. The new metric is shown to outperform Vector Cosine in most settings, except when the latter metric is applied on a PPMI-SVD reduced matrix (Bullinaria and Levy, 2012), against which APSyn still obtains competitive performances. The results are also discussed in relation to the state-of-the-art DSMs, as reported in Hill et al. (201"
Y16-2021,P12-1092,0,0.686827,"wise Mutual Information (PPMI) or its variants (Church and Hanks, 1990; Bullinaria and Levy, 2012; Levy et al., 2015), have been adopted to normalize these values. Also, these models have exploited the power of dimensionality reduction techniques, such as Singular Value Decomposition (SVD; Landauer and Dumais, 1997) and Random Indexing (Sahlgren, 2005). These ﬁrst-generation models are currently referred to as count-based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013). More commonly known as word embeddings, these secondgeneration models learn meaning representations through neural network training: the vectors dimensions are set to maximize the probability for the contexts that typically occur with the target word. Vector Cosine is generally adopted by both types of models as a similarity measure. However, this metric has been found to suffer from several problems (Li and Han, 2013; Faruqui et al., 2016), such as a bias towards features with higher values and the inability of considering how many features are actually shared by the"
Y16-2021,W14-1503,0,0.0315309,"0.335 0.519 0.525 0.564 0.546 0.562 0.553 WSim (REL) 2 3 0.167 0.175 0.251 0.269 0.378 0.396 0.051 0.084 0.141 0.151 0.325 0.323 0.259 0.241 0.261 0.284 0.233 0.27 0.337 0.397 0.361 0.382 0.287 0.309 Table 3: Spearman correlation scores for our eight models trained on RCV1, in the two subsets of WordSim353. might depend on the different type of similarity encoded in SimLex-999 (i.e. genuine similarity). On top of it, despite Hill et al. (2015)’s claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity (Agirre et al., 2009; Kiela and Clark, 2014), we need to mention that window 5 was abandoned because of its low performance. With reference to the hubness effect, we have conducted a pilot study inspired to the one carried out by Schnabel et al. (2015), using the words of the SimLex-999 dataset as query words and collecting for each of them the top 1000 nearest neighbors. Given all the neighbors at rank r, we have checked their rank in the frequency list extracted from our corpora. Figure 1 shows the relation between the rank in the nearest neighbor list and the rank in the frequency list. It can be easily noticed that the highest ranke"
Y16-2021,Q15-1016,0,0.382486,"s that words occurring in the same contexts tend to have similar meanings (Harris, 1954; Firth, 1957; Sahlgren, 2008). Such hypothesis provides the theoretical ground for Distributional Semantic Models (DSMs), which represent word meaning by means of high-dimensional vectors encoding corpus-extracted co-occurrences between targets and their linguistic contexts (Turney and Pantel, 2010). Traditional DSMs initialize vectors with cooccurrence frequencies. Statistical measures, such as Positive Pointwise Mutual Information (PPMI) or its variants (Church and Hanks, 1990; Bullinaria and Levy, 2012; Levy et al., 2015), have been adopted to normalize these values. Also, these models have exploited the power of dimensionality reduction techniques, such as Singular Value Decomposition (SVD; Landauer and Dumais, 1997) and Random Indexing (Sahlgren, 2005). These ﬁrst-generation models are currently referred to as count-based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013). More commonly known as word embeddings, these secondgeneration models lear"
Y16-2021,L16-1723,1,0.788938,"higher values and the inability of considering how many features are actually shared by the vectors. Finally, Cosine is affected by the hubness effect (Dinu et al., 2014; Schn30th Pacific Asia Conference on Language, Information and Computation (PACLIC 30) Seoul, Republic of Korea, October 28-30, 2016 229 abel et al., 2015), i.e. the fact that words with high frequency tend to be universal neighbours. Even though other measures have been proposed in the literature (Deza and Deza, 2009), Vector Cosine is still by far the most popular one (Turney and Pantel, 2010). However, in a recent paper of Santus et al. (2016b), the authors have claimed that Vector Cosine is outperformed by APSyn (Average Precision for Synonymy), a metric based on the extent of the intersection between the most salient contexts of two target words. The measure, tested on a window-based DSM, outperformed Vector Cosine on the ESL and on the TOEFL datasets. In the present work, we perform a systematic evaluation of APSyn, testing it on the most popular test sets for similarity estimation - namely WordSim-353 (Finkelstein et al., 2001), MEN (Bruni et al., 2014) and SimLex-999 (Hill et al., 2015). For comparison, Vector Cosine is also"
Y16-2021,D15-1036,0,0.145843,"andauer and Dumais, 1997; Jarmasz and Szpakowicz, 2004; Mikolov et al., 2013; Levy et al., 2015), looks at the normalized correlation between the dimensions of two word vectors, w1 and w2 and returns a score between -1 and 1. It is described by the following equation: n × f2i i=1 f1 i n i=1 f1 i × i=1 f2 i cos(w1 , w2 ) = n (3) where fi x is the i-th dimension in the vector x. Despite its extensive usage, Vector Cosine has been recently criticized for its hyper sensibility to features with high values and for the inability of identifying the actual feature intersection (Li and Han, 2013; Schnabel et al., 2015). Recalling an example by Li and Han (2013), the Vector Cosine for the toy-vectors a = [1, 2, 0] and b = [0, 1, 0] (i.e. 0.8944) is unexpectedly higher than the one for a and c = [2, 1, 0] (i.e. 0.8000), and even higher than the one for the toy-vectors a and d = [1, 2, 1] (i.e. 0.6325), which instead share a larger feature intersection. Since the Vector Cosine is a distance measure, it is also subject to the hubness problem, which was shown by Radovanovic et al. (2010) to be an inherent property of data distributions in highdimensional vector space. The problem consists in the fact that vector"
Y16-2021,P10-1040,0,0.0618988,"uch as Positive Pointwise Mutual Information (PPMI) or its variants (Church and Hanks, 1990; Bullinaria and Levy, 2012; Levy et al., 2015), have been adopted to normalize these values. Also, these models have exploited the power of dimensionality reduction techniques, such as Singular Value Decomposition (SVD; Landauer and Dumais, 1997) and Random Indexing (Sahlgren, 2005). These ﬁrst-generation models are currently referred to as count-based, as distinguished from the contextpredicting ones, which have been recently proposed in the literature (Bengio et al., 2006; Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012; Mikolov et al., 2013). More commonly known as word embeddings, these secondgeneration models learn meaning representations through neural network training: the vectors dimensions are set to maximize the probability for the contexts that typically occur with the target word. Vector Cosine is generally adopted by both types of models as a similarity measure. However, this metric has been found to suffer from several problems (Li and Han, 2013; Faruqui et al., 2016), such as a bias towards features with higher values and the inability of considering how many features are act"
