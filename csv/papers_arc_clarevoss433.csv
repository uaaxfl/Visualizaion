2021.naacl-demos.8,{COVID}-19 Literature Knowledge Graph Construction and Drug Repurposing Report Generation,2021,-1,-1,25,0,4844,qingyun wang,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations,0,"To combat COVID-19, both clinicians and scientists need to digest the vast amount of relevant biomedical knowledge in literature to understand the disease mechanism and the related biological functions. We have developed a novel and comprehensive knowledge discovery framework, COVID-KG to extract fine-grained multimedia knowledge elements (entities, relations and events) from scientific literature. We then exploit the constructed multimedia knowledge graphs (KGs) for question answering and report generation, using drug repurposing as a case study. Our framework also provides detailed contextual sentences, subfigures, and knowledge subgraphs as evidence. All of the data, KGs, reports."
2021.mrqa-1.7,What Can a Generative Language Model Answer About a Passage?,2021,-1,-1,3,1,5183,douglas summersstay,Proceedings of the 3rd Workshop on Machine Reading for Question Answering,0,"Generative language models trained on large, diverse corpora can answer questions about a passage by generating the most likely continuation of the passage followed by a question/answer pair. However, accuracy rates vary depending on the type of question asked. In this paper we keep the passage fixed, and test with a wide variety of question types, exploring the strengths and weaknesses of the GPT-3 language model. We provide the passage and test questions as a challenge set for other language models."
2021.emnlp-main.422,The Future is not One-dimensional: Complex Event Schema Induction by Graph Modeling for Event Prediction,2021,-1,-1,8,0.972222,714,manling li,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Event schemas encode knowledge of stereotypical structures of events and their connections. As events unfold, schemas are crucial to act as a scaffolding. Previous work on event schema induction focuses either on atomic events or linear temporal event sequences, ignoring the interplay between events via arguments and argument relations. We introduce a new concept of Temporal Complex Event Schema: a graph-based schema representation that encompasses events, arguments, temporal connections and argument relations. In addition, we propose a Temporal Event Graph Model that predicts event instances following the temporal complex event schema. To build and evaluate such schemas, we release a new schema learning corpus containing 6,399 documents accompanied with event graphs, and we have manually constructed gold-standard schemas. Intrinsic evaluations by schema matching and instance graph perplexity, prove the superior quality of our probabilistic graph schema library compared to linear representations. Extrinsic evaluation on schema-guided future event prediction further demonstrates the predictive power of our event graph model, significantly outperforming human schemas and baselines by more than 17.8{\%} on HITS@1."
2020.lrec-1.86,Dialogue-{AMR}: {A}bstract {M}eaning {R}epresentation for Dialogue,2020,-1,-1,9,0.566779,5184,claire bonial,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper describes a schema that enriches Abstract Meaning Representation (AMR) in order to provide a semantic representation for facilitating Natural Language Understanding (NLU) in dialogue systems. AMR offers a valuable level of abstraction of the propositional content of an utterance; however, it does not capture the illocutionary force or speaker{'}s intended contribution in the broader dialogue context (e.g., make a request or ask a question), nor does it capture tense or aspect. We explore dialogue in the domain of human-robot interaction, where a conversational robot is engaged in search and navigation tasks with a human partner. To address the limitations of standard AMR, we develop an inventory of speech acts suitable for our domain, and present {``}Dialogue-AMR{''}, an enhanced AMR that represents not only the content of an utterance, but the illocutionary force behind it, as well as tense and aspect. To showcase the coverage of the schema, we use both manual and automatic methods to construct the {``}DialAMR{''} corpus{---}a corpus of human-robot dialogue annotated with standard AMR and our enriched Dialogue-AMR schema. Our automated methods can be used to incorporate AMR into a larger NLU pipeline supporting human-robot dialogue."
2020.lrec-1.243,Cross-lingual Structure Transfer for Zero-resource Event Extraction,2020,-1,-1,7,1,4012,di lu,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Most of the current cross-lingual transfer learning methods for Information Extraction (IE) have been only applied to name tagging. To tackle more complex tasks such as event extraction we need to transfer graph structures (event trigger linked to multiple arguments with various roles) across languages. We develop a novel share-and-transfer framework to reach this goal with three steps: (1) Convert each sentence in any language to language-universal graph structures; in this paper we explore two approaches based on universal dependency parses and complete graphs, respectively. (2) Represent each node in the graph structure with a cross-lingual word embedding so that all sentences in multiple languages can be represented with one shared semantic space. (3) Using this common semantic space, train event extractors from English training data and apply them to languages that do not have any event annotations. Experimental results on three languages (Spanish, Russian and Ukrainian) without any annotations show this framework achieves comparable performance to a state-of-the-art supervised model trained from more than 1,500 manually annotated event mentions."
2020.emnlp-main.50,Connecting the Dots: Event Graph Schema Induction with Path Language Modeling,2020,-1,-1,8,1,714,manling li,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Event schemas can guide our understanding and ability to make predictions with respect to what might happen next. We propose a new Event Graph Schema, where two event types are connected through multiple paths involving entities that fill important roles in a coherent story. We then introduce Path Language Model, an auto-regressive language model trained on event-event paths, and select salient and coherent paths to probabilistically construct these graph schemas. We design two evaluation metrics, instance coverage and instance coherence, to evaluate the quality of graph schema induction, by checking when coherent event instances are covered by the schema graph. Intrinsic evaluations show that our approach is highly effective at inducing salient and coherent schemas. Extrinsic evaluations show the induced schema repository provides significant improvement to downstream end-to-end Information Extraction over a state-of-the-art joint neural extraction model, when used as additional global features to unfold instance graphs."
2020.dmr-1.7,{I}nfo{F}orager: Leveraging Semantic Search with {AMR} for {COVID}-19 Research,2020,-1,-1,5,0.566779,5184,claire bonial,Proceedings of the Second International Workshop on Designing Meaning Representations,0,"This paper examines how Abstract Meaning Representation (AMR) can be utilized for finding answers to research questions in medical scientific documents, in particular, to advance the study of UV (ultraviolet) inactivation of the novel coronavirus that causes the disease COVID-19. We describe the development of a proof-of-concept prototype tool, InfoForager, which uses AMR to conduct a semantic search, targeting the meaning of the user question, and matching this to sentences in medical documents that may contain information to answer that question. This work was conducted as a sprint over a period of six weeks, and reveals both promising results and challenges in reducing the user search time relating to COVID-19 research, and in general, domain adaption of AMR for this task."
2020.acl-demos.11,{GAIA}: A Fine-grained Multimedia Knowledge Extraction System,2020,-1,-1,10,1,714,manling li,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We present the first comprehensive, open source multimedia knowledge extraction system that takes a massive stream of unstructured, heterogeneous multimedia data from various sources and languages as input, and creates a coherent, structured knowledge base, indexing entities, relations, and events, following a rich, fine-grained ontology. Our system, GAIA, enables seamless search of complex graph queries, and retrieves multimedia evidence including text, images and videos. GAIA achieves top performance at the recent NIST TAC SM-KBP2019 evaluation. The system is publicly available at GitHub and DockerHub, with a narrated video that documents the system."
W19-4610,Constrained Sequence-to-sequence {S}emitic Root Extraction for Enriching Word Embeddings,2019,0,0,5,0,7813,ahmed elkishky,Proceedings of the Fourth Arabic Natural Language Processing Workshop,0,"In this paper, we tackle the problem of {``}root extraction{''} from words in the Semitic language family. A challenge in applying natural language processing techniques to these languages is the data sparsity problem that arises from their rich internal morphology, where the substructure is inherently non-concatenative and morphemes are interdigitated in word formation. While previous automated methods have relied on human-curated rules or multiclass classification, they have not fully leveraged the various combinations of regular, sequential concatenative morphology within the words and the internal interleaving within templatic stems of roots and patterns. To address this, we propose a constrained sequence-to-sequence root extraction method. Experimental results show our constrained model outperforms a variety of methods at root extraction. Furthermore, by enriching word embeddings with resulting decompositions, we show improved results on word analogy, word similarity, and language modeling tasks."
W19-3322,Augmenting {A}bstract {M}eaning {R}epresentation for Human-Robot Dialogue,2019,0,1,7,0.609554,5184,claire bonial,Proceedings of the First International Workshop on Designing Meaning Representations,0,"We detail refinements made to Abstract Meaning Representation (AMR) that make the representation more suitable for supporting a situated dialogue system, where a human remotely controls a robot for purposes of search and rescue and reconnaissance. We propose 36 augmented AMRs that capture speech acts, tense and aspect, and spatial information. This linguistic information is vital for representing important distinctions, for example whether the robot has moved, is moving, or will move. We evaluate two existing AMR parsers for their performance on dialogue data. We also outline a model for graph-to-graph conversion, in which output from AMR parsers is converted into our refined AMRs. The design scheme presented here, though task-specific, is extendable for broad coverage of speech acts using AMR in future task-independent work."
W19-0124,{A}bstract {M}eaning {R}epresentation for Human-Robot Dialogue,2019,0,0,4,0.609554,5184,claire bonial,Proceedings of the Society for Computation in Linguistics ({SC}i{L}) 2019,0,None
N19-4019,"Multilingual Entity, Relation, Event and Human Value Extraction",2019,0,1,5,1,714,manling li,Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations),0,"This paper demonstrates a state-of-the-art end-to-end multilingual (English, Russian, and Ukrainian) knowledge extraction system that can perform entity discovery and linking, relation extraction, event extraction, and coreference. It extracts and aggregates knowledge elements across multiple languages and documents as well as provides visualizations of the results along three dimensions: temporal (as displayed in an event timeline), spatial (as displayed in an event heatmap), and relational (as displayed in entity-relation networks). For our system to further support users{'} analyses of causal sequences of events in complex situations, we also integrate a wide range of human moral value measures, independently derived from region-based survey, into the event heatmap. This system is publicly available as a docker container and a live demo."
N19-4023,A {R}esearch {P}latform for {M}ulti-{R}obot {D}ialogue with {H}umans,2019,0,2,7,1,1549,matthew marge,Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations),0,"This paper presents a research platform that supports spoken dialogue interaction with multiple robots. The demonstration showcases our crafted MultiBot testing scenario in which users can verbally issue search, navigate, and follow instructions to two robotic teammates: a simulated ground robot and an aerial robot. This flexible language and robotic platform takes advantage of existing tools for speech recognition and dialogue management that are compatible with new domains, and implements an inter-agent communication protocol (tactical behavior specification), where verbal instructions are encoded for tasks assigned to the appropriate robot."
D19-1030,Cross-lingual Structure Transfer for Relation and Event Extraction,2019,0,1,7,0,17109,ananya subburathinam,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"The identification of complex semantic structures such as events and entity relations, already a challenging Information Extraction task, is doubly difficult from sources written in under-resourced and under-annotated languages. We investigate the suitability of cross-lingual structure transfer techniques for these tasks. We exploit relation- and event-relevant language-universal features, leveraging both symbolic (including part-of-speech and dependency path) and distributional (including type representation and contextualized representation) information. By representing all entity mentions, event triggers, and contexts into this complex and structured multilingual common space, using graph convolutional networks, we can train a relation or event extractor from source language annotations and apply it to the target language. Extensive experiments on cross-lingual relation and event transfer among English, Chinese, and Arabic demonstrate that our approach achieves performance comparable to state-of-the-art supervised models trained on up to 3,000 manually annotated mentions: up to 62.6{\%} F-score for Relation Extraction, and 63.1{\%} F-score for Event Argument Role Labeling. The event argument role labeling model transferred from English to Chinese achieves similar performance as the model trained from Chinese. We thus find that language-universal symbolic and distributional representations are complementary for cross-lingual structure transfer."
W18-5012,Consequences and Factors of Stylistic Differences in Human-Robot Dialogue,2018,0,0,8,1,16783,stephanie lukin,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"This paper identifies stylistic differences in instruction-giving observed in a corpus of human-robot dialogue. Differences in verbosity and structure (i.e., single-intent vs. multi-intent instructions) arose naturally without restrictions or prior guidance on how users should speak with the robot. Different styles were found to produce different rates of miscommunication, and correlations were found between style differences and individual user variation, trust, and interaction experience with the robot. Understanding potential consequences and factors that influence style can inform design of dialogue systems that are robust to natural variation from human users."
W18-4910,"Towards a Computational Lexicon for {M}oroccan {D}arija: Words, Idioms, and Constructions",2018,0,0,5,1,28087,jamal laoudi,"Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions ({LAW}-{MWE}-{C}x{G}-2018)",0,"In this paper, we explore the challenges of building a computational lexicon for Moroccan Darija (MD), an Arabic dialect spoken by over 32 million people worldwide but which only recently has begun appearing frequently in written form in social media. We raise the question of what belongs in such a lexicon and start by describing our work building traditional word-level lexicon entries with their English translations. We then discuss challenges in translating idiomatic MD text that led to creating multi-word expression lexicon entries whose meanings could not be fully derived from the individual words. Finally, we provide a preliminary exploration of constructions to be considered for inclusion in an MD constructicon by translating examples of English constructions and examining their MD counterparts."
W18-4307,Can You Spot the Semantic Predicate in this Video?,2018,0,0,4,0,28183,christopher reale,Proceedings of the Workshop Events and Stories in the News 2018,0,"We propose a method to improve human activity recognition in video by leveraging semantic information about the target activities from an expert-defined linguistic resource, VerbNet. Our hypothesis is that activities that share similar event semantics, as defined by the semantic predicates of VerbNet, will be more likely to share some visual components. We use a deep convolutional neural network approach as a baseline and incorporate linguistic information from VerbNet through multi-task learning. We present results of experiments showing the added information has negligible impact on recognition performance. We discuss how this may be because the lexical semantic information defined by VerbNet is generally not visually salient given the video processing approach used here, and how we may handle this in future approaches."
W18-3808,{STYLUS}: A Resource for Systematically Derived Language Usage,2018,-1,-1,2,0,14512,bonnie dorr,Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing,0,"We describe a resource derived through extraction of a set of argument realizations from an existing lexical-conceptual structure (LCS) Verb Database of 500 verb classes (containing a total of 9525 verb entries) to include information about realization of arguments for a range of different verb classes. We demonstrate that our extended resource, called STYLUS (SysTematicallY Derived Language USe), enables systematic derivation of regular patterns of language usage without requiring manual annotation. We posit that both spatially oriented applications such as robot navigation and more general applications such as narrative generation require a layered representation scheme where a set of primitives (often grounded in space/motion such as GO) is coupled with a representation of constraints at the syntax-semantics interface. We demonstrate that the resulting resource covers three cases of lexico-semantic operations applicable to both language understanding and language generation."
W18-1921,Challenges in Speech Recognition and Translation of High-Value Low-Density Polysynthetic Languages,2018,0,1,5,0,8328,judith klavans,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 2: User Track),0,None
W18-1503,A Pipeline for Creative Visual Storytelling,2018,11,1,3,1,16783,stephanie lukin,Proceedings of the First Workshop on Storytelling,0,"Computational visual storytelling produces a textual description of events and interpretations depicted in a sequence of images. These texts are made possible by advances and cross-disciplinary approaches in natural language processing, generation, and computer vision. We define a computational creative visual storytelling as one with the ability to alter the telling of a story along three aspects: to speak about different environments, to produce variations based on narrative goals, and to adapt the narrative to the audience. These aspects of creative storytelling and their effect on the narrative have yet to be explored in visual storytelling. This paper presents a pipeline of task-modules, Object Identification, Single-Image Inferencing, and Multi-Image Narration, that serve as a preliminary design for building a creative visual storyteller. We have piloted this design for a sequence of images in an annotation task. We present and analyze the collected corpus and describe plans towards automation."
W18-1408,The Case for Systematically Derived Spatial Language Usage,2018,0,0,2,0,14512,bonnie dorr,Proceedings of the First International Workshop on Spatial Language Understanding,0,"This position paper argues that, while prior work in spatial language understanding for tasks such as robot navigation focuses on mapping natural language into deep conceptual or non-linguistic representations, it is possible to systematically derive regular patterns of spatial language usage from existing lexical-semantic resources. Furthermore, even with access to such resources, effective solutions to many application areas such as robot navigation and narrative generation also require additional knowledge at the syntax-semantics interface to cover the wide range of spatial expressions observed and available to natural language speakers. We ground our insights in, and present our extensions to, an existing lexico-semantic resource, covering 500 semantic classes of verbs, of which 219 fall within a spatial subset. We demonstrate that these extensions enable systematic derivation of regular patterns of spatial language without requiring manual annotation."
P18-4016,{S}cout{B}ot: A Dialogue System for Collaborative Navigation,2018,0,3,9,1,16783,stephanie lukin,"Proceedings of {ACL} 2018, System Demonstrations",0,"ScoutBot is a dialogue interface to physical and simulated robots that supports collaborative exploration of environments. The demonstration will allow users to issue unconstrained spoken language commands to ScoutBot. ScoutBot will prompt for clarification if the user{'}s instruction needs additional input. It is trained on human-robot dialogue collected from Wizard-of-Oz experiments, where robot responses were initiated by a human wizard in previous interactions. The demonstration will show a simulated ground robot (Clearpath Jackal) in a simulated environment supported by ROS (Robot Operating System)."
P18-1201,Zero-Shot Transfer Learning for Event Extraction,2018,0,11,6,0.392157,9579,lifu huang,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Most previous supervised event extraction methods have relied on features derived from manual annotations, and thus cannot be applied to new event types without extra annotation effort. We take a fresh look at event extraction and model it as a generic grounding problem: mapping each event mention to a specific type in a target event ontology. We design a transferable architecture of structural and compositional neural networks to jointly represent and map event mentions and types into a shared semantic space. Based on this new framework, we can select, for each event mention, the event type which is semantically closest in this space as its type. By leveraging manual annotations available for a small set of existing event types, our framework can be applied to new unseen event types without additional manual annotations. When tested on 23 unseen event types, our zero-shot framework, without manual annotations, achieved performance comparable to a supervised model trained from 3,000 sentences annotated with 500 event mentions."
L18-1017,Dialogue Structure Annotation for Multi-Floor Interaction,2018,0,2,9,0,16786,david traum,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
D18-1433,Incorporating Background Knowledge into Video Description Generation,2018,0,5,5,0,22725,spencer whitehead,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Most previous efforts toward video captioning focus on generating generic descriptions, such as, {``}A man is talking.{''} We collect a news video dataset to generate enriched descriptions that include important background knowledge, such as named entities and related events, which allows the user to fully understand the video content. We develop an approach that uses video meta-data to retrieve topically related news documents for a video and extracts the events and named entities from these documents. Then, given the video as well as the extracted events and entities, we generate a description using a Knowledge-aware Video Description network. The model learns to incorporate entities found in the topically related documents into the description via an entity pointer network and the generation procedure is guided by the event and entity types from the topically related documents through a knowledge gate, which is a gating mechanism added to the model{'}s decoder that takes a one-hot vector of these types. We evaluate our approach on the new dataset of news videos we have collected, establishing the first benchmark for this dataset as well as proposing a new metric to evaluate these descriptions."
W17-2808,Exploring Variation of Natural Human Commands to a Robot in a Collaborative Navigation Task,2017,27,4,8,1,1549,matthew marge,Proceedings of the First Workshop on Language Grounding for Robotics,0,"Robot-directed communication is variable, and may change based on human perception of robot capabilities. To collect training data for a dialogue system and to investigate possible communication changes over time, we developed a Wizard-of-Oz study that (a) simulates a robot{'}s limited understanding, and (b) collects dialogues where human participants build a progressively better mental model of the robot{'}s understanding. With ten participants, we collected ten hours of human-robot dialogue. We analyzed the structure of instructions that participants gave to a remote robot before it responded. Our findings show a general initial preference for including metric information (e.g., move forward 3 feet) over landmarks (e.g., move to the desk) in motion commands, but this decreased over time, suggesting changes in perception."
P16-1025,Liberal Event Extraction and Event Schema Induction,2016,56,33,5,0.392157,9579,lifu huang,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
N16-3015,Cross-media Event Extraction and Recommendation,2016,11,8,2,0.641026,4012,di lu,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Demonstrations,0,None
2016.amta-users.25,Toward Temporally-aware {MT}: Can Information Extraction Help Preserve Temporal Interpretation?,2016,-1,-1,3,0.666667,34445,taylor cassidy,Conferences of the Association for Machine Translation in the Americas: MT Users' Track,0,None
W14-5402,Joint Navigation in Commander/Robot Teams: Dialog {\\&} Task Performance When Vision is Bandwidth-Limited,2014,18,2,3,1,5183,douglas summersstay,Proceedings of the Third Workshop on Vision and Language,0,"The prospect of human commanders teaming with mobile robots xe2x80x9csmart enoughxe2x80x9d to undertake joint exploratory tasksxe2x80x94especially tasks that neither commander nor robot could perform alonexe2x80x94requires novel methods of preparing and testing human-robot teams for these ventures prior to real-time operations. In this paper, we report work-in-progress that maintains face validity of selected configurations of resources and people, as would be available in emergency circumstances. More specifically, from an off-site post, we ask human commanders (C) to perform an exploratory task in collaboration with a remotely located human robot-navigator (Rn) who controls the navigation of, but cannot see the physical robot (R). We impose network bandwidth restrictions in two mission scenarios comparable to real circumstances by varying the availability of sensor, image, and video signals to Rn, in effect limiting the human Rn to function as an automation stand-in. To better understand the capabilities and language required in such configurations, we constructed multi-modal corpora of time-synced dialog, video, and LIDAR files recorded during task sessions. We can now examine commander/robot dialogs while replaying what C and Rn saw, to assess their task performance under these varied conditions."
W14-1008,Resumptive Pronoun Detection for {M}odern {S}tandard {A}rabic to {E}nglish {MT},2014,16,0,2,0.664334,16784,stephen tratz,Proceedings of the 3rd Workshop on Hybrid Approaches to Machine Translation ({H}y{T}ra),0,"Many languages, including Modern Standard Arabic (MSA), insert resumptive pronouns in relative clauses, whereas many others, such as English, do not, using empty categories instead. This discrepancy is a source of difficulty when translating between these languages because there are words in one language that correspond to empty categories in the other, and these words must either be inserted or deletedxe2x80x94depending on translation direction. In this paper, we first examine challenges presented by resumptive pronouns in MSA-English translations and review resumptive pronoun translations generated by a popular online MSA-English MT engine. We then present what is, to the best of our knowledge, the first system for automatic identification of resumptive pronouns. The system achieves 91.9 F1 and 77.8 F1 on Arabic Treebank data when using gold standard parses and automatic parses, respectively."
W14-0207,"Collaborative Exploration in Human-Robot Teams: What{'}s in their Corpora of Dialog, Video, {\\&} {LIDAR} Messages?",2014,20,2,1,1,4860,clare voss,Proceedings of the {EACL} 2014 Workshop on Dialogue in Motion,0,"This paper briefly sketches new work-inprogress (i) developing task-based scenarios where human-robot teams collaboratively explore real-world environments in which the robot is immersed but the humans are not, (ii) extracting and constructing xe2x80x9cmulti-modal interval corporaxe2x80x9d from dialog, video, and LIDAR messages that were recorded in ROS bagfiles during task sessions, and (iii) testing automated methods to identify, track, and align co-referent content both within and across modalities in these interval corpora. The pre-pilot study and its corpora provide a unique, empirical starting point for our longerterm research objective: characterizing the balance of explicitly shared and tacitly assumed information exchanged during effective teamwork. 1 Overview"
voss-etal-2014-finding,Finding {R}omanized {A}rabic Dialect in Code-Mixed Tweets,2014,7,16,1,1,4860,clare voss,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Recent computational work on Arabic dialect identification has focused primarily on building and annotating corpora written in Arabic script. Arabic dialects however also appear written in Roman script, especially in social media. This paper describes our recent work developing tweet corpora and a token-level classifier that identifies a Romanized Arabic dialect and distinguishes it from French and English in tweets. We focus on Moroccan Darija, one of several spoken vernaculars in the family of Maghrebi Arabic dialects. Even given noisy, code-mixed tweets,the classifier achieved token-level recall of 93.2{\%} on Romanized Arabic dialect, 83.2{\%} on English, and 90.1{\%} on French. The classifier, now integrated into our tweet conversation annotation tool (Tratz et al. 2013), has semi-automated the construction of a Romanized Arabic-dialect lexicon. Two datasets, a full list of Moroccan Darija surface token forms and a table of lexical entries derived from this list with spelling variants, as extracted from our tweet corpus collection, will be made available in the LRE MAP."
C14-1149,The Wisdom of Minority: Unsupervised Slot Filling Validation based on Multi-dimensional Truth-Finding,2014,27,42,8,0,3415,dian yu,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Information Extraction using multiple information sources and systems is beneficial due to multisource/system consolidation and challenging due to the resulting inconsistency and redundancy. We integrate IE and truth-finding research and present a novel unsupervised multi-dimensional truth finding framework which incorporates signals from multiple sources, multiple systems and multiple pieces of evidence by knowledge graph construction through multi-layer deep linguistic analysis. Experiments on the case study of Slot Filling Validation demonstrate that our approach can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (finding 90% truths with only one half the cost of a baseline without credibility estimation)."
W13-2317,"Tweet Conversation Annotation Tool with a Focus on an {A}rabic Dialect, {M}oroccan {D}arija",2013,14,6,4,0.664334,16784,stephen tratz,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"This paper presents the DATOOL, a graphical tool for annotating conversations consisting of short messages (i.e., tweets), and the results we obtain in using it to annotate tweets for Darija, an historically unwritten Arabic dialect spoken by millions but not taught in schools and lacking standardization and linguistic resources. With the DATOOL, a native-Darija speaker annotated hundreds of mixedlanguage and mixed-script conversations at approximately 250 tweets per hour. The resulting corpus was used in developing and evaluating Arabic dialect classifiers described briefly herein. The DATOOL supports downstream discourse analysis of tweeted xe2x80x9cconversationsxe2x80x9d by mapping extracted relations such as, who tweets to whom in which language, into graph markup formats for analysis in network visualization tools."
jaja-etal-2012-assessing,Assessing Divergence Measures for Automated Document Routing in an Adaptive {MT} System,2012,16,0,4,0,43231,claire jaja,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Custom machine translation (MT) engines systematically outperform general-domain MT engines when translating within the relevant custom domain. This paper investigates the use of the Jensen-Shannon divergence measure for automatically routing new documents within a translation system with multiple MT engines to the appropriate custom MT engine in order to obtain the best translation. Three distinct domains are compared, and the impact of the language, size, and preprocessing of the documents on the Jensen-Shannon score is addressed. Six test datasets are then compared to the three known-domain corpora to predict which of the three custom MT engines they would be routed to at runtime given their Jensen-Shannon scores. The results are promising for incorporating this divergence measure into a translation workflow."
C12-1076,Tweet Ranking Based on Heterogeneous Networks,2012,32,28,11,0.576923,37501,hongzhao huang,Proceedings of {COLING} 2012,0,"Ranking tweets is a fundamental task to make it easier to distill the vast amounts of information shared by users. In this paper, we explore the novel idea of ranking tweets on a topic using heterogeneous networks. We construct heterogeneous networks by harnessing cross-genre linkages between tweets and semantically-related web documents from formal genres, and inferring implicit links between tweets and users. To rank tweets effectively by capturing the semantics and importance of different linkages, we introduce Tri-HITS, a model to iteratively propagate ranking scores across heterogeneous networks. We show that integrating both formal genre and inferred social networks with tweet networks produces a higher-quality ranking than the tweet networks alone. 1 Title and Abstract in Chinese u"
2009.mtsummit-government.3,On beyond {TM}: When the Translator Leads the Design of a Translation Support Framework,2009,-1,-1,2,1,28555,reginald hobbs,Proceedings of Machine Translation Summit XII: Government MT User Program,0,None
W08-0511,{B}uckwalter-based Lookup Tool as Language Resource for {A}rabic Language Learners,2008,1,3,2,0,14770,jeffrey micher,"Software Engineering, Testing, and Quality Assurance for Natural Language Processing",0,"The morphology of the Arabic language is rich and complex; words are inflected to express variations in tense-aspect, person, number, and gender, while they may also appear with clitics attached to express possession on nouns, objects on verbs and prepositions, and conjunctions. Furthermore, Arabic script allows the omission of short vowel diacritics. For the Arabic language learner trying to understand non-diacritized text, the challenge when reading new vocabulary is first to isolate individual words within text tokens and then to determine the underlying lemma and root forms to look up the word in an Arabic dictionary."
hobbs-etal-2008-mtriage,"{MT}riage: Web-enabled Software for the Creation, Machine Translation, and Annotation of Smart Documents",2008,4,1,3,1,28555,reginald hobbs,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Progress in the Machine Translation (MT) research community, particularly for statistical approaches, is intensely data-driven. Acquiring source language documents for testing, creating training datasets for customized MT lexicons, and building parallel corpora for MT evaluation require translators and non-native speaking analysts to handle large document collections. These collections are further complicated by differences in format, encoding, source media, and access to metadata describing the documents. Automated tools that allow language professionals to quickly annotate, translate, and evaluate foreign language documents are essential to improving MT quality and efficacy. The purpose of this paper is present our research approach to improving MT through pre-processing source language documents. In particular, we will discuss the development and use of MTriage, an application environment that enables the translator to markup documents with metadata for MT parameterization and routing. The use of MTriage as a web-enabled front end to multiple MT engines has leveraged the capabilities of our human translators for creating lexicons from NFW (Not-Found-Word) lists, writing reference translations, and creating parallel corpora for MT development and evaluation."
voss-etal-2008-exploitation,Exploitation of an {A}rabic Language Resource for Machine Translation Evaluation: using {B}uckwalter-based Lookup Tool to Augment {CMU} Alignment Algorithm,2008,0,0,1,1,4860,clare voss,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Voss et al. (2006) analyzed newswire translations of three DARPA GALE Arabic-English MT systems at the segment level in terms of subjective judgmen+F925t scores, automated metric scores, and correlations among these different score types. At this level of granularity, the correlations are weak. In this paper, we begin to reconcile the subjective and automated scores that underlie these correlations by explicitly ÂgroundingÂ MT output with its Reference Translation (RT) prior to subjective or automated evaluation. The first two phases of our approach annotate {MT, RT} pairs with the same types of textual comparisons that subjects intuitively apply, while the third phase (not presented here) entails scoring the pairs: (i) automated calculation of ÂMT-RT hitsÂ using CMU aligner from METEOR, (ii) an extension phase where our Buckwalter-based Lookup Tool serves to generate six other textual comparison categories on items in the MT output that the CMU aligner does not identify, and (iii) given the fully categorized RT {\&} MT pair, a final adequacy score is assigned to the MT output, either by an automated metric based on weighted category counts and segment length, or by a trained human judge."
2008.eamt-1.26,Boosting performance of weak {MT} engines automatically: using {MT} output to align segments {\\&} build statistical post-editors,2008,8,2,1,1,4860,clare voss,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,"This paper addresses the practical challenge of improving existing, op- erational translation systems with relatively weak, black-box MT engines when higher quality MT engines are not available and only a limited quantity of online re- sources is available. Recent research results show impressive performance gains in translating between Indo-European languages when chaining mature, existing rule- based MT engines and post-MT editors built automatically with limited amounts of parallel data. We show that this hybrid approach of serially composing or chaining an MT engine and automated post-MT editor---when applied to much weaker lexi- con-based and rule-based MT engines, translating across the more widely divergent languages of Urdu and English, and given limited amounts of document-parallel only training data---will yield statistically significant boosts in translation quality up to the 50K of parallel segments in training the post-editor, but not necessarily be- yond that."
2008.amta-govandcom.12,Designing and executing {MT} workflows through the Kepler Framework,2008,-1,-1,2,1,28555,reginald hobbs,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Government and Commercial Uses of MT,0,None
2007.mtsummit-papers.32,Report on the {NSF}-sponsored Human Language Technology Workshop on Industrial Centers,2007,-1,-1,19,0,40215,mary harper,Proceedings of Machine Translation Summit XI: Papers,0,None
laoudi-etal-2006-task,Task-based {MT} Evaluation: From Who/When/Where Extraction to Event Understanding,2006,7,6,3,1,28087,jamal laoudi,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Task-based machine translation (MT) evaluation asks, how well do people perform text-handling tasks given MT output? This method of evaluation yields an extrinsic assessment of an MT engine, in terms of usersÂ task performance on MT output. While this method is time-consuming, its key advantage is that MT users and stakeholders understand how to interpret the assessment results. Prior experiments showed that subjects can extract individual who-, when-, and where-type elements of information from MT output passages that were not especially fluent. This paper presents the results of a pilot study to assess a slightly more complex task: when given such wh-items already identified in an MT output passage, how well can subjects properly select from and place these items into wh-typed slots to complete a sentence-template about the passageÂs event? The results of the pilot with nearly sixty subjects, while only preliminary, indicate that this task was extremely challenging: given six test templates to complete, half of the subjects had no completely correct templates and 42{\%} had exactly one completely correct template. The provisional interpretation of this pilot study is that event-based template completion defines a task ceiling, against which to evaluate future improvements on MT engines."
2006.eamt-1.25,"Task-based Evaluation of Machine Translation ({MT}) Engines. Measuring How Well People Extract Who, When, Where-Type Elements in {MT} Output",2006,-1,-1,1,1,4860,clare voss,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,None
2006.amta-papers.27,Combining Evaluation Metrics via Loss Functions,2006,19,3,2,1,48812,calandra tate,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"When response metrics for evaluating the utility of machine translation (MT) output on a given task do not yield a single ranking of MT engines, how are MT users to decide which engine best supports their task? When the cost of different types of response errors vary, how are MT users to factor that information into their rankings? What impact do different costs have on response-based rankings? Starting with data from an extraction experiment detailed in Voss and Tate (2006), this paper describes three response-rate metrics developed to quantify different aspects of MT users{'} performance identifying who/when/where-items in MT output, and then presents a loss function analysis over these rates to derive a single customizable metric, applying a range of values to correct responses and costs to different error types. For the given experimental dataset, loss function analyses provided a clearer characterization of the engines{'} relative strength than did comparing the response rates to each other. For one MT engine, varying the costs had no impact: the engine consistently ranked best. By contrast, cost variations did impact the ranking of the other two engines: a rank reversal occurred on who-item extractions when incorrect responses were penalized more than non-responses. Future work with loss analysis, developing operational cost ratios of error rates to correct response rates, will require user studies and expert document-screening personnel to establish baseline values for effective MT engine support on wh-item extraction."
2004.eamt-1.13,Towards an automated evaluation of an embedded {MT} system,2004,-1,-1,3,0,52497,laoudi,Proceedings of the 9th EAMT Workshop: Broadening horizons of machine translation and its applications,0,None
2003.mtsummit-eval.6,"Task-based {MT} evaluation: tackling software, experimental design, {\\&} statistical models.",2003,-1,-1,3,1,48812,calandra tate,Workshop on Systemizing MT Evaluation,0,"Even with recent, renewed attention to MT evaluation{---}due in part to n-gram-based metrics (Papineni et al., 2001; Doddington, 2002) and the extensive, online catalogue of MT metrics on the ISLE project (Hovy et al., 2001, 2003), few reports involving task-based metrics have surfaced. This paper presents our work on three parts of task-based MT evaluation: (i) software to track and record users' task performance via a browser, run from a desktop computer or remotely over the web, (ii) factorial experimental design with replicate observations to compare the MT engines, based on the accuracy of users' task responses, and (iii) the use of chi-squared and generalized linear models (GLMs) to permit finer-grained data analyses. We report on the experimental results of a six-way document categorization task, used for the evaluation of three Korean-English MT engines. The statistical models of the probabilities of correct responses yield an ordering of the MT engines, with one engine having a statistically significant lead over the other two. Future research will involve testing user performance on linguistically more complex tasks, as well as extending our initial GLMs with the documents' Bleu scores as variables, to test the scores as independent predictors of task results."
W00-0501,When is an Embedded {MT} System {``}Good Enough{''} for Filtering?,2000,6,5,1,1,4860,clare voss,{ANLP}-{NAACL} 2000 Workshop: Embedded Machine Translation Systems,0,"This paper proposes an end-to-end process analysis template with replicable measures to evaluate the filtering performance of a Scan-OCR-MT system. Preliminary results across three language-specific FALCon systems show that, with one exception, the derived measures consistently yield the same performance ranking: Haitian Creole at the low end, Arabic in the middle, and Spanish at the high end."
W99-0406,Dual Use of Linguistic Resources: Evaluation of {MT} Systems and Language Learners,1999,10,0,2,0,54867,lisa decrozant,Computer Mediated Language Assessment and Evaluation in Natural Language Processing,0,"Human translators working with embedded machine translation (MT) systems on the task of filtering text documents in a foreign language often have limited training in the foreign language they encounter. For our MT system users who are also language learners, we are developing a suite of linguistic tools that enable them, on the same laptop platform, to perform their foreign language filtering tasks using a combination of Optical Character Recognition (OCR), Machine Translation (MT), Information Retrieval (IR) and language sustainment tools. Thus we have begun constructing linguistic test suites that can serve the dual needs we have for the evaluation of MT systems and language learning."
1994.amta-1.6,The Case for a {MT} Developers{'} Tool with a Two-Component View of the Interlingua,1994,-1,-1,2,0,14512,bonnie dorr,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
