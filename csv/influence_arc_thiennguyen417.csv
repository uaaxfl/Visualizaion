2020.acl-main.523,W17-4419,0,0.0417257,"cally requires a large amount of manually labeled training data, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., training coarsegrained NER (Aguilar et al., 2017), fine-tuning bilingual word embeddings (Wang et al., 2017), applying language models (Rei, 2017), integrating part-of-speech (POS) tagging (Lin et al., 2018), using cross-lingual knowledge (Feng et al., 2018), and learning paraphrases (Watanabe et al., 2019). While most of the previous studies have exploited token-level information from auxiliary tasks, a few of them have tried to use sentence-level information (Rei and Søgaard, 2018; Devlin et al., 2019). Our work is closely related to the joint labeling framework in Rei and Søgaard (2019). However, they only focused on binary classification"
2020.acl-main.523,N19-4010,0,0.0111932,"y Bag Messenger bag for Men Women Office Laptop”, the underlined elements are 3 PRODUCT and 2 CONSUMER_GROUP entities. The other reason is that in one product title, it is common to find repeated identical expressions in the same language, as well as the same entity words appearing in English. Using a VI example to illustrate: “T-Shirt - Áo thun in phản quang Ao thun Nam - Ao thun nữ - Áo thun phong cách Nam Nữ”, the underlined elements refer to the same product (t-shirt), appearing multiple times in VI and in English. 3.2 Training details We implement our model on top of the Flair framework (Akbik et al., 2019), which has recently achieved state-of-the-art results in various sequence labeling tasks. Following Lample et al. (2016), we use the IOBES tagging scheme. We use the pretrained word embeddings of fastText4 (Bojanowski et al., 2016) with de = 300 dimensions for each language and a single-layer BiLSTM with dh = 512 hidden units. We apply a locked dropout (Merity et al., 2018) with the probability of 0.5 before and after the BiLSTM layer and to the attention output before the residual connection. For the multi-head self-attention layer, we adapt the implementation of “The Annotated Transformer”"
2020.acl-main.523,C18-1139,0,0.0128372,"… Korean flexible silicon case …’’ Category: HEALTH_BEAUTY Title: COMBO Gôm Label: O Translation: combo xịt tóc Tigi Bed Head B-PRODUCT I-PRODUCT E-PRODUCT B-BRAND I-BRAND E-BRAND hairspray Tigi Bed Head ‘‘… Tigi Bed Head hairspray combo …’’ Figure 1: Examples of product titles with NER annotation in Vietnamese. Product categories are provided by sellers and can be used as sentence-level labels. Introduction Neural named entity recognition (NER) has become a mainstream approach due to its superior performance (Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Akbik et al., 2018). However, neural NER typically requires a large amount of manually labeled training data, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., tr"
2020.acl-main.523,Q16-1026,0,0.0372942,"le Hàn Quốc O O Korea ‘‘… Korean flexible silicon case …’’ Category: HEALTH_BEAUTY Title: COMBO Gôm Label: O Translation: combo xịt tóc Tigi Bed Head B-PRODUCT I-PRODUCT E-PRODUCT B-BRAND I-BRAND E-BRAND hairspray Tigi Bed Head ‘‘… Tigi Bed Head hairspray combo …’’ Figure 1: Examples of product titles with NER annotation in Vietnamese. Product categories are provided by sellers and can be used as sentence-level labels. Introduction Neural named entity recognition (NER) has become a mainstream approach due to its superior performance (Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Akbik et al., 2018). However, neural NER typically requires a large amount of manually labeled training data, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of"
2020.acl-main.523,N16-1030,0,0.809852,"TERIAL S-PATTERN case dẻo silicon flexible Hàn Quốc O O Korea ‘‘… Korean flexible silicon case …’’ Category: HEALTH_BEAUTY Title: COMBO Gôm Label: O Translation: combo xịt tóc Tigi Bed Head B-PRODUCT I-PRODUCT E-PRODUCT B-BRAND I-BRAND E-BRAND hairspray Tigi Bed Head ‘‘… Tigi Bed Head hairspray combo …’’ Figure 1: Examples of product titles with NER annotation in Vietnamese. Product categories are provided by sellers and can be used as sentence-level labels. Introduction Neural named entity recognition (NER) has become a mainstream approach due to its superior performance (Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Akbik et al., 2018). However, neural NER typically requires a large amount of manually labeled training data, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary task"
2020.acl-main.523,D17-1070,0,0.0361231,", . . . , wT be an input token sequence, where wt denotes the t-th token in the sequence. We represent each wt using a pre-trained word embedding et ∈ Rde , where de is the dimensionality of word embeddings. We do not fine-tune word embeddings but project them into a new space ← ht = concat( h t , h t ) ∈ Rdh . We can either use H for both the sentence classification and NER tasks directly or apply an attention mechanism on it to help the model focus on particular tokens (detailed in §2.2). Sentence classification We create a fixed size vector by applying max-pooling (Collobert et al., 2011; Conneau et al., 2017) over H, which encourages the model to capture the most useful local features encoded in the hidden states. We feed the fixed size global feature vector to a linear layer to obtain the unnormalized predicted scores for each class. Let K be the number of target classes, sk be the k-th normalized predicted score after applying a softmax function, and t ∈ RK be the one-hot encoded true label. To train the sentence classification model, we minimize the multi-class cross-entropy loss: N K 1 X X (i) (i) tk log(sk ), LC = − N (1) i=1 k=1 where i denotes the sentence index, and N is the number of trai"
2020.acl-main.523,N19-1423,0,0.293958,"used as sentence-level labels. Introduction Neural named entity recognition (NER) has become a mainstream approach due to its superior performance (Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Akbik et al., 2018). However, neural NER typically requires a large amount of manually labeled training data, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., training coarsegrained NER (Aguilar et al., 2017), fine-tuning bilingual word embeddings (Wang et al., 2017), applying language models (Rei, 2017), integrating part-of-speech (POS) tagging (Lin et al., 2018), using cross-lingual knowledge (Feng et al., 2018), and learning paraphrases (Watanabe et al., 2019). While most of the previous studies have exploited token-level"
2020.acl-main.523,D17-1206,0,0.0278784,"tle texts indicate that the proposed method is effective for low-resource NER across three different languages: Vietnamese, Thai, and Indonesian. Proposed method Figure 2 shows the architecture of our joint sentence and token labeling model. Our model is based on hard parameter sharing (Ruder, 2017) in which the hidden layers are shared between two tasks. The task-specific layers include a conditional random field (CRF) layer for NER and a linear layer for sentence classification.2 Unlike the standard MTL, which trains multiple tasks at once and expects the model to perform well on all tasks (Hashimoto et al., 2017; Rei and Søgaard, 2019), the goal of our work is to improve the performance of the main task (NER) using the auxiliary task (sentence classification) for creating pre-trained representations and as a regularizer. 2.1 dh 2 ← and a backward hid← dh den state sequence H = [ h 1 , . . . , h T ] ∈ RT × 2 , where dh is the number of hidden units. We concatenate the hidden states of both directions to obtain the final hidden representation H = [h1 , . . . , hT ] ∈ RT ×dh , where Figure 2: Architecture of our joint sentence and token labeling model. The attention layer is optional, which can be skipp"
2020.acl-main.523,P18-1074,0,0.0155237,"d data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., training coarsegrained NER (Aguilar et al., 2017), fine-tuning bilingual word embeddings (Wang et al., 2017), applying language models (Rei, 2017), integrating part-of-speech (POS) tagging (Lin et al., 2018), using cross-lingual knowledge (Feng et al., 2018), and learning paraphrases (Watanabe et al., 2019). While most of the previous studies have exploited token-level information from auxiliary tasks, a few of them have tried to use sentence-level information (Rei and Søgaard, 2018; Devlin et al., 2019). Our work is closely related to the joint labeling framework in Rei and Søgaard (2019). However, they only focused on binary classification, while we attempt to handle multi-class classification on both sentence and token levels. In this work, we focus on improving lowresource NER by exploiting l"
2020.acl-main.523,P16-1101,0,0.0598024,"dẻo silicon flexible Hàn Quốc O O Korea ‘‘… Korean flexible silicon case …’’ Category: HEALTH_BEAUTY Title: COMBO Gôm Label: O Translation: combo xịt tóc Tigi Bed Head B-PRODUCT I-PRODUCT E-PRODUCT B-BRAND I-BRAND E-BRAND hairspray Tigi Bed Head ‘‘… Tigi Bed Head hairspray combo …’’ Figure 1: Examples of product titles with NER annotation in Vietnamese. Product categories are provided by sellers and can be used as sentence-level labels. Introduction Neural named entity recognition (NER) has become a mainstream approach due to its superior performance (Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Akbik et al., 2018). However, neural NER typically requires a large amount of manually labeled training data, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to"
2020.acl-main.523,N18-1202,0,0.0503169,"y sellers and can be used as sentence-level labels. Introduction Neural named entity recognition (NER) has become a mainstream approach due to its superior performance (Huang et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; Akbik et al., 2018). However, neural NER typically requires a large amount of manually labeled training data, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., training coarsegrained NER (Aguilar et al., 2017), fine-tuning bilingual word embeddings (Wang et al., 2017), applying language models (Rei, 2017), integrating part-of-speech (POS) tagging (Lin et al., 2018), using cross-lingual knowledge (Feng et al., 2018), and learning paraphrases (Watanabe et al., 2019). While most of the previous studies have"
2020.acl-main.523,P17-1194,0,0.0237448,"rce languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., training coarsegrained NER (Aguilar et al., 2017), fine-tuning bilingual word embeddings (Wang et al., 2017), applying language models (Rei, 2017), integrating part-of-speech (POS) tagging (Lin et al., 2018), using cross-lingual knowledge (Feng et al., 2018), and learning paraphrases (Watanabe et al., 2019). While most of the previous studies have exploited token-level information from auxiliary tasks, a few of them have tried to use sentence-level information (Rei and Søgaard, 2018; Devlin et al., 2019). Our work is closely related to the joint labeling framework in Rei and Søgaard (2019). However, they only focused on binary classification, while we attempt to handle multi-class classification on both sentence and token levels. In thi"
2020.acl-main.523,N18-1027,0,0.0627943,"led data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., training coarsegrained NER (Aguilar et al., 2017), fine-tuning bilingual word embeddings (Wang et al., 2017), applying language models (Rei, 2017), integrating part-of-speech (POS) tagging (Lin et al., 2018), using cross-lingual knowledge (Feng et al., 2018), and learning paraphrases (Watanabe et al., 2019). While most of the previous studies have exploited token-level information from auxiliary tasks, a few of them have tried to use sentence-level information (Rei and Søgaard, 2018; Devlin et al., 2019). Our work is closely related to the joint labeling framework in Rei and Søgaard (2019). However, they only focused on binary classification, while we attempt to handle multi-class classification on both sentence and token levels. In this work, we focus on improving lowresource NER by exploiting large data, only having sentence-level labels. Figure 1 shows examples of product titles on an e-commerce website in Vietnamese. While the product titles with NER annotation done by our annotators are limited, those with product categories (e.g., ELECTRONICS) labeled by sellers ar"
2020.acl-main.523,W18-2509,0,0.0154433,"which has recently achieved state-of-the-art results in various sequence labeling tasks. Following Lample et al. (2016), we use the IOBES tagging scheme. We use the pretrained word embeddings of fastText4 (Bojanowski et al., 2016) with de = 300 dimensions for each language and a single-layer BiLSTM with dh = 512 hidden units. We apply a locked dropout (Merity et al., 2018) with the probability of 0.5 before and after the BiLSTM layer and to the attention output before the residual connection. For the multi-head self-attention layer, we adapt the implementation of “The Annotated Transformer” (Rush, 2018)5 and use its default hyperparameters. We train all models using Adam (Kingma and Ba, 2015) with the batch size of 32, the learning rate of 1e-3, and the gradient clipping of 5. We initialize all model parameters by sampling from U(−0.1, 0.1). We set λ in Eq. (3) to 1. We use the same parameter setting for all languages. We apply early stopping in which the learning rate decays by 3 For TH, 941 training examples remain after removing annotation errors. 4 https://fasttext.cc/docs/en/crawl-vectors.html 5 https://nlp.seas.harvard.edu/2018/04/03/attention.html 0.5 if the F1 score on the NER develo"
2020.acl-main.523,I17-2065,0,0.0122182,"a, which are not always available in low-resource languages. Training neural NER with limited labeled data can be very challenging. In this paper, we consider bridging multi-task learning (MTL) (Caruana, 1993; Ruder, 2017) and pretraining (Peters et al., 2018; Devlin et al., 2019) to leverage training signals of an auxiliary task that has a sufficiently large number of labeled data. Researchers have investigated a wide variety of auxiliary tasks and resources to boost the performance of neural NER, e.g., training coarsegrained NER (Aguilar et al., 2017), fine-tuning bilingual word embeddings (Wang et al., 2017), applying language models (Rei, 2017), integrating part-of-speech (POS) tagging (Lin et al., 2018), using cross-lingual knowledge (Feng et al., 2018), and learning paraphrases (Watanabe et al., 2019). While most of the previous studies have exploited token-level information from auxiliary tasks, a few of them have tried to use sentence-level information (Rei and Søgaard, 2018; Devlin et al., 2019). Our work is closely related to the joint labeling framework in Rei and Søgaard (2019). However, they only focused on binary classification, while we attempt to handle multi-class classification on"
2020.acl-main.715,H05-1091,0,0.126333,"entations learned by the deep learning models for RE, we introduce a new inductive bias to promote the similarity between the representation vectors for the overall sentences and the words along the shortest dependency paths between the two entity mentions. The intuition is that the relation between the two entity mentions of interest in a sentence for RE can be inferred from either the entire sentence or the shortest dependency path between the two entity mentions (due to the demonstrated ability of the shortest dependency path to capture the important context words for RE in the prior work (Bunescu and Mooney, 2005)). We thus expect that the representation vectors for the sentence and the dependency path should be similar (as both capture the semantic relation) and explicitly exploiting such similarity can help the models to induce more effective representations for RE. Our extensive experiments on three benchmark datasets (i.e., ACE 2005, SPOUSE and SciERC) demonstrate the effectiveness of the proposed model for RE, leading to the state-of-the-art performance for these datasets. 2 Related Work RE has been traditionally solved by the featurebased or kernel-based approaches (Zelenko et al., 8022 2003; Zho"
2020.acl-main.715,C10-1018,0,0.0389467,"ntence and the dependency path should be similar (as both capture the semantic relation) and explicitly exploiting such similarity can help the models to induce more effective representations for RE. Our extensive experiments on three benchmark datasets (i.e., ACE 2005, SPOUSE and SciERC) demonstrate the effectiveness of the proposed model for RE, leading to the state-of-the-art performance for these datasets. 2 Related Work RE has been traditionally solved by the featurebased or kernel-based approaches (Zelenko et al., 8022 2003; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen and Grishman, 2014; Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishma"
2020.acl-main.715,N19-1423,0,0.0381472,"sition embeddings and entity type embeddings, 200 hidden units for the CEON-LSTM model and all the other hidden vectors in the model (i.e., the hidden vectors in the final feed-forward neural network (with 2 layers) and the intermediate vectors in the weighted sum vector for x0t ), 1.0 for both loss tradeoff parameters α and β, and 0.001 for the initial learning rate with the Adam optimizer. The batch size is set to 50. Finally, we use either the uncontextualized word embeddings word2vec (with 300 dimensions) or the hidden vectors in the last layer of the BERTbase model (with 768 dimensions) (Devlin et al., 2019) to obtain the pre-trained word embeddings for the sentences (Devlin et al., 2019). We find it better to fix BERT in the experiments. Note that besides this section, we provide some additional analysis for the models in the Appendix. 4.2 Comparison with the state of the art We fist compare the proposed model (called CEONLSTM) with the baselines on the popular ACE 2005 dataset. In particular, the four following groups of RE models in the prior work on RE with the ACE 2005 dataset is chosen for comparison: (i) Feature based models: These models handdesign linguistic features for RE, i.e., FCM, H"
2020.acl-main.715,I17-2072,1,0.936545,"e negative log-likelihood function is then obtained to serve as the loss function for the model: Llabel = − log P (y|W, ws , wo ) (y is the golden relation label for ws and wo in W ). Eventually, the overall loss function of the model in this work is: L = Llabel + αLimport + βLpath (6) where α and β are trade-off parameters. The model is trained with shuffled mini-batching. 4 4.1 Experiments Datasets and Hyper-parameters We evaluate the models in this work using three benchmark datasets, i.e., ACE 2005, SPOUSE, and SciERC. For ACE 2005, similar to the previous work (Nguyen and Grishman, 2016; Fu et al., 2017; Shi et al., 2018; Veyseh et al., 2019), we use the dataset preprocessed and provided by (Yu et al., 2015) for compatible comparison. There are 6 different domains in this dataset, i.e., (bc, bn, cts, nw, un, and wl), covering text from news, conversations and web blogs. Following the prior work, the union of the domains bn and nw (called news) is used as the training data (called the source domain); a half of the documents in bc is reserved for the development data, and the remainder (cts, wl and the other half of bc) serve as the test data (called the target domains). This data separation f"
2020.acl-main.715,P19-1024,0,0.272518,"e semantic relationships between two entity mentions in text. Due to its importance, RE has been studied extensively in the literature. The recent studies on RE has focused on deep learning to develop methods to automatically induce sentence representations from data (Zeng et al., 2014; Nguyen and Grishman, 2015a; Verga et al., 2018). A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Guo et al., 2019; Tran et al., 2019). In particular, the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks (GCN) over the dependency trees (Zhang et al., 2018)). Unfortunately, these models might not be able to generalize well as the tree structures of the training data might significantly differ from those in the test data (i.e., the models are overfit to the syntactic structures in the training data). For instance, in the cross-doma"
2020.acl-main.715,P18-1175,0,0.0301798,"Missing"
2020.acl-main.715,D19-6203,1,0.888149,"Missing"
2020.acl-main.715,S10-1006,0,0.0317503,"Missing"
2020.acl-main.715,P15-2047,0,0.0384495,"problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017; Nguyen et al., 2019a), and self-attentions in Transformer (Verga et al., 2018). The syntactic information from the dependency trees has also been shown to be useful for the deep learning models for RE (Tai et al., 2015; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Peng et al., 2017; Zhang et al., 2018; Guo et al., 2019; Tran et al., 2019; Song et al., 2019; Veyseh et al., 2019). However, these methods tend to poorly generalize to new syntactic structures due to the direct reliance on the syntactic trees (e.g., in different domains) or fail to exploit the syntax-based importance of the words for RE due to the sole focus on edges of the dependency trees (Veyseh et al., 2019). 3 Model The RE problem can be formulated as a multi-class classification problem. Formally, given an input sentence W = w1 , w2 , . . . , wN where wt is the"
2020.acl-main.715,D18-1360,0,0.0227953,"data (called the target domains). This data separation facilitates the evaluation of the cross-domain generalization of the models due to the domain difference of the training and test data. The SPOUSE dataset is recently introduced by (Hancock et al., 2018), involving 22,195 sentences for the training data, 2,796 sentences for the validation data, and 2,697 sentences for the test data. Each sentence in this dataset contains two marked person names (i.e., the entity mentions) and the goal is to identify whether the two people mentioned in the sentence are spouses. Finally, the SciERC dataset (Luan et al., 2018) annotates 500 scientific abstracts for the entity mentions along with the coreferences and relations between them. For RE, this dataset provides 3,219 sentences in the training data, 455 sentences in the validation data and 974 sentences in the test data. We fine tune the hyper-parameters for the models in this work on the validation data of the ACE 2005 dataset. The best parameters suggested by this process include: 30 dimensions for the position embeddings and entity type embeddings, 200 hidden units for the CEON-LSTM model and all the other hidden vectors in the model (i.e., the hidden vec"
2020.acl-main.715,P16-1105,0,0.0410265,"raditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017; Nguyen et al., 2019a), and self-attentions in Transformer (Verga et al., 2018). The syntactic information from the dependency trees has also been shown to be useful for the deep learning models for RE (Tai et al., 2015; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Peng et al., 2017; Zhang et al., 2018; Guo et al., 2019; Tran et al., 2019; Song et al., 2019; Veyseh et al., 2019). However, these methods tend to poorly generalize to new syntactic structures due to the direct reliance on the syntactic trees (e.g., in different domains) or fail to exploit the syntax-based importance of the words for RE due to the sole focus on edges of the dependency trees (Veyseh et al., 2019). 3 Model The RE problem can be formulated as a multi-class classification problem. Formally, given an input sentence W = w1 , w2 , . . . , wN where wt is the t-th word in the senten"
2020.acl-main.715,C18-1193,1,0.849838,"contextual importance of wt with respect to the relation prediction between ws and wo in W . In this section, we first describe the ON-LSTM model to achieve these importance scores (i.e., the model-based scores). A new model (called CEON-LSTM) that integrates the representation of the entire sentence into the cells of ON-LSTM will be presented afterward. ON-LSTM: Long-short Term Memory Networks (LSTM) (Hochreiter and Schmidhuber, 1997) has been widely used in Natural Language Processing (NLP) due to its natural mechanism to obtain the abstract representations for a sequence of input vectors (Nguyen and Nguyen, 2018b, 2019). Given the input representation vector sequence X = x1 , x2 , . . . , xN , LSTM produces a sequence of hidden vectors H = h1 , h2 , . . . , hN using the following recurrent functions at the time step (word) wt (assuming the zero vector for h0 ): ft = σ(Wf xt + Uf ht−1 + bf ) it = σ(Wi xt + Ui ht−1 + bi ) ot = σ(Wo xt + Uo ht−1 + bo ) cˆt = tanh(Wc xt + Uc ht−1 + bc ) (1) ct = ft ◦ ct−1 + it ◦ cˆt ht = ot ◦ tanh(ct ) where ft , it and ot are called the forget, input and output gates (respectively). In order to compute the importance score for each word wt , ON-LSTM introduce into the m"
2020.acl-main.715,N16-1034,1,0.872658,"posed model CEON-LSTM achieves significantly better performance than HIS-CEON-LSTM (with large performance gap), thus testifying to the importance of the master gates to obtain the model-based importance scores for CEON-LSTM. 5 whole input sentences and the shortest dependency paths between the two entity mentions for RE. Extensive experiments are conducted to demonstrate the benefits of the proposed model. We achieve the state-of-the-art performance on three datasets for RE. In the future, we plan to apply CEON-LSTM to other related NLP tasks (e.g., Event Extraction, Semantic Role Labeling) (Nguyen et al., 2016a; Nguyen and Grishman, 2018a). Acknowledgments This research has been supported in part by Vingroup Innovation Foundation (VINIF) in project code VINIF.2019.DA18, the NSF grant CNS1747798 to the IUCRC Center for Big Learning, and a gift from Adobe Research. This research is also based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA Contract No. 201919051600006 under the Better Extraction from Text Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein"
2020.acl-main.715,Q17-1008,0,0.0380413,"s, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017; Nguyen et al., 2019a), and self-attentions in Transformer (Verga et al., 2018). The syntactic information from the dependency trees has also been shown to be useful for the deep learning models for RE (Tai et al., 2015; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Peng et al., 2017; Zhang et al., 2018; Guo et al., 2019; Tran et al., 2019; Song et al., 2019; Veyseh et al., 2019). However, these methods tend to poorly generalize to new syntactic structures due to the direct reliance on the syntactic trees (e.g., in different domains) or fail to exploit the syntax-based importance of the words for RE due to the sole focus on edges of the dependency trees (Veyseh et al., 2019). 3 Model The RE problem can be formulated as a multi-class classification problem. Formally, given an input sentence W = w1 , w2 , . . . , wN where wt is the t-th word in the sentence W of length N ,"
2020.acl-main.715,P15-1061,0,0.0149081,"03; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen and Grishman, 2014; Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017; Nguyen et al., 2019a), and self-attentions in Transformer (Verga et al., 2018). The syntactic information from the dependency trees has also been shown to be useful for the deep learning models for RE (Tai et al., 2015; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Peng et al., 2017; Zhang et al., 2018; Guo et al., 2019; Tran et al., 2019; Song et al., 2019; Veyseh et al., 2019). However, these methods tend to poorly generalize to new syntactic structures due to the di"
2020.acl-main.715,D18-1125,0,0.23386,"liance on the syntactic trees (e.g., in different domains) or fail to exploit the syntax-based importance of the words for RE due to the sole focus on edges of the dependency trees (Veyseh et al., 2019). 3 Model The RE problem can be formulated as a multi-class classification problem. Formally, given an input sentence W = w1 , w2 , . . . , wN where wt is the t-th word in the sentence W of length N , and two entity mentions of interest at indexes s and o (1 ≤ s < o ≤ N ), our goal is to predict the semantic relation between ws and wo in W . Similar to the previous work on deep learning for RE (Shi et al., 2018; Veyseh et al., 2019), we first transform each word wt into a representation vector xt using the concatenation of the three following vectors: (i) the pre-trained word embeddings of wt , (ii) the position embedding vectors (to encode the relative distances of wt to the two entity mentions of interest ws and wo (i.e., t − s and t − o)), and (iii) the entity type embeddings (i.e., the embeddings of the BIO labels for the words to capture the entity mentions present in X). This word-to-vector transformation converts the input sentence W into a sequence of representation vectors X = x1 , x2 , . ."
2020.acl-main.715,P11-1053,0,0.0729171,"vectors for the sentence and the dependency path should be similar (as both capture the semantic relation) and explicitly exploiting such similarity can help the models to induce more effective representations for RE. Our extensive experiments on three benchmark datasets (i.e., ACE 2005, SPOUSE and SciERC) demonstrate the effectiveness of the proposed model for RE, leading to the state-of-the-art performance for these datasets. 2 Related Work RE has been traditionally solved by the featurebased or kernel-based approaches (Zelenko et al., 8022 2003; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen and Grishman, 2014; Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Network"
2020.acl-main.715,P14-2012,1,0.902936,"ency path should be similar (as both capture the semantic relation) and explicitly exploiting such similarity can help the models to induce more effective representations for RE. Our extensive experiments on three benchmark datasets (i.e., ACE 2005, SPOUSE and SciERC) demonstrate the effectiveness of the proposed model for RE, leading to the state-of-the-art performance for these datasets. 2 Related Work RE has been traditionally solved by the featurebased or kernel-based approaches (Zelenko et al., 8022 2003; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen and Grishman, 2014; Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016;"
2020.acl-main.715,P15-1150,0,0.0245195,"has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017; Nguyen et al., 2019a), and self-attentions in Transformer (Verga et al., 2018). The syntactic information from the dependency trees has also been shown to be useful for the deep learning models for RE (Tai et al., 2015; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Peng et al., 2017; Zhang et al., 2018; Guo et al., 2019; Tran et al., 2019; Song et al., 2019; Veyseh et al., 2019). However, these methods tend to poorly generalize to new syntactic structures due to the direct reliance on the syntactic trees (e.g., in different domains) or fail to exploit the syntax-based importance of the words for RE due to the sole focus on edges of the dependency trees (Veyseh et al., 2019). 3 Model The RE problem can be formulated as a multi-class classification problem. Formally, given an input sentence W = w1"
2020.acl-main.715,W15-1506,1,0.957182,"ion injection. We perform extensive experiments to demonstrate the effectiveness of the proposed method, leading to the state-of-the-art performance on three RE benchmark datasets. 1 Introduction One of the fundamental tasks in Information Extraction (IE) is Relation Extraction (RE) where the goal is to find the semantic relationships between two entity mentions in text. Due to its importance, RE has been studied extensively in the literature. The recent studies on RE has focused on deep learning to develop methods to automatically induce sentence representations from data (Zeng et al., 2014; Nguyen and Grishman, 2015a; Verga et al., 2018). A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Guo et al., 2019; Tran et al., 2019). In particular, the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks (GCN) over the dependency tr"
2020.acl-main.715,N19-1286,0,0.231821,"nships between two entity mentions in text. Due to its importance, RE has been studied extensively in the literature. The recent studies on RE has focused on deep learning to develop methods to automatically induce sentence representations from data (Zeng et al., 2014; Nguyen and Grishman, 2015a; Verga et al., 2018). A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Guo et al., 2019; Tran et al., 2019). In particular, the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks (GCN) over the dependency trees (Zhang et al., 2018)). Unfortunately, these models might not be able to generalize well as the tree structures of the training data might significantly differ from those in the test data (i.e., the models are overfit to the syntactic structures in the training data). For instance, in the cross-domain setting for RE, t"
2020.acl-main.715,N18-1080,0,0.145516,"tensive experiments to demonstrate the effectiveness of the proposed method, leading to the state-of-the-art performance on three RE benchmark datasets. 1 Introduction One of the fundamental tasks in Information Extraction (IE) is Relation Extraction (RE) where the goal is to find the semantic relationships between two entity mentions in text. Due to its importance, RE has been studied extensively in the literature. The recent studies on RE has focused on deep learning to develop methods to automatically induce sentence representations from data (Zeng et al., 2014; Nguyen and Grishman, 2015a; Verga et al., 2018). A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Guo et al., 2019; Tran et al., 2019). In particular, the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks (GCN) over the dependency trees (Zhang et al., 201"
2020.acl-main.715,P15-1062,1,0.890147,"(as both capture the semantic relation) and explicitly exploiting such similarity can help the models to induce more effective representations for RE. Our extensive experiments on three benchmark datasets (i.e., ACE 2005, SPOUSE and SciERC) demonstrate the effectiveness of the proposed model for RE, leading to the state-of-the-art performance for these datasets. 2 Related Work RE has been traditionally solved by the featurebased or kernel-based approaches (Zelenko et al., 8022 2003; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen and Grishman, 2014; Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017;"
2020.acl-main.715,P19-1132,0,0.0351558,"Missing"
2020.acl-main.715,P16-1123,0,0.0658141,"Missing"
2020.acl-main.715,D15-1206,0,0.261466,"oal is to find the semantic relationships between two entity mentions in text. Due to its importance, RE has been studied extensively in the literature. The recent studies on RE has focused on deep learning to develop methods to automatically induce sentence representations from data (Zeng et al., 2014; Nguyen and Grishman, 2015a; Verga et al., 2018). A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Guo et al., 2019; Tran et al., 2019). In particular, the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks (GCN) over the dependency trees (Zhang et al., 2018)). Unfortunately, these models might not be able to generalize well as the tree structures of the training data might significantly differ from those in the test data (i.e., the models are overfit to the syntactic structures in the training data). For instance,"
2020.acl-main.715,N15-1155,0,0.106033,"− log P (y|W, ws , wo ) (y is the golden relation label for ws and wo in W ). Eventually, the overall loss function of the model in this work is: L = Llabel + αLimport + βLpath (6) where α and β are trade-off parameters. The model is trained with shuffled mini-batching. 4 4.1 Experiments Datasets and Hyper-parameters We evaluate the models in this work using three benchmark datasets, i.e., ACE 2005, SPOUSE, and SciERC. For ACE 2005, similar to the previous work (Nguyen and Grishman, 2016; Fu et al., 2017; Shi et al., 2018; Veyseh et al., 2019), we use the dataset preprocessed and provided by (Yu et al., 2015) for compatible comparison. There are 6 different domains in this dataset, i.e., (bc, bn, cts, nw, un, and wl), covering text from news, conversations and web blogs. Following the prior work, the union of the domains bn and nw (called news) is used as the training data (called the source domain); a half of the documents in bc is reserved for the development data, and the remainder (cts, wl and the other half of bc) serve as the test data (called the target domains). This data separation facilitates the evaluation of the cross-domain generalization of the models due to the domain difference of"
2020.acl-main.715,C14-1220,0,0.439643,"syntactic information injection. We perform extensive experiments to demonstrate the effectiveness of the proposed method, leading to the state-of-the-art performance on three RE benchmark datasets. 1 Introduction One of the fundamental tasks in Information Extraction (IE) is Relation Extraction (RE) where the goal is to find the semantic relationships between two entity mentions in text. Due to its importance, RE has been studied extensively in the literature. The recent studies on RE has focused on deep learning to develop methods to automatically induce sentence representations from data (Zeng et al., 2014; Nguyen and Grishman, 2015a; Verga et al., 2018). A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Guo et al., 2019; Tran et al., 2019). In particular, the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks ("
2020.acl-main.715,D18-1244,0,0.514323,"rga et al., 2018). A notable insight in these recent studies is that the syntactic trees of the input sentences (i.e., the dependency trees) can provide effective information for the deep learning models, leading to the stateof-the-art performance for RE recently (Xu et al., 2015; Guo et al., 2019; Tran et al., 2019). In particular, the previous deep learning models for RE has mostly exploited the syntactic trees to structure the network architectures according to the word connections presented in the trees (e.g., performing Graph Convolutional Neural Networks (GCN) over the dependency trees (Zhang et al., 2018)). Unfortunately, these models might not be able to generalize well as the tree structures of the training data might significantly differ from those in the test data (i.e., the models are overfit to the syntactic structures in the training data). For instance, in the cross-domain setting for RE, the domains for the training data and test data are dissimilar, often leading to a mismatch between the syntactic structures of the training data and test data. In order to overcome this issue, the overall strategy is to obtain a more general representation of the syntactic trees that can be used to i"
2020.acl-main.715,D17-1004,0,0.022091,"Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017; Nguyen et al., 2019a), and self-attentions in Transformer (Verga et al., 2018). The syntactic information from the dependency trees has also been shown to be useful for the deep learning models for RE (Tai et al., 2015; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Peng et al., 2017; Zhang et al., 2018; Guo et al., 2019; Tran et al., 2019; Song et al., 2019; Veyseh et al., 2019). However, these methods tend to poorly generalize to new syntactic structures due to the direct reliance on the syntactic trees (e.g., in different domains) or fail to exploit the syntax-based importance"
2020.acl-main.715,P05-1053,0,0.426203,"05)). We thus expect that the representation vectors for the sentence and the dependency path should be similar (as both capture the semantic relation) and explicitly exploiting such similarity can help the models to induce more effective representations for RE. Our extensive experiments on three benchmark datasets (i.e., ACE 2005, SPOUSE and SciERC) demonstrate the effectiveness of the proposed model for RE, leading to the state-of-the-art performance for these datasets. 2 Related Work RE has been traditionally solved by the featurebased or kernel-based approaches (Zelenko et al., 8022 2003; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen and Grishman, 2014; Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015;"
2020.acl-main.715,P16-2034,0,0.02743,"and Grishman, 2014; Nguyen et al., 2015c). One of the issues in these approaches is the requirement for extensive feature or kernel engineering effort that hinder the generalization and applicability of the RE models. Recently, deep learning has been applied to address these problems for the traditional RE approaches, producing the state-ofthe-art performance for RE. The typical network architectures for RE include the Convolutional Neural Networks (Zeng et al., 2014; Nguyen and Grishman, 2015a; dos Santos et al., 2015; Wang et al., 2016), Recurrent Neural Networks (Nguyen and Grishman, 2016; Zhou et al., 2016; Zhang et al., 2017; Nguyen et al., 2019a), and self-attentions in Transformer (Verga et al., 2018). The syntactic information from the dependency trees has also been shown to be useful for the deep learning models for RE (Tai et al., 2015; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Peng et al., 2017; Zhang et al., 2018; Guo et al., 2019; Tran et al., 2019; Song et al., 2019; Veyseh et al., 2019). However, these methods tend to poorly generalize to new syntactic structures due to the direct reliance on the syntactic trees (e.g., in different domains) or fail to exploit the synt"
2020.coling-main.292,W15-3822,0,0.452357,"plications including slotfilling (Veyseh et al., 2020), definition extraction (Kang et al., 2020; Veyseh et al., 2020), and question answering (Ackermann et al., 2020; Veyseh, 2016) Over the past two decades, several approaches and resources have been proposed to solve the two subtasks for acronyms. These approaches extend from rule-based methods for AI and feature-based models for AD (i.e., SVM and Naive Bayes) (Schwartz and Hearst, 2002; Nadeau and Turney, 2005; Okazaki and Ananiadou, 2006; Yu et al., 2007) to the recent deep learning methods (Li et al., 2015; Charbonnier and Wartena, 2018; Wu et al., 2015; Ciosici et al., 2019; Jin et al., 2019; Li et al., 2019). While the prior work has made substantial progress on this task by providing new approaches and datasets, there are some limitations in the existing datasets which hinder further improvement. First, most of the existing datasets for AI are either limited in their sizes or created using simple rule-based methods (i.e., not humnanannotated). For instance, Ciosici (2019) exploits the rules proposed by Schwartz (2002) to generate a corpus for acronym disambiguation from Wikipedia. This is unfortunate as rules are in general not able to ca"
2020.emnlp-main.433,P17-1038,0,0.0225165,"y is then extended in the SecureNLP SemEval evaluation (Phandi et al., 2018). However, different from our CySecED dataset, the annotated dataset in these work is very sparse (i.e., involving less than 5 examples for many labels), hindering the development of the deep learning models (Roy et al., 2019). Also, it does not annotate event triggers for rich event types as we do. Finally, ED has been extensively studied in the literature (Liao and Grishman, 2010; Li et al., 2013; Nguyen and Grishman, 2015, 2016e; Chen et al., 2015; Nguyen et al., 2016g; Lu and Nguyen, 2018; Liu et al., 2016b, 2017; Chen et al., 2017; Hong et al., 2018; Lai et al., 2020b), partly due to the availability of the large evaluation datasets (i.e., the ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015) for the general domains, and the BioNLP datasets (Kim et al., 2009) for the biomedical domain). The closest works to our in the cybersecurity domain involve (Qiu et al., 2016) to extract events on Chinese news, (Khandpur et al., 2017) to perform cyberattack detection on Twitter, and (Satyapanich et al., 2019; Satyapanich et al., 2020) to present the CASIE dataset for event extraction. However, these datasets co"
2020.emnlp-main.433,P15-1017,0,0.472406,"ine Information Extraction technologies (IE) in Natural Language Processing ∗ The first four authors contribute equally to this paper. Corresponding author. † (NLP) as a promising candidate for the knowledge extraction task from cybersecurity text. In particular, we focus on Event Detection (ED), an important task in IE that seeks to identify trigger words of specified types of events in text (Ahn, 2006; Ji and Grishman, 2008). ED is an actively studied task in IE where deep learning models have been the dominant approach to deliver the state-of-the-art performance (Nguyen and Grishman, 2015; Chen et al., 2015). For instance, consider the sentence: Remote attackers to completely takeover player accounts just by tricking users into clicking an unsuspectable link. An ED system for cybersecurity texts should be able to identify “takeover” as an event trigger word of the event type ATTACK.User Compromise in this case. In order to enable the application of the ED methods in the cybersecurity domain, a crucial requirement has to do with the benchmark datasets to facilitate the development and evaluation of ED models. Unfortunately, most of the current benchmark datasets for ED (i.e., the ACE and TAC KBP d"
2020.emnlp-main.433,D18-1158,0,0.0129715,"raph Convolutional Neural Network model (GCN) based on dependency trees for ED. • MOGANED (Yan et al., 2019): an ED model with Multi-Order Graph Convolution and Attention. This is currently the state-of-the-art ED model with uncontextualized word embeddings in the general domain (i.e., the ACE 2005 dataset). • CyberLSTM (Satyapanich et al., 2020): a LSTM model developed for ED in the cybersecurity domain that exploits different features (e.g., the dependency trees) for the input representation. Regarding the document-level models, we consider the following representative ED models: • HBTNGMA (Chen et al., 2018): a Collective ED model with Hierarchical and Bias Tagging Networks and Gated Multi-level Attention Mechanisms to exploit the document-level information. • DEEB-RNN (Zhao et al., 2018): a Document Embedding Enhanced Bidirectional RNN for ED. For the models in this work, we experiment with both the traditional uncontextualized word embeddings word2vec (Mikolov et al., 2013b) (i.e., the 300 dimension version) and the recent contextualized word embeddings BERT (i.e., the uncased base model) (Devlin et al., 2019) as the pre-trained word embeddings. For BERT, we additionally evaluate the BERT-based"
2020.emnlp-main.433,N19-1423,0,0.0192534,"e document-level models, we consider the following representative ED models: • HBTNGMA (Chen et al., 2018): a Collective ED model with Hierarchical and Bias Tagging Networks and Gated Multi-level Attention Mechanisms to exploit the document-level information. • DEEB-RNN (Zhao et al., 2018): a Document Embedding Enhanced Bidirectional RNN for ED. For the models in this work, we experiment with both the traditional uncontextualized word embeddings word2vec (Mikolov et al., 2013b) (i.e., the 300 dimension version) and the recent contextualized word embeddings BERT (i.e., the uncased base model) (Devlin et al., 2019) as the pre-trained word embeddings. For BERT, we additionally evaluate the BERT-based ED models in (Wang et al., 2019) (called DMBERT) and (Yang et al., 2019) (called BERT-ED) that are the sentence-level models with the best-reported ED performance on the ACE 2005 dataset. Finally, we tune the hyperparameters for the models using the development Training #Pos #Neg 6,776 192,937 6,382 224,684 #Pos 847 835 Test #Neg 24,804 29,152 Development #Pos #Neg 847 22,941 797 28,384 Table 3: The size of datasets. #Pos and #Neg represent the numbers of positive and negative examples. data of the datasets"
2020.emnlp-main.433,S18-1113,0,0.0568296,"Missing"
2020.emnlp-main.433,P19-1353,0,0.0355441,"Missing"
2020.emnlp-main.435,W06-0901,0,0.646727,"rd based on its distance to the trigger candidate. Afterward, we propose to incorporate such importance scores into the ED models by encouraging them to be consistent with another set of model-based importance scores that are computed from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the d"
2020.emnlp-main.435,P17-1038,0,0.450952,"Missing"
2020.emnlp-main.435,P15-1017,0,0.838731,"6). The event detection task, precisely speaking, seeks to identify the event triggers and classify them into some types of interest. For instance, consider the following sentences: (1) They’ll be fired on at the crossing. (2) She is on her way to get fired. An ideal ED system should be able to recognize the two words “fired” in the sentences as the triggers of the event types “Attack” (for the first sentence) and “End-Position” (for the second sentence). The dominant approaches for ED involve deep neural networks to learn effective features for the input sentences, including separate models (Chen et al., 2015) and joint inference models with event argument prediction (Nguyen and Nguyen, 2019). Among those deep neural networks, graph convolutional neural networks (GCN) (Kipf and Welling, 2017) have achieved state-of-the-art performance due to the ability to exploit the syntactic dependency graph to learn effective representations for the words (Nguyen and Grishman, 2018; Liu et al., 2018; Yan et al., 2019). However, two critical issues should be addressed to further improve the performance of such models. First, given a sentence and a trigger candidate word, the hidden vectors induced by the current"
2020.emnlp-main.435,D18-1158,0,0.523632,"graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in this work. 3 and classifying them for the event types of interest (event classification). Following the previous studies (Nguyen an"
2020.emnlp-main.435,N19-1423,0,0.0410504,"r the event types of interest (event classification). Following the previous studies (Nguyen and Grishman, 2015), we combine these two tasks as a single multi-way classification task by introducing a None class, indicating non-event. Formally, given a sentence X = [x1 , x2 , . . . , xn ] of n words, and an index t (1 ≤ t ≤ n) of the trigger candidate xt , the goal is to predict the event type y ∗ for the candidate xt . Our ED model consists of three modules: (1) Sentence Encoder, (2) GCN and Gate Diversity, and (3) Graph and Model Consistency. Sentence Encoder: We employ the pre-trained BERT (Devlin et al., 2019) to encode the given sentence X. In particular, we create an input sequence of [[CLS], x1 , · · · , xn , [SEP ], xt , [SEP ]] where [CLS] and [SEP ] are the two special tokens in BERT. The word pieces, tokenized from the words, are fed to BERT to obtain the hidden vectors of all layers. We concatenate the vectors of the top M layers to obtain the corresponding hidden vectors for each word piece, where M is a hyper-parameter. Then, we obtain the representation of the sentence E = {e1 , · · · , en } in which the vectors ei of xi is the average of layer-concatenated vectors of its word pieces. Fi"
2020.emnlp-main.435,P13-1008,0,0.613918,"terward, we propose to incorporate such importance scores into the ED models by encouraging them to be consistent with another set of model-based importance scores that are computed from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. Howe"
2020.emnlp-main.435,P17-1164,0,0.366215,"cy, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in this work. 3 and classifying them for the event types of interest (event classification). Following the previou"
2020.emnlp-main.435,D18-1156,0,0.255376,"Missing"
2020.emnlp-main.435,D17-1159,0,0.031988,", en } in which the vectors ei of xi is the average of layer-concatenated vectors of its word pieces. Finally, we feed the embedding vectors in E to a bidirectional LSTM, resulting in a sequence of hidden vectors h0 = {h01 , · · · , h0n }. GCN and Gate Diversity: To apply the GCN model, we first build the sentence graph G = (V, E) for X based on its dependency tree, where V, E are the sets of nodes and edges, respectively. V has n nodes, corresponding to the n words X. Each edge (xi , xj ) in E amounts to a directed edge from the head xi to the dependent xj in the dependency tree. Following (Marcheggiani and Titov, 2017), we also include the opposite edges of the dependency edges and the self-loops in E to improve the information flow in the graph. Our GCN module contains L stacked GCN layers (Kipf and Welling, 2017), operating over the sequence of hidden vectors h0 . The hidden vector hli (1 ≤ i ≤ n, 1 ≤ l ≤ L) of the word xi at the l-th layer is computed by averaging the hidden vectors of neighboring nodes of xi at the (l − 1)-th layer. Formally, hli is computed as follow:  hli = ReLU W l Model X (xi ,xj )∈E Task Description: The goal of ED consists of identifying trigger words (trigger identification) hl"
2020.emnlp-main.435,N16-1034,1,0.939306,"t of model-based importance scores that are computed from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in"
2020.emnlp-main.435,P16-2011,0,0.0850819,"rs of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in this work. 3 and classifying them for the event types of interest (event"
2020.emnlp-main.435,W16-1618,1,0.952834,"t of model-based importance scores that are computed from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in"
2020.emnlp-main.435,P11-1113,0,0.405393,"igger candidate. Afterward, we propose to incorporate such importance scores into the ED models by encouraging them to be consistent with another set of model-based importance scores that are computed from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the"
2020.emnlp-main.435,P15-2060,1,0.938178,"consistent with another set of model-based importance scores that are computed from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based"
2020.emnlp-main.435,N16-1056,0,0.0312232,"ted from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in this work. 3 and classifying them for the event type"
2020.emnlp-main.435,P08-1030,0,0.660912,"its distance to the trigger candidate. Afterward, we propose to incorporate such importance scores into the ED models by encouraging them to be consistent with another set of model-based importance scores that are computed from the hidden vectors of the models. Based on this consistency, we expect that graph-based scores can enhance the representation learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are emp"
2020.emnlp-main.435,2020.nuse-1.5,1,0.827212,"gregation mechanism in GCN to learn better hidden vectors, leading to improved performance for ED in this case. 5 P 76.7 78.5 80.5 79.0 77.8 83.0 Conclusion We demonstrate how gating mechanisms, gate diversity, and graph structure can be used to integrating syntactic information and improve the hidden vectors for ED models. The proposed model achieves state-of-the-art performance on two ED datasets. In the future, we plan to apply the proposed model for the related tasks and other settings of ED, including new type extension (Nguyen et al., 2016b; Lai and Nguyen, 2019), and few-shot learning (Lai et al., 2020a,b). Acknowledgement This research has been supported in part by Vingroup Innovation Foundation (VINIF) in project code VINIF.2019.DA18 and Adobe Research Gift. This research is also based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA Contract No. 2019-19051600006 under the Better Extraction from Text Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official"
2020.emnlp-main.435,D19-5532,1,0.857584,"nce scores. This enables the representation aggregation mechanism in GCN to learn better hidden vectors, leading to improved performance for ED in this case. 5 P 76.7 78.5 80.5 79.0 77.8 83.0 Conclusion We demonstrate how gating mechanisms, gate diversity, and graph structure can be used to integrating syntactic information and improve the hidden vectors for ED models. The proposed model achieves state-of-the-art performance on two ED datasets. In the future, we plan to apply the proposed model for the related tasks and other settings of ED, including new type extension (Nguyen et al., 2016b; Lai and Nguyen, 2019), and few-shot learning (Lai et al., 2020a,b). Acknowledgement This research has been supported in part by Vingroup Innovation Foundation (VINIF) in project code VINIF.2019.DA18 and Adobe Research Gift. This research is also based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA Contract No. 2019-19051600006 under the Better Extraction from Text Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are those of the authors and should not be interpreted"
2020.emnlp-main.435,D16-1085,1,0.924964,"Missing"
2020.emnlp-main.435,P19-1353,0,0.11959,"Missing"
2020.emnlp-main.435,P19-1432,1,0.6672,"ture engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in this work. 3 and classifying them for the event types of interest (event classification). Following the previous studies (Nguyen and Grishman, 2015), we combine these two tasks as a single multi-way classification task by introducing a None class, indicating non-event. Formally, given a sentence X = [x1 , x2 , . . . , xn ] of n words, and an index t (1 ≤ t ≤ n) of the trigg"
2020.emnlp-main.435,N19-1105,0,0.461192,"ow that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in this work. 3 and classifying them for the event types of interest (event classification). Following the previous studies (Nguyen and Grishman, 2015), we combine these two tasks as a single multi-way classification task by in"
2020.emnlp-main.435,D19-1582,0,0.485017,"sentence) and “End-Position” (for the second sentence). The dominant approaches for ED involve deep neural networks to learn effective features for the input sentences, including separate models (Chen et al., 2015) and joint inference models with event argument prediction (Nguyen and Nguyen, 2019). Among those deep neural networks, graph convolutional neural networks (GCN) (Kipf and Welling, 2017) have achieved state-of-the-art performance due to the ability to exploit the syntactic dependency graph to learn effective representations for the words (Nguyen and Grishman, 2018; Liu et al., 2018; Yan et al., 2019). However, two critical issues should be addressed to further improve the performance of such models. First, given a sentence and a trigger candidate word, the hidden vectors induced by the current GCN models are not yet customized for the trigger candidate. As such, the trigger-agnostic representations in the GCN models might retain redundant/noisy information that is not relevant to the trigger candidate. As the trigger candidate is the focused word in the sentence, that noisy information might impair the performance of the ED models. To this end, we propose to filter the noisy information f"
2020.emnlp-main.435,P19-1522,0,0.724093,"ion learning for ED. In our experiments, we show that our method outperforms the state-of-the-art models on the benchmark datasets for ED. 2 Related Work Prior studies on ED involve handcrafted feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2013; Mitamura et al., 2015) and deep neural networks, e.g., CNN (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016g), RNN (Nguyen et al., 2016; Jagannatha and Yu, 2016; Feng et al., 2016), attention mechanism (Liu et al., 2017; Chen et al., 2018), contextualized embeddings (Yang et al., 2019), and adversarial training (Wang et al., 2019). The last few years witness the success of graph convolutional neural networks for ED (Nguyen and Grishman, 2018; Liu et al., 2018; Veyseh et al., 2019; Yan et al., 2019) where the dependency trees are employed to boost the performance. However, these graph-based models have not considered representation regulation for GCNs and exploiting graph-based distances as we do in this work. 3 and classifying them for the event types of interest (event classification). Following the previous studies (Nguyen and Grishman, 2015), we combine these two tasks a"
2020.emnlp-main.488,N19-4010,0,0.02402,"Missing"
2020.emnlp-main.488,C18-1139,0,0.0275194,"Missing"
2020.emnlp-main.488,P18-1246,0,0.0265305,"Missing"
2020.emnlp-main.488,Q17-1010,0,0.0180151,"4) with initial learning rate 1e-3 and batch size 32. Learning rate is decayed by 0.5 if the performance on dev set does not improve in 3 consecutive epochs. We stop training when the learning rate drops below 1e-5 or number of epochs reaches 100. We use the pre3 Condition tag c is also in w<t , since it is a special token added to the beginning of each sentence. We write it explicitly to emphasize the conditional effect. 4 The baseline model provided in the original paper is used for evaluating end to end target based sentiment analysis task. trained 300-dimensional fastText word embeddings (Bojanowski et al., 2017) for all languages. We employ relatively simple basic models because: 1) They help to avoid the possible overfitting problems due to the small data size under the low resource setting; 2) They allow more faithful understanding on the effects of the proposed data augmentation method. 4.2 Supervised Experiments To verify the effectiveness of our data augmentation method in the supervised settings, we evaluate it on three different tagging tasks, including NER, POS and E2E-TBSA. Most of the prior works rely on additional information, so we use random deletion (rd) (Wei and Zou, 2019) as our basel"
2020.emnlp-main.488,D17-1047,1,0.833037,"Missing"
2020.emnlp-main.488,D17-1091,0,0.0158196,"t is more challenging to apply data augmentation techniques to natural language processing (NLP). Unlike computer vision and speech, where handcrafted rules (such as rotation, cropping, masking, etc.) can be easily applied to transform original data, it is difficult to generalize such rules for languages. Although simple distortion usually does not change the semantics of visual information, deleting or replacing a single word could completely change the meaning of the sentence. One successful method for data augmentation in NLP is back translation (Sennrich et al., 2016; Fadaee et al., 2017; Dong et al., 2017; Yu et al., 2018), where a translation model is used to translate monolingual sentences from target language to source language to generate synthetic parallel sentences. Other successful methods include: systematically reordering the dependents of some nodes in gold data to generate synthetic data for dependency parsing (Wang and Eisner, 2016), leveraging knowledge base for question generation (Serban et al., 2016) and using simulation-based approach to generate a set of prerequisite toy tasks for QA (Weston et al., 2015). Besides, synonym replace6045 Proceedings of the 2020 Conference on Emp"
2020.emnlp-main.488,P17-2090,0,0.0976786,"lexity of language, it is more challenging to apply data augmentation techniques to natural language processing (NLP). Unlike computer vision and speech, where handcrafted rules (such as rotation, cropping, masking, etc.) can be easily applied to transform original data, it is difficult to generalize such rules for languages. Although simple distortion usually does not change the semantics of visual information, deleting or replacing a single word could completely change the meaning of the sentence. One successful method for data augmentation in NLP is back translation (Sennrich et al., 2016; Fadaee et al., 2017; Dong et al., 2017; Yu et al., 2018), where a translation model is used to translate monolingual sentences from target language to source language to generate synthetic parallel sentences. Other successful methods include: systematically reordering the dependents of some nodes in gold data to generate synthetic data for dependency parsing (Wang and Eisner, 2016), leveraging knowledge base for question generation (Serban et al., 2016) and using simulation-based approach to generate a set of prerequisite toy tasks for QA (Weston et al., 2015). Besides, synonym replace6045 Proceedings of the 202"
2020.emnlp-main.488,P19-1553,1,0.679347,"wt |w<t ) in Eq. 2 becomes pθ (wt |w<t , c).3 A similar approach is used in CTRL (Keskar et al., 2019) to control style, task-specific behavior, etc., during text generation. 4 Experiments In this section, we present our experiments in both supervised and semi-supervised settings. In the supervised settings, only gold data are used for augmentation. In the semi-supervised settings, we also leverage unlabeled data and knowledge bases. 4.1 Basic Models Language Model We use the language model described in Section 3.2 for synthetic data generation. We modified the decoder of the LSTM-LM model in Kruengkrai (2019) to implement this language model. We set LSTM hidden state size to 512 and embedding size to 300. We use dropout rate 0.5 for the two dropout layers. All language model are trained using Stochastic gradient descent (SGD) with initial learning rate 1 and batch size 32. Learning rate will be decayed by 0.5 in the next epoch if the perplexity on dev set does not improve. We set the maximum number of epochs to 30 and stop training early if the perplexity on dev set does not improve in 3 consecutive epochs. During synthetic data generation, we use the average length of gold sentences in the traini"
2020.emnlp-main.488,2020.lifelongnlp-1.3,0,0.13528,"2016), leveraging knowledge base for question generation (Serban et al., 2016) and using simulation-based approach to generate a set of prerequisite toy tasks for QA (Weston et al., 2015). Besides, synonym replace6045 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 6045–6057, c November 16–20, 2020. 2020 Association for Computational Linguistics ment, random deletion/swap/insertion, generation with VAE or pre-trained language models are also used in some NLP tasks (Kobayashi, 2018; Wei and Zou, 2019; Anaby-Tavor et al., 2020; Raille et al., 2020; Kumar et al., 2020), but mainly for translation and classification tasks. Compared with the above-mentioned downstream tasks like translation and classification, sequence tagging is more fragile when it is confronted with data augmentation noises due to the finer granularity of the (token-level) task. Annotating unlabeled data with a weak tagger, leveraging aligned bilingual corpora to induce annotation and synonym replacement are three attempted data augmentation methods for sequence tagging (Shang et al., 2018; Yarowsky et al., 2001; Mathew et al., 2019). Weakly labeled data will inevitably introduce more nois"
2020.emnlp-main.488,N16-1030,0,0.308802,"ings, our method demonstrates strong ability to exploit useful information from unlabeled data and knowledge base. 2 Background Named Entity Recognition (NER) Named entities refer to phrases that are names of persons, organizations and locations, etc. in text. For example, “[ORG U.N.] official [PER Ekeus] heads for [LOC Baghdad] ”. Named entity recognition is an important task of information extraction and it aims to locate and classify named entities in text into the predefined types (Mikheev et al., 1999; Sang and De Meulder, 2003; Li et al., 2020). It is a challenging task for two reasons (Lample et al., 2016): 1) in most languages and domains, the amount of manually labeled training data for NER is limited; 2) it is difficult to generalize from this small sample of training data due to the constraints on the kinds of words that can be names. Part-of-Speech (POS) Tagging Part-of-speech tagging consists of assigning a tag that represents a grammatical class to each word in a given sentence. It is a critical component of most NLP systems and is fundamental to facilitate downstream tasks such as syntactic parsing (Sch¨utze, 1993) and opinion analysis (Liu et al., 2015). The current state-ofthe-art POS"
2020.emnlp-main.488,D19-5505,1,0.898289,"sunaga et al., 2018). Target Based Sentiment Analysis The target based sentiment analysis is a fundamental task of sentiment analysis and it aims to detect the opinion targets in sentences and predict the sentiment polarities over the targets (Liu et al., 2015; Chen et al., 2017; Li et al., 2018, 2019a). For example, “USB3 Peripherals are noticeably less expensive than the ThunderBolt ones”. In this sentence, two opinion targets were mentioned, namely “USB3 Peripherals” and “ThunderBolt ones” and the user expresses a positive sentiment over the first, and a negative sentiment over the second. Li et al. (2019a,b) propose an end-to-end solution (E2ETBSA) of TBSA, which converts TBSA to a tagging task, and aims to solve the two subtasks (i.e. target detection and sentiment classification) in a unified manning by predicting unified tags. For example, the tag “B-POS” indicates the beginning of a target with positive sentiment. So after annotation, the above example becomes “[B-POS USB3] [E-POS Peripherals] are noticeably less expensive than the [B-NEG ThunderBolt] [E-NEG ones]”. 3 Proposed Method We propose a novel data augmentation method for sequence tagging tasks. We first linearize labeled sentenc"
2020.emnlp-main.488,D15-1168,1,0.889428,"Missing"
2020.emnlp-main.488,P14-5010,0,0.00283339,"gold data). Our method. Generate synthetic data with LM, where LM is trained on gold data and unlabeled data. Baseline method. Annotate unlabeled data with knowledge base. Our method. Generate synthetic data with LM, where LM is trained on gold data and knowledge base annotated data. Table 5: Data sources for the semi-supervised setting. 4.3.1 Only Using Unlabeled Data Dataset We use CoNLL2003 English NER data (Tjong Kim Sang and De Meulder, 2003) for evaluation. In addition to the gold NER training data, we utilize unlabeled data for semi-supervised training. The Stanford CoreNLP tokenizer (Manning et al., 2014) is used to tokenize Wikipedia sentences. Experimental Settings Similar to the above experiments, we use 1k, 2k, 4k, 6k and 8k sentences randomly sampled from NER gold data as well as the full dataset to evaluate our method. For fair comparison, we only use the same set of 10k sentences randomly sampled from Wikipedia dump in both of our and baseline methods. Let Dgold and Dunlabeled be the sampled gold NER data and the Wikipedia data, respectively. In our method, Dgold and Dunlabeled are concatenated to train language models, following the steps 6051 Method 1k 2k 4k 6k 8k all gold 58.06 67.85"
2020.emnlp-main.488,E99-1001,0,0.544131,"Missing"
2020.emnlp-main.488,P16-2067,0,0.0505893,"Missing"
2020.emnlp-main.488,S15-2082,0,0.0602815,"Missing"
2020.emnlp-main.488,S14-2004,0,0.149978,"Missing"
2020.emnlp-main.488,W03-0419,0,0.698327,"Missing"
2020.emnlp-main.488,P93-1034,0,0.295575,"Missing"
2020.emnlp-main.488,P16-1009,0,0.0477906,"owever, due to the complexity of language, it is more challenging to apply data augmentation techniques to natural language processing (NLP). Unlike computer vision and speech, where handcrafted rules (such as rotation, cropping, masking, etc.) can be easily applied to transform original data, it is difficult to generalize such rules for languages. Although simple distortion usually does not change the semantics of visual information, deleting or replacing a single word could completely change the meaning of the sentence. One successful method for data augmentation in NLP is back translation (Sennrich et al., 2016; Fadaee et al., 2017; Dong et al., 2017; Yu et al., 2018), where a translation model is used to translate monolingual sentences from target language to source language to generate synthetic parallel sentences. Other successful methods include: systematically reordering the dependents of some nodes in gold data to generate synthetic data for dependency parsing (Wang and Eisner, 2016), leveraging knowledge base for question generation (Serban et al., 2016) and using simulation-based approach to generate a set of prerequisite toy tasks for QA (Weston et al., 2015). Besides, synonym replace6045 P"
2020.emnlp-main.488,P16-1056,0,0.021012,"a single word could completely change the meaning of the sentence. One successful method for data augmentation in NLP is back translation (Sennrich et al., 2016; Fadaee et al., 2017; Dong et al., 2017; Yu et al., 2018), where a translation model is used to translate monolingual sentences from target language to source language to generate synthetic parallel sentences. Other successful methods include: systematically reordering the dependents of some nodes in gold data to generate synthetic data for dependency parsing (Wang and Eisner, 2016), leveraging knowledge base for question generation (Serban et al., 2016) and using simulation-based approach to generate a set of prerequisite toy tasks for QA (Weston et al., 2015). Besides, synonym replace6045 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 6045–6057, c November 16–20, 2020. 2020 Association for Computational Linguistics ment, random deletion/swap/insertion, generation with VAE or pre-trained language models are also used in some NLP tasks (Kobayashi, 2018; Wei and Zou, 2019; Anaby-Tavor et al., 2020; Raille et al., 2020; Kumar et al., 2020), but mainly for translation and classification tasks. Compa"
2020.emnlp-main.488,W02-2024,0,0.554171,"ted. See Table 1 for the notations of the methods used in our supervised experiments. Method Description gold gen rd rd* Only use the gold data. Our method. Generate synthetic data with the language models, and oversample gold data. Baseline method. Generate synthetic data by random deletion, and oversample gold data with the same ratio as gen. Baseline method. Similar to rd, except that gold and synthetic data are equally sampled. Table 1: Data sources for the supervised setting. 4.2.1 Named Entity Recognition Dataset We evaluate our proposed methods on the CoNLL2002/2003 NER data (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003), with four languages: English, German, Dutch and Spanish. Besides, we evaluate our methods on Thai and Vietnamese NER data, which are product titles obtained from major e-commerce websites in Southeast Asian countries and annotated with 11 product attribute NER tags, including PRODUCT, BRAND, CONSUMER GROUP, MATERIAL, PATTERN, COLOR, FABRIC, OCCASION, ORIGIN, SEASON and STYLE. See Appendix for the statistics of the Thai and Vietnamese NER data used in our experiments. Experimental Settings In addition to evaluating our method on the full training data, we"
2020.emnlp-main.488,Q16-1035,0,0.0522738,"does not change the semantics of visual information, deleting or replacing a single word could completely change the meaning of the sentence. One successful method for data augmentation in NLP is back translation (Sennrich et al., 2016; Fadaee et al., 2017; Dong et al., 2017; Yu et al., 2018), where a translation model is used to translate monolingual sentences from target language to source language to generate synthetic parallel sentences. Other successful methods include: systematically reordering the dependents of some nodes in gold data to generate synthetic data for dependency parsing (Wang and Eisner, 2016), leveraging knowledge base for question generation (Serban et al., 2016) and using simulation-based approach to generate a set of prerequisite toy tasks for QA (Weston et al., 2015). Besides, synonym replace6045 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 6045–6057, c November 16–20, 2020. 2020 Association for Computational Linguistics ment, random deletion/swap/insertion, generation with VAE or pre-trained language models are also used in some NLP tasks (Kobayashi, 2018; Wei and Zou, 2019; Anaby-Tavor et al., 2020; Raille et al., 2020; Kumar"
2020.emnlp-main.488,D19-1670,0,0.046969,"o generate synthetic data for dependency parsing (Wang and Eisner, 2016), leveraging knowledge base for question generation (Serban et al., 2016) and using simulation-based approach to generate a set of prerequisite toy tasks for QA (Weston et al., 2015). Besides, synonym replace6045 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 6045–6057, c November 16–20, 2020. 2020 Association for Computational Linguistics ment, random deletion/swap/insertion, generation with VAE or pre-trained language models are also used in some NLP tasks (Kobayashi, 2018; Wei and Zou, 2019; Anaby-Tavor et al., 2020; Raille et al., 2020; Kumar et al., 2020), but mainly for translation and classification tasks. Compared with the above-mentioned downstream tasks like translation and classification, sequence tagging is more fragile when it is confronted with data augmentation noises due to the finer granularity of the (token-level) task. Annotating unlabeled data with a weak tagger, leveraging aligned bilingual corpora to induce annotation and synonym replacement are three attempted data augmentation methods for sequence tagging (Shang et al., 2018; Yarowsky et al., 2001; Mathew et"
2020.emnlp-main.719,N19-1423,0,0.0292875,"ax-Model Consistency, (iii) Graph Convolutional Neural Networks, and (iv) Representation Regularization. 3.1 sition embedding table (initialized randomly). The position embeddings are fine-tuned during training in this work. The resulting vector sequence X = x1 , x2 , . . . , xN for W will be then sent to the next computation step. Sentence Encoding In order to represent the input sentence W , we encode each word wi into a real-valued vector xi based on the concatenation of the two following vectors: (1) the hidden vector of the first wordpiece of wi from the last layer of the BERTbase model (Devlin et al., 2019), and (2) the position embedding for wi . For this vector, we first compute the relative distance di from wi to the target word wt (i.e., ri = i − t). Afterward, we retrieve the position embedding for wi by looking up ri in a poP exp(−dsyn ) i syn . ) j=1..N exp(−dj In order to implement the possibility score consistency, our deep learning model needs to produce syn syn ssyn 1 , s2 , . . . , sN as the model-based possibility scores the words w1 , w2 , . . . , wN in W respectively. While the model-based score computation would be explained later, given the model-based scores, the syntax-model c"
2020.emnlp-main.719,N19-1259,0,0.772959,"disappointing.”, “disappointing” is the opinion word for the target word “warranties” while the opinion words for the target word “company” would involve “reputable”. Among others, TOWE finds its applications in target-oriented sentiment analysis (Tang et al., 2016; Xue and Li, 2018; Veyseh et al., 2020) and opinion summarization (Wu et al., 2020). Equal contribution. honored XYZ Introduction ∗ are The early approach for TOWE has involved the rule-based and lexicon-based methods (Hu and Liu, 2004; Zhuang et al., 2006) while the recent work has focused on deep learning models for this problem (Fan et al., 2019; Wu et al., 2020). One of the insights from the rule-based methods is that the syntactic structures (i.e., the parsing trees) of the sentences can provide useful information to improve the performance for TOWE (Zhuang et al., 2006). However, these syntactic structures have not been exploited in the current deep learning models for TOWE (Fan et al., 2019; Wu et al., 2020). Consequently, in this work, we seek to fill in this gap by extracting useful knowledge from the syntactic structures to help the deep learning models learn better representations for TOWE. In particular, based on the depende"
2020.emnlp-main.719,D17-1310,0,0.136145,"). A key difference between OWE and TOWE is that OWE does not require the opinion words to tie to any target words 8948 in the sentence while the opinion words in TOWE should be explicitly paired with a given target word. Another related task for TOWE is opinion target extraction (OTE) that attempts to identify the target words in the sentences (Qiu et al., 2011; Liu et al., 2015; Poria et al., 2016; Yin et al., 2016; Xu et al., 2018). Note that some previous works have also attempted to jointly predict the target and opinion words (Qiu et al., 2011; Liu et al., 2013; Wang et al., 2016, 2017; Li and Lam, 2017); however, the target words are still not paired with their corresponding opinion words in these studies. As mentioned in the introduction, among a few previous work on TOWE, the main approaches include the rule-based methods (i.e., based on word distances or syntactic patterns) (Zhuang et al., 2006; Hu and Liu, 2004) and the recent deep learning models (Fan et al., 2019; Wu et al., 2020). Our model is different from the previous deep learning models as we exploit the syntactic information (i.e., dependency trees) for TOWE with deep learning. 3 3.2 Syntax-Model Consistency As presented in the"
2020.emnlp-main.719,D15-1168,0,0.130936,"n relatively less explored in the literature. In particular, the most related task of TOWE is opinion word extraction (OWE) that aims to locate the terms used to express attitude in the sentences (Htay and Lynn, 2013; Shamshurin, 2012). A key difference between OWE and TOWE is that OWE does not require the opinion words to tie to any target words 8948 in the sentence while the opinion words in TOWE should be explicitly paired with a given target word. Another related task for TOWE is opinion target extraction (OTE) that attempts to identify the target words in the sentences (Qiu et al., 2011; Liu et al., 2015; Poria et al., 2016; Yin et al., 2016; Xu et al., 2018). Note that some previous works have also attempted to jointly predict the target and opinion words (Qiu et al., 2011; Liu et al., 2013; Wang et al., 2016, 2017; Li and Lam, 2017); however, the target words are still not paired with their corresponding opinion words in these studies. As mentioned in the introduction, among a few previous work on TOWE, the main approaches include the rule-based methods (i.e., based on word distances or syntactic patterns) (Zhuang et al., 2006; Hu and Liu, 2004) and the recent deep learning models (Fan et a"
2020.emnlp-main.719,D17-1159,0,0.0250308,"rtance of the contextual information from wj with respect to the representation vector computation for wi in W . In particular, one score matrix would be used to capture the syntactic neighboring words of the current words (i.e., wi ) while the other score matrix would 8950 be reserved for the neighboring words of the target word wt . These two matrices would then be combined and consumed by a GCN model (Kipf and Welling, 2017) for representation learning. GCN model would be computed by: Specifically, for the syntactic neighbors of the current words, following the previous GCN models for NLP (Marcheggiani and Titov, 2017; Nguyen and Grishman, 2018; Veyseh et al., 2019), we directly use the adjacency binary matrix Ad = {adi,j }i,j=1..N of the dependency tree for W as the importance score matrix for this group of words. Note that adi,j is only set to 1 if wi is directly connected to wj in the dependency tree or i = j in this case. In the next step for the neighboring words of the target word wt , as we expect the closer words to the target word wt to have larger contributions for the representation vectors of the words in W for TOWE, we propose to use the syntactic distances (to the target word) dsyn and dsyn o"
2020.emnlp-main.719,C16-1311,0,0.0487846,") in the input sentence, the goal of TOWE is to identify the words in the sentence (called the target-oriented opinion words) that help to express the attitude of the author toward the aspect represented by the target word. For instance, as a running example, in the sentence “All warranties honored by XYZ (what I thought was a reputable company) are disappointing.”, “disappointing” is the opinion word for the target word “warranties” while the opinion words for the target word “company” would involve “reputable”. Among others, TOWE finds its applications in target-oriented sentiment analysis (Tang et al., 2016; Xue and Li, 2018; Veyseh et al., 2020) and opinion summarization (Wu et al., 2020). Equal contribution. honored XYZ Introduction ∗ are The early approach for TOWE has involved the rule-based and lexicon-based methods (Hu and Liu, 2004; Zhuang et al., 2006) while the recent work has focused on deep learning models for this problem (Fan et al., 2019; Wu et al., 2020). One of the insights from the rule-based methods is that the syntactic structures (i.e., the parsing trees) of the sentences can provide useful information to improve the performance for TOWE (Zhuang et al., 2006). However, these"
2020.emnlp-main.719,P19-1432,1,0.781312,"to the representation vector computation for wi in W . In particular, one score matrix would be used to capture the syntactic neighboring words of the current words (i.e., wi ) while the other score matrix would 8950 be reserved for the neighboring words of the target word wt . These two matrices would then be combined and consumed by a GCN model (Kipf and Welling, 2017) for representation learning. GCN model would be computed by: Specifically, for the syntactic neighbors of the current words, following the previous GCN models for NLP (Marcheggiani and Titov, 2017; Nguyen and Grishman, 2018; Veyseh et al., 2019), we directly use the adjacency binary matrix Ad = {adi,j }i,j=1..N of the dependency tree for W as the importance score matrix for this group of words. Note that adi,j is only set to 1 if wi is directly connected to wj in the dependency tree or i = j in this case. In the next step for the neighboring words of the target word wt , as we expect the closer words to the target word wt to have larger contributions for the representation vectors of the words in W for TOWE, we propose to use the syntactic distances (to the target word) dsyn and dsyn of i j wi and wj as the features to learn the impo"
2020.emnlp-main.719,D16-1059,0,0.0377237,"n, 2013; Shamshurin, 2012). A key difference between OWE and TOWE is that OWE does not require the opinion words to tie to any target words 8948 in the sentence while the opinion words in TOWE should be explicitly paired with a given target word. Another related task for TOWE is opinion target extraction (OTE) that attempts to identify the target words in the sentences (Qiu et al., 2011; Liu et al., 2015; Poria et al., 2016; Yin et al., 2016; Xu et al., 2018). Note that some previous works have also attempted to jointly predict the target and opinion words (Qiu et al., 2011; Liu et al., 2013; Wang et al., 2016, 2017; Li and Lam, 2017); however, the target words are still not paired with their corresponding opinion words in these studies. As mentioned in the introduction, among a few previous work on TOWE, the main approaches include the rule-based methods (i.e., based on word distances or syntactic patterns) (Zhuang et al., 2006; Hu and Liu, 2004) and the recent deep learning models (Fan et al., 2019; Wu et al., 2020). Our model is different from the previous deep learning models as we exploit the syntactic information (i.e., dependency trees) for TOWE with deep learning. 3 3.2 Syntax-Model Consist"
2020.emnlp-main.719,P18-2094,0,0.0904373,"lar, the most related task of TOWE is opinion word extraction (OWE) that aims to locate the terms used to express attitude in the sentences (Htay and Lynn, 2013; Shamshurin, 2012). A key difference between OWE and TOWE is that OWE does not require the opinion words to tie to any target words 8948 in the sentence while the opinion words in TOWE should be explicitly paired with a given target word. Another related task for TOWE is opinion target extraction (OTE) that attempts to identify the target words in the sentences (Qiu et al., 2011; Liu et al., 2015; Poria et al., 2016; Yin et al., 2016; Xu et al., 2018). Note that some previous works have also attempted to jointly predict the target and opinion words (Qiu et al., 2011; Liu et al., 2013; Wang et al., 2016, 2017; Li and Lam, 2017); however, the target words are still not paired with their corresponding opinion words in these studies. As mentioned in the introduction, among a few previous work on TOWE, the main approaches include the rule-based methods (i.e., based on word distances or syntactic patterns) (Zhuang et al., 2006; Hu and Liu, 2004) and the recent deep learning models (Fan et al., 2019; Wu et al., 2020). Our model is different from"
2020.emnlp-main.719,P18-1234,0,0.0359451,"ence, the goal of TOWE is to identify the words in the sentence (called the target-oriented opinion words) that help to express the attitude of the author toward the aspect represented by the target word. For instance, as a running example, in the sentence “All warranties honored by XYZ (what I thought was a reputable company) are disappointing.”, “disappointing” is the opinion word for the target word “warranties” while the opinion words for the target word “company” would involve “reputable”. Among others, TOWE finds its applications in target-oriented sentiment analysis (Tang et al., 2016; Xue and Li, 2018; Veyseh et al., 2020) and opinion summarization (Wu et al., 2020). Equal contribution. honored XYZ Introduction ∗ are The early approach for TOWE has involved the rule-based and lexicon-based methods (Hu and Liu, 2004; Zhuang et al., 2006) while the recent work has focused on deep learning models for this problem (Fan et al., 2019; Wu et al., 2020). One of the insights from the rule-based methods is that the syntactic structures (i.e., the parsing trees) of the sentences can provide useful information to improve the performance for TOWE (Zhuang et al., 2006). However, these syntactic structur"
2020.emnlp-main.719,J11-1002,0,0.0962642,"asks, TOWE has been relatively less explored in the literature. In particular, the most related task of TOWE is opinion word extraction (OWE) that aims to locate the terms used to express attitude in the sentences (Htay and Lynn, 2013; Shamshurin, 2012). A key difference between OWE and TOWE is that OWE does not require the opinion words to tie to any target words 8948 in the sentence while the opinion words in TOWE should be explicitly paired with a given target word. Another related task for TOWE is opinion target extraction (OTE) that attempts to identify the target words in the sentences (Qiu et al., 2011; Liu et al., 2015; Poria et al., 2016; Yin et al., 2016; Xu et al., 2018). Note that some previous works have also attempted to jointly predict the target and opinion words (Qiu et al., 2011; Liu et al., 2013; Wang et al., 2016, 2017; Li and Lam, 2017); however, the target words are still not paired with their corresponding opinion words in these studies. As mentioned in the introduction, among a few previous work on TOWE, the main approaches include the rule-based methods (i.e., based on word distances or syntactic patterns) (Zhuang et al., 2006; Hu and Liu, 2004) and the recent deep learnin"
2020.findings-emnlp.326,W06-0901,0,0.0636536,"rmance for EAE but also minimize the mutual information with the input sentences (Belghazi et al., 2018). To this end, we introduce the mutual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et"
2020.findings-emnlp.326,P17-1038,0,0.0260163,"hn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic structures of the sentences to better learn the representations for EAE. We also note some new directions on EE based on zero-shot learning (Huang et al., 2018), few-shot learning (Lai et al., 2020a,b) and multimodal learning (Zhang et al"
2020.findings-emnlp.326,P15-1017,0,0.218598,"ile EAE is relatively less explored (Wang et al., 2019b). As EAE is necessary to accomplish EE and helpful for many downstream applications (Yang et al., 2003; Cheng and Erk, 2018), further studies are required to improve the performance of EAE. This work focuses on EAE to meet this requirement for EE. The current state-of-the-art methods for EAE have involved deep learning models that compute an abstract representation vector for each word in the input sentences based on the information from the other context words. The representation vectors for the words are then aggregated to perform EAE (Chen et al., 2015; Nguyen et al., 2016). Our main motivation in this work is to exploit different structures in the input sentences to improve the representation vectors for the words in the deep learning models for EAE. In this work, a sentence structure (or view) refers to an importance score matrix whose cells quantify the contribution of a context word for the representation vector computation of the current word for EAE. In particular, we consider two types of sentence structures in this work, i.e., syntactic and semantic structures. As such, the importance score for a pair of words in the syntactic struc"
2020.findings-emnlp.326,N18-1076,0,0.0250825,"tion Event Extraction (EE) is an important task of Information Extraction that aims to recognize events and their arguments in text. In the literature, EE is often divided into two sub-tasks: (1) Event Detection (ED) to detect the event trigger words, and (2) Event Argument Extraction (EAE) to identity the event arguments and their roles for the given event triggers. In recent years, ED has been studied extensively with deep learning while EAE is relatively less explored (Wang et al., 2019b). As EAE is necessary to accomplish EE and helpful for many downstream applications (Yang et al., 2003; Cheng and Erk, 2018), further studies are required to improve the performance of EAE. This work focuses on EAE to meet this requirement for EE. The current state-of-the-art methods for EAE have involved deep learning models that compute an abstract representation vector for each word in the input sentences based on the information from the other context words. The representation vectors for the words are then aggregated to perform EAE (Chen et al., 2015; Nguyen et al., 2016). Our main motivation in this work is to exploit different structures in the input sentences to improve the representation vectors for the wo"
2020.findings-emnlp.326,N19-1423,0,0.0659757,"ii) structure combination, and (iv) model regularization as described in the following. 3.1 Sentence Encoding To represent the sentence, we encode each word wi with a real-valued vector xi that is the concatenation of the two following vectors: (i) the embeddings of the relative distances of the word wi to the argument candidate (i.e., i − a) and event trigger (i.e., i − e) (these embeddings are initialized randomly and updated during training), and (ii) the BERT embedding of the word wi . In particular, to achieve a fair comparison with (Wang et al., 2019b), we run the BERT base cased model (Devlin et al., 2019) over W and use the hidden vector for the first wordpiece of wi in the last layer of BERT as the embedding vector (of 768 dimensions) for wi . The word encoding step then produces a sequence of vectors X = x1 , . . . , xN to represent the input sentence W . In order to better combine the BERT embeddings and the relative distance embeddings, we further feed X into a Bidirectional Longshort Term Memory network (BiLSTM), resulting in the hidden vector sequence H = h1 , . . . , hN as the representation vectors for the next steps. 3.2 Structure Generation As presented in the introduction, the motiv"
2020.findings-emnlp.326,P08-1030,0,0.215866,"EAE but also minimize the mutual information with the input sentences (Belghazi et al., 2018). To this end, we introduce the mutual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al.,"
2020.findings-emnlp.326,2020.nuse-1.5,1,0.706336,"10a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic structures of the sentences to better learn the representations for EAE. We also note some new directions on EE based on zero-shot learning (Huang et al., 2018), few-shot learning (Lai et al., 2020a,b) and multimodal learning (Zhang et al., 2017). 3652 3 Model EAE can be formulated as a multi-class classification probl"
2020.findings-emnlp.326,2020.emnlp-main.435,1,0.736614,"10a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic structures of the sentences to better learn the representations for EAE. We also note some new directions on EE based on zero-shot learning (Huang et al., 2018), few-shot learning (Lai et al., 2020a,b) and multimodal learning (Zhang et al., 2017). 3652 3 Model EAE can be formulated as a multi-class classification probl"
2020.findings-emnlp.326,P13-1008,0,0.793447,"en the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wan"
2020.findings-emnlp.326,C10-1077,0,0.0419351,"e input sentences (Belghazi et al., 2018). To this end, we introduce the mutual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; La"
2020.findings-emnlp.326,P10-1081,0,0.0662901,"e input sentences (Belghazi et al., 2018). To this end, we introduce the mutual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; La"
2020.findings-emnlp.326,P17-1164,0,0.0250094,"ishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic structures of the sentences to better learn the representations for EAE. We also note some new directions on EE based on zero-shot learning (Huang et al., 2018), few-shot learning (Lai et al., 2020a,b) and multimodal learning (Zhang et al., 2017). 3652 3 M"
2020.findings-emnlp.326,D18-1156,0,0.0686744,"h the baselines on the ACE 2005 dataset. Following (Wang et al., 2019b), we use the following baselines in our experiments: (i) the feature-based models (i.e., Li’s Joint (Li et al., 2013) and RBPB (Sha et al., 2016)), (ii) the deep sequence-based models that run over the sequential order of the words in the sentences (i.e., DMCNN (Chen et al., 2015), JRNN (Nguyen et al., 2016), PLMEE (Yang et al., 2019), and DMBERT (i.e., DMCNN with BERT) (Wang et al., 2019b)), (iii) the deep structure-based models that employ dependency trees for BiLSTM or GCNs (i.e., dbRNN (Sha et al., 2018) and JMEE 3656 (Liu et al., 2018b)), (iv) the models with Generative Adversarial Imitation Learning (GAIL (Zhang et al., 2019a)), and (v) the deep learning model that exploits the hierarchical concept correlation among argument roles (i.e., HMEAE (Wang et al., 2019b)). HMEAE is a BERT-based model with the current best EAE performance on ACE 2005. Model Li’s joint (Li et al., 2013) RBPB (Sha et al., 2016) DMCNN (Chen et al., 2015) JRNN (Nguyen et al., 2016) dbRNN (Sha et al., 2018) GAIL (Zhang et al., 2019a) JMEE (Liu et al., 2018b) SemSynGTN (ours) PLMEE (Yang et al., 2019)* DMBERT (Wang et al., 2019b)* HMEAE (Wang et al., 2"
2020.findings-emnlp.326,P11-1163,0,0.0649343,"utual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest wor"
2020.findings-emnlp.326,P11-1113,0,0.0285732,"we introduce the mutual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less ex"
2020.findings-emnlp.326,C14-1214,0,0.0155292,"representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) th"
2020.findings-emnlp.326,P18-1201,0,0.063657,"rning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic structures of the sentences to better learn the representations for EAE. We also note some new directions on EE based on zero-shot learning (Huang et al., 2018), few-shot learning (Lai et al., 2020a,b) and multimodal learning (Zhang et al., 2017). 3652 3 Model EAE can be formulated as a multi-class classification problem in which the input involves a sentence W = w1 , w2 , . . . , wN (wi is the i-th word/token in the sentence of length N ), and an argument candidate and event trigger at indexes a and t in the sentence (i.e., the words wa and we ) respectively. The goal in this problem is to predict the role that the argument candidate wa plays in the event triggered by we . Note that the set of the possible roles also include a special type None to i"
2020.findings-emnlp.326,N16-1034,1,0.940519,"ly less explored (Wang et al., 2019b). As EAE is necessary to accomplish EE and helpful for many downstream applications (Yang et al., 2003; Cheng and Erk, 2018), further studies are required to improve the performance of EAE. This work focuses on EAE to meet this requirement for EE. The current state-of-the-art methods for EAE have involved deep learning models that compute an abstract representation vector for each word in the input sentences based on the information from the other context words. The representation vectors for the words are then aggregated to perform EAE (Chen et al., 2015; Nguyen et al., 2016). Our main motivation in this work is to exploit different structures in the input sentences to improve the representation vectors for the words in the deep learning models for EAE. In this work, a sentence structure (or view) refers to an importance score matrix whose cells quantify the contribution of a context word for the representation vector computation of the current word for EAE. In particular, we consider two types of sentence structures in this work, i.e., syntactic and semantic structures. As such, the importance score for a pair of words in the syntactic structures is determined by"
2020.findings-emnlp.326,P15-2060,1,0.883219,"is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic structures of the sentences to better learn the representations for EAE. We also note some new directions on EE based on zero-shot learning (Huang et al., 2018), few-shot learnin"
2020.findings-emnlp.326,D09-1016,0,0.176589,"he mutual information with the input sentences (Belghazi et al., 2018). To this end, we introduce the mutual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 201"
2020.findings-emnlp.326,W11-1807,0,0.0360831,"et al., 2018). To this end, we introduce the mutual information between the generated representations of GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been"
2020.findings-emnlp.326,P16-1116,0,0.0136095,"d model with BERT takes as inputs the predicted event triggers from the BERT-based ED model in (Wang et al., 2019a) while the proposed model with word2vec utilizes the predicted event triggers from the word2vec-based ED model in (Chen et al., 2015) for compatibility. Comparison with the State of the Art: To evaluate the effectiveness of the proposed model (called SemSynGTN), we first compare it with the baselines on the ACE 2005 dataset. Following (Wang et al., 2019b), we use the following baselines in our experiments: (i) the feature-based models (i.e., Li’s Joint (Li et al., 2013) and RBPB (Sha et al., 2016)), (ii) the deep sequence-based models that run over the sequential order of the words in the sentences (i.e., DMCNN (Chen et al., 2015), JRNN (Nguyen et al., 2016), PLMEE (Yang et al., 2019), and DMBERT (i.e., DMCNN with BERT) (Wang et al., 2019b)), (iii) the deep structure-based models that employ dependency trees for BiLSTM or GCNs (i.e., dbRNN (Sha et al., 2018) and JMEE 3656 (Liu et al., 2018b)), (iv) the models with Generative Adversarial Imitation Learning (GAIL (Zhang et al., 2019a)), and (v) the deep learning model that exploits the hierarchical concept correlation among argument role"
2020.findings-emnlp.326,P19-1522,0,0.176738,"datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic str"
2020.findings-emnlp.326,P18-2066,0,0.0280709,"and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and exploits the concept hierarchy of event argument roles to perform the task. Our work differs from (Wang et al., 2019b) in that we employ the syntactic and semantic structures of the sentences to better learn the representations for EAE. We also note some new directions on EE based on zero-shot learning (Huang et al., 2018), few-shot learning (Lai et al., 2020a,b) and multimodal learning (Zhang et al., 2017). 3652 3 Model EAE can be formulated"
2020.findings-emnlp.326,N19-1105,0,0.0594084,"strate the benefits of the proposed model, leading to state-of-the-art performance for EAE on standard datasets. 1 Introduction Event Extraction (EE) is an important task of Information Extraction that aims to recognize events and their arguments in text. In the literature, EE is often divided into two sub-tasks: (1) Event Detection (ED) to detect the event trigger words, and (2) Event Argument Extraction (EAE) to identity the event arguments and their roles for the given event triggers. In recent years, ED has been studied extensively with deep learning while EAE is relatively less explored (Wang et al., 2019b). As EAE is necessary to accomplish EE and helpful for many downstream applications (Yang et al., 2003; Cheng and Erk, 2018), further studies are required to improve the performance of EAE. This work focuses on EAE to meet this requirement for EE. The current state-of-the-art methods for EAE have involved deep learning models that compute an abstract representation vector for each word in the input sentences based on the information from the other context words. The representation vectors for the words are then aggregated to perform EAE (Chen et al., 2015; Nguyen et al., 2016). Our main moti"
2020.findings-emnlp.326,D19-1584,0,0.126947,"strate the benefits of the proposed model, leading to state-of-the-art performance for EAE on standard datasets. 1 Introduction Event Extraction (EE) is an important task of Information Extraction that aims to recognize events and their arguments in text. In the literature, EE is often divided into two sub-tasks: (1) Event Detection (ED) to detect the event trigger words, and (2) Event Argument Extraction (EAE) to identity the event arguments and their roles for the given event triggers. In recent years, ED has been studied extensively with deep learning while EAE is relatively less explored (Wang et al., 2019b). As EAE is necessary to accomplish EE and helpful for many downstream applications (Yang et al., 2003; Cheng and Erk, 2018), further studies are required to improve the performance of EAE. This work focuses on EAE to meet this requirement for EE. The current state-of-the-art methods for EAE have involved deep learning models that compute an abstract representation vector for each word in the input sentences based on the information from the other context words. The representation vectors for the words are then aggregated to perform EAE (Chen et al., 2015; Nguyen et al., 2016). Our main moti"
2020.findings-emnlp.326,N16-1033,0,0.283077,"GTNs and the input sentences as an additional term in the overall loss function to improve the generalization of GTNs for EAE. Our extensive experiments on two benchmark datasets for EAE show that the proposed model can achieve the state-of-the-art performance for EAE. 2 Related Work EAE is one of the two subtasks in EE (the other one is ED) that has been approached early by the feature-based models (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Riedel and McCallum, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). The recent work on EE has focused on deep learning to improve the models’ performance (Chen et al., 2015; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020). Among the two subtasks of EE, while ED has been studied extensively by the recent deep learning work (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016g; Chen et al., 2017; Liu et al., 2017, 2018a; Zhao et al., 2018; Wang et al., 2019a; Lai et al., 2020c), EAE has been relatively less explored. The closest work to ours is (Wang et al., 2019b) that focuses on EAE and expl"
2020.findings-emnlp.407,D19-1566,0,0.0281578,"A novel method to regulate the GCN-based representation vectors of the words using the given aspect term for ABSA. • A novel method to encourage the consistency between the syntax-based and model-based importance scores of the words based on the given aspect term. • Extensive experiments on three benchmark datasets for ABSA, resulting in new state-of-theart performance for all the datasets. 2 Related Work Sentiment analysis has been studied under different settings in the literature (e.g., sentence-level, aspect-level, cross-domain) (Wang et al., 2019; Zhang and Zhang, 2019; Sun et al., 2019; Chauhan et al., 2019; Hu et al., 2019). For ABSA, the early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN) (Wagner et al., 2016), memory networks"
2020.findings-emnlp.407,N19-1423,0,0.0220111,"rk. 3 Model The task of ABSA can be formalized as follows: Given a sentence X = [x1 , x2 , . . . , xn ] of n words/tokens and the index t (1 ≤ t ≤ n) for the aspect term xt , the goal is to predict the sentiment polarity y ∗ toward the aspect term xt for X. Our model for ABSA in this work consists of three major components: (i) Representation Learning, (ii) Graph Convolution and Regulation, and (iii) Syntax and Model Consistency. (i) Representation Learning: Following the recent work in ABSA (Huang and Carley, 2019; Song et al., 2019), we first utilize the contextualized word embeddings BERT (Devlin et al., 2019) to obtain the representation vectors for the words in X. In particular, we first generate a sequence of words of ˆ = [CLS] + X + [SEP ] + xt + [SEP ] the form X where [CLS] and [SEP ] are the special tokens 4544 in BERT. This word sequence is then fed into the pre-trained BERT model to obtain the hidden vectors in the last layer. Afterwards, we obtain the embedding vector ei for each word xi ∈ X by averaging the hidden vectors of xi ’s sub-word units (i.e., wordpiece). As the result, the input sentence X will be represented by the vector sequence E = e1 , e2 , . . . , en in our model. Finally"
2020.findings-emnlp.407,C18-1096,0,0.0447998,"ering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN) (Wagner et al., 2016), memory networks (Tang et al., 2016), attention (Luong et al., 2015) and gating mechanisms (He et al., 2018). The current state-of-the-art deep learning models for ABSA feature the graph-based models where the dependency trees are leveraged to improve the performance. (Huang and Carley, 2019; Zhang et al., 2019; Hou et al., 2019). However, to the best of our knowledge, none of these works has used the information from the aspect term to filter the graph-based hidden vectors and exploited importance scores for words from dependency trees as we do in this work. 3 Model The task of ABSA can be formalized as follows: Given a sentence X = [x1 , x2 , . . . , xn ] of n words/tokens and the index t (1 ≤ t ≤"
2020.findings-emnlp.407,D19-1558,0,0.0195738,"late the GCN-based representation vectors of the words using the given aspect term for ABSA. • A novel method to encourage the consistency between the syntax-based and model-based importance scores of the words based on the given aspect term. • Extensive experiments on three benchmark datasets for ABSA, resulting in new state-of-theart performance for all the datasets. 2 Related Work Sentiment analysis has been studied under different settings in the literature (e.g., sentence-level, aspect-level, cross-domain) (Wang et al., 2019; Zhang and Zhang, 2019; Sun et al., 2019; Chauhan et al., 2019; Hu et al., 2019). For ABSA, the early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN) (Wagner et al., 2016), memory networks (Tang et al., 2016"
2020.findings-emnlp.407,D19-1549,0,0.296281,"d be able to return the negative sentiment for input sentence “The staff were very polite, but the quality of the food was terrible.” assuming “food” as the aspect term. Due to its important applications (e.g., for opinion mining), ABSA has been studied extensively ∗ Equal contribution. in the literature. In these studies, deep learning has been employed to produce the state-of-the-art performance for this problem (Wagner et al., 2016; Dehong et al., 2017). Recently, in order to further improve the performance, the syntactic dependency trees have been integrated into the deep learning models (Huang and Carley, 2019; Zhang et al., 2019) for ABSA (called the graph-based deep learning models). Among others, dependency trees help to directly link the aspect term to the syntactically related words in the sentence, thus facilitating the graph convolutional neural networks (GCN) (Kipf and Welling, 2017) to enrich the representation vectors for the aspect terms. However, there are at least two major issues in these graph-based models that should be addressed to boost the performance. First, the representation vectors for the words in different layers of the current graph-based models for ABSA are not customized"
2020.findings-emnlp.407,D19-1654,0,0.0821052,"network with softmax in the end to estimate the probability distribution P (.|X, xt ) over the sentiments for X and xt . The negative log-likelihood Lpred = − log P (y ∗ |X, xt ) is then used as the prediction loss in this work. The overall loss to train the proposed model is then: L = Ldiv +αLconst +βLpred where α and β are trade-off parameters. 4 Experiments Datasets and Parameters: We employ three datasets to evaluate the models in this work. Two datasets, Restaurant and Laptop, are adopted from the SemEval 2014 Task 4 (Pontiki et al., 2014) while the third dataset, MAMS, is introduced in (Jiang et al., 2019). All the three datasets involve three sentiment categories, i.e., positive, neural, and negative. The numbers of examples for different portions of the three datasets are shown in Table 1. As only the MAMS dataset provides the development data, we fine-tune the model’s hyperparameters on the development data of MAMS and use the same hyper-parameters for the other datasets. The following hyper-parameters are suggested for the proposed model by the fine-tuning process: 200 dimensions for the hidden vectors of Dataset Restaurant-Train Restaurant-Test Laptop-Train Laptop-Test MAMS-Train MAMS-Dev"
2020.findings-emnlp.407,D19-1569,0,0.0904824,"utions include: • A novel method to regulate the GCN-based representation vectors of the words using the given aspect term for ABSA. • A novel method to encourage the consistency between the syntax-based and model-based importance scores of the words based on the given aspect term. • Extensive experiments on three benchmark datasets for ABSA, resulting in new state-of-theart performance for all the datasets. 2 Related Work Sentiment analysis has been studied under different settings in the literature (e.g., sentence-level, aspect-level, cross-domain) (Wang et al., 2019; Zhang and Zhang, 2019; Sun et al., 2019; Chauhan et al., 2019; Hu et al., 2019). For ABSA, the early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN) (Wagner et al., 2"
2020.findings-emnlp.407,D16-1021,0,0.243901,"elated Work Sentiment analysis has been studied under different settings in the literature (e.g., sentence-level, aspect-level, cross-domain) (Wang et al., 2019; Zhang and Zhang, 2019; Sun et al., 2019; Chauhan et al., 2019; Hu et al., 2019). For ABSA, the early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN) (Wagner et al., 2016), memory networks (Tang et al., 2016), attention (Luong et al., 2015) and gating mechanisms (He et al., 2018). The current state-of-the-art deep learning models for ABSA feature the graph-based models where the dependency trees are leveraged to improve the performance. (Huang and Carley, 2019; Zhang et al., 2019; Hou et al., 2019). However, to the best of our knowledge, none of these works has used the informa"
2020.findings-emnlp.407,P19-1432,1,0.816757,"o obtain the hidden vectors in the last layer. Afterwards, we obtain the embedding vector ei for each word xi ∈ X by averaging the hidden vectors of xi ’s sub-word units (i.e., wordpiece). As the result, the input sentence X will be represented by the vector sequence E = e1 , e2 , . . . , en in our model. Finally, we also employ the hidden vector s for the special token ˆ from BERT to encode the overall input [CLS] in X sentence X and its aspect term xt . (ii) Graph Convolution and Regulation: In order to employ the dependency trees for ABSA, we apply the GCN model (Nguyen and Grishman, 2018; Veyseh et al., 2019) to perform L abstraction layers over the word representation vector sequence E. A hidden vector for a word xi in the current layer of GCN is obtained by aggregating the hidden vectors of the dependency-based neighbor words of xi in the previous layer. Formally, let hli (0 ≤ l ≤ L, 1 ≤ i ≤ n) be the hidden vector of the word xi at the l-th layer of GCN. At the beginning, the GCN hidden vector h0i at the zero layer will be set to the word representation vector ei . Afterwards, hli (l > 0) will be computed by: ˆ l = Σj∈N (i) hl−1 /|N (i)| ˆ l ), h hli = ReLU (Wl h i i j where N (i) is the set of"
2020.findings-emnlp.407,S14-2076,0,0.465633,"ed and model-based importance scores of the words based on the given aspect term. • Extensive experiments on three benchmark datasets for ABSA, resulting in new state-of-theart performance for all the datasets. 2 Related Work Sentiment analysis has been studied under different settings in the literature (e.g., sentence-level, aspect-level, cross-domain) (Wang et al., 2019; Zhang and Zhang, 2019; Sun et al., 2019; Chauhan et al., 2019; Hu et al., 2019). For ABSA, the early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN) (Wagner et al., 2016), memory networks (Tang et al., 2016), attention (Luong et al., 2015) and gating mechanisms (He et al., 2018). The current state-of-the-art deep learning models for ABSA feature the graph-based models"
2020.findings-emnlp.407,C16-1311,0,0.524864,"n aspect. We focus on the term-based aspects for ABSA where the aspects correspond to some terms (i.e., sequences of words) in the input sentence. For instance, an ABSA system should be able to return the negative sentiment for input sentence “The staff were very polite, but the quality of the food was terrible.” assuming “food” as the aspect term. Due to its important applications (e.g., for opinion mining), ABSA has been studied extensively ∗ Equal contribution. in the literature. In these studies, deep learning has been employed to produce the state-of-the-art performance for this problem (Wagner et al., 2016; Dehong et al., 2017). Recently, in order to further improve the performance, the syntactic dependency trees have been integrated into the deep learning models (Huang and Carley, 2019; Zhang et al., 2019) for ABSA (called the graph-based deep learning models). Among others, dependency trees help to directly link the aspect term to the syntactically related words in the sentence, thus facilitating the graph convolutional neural networks (GCN) (Kipf and Welling, 2017) to enrich the representation vectors for the aspect terms. However, there are at least two major issues in these graph-based mod"
2020.findings-emnlp.407,D19-1560,0,0.0187441,"datasets for ABSA. In summary, our contributions include: • A novel method to regulate the GCN-based representation vectors of the words using the given aspect term for ABSA. • A novel method to encourage the consistency between the syntax-based and model-based importance scores of the words based on the given aspect term. • Extensive experiments on three benchmark datasets for ABSA, resulting in new state-of-theart performance for all the datasets. 2 Related Work Sentiment analysis has been studied under different settings in the literature (e.g., sentence-level, aspect-level, cross-domain) (Wang et al., 2019; Zhang and Zhang, 2019; Sun et al., 2019; Chauhan et al., 2019; Hu et al., 2019). For ABSA, the early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurren"
2020.findings-emnlp.407,2020.acl-main.295,0,0.0411807,"he proposed method, we compare it with the following baselines: (1) the feature-based model that applies feature engineering and the SVM model (Wagner et al., 2014), (2) the deep learning models based on the sequential order of the words in the sentences, including CNN, LSTM, attention and the gating mechanism (Wagner et al., 2016; Wang et al., 2016; Tang et al., 2016; Huang et al., 2018; Jiang et al., 2019), and (3) the graph-based models that exploit dependency trees to improve the deep learning models for ABSA (Huang and Carley, 2019; Zhang et al., 2019; Hou et al., 2019; Sun et al., 2019; Wang et al., 2020). Table 2 presents the performance of the models on the test sets of the three benchmark datasets. This table shows that the proposed model outperforms all the baselines over different benchmark datasets. The performance gaps are significant with p < 0.01, thereby demonstrating the effectiveness of the proposed model for ABSA. Ablation Study: There are three major components in the proposed model: (1) the gate vectors gl to regulate the hidden vectors of GCN (called Gate), (2) the gate diversity component Ldiv to promote the distinction between the gates (called Div.), and (3) the syntax and m"
2020.findings-emnlp.407,D16-1058,0,0.0300107,"n GCN, the size 32 for the mini-batches, the learning rate of 0.001 for the Adam optimizer, and 1.0 for the trade-off parameters α and β. Finally, we use the cased BERTbase model with 768 hidden dimensions in this work. Results: To demonstrate the effectiveness of the proposed method, we compare it with the following baselines: (1) the feature-based model that applies feature engineering and the SVM model (Wagner et al., 2014), (2) the deep learning models based on the sequential order of the words in the sentences, including CNN, LSTM, attention and the gating mechanism (Wagner et al., 2016; Wang et al., 2016; Tang et al., 2016; Huang et al., 2018; Jiang et al., 2019), and (3) the graph-based models that exploit dependency trees to improve the deep learning models for ABSA (Huang and Carley, 2019; Zhang et al., 2019; Hou et al., 2019; Sun et al., 2019; Wang et al., 2020). Table 2 presents the performance of the models on the test sets of the three benchmark datasets. This table shows that the proposed model outperforms all the baselines over different benchmark datasets. The performance gaps are significant with p < 0.01, thereby demonstrating the effectiveness of the proposed model for ABSA. Abla"
2020.findings-emnlp.407,D19-1464,0,0.454686,"negative sentiment for input sentence “The staff were very polite, but the quality of the food was terrible.” assuming “food” as the aspect term. Due to its important applications (e.g., for opinion mining), ABSA has been studied extensively ∗ Equal contribution. in the literature. In these studies, deep learning has been employed to produce the state-of-the-art performance for this problem (Wagner et al., 2016; Dehong et al., 2017). Recently, in order to further improve the performance, the syntactic dependency trees have been integrated into the deep learning models (Huang and Carley, 2019; Zhang et al., 2019) for ABSA (called the graph-based deep learning models). Among others, dependency trees help to directly link the aspect term to the syntactically related words in the sentence, thus facilitating the graph convolutional neural networks (GCN) (Kipf and Welling, 2017) to enrich the representation vectors for the aspect terms. However, there are at least two major issues in these graph-based models that should be addressed to boost the performance. First, the representation vectors for the words in different layers of the current graph-based models for ABSA are not customized for the aspect terms"
2020.findings-emnlp.407,P19-1342,0,0.0285118,"In summary, our contributions include: • A novel method to regulate the GCN-based representation vectors of the words using the given aspect term for ABSA. • A novel method to encourage the consistency between the syntax-based and model-based importance scores of the words based on the given aspect term. • Extensive experiments on three benchmark datasets for ABSA, resulting in new state-of-theart performance for all the datasets. 2 Related Work Sentiment analysis has been studied under different settings in the literature (e.g., sentence-level, aspect-level, cross-domain) (Wang et al., 2019; Zhang and Zhang, 2019; Sun et al., 2019; Chauhan et al., 2019; Hu et al., 2019). For ABSA, the early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN)"
2020.findings-emnlp.407,D15-1166,0,0.039176,"e early works have performed feature engineering to produce useful features for the statistical classification models (e.g., SVM) (Wagner et al., 2014). Recently, deep learning models have superseded the feature based models due to their ability to automatically learn effective features from data (Wagner et al., 2016; Johnson and Zhang, 2015; Tang et al., 2016). The typical network architectures for ABSA in the literature involve convolutional neural networks (CNN) (Johnson and Zhang, 2015), recurrent neural networks (RNN) (Wagner et al., 2016), memory networks (Tang et al., 2016), attention (Luong et al., 2015) and gating mechanisms (He et al., 2018). The current state-of-the-art deep learning models for ABSA feature the graph-based models where the dependency trees are leveraged to improve the performance. (Huang and Carley, 2019; Zhang et al., 2019; Hou et al., 2019). However, to the best of our knowledge, none of these works has used the information from the aspect term to filter the graph-based hidden vectors and exploited importance scores for words from dependency trees as we do in this work. 3 Model The task of ABSA can be formalized as follows: Given a sentence X = [x1 , x2 , . . . , xn ] of"
2020.findings-emnlp.407,P15-2060,1,0.791192,"t dataset of MAMS. As can be seen, the proposed model is significantly Conclusion We introduce a new model for ABSA that addresses two limitations of the prior work. It employs the given aspect terms to customize the hidden vectors. It also benefits from the overall dependency-based importance scores of the words. Our extensive experiments on three benchmark datasets empirically demonstrate the effectiveness of the proposed approach, leading to state-of-the-art results on these datasets. The future work involves applying the proposed model to the related tasks for ABSA, e.g., event detection (Nguyen and Grishman, 2015). Acknowledgement This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA Contract No. 2019-19051600006 under the Better Extraction from Text Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, the Department of Defense, or the U.S. Government. The U.S. Government is authorized to repro"
2020.findings-emnlp.409,W16-2922,0,0.0180225,"CDR (Chemical-Disease Reactions) dataset is manually annotated for the binary interactions between Chemical and Disease concepts (Li et al., 2016a) while GDA (Gene-Disease Associations) (Ye et al., 2019) provides the annotations for the binary interactions between Gene and Disease concepts using distant supervision. For both datasets, we follow the same data preprocessing and spits (i.e., for training/development/test data) as the prior work (Christopoulou et al., 2019) to achieve a fair comparison. Also, similar to (Christopoulou et al., 2019), we use the PubMed pre-trained word embeddings (Chiu et al., 2016) 4563 Model (Gu et al., 2017) (Verga et al., 2018) (Nguyen and Verspoor, 2018) EoG (Christopoulou et al., 2019) EoGANE (our system) (Zhou et al., 2016)* (Peng et al., 2016)* (Li et al., 2016b)* (Chandrasekarasastry et al., 2018)* (Zheng et al., 2018)* for the models on CDR while randomly initialized word embeddings are employed for GDA. These word embeddings are optimized during the training process of the models in this work. We implement the EoGANE model in this work by extending the code for the EoG model that is provided in its original paper (Christopoulou et al., 2019). As such, we inher"
2020.findings-emnlp.409,D19-1498,0,0.388496,"siders relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determined by the coreferences of the entity mentions and the appearance of the entity mentions"
2020.findings-emnlp.409,N19-1370,0,0.0203949,"k RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) i"
2020.findings-emnlp.409,C16-1139,0,0.0167383,"he similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopo"
2020.findings-emnlp.409,P16-1200,0,0.0261951,"r DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented"
2020.findings-emnlp.409,P09-1113,0,0.0739897,"regularization techniques to improve the representations for DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches"
2020.findings-emnlp.409,W18-2314,0,0.0921693,"eyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE is to predict the semantic relationships between each pair of entities in E (i.e., including the type NONE for the entity pairs with no relations). In this se"
2020.findings-emnlp.409,P14-2012,1,0.742077,"puting the representations for the nodes in the graphs. Based on such node representations, we introduce two novel regularization techniques to improve the representations for DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al"
2020.findings-emnlp.409,W15-1506,1,0.826948,"odel for DRE. These node representations allow us to introduce two novel representation regularization mechanisms to improve the representation vectors for DRE. The experiments show that our model achieves state-of-the-art performance on two benchmark datasets. 1 Introduction An important task of Information Extraction is Relation Extraction (RE) that seeks to identify the semantic relationships between entities mentioned in text. The prior works have mainly focused on the intra-sentence scenario where the two entity mentions appear in the same sentences (Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2015). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Pen"
2020.findings-emnlp.409,Q17-1008,0,0.0897077,"15). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determin"
2020.findings-emnlp.409,E17-1110,0,0.150604,"we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determined by the coreferences"
2020.findings-emnlp.409,P19-1423,0,0.113527,"nsively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE"
2020.findings-emnlp.409,N19-1147,0,0.0210858,"ision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE is to predict the semantic relationships between each pair of entities in E (i.e., including the type NONE for the entity pairs with no relations). In this section, we will first describe the graph-ba"
2020.findings-emnlp.409,D18-1246,0,0.0217721,"n two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity m"
2020.findings-emnlp.409,N18-1080,0,0.0725814,"hang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019) that introduces new document graphs for DRE based on entity mentions, entities and sentences as the nodes. 3 Model Formally, in the DRE problem, the input involves a document D with S, M , and E as the sets of the sentences, entity mentions, and entities (respectively) in D. The goal of DRE is to predict the semantic relationships between each pair of entities in E (i.e., including the type NONE for the entity pairs wit"
2020.findings-emnlp.409,2020.acl-main.715,1,0.876087,"Missing"
2020.findings-emnlp.409,D15-1203,0,0.0297258,"representations for DRP, capturing the similarities between the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-"
2020.findings-emnlp.409,C14-1220,0,0.253627,"sed edge-oriented model for DRE. These node representations allow us to introduce two novel representation regularization mechanisms to improve the representation vectors for DRE. The experiments show that our model achieves state-of-the-art performance on two benchmark datasets. 1 Introduction An important task of Information Extraction is Relation Extraction (RE) that seeks to identify the semantic relationships between entities mentioned in text. The prior works have mainly focused on the intra-sentence scenario where the two entity mentions appear in the same sentences (Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2015). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distance and intersentent"
2020.findings-emnlp.409,D17-1186,0,0.0180602,"een the node and edge representations of the same edges or the same entities. We conduct extensive experiments to demonstrate the effectiveness of the proposed method for DRE, yielding the state-of-the-art performance for this task on two benchmark datasets. 2 Related Work RE has been extensively studied in the intersentence (Zelenko et al., 2003; Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2014, 2016; Zhang et al., 2018; Veyseh et al., 2019, 2020) and distant supervision settings (Mintz et al., 2009; Riedel et al., 2010; Zeng et al., 2015; Lin et al., 2016; Jiang et al., 2016; Zeng et al., 2017; Vashishth et al., 2018). Recently, document-level RE has gained more attention from the community. Two major approaches have been considered for DRE, i.e., the graph-based (Quirk and Poon, 2017; Peng et al., 2017; Song et al., 2018; Gupta et al., 2019; Jia et al., 2019; Sahu et al., 2019) and non-graph-based (Gu et al., 2017; Peng et al., 2016; Zhou et al., 2016; Zheng et al., 2018; Li et al., 2018; Verga et al., 2018; Nguyen and Verspoor, 2018; Ye et al., 2019; Singh and Bhatia, 2019) approaches. The closest work to ours is the graph-based edgeoriented model in (Christopoulou et al., 2019)"
2020.findings-emnlp.409,D18-1244,0,0.125622,"their ability to capture long-distance and intersentential information in text (Peng et al., 2017; Quirk and Poon, 2017; Gupta et al., 2019). In particular, (Christopoulou et al., 2019) has recently introduced a graph-based edge-oriented network that achieves state-of-the-art performance for DRE. The key idea in this model is to build a interaction graph for each input document where the nodes include the entity mentions, the entities, and the sentences. Note that this is fundamentally different from the prior graph-based models for RE that have mostly used words as the nodes for the graphs (Zhang et al., 2018; Gupta et al., 2019). In this model, the edges between these nodes are determined by the coreferences of the entity mentions and the appearance of the entity mentions in the sentences. The representation vectors for the edges of the graph (thus called edge-oriented) are then computed via several inference layers, serving as the features to predict the relations between the pairs of entities in the documents. In this way, the model can leverage the interactions between the nodes and edges of different types to obtain richer representation vectors for the edges between the entity nodes (Christo"
2020.findings-emnlp.409,P05-1053,0,0.294916,"des in the graph-based edge-oriented model for DRE. These node representations allow us to introduce two novel representation regularization mechanisms to improve the representation vectors for DRE. The experiments show that our model achieves state-of-the-art performance on two benchmark datasets. 1 Introduction An important task of Information Extraction is Relation Extraction (RE) that seeks to identify the semantic relationships between entities mentioned in text. The prior works have mainly focused on the intra-sentence scenario where the two entity mentions appear in the same sentences (Zhou et al., 2005; Zeng et al., 2014; Nguyen and Grishman, 2015). In this work, we study a more recent setting for RE that additionally considers relations between two entity mentions in different sentences of the documents (i.e., inter-sentence relations) (called document-level RE (DRE)). The current methods for document-level RE have intensively relied on deep learning to induce effective representation vectors for relation prediction. Among these deep learning models, graphbased neural networks have been demonstrated as one of the most effective approaches for DRE due to their ability to capture long-distan"
2020.findings-emnlp.411,D17-1321,0,0.0243344,"in the images are not necessarily covered in their full details. Consequently, in this work, we seek to fill in this gap for IC by exploring personality image captioning (PIC) where the models need to further consider a personality/trait in the captioning process. In particular, we leverage PERSONALITY-CAPTIONS (PC) (Shuster et al., 2019), the first dataset for PIC, to evaluate the models in this work. Which characteristics should a caption have to adequately describe an image in PIC? Motivated by the functional and structural decomposition for language learning (Lazaridou et al., 2016, 2020; Kottur et al., 2017), we argue that an effective caption for PIC should posses two important properties. On the one hand, the captions in PIC should follow the natural language structures to induce effective communication with human (i.e., the structural view or naturalness of the captions). On the other hand, for the functional view, the generated captions from a model should involve sufficient information to enable another system or human to uniquely identify the input images and traits. In this paper, we propose to achieve these two goals by recasting PIC as a multi-agent communication framework that involves"
2020.findings-emnlp.411,P16-1162,0,0.00957698,"del with 20 epochs for the pre-training step and 3 epochs for the main training step using early stopping on the development data. In addition, we use the distilled version of GPT2 in (Sanh et al., 2019) for the GPT2 model in this work. The size of the transformer model in GPT2 follows (Sanh et al., 2019) where the number of layers is L = 6, the number of attention heads is 8, the dimensionality of the hidden vectors is d = 1024, and the dimension of the input embeddings (i.e., the segmentation embeddings, positional embeddings, and word embeddings) is 768. Finally, we use Byte Pair Encoding (Sennrich et al., 2016) to tokenize the captions in the dataset. 3.2 Comparing to the State of the Art We compare our proposed model (called GPTSpeaker) with the state-of-the-art models on the PC test data. In particular, we consider the following baselines (reported in Shuster et al. (2019)): (1) ShowTell: the encoder-decoder architecture (Vinyals et al., 2014), (2) ShowAttTell: a similar model to ShowTell where the visual feature vector is computed via attention (Xu et al., 2015), and (3) UpDown: an encoder-decoder model with two LSTM layers for the decoder (Shuster et al., 2019). UpDown, which is adapted from (An"
2020.findings-emnlp.411,2020.acl-main.685,0,0.0310499,"Missing"
2020.findings-emnlp.411,Q14-1006,0,0.0357364,"nerated captions from GPT-Speaker and UpDown are selected by the annotators (i.e., the win percentages). Table 3 shows the win percentages of GPT-Speaker and UpDown for the three tests. It is clear from the table that GPT-Speaker substantially outperforms UpDown in this human evaluation. This is significant with p < 0.005 (using a binomial two-tailed test), thus highlighting the advantage of GPT-Speaker to generate more engaging and relevant captions for PIC. Related Work The main approach for IC so far involves deep learning models where several datasets have been created (Chen et al., 2015; Young et al., 2014) and different variants of the encoder-decoder architectures have been proposed (Xu et al., 2015; Herdade et al., 2019; Su et al., 2019). PIC is a way to encourage more engaging captions for which several features are considered, i.e., location and age (Denton et al., 2015), reader’s active vocabulary (Park et al., 2017), humour (Yoshida et al., 2018), sentiment (Mathews et al., 2016), dialog/conversation (Zhang et al., 2018), and caption styles (Gan et al., 2017; Mathews et al., 2018). The closest work to ours is (Shuster et al., 2019) that examines a different feature of diverse personality"
2020.findings-emnlp.411,P18-1205,0,0.0222038,"ing and relevant captions for PIC. Related Work The main approach for IC so far involves deep learning models where several datasets have been created (Chen et al., 2015; Young et al., 2014) and different variants of the encoder-decoder architectures have been proposed (Xu et al., 2015; Herdade et al., 2019; Su et al., 2019). PIC is a way to encourage more engaging captions for which several features are considered, i.e., location and age (Denton et al., 2015), reader’s active vocabulary (Park et al., 2017), humour (Yoshida et al., 2018), sentiment (Mathews et al., 2016), dialog/conversation (Zhang et al., 2018), and caption styles (Gan et al., 2017; Mathews et al., 2018). The closest work to ours is (Shuster et al., 2019) that examines a different feature of diverse personality traits. Our work also bears some similarity with the previous IC models that attempts to improve the ability to discriminate images for the generated captions (Liu et al., 2018; Luo et al., 2018; Vered et al., 2019). However, these IC models do not capture personality traits for PIC as we do. We also note the stylized IC model in (Guo et al., 2019) that applies a style classification loss. However, this work does not consider"
2020.nlp4convai-1.11,L18-1683,0,0.0176462,"s, Pi (.|{x1 , x2 , ..., xn }/xi ) = sof tmax(F F (hci )). Finally, we use the following negative log-likelihood as the loss function to be optimized during training: Lwp = 1 |L| Σ − (yks · log(Pk (yks |x1 , x2 , ..., xn ))+ |L |k=1 (1 − yks ) · log(1 − Pk (yks |x1 , x2 , ..., xn ))) (5) L = Lpred + αLdiscr + βLwp + γLsp (6) where α, β and γ are the trade-off parameters to be tuned based on the development set performance. 4 4.1 Experiments Dataset and Parameters We evaluate our model on three SF datasets. Namely, we employ ATIS (Hemphill et al., 1990), SNIPS (Coucke et al., 2018) and EditMe (Manuvinakurike et al., 2018). ATIS and SNIPS are two widely adopted SF dataset and EditMe is a SF dataset for editing images with four slot labels (i.e., Action, Object, Attribute and Value). The 1 n Σ − log(Pi (yi |{x1 , x2 , ..., xn }/xi )) n i=1 (4) 92 Model Joint Seq(2016) Attention-Based(2016) Sloted-Gated(2018) SF-ID(2019) CAPSULE-NLU(2019) SPTID(2019) CVT(2018) GCDT(2019) Ours statistics of the datasets are presented in the Appendix A. Based on the experiments on EditMe development set, the following parameters are selected: GloVe embedding with 300 dimensions to initialize word embedding ; 200 dimensions for the"
2020.nlp4convai-1.11,D18-1217,0,0.0212242,"Table 1: Performance of the model and baselines on the Test sets. We compare our model with other deep learning based models for SF. Namely, we compare the proposed model with Joint Seq (Hakkani-T¨ur et al., 2016), Attention-Based (Liu and Lane, 2016), Sloted-Gated (Goo et al., 2018), SF-ID (E et al., 2019), CAPSULE-NLU (Zhang et al., 2019), and SPTID (Qin et al., 2019). Note that we compare our model with the single-task version of these baselines. We also compare our model with other sequence labeling models which are not specifically proposed for SF. Namely, we compare the model with CVT (Clark et al., 2018) and GCDT (Liu et al., 2019). CVT aims to improve input representation using improving partial views and GCDT exploits contextual information to enhance word representations via concatenation of context and word representation. 4.3 SNIPS 87.3 87.8 89.2 90.9 91.8 90.8 91.4 92.0 93.6 5 Conclusion In this work, we introduced a new deep model for the task of Slot Filling (SF). In a multi-task setting, our model increases the mutual information between the word representation and its context, improves label information in the context and predicts which concepts are expressed in the given sentence."
2020.nlp4convai-1.11,D19-1214,0,0.060801,"spoken language understanding (SLU). Early work employed feature engineering for statistical models, e.g., Conditional Random Field (Raymond and Riccardi, 2007). Due to the lack of generalisation ability of feature based models, deep learning based models superseded them (Yao et al., 2014; Peng et al., 2015; Kurata et al., 2016; Hakkani-T¨ur et al., 2016). Also, joint models to simultaneously predict the intent of the utterance and to extract the semantic slots has also gained a lot of attention (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Qin et al., 2019; E et al., 2019). In addition to the supervised settings, recently other setting such as progressive learning (Shen et al., 2019) or zero-shot learning has also been studied (Shah et al., 2019). To the best of our knowledge, none of the existing work introduces a multi-task learning solely for the SF to incorporate the contextual information in both representation and task levels. 3 3.2 In this sub-task we aim to increase the consistency between the word representation and its context. To obtain the context of each word, we use max pooling over the outputs of the BiLSTM for all words of the s"
2020.nlp4convai-1.11,P19-1544,0,0.0271447,"Missing"
2020.nlp4convai-1.11,N18-2118,0,0.0817736,"f the sub-tasks of spoken language understanding (SLU). Early work employed feature engineering for statistical models, e.g., Conditional Random Field (Raymond and Riccardi, 2007). Due to the lack of generalisation ability of feature based models, deep learning based models superseded them (Yao et al., 2014; Peng et al., 2015; Kurata et al., 2016; Hakkani-T¨ur et al., 2016). Also, joint models to simultaneously predict the intent of the utterance and to extract the semantic slots has also gained a lot of attention (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Qin et al., 2019; E et al., 2019). In addition to the supervised settings, recently other setting such as progressive learning (Shen et al., 2019) or zero-shot learning has also been studied (Shah et al., 2019). To the best of our knowledge, none of the existing work introduces a multi-task learning solely for the SF to incorporate the contextual information in both representation and task levels. 3 3.2 In this sub-task we aim to increase the consistency between the word representation and its context. To obtain the context of each word, we use max pooling over the outputs of the BiLSTM for"
2020.nlp4convai-1.11,D19-1126,0,0.017678,"ield (Raymond and Riccardi, 2007). Due to the lack of generalisation ability of feature based models, deep learning based models superseded them (Yao et al., 2014; Peng et al., 2015; Kurata et al., 2016; Hakkani-T¨ur et al., 2016). Also, joint models to simultaneously predict the intent of the utterance and to extract the semantic slots has also gained a lot of attention (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Qin et al., 2019; E et al., 2019). In addition to the supervised settings, recently other setting such as progressive learning (Shen et al., 2019) or zero-shot learning has also been studied (Shah et al., 2019). To the best of our knowledge, none of the existing work introduces a multi-task learning solely for the SF to incorporate the contextual information in both representation and task levels. 3 3.2 In this sub-task we aim to increase the consistency between the word representation and its context. To obtain the context of each word, we use max pooling over the outputs of the BiLSTM for all words of the sentence excluding the word itself, hci = M axP ooling(h1 , h2 , ..., hn /hi ). We aim to increase the consistency between vectors"
2020.nlp4convai-1.11,N18-2050,0,0.0177448,"ategorized as one of the sub-tasks of spoken language understanding (SLU). Early work employed feature engineering for statistical models, e.g., Conditional Random Field (Raymond and Riccardi, 2007). Due to the lack of generalisation ability of feature based models, deep learning based models superseded them (Yao et al., 2014; Peng et al., 2015; Kurata et al., 2016; Hakkani-T¨ur et al., 2016). Also, joint models to simultaneously predict the intent of the utterance and to extract the semantic slots has also gained a lot of attention (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Qin et al., 2019; E et al., 2019). In addition to the supervised settings, recently other setting such as progressive learning (Shen et al., 2019) or zero-shot learning has also been studied (Shah et al., 2019). To the best of our knowledge, none of the existing work introduces a multi-task learning solely for the SF to incorporate the contextual information in both representation and task levels. 3 3.2 In this sub-task we aim to increase the consistency between the word representation and its context. To obtain the context of each word, we use max pooling over the outputs"
2020.nlp4convai-1.11,P19-1519,0,0.020202,"dataset is more challenging than the other datasets, despite having fewer slot types. This difficulty could be explained by the limited number of training examples and more diversity in sentence structures in this dataset. 4.4 ATIS 94.3 94.2 95.4 95.5 95.2 95.1 94.8 95.1 95.8 Table 1: Performance of the model and baselines on the Test sets. We compare our model with other deep learning based models for SF. Namely, we compare the proposed model with Joint Seq (Hakkani-T¨ur et al., 2016), Attention-Based (Liu and Lane, 2016), Sloted-Gated (Goo et al., 2018), SF-ID (E et al., 2019), CAPSULE-NLU (Zhang et al., 2019), and SPTID (Qin et al., 2019). Note that we compare our model with the single-task version of these baselines. We also compare our model with other sequence labeling models which are not specifically proposed for SF. Namely, we compare the model with CVT (Clark et al., 2018) and GCDT (Liu et al., 2019). CVT aims to improve input representation using improving partial views and GCDT exploits contextual information to enhance word representations via concatenation of context and word representation. 4.3 SNIPS 87.3 87.8 89.2 90.9 91.8 90.8 91.4 92.0 93.6 5 Conclusion In this work, we introduced"
2020.nlp4convai-1.11,H90-1021,0,0.51665,"Missing"
2020.nlp4convai-1.11,D16-1223,0,0.0198318,"of each word. Our extensive experiments on three benchmark datasets, empirically prove the effectiveness of the proposed model leading to new the state-of-the-art results on all three datasets. 2 Related Work In the literature, Slot Filling (SF), is categorized as one of the sub-tasks of spoken language understanding (SLU). Early work employed feature engineering for statistical models, e.g., Conditional Random Field (Raymond and Riccardi, 2007). Due to the lack of generalisation ability of feature based models, deep learning based models superseded them (Yao et al., 2014; Peng et al., 2015; Kurata et al., 2016; Hakkani-T¨ur et al., 2016). Also, joint models to simultaneously predict the intent of the utterance and to extract the semantic slots has also gained a lot of attention (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Qin et al., 2019; E et al., 2019). In addition to the supervised settings, recently other setting such as progressive learning (Shen et al., 2019) or zero-shot learning has also been studied (Shah et al., 2019). To the best of our knowledge, none of the existing work introduces a multi-task learning solely for the SF to incorpor"
2020.nlp4convai-1.11,P19-1233,0,0.023226,"odel and baselines on the Test sets. We compare our model with other deep learning based models for SF. Namely, we compare the proposed model with Joint Seq (Hakkani-T¨ur et al., 2016), Attention-Based (Liu and Lane, 2016), Sloted-Gated (Goo et al., 2018), SF-ID (E et al., 2019), CAPSULE-NLU (Zhang et al., 2019), and SPTID (Qin et al., 2019). Note that we compare our model with the single-task version of these baselines. We also compare our model with other sequence labeling models which are not specifically proposed for SF. Namely, we compare the model with CVT (Clark et al., 2018) and GCDT (Liu et al., 2019). CVT aims to improve input representation using improving partial views and GCDT exploits contextual information to enhance word representations via concatenation of context and word representation. 4.3 SNIPS 87.3 87.8 89.2 90.9 91.8 90.8 91.4 92.0 93.6 5 Conclusion In this work, we introduced a new deep model for the task of Slot Filling (SF). In a multi-task setting, our model increases the mutual information between the word representation and its context, improves label information in the context and predicts which concepts are expressed in the given sentence. Our experiments on three ben"
2020.nuse-1.5,W06-0901,0,0.500858,"detection as a few-shot learning problem to extend ED to new event types and provide a baseline for this new research direction. To our best knowledge, this is a new branch of research that has not been explored. • We propose two novel training signals for FSL. These signals can remarkably improve the performance of existing FSL models. As these signals do not require any additional information (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models. 2 Related work Early studies in event detection mainly address feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2014, 2015) including semantic features and syntactic features. Recently, due to the advances with deep learning, many neural network architectures have been presented for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED a"
2020.nuse-1.5,P15-1017,0,0.555985,"emarkably improve the performance of existing FSL models. As these signals do not require any additional information (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models. 2 Related work Early studies in event detection mainly address feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2014, 2015) including semantic features and syntactic features. Recently, due to the advances with deep learning, many neural network architectures have been presented for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning problem which usually fails to predict the labels of new event types. By transitioning the symbolic event types to descriptive event types in the form of bags of keywords (Bronstein et al., 2015; Peng et al., 2016; Lai and Nguyen, 2019), the adaptibility of event de"
2020.nuse-1.5,D18-1158,0,0.221197,"text (e.g. a sentence) and classify it into one of the event types of interest. The following sentence is an example of ED: In 1997, the company hired John D. Idol to take over as chief executive. In this example, an ideal event detection system should detect the word hired as an event, and classify it to class of Personnel:Start-Position, assuming that Personnel:Start-Position is in the set of interested classes. The current works in ED typically employ traditional supervised learning based on feature engineering (Li et al., 2014; Chen et al., 2017) and neural networks (Nguyen et al., 2016a; Chen et al., 2018; Lu and Nguyen, 2018). The main problem with supervised learning models is that they can not perform well on unseen classes (e.g. training a model to classify daily events, then run this 38 Proceedings of the 1st Joint Workshop on Narrative Understanding, Storylines, and Events, pages 38–45 c July 9, 2020. 2020 Association for Computational Linguistics (Grishman et al., 2005). Therefore, in this study, we propose to train an ED model using matching information (1) between query instance and the support set and (2) between the samples in the support themselves. This is implemented by adding tw"
2020.nuse-1.5,P11-1113,0,0.191269,"problem to extend ED to new event types and provide a baseline for this new research direction. To our best knowledge, this is a new branch of research that has not been explored. • We propose two novel training signals for FSL. These signals can remarkably improve the performance of existing FSL models. As these signals do not require any additional information (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models. 2 Related work Early studies in event detection mainly address feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2014, 2015) including semantic features and syntactic features. Recently, due to the advances with deep learning, many neural network architectures have been presented for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning problem which usua"
2020.nuse-1.5,W16-1618,1,0.94803,"triggers from a given text (e.g. a sentence) and classify it into one of the event types of interest. The following sentence is an example of ED: In 1997, the company hired John D. Idol to take over as chief executive. In this example, an ideal event detection system should detect the word hired as an event, and classify it to class of Personnel:Start-Position, assuming that Personnel:Start-Position is in the set of interested classes. The current works in ED typically employ traditional supervised learning based on feature engineering (Li et al., 2014; Chen et al., 2017) and neural networks (Nguyen et al., 2016a; Chen et al., 2018; Lu and Nguyen, 2018). The main problem with supervised learning models is that they can not perform well on unseen classes (e.g. training a model to classify daily events, then run this 38 Proceedings of the 1st Joint Workshop on Narrative Understanding, Storylines, and Events, pages 38–45 c July 9, 2020. 2020 Association for Computational Linguistics (Grishman et al., 2005). Therefore, in this study, we propose to train an ED model using matching information (1) between query instance and the support set and (2) between the samples in the support themselves. This is impl"
2020.nuse-1.5,P18-1201,0,0.205746,"port set and (2) between the samples in the support themselves. This is implemented by adding two auxiliary factors into the loss function to constrain the learning process. We apply the proposed training signals to different FSL models on the benchmark event detection dataset (Grishman et al., 2005). The experiments show that the training signal can improve the performance of the examined FSL models. To summarize, our contributions to this work include: FSL as we do in this work. One can also address this problem in zero-shot learning with data generated from abstract meaning representation (Huang et al., 2018) or two-stage pipeline ( trigger identification and few-shot event classification) based on dynamic memory network (Deng et al., 2020). A recent study has employed few-shot learning for event classification (Lai et al., 2020). Our work is similar in terms of formulation, however, we consider it in a larger extent of event detection where the NULL event is also included. Few-shot learning has been studied early in the literature (Thrun, 1996). Before the era of the deep neural network, FSL approaches focused on building generative models that can transfer priors across classes. However, these m"
2020.nuse-1.5,P08-1030,0,0.606901,"as a few-shot learning problem to extend ED to new event types and provide a baseline for this new research direction. To our best knowledge, this is a new branch of research that has not been explored. • We propose two novel training signals for FSL. These signals can remarkably improve the performance of existing FSL models. As these signals do not require any additional information (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models. 2 Related work Early studies in event detection mainly address feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2014, 2015) including semantic features and syntactic features. Recently, due to the advances with deep learning, many neural network architectures have been presented for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning"
2020.nuse-1.5,P15-2060,1,0.941981,"he performance of existing FSL models. As these signals do not require any additional information (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models. 2 Related work Early studies in event detection mainly address feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2014, 2015) including semantic features and syntactic features. Recently, due to the advances with deep learning, many neural network architectures have been presented for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning problem which usually fails to predict the labels of new event types. By transitioning the symbolic event types to descriptive event types in the form of bags of keywords (Bronstein et al., 2015; Peng et al., 2016; Lai and Nguyen, 2019), the adaptibility of event detection can be formed as a"
2020.nuse-1.5,D14-1181,0,0.00551631,"Once we get the embedding for the whole sentence E(s) = {m1 , m2 , · · · , mL }, we employ a neural network, denoted as f , to encode the information of an instance (s, a) of the anchor wa under the context in the sentence s into a single vector v = f (E(s), a). In this work, consider the three following neural network architectures for this encoding purpose: ... K (s1N , a1N , tN ), . . . , (sK N , aN , tN ), K (s1N +1 , a1N +1 , tnull ), . . . , (sK 1 , aN +1 , tnull )} where: • {t1 , t2 , · · · tN } is the set of positive labels, which indicate an event • Convolution Neural Network (CNN) (Kim, 2014) encodes the sentence by convolution operation on k consecutive vectors representing k-gram. Follow (Nguyen and Grishman, 2015), we use multiple kernel sizes k ∈ {2, 3, 4, 5} to cover the context with 150 filters for each kernel size. To squeeze the information of the sentence, we apply max pooling to the top convolution layer to get a pooled vector p. We also introduce local embedding e[a−w,a+w] with window size w = 2. We concatenate pooled vector and local embeddings, and feed them through multiple dense layer to get the final representation: • tnull a special label for non-event. • (sji , a"
2020.nuse-1.5,D16-1085,1,0.929964,"Missing"
2020.nuse-1.5,D16-1038,0,0.0186814,"ed for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning problem which usually fails to predict the labels of new event types. By transitioning the symbolic event types to descriptive event types in the form of bags of keywords (Bronstein et al., 2015; Peng et al., 2016; Lai and Nguyen, 2019), the adaptibility of event detection can be formed as a supervised-learning problem. However, these studies have not examined 3 Methodology Our goal in this work is to formulate ED as a FSL problem, which has not been done in prior work. In order to achieve this, this section is divided into three parts. In the section 3.1 we present the overall framework that formulate Event Detection as an Few-Shot Learning problem. Then, we present popular models for FSL in the prior work and common sentence encoders which have been widely used in ED in section 3.2. Finally, we prese"
2020.nuse-1.5,P19-1432,1,0.861759,"ture engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2014, 2015) including semantic features and syntactic features. Recently, due to the advances with deep learning, many neural network architectures have been presented for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning problem which usually fails to predict the labels of new event types. By transitioning the symbolic event types to descriptive event types in the form of bags of keywords (Bronstein et al., 2015; Peng et al., 2016; Lai and Nguyen, 2019), the adaptibility of event detection can be formed as a supervised-learning problem. However, these studies have not examined 3 Methodology Our goal in this work is to formulate ED as a FSL problem, which has not been done in prior work. In order to achieve this, this section is divided into three parts. In"
2020.nuse-1.5,D19-5532,1,0.662469,"volutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning problem which usually fails to predict the labels of new event types. By transitioning the symbolic event types to descriptive event types in the form of bags of keywords (Bronstein et al., 2015; Peng et al., 2016; Lai and Nguyen, 2019), the adaptibility of event detection can be formed as a supervised-learning problem. However, these studies have not examined 3 Methodology Our goal in this work is to formulate ED as a FSL problem, which has not been done in prior work. In order to achieve this, this section is divided into three parts. In the section 3.1 we present the overall framework that formulate Event Detection as an Few-Shot Learning problem. Then, we present popular models for FSL in the prior work and common sentence encoders which have been widely used in ED in section 3.2. Finally, we present two novel reguarliza"
2020.nuse-1.5,D14-1198,0,0.13744,"ssing (NLP). Event Detection is the task to detect event triggers from a given text (e.g. a sentence) and classify it into one of the event types of interest. The following sentence is an example of ED: In 1997, the company hired John D. Idol to take over as chief executive. In this example, an ideal event detection system should detect the word hired as an event, and classify it to class of Personnel:Start-Position, assuming that Personnel:Start-Position is in the set of interested classes. The current works in ED typically employ traditional supervised learning based on feature engineering (Li et al., 2014; Chen et al., 2017) and neural networks (Nguyen et al., 2016a; Chen et al., 2018; Lu and Nguyen, 2018). The main problem with supervised learning models is that they can not perform well on unseen classes (e.g. training a model to classify daily events, then run this 38 Proceedings of the 1st Joint Workshop on Narrative Understanding, Storylines, and Events, pages 38–45 c July 9, 2020. 2020 Association for Computational Linguistics (Grishman et al., 2005). Therefore, in this study, we propose to train an ED model using matching information (1) between query instance and the support set and (2"
2020.nuse-1.5,W15-4502,1,0.883188,"Missing"
2020.nuse-1.5,P17-1164,0,0.303305,"ormation (e.g. dependency tree or part-of-speech), they can be applied in any metric-based FSL models. 2 Related work Early studies in event detection mainly address feature engineering for statistical models (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Li et al., 2014, 2015) including semantic features and syntactic features. Recently, due to the advances with deep learning, many neural network architectures have been presented for ED, e.g. convolutional neural networks (CNN) (Chen et al., 2015; Nguyen and Grishman, 2015, 2016; Nguyen et al., 2016b), recurrent neural networks (RNN) (Liu et al., 2017; Chen et al., 2018; Nguyen et al., 2016a; Nguyen and Nguyen, 2018) and graph convolutional neural networks (GCN) (Nguyen and Grishman, 2018; Pouran Ben Veyseh et al., 2019). These methods formulate ED as a supervised learning problem which usually fails to predict the labels of new event types. By transitioning the symbolic event types to descriptive event types in the form of bags of keywords (Bronstein et al., 2015; Peng et al., 2016; Lai and Nguyen, 2019), the adaptibility of event detection can be formed as a supervised-learning problem. However, these studies have not examined 3 Methodol"
2020.nuse-1.5,N19-1080,0,0.0132604,"vent Detection Viet Dac Lai1 , Franck Dernoncourt2 and Thien Huu Nguyen1 1 Department of Computer and Information Science, University of Oregon, Eugene, Oregon, USA 2 Adobe Research, San Jose, CA, USA {vietl, thien}@cs.uoregon.edu franck.dernoncourt@adobe.com Abstract model to classify laboratory operations). As a result, supervised learning ED can not extend to unseen event types. A trivial solution is to annotate more data for unseen event types, then retraining the model with newly annotated data. However, this method is usually impractical because of the extremely high cost of annotation (Liu et al., 2019). A human can learn about a new concept with limited supervision e.g. one can detect and classify events with 3-5 examples (Grishman et al., 2005). This motivates the setting we aim for event detection: few-shot learning (FSL). In FSL, a trained model rapidly learns a new concept from a few examples while keeping great generalization from observed examples (Vinyals et al., 2016). Hence, if we need to extend event detection into a new domain, a few examples are needed to activate the system in the new domain without retraining the model. By formulating ED as FSL, we can significantly reduce the"
2020.nuse-1.5,D18-1517,1,0.831588,"ce) and classify it into one of the event types of interest. The following sentence is an example of ED: In 1997, the company hired John D. Idol to take over as chief executive. In this example, an ideal event detection system should detect the word hired as an event, and classify it to class of Personnel:Start-Position, assuming that Personnel:Start-Position is in the set of interested classes. The current works in ED typically employ traditional supervised learning based on feature engineering (Li et al., 2014; Chen et al., 2017) and neural networks (Nguyen et al., 2016a; Chen et al., 2018; Lu and Nguyen, 2018). The main problem with supervised learning models is that they can not perform well on unseen classes (e.g. training a model to classify daily events, then run this 38 Proceedings of the 1st Joint Workshop on Narrative Understanding, Storylines, and Events, pages 38–45 c July 9, 2020. 2020 Association for Computational Linguistics (Grishman et al., 2005). Therefore, in this study, we propose to train an ED model using matching information (1) between query instance and the support set and (2) between the samples in the support themselves. This is implemented by adding two auxiliary factors in"
2020.nuse-1.5,N16-1034,1,0.960297,"triggers from a given text (e.g. a sentence) and classify it into one of the event types of interest. The following sentence is an example of ED: In 1997, the company hired John D. Idol to take over as chief executive. In this example, an ideal event detection system should detect the word hired as an event, and classify it to class of Personnel:Start-Position, assuming that Personnel:Start-Position is in the set of interested classes. The current works in ED typically employ traditional supervised learning based on feature engineering (Li et al., 2014; Chen et al., 2017) and neural networks (Nguyen et al., 2016a; Chen et al., 2018; Lu and Nguyen, 2018). The main problem with supervised learning models is that they can not perform well on unseen classes (e.g. training a model to classify daily events, then run this 38 Proceedings of the 1st Joint Workshop on Narrative Understanding, Storylines, and Events, pages 38–45 c July 9, 2020. 2020 Association for Computational Linguistics (Grishman et al., 2005). Therefore, in this study, we propose to train an ED model using matching information (1) between query instance and the support set and (2) between the samples in the support themselves. This is impl"
2021.acl-long.374,J14-2004,0,0.0223991,"n entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017a; Joshi et al., 2019b,a). However, resolving event mentions has been considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previous methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), joint modeling of ECR with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; C"
2021.acl-long.374,D15-1247,0,0.0196341,"n the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previous methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), joint modeling of ECR with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Lu et al., 2020; Choubey et al., 2020). Compared to previous deep learning works for ECR, our model presents a novel representation learning framework based on document structures to explicitly encode important interactions between relevant objects, and representation regularization to exploit the cluster consistency between golden and predicted clusters for event mentions. 3 Model Formally, in ECR, given an input document D = w1 , w2 , . ."
2021.acl-long.374,P98-1012,0,0.339557,"documents from KBP 2015 as in (Choubey and Huang, 2018) for the training data and the remaining 50 documents for the development data. Also, similar to (Choubey and Huang, 2018), the news articles in KBP 2016 (85 documents) and KBP 2017 (83 documents) are leveraged for test datasets. To ensure a fair comparison, we use the predicted event mentions provided by (Choubey and Huang, 2018) in all the datasets. Finally, we report the ECR performance based on the official KBP 2017 scorer (version 1.8)3 . The scorer employs four coreference scoring measures, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998), CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b), and the unweighted average of their F1 scores (AVGF 1 ). Hyper-parameters for the models are fine-tuned by the AVGF 1 scores over development data. The selected values from the tuning process include: 1e5 for the learning rate of the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 8 for the mini-batch size (selected from [8, 16, 32, 64]); 128 hidden units for all the feed-forward network and GCN layers (selected from [64, 128, 256, 512]); 2 layers for the GCN model, G = 2 (selected from [1, 2, 3, 4]), and αinner = 0.1, αinter = 0."
2021.acl-long.374,P19-1409,0,0.217681,"esentation vectors to encode discriminative features for coreference prediction. Early work on ECR has achieved feature representation via feature engineering where multiple features are hand-designed for input event mention pairs (Lu and Ng, 2017). A major problem with feature engineering is the sparsity of the features that limits the generalization to unseen data. Representation learning in deep learning models has recently been introduced to address this issue, leading to more robust methods with better performance for ECR (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Barhom et al., 2019). As such, there are at least two limitations in existing deep learning models for ECR that will be addressed in this work to improve the performance. First, as event mentions pairs for coreference prediction might belong to long-distance sentences in documents, capturing document-level context between the event mentions (i.e., beyond the two sentences that host the event mentions) might present useful information for ECR. As their first limitation, prior deep learning models for ECR has only attempted to encode document-level context via hand-designed features (Kenyon-Dean et al., 2018; Barho"
2021.acl-long.374,2020.acl-main.95,0,0.0172633,"teraction scores aij for the nodes in N . To this end, we propose to utilize WordNet (Miller, 1995), a rich network of word meanings, to obtain external knowledge for the words in D. The word meanings (i.e., synsets) in WordNet are connected to each other via different semantic relations (e.g., synonyms, hyponyms). In particular, our first step to generate knowledge-based similarity scores involves mapping each word node ni ∈ D ∩ N to a synset node Mi in WordNet using a Word Sense Disambiguation (WSD) tool. In particular, we employ WordNet 3.0 and the state-of-the-art BERT-based WSD model in (Blevins and Zettlemoyer, 2020) to perform the word-synset mapping in this work. Afterward, we compute a knowledge-based similarity score astruct for each pair of word nodes ni and nj ij in D ∩ N using the structure-based similarity of their linked synsets Mi and Mj in WordNet (i.e., astruct = 0 if either ni or nj is not a word node in ij D ∩ N ). Accordingly, the Lin similarity measure (Lin et al., 1998) for synset nodes in WordNet is uti2∗IC(LCS(Mi ,Mj )) lized for this purpose: astruct = IC(Mi )+IC(M . ij j) Here, IC and LCS represent the information content of synset nodes and the least common subsumer of two synsets in"
2021.acl-long.374,W09-3208,0,0.170098,"es of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previous methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), joint modeling of ECR with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Lu et al., 2020; Choubey et al., 2020). Compared to previous deep learning works for ECR, our model presents a novel representation learning framework based on document structures to explicitly encode important interactions between relevant objects, and representation regularization to exp"
2021.acl-long.374,W09-4303,0,0.231232,"of-the-art performance on two benchmark datasets. 1 Introduction Event coreference resolution (ECR) is the task of clustering event mentions (i.e., trigger words that evoke an event) in a document such that each cluster represents a unique real world event. For example, the three event mentions in Figure 1, i.e., “refuse to sign, “raised objections”, and “doesn’t sign”, should be grouped into the same cluster to indicate their coreference to the same event. A common component in prior ECR models involves a binary classifier that receives a pair of event mentions and predict their coreference (Chen et al., 2009; Lu et al., 2016; Lu and Ng, 2017). To this end, an important step in ECR models is to transform event mention pairs into representation vectors to encode discriminative features for coreference prediction. Early work on ECR has achieved feature representation via feature engineering where multiple features are hand-designed for input event mention pairs (Lu and Ng, 2017). A major problem with feature engineering is the sparsity of the features that limits the generalization to unseen data. Representation learning in deep learning models has recently been introduced to address this issue, lea"
2021.acl-long.374,D17-1226,0,0.0308769,"Missing"
2021.acl-long.374,P18-1045,0,0.288675,"is to transform event mention pairs into representation vectors to encode discriminative features for coreference prediction. Early work on ECR has achieved feature representation via feature engineering where multiple features are hand-designed for input event mention pairs (Lu and Ng, 2017). A major problem with feature engineering is the sparsity of the features that limits the generalization to unseen data. Representation learning in deep learning models has recently been introduced to address this issue, leading to more robust methods with better performance for ECR (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Barhom et al., 2019). As such, there are at least two limitations in existing deep learning models for ECR that will be addressed in this work to improve the performance. First, as event mentions pairs for coreference prediction might belong to long-distance sentences in documents, capturing document-level context between the event mentions (i.e., beyond the two sentences that host the event mentions) might present useful information for ECR. As their first limitation, prior deep learning models for ECR has only attempted to encode document-level context via hand-designed"
2021.acl-long.374,2020.acl-main.478,0,0.577604,"t al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previous methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), joint modeling of ECR with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Lu et al., 2020; Choubey et al., 2020). Compared to previous deep learning works for ECR, our model presents a novel representation learning framework based on document structures to explicitly encode important interactions between relevant objects, and representation regularization to exploit the cluster consistency between golden and predicted clusters for event mentions. 3 Model Formally, in ECR, given an input document D = w1 , w2 , . . . , wN (of N words/tokens) with a set of event mentions E = {e1 , e2 , . . . , e|E |}, the goal is to group the event mentions in E into clusters to capture the coreference relation between men"
2021.acl-long.374,N19-1423,0,0.0366961,"ion vectors, (ii) Document Structure to create graphs for documents and learn rich representation vectors for event mentions, (iii) End-to-end Resolution to simultaneously resolve the coreference for the entity mentions in D, and (iv) Cluster Consistency Regularization to regularize representation vectors based on consistency constraints between golden and predict event mention clusters. Figure 2 presents an overview of our model for ECR. 3.1 Document Encoder In the first step, we transform each word wi ∈ D into a representation vector xi by feeding D into the pre-trained language model BERT (Devlin et al., 2019). In particular, as BERT might split wi into several word-pieces, we average the hidden vectors of the word-pieces of wi in the last layer of BERT to obtain the representation vector xi for wi . To handle long documents with BERT, we divide D into segments of 512 consecutive word-pieces that will be encoded separately. The resulting sequence X = x1 , x2 , . . . , xn for D is then sent to the next steps for further computation. 3.2 Document Structure This component aims to learn representation vectors for the event mentions in E using an interaction graph G = {N , E} for D that facilitates the"
2021.acl-long.374,D13-1203,0,0.116797,"ng signals to improve representation vectors for event mentions in ECR. To our knowledge, this is also the first work to exploit cluster consistency-based regularization for representation learning in ECR. Finally, we conduct extensive experiments for ECR on the KBP benchmark datasets. The experiments demonstrate the benefits of the proposed methods and lead to state-of-the-art performance for ECR. 2 Related Work Event coreference resolution is broadly related to works on entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017a; Joshi et al., 2019b,a). However, resolving event mentions has been considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-documen"
2021.acl-long.374,N19-1085,0,0.662906,"tion pairs into representation vectors to encode discriminative features for coreference prediction. Early work on ECR has achieved feature representation via feature engineering where multiple features are hand-designed for input event mention pairs (Lu and Ng, 2017). A major problem with feature engineering is the sparsity of the features that limits the generalization to unseen data. Representation learning in deep learning models has recently been introduced to address this issue, leading to more robust methods with better performance for ECR (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Barhom et al., 2019). As such, there are at least two limitations in existing deep learning models for ECR that will be addressed in this work to improve the performance. First, as event mentions pairs for coreference prediction might belong to long-distance sentences in documents, capturing document-level context between the event mentions (i.e., beyond the two sentences that host the event mentions) might present useful information for ECR. As their first limitation, prior deep learning models for ECR has only attempted to encode document-level context via hand-designed features (Kenyon-De"
2021.acl-long.374,D19-1588,0,0.0413228,"Missing"
2021.acl-long.374,S18-2001,0,0.401987,"al., 2019; Barhom et al., 2019). As such, there are at least two limitations in existing deep learning models for ECR that will be addressed in this work to improve the performance. First, as event mentions pairs for coreference prediction might belong to long-distance sentences in documents, capturing document-level context between the event mentions (i.e., beyond the two sentences that host the event mentions) might present useful information for ECR. As their first limitation, prior deep learning models for ECR has only attempted to encode document-level context via hand-designed features (Kenyon-Dean et al., 2018; Barhom et al., 2019) that still suffer from the feature sparsity issue. In addition, such prior work is unable to exploit ECR-related objects in documents (e.g., entity mentions, context words) and their connections/interactions (possibly beyond sentence boundary) to aid representation learning. An example for the importance of context words, entity mentions, and their interactions for ECR can be seen in Figure 1. Here, to decisively determine the coreference of “raised objections” and “doesn’t sign”, ECR systems should recognize “Trump” and “the 4840 Proceedings of the 59th Annual Meeting o"
2021.acl-long.374,D12-1045,0,0.494385,"broadly related to works on entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017a; Joshi et al., 2019b,a). However, resolving event mentions has been considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previous methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), joint modeling of ECR with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep lear"
2021.acl-long.374,D17-1018,0,0.212186,"resentation vectors for event mentions in ECR. To our knowledge, this is also the first work to exploit cluster consistency-based regularization for representation learning in ECR. Finally, we conduct extensive experiments for ECR on the KBP benchmark datasets. The experiments demonstrate the benefits of the proposed methods and lead to state-of-the-art performance for ECR. 2 Related Work Event coreference resolution is broadly related to works on entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017a; Joshi et al., 2019b,a). However, resolving event mentions has been considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previo"
2021.acl-long.374,P13-1008,0,0.0329816,". Here, aspan is ij ij only set to 1 (i.e., 0 otherwise) if ni is a word (ni ∈ D) in the span of the entity/event mention nj (nj ∈ E ∪M ) or vice verse. aspan is important as it ij helps ground representation vectors of event/entity mentions to the contextual information in D. Syntax-based Edges: We expect the dependency trees of the sentences in D to provide beneficial information to connect the nodes in N for effective representation learning in ECR. For example, dependency trees have been used to retrieve important context words between an event mentions and their arguments in prior work (Li et al., 2013; Veyseh et al., 2020a,b). To this end, we propose to employ the dependency relations/connections between the words in D to obtain a syntax-based interaction score adep ij for each pair of nodes ni and nj in N , serving as an additional input for aij . In particular, by inheriting the graph structures of the dependency trees of the sentences in D, we set adep ij to 1 if ni and nj are two words in the same sentence (i.e., ni , nj ∈ D) and there is an edge between them in the corresponding dependency tree1 , and 0 otherwise. Semantic-based Edges: This information leverages the semantic similarit"
2021.acl-long.374,liu-etal-2014-supervised,0,0.188244,"work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previous methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), joint modeling of ECR with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Lu et al., 2020; Choubey et al., 2020). Compared to previous deep learning works for ECR, our model presents a novel representation learning framework based on document structures to explicitly encode important interactions between relevant objects, and representation regularization to exploit the cluster consistency between golden"
2021.acl-long.374,P17-1009,0,0.759973,"ark datasets. 1 Introduction Event coreference resolution (ECR) is the task of clustering event mentions (i.e., trigger words that evoke an event) in a document such that each cluster represents a unique real world event. For example, the three event mentions in Figure 1, i.e., “refuse to sign, “raised objections”, and “doesn’t sign”, should be grouped into the same cluster to indicate their coreference to the same event. A common component in prior ECR models involves a binary classifier that receives a pair of event mentions and predict their coreference (Chen et al., 2009; Lu et al., 2016; Lu and Ng, 2017). To this end, an important step in ECR models is to transform event mention pairs into representation vectors to encode discriminative features for coreference prediction. Early work on ECR has achieved feature representation via feature engineering where multiple features are hand-designed for input event mention pairs (Lu and Ng, 2017). A major problem with feature engineering is the sparsity of the features that limits the generalization to unseen data. Representation learning in deep learning models has recently been introduced to address this issue, leading to more robust methods with be"
2021.acl-long.374,C16-1308,0,0.646214,"nce on two benchmark datasets. 1 Introduction Event coreference resolution (ECR) is the task of clustering event mentions (i.e., trigger words that evoke an event) in a document such that each cluster represents a unique real world event. For example, the three event mentions in Figure 1, i.e., “refuse to sign, “raised objections”, and “doesn’t sign”, should be grouped into the same cluster to indicate their coreference to the same event. A common component in prior ECR models involves a binary classifier that receives a pair of event mentions and predict their coreference (Chen et al., 2009; Lu et al., 2016; Lu and Ng, 2017). To this end, an important step in ECR models is to transform event mention pairs into representation vectors to encode discriminative features for coreference prediction. Early work on ECR has achieved feature representation via feature engineering where multiple features are hand-designed for input event mention pairs (Lu and Ng, 2017). A major problem with feature engineering is the sparsity of the features that limits the generalization to unseen data. Representation learning in deep learning models has recently been introduced to address this issue, leading to more robu"
2021.acl-long.374,H05-1004,0,0.299596,"oubey and Huang, 2018) for the training data and the remaining 50 documents for the development data. Also, similar to (Choubey and Huang, 2018), the news articles in KBP 2016 (85 documents) and KBP 2017 (83 documents) are leveraged for test datasets. To ensure a fair comparison, we use the predicted event mentions provided by (Choubey and Huang, 2018) in all the datasets. Finally, we report the ECR performance based on the official KBP 2017 scorer (version 1.8)3 . The scorer employs four coreference scoring measures, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998), CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b), and the unweighted average of their F1 scores (AVGF 1 ). Hyper-parameters for the models are fine-tuned by the AVGF 1 scores over development data. The selected values from the tuning process include: 1e5 for the learning rate of the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 8 for the mini-batch size (selected from [8, 16, 32, 64]); 128 hidden units for all the feed-forward network and GCN layers (selected from [64, 128, 256, 512]); 2 layers for the GCN model, G = 2 (selected from [1, 2, 3, 4]), and αinner = 0.1, αinter = 0.1, and αsim = 0.1 fo"
2021.acl-long.374,M95-1005,0,0.805819,"icles). We use the same 310 documents from KBP 2015 as in (Choubey and Huang, 2018) for the training data and the remaining 50 documents for the development data. Also, similar to (Choubey and Huang, 2018), the news articles in KBP 2016 (85 documents) and KBP 2017 (83 documents) are leveraged for test datasets. To ensure a fair comparison, we use the predicted event mentions provided by (Choubey and Huang, 2018) in all the datasets. Finally, we report the ECR performance based on the official KBP 2017 scorer (version 1.8)3 . The scorer employs four coreference scoring measures, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998), CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b), and the unweighted average of their F1 scores (AVGF 1 ). Hyper-parameters for the models are fine-tuned by the AVGF 1 scores over development data. The selected values from the tuning process include: 1e5 for the learning rate of the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 8 for the mini-batch size (selected from [8, 16, 32, 64]); 128 hidden units for all the feed-forward network and GCN layers (selected from [64, 128, 256, 512]); 2 layers for the GCN model, G = 2 (selected from [1, 2, 3, 4])"
2021.acl-long.374,Q15-1037,0,0.119555,"periments for ECR on the KBP benchmark datasets. The experiments demonstrate the benefits of the proposed methods and lead to state-of-the-art performance for ECR. 2 Related Work Event coreference resolution is broadly related to works on entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017a; Joshi et al., 2019b,a). However, resolving event mentions has been considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As such, for within-document 4841 ECR, previous methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009), information propagat"
2021.acl-long.374,P10-1142,0,0.183027,"ful training signals to improve representation vectors for event mentions in ECR. To our knowledge, this is also the first work to exploit cluster consistency-based regularization for representation learning in ECR. Finally, we conduct extensive experiments for ECR on the KBP benchmark datasets. The experiments demonstrate the benefits of the proposed methods and lead to state-of-the-art performance for ECR. 2 Related Work Event coreference resolution is broadly related to works on entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017a; Joshi et al., 2019b,a). However, resolving event mentions has been considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al., 2020). As"
2021.acl-long.374,D16-1038,0,0.24998,"Missing"
2021.acl-long.374,D10-1048,0,0.204396,"f clusters can provide useful training signals to improve representation vectors for event mentions in ECR. To our knowledge, this is also the first work to exploit cluster consistency-based regularization for representation learning in ECR. Finally, we conduct extensive experiments for ECR on the KBP benchmark datasets. The experiments demonstrate the benefits of the proposed methods and lead to state-of-the-art performance for ECR. 2 Related Work Event coreference resolution is broadly related to works on entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017a; Joshi et al., 2019b,a). However, resolving event mentions has been considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions (Yang et al., 2015). Our work focuses on the within-document setting for ECR where input event mentions are expected to appear in the same input documents; however, we also note prior works on crossdocument ECR (Lee et al., 2012a; Adrian Bejan and Harabagiu, 2014; Choubey and Huang, 2017; Kenyon-Dean et al., 2018; Barhom et al., 2019; Cattan et al.,"
2021.acl-long.374,2020.acl-main.715,1,0.766084,"ij ij only set to 1 (i.e., 0 otherwise) if ni is a word (ni ∈ D) in the span of the entity/event mention nj (nj ∈ E ∪M ) or vice verse. aspan is important as it ij helps ground representation vectors of event/entity mentions to the contextual information in D. Syntax-based Edges: We expect the dependency trees of the sentences in D to provide beneficial information to connect the nodes in N for effective representation learning in ECR. For example, dependency trees have been used to retrieve important context words between an event mentions and their arguments in prior work (Li et al., 2013; Veyseh et al., 2020a,b). To this end, we propose to employ the dependency relations/connections between the words in D to obtain a syntax-based interaction score adep ij for each pair of nodes ni and nj in N , serving as an additional input for aij . In particular, by inheriting the graph structures of the dependency trees of the sentences in D, we set adep ij to 1 if ni and nj are two words in the same sentence (i.e., ni , nj ∈ D) and there is an edge between them in the corresponding dependency tree1 , and 0 otherwise. Semantic-based Edges: This information leverages the semantic similarity of the nodes in N t"
2021.acl-long.374,2020.findings-emnlp.326,1,0.77486,"ij ij only set to 1 (i.e., 0 otherwise) if ni is a word (ni ∈ D) in the span of the entity/event mention nj (nj ∈ E ∪M ) or vice verse. aspan is important as it ij helps ground representation vectors of event/entity mentions to the contextual information in D. Syntax-based Edges: We expect the dependency trees of the sentences in D to provide beneficial information to connect the nodes in N for effective representation learning in ECR. For example, dependency trees have been used to retrieve important context words between an event mentions and their arguments in prior work (Li et al., 2013; Veyseh et al., 2020a,b). To this end, we propose to employ the dependency relations/connections between the words in D to obtain a syntax-based interaction score adep ij for each pair of nodes ni and nj in N , serving as an additional input for aij . In particular, by inheriting the graph structures of the dependency trees of the sentences in D, we set adep ij to 1 if ni and nj are two words in the same sentence (i.e., ni , nj ∈ D) and there is an edge between them in the corresponding dependency tree1 , and 0 otherwise. Semantic-based Edges: This information leverages the semantic similarity of the nodes in N t"
2021.acl-long.490,P19-1470,0,0.0657238,"Missing"
2021.acl-long.490,W06-0901,0,0.542316,"hrases that evoke events in text (i.e., event triggers). For instance, in the sentence “The organization donated 2 million dollars to humanitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-"
2021.acl-long.490,C18-1075,0,0.0662701,"d deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Araki and Mitamura, 2018) techniques. The common strategy in these methods is to exploit unlabeled text data that are rich in event mentions to aid the expansion of training data for ED. In this work, we explore a novel approach for training data expansion in ED by leveraging the existing pre-trained language model GPT-2 (Radford et al., 2019) to automatically generate training data for models. Motivated by the promising performance of GPT models for text generation, we expect our approach to produce effective data for ED in different domains. Specifically, we aim to fine-tune GPT-2 on existing training datasets so it"
2021.acl-long.490,P15-1017,0,0.828899,"lion dollars to humanitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Araki and Mitamura, 2018) techniques. The common strategy in these me"
2021.acl-long.490,I17-1036,0,0.0277904,"Missing"
2021.acl-long.490,2020.acl-main.718,0,0.0271263,"Missing"
2021.acl-long.490,N18-2058,0,0.0131448,"., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi-supervised (Liao and Grishman, 2010a; Huang and Riloff, 2012; Ferguson et al., 2018), distantly supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Zeng et al., 2017; Araki and Mitamura, 2018), and few/zeroshot (Huang et al., 2018; Lai et al., 2020a,b) learn6278 ing. In this work, we propose a novel method to augment training data for ED by exploiting the powerful language model GPT-2 to automatically generate new samples. Leveraging GPT-2 for augmenting training data has also been studied for other NLP tasks recently (e.g., relation extraction, commonsense reasoning) (Papanikolaou and Pierleoni, 2020; Zhang et al., 2020a; Yang et al., 2020; Madaan et al., 2020; Bosselut"
2021.acl-long.490,P11-1113,0,0.12926,"l data O. The results are shown in Table 7. According to this table, the highest performance of the proposed model is achieved when the numbers of the generated and original data are equal. More specifically, decreasing the number of generated samples potentially limits the benefits of data augmentation. On the other hand, increasing the size of generated data might introduces extensive noises and become harmful to the ED models. 4 Related Work Early methods for ED have employed featurebased techniques (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi-supervised (Liao and Grishman, 2010a; Huang an"
2021.acl-long.490,P16-1025,0,0.118895,"r ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Araki and Mitamura, 2018) techniques. The common strategy in these methods is to exploit unlabeled text data that are rich in event mentions to aid the expansion of training data for ED. In this work, we explore a novel approach for training data expansion in ED by leveraging the existing pre-trained language model GPT-2 (Radford et al., 2019) to automatically generate training data for models. Motivated by the promising performance of GPT models for text generation, we expect our approach to produce eff"
2021.acl-long.490,P10-1081,0,0.78252,"evoke events in text (i.e., event triggers). For instance, in the sentence “The organization donated 2 million dollars to humanitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al.,"
2021.acl-long.490,P18-1201,0,0.0737794,"Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi-supervised (Liao and Grishman, 2010a; Huang and Riloff, 2012; Ferguson et al., 2018), distantly supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Zeng et al., 2017; Araki and Mitamura, 2018), and few/zeroshot (Huang et al., 2018; Lai et al., 2020a,b) learn6278 ing. In this work, we propose a novel method to augment training data for ED by exploiting the powerful language model GPT-2 to automatically generate new samples. Leveraging GPT-2 for augmenting training data has also been studied for other NLP tasks recently (e.g., relation extraction, commonsense reasoning) (Papanikolaou and Pierleoni, 2020; Zhang et al., 2020a; Yang et al., 2020; Madaan et al., 2020; Bosselut et al., 2019; Kumar et al., 2020; AnabyTavor et al., 2020; Peng et al., 2020). However, none of those works has explored GPT-2 for ED. In addition, ex"
2021.acl-long.490,E12-1029,0,0.026607,"l., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi-supervised (Liao and Grishman, 2010a; Huang and Riloff, 2012; Ferguson et al., 2018), distantly supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Zeng et al., 2017; Araki and Mitamura, 2018), and few/zeroshot (Huang et al., 2018; Lai et al., 2020a,b) learn6278 ing. In this work, we propose a novel method to augment training data for ED by exploiting the powerful language model GPT-2 to automatically generate new samples. Leveraging GPT-2 for augmenting training data has also been studied for other NLP tasks recently (e.g., relation extraction, commonsense reasoning) (Papanikolaou and Pierleoni, 2020; Zhang et al., 2020a; Yang et al., 2020; Madaa"
2021.acl-long.490,P08-1030,0,0.141432,"generated samples in G (for the ACE 2005 dataset) are combined with the original data O. The results are shown in Table 7. According to this table, the highest performance of the proposed model is achieved when the numbers of the generated and original data are equal. More specifically, decreasing the number of generated samples potentially limits the benefits of data augmentation. On the other hand, increasing the size of generated data might introduces extensive noises and become harmful to the ED models. 4 Related Work Early methods for ED have employed featurebased techniques (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2"
2021.acl-long.490,D17-1163,0,0.0442459,"Missing"
2021.acl-long.490,P17-1164,0,0.03681,"Missing"
2021.acl-long.490,P19-1429,0,0.326408,"Missing"
2021.acl-long.490,2020.lifelongnlp-1.3,0,0.035258,"Missing"
2021.acl-long.490,2020.nuse-1.5,1,0.953836,"ined loss function is used in our framework: L = Lpred + αLaux + βLKL + γLdist , where α, β, and γ are the trade-off parameters. 3 3.1 Experiments Datasets, Baselines & Hyper-Parameters To evaluate the effectiveness of the proposed model, called the GPT-based data augmentation model for ED with OT (GPTEDOT), we conduct experiments on the following ED datasets: ACE 2005 (Walker et al., 2006): This dataset annotates 599 documents for 33 event types that cover different text domains(e.g., news, weblog or conversation documents). We use the same preprocessing script and data split as prior works (Lai et al., 2020c; Tong et al., 2020b) to achieve fair comparisons. In particular, the data split involves 529/30/40 articles for train/dev/test sets respectively. For this dataset, we compare our model with prior state-of-the-art models reported in the recent works (Lai et al., 2020c; Tong et al., 2020b), including BERT-based models such as DMBERT, AD-DMBERT (Wang et al., 2019), DRMM, EKD (Tong et al., 2020b), and GatedGCN (Lai et al., 2020c). CySecED (Man Duc Trong et al., 2020): This dataset provides 8,014 event triggers for 30 event types from 300 articles of the cybersecurity domain (i.e., cybersecurity"
2021.acl-long.490,2020.emnlp-main.435,1,0.936469,"ined loss function is used in our framework: L = Lpred + αLaux + βLKL + γLdist , where α, β, and γ are the trade-off parameters. 3 3.1 Experiments Datasets, Baselines & Hyper-Parameters To evaluate the effectiveness of the proposed model, called the GPT-based data augmentation model for ED with OT (GPTEDOT), we conduct experiments on the following ED datasets: ACE 2005 (Walker et al., 2006): This dataset annotates 599 documents for 33 event types that cover different text domains(e.g., news, weblog or conversation documents). We use the same preprocessing script and data split as prior works (Lai et al., 2020c; Tong et al., 2020b) to achieve fair comparisons. In particular, the data split involves 529/30/40 articles for train/dev/test sets respectively. For this dataset, we compare our model with prior state-of-the-art models reported in the recent works (Lai et al., 2020c; Tong et al., 2020b), including BERT-based models such as DMBERT, AD-DMBERT (Wang et al., 2019), DRMM, EKD (Tong et al., 2020b), and GatedGCN (Lai et al., 2020c). CySecED (Man Duc Trong et al., 2020): This dataset provides 8,014 event triggers for 30 event types from 300 articles of the cybersecurity domain (i.e., cybersecurity"
2021.acl-long.490,P13-1008,0,0.0737663,". According to this table, the highest performance of the proposed model is achieved when the numbers of the generated and original data are equal. More specifically, decreasing the number of generated samples potentially limits the benefits of data augmentation. On the other hand, increasing the size of generated data might introduces extensive noises and become harmful to the ED models. 4 Related Work Early methods for ED have employed featurebased techniques (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi-supervised (Liao and Grishman, 2010a; Huang and Riloff, 2012; Ferguson et al., 2018),"
2021.acl-long.490,C10-1077,0,0.73535,"evoke events in text (i.e., event triggers). For instance, in the sentence “The organization donated 2 million dollars to humanitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al.,"
2021.acl-long.490,P11-1163,0,0.0457237,"ts are shown in Table 7. According to this table, the highest performance of the proposed model is achieved when the numbers of the generated and original data are equal. More specifically, decreasing the number of generated samples potentially limits the benefits of data augmentation. On the other hand, increasing the size of generated data might introduces extensive noises and become harmful to the ED models. 4 Related Work Early methods for ED have employed featurebased techniques (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi-supervised (Liao and Grishman, 2010a; Huang and Riloff, 2012; Ferguso"
2021.acl-long.490,C14-1214,0,0.824617,"., event triggers). For instance, in the sentence “The organization donated 2 million dollars to humanitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al., 2017; Nguyen and Ngu"
2021.acl-long.490,2021.naacl-main.3,1,0.527941,"Missing"
2021.acl-long.490,C18-1193,1,0.892717,"Missing"
2021.acl-long.490,N16-1034,1,0.958134,"anitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Araki and Mitamura, 2018) techniques. The common strategy in these methods is to exploit u"
2021.acl-long.490,W16-1618,1,0.957031,"anitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Araki and Mitamura, 2018) techniques. The common strategy in these methods is to exploit u"
2021.acl-long.490,P15-2060,1,0.915263,"organization donated 2 million dollars to humanitarian helps.”, ED systems should recognize “donated” as an event trigger of type Pay. We differentiate two subtasks in ED, i.e., Event Identification (EI): a binary classification problem to predict if a word in text is an event trigger or not, and Event Classification (EC): a multi-class classification problem to classify event triggers according to predefined event types. Several methods have been introduced for ED, extending from feature-based models (Ahn, 2006; Liao and Grishman, 2010a; Miwa et al., 2014) to advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016c; Sha et al., 2018; Zhang et al., 2020b; Nguyen et al., 2021). Although deep learning models have achieved substantial improvement, their requirement of large training datasets together with the small sizes of existing ED datasets constitutes a major hurdle to build high-performing ED models. Recently, there have been some efforts to enlarge training data for ED models by exploiting unsupervised (Huang et al., 2016; Yuan et al., 2018) or distantly-supervised (Keith et al., 2017; Nguyen and Nguyen, 2018; Araki and Mitamura, 2018) techniques. The common s"
2021.acl-long.490,D09-1016,0,0.196452,"(for the ACE 2005 dataset) are combined with the original data O. The results are shown in Table 7. According to this table, the highest performance of the proposed model is achieved when the numbers of the generated and original data are equal. More specifically, decreasing the number of generated samples potentially limits the benefits of data augmentation. On the other hand, increasing the size of generated data might introduces extensive noises and become harmful to the ED models. 4 Related Work Early methods for ED have employed featurebased techniques (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi"
2021.acl-long.490,2020.acl-main.522,0,0.817703,"is used in our framework: L = Lpred + αLaux + βLKL + γLdist , where α, β, and γ are the trade-off parameters. 3 3.1 Experiments Datasets, Baselines & Hyper-Parameters To evaluate the effectiveness of the proposed model, called the GPT-based data augmentation model for ED with OT (GPTEDOT), we conduct experiments on the following ED datasets: ACE 2005 (Walker et al., 2006): This dataset annotates 599 documents for 33 event types that cover different text domains(e.g., news, weblog or conversation documents). We use the same preprocessing script and data split as prior works (Lai et al., 2020c; Tong et al., 2020b) to achieve fair comparisons. In particular, the data split involves 529/30/40 articles for train/dev/test sets respectively. For this dataset, we compare our model with prior state-of-the-art models reported in the recent works (Lai et al., 2020c; Tong et al., 2020b), including BERT-based models such as DMBERT, AD-DMBERT (Wang et al., 2019), DRMM, EKD (Tong et al., 2020b), and GatedGCN (Lai et al., 2020c). CySecED (Man Duc Trong et al., 2020): This dataset provides 8,014 event triggers for 30 event types from 300 articles of the cybersecurity domain (i.e., cybersecurity events). We follow t"
2021.acl-long.490,N19-1105,0,0.534464,"ACE 2005 (Walker et al., 2006): This dataset annotates 599 documents for 33 event types that cover different text domains(e.g., news, weblog or conversation documents). We use the same preprocessing script and data split as prior works (Lai et al., 2020c; Tong et al., 2020b) to achieve fair comparisons. In particular, the data split involves 529/30/40 articles for train/dev/test sets respectively. For this dataset, we compare our model with prior state-of-the-art models reported in the recent works (Lai et al., 2020c; Tong et al., 2020b), including BERT-based models such as DMBERT, AD-DMBERT (Wang et al., 2019), DRMM, EKD (Tong et al., 2020b), and GatedGCN (Lai et al., 2020c). CySecED (Man Duc Trong et al., 2020): This dataset provides 8,014 event triggers for 30 event types from 300 articles of the cybersecurity domain (i.e., cybersecurity events). We follow the the same pre-processing and data split as the original work (Man Duc Trong et al., 2020) with 240/30/30 documents for the train/dev/test sets. To be consistent with other experiments and facilitate the data generation based on GPT-2, the experiments on Cy6275 SecED are conducted at the sentence level where inputs for models involve sentence"
2021.acl-long.490,D19-1582,0,0.0306493,"Missing"
2021.acl-long.490,N16-1033,0,0.054236,"st performance of the proposed model is achieved when the numbers of the generated and original data are equal. More specifically, decreasing the number of generated samples potentially limits the benefits of data augmentation. On the other hand, increasing the size of generated data might introduces extensive noises and become harmful to the ED models. 4 Related Work Early methods for ED have employed featurebased techniques (Ahn, 2006; Ji and Grishman, 2008; Patwardhan and Riloff, 2009; Liao and Grishman, 2010a,b; Hong et al., 2011; McClosky et al., 2011; Li et al., 2013; Miwa et al., 2014; Yang and Mitchell, 2016). Later, advanced deep learning methods (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a,b; Sha et al., 2018; Zhang et al., 2019; Yang et al., 2019; Nguyen and Nguyen, 2019; Zhang et al., 2020b) have been applied for ED. One challenge for ED research is the limited size of existing datasets that hinder the training of effective models. Prior works have attempted to address this issue via unsupervised (Huang et al., 2016; Yuan et al., 2018), semi-supervised (Liao and Grishman, 2010a; Huang and Riloff, 2012; Ferguson et al., 2018), distantly supervised (Keith et al., 2017; Ngu"
2021.acl-long.490,P19-1522,0,0.4632,"or 30 event types from 300 articles of the cybersecurity domain (i.e., cybersecurity events). We follow the the same pre-processing and data split as the original work (Man Duc Trong et al., 2020) with 240/30/30 documents for the train/dev/test sets. To be consistent with other experiments and facilitate the data generation based on GPT-2, the experiments on Cy6275 SecED are conducted at the sentence level where inputs for models involve sentences. As such, we employ the state-of-the-art sentence-level models reported in (Man Duc Trong et al., 2020), i.e., DMBERT (Wang et al., 2019), BERT-ED (Yang et al., 2019), as the baselines for CySecED. RAMS (Ebner et al., 2020): This dataset annotates 9,124 event triggers for 38 event types. We use the official data split with 3,194, 399, and 400 documents for training, development, and testing respectively for RAMS. We also perform ED at the sentence level in this dataset. For the baselines, we utilize recent state-of-the-art BERT-based models for ED, i.e., DMBERT (Wang et al., 2019) and GatedGCN (Lai et al., 2020c). For a fair comparison, the performance of such baseline models is obtained via their official implementations from the original papers that are"
2021.acl-long.490,2020.findings-emnlp.90,0,0.0444946,"Missing"
2021.eacl-demos.10,N19-1388,0,0.0237634,"ll efficient in memory usage and speed. This is achieved by our novel plugand-play mechanism with Adapters where a multilingual pretrained transformer is shared across pipelines for different languages. Our toolkit along with pretrained models and code are publicly available at: https: //github.com/nlp-uoregon/trankit. A demo website for our toolkit is also available at: http://nlp.uoregon.edu/trankit. Finally, we create a demo video for Trankit at: https://youtu.be/q0KGP3zGjGc. 1 Introduction Many efforts have been devoted to developing multilingual NLP systems to overcome language barriers (Aharoni et al., 2019; Liu et al., 2019a; Taghizadeh and Faili, 2020; Zhu, 2020; Kanayama and Iwamoto, 2020; Nguyen and Nguyen, 2021). A large portion of existing multilingual systems has focused on downstream NLP tasks that critically depend on upstream linguistic features, ranging from basic information such as token and sentence boundaries for raw text to more sophisticated structures such as part-of-speech tags, morphological 1 https://spacy.io/ 80 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, pages 80–90 April 19 - 23, 2021."
2021.eacl-demos.10,2020.lrec-1.500,0,0.0398918,"ay mechanism with Adapters where a multilingual pretrained transformer is shared across pipelines for different languages. Our toolkit along with pretrained models and code are publicly available at: https: //github.com/nlp-uoregon/trankit. A demo website for our toolkit is also available at: http://nlp.uoregon.edu/trankit. Finally, we create a demo video for Trankit at: https://youtu.be/q0KGP3zGjGc. 1 Introduction Many efforts have been devoted to developing multilingual NLP systems to overcome language barriers (Aharoni et al., 2019; Liu et al., 2019a; Taghizadeh and Faili, 2020; Zhu, 2020; Kanayama and Iwamoto, 2020; Nguyen and Nguyen, 2021). A large portion of existing multilingual systems has focused on downstream NLP tasks that critically depend on upstream linguistic features, ranging from basic information such as token and sentence boundaries for raw text to more sophisticated structures such as part-of-speech tags, morphological 1 https://spacy.io/ 80 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, pages 80–90 April 19 - 23, 2021. ©2021 Association for Computational Linguistics Input: Raw Sentence/Document String J"
2021.eacl-demos.10,N19-4010,0,0.0647179,"Missing"
2021.eacl-demos.10,benikova-etal-2014-nosta,0,0.0157028,"h', gpu=True, cache_dir='./cache') doc = '''Hello! This is Trankit.''' # perform all tasks on the input all = p(doc) Figure 4: A function performing all tasks on the input. the XLM-Roberta encoder which is pretrained on those languages. Figure 6 illustrates how to train a token and sentence splitter with TPipeline. Demo Website. A demo website for Trankit to support 90 pretrained pipelines is hosted at: http: //nlp.uoregon.edu/trankit. Figure 7 shows its interface. 5 5.1 Figure 5: Output from Trankit. Some parts are collapsed to improve visualization. System Evaluation der, 2003), GermEval14 (Benikova et al., 2014), OntoNotes (Weischedel et al., 2013), and WikiNER (Nothman et al., 2012). Hyper-parameters for all models and datasets are selected based on the development data in this work. Datasets & Hyper-parameters To achieve a fair comparison, we follow Stanza (Qi et al., 2020) to train and evaluate all the models on the same canonical data splits of 90 Universal Dependencies treebanks v2.5 (UD2.5)3 (Zeman et al., 2019), and 11 public NER datasets provided in the following corpora: AQMAR (Mohit et al., 2012), CoNLL02 (Tjong Kim Sang, 2002), CoNLL03 (Tjong Kim Sang and De Meul5.2 Universal Dependencies"
2021.eacl-demos.10,D19-1279,0,0.125567,"ssing Minh Van Nguyen, Viet Lai, Amir Pouran Ben Veyseh, Thien Huu Nguyen Department of Computer and Information Science University of Oregon, Eugene, Oregon, USA {minhnv,vietl,apouranb,thien}@cs.uoregon.edu Abstract features, and dependency trees of sentences (called fundamental NLP tasks). As such, building effective multilingual systems/pipelines for fundamental upstream NLP tasks to produce such information has the potentials to transform multilingual downstream systems. There have been several NLP toolkits that concerns multilingualism for fundamental NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performan"
2021.eacl-demos.10,Q17-1010,0,0.037994,"ntal NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performance for many languages. However, Stanza and UDPipe’s pipelines for different languages are trained separately and do not share any component, especially the embedding layers that account for most of the model size. This makes their memory usage grow aggressively as pipelines for more languages are simultaneously needed and loaded into the memory (e.g., for language learning apps). Most importantly, none of such toolkits have explored contextualized embeddings from pretrained transformer-based language models that have the potentials to significantly"
2021.eacl-demos.10,P18-1007,0,0.0228726,"ork architecture of an adapter. boxes) are fixed and only the adapter weights of two projection layers and the task-specific weights outside the transformer (for final predictions) are updated. As demonstrated in Figure 1, Trankit involves six components described as follows. Multilingual Encoder with Adapters. This is our core component that is shared across different transformer-based components for different languages of the system. Given an input raw text s, we first split it into substrings by spaces. Afterward, Sentence Piece, a multilingual subword tokenizer (Kudo and Richardson, 2018; Kudo, 2018), is used to further split each substring into wordpieces. By concatenating wordpiece sequences for substrings, we obtain an overall sequence of wordpieces w = [w1 , w2 , . . . , wK ] for s. In the next step, w is fed into the pretrained transformer, which is already integrated with adapters, to obtain the wordpiece representations: l,m xl,m 1:K = Transformer(w1:K ; θAD ) Design and Architecture (2) l,m Here, θAD represents the adapter weights for language l and component m of the system. As such, we have specific adapters in all transformer layers for each component m and language l. Note tha"
2021.eacl-demos.10,D18-2012,0,0.0264541,"rmer layer. Right: the network architecture of an adapter. boxes) are fixed and only the adapter weights of two projection layers and the task-specific weights outside the transformer (for final predictions) are updated. As demonstrated in Figure 1, Trankit involves six components described as follows. Multilingual Encoder with Adapters. This is our core component that is shared across different transformer-based components for different languages of the system. Given an input raw text s, we first split it into substrings by spaces. Afterward, Sentence Piece, a multilingual subword tokenizer (Kudo and Richardson, 2018; Kudo, 2018), is used to further split each substring into wordpieces. By concatenating wordpiece sequences for substrings, we obtain an overall sequence of wordpieces w = [w1 , w2 , . . . , wK ] for s. In the next step, w is fed into the pretrained transformer, which is already integrated with adapters, to obtain the wordpiece representations: l,m xl,m 1:K = Transformer(w1:K ; θAD ) Design and Architecture (2) l,m Here, θAD represents the adapter weights for language l and component m of the system. As such, we have specific adapters in all transformer layers for each component m and languag"
2021.eacl-demos.10,2020.acl-main.747,0,0.432414,"t languages are trained separately and do not share any component, especially the embedding layers that account for most of the model size. This makes their memory usage grow aggressively as pipelines for more languages are simultaneously needed and loaded into the memory (e.g., for language learning apps). Most importantly, none of such toolkits have explored contextualized embeddings from pretrained transformer-based language models that have the potentials to significantly improve the performance of the NLP tasks, as demonstrated in many prior works (Devlin et al., 2019; Liu et al., 2019b; Conneau et al., 2020). In this paper, we introduce Trankit, a multilingual Transformer-based NLP Toolkit that overWe introduce Trankit, a light-weight Transformer-based Toolkit for multilingual Natural Language Processing (NLP). It provides a trainable pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained pipelines for 56 languages. Built on a state-of-the-art pretrained language model, Trankit significantly outperforms prior multilingual NLP pipelines over sentence segmentation, part-of-speech tagging, morphological feature tagging, and dependency parsing while maintaining competitive performan"
2021.eacl-demos.10,D19-1068,0,0.143853,"Missing"
2021.eacl-demos.10,N19-1423,0,0.0559401,"anza and UDPipe’s pipelines for different languages are trained separately and do not share any component, especially the embedding layers that account for most of the model size. This makes their memory usage grow aggressively as pipelines for more languages are simultaneously needed and loaded into the memory (e.g., for language learning apps). Most importantly, none of such toolkits have explored contextualized embeddings from pretrained transformer-based language models that have the potentials to significantly improve the performance of the NLP tasks, as demonstrated in many prior works (Devlin et al., 2019; Liu et al., 2019b; Conneau et al., 2020). In this paper, we introduce Trankit, a multilingual Transformer-based NLP Toolkit that overWe introduce Trankit, a light-weight Transformer-based Toolkit for multilingual Natural Language Processing (NLP). It provides a trainable pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained pipelines for 56 languages. Built on a state-of-the-art pretrained language model, Trankit significantly outperforms prior multilingual NLP pipelines over sentence segmentation, part-of-speech tagging, morphological feature tagging, and dependency parsi"
2021.eacl-demos.10,2021.ccl-1.108,0,0.0638997,"Missing"
2021.eacl-demos.10,P14-5010,0,0.00479643,"Nguyen Department of Computer and Information Science University of Oregon, Eugene, Oregon, USA {minhnv,vietl,apouranb,thien}@cs.uoregon.edu Abstract features, and dependency trees of sentences (called fundamental NLP tasks). As such, building effective multilingual systems/pipelines for fundamental upstream NLP tasks to produce such information has the potentials to transform multilingual downstream systems. There have been several NLP toolkits that concerns multilingualism for fundamental NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performance for many languages. However, Stanza and UDPipe’s pipeline"
2021.eacl-demos.10,2020.emnlp-demos.7,0,0.200879,"Missing"
2021.eacl-demos.10,2020.emnlp-main.617,0,0.0701328,"Missing"
2021.eacl-demos.10,E12-1017,0,0.0185113,"Some parts are collapsed to improve visualization. System Evaluation der, 2003), GermEval14 (Benikova et al., 2014), OntoNotes (Weischedel et al., 2013), and WikiNER (Nothman et al., 2012). Hyper-parameters for all models and datasets are selected based on the development data in this work. Datasets & Hyper-parameters To achieve a fair comparison, we follow Stanza (Qi et al., 2020) to train and evaluate all the models on the same canonical data splits of 90 Universal Dependencies treebanks v2.5 (UD2.5)3 (Zeman et al., 2019), and 11 public NER datasets provided in the following corpora: AQMAR (Mohit et al., 2012), CoNLL02 (Tjong Kim Sang, 2002), CoNLL03 (Tjong Kim Sang and De Meul5.2 Universal Dependencies performance Table 1 compares the performance of Trankit and the latest available versions of other popular toolkits, including Stanza (v1.1.1) with current stateof-the-art performance, UDPipe (v1.2), and spaCy (v2.3) on the UD2.5 test sets. The performance for all systems is obtained using the official scorer 3 We skip 10 treebanks whose languages are not supported by XLM-Roberta. 84 System Trankit (plug-and-play with adapters) Multilingual No-adapters Tokens 99.05 96.69 95.06 Sents. 95.12 88.95 89."
2021.eacl-demos.10,2020.acl-demos.14,0,0.28296,"ersity of Oregon, Eugene, Oregon, USA {minhnv,vietl,apouranb,thien}@cs.uoregon.edu Abstract features, and dependency trees of sentences (called fundamental NLP tasks). As such, building effective multilingual systems/pipelines for fundamental upstream NLP tasks to produce such information has the potentials to transform multilingual downstream systems. There have been several NLP toolkits that concerns multilingualism for fundamental NLP tasks, featuring spaCy1 , UDify (Kondratyuk and Straka, 2019), Flair (Akbik et al., 2019), CoreNLP (Manning et al., 2014), UDPipe (Straka, 2018), and Stanza (Qi et al., 2020). However, these toolkits have their own limitations. spaCy is designed to focus on speed, thus it needs to sacrifice the performance. UDify and Flair cannot process raw text as they depend on external tokenizers. CoreNLP supports raw text, but it does not offer state-ofthe-art performance. UDPipe and Stanza are the recent toolkits that leverage word embeddings, i.e., word2vec (Mikolov et al., 2013) and fastText (Bojanowski et al., 2017), to deliver current state-ofthe-art performance for many languages. However, Stanza and UDPipe’s pipelines for different languages are trained separately and"
2021.eacl-demos.10,2019.nsurl-1.4,0,0.0901258,"Missing"
2021.eacl-demos.10,2020.findings-emnlp.92,0,0.0355468,"Missing"
2021.eacl-demos.10,2021.wanlp-1.27,1,0.682957,"Missing"
2021.eacl-demos.10,P19-1452,0,0.0317287,"component, the corresponding trained adapter and task-specific weights are activated and plugged into the pipeline to process the input. This mechanism not only solves the memory problem but also substantially reduces the training time. Add & Norm Adapter FF Up Add & Norm Feed-forward FF Down Adapter 2 Add & Norm Related Work Multi-Head Attention There have been works using pre-trained transformers to build models for character-based word segmentation for Chinese (Yang, 2019; Tian et al., 2020; Che et al., 2020); POS tagging for Dutch, English, Chinese, and Vietnamese (de Vries et al., 2019; Tenney et al., 2019; Tian et al., 2020; Che et al., 2020; Nguyen and Nguyen, 2020); morphological feature tagging for Estonian and Persian (Kittask et al., 2020; Mohseni and Tebbifakhr, 2019); and dependency parsing for English and Chinese (Tenney et al., 2019; Che et al., 2020). However, all of these works are only developed for some specific language, thus potentially unable to support and scale to the multilingual setting. Some works have designed multilingual transformer-based systems via multilingual training on the combined data of different languages (Tsai et al., 2019; Kondratyuk and Straka, 2019; ¨ un e"
2021.eacl-demos.10,2020.lrec-1.497,0,0.0620223,"Missing"
2021.eacl-demos.10,2020.acl-main.735,0,0.0134215,"rks well for 56 languages. Figure 1 presents the overall architecture of Trankit pipeline that features three novel 81 component, the corresponding trained adapter and task-specific weights are activated and plugged into the pipeline to process the input. This mechanism not only solves the memory problem but also substantially reduces the training time. Add & Norm Adapter FF Up Add & Norm Feed-forward FF Down Adapter 2 Add & Norm Related Work Multi-Head Attention There have been works using pre-trained transformers to build models for character-based word segmentation for Chinese (Yang, 2019; Tian et al., 2020; Che et al., 2020); POS tagging for Dutch, English, Chinese, and Vietnamese (de Vries et al., 2019; Tenney et al., 2019; Tian et al., 2020; Che et al., 2020; Nguyen and Nguyen, 2020); morphological feature tagging for Estonian and Persian (Kittask et al., 2020; Mohseni and Tebbifakhr, 2019); and dependency parsing for English and Chinese (Tenney et al., 2019; Che et al., 2020). However, all of these works are only developed for some specific language, thus potentially unable to support and scale to the multilingual setting. Some works have designed multilingual transformer-based systems via m"
2021.eacl-demos.10,W02-2024,0,0.249791,"alization. System Evaluation der, 2003), GermEval14 (Benikova et al., 2014), OntoNotes (Weischedel et al., 2013), and WikiNER (Nothman et al., 2012). Hyper-parameters for all models and datasets are selected based on the development data in this work. Datasets & Hyper-parameters To achieve a fair comparison, we follow Stanza (Qi et al., 2020) to train and evaluate all the models on the same canonical data splits of 90 Universal Dependencies treebanks v2.5 (UD2.5)3 (Zeman et al., 2019), and 11 public NER datasets provided in the following corpora: AQMAR (Mohit et al., 2012), CoNLL02 (Tjong Kim Sang, 2002), CoNLL03 (Tjong Kim Sang and De Meul5.2 Universal Dependencies performance Table 1 compares the performance of Trankit and the latest available versions of other popular toolkits, including Stanza (v1.1.1) with current stateof-the-art performance, UDPipe (v1.2), and spaCy (v2.3) on the UD2.5 test sets. The performance for all systems is obtained using the official scorer 3 We skip 10 treebanks whose languages are not supported by XLM-Roberta. 84 System Trankit (plug-and-play with adapters) Multilingual No-adapters Tokens 99.05 96.69 95.06 Sents. 95.12 88.95 89.57 Words 98.96 96.35 94.08 UPOS"
2021.eacl-demos.10,W19-4302,0,0.04269,"Missing"
2021.eacl-demos.10,W03-0419,0,0.389165,"Missing"
2021.eacl-demos.10,2020.emnlp-main.180,0,0.0863549,"Missing"
2021.eacl-demos.20,C18-1221,0,0.0808659,"on and disambiguation system Evaluation This section provides more insight into the performance of the proposed acronym identification and disambiguation models. To evaluate the performance of the models in comparison with other state-of-the-art AI and AD models, we report the performance of the proposed models on SciAI and SciAD benchmark datasets (Pouran Ben Veyseh et al., 2020d). We also compare the performance of the proposed model with the baselines provided in the recent work (Pouran Ben Veyseh et al., 2020d). More specifically, on SciAI, we compare our model with rule-based models NOA (Charbonnier and Wartena, 2018), ADE (Li et al., 2018) and UAD (Ciosici et al., 2019); and also the feature-based models BIOADI (Kuo et al., 2009) and LNCRF (Liu et al., 2017); and finally the SOTA deep model LSTM-CRF (Pouran Ben Veyseh et al., 2020d). For evaluation metrics, following prior work, we report precision, recall, and F1 score for the acronym and long-form prediction and also their macro-averaged F1 score. The results are shown in Table 2. This table shows that our model outperforms both rulebased and more advanced feature-based or deep learning models. More interestingly, while the proposed model has comparable"
2021.eacl-demos.20,C18-2001,0,0.215514,"orks are not capable to expand all acronyms of a domain or acronyms in other domains other than the one used in the training set. Although in the recent work (Wen et al., 2020), authors proposed a big dataset for acronym disambiguation in the medical domain with more than 14 million samples, it is still limited to a specific domain (i.e., medical domain). Another limitation in prior works is that they do not provide a unified system capable of performing both tasks in various domains and to be publicly available. To our knowledge, the only exiting web-based system for AI and AD is proposed by Ciosici and Assent (2018). For acronym identification, this system employs the rule-based model introduced by (Schwartz and Hearst, 2002). To handle corner cases, they add extra rules in addition to Schwartz’s rules in their system. Unfortunately, they do not provide detailed information about these corner cases and extra rules or any evaluation to assess the performance of the model. For acronym disambiguation, they resort to a statistical model in which a pre-computed vector representation for each candidate long-form is employed to compute the similarity between candidate long-form with the context of the ambiguous"
2021.eacl-demos.20,W19-5010,0,0.0207905,"odels. Specifically, we compare the model with non-deep learning models including most frequent (MF) meaning (Pouran Ben Veyseh et al., 2020d), feature-based model (i.e., ADE (Li et al., 2018)), and deep learning models including NOA (Charbonnier and Wartena, 2018), UAD (Ciosici et al., 2019), BEM (Blevins 164 Model MF ADE NOA UAD BEM DECBAE GAD MadDog P 89.03 86.74 78.14 89.01 86.75 88.67 89.27 92.27 R 42.2 43.25 35.06 70.08 35.94 74.32 76.66 85.01 F1 57.26 57.72 48.40 78.37 50.82 80.86 81.90 88.49 Table 3: Performance of models for acronym disambiguation (AD) and Zettlemoyer, 2020), DECBAE (Jin et al., 2019) and GAD (Pouran Ben Veyseh et al., 2020d). The results are shown in Table 3. This table demonstrates the effectiveness of the proposed model compared with the baselines. Our hypothesis for the higher performance of the proposed model is the massive number of training examples for all acronyms which results in low generalization error. 4 Related Work Acronym identification (AI) and acronym disambiguation (AD) are two well-known tasks with several prior works in the past two decades. For AI, both rule-based models (Park and Byrd, 2001; Wren and Garner, 2002; Schwartz and Hearst, 2002; Adar, 200"
2021.eacl-demos.20,W16-6107,0,0.0211405,"esults are shown in Table 3. This table demonstrates the effectiveness of the proposed model compared with the baselines. Our hypothesis for the higher performance of the proposed model is the massive number of training examples for all acronyms which results in low generalization error. 4 Related Work Acronym identification (AI) and acronym disambiguation (AD) are two well-known tasks with several prior works in the past two decades. For AI, both rule-based models (Park and Byrd, 2001; Wren and Garner, 2002; Schwartz and Hearst, 2002; Adar, 2004; Nadeau and Turney, 2005; Ao and Takagi, 2005; Kirchhoff and Turner, 2016) and supervised feature-based or deep learning models (Kuo et al., 2009; Liu et al., 2017; Pouran Ben Veyseh et al., 2020d, 2021) are utilized. Due to the higher accuracy of rule-based models, they are dominantly used in the majority of the related works, especially to automatically create acronym dictionary (Ciosici et al., 2019; Li et al., 2018; Charbonnier and Wartena, 2018). However, the existing works prepare a small-size dictionary in a specific domain. In contrast, in this work, we first improve the existing rules for acronym identification, then, we use a diverse acronym glossary in ou"
2021.eacl-demos.20,P18-1121,0,0.0995157,"on This section provides more insight into the performance of the proposed acronym identification and disambiguation models. To evaluate the performance of the models in comparison with other state-of-the-art AI and AD models, we report the performance of the proposed models on SciAI and SciAD benchmark datasets (Pouran Ben Veyseh et al., 2020d). We also compare the performance of the proposed model with the baselines provided in the recent work (Pouran Ben Veyseh et al., 2020d). More specifically, on SciAI, we compare our model with rule-based models NOA (Charbonnier and Wartena, 2018), ADE (Li et al., 2018) and UAD (Ciosici et al., 2019); and also the feature-based models BIOADI (Kuo et al., 2009) and LNCRF (Liu et al., 2017); and finally the SOTA deep model LSTM-CRF (Pouran Ben Veyseh et al., 2020d). For evaluation metrics, following prior work, we report precision, recall, and F1 score for the acronym and long-form prediction and also their macro-averaged F1 score. The results are shown in Table 2. This table shows that our model outperforms both rulebased and more advanced feature-based or deep learning models. More interestingly, while the proposed model has comparable precision with the exi"
2021.eacl-demos.20,W01-0516,0,0.375926,"or acronym disambiguation (AD) and Zettlemoyer, 2020), DECBAE (Jin et al., 2019) and GAD (Pouran Ben Veyseh et al., 2020d). The results are shown in Table 3. This table demonstrates the effectiveness of the proposed model compared with the baselines. Our hypothesis for the higher performance of the proposed model is the massive number of training examples for all acronyms which results in low generalization error. 4 Related Work Acronym identification (AI) and acronym disambiguation (AD) are two well-known tasks with several prior works in the past two decades. For AI, both rule-based models (Park and Byrd, 2001; Wren and Garner, 2002; Schwartz and Hearst, 2002; Adar, 2004; Nadeau and Turney, 2005; Ao and Takagi, 2005; Kirchhoff and Turner, 2016) and supervised feature-based or deep learning models (Kuo et al., 2009; Liu et al., 2017; Pouran Ben Veyseh et al., 2020d, 2021) are utilized. Due to the higher accuracy of rule-based models, they are dominantly used in the majority of the related works, especially to automatically create acronym dictionary (Ciosici et al., 2019; Li et al., 2018; Charbonnier and Wartena, 2018). However, the existing works prepare a small-size dictionary in a specific domain."
2021.eacl-demos.20,2020.emnlp-main.713,0,0.0129276,"the most likely expansion. However, there are some limitations to this previous system. Firstly, it is restricted to the general domain (i.e., Wikipedia) and it covers a limited number of acronyms. Second, it does not provide any analysis and evaluations of the performance of the proposed model. Lastly, it is not publicly available anymore. The proposed MadDog system could be useful for many downstream applications including definition extraction (Pouran Ben Veyseh et al., 2020a; Spala et al., 2020, 2019), information extraction (Pouran Ben Veyseh et al., 2019, 2020b,c) or question answering (Perez et al., 2020) 5 System Deployment MadDog is purely written in Python 3 and could be run as a FLASK (Grinberg, 2018) server. For text toknization, it employs SpaCy 2 (Honnibal and Montani, 2017). Also, the trained acronym expansion model requires PyTorch 1.7 and 64 GB of disk space. Note that all acronyms with their long-forms are encoded in the trained model so they can perform both the dictionary look-up operation and the disambiguation task. Moreover, the trained models could be loaded both on GPU and CPU. 6 Conclusion In this work, we propose a new web-based system for acronym identification and disambi"
2021.eacl-demos.20,2020.acl-main.715,1,0.235653,"r science papers), biomedical (e.g., Medline abstracts), or financial (e.g., financial discussions in Reddit). Note that the proposed system is capable to identify acronyms and their long-forms in all Latin-script languages. More specifically, for acronym identification, we propose a rule-based model by extending the set of rules proposed by (Schwartz and Hearst, 2002). We empirically show that the proposed model outperforms both the previous rule-based model and also the existing state-ofthe-art deep learning models for acronym identification on the recent benchmark dataset SciAI (Pouran Ben Veyseh et al., 2020d). Next, we use a large dataset created from corpora in various domains for acronym disambiguation to train a deep model for this task. Specifically, we employ a sequential deep model to encode the context of the ambiguous acronym and solve the AD task using a feedforward multi-class classifier. We also evaluate the performance of the proposed acronym disambiguation model on the recent benchmark dataset SciAD (Pouran Ben Veyseh et al., 2020d). To summarize, our contributions are: • The first web-based multi-domain acronym identification and disambiguation system • Extensive evaluation of the"
2021.eacl-demos.20,2020.coling-main.292,1,0.739404,"r science papers), biomedical (e.g., Medline abstracts), or financial (e.g., financial discussions in Reddit). Note that the proposed system is capable to identify acronyms and their long-forms in all Latin-script languages. More specifically, for acronym identification, we propose a rule-based model by extending the set of rules proposed by (Schwartz and Hearst, 2002). We empirically show that the proposed model outperforms both the previous rule-based model and also the existing state-ofthe-art deep learning models for acronym identification on the recent benchmark dataset SciAI (Pouran Ben Veyseh et al., 2020d). Next, we use a large dataset created from corpora in various domains for acronym disambiguation to train a deep model for this task. Specifically, we employ a sequential deep model to encode the context of the ambiguous acronym and solve the AD task using a feedforward multi-class classifier. We also evaluate the performance of the proposed acronym disambiguation model on the recent benchmark dataset SciAD (Pouran Ben Veyseh et al., 2020d). To summarize, our contributions are: • The first web-based multi-domain acronym identification and disambiguation system • Extensive evaluation of the"
2021.eacl-demos.20,2020.semeval-1.41,1,0.710258,"onary of acronyms. For AD, unlike our work that trains a deep model, they use word embedding similarity to predict the most likely expansion. However, there are some limitations to this previous system. Firstly, it is restricted to the general domain (i.e., Wikipedia) and it covers a limited number of acronyms. Second, it does not provide any analysis and evaluations of the performance of the proposed model. Lastly, it is not publicly available anymore. The proposed MadDog system could be useful for many downstream applications including definition extraction (Pouran Ben Veyseh et al., 2020a; Spala et al., 2020, 2019), information extraction (Pouran Ben Veyseh et al., 2019, 2020b,c) or question answering (Perez et al., 2020) 5 System Deployment MadDog is purely written in Python 3 and could be run as a FLASK (Grinberg, 2018) server. For text toknization, it employs SpaCy 2 (Honnibal and Montani, 2017). Also, the trained acronym expansion model requires PyTorch 1.7 and 64 GB of disk space. Note that all acronyms with their long-forms are encoded in the trained model so they can perform both the dictionary look-up operation and the disambiguation task. Moreover, the trained models could be loaded both"
2021.eacl-demos.20,W19-4015,1,0.872953,"Missing"
2021.eacl-demos.20,2020.clinicalnlp-1.15,0,0.0245505,"if it has multiple meanings. Despite the progress made on the AI and AD task in the last two decades, there are some limitations in the prior works that prevent achieving a functional system to be used in practice. More specifically, considering the research on the AD task, all of the prior works employ a small-size dataset covering a few hundred to a few thousand long-forms in a specific domain. Therefore, the models trained in these works are not capable to expand all acronyms of a domain or acronyms in other domains other than the one used in the training set. Although in the recent work (Wen et al., 2020), authors proposed a big dataset for acronym disambiguation in the medical domain with more than 14 million samples, it is still limited to a specific domain (i.e., medical domain). Another limitation in prior works is that they do not provide a unified system capable of performing both tasks in various domains and to be publicly available. To our knowledge, the only exiting web-based system for AI and AD is proposed by Ciosici and Assent (2018). For acronym identification, this system employs the rule-based model introduced by (Schwartz and Hearst, 2002). To handle corner cases, they add extr"
2021.eacl-demos.20,W15-3822,0,0.0906585,"er, some feature-based models have been also used for acronym identification (Kuo et al., 2009; Liu et al., 2017). In addition, some of the existing software employs regular expressions for acronym identification in the biomedical domain (Gooch, 2011). Acronym disambiguation is also approached with feature-based models (Wang et al., 2016) or more advanced deep learning meth160 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations, pages 160–167 April 19 - 23, 2021. ©2021 Association for Computational Linguistics ods (Wu et al., 2015; Ciosici et al., 2019). The majority of deep models employ word embeddings to compute the similarity between the candidate longform and the acronym context. In addition to the existing research for AD, there is some web-based software that employ dictionary look-up to expand an acronym to its long-form (ABBREX2018). Note that the methods based on dictionary look-up are not able to disambiguate the acronym if it has multiple meanings. Despite the progress made on the AI and AD task in the last two decades, there are some limitations in the prior works that prevent achieving a functional system"
2021.eacl-main.237,E17-1075,0,0.0234992,"2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant supervision (Ling and Weld, 2012; Abhishek et al., 2017) and manual annotation (Murty et al., 2018; Choi et al., 2018). Notably, (Del Corro et al., 2015) also uses WordNet to establish the fine-grained entity types, applying different entity mention extractors over external corpus. Our work is different as we focus on fine-grained event types using the manually annotated corpus Semcor to generate data. 5 Conclusion We study a new task of FED, featuring 449 finegrained event types in the dataset for ED. A novel method to generate the evaluation dataset for FED is introduced, leveraging manually annotated WSD datasets (i.e., Semcor) and the eventive"
2021.eacl-main.237,W06-0901,0,0.649198,"Missing"
2021.eacl-main.237,C18-1075,0,0.237943,"the large datasets to evaluate the models (e.g., the ACE 2005 and TAC KBP 2015 datasets (Walker et al., 2006; Mitamura et al., 2015)). Unfortunately, a major issue in these existing datasets for ED is that they tend to only focus on a limited set of event types. For example, the popular ACE 2005 dataset is only annotated ∗ Corresponding author. for 33 event subtypes (e.g., Attack, Start-Position, Elect) while the number of events in the TAC KBP dataset (Mitamura et al., 2015) is 38. On the one hand, the limited numbers of types are unable to cover a wide range of possible events in practice (Araki and Mitamura, 2018). On the other hand, the small label sets often amount to the coarse-grained event types in the existing datasets that cannot capture the slightly different nuances (i.e., fine-grained distinction) of the events. For instance, both the words “quit” and “fired” in the two sentences “He decided to quit the job.” and “He was fired due to a policy violation.” (respectively) would be considered as the trigger words of the same event type of End-Position in the ACE 2005 dataset. However, the nuances in these two events are quite different (i.e., in term of the willingness of the job termination) and"
2021.eacl-main.237,P17-1038,0,0.0148862,"mcor for FED. 4 Related Work ED has been studied extensively in the last decade, featuring feature-based models (Ahn, 2006; Ji and Grishman, 2008; Li et al., 2013, 2015), deep learning models (Chen et al., 2015; Nguyen et al., Model WSD-based CNN DMCNN SupAtt GCN MOGANED DMBERT BERT-ED word2vec P R F1 48.8 53.6 51.1 43.7 51.6 47.4 58.5 46.0 51.5 53.7 60.0 56.7 48.6 61.8 54.4 - P 47.2 52.8 56.9 59.5 58.9 55.8 57.7 59.2 BERT R 68.7 69.8 71.5 71.1 71.5 71.2 63.2 72.1 F1 56.0 60.1 63.4 64.8 64.6 62.6 60.3 65.0 Table 3: The performance on the FedSemcor test set. 2016b,a; Nguyen and Grishman, 2016; Chen et al., 2017; Liu et al., 2018; Yan et al., 2019; Ngo et al., 2020; Lai et al., 2020b), and few/zero-shot learning models (Huang et al., 2018; Lai and Nguyen, 2019; Lai et al., 2020a). The rapid development of such models has been facilitated by the availability of the ED datasets in different domains, including the general domain with the popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mita"
2021.eacl-main.237,P15-1017,0,0.504324,"ntroduction Understanding events in text is an important aspect of Natural Language Processing (NLP). Toward this end, Event Detection (ED), a task of Information Extraction (IE), aims to identify event triggers in sentences and classify them into some predefined types of interest. Event triggers represent the most important words (usually single verbs or nominalizations) in the sentences that evoke the events. The current state-of-the-art methods for ED feature the deep learning models where many new network architectures are introduced in the last couple of years (Nguyen and Grishman, 2015; Chen et al., 2015; Liu et al., 2017, 2019a; Lai et al., 2020b). Among others, the rapid development of the deep learning models for ED can be partly attributed to the availability of the large datasets to evaluate the models (e.g., the ACE 2005 and TAC KBP 2015 datasets (Walker et al., 2006; Mitamura et al., 2015)). Unfortunately, a major issue in these existing datasets for ED is that they tend to only focus on a limited set of event types. For example, the popular ACE 2005 dataset is only annotated ∗ Corresponding author. for 33 event subtypes (e.g., Attack, Start-Position, Elect) while the number of events"
2021.eacl-main.237,P18-1009,0,0.114936,"ng datasets that cannot capture the slightly different nuances (i.e., fine-grained distinction) of the events. For instance, both the words “quit” and “fired” in the two sentences “He decided to quit the job.” and “He was fired due to a policy violation.” (respectively) would be considered as the trigger words of the same event type of End-Position in the ACE 2005 dataset. However, the nuances in these two events are quite different (i.e., in term of the willingness of the job termination) and the ability to characterize such subtle distinction would be useful for the downstream applications (Choi et al., 2018). In order to address these problems, we propose to explore the problem of Fine-grained Event Detection (FED) that seeks to solve ED with much larger and finer-grained sets of event types (motivated by the fine-grained entity typing task (Ling and Weld, 2012; Choi et al., 2018)). To our knowledge, this is the first work to explicitly study FED in the literature. A major challenge in this research direction is the creation of the evaluation datasets to enable effective model development and analysis. In particular, it is non-trivial to design a large set of fine-grained event types to be applie"
2021.eacl-main.237,D15-1103,0,0.0303692,"aki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant supervision (Ling and Weld, 2012; Abhishek et al., 2017) and manual annotation (Murty et al., 2018; Choi et al., 2018). Notably, (Del Corro et al., 2015) also uses WordNet to establish the fine-grained entity types, applying different entity mention extractors over external corpus. Our work is different as we focus on fine-grained event types using the manually annotated corpus Semcor to generate data. 5 Conclusion We study a new task of FED, featuring 449 finegrained event types in the dataset for ED. A novel method to generate the evaluation dataset for FED is introduced, leveraging manually annotated WSD datasets (i.e., Semcor) and the eventive synsets in WordNet. We evaluate the state-of-the-art ED models on the new dataset to show the opp"
2021.eacl-main.237,N19-1423,0,0.0187413,"predict the event type for the word. Afterward, we consider the following representative models for ED: CNN (Nguyen and Grishman, 2015), DMCNN (Chen et al., 2015), SupAtt (Liu et al., 2017) (i.e., supervised attention), GCN (Nguyen and Grishman, 2018), and MOGANED (Yan et al., 2019) (i.e., a Multi-Order Graph Convolution model). MOGANED is the state-of-theart model with uncontextualized word embeddings in traditional ED (i.e., on ACE 2005). For these models, we use both the traditional word embeddings word2vec and the recent contextualized word embeddings BERT (i.e., the uncased base model) (Devlin et al., 2019) as the pre-trained word embeddings. For BERT, we further evaluate the ED models in (Wang et al., 2019) (called DMBERT) and (Yang et al., 2019) (called BERT-ED) that have the best-reported performance on ACE 2005 for ED. For the experiments in this work, we re-tune the hyper-parameters of the models on the development set of FedSemcor. In particular, depending on which components each model has, we use the following bounds to search for the hyperparameters: [100, 200, 300, 400, 500] for the dimensionality of the hidden vectors in the layers of all 2748 the feed-forward, BiLSTM, and GCN network"
2021.eacl-main.237,D19-1533,0,0.0441966,"Missing"
2021.eacl-main.237,P18-1201,0,0.017595,"nd Grishman, 2008; Li et al., 2013, 2015), deep learning models (Chen et al., 2015; Nguyen et al., Model WSD-based CNN DMCNN SupAtt GCN MOGANED DMBERT BERT-ED word2vec P R F1 48.8 53.6 51.1 43.7 51.6 47.4 58.5 46.0 51.5 53.7 60.0 56.7 48.6 61.8 54.4 - P 47.2 52.8 56.9 59.5 58.9 55.8 57.7 59.2 BERT R 68.7 69.8 71.5 71.1 71.5 71.2 63.2 72.1 F1 56.0 60.1 63.4 64.8 64.6 62.6 60.3 65.0 Table 3: The performance on the FedSemcor test set. 2016b,a; Nguyen and Grishman, 2016; Chen et al., 2017; Liu et al., 2018; Yan et al., 2019; Ngo et al., 2020; Lai et al., 2020b), and few/zero-shot learning models (Huang et al., 2018; Lai and Nguyen, 2019; Lai et al., 2020a). The rapid development of such models has been facilitated by the availability of the ED datasets in different domains, including the general domain with the popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considere"
2021.eacl-main.237,P08-1030,0,0.0930279,"Missing"
2021.eacl-main.237,E17-2119,0,0.0349108,"Missing"
2021.eacl-main.237,W09-1401,0,0.0987378,"1.2 63.2 72.1 F1 56.0 60.1 63.4 64.8 64.6 62.6 60.3 65.0 Table 3: The performance on the FedSemcor test set. 2016b,a; Nguyen and Grishman, 2016; Chen et al., 2017; Liu et al., 2018; Yan et al., 2019; Ngo et al., 2020; Lai et al., 2020b), and few/zero-shot learning models (Huang et al., 2018; Lai and Nguyen, 2019; Lai et al., 2020a). The rapid development of such models has been facilitated by the availability of the ED datasets in different domains, including the general domain with the popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant"
2021.eacl-main.237,W11-1802,0,0.0642031,"Missing"
2021.eacl-main.237,D19-5532,1,0.806923,"i et al., 2013, 2015), deep learning models (Chen et al., 2015; Nguyen et al., Model WSD-based CNN DMCNN SupAtt GCN MOGANED DMBERT BERT-ED word2vec P R F1 48.8 53.6 51.1 43.7 51.6 47.4 58.5 46.0 51.5 53.7 60.0 56.7 48.6 61.8 54.4 - P 47.2 52.8 56.9 59.5 58.9 55.8 57.7 59.2 BERT R 68.7 69.8 71.5 71.1 71.5 71.2 63.2 72.1 F1 56.0 60.1 63.4 64.8 64.6 62.6 60.3 65.0 Table 3: The performance on the FedSemcor test set. 2016b,a; Nguyen and Grishman, 2016; Chen et al., 2017; Liu et al., 2018; Yan et al., 2019; Ngo et al., 2020; Lai et al., 2020b), and few/zero-shot learning models (Huang et al., 2018; Lai and Nguyen, 2019; Lai et al., 2020a). The rapid development of such models has been facilitated by the availability of the ED datasets in different domains, including the general domain with the popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-gr"
2021.eacl-main.237,2020.emnlp-main.435,1,0.926856,"an important aspect of Natural Language Processing (NLP). Toward this end, Event Detection (ED), a task of Information Extraction (IE), aims to identify event triggers in sentences and classify them into some predefined types of interest. Event triggers represent the most important words (usually single verbs or nominalizations) in the sentences that evoke the events. The current state-of-the-art methods for ED feature the deep learning models where many new network architectures are introduced in the last couple of years (Nguyen and Grishman, 2015; Chen et al., 2015; Liu et al., 2017, 2019a; Lai et al., 2020b). Among others, the rapid development of the deep learning models for ED can be partly attributed to the availability of the large datasets to evaluate the models (e.g., the ACE 2005 and TAC KBP 2015 datasets (Walker et al., 2006; Mitamura et al., 2015)). Unfortunately, a major issue in these existing datasets for ED is that they tend to only focus on a limited set of event types. For example, the popular ACE 2005 dataset is only annotated ∗ Corresponding author. for 33 event subtypes (e.g., Attack, Start-Position, Elect) while the number of events in the TAC KBP dataset (Mitamura et al., 20"
2021.eacl-main.237,P13-1008,0,0.260546,"Missing"
2021.eacl-main.237,W15-4502,1,0.881421,"Missing"
2021.eacl-main.237,D19-1641,0,0.0203637,"P datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant supervision (Ling and Weld, 2012; Abhishek et al., 2017) and manual annotation (Murty et al., 2018; Choi et al., 2018). Notably, (Del Corro et al., 2015) also uses WordNet to establish the fine-grained entity types, applying different entity mention extractors over external corpus. Our work is different as we focus on fine-grained event types using the manually annotated corpus Semcor to generate data. 5 Conclusion We study a new task of FED, featuring 449 finegrained event types in the dataset for ED. A novel"
2021.eacl-main.237,P17-1164,0,0.0920207,"anding events in text is an important aspect of Natural Language Processing (NLP). Toward this end, Event Detection (ED), a task of Information Extraction (IE), aims to identify event triggers in sentences and classify them into some predefined types of interest. Event triggers represent the most important words (usually single verbs or nominalizations) in the sentences that evoke the events. The current state-of-the-art methods for ED feature the deep learning models where many new network architectures are introduced in the last couple of years (Nguyen and Grishman, 2015; Chen et al., 2015; Liu et al., 2017, 2019a; Lai et al., 2020b). Among others, the rapid development of the deep learning models for ED can be partly attributed to the availability of the large datasets to evaluate the models (e.g., the ACE 2005 and TAC KBP 2015 datasets (Walker et al., 2006; Mitamura et al., 2015)). Unfortunately, a major issue in these existing datasets for ED is that they tend to only focus on a limited set of event types. For example, the popular ACE 2005 dataset is only annotated ∗ Corresponding author. for 33 event subtypes (e.g., Attack, Start-Position, Elect) while the number of events in the TAC KBP dat"
2021.eacl-main.237,P19-1276,0,0.0152572,", 2018; Yan et al., 2019; Ngo et al., 2020; Lai et al., 2020b), and few/zero-shot learning models (Huang et al., 2018; Lai and Nguyen, 2019; Lai et al., 2020a). The rapid development of such models has been facilitated by the availability of the ED datasets in different domains, including the general domain with the popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant supervision (Ling and Weld, 2012; Abhishek et al., 2017) and manual annotation (Murty et al., 2018; Choi et al., 2018). Notably, (Del Corro et al., 2015) also uses WordNet to"
2021.eacl-main.237,H94-1046,0,0.0698358,"fine-grained event types to evaluate the FED models. Our proposed procedure to achieve this goal involves two major steps. First, we identify the eventive synsets/senses in WordNet 3.0 (Miller, 1995) and group them into classes with similar eventive meanings. These classes would serve as the fine-grained event types in the resulting FED dataset. As the result, we obtain a mapping from the set of WordNet synsets to the set of the fine-grained event types for our problem (some WordNet synsets might not be mapped to any event type in our case). Afterward, we leverage the Semcor dataset for WSD (Miller et al., 1994) and map the synsets annotated for the words in this dataset into the event types in our setting. This conversion process produces a dataset whose words are assigned with the fine-grained event types in our FED problem. As the Semcor dataset is manually annotated, the resulting FED dataset would be large and have high quality if the synset-event type mapping is constructed well. In particular, for eventive synset/sense identification, we first start with nouns. Following (Araki and Mitamura, 2018), we assume that any synset for a noun subsumed by one of the three following synsets via the Word"
2021.eacl-main.237,P18-1010,0,0.0169073,"; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant supervision (Ling and Weld, 2012; Abhishek et al., 2017) and manual annotation (Murty et al., 2018; Choi et al., 2018). Notably, (Del Corro et al., 2015) also uses WordNet to establish the fine-grained entity types, applying different entity mention extractors over external corpus. Our work is different as we focus on fine-grained event types using the manually annotated corpus Semcor to generate data. 5 Conclusion We study a new task of FED, featuring 449 finegrained event types in the dataset for ED. A novel method to generate the evaluation dataset for FED is introduced, leveraging manually annotated WSD datasets (i.e., Semcor) and the eventive synsets in WordNet. We evaluate the state-"
2021.eacl-main.237,N16-1034,1,0.940596,"Missing"
2021.eacl-main.237,P15-2060,1,0.926411,"ch effort in this area. 1 Introduction Understanding events in text is an important aspect of Natural Language Processing (NLP). Toward this end, Event Detection (ED), a task of Information Extraction (IE), aims to identify event triggers in sentences and classify them into some predefined types of interest. Event triggers represent the most important words (usually single verbs or nominalizations) in the sentences that evoke the events. The current state-of-the-art methods for ED feature the deep learning models where many new network architectures are introduced in the last couple of years (Nguyen and Grishman, 2015; Chen et al., 2015; Liu et al., 2017, 2019a; Lai et al., 2020b). Among others, the rapid development of the deep learning models for ED can be partly attributed to the availability of the large datasets to evaluate the models (e.g., the ACE 2005 and TAC KBP 2015 datasets (Walker et al., 2006; Mitamura et al., 2015)). Unfortunately, a major issue in these existing datasets for ED is that they tend to only focus on a limited set of event types. For example, the popular ACE 2005 dataset is only annotated ∗ Corresponding author. for 33 event subtypes (e.g., Attack, Start-Position, Elect) while th"
2021.eacl-main.237,D16-1085,1,0.83415,"sion from Semcor into FedSemcor for FED. 4 Related Work ED has been studied extensively in the last decade, featuring feature-based models (Ahn, 2006; Ji and Grishman, 2008; Li et al., 2013, 2015), deep learning models (Chen et al., 2015; Nguyen et al., Model WSD-based CNN DMCNN SupAtt GCN MOGANED DMBERT BERT-ED word2vec P R F1 48.8 53.6 51.1 43.7 51.6 47.4 58.5 46.0 51.5 53.7 60.0 56.7 48.6 61.8 54.4 - P 47.2 52.8 56.9 59.5 58.9 55.8 57.7 59.2 BERT R 68.7 69.8 71.5 71.1 71.5 71.2 63.2 72.1 F1 56.0 60.1 63.4 64.8 64.6 62.6 60.3 65.0 Table 3: The performance on the FedSemcor test set. 2016b,a; Nguyen and Grishman, 2016; Chen et al., 2017; Liu et al., 2018; Yan et al., 2019; Ngo et al., 2020; Lai et al., 2020b), and few/zero-shot learning models (Huang et al., 2018; Lai and Nguyen, 2019; Lai et al., 2020a). The rapid development of such models has been facilitated by the availability of the ED datasets in different domains, including the general domain with the popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open dom"
2021.eacl-main.237,W16-1313,0,0.0162298,"popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant supervision (Ling and Weld, 2012; Abhishek et al., 2017) and manual annotation (Murty et al., 2018; Choi et al., 2018). Notably, (Del Corro et al., 2015) also uses WordNet to establish the fine-grained entity types, applying different entity mention extractors over external corpus. Our work is different as we focus on fine-grained event types using the manually annotated corpus Semcor to generate data. 5 Conclusion We study a new task of FED, featuring 449 finegrained event types in the data"
2021.eacl-main.237,P19-1353,0,0.0129911,"64.6 62.6 60.3 65.0 Table 3: The performance on the FedSemcor test set. 2016b,a; Nguyen and Grishman, 2016; Chen et al., 2017; Liu et al., 2018; Yan et al., 2019; Ngo et al., 2020; Lai et al., 2020b), and few/zero-shot learning models (Huang et al., 2018; Lai and Nguyen, 2019; Lai et al., 2020a). The rapid development of such models has been facilitated by the availability of the ED datasets in different domains, including the general domain with the popular ACE and TAC KBP datasets (Walker et al., 2006; Mitamura et al., 2015, 2016), the biomedical domain (Kim et al., 2009, 2011), literature (Sims et al., 2019), cybersecurity (Satyapanich et al., 2020; Man Duc Trong et al., 2020), and the open domain (Araki and Mitamura, 2018; Liu et al., 2019b). However, these datasets only involve a small number of event types and none of them has considered ED with many fine-grained event types as we do. Our FED task is also related to fine-grained entity typing that aims to classify entity mentions into a fine-grained set of types (Karn et al., 2017; Shimaoka et al., 2016; Lin and Ji, 2019). The techniques to generate datasets for fine-grained entity typing include distant supervision (Ling and Weld, 2012; Abhis"
2021.eacl-main.237,N19-1105,0,0.106171,"CNN (Nguyen and Grishman, 2015), DMCNN (Chen et al., 2015), SupAtt (Liu et al., 2017) (i.e., supervised attention), GCN (Nguyen and Grishman, 2018), and MOGANED (Yan et al., 2019) (i.e., a Multi-Order Graph Convolution model). MOGANED is the state-of-theart model with uncontextualized word embeddings in traditional ED (i.e., on ACE 2005). For these models, we use both the traditional word embeddings word2vec and the recent contextualized word embeddings BERT (i.e., the uncased base model) (Devlin et al., 2019) as the pre-trained word embeddings. For BERT, we further evaluate the ED models in (Wang et al., 2019) (called DMBERT) and (Yang et al., 2019) (called BERT-ED) that have the best-reported performance on ACE 2005 for ED. For the experiments in this work, we re-tune the hyper-parameters of the models on the development set of FedSemcor. In particular, depending on which components each model has, we use the following bounds to search for the hyperparameters: [100, 200, 300, 400, 500] for the dimensionality of the hidden vectors in the layers of all 2748 the feed-forward, BiLSTM, and GCN networks, [1, 2, 3] for the numbers of layers for BiLSTM and GCN, [16, 32, 64] for the mini-batch size, [1e-5,"
2021.eacl-main.237,D19-1582,0,0.0734698,"nt and test data using the 6:2:2 ratio over the entire dataset. Table 2 presents the statistics about these data portions. Note that similar to some prior ED work (Nguyen and Grishman, 2015; Chen et al., 2015), our FED problem is formulated as a word classification problem where given a word in an input sentence, the models need to predict the event type for the word. Afterward, we consider the following representative models for ED: CNN (Nguyen and Grishman, 2015), DMCNN (Chen et al., 2015), SupAtt (Liu et al., 2017) (i.e., supervised attention), GCN (Nguyen and Grishman, 2018), and MOGANED (Yan et al., 2019) (i.e., a Multi-Order Graph Convolution model). MOGANED is the state-of-theart model with uncontextualized word embeddings in traditional ED (i.e., on ACE 2005). For these models, we use both the traditional word embeddings word2vec and the recent contextualized word embeddings BERT (i.e., the uncased base model) (Devlin et al., 2019) as the pre-trained word embeddings. For BERT, we further evaluate the ED models in (Wang et al., 2019) (called DMBERT) and (Yang et al., 2019) (called BERT-ED) that have the best-reported performance on ACE 2005 for ED. For the experiments in this work, we re-tun"
2021.eacl-main.237,P19-1522,0,0.120719,"Chen et al., 2015), SupAtt (Liu et al., 2017) (i.e., supervised attention), GCN (Nguyen and Grishman, 2018), and MOGANED (Yan et al., 2019) (i.e., a Multi-Order Graph Convolution model). MOGANED is the state-of-theart model with uncontextualized word embeddings in traditional ED (i.e., on ACE 2005). For these models, we use both the traditional word embeddings word2vec and the recent contextualized word embeddings BERT (i.e., the uncased base model) (Devlin et al., 2019) as the pre-trained word embeddings. For BERT, we further evaluate the ED models in (Wang et al., 2019) (called DMBERT) and (Yang et al., 2019) (called BERT-ED) that have the best-reported performance on ACE 2005 for ED. For the experiments in this work, we re-tune the hyper-parameters of the models on the development set of FedSemcor. In particular, depending on which components each model has, we use the following bounds to search for the hyperparameters: [100, 200, 300, 400, 500] for the dimensionality of the hidden vectors in the layers of all 2748 the feed-forward, BiLSTM, and GCN networks, [1, 2, 3] for the numbers of layers for BiLSTM and GCN, [16, 32, 64] for the mini-batch size, [1e-5, 1e-4, 1e-3, 1e-2, 1e-1] for the learnin"
2021.emnlp-main.427,W06-0901,0,0.124594,"produces more accurate predictions than Proto, as 5273 shown on the diagonal. Second, ProAcT involves remarkably more correct predictions for negative examples than Proto. In the mean time, it generates significantly lower number of errors in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer v"
2021.emnlp-main.427,P17-1038,0,0.0137312,"inly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, prior FSL work has mostly relied on Prototypical network (Lai et al., 2020b; Deng et al., 2020). However, these models do not explore cross-task modeling as we do. 5 Conclusion In this paper, we propose to exploit the relationship between training tasks for few-sho"
2021.emnlp-main.427,P15-1017,0,0.0198,"tes significantly lower number of errors in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et"
2021.emnlp-main.427,P16-2011,0,0.0167668,"in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, prior FSL work has m"
2021.emnlp-main.427,D18-1514,0,0.0275321,", 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, prior FSL work has mostly relied on Prototypical network (Lai et al., 2020b; Deng et al., 2020). However, these models do not explore cross-task modeling as we do. 5 Conclusion In this paper, we propose to exploit the relationship between training tasks for few-shot learning event detection. We compute prototypes based on cross-task modeling and present a regularization to enforce prediction consistency of classifiers across tasks. The experiment results show that exploiting cross-task relation can alleviate the poor sampling and outliers in the support set for FSL"
2021.emnlp-main.427,P11-1113,0,0.0350367,"wn on the diagonal. Second, ProAcT involves remarkably more correct predictions for negative examples than Proto. In the mean time, it generates significantly lower number of errors in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017;"
2021.emnlp-main.427,P18-1201,0,0.0136827,"ervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, prior FSL work has mostly relied on Prototypical network (Lai et al., 2020b; Deng et al., 2020). However, these models do not explore cross-task modeling as we do. 5 Conclusion In this paper, we propose to exploit the relationship between training tasks for few-shot learning event det"
2021.emnlp-main.427,2020.nuse-1.5,1,0.896678,"rtunately, the sample ducing cross-task prototypes. We further propose to enforce prediction consistency among size is so small (K ∈ [1, 10]) that the FSL models classifiers across tasks to make the model more might suffer from sample bias, thus hindering the robust to outliers. Our extensive experiment generalization to novel event types. shows a consistent improvement on three fewPrototypical network is a popular metric-based shot learning datasets. The findings suggest few-shot learning model (Snell et al., 2017) that has that our model is more robust when labeled been explored for FSL ED (Lai et al., 2020b; Deng data of novel event types is limited. The source code is available at http://github.com/ et al., 2020). It introduces a prototype vector for laiviet/fsl-proact. each event type by averaging the representations of the instances of that type. A non-parametric classi1 Introduction fier then predicts the event type of a query instance In Information Extraction, Event Detection (ED) based on its distances from the prototypes (Snell et al., 2017). Hence, an outlier in the support set is an important task that aims to identify and might significantly change the prototypes and flip classify ev"
2021.emnlp-main.427,2020.emnlp-main.435,1,0.741589,"rtunately, the sample ducing cross-task prototypes. We further propose to enforce prediction consistency among size is so small (K ∈ [1, 10]) that the FSL models classifiers across tasks to make the model more might suffer from sample bias, thus hindering the robust to outliers. Our extensive experiment generalization to novel event types. shows a consistent improvement on three fewPrototypical network is a popular metric-based shot learning datasets. The findings suggest few-shot learning model (Snell et al., 2017) that has that our model is more robust when labeled been explored for FSL ED (Lai et al., 2020b; Deng data of novel event types is limited. The source code is available at http://github.com/ et al., 2020). It introduces a prototype vector for laiviet/fsl-proact. each event type by averaging the representations of the instances of that type. A non-parametric classi1 Introduction fier then predicts the event type of a query instance In Information Extraction, Event Detection (ED) based on its distances from the prototypes (Snell et al., 2017). Hence, an outlier in the support set is an important task that aims to identify and might significantly change the prototypes and flip classify ev"
2021.emnlp-main.427,P10-1081,0,0.0460022,"s than Proto, as 5273 shown on the diagonal. Second, ProAcT involves remarkably more correct predictions for negative examples than Proto. In the mean time, it generates significantly lower number of errors in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017;"
2021.emnlp-main.427,R11-1002,0,0.0279005,"oise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, prior FSL work has mostly relied on Prototypical network (Lai et al., 2020b; Deng et al., 2020). However, these models do not explore cross-task modeling as we do. 5 Conclusion In this paper, we pro"
2021.emnlp-main.427,2021.naacl-main.3,1,0.815166,"Missing"
2021.emnlp-main.427,P08-1030,0,0.0744155,"ore accurate predictions than Proto, as 5273 shown on the diagonal. Second, ProAcT involves remarkably more correct predictions for negative examples than Proto. In the mean time, it generates significantly lower number of errors in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al.,"
2021.emnlp-main.427,N16-1034,1,0.819061,"ower number of errors in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, p"
2021.emnlp-main.427,W16-1618,1,0.830547,"ower number of errors in both false positive and false negative related to the NULL class, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, p"
2021.emnlp-main.427,2020.acl-main.522,0,0.0251637,"eme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, prior FSL work has mostly relied on Prototypical network (Lai et al., 2020b; Deng et al., 2020). However, these models do not explore cross-task modeling as we do. 5 Conclusion In this paper, we propose to exploit the relationship between training tasks for few-shot learning event detection. We compute"
2021.emnlp-main.427,2021.acl-long.490,1,0.676738,"ass, i.e. Other class in Figure 1, suggesting that our proposed model effectively mitigates the effect of noise introduced by the NULL class. 4 Related works Prior studies in ED mainly follow the supervised learning scheme. The early work focuses on feature engineering with statistical models (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011). Recently, many deep learning architectures have been explored for automatic feature learning (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Feng et al., 2016; Nguyen and Grishman, 2018; Lai et al., 2020c; Veyseh et al., 2021). Some recent studies have also introduced methods to extending ED to new event types (Liao and Grishman, 2011; Huang and Riloff, 2012; Nguyen et al., 2016b,g; Chen et al., 2017; Huang et al., 2018; Tong et al., 2020; Lai et al., 2020b). FSL has been extensively studied in computer vision (Vinyals et al., 2016; Snell et al., 2017; Finn et al., 2017; Lee et al., 2019; Fei et al., 2021). Recent work has also considered FSL for tasks in natural language processing (Han et al., 2018; Bao et al., 2020). For ED, prior FSL work has mostly relied on Prototypical network (Lai et al., 2020b; Deng et al."
2021.emnlp-main.427,P19-1522,0,0.0138166,"ypes memory network running on the data of the same (Ebner et al., 2020). ACE is a benchmark dataset class (Deng et al., 2020). Since the source code of in event extraction with 33 event subtypes (Walker et al., 2006). LR-KBP is a large scale event de- DMB-Proto is not published, we reimplement the few-shot classifier with a dynamic memory module tection dataset for FSL. It merges ACE-2005 and (Xiong et al., 2016). We examine two state-of-theTAC-KBP datasets and extends some event types art BERT-based sentence encoders φ for ED, i.e. by automatically collecting data from Freebase and BERTMLP (Yang et al., 2019) and BERTGCN (Lai Wikipedia (Deng et al., 2020). Since RAMS and ACE datasets are designed for supervised learn- et al., 2020c). Hyperparameters: In this paper, stochastic graing, we need to resplit them for FSL training. We dient decent optimizer is used with learning rate use the exact training/development/testing split for −4 ACE as presented in a prior study (Lai et al., 2020b). 1e . The training/evaluation are set to 6,000 and 500 iterations respectively; the evaluation is done Following the same method, for RAMS, we merge the original training/development and testing splits. after every 5"
2021.emnlp-main.439,W06-0901,0,0.383101,"event to document context that can fit into the BERT types (event trigger words). For instance, in the length limit. The typical approaches involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major approaches from other NLP tasks can be"
2021.emnlp-main.439,P15-1017,0,0.175775,"tem needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major approaches from other NLP tasks can be considered: (1) Architecture Change for Self-Attention (Zaheer et al., 2020; Beltagy et al., 2020; Kitaev et al., 2020): In this group, the vanilla self-attention of transformer is replaced with some variant mechanism such as sparse selfattention (Zaheer et al., 2020) that can encode larger cont"
2021.emnlp-main.439,D18-1158,0,0.0578434,"4 78.12 ACE 2005 (WP) P R F1 EKD 79.10 78.00 78.60 73.42 78.68 75.96 70.91 79.38 74.91 72.84 79.46 76.01 70.31 80.98 75.27 74.39 79.07 76.66 79.32 73.24 76.16 76.19 79.70 77.91 75.13 83.51 79.10 CySecED P R F1 DEEB-RNN (word2vec) 68.40 72.18 54.95 62.40 71.77 60.23 65.50 71.42 56.32 62.98 70.13 55.54 61.99 70.70 57.12 63.19 72.91 54.43 62.33 62.64 58.30 66.71 75.14 65.57 70.03 Table 1: Performance of the models on ACE 2005 and CySecED test sets. SL and WP stands for sequence-labeling and word-classification. The proposed model is significantly better than baselines with p &lt; 0.01. ing HBTNGMA (Chen et al., 2018) that employs gated multi-level attention mechanism and DEEBRNN (BERT) (Zhao et al., 2018) that uses a bidirectional RNN for encoding the sentences of the documents. Note that as BERT is not originally used in these models, we use their provided implementations and inject the BERTbase model into the encoding components for a fairer comparison. Furthermore, we compare ED3C with other variants of pre-trained transformer-based language models capable of encoding input texts with longer length than BERTbase limit. Specifically, we consider three commonly used language models: BigBird (Zaheer et al"
2021.emnlp-main.439,2020.emnlp-main.435,1,0.900055,"ess of the proposed model, called Event Detection with Dynamic Document Context (ED3C), we evaluate its performance on two benchmark datasets ACE 2005 (Walker et al., 2006) and CySecED (Trong et al., 2020). We choose these two datasets as they provide documents that are much longer than the input length limit for BERTbase , thus being more suitable to our focus on document-context modeling for ED2 . We use full document context for the documents in these datasets. ACE 2005 annotates 599 documents for 33 event types. We use the same data split and preprocessing as prior work (Lin et al., 2020; Lai et al., 2020b; Tong et al., 2020) for this dataset. The numbers of documents for the training/test/validation data are 529/40/30 respectively. In prior work, the ED problem on ACE 2005 has been addressed via both the sequence-labeling (Wang et al., 2020b; Lin et al., 2020) and word-classification (Lai et al., 2020b; Tong et al., 2020) formulations. The sequencelabeling formulation adheres to the original annotation in ACE 2005 to allow multiple words in event triggers. The word-classification formulation, in contrast, simplifies the problem by only concerning the single most important words in event trigg"
2021.emnlp-main.439,2021.eacl-main.237,1,0.772918,"e trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learnable component for context seED in the low-shot learning settings to improve the lection in ED3C. Interestingly, selecting only right data efficiency of"
2021.emnlp-main.439,P13-1008,0,0.0335033,"ighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for c"
2021.emnlp-main.439,C10-1077,0,0.0467773,"at augment the target sentence Si with all neighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms"
2021.emnlp-main.439,P10-1081,0,0.0494868,"at augment the target sentence Si with all neighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms"
2021.emnlp-main.439,2020.acl-main.713,0,0.556362,"earch, Vietnam 3 Raytheon BBN Technologies, USA {apouranb,minhnv,thien}@cs.uoregon.edu, v.nghiant66@vinai.io,bonan.min@raytheon.com Abstract Nguyen et al., 2021). Similar to other NLP tasks, the current best systems for ED leverage Event Detection (ED) aims to recognize transformer-based language models, e.g., BERT and classify trigger words of events in (Devlin et al., 2019), as a critical encoding compotext. The recent progress has featured adnent to achieve state-of-the-art performance (Lai vanced transformer-based language models (e.g., BERT) as a critical component in stateet al., 2020b; Lin et al., 2020). As such, most of of-the-art models for ED. However, the length the current transformer-based models for ED only limit for input texts is a barrier for such focus on sentence-level context in which the scope ED models as they cannot encode long-range of context to predict event type for each word is document-level context that has been shown to limited to the host sentence (Lu et al., 2019; Wang be beneficial for ED. To address this issue, we et al., 2019). However, it has been shown that propose a novel method to model documentdocument-level context also provides important inlevel context wi"
2021.emnlp-main.439,P19-1429,0,0.0260634,"Missing"
2021.emnlp-main.439,2020.coling-main.78,0,0.239236,"ications events and classifying them into predefined event to document context that can fit into the BERT types (event trigger words). For instance, in the length limit. The typical approaches involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major a"
2021.emnlp-main.439,C14-1214,0,0.013261,"involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further improve the ED performance. ishman, 2015; Chen et al., 2015; Lin et al., 2020; To alleviate the length limit for BERT-based ED 5403 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5403–5413 c November 7–11, 2021. 2021 Association for Computational Linguistics models, two major approaches from other NLP tasks can be considered: (1) Architecture Change for Self-Attention (Zaheer et al., 2020; Beltagy et al., 2020; Kitaev et al., 2020): In this group, the vanilla"
2021.emnlp-main.439,2021.naacl-main.3,1,0.814374,"Missing"
2021.emnlp-main.439,N16-1034,1,0.834623,"tences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learn"
2021.emnlp-main.439,P15-2060,1,0.933277,"on module using the performance of BERT for ED as the reward. In addition, we introduce auxiliary rewards based on linguistic intuition (i.e., semantic and discourse relations between the input sentence Si and selected context sentences) to enhance the selection process. Our extensive experiments on benchmark datasets show that the proposed method can achieve state-of-theart results for ED on both the sequence-labeling and the word-classification formulations. 2 Model In the literature, ED has been formulated as sequence-labeling (Lin et al., 2020; Nguyen et al., 2021) or word-classification (Nguyen and Grishman, 2015) problems. In this work, we explore both formulations of the task. Formally, given the input sentence Si = [w1 , w2 , . . . , wn ] (with n words) from the document D = [S1 , S2 , . . . , SN ] (with N sentences), the goal is to recognize and To this end, to develop an effective BERT- classify event triggers in Si , leveraging the broader based document-level model for ED, our motiva- context in D. In the sequence-labeling formulation tion in this work is to explicitly select only im- (Lin et al., 2020), as event triggers are allowed to portant/relevant parts of a document for a given involve mu"
2021.emnlp-main.439,D09-1016,0,0.0598491,"r and “Neighbor Sentence”) that augment the target sentence Si with all neighbor sentences. Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA dee"
2021.emnlp-main.439,2021.ccl-1.54,0,0.0473379,"Missing"
2021.emnlp-main.439,2020.acl-main.522,0,0.0199792,"model, called Event Detection with Dynamic Document Context (ED3C), we evaluate its performance on two benchmark datasets ACE 2005 (Walker et al., 2006) and CySecED (Trong et al., 2020). We choose these two datasets as they provide documents that are much longer than the input length limit for BERTbase , thus being more suitable to our focus on document-context modeling for ED2 . We use full document context for the documents in these datasets. ACE 2005 annotates 599 documents for 33 event types. We use the same data split and preprocessing as prior work (Lin et al., 2020; Lai et al., 2020b; Tong et al., 2020) for this dataset. The numbers of documents for the training/test/validation data are 529/40/30 respectively. In prior work, the ED problem on ACE 2005 has been addressed via both the sequence-labeling (Wang et al., 2020b; Lin et al., 2020) and word-classification (Lai et al., 2020b; Tong et al., 2020) formulations. The sequencelabeling formulation adheres to the original annotation in ACE 2005 to allow multiple words in event triggers. The word-classification formulation, in contrast, simplifies the problem by only concerning the single most important words in event triggers (Nguyen and Grish"
2021.emnlp-main.439,2021.acl-long.490,1,0.683626,"tly, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learnable component for context seED in the low-shot learning settings to improve the lection in ED3C. Interestingly, selecting only right data efficiency of the models (Lai et al., 2020a, or left context achieves better results than “Neigh2021). The majority of prior DL models for ED bor Sentences”. It suggests that important context are restricted to sentence-level context. In recent sentences might be far away from the target senyears, encoding document context with DL has"
2021.emnlp-main.439,P18-2066,0,0.2939,"el context in which the scope ED models as they cannot encode long-range of context to predict event type for each word is document-level context that has been shown to limited to the host sentence (Lu et al., 2019; Wang be beneficial for ED. To address this issue, we et al., 2019). However, it has been shown that propose a novel method to model documentdocument-level context also provides important inlevel context with BERT for ED that dynamically selects relevant sentences in the docuformation for deep learning models for ED (Chen ment for the event prediction of the target senet al., 2018; Zhao et al., 2018). For instance, in the tence. The target sentence will be then augdocument “The troops were retreating cautiously. mented with the selected sentences and conHe was shocked after he heard “Fire!"".”, to corsumed entirely by BERT for improved reprerectly predict Attack as the type of the event evoked sentation learning for ED. To this end, the REby “Fire” (i.e., avoiding the confusion with the INFORCE algorithm is employed to train the event type End-Position), it is necessary to consider relevant sentence selection for ED. Several inthe previous sentence with the important context formation type"
2021.emnlp-main.439,D19-1032,0,0.0252258,"Missing"
2021.emnlp-main.439,N19-1105,0,0.0294209,"Missing"
2021.emnlp-main.439,2020.emnlp-main.129,0,0.1737,"e input texts with up to 512 Event Detection (ED) is one of the fundamental sub-tokens (due to the quadratic self-attention comtasks for Information Extraction. Its goal is to plexity), current BERT-based document-level modidentify the word(s) in text that most clearly evoke els for ED has only constrained their applications events and classifying them into predefined event to document context that can fit into the BERT types (event trigger words). For instance, in the length limit. The typical approaches involve only input sentence “After the scandal, David James considering short documents (Wang et al., 2020b) was fired from the company."", an ED system needs or truncating long documents (Trong et al., 2020), to recognize the word “fired” as an event trigger as also done for other tasks (Schweter and Akbik, and predict its event type as End-Position. The early methods for ED have involved feature- 2020; Luoma and Pyysalo, 2020). These models based models (Ahn, 2006; Liao and Grishman, are thus unable to encode long-range dependencies in document context that go beyond the length limit 2010a; Miwa et al., 2014) while recent work has featured deep learning methods (Nguyen and Gr- of BERT to further"
2021.emnlp-main.439,N16-1033,0,0.0166467,"Noisy/irrelevant sentences might thus be included and impair induced representation vectors for ED. For instance, in Table 4, the immediately preceding sentences are not relevant to the event prediction of the target sentences, but are still introduced into the input texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al.,"
2021.emnlp-main.439,P19-1522,0,0.0150764,"texts for transformer-based models. Due to the trained context selection, ED3C can avoid those irrelevant sentences to perform ED correctly in these cases. 5 Related Work ED has been approached with feature-based models earlier (Ahn, 2006; Patwardhan and Riloff, 2009; Liao and Grishman, 2010b; Hong et al., 2011; Li et al., 2013; Yang and Mitchell, 2016). Recently, deep learning (DL) methods are proved to be an effective approach for ED (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Sha et al., 2018; Zhang et al., 2019; Nguyen and Nguyen, 2019; Yang et al., 2019; Zhang et al., 2020; Le and Nguyen, 2021). Transformer-based language modThe results of this analysis are provided in Taels such as BERT (Devlin et al., 2019) are the core ble 3. As can be seen, the proposed model ED3C components for current SOTA deep learning modoutperforms all heuristics-based baselines for conels for ED (Lai et al., 2020b; Veyseh et al., 2021). text selection, thus demonstrating the benefit of a Recently, there have been growing interests to solve dynamic and learnable component for context seED in the low-shot learning settings to improve the lection in ED3C. Interestingl"
2021.emnlp-main.440,2020.acl-main.554,0,0.0123433,"the target language to improve the cross-lingual representations for REE. This section presents the typical approaches for leveraging unlabeled target language data for crosslingual transfer learning in NLP, offering additional baselines for our proposed model later. Language Adversarial Training (LADV): To leverage unlabeled data in the target language, this method introduces a language discriminator that receives representation vectors for input sentences and predicts the language identity (i.e., source or target) of the sentences (Chen et al., 2019; Huang et al., 2019; Keung et al., 2019; Cao et al., 2020). As such, given an REE task t ∈ {ED, RE, EAE}, the method seeks to jointly train a model for t (i.e., those described in Section 3.1) and the language 4 Proposed Method discriminator so that the induced representation 4.1 Class-based Alignment vectors for t can contain necessary information for the predictions in t and be language-agnostic to An overview for the proposed model is shown in better transfer knowledge across languages at the Figure 1. As described in the introduction, to avoid same time. the potential cross-class alignment of representaTo implement this method, we first obtain a"
2021.emnlp-main.440,P19-1299,0,0.108687,"REE. ample of a different class. To address this However, previous work on crosslingual REE issue, we propose a novel crosslingual alignsuffers from the monolingual bias issue due to the ment method that leverages class information of REE tasks for representation learning. In monolingual training of models on only the source particular, we propose to learn two versions language data, leading to non-optimal crosslingual of representation vectors for each class in an performance. A solution for this issue can resort REE task based on either source or target lanto language adversarial training (Chen et al., 2019; guage examples. Representation vectors for Huang et al., 2019; Keung et al., 2019; Lange et al., corresponding classes will then be aligned to 2020; He et al., 2020) where unlabeled data in achieve class-aware alignment for crosslingual the target language is used to aid crosslingual reprepresentations. In addition, we propose to further align representation vectors for languageresentations via fooling a language discriminator. universal word categories (i.e., parts of speech The underlying principle for this approach is to and dependency relations). As such, a novel encourage the closeness"
2021.emnlp-main.440,P15-1017,0,0.053443,"ferent classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due t"
2021.emnlp-main.440,N19-1423,0,0.0142691,"from Ldisc . Overall, fooling the language discriminator in LADV with GRL eliminates languagespecific features to improve generalization across languages for t. mBERT Finetuning (FMBERT): Recently, it has been shown that fine-tuning multilingual pretrained language models on unlabeled data of the target language can improve the crosslingual performance for NLP tasks (Pfeiffer et al., 2020). Motivated by such prior work, this baseline exploits the unlabeled data in the target language for cross-lingual representation learning by fine-tuning mBERT on the data using mask language modeling (MLM) (Devlin et al., 2019). Afterward, the finetuned mBERT model is utilized in the encoders for the baseline models for REE tasks in Section 3.1. To avoid the monolingual bias in the cross-lingual methods for REE in Section 3.1, our work aims to exploit unlabeled data in the target language to improve the cross-lingual representations for REE. This section presents the typical approaches for leveraging unlabeled target language data for crosslingual transfer learning in NLP, offering additional baselines for our proposed model later. Language Adversarial Training (LADV): To leverage unlabeled data in the target langua"
2021.emnlp-main.440,I17-2072,1,0.832228,"ed Research Projects Activet al., 2020; He et al., 2020). Unfortunately, LADV suffers from the cross-class alignment issue, mak- ity (IARPA), via IARPA Contract No. 2019ing it less optimal for crosslingual REE. Finally, we 19051600006 under the Better Extraction from Text note that language-universal representation learn- Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are ing is related to domain adaption research where models seek to learn domain-invariant representa- those of the authors and should not be interpreted tions (Ganin and Lempitsky, 2015; Fu et al., 2017; as necessarily representing the official policies, eiAdel et al., 2017; Xie et al., 2018; Cicek and Soatto, ther expressed or implied, of ARO, ODNI, IARPA, the Department of Defense, or the U.S. Govern2019; Tang et al., 2020; Ngo et al., 2021). ment. The U.S. Government is authorized to reproduce and distribute reprints for governmental 7 Conclusions purposes notwithstanding any copyright annotation We present a novel method for crosslingual transfer therein. This document does not contain technollearning for REE that leverages unlabeled data in ogy or technical data controlled under either"
2021.emnlp-main.440,N19-1383,0,0.29477,"vious work on crosslingual REE issue, we propose a novel crosslingual alignsuffers from the monolingual bias issue due to the ment method that leverages class information of REE tasks for representation learning. In monolingual training of models on only the source particular, we propose to learn two versions language data, leading to non-optimal crosslingual of representation vectors for each class in an performance. A solution for this issue can resort REE task based on either source or target lanto language adversarial training (Chen et al., 2019; guage examples. Representation vectors for Huang et al., 2019; Keung et al., 2019; Lange et al., corresponding classes will then be aligned to 2020; He et al., 2020) where unlabeled data in achieve class-aware alignment for crosslingual the target language is used to aid crosslingual reprepresentations. In addition, we propose to further align representation vectors for languageresentations via fooling a language discriminator. universal word categories (i.e., parts of speech The underlying principle for this approach is to and dependency relations). As such, a novel encourage the closeness of representation vectors filtering mechanism is presented to f"
2021.emnlp-main.440,D18-1330,0,0.0282069,", Eugene, OR, USA 2 Raytheon BBN Technologies, USA 3 VinAI Research, Vietnam {minhnv,tnguyen,thien}@cs.uoregon.edu, bonan.min@raytheon.com Abstract REE in which a model is trained on a language, i.e., source language, and applied to another lanPrevious work on crosslingual Relation and guage, i.e., target language, where the annotations Event Extraction (REE) suffers from the monoare not available. Recent approaches for crosslinlingual bias issue due to the training of models gual REE have mainly employed multilingual word on only the source language data. An approach embeddings, e.g., MUSE, (Joulin et al., 2018; Ni to overcome this issue is to use unlabeled data and Florian, 2019; Liu et al., 2019; Subburathinam in the target language to aid the alignment of et al., 2019) or multilingual pre-trained language crosslingual representations, i.e., via fooling a language discriminator. However, as this apmodels, e.g., multilingual BERT, (Devlin et al., proach does not condition on class informa2019; M’hamdi et al., 2019; Ahmad et al., 2021; tion, a target language example of a class could Nguyen and Nguyen, 2021) to learn crosslingual be incorrectly aligned to a source language exrepresentation vectors f"
2021.emnlp-main.440,D19-1138,0,0.323614,"ingual REE issue, we propose a novel crosslingual alignsuffers from the monolingual bias issue due to the ment method that leverages class information of REE tasks for representation learning. In monolingual training of models on only the source particular, we propose to learn two versions language data, leading to non-optimal crosslingual of representation vectors for each class in an performance. A solution for this issue can resort REE task based on either source or target lanto language adversarial training (Chen et al., 2019; guage examples. Representation vectors for Huang et al., 2019; Keung et al., 2019; Lange et al., corresponding classes will then be aligned to 2020; He et al., 2020) where unlabeled data in achieve class-aware alignment for crosslingual the target language is used to aid crosslingual reprepresentations. In addition, we propose to further align representation vectors for languageresentations via fooling a language discriminator. universal word categories (i.e., parts of speech The underlying principle for this approach is to and dependency relations). As such, a novel encourage the closeness of representation vectors filtering mechanism is presented to facilitate for senten"
2021.emnlp-main.440,2020.repl4nlp-1.14,0,0.017951,"od achieves SOTA performance for three REE tasks in different crosslingual settings. In the future, we plan to extend our methods to related problems in IE (e.g., coreference resolution). Acknowledgments This research has been supported by the Army Research Office (ARO) grant W911NF-21-1-0112 and the NSF grant CNS-1747798 to the IUCRC Center for Big Learning. This research is unlabeled data in the target language to perform crosslingual representation alignment (Chen et al., also based upon work supported by the Office of the Director of National Intelligence (ODNI), 2019; Huang et al., 2019; Lange et al., 2020; Cao Intelligence Advanced Research Projects Activet al., 2020; He et al., 2020). Unfortunately, LADV suffers from the cross-class alignment issue, mak- ity (IARPA), via IARPA Contract No. 2019ing it less optimal for crosslingual REE. Finally, we 19051600006 under the Better Extraction from Text note that language-universal representation learn- Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are ing is related to domain adaption research where models seek to learn domain-invariant representa- those of the authors and should not be interpreted tions (Ga"
2021.emnlp-main.440,P13-1008,0,0.0246106,"ue by pushing representations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021"
2021.emnlp-main.440,R11-1002,0,0.0153547,"LADV can address this issue by pushing representations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen"
2021.emnlp-main.440,2020.acl-main.713,0,0.024048,"on on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV has discussed earlier, a"
2021.emnlp-main.440,D19-1068,0,0.0296773,"Missing"
2021.emnlp-main.440,K19-1061,0,0.0407902,"Missing"
2021.emnlp-main.440,2021.findings-acl.351,1,0.755762,"Missing"
2021.emnlp-main.440,2021.naacl-main.3,1,0.849686,"Missing"
2021.emnlp-main.440,2021.eacl-demos.10,1,0.727369,"Missing"
2021.emnlp-main.440,2021.wanlp-1.27,1,0.887473,"Missing"
2021.emnlp-main.440,P19-1423,0,0.0133095,"ettings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In ot"
2021.emnlp-main.440,K18-2020,0,0.0145777,"e cross-lingual alignment We conduct extensive experiments with differfor representation vectors in REE. As such univer- ent crosslingual settings on English, Chinese, and sal word categories have been consistently anno- Arabic for three REE tasks, i.e., Relation Extractated for more than 100 languages (Zeman et al., tion, Event Detection, and Event Argument Extrac2020) and can be generated with high accuracy tion. The results demonstrate the benefits of the via existing toolkits, e.g., the transformer-based proposed method that significantly advances the toolkit Trankit for multilingual NLP (Straka, 2018; state-of-the-art performance in these settings. 5415 2 Problem Statement We study cross-lingual transfer learning for three REE tasks as defined in the ACE 2005 dataset (Walker et al., 2006), i.e., Relation Extraction (RE), Event Detection (ED), and Event Argument Extraction (EAE). Given two entity mentions in an input sentence, the goal of RE is to determine the semantic relationship between the mentions according to predefined relation types/classes (e.g., Employment). For ED, its purpose is to identify event triggers, which can be verbs/normalization with one or multiple words, that expre"
2021.emnlp-main.440,K17-3009,0,0.0159522,"ions by RE EAE sending the score vectors sED tgt,k , stgt , and stgt ED to a softmax layer: ˆ yED tgt,k = softmax(stgt,k ), and ˆyttgt = softmax(sttgt ) (for t = RE or EAE). As such, we obtain the target-language representation for l via the weighted sum of rttgt (for RE and EAE): 4.2 Word Category-based Alignment We further exploit universal parts of speech (UPOS) and dependency relations as the language-agnostic knowledge to align crosslingual representations for REE. To achieve a fair comparison with prior work (Subburathinam et al., 2019; Ahmad et al., 2021), we employ the UDPipe toolkit (Straka and Straková, 2017) to obtain parts of speech and dependency relations for the sentences. Due to their similarity, we will only describe the UPOS-based alignment process and the dependency-based alignment can be done in the same way. As such, we utilize an embedding table U (initialized randomly) to capture representation vectors for the possible UPOS, serving as an anchor knowledge across languages. Next, to facilitate the UPOS-based representation alignment, we comP t t ˆ y r tgt tgt,l x ∈D tgt tgt pute additional representation vectors for UPOS cttgt,l = P (5) ˆt xtgt ∈Dtgt ytgt,l based on representation vect"
2021.emnlp-main.440,N16-1034,1,0.8894,"unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance o"
2021.emnlp-main.440,D19-1030,0,0.241678,"Missing"
2021.emnlp-main.440,P15-2060,1,0.81307,"tions for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the mon"
2021.emnlp-main.440,D19-1038,0,0.0264843,"t to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV has discussed earlier, a major issue for LADV is that been explored to address this issue by leveraging 5421 a) GATE+CCCAR 80 b) GATE+LADV 0 1 2 3 4 40 0 1 2 3 4"
2021.emnlp-main.440,D09-1016,0,0.0508587,"esentation alignment in GATE+LADV can address this issue by pushing representations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (A"
2021.emnlp-main.440,2020.emnlp-main.617,0,0.0460523,"Missing"
2021.emnlp-main.440,2020.acl-demos.14,0,0.0254322,". 2021 Association for Computational Linguistics Class-aware Alignment Averaging Target Lang Source Lang Class Representations Class Representations FFN ... Contextualized Embeddings Epoch-level Path Transformer ... Dsrc={(xsrc , ysrc)} UPOS/DEP Representation Alignment MBERT D={(x )} tgt tgt Lcls Lpos/dep Word Classifier Gradient Reversal Layer t align ctx Lpos/dep Task Classifier t L Example Representations Figure 1: Overall architecture of the proposed models for RE, EAE. For ED, example representations are the contextualized embeddings. erally invariant across languages that can be lever- Qi et al., 2020; Nguyen et al., 2021b), we expect aged as anchors to bridge representation vectors for this information to provide helpful anchor knowlexamples in different languages. As such, we can edge for cross-lingual representation learning. To obtain two semantic representation vectors for each this end, similar to the class-aware alignment, we class in an REE task based on representation vec- propose to align representation vectors of the same tors of examples in either source or target language. universal word categories that are computed using Afterward, the representation vectors of the same conte"
2021.emnlp-main.440,2020.acl-main.715,1,0.735548,"ue to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV h"
2021.emnlp-main.440,2020.findings-emnlp.326,1,0.720993,"ue to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Proposed Method: As data for training. In other NLP tasks, LADV h"
2021.emnlp-main.440,D19-1584,0,0.0116059,"imal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental limitation of existing crosslingual models for REE is the monolingual bias due to the sole reliance on source language Alignment Effect of the Propo"
2021.emnlp-main.440,N16-1033,0,0.0144251,"resentations from both languages closer. However, representations for examples with different classes are unexpectedly aligned in GATE+LADV, causing suboptimal representations for crosslingual settings. Finally, due to the explicit condition on class information for alignment, GATE+CCCAR can match representations for both languages while avoiding the cross-class alignment to improve crosslingual performance for REE. 6 Related Work REE has been extensively studied for English, featuring traditional machine learning methods (Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Li et al., 2013; Yang and Mitchell, 2016) and advanced deep learning models (Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016a; Nguyen and Grishman, 2018; Wang et al., 2019; Zhang et al., 2019; Sahu et al., 2019; Veyseh et al., 2020b,a,c; Lin et al., 2020; Nguyen et al., 2021a). Recently, several works have considered cross-lingual transfer learning for three REE tasks (Ni and Florian, 2019; Liu et al., 2019; Subburathinam et al., 2019) where multilingual pre-trained language models (e.g., mBERT) have been proved as an important encoding component (Ahmad et al., 2021; Nguyen and Nguyen, 2021). However, a fundamental"
2021.emnlp-main.440,N10-1000,0,0.0435046,"Missing"
2021.findings-acl.211,W06-0901,0,0.117514,"NLP for historical texts has mainly focused on spelling and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 2020c; Nguyen et al., 2021). Some recent studies in EE have also addressed extensible learning settings for EE to new event types, e.g. zero-shot learning (Huang et al., 2018), fewshot learning (Lai et al., 2020a,b), or new domains (Naik and Ros´e, 2020). The closet works to ours involve recent efforts to create new datasets for EE (Satyapanich et al., 2020; Ebner et al., 2020; Wang et al., 2020; Trong et al., 2020; Le and Nguyen, 2021). However, these works"
2021.findings-acl.211,P17-1031,0,0.0161853,"2005. The BRAD# columns report the performance with BERT fine-tuned on the African American corpus. history, thus impairing the models and requiring appropriate adaptation to boost the EE performance. Finally, we note that the human performance (F1 scores) for Entity, Trig-C, and Arg-C on BRAD are 95.43, 88.3, and 79.8 respectively. The large performance gaps between human and current EE systems thus presents many research opportunities for future work on BRAD. 4 Related work Prior work in NLP for historical texts has mainly focused on spelling and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al."
2021.findings-acl.211,P15-1017,0,0.0143508,"g and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 2020c; Nguyen et al., 2021). Some recent studies in EE have also addressed extensible learning settings for EE to new event types, e.g. zero-shot learning (Huang et al., 2018), fewshot learning (Lai et al., 2020a,b), or new domains (Naik and Ros´e, 2020). The closet works to ours involve recent efforts to create new datasets for EE (Satyapanich et al., 2020; Ebner et al., 2020; Wang et al., 2020; Trong et al., 2020; Le and Nguyen, 2021). However, these works do not consider historical texts as we do. 5 Acknowledgement T"
2021.findings-acl.211,N19-1423,0,0.0126723,"age models to better capture the nature of historical texts which, in turn, will facilitate a more accurate performance of EE. 3 Experiment There are three major EE tasks that BRAD supports for historical texts, including entity mention detection (EMD), event trigger detection (ED), and event argument extraction (EAE). This section aims to reveal the complexity of the EE tasks in BRAD by evaluating the performance of existing state-of-theart models for EE on this dataset. In particular, we focus on the following state-of-the-art models for EE that leverage the pre-trained language model BERT (Devlin et al., 2019) for the text encoding and jointly perform predictions for all EE tasks in an end-to-end fashion (i.e., joint inference): DyGIE++ (Wadden et al., 2019): This model utilizes dynamic span graphs to exploit long-range OneIE (Lin et al., 2020): This model first identifies spans of entity mentions and event triggers. The detected spans are then paired to jointly predict entity types, event types, relations, and argument roles for IE. Global features are used to capture cross-task and cross-instance dependencies and are employed in the decoding phase with beam searches to improve extraction performa"
2021.findings-acl.211,2020.acl-main.718,0,0.0331035,"Missing"
2021.findings-acl.211,P19-1157,0,0.0131066,"report the performance with BERT fine-tuned on the African American corpus. history, thus impairing the models and requiring appropriate adaptation to boost the EE performance. Finally, we note that the human performance (F1 scores) for Entity, Trig-C, and Arg-C on BRAD are 95.43, 88.3, and 79.8 respectively. The large performance gaps between human and current EE systems thus presents many research opportunities for future work on BRAD. 4 Related work Prior work in NLP for historical texts has mainly focused on spelling and text normalization (Pettersson et al., 2014; Bollmann et al., 2017; Flachs et al., 2019). Recently, some studies have undertaken research on historical texts with NLP tasks such as POS tagging (Yang and Eisenstein, 2016) and information extraction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 20"
2021.findings-acl.211,P18-1201,0,0.0182895,"ction (Pettersson et al., 2016). However, none of this work has explored EE. EE is an active research area due to the availability of EE datasets e.g., for general (Walker et al., 2005; Mitamura et al., 2015) and biomedical (Kim et al., 2011) domains. Most of prior studies focus on in-domain EE (Ahn, 2006; Li et al., 2013; Nguyen and Grishman, 2015; Chen et al., 2015; Nguyen et al., 2016; Yang et al., 2019; Wadden et al., 2019; Lai et al., 2020c; Nguyen et al., 2021). Some recent studies in EE have also addressed extensible learning settings for EE to new event types, e.g. zero-shot learning (Huang et al., 2018), fewshot learning (Lai et al., 2020a,b), or new domains (Naik and Ros´e, 2020). The closet works to ours involve recent efforts to create new datasets for EE (Satyapanich et al., 2020; Ebner et al., 2020; Wang et al., 2020; Trong et al., 2020; Le and Nguyen, 2021). However, these works do not consider historical texts as we do. 5 Acknowledgement This work is supported by an I3 grant from the University of Oregon Provost’s Office (Incubating Interdisciplinary Initiatives) and the Army Research Office (ARO) grant W911NF-21-1-0112. This research is also based upon work supported by the Office of"
2021.findings-acl.211,P19-1353,0,0.0376032,"Missing"
2021.findings-acl.351,P15-1017,0,0.371073,"hieve optimal alignment. The faraway source instances that induce the highest transportation costs are those out-of-distribution samples that may introduce noise and hurt adaptation performance. Accordingly, they are omitted from the domain-adversarial training process. The entire computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related knowledge encoded in"
2021.findings-acl.351,N19-1423,0,0.0347298,"the network learns to map each representation into the same orthogonal space with Aj while not having any expressive capability of their corresponding domains. To address this issue, we incorporate a self-supervised component, using the popular Masked Language Modeling (MLM) as our unsupervised task. The token predictor hm : Rdmodel → RV (V is the vocabulary size), is shared between source and target domains: Lm = NX mask Lsm (xsi ) + Ltm (xti ) i=1 Ldm (xdi )   = −wid log hm Aj (xdi ) + Ad (xdi ) where Nmask is the number of randomly masked input tokens, following the original procedure in Devlin et al. (2019). The benefit of adding the MLM component is twofold. On one hand, it serves as a constraint to learn informative representations for domain-specific adapters. On the other hand, it also help conditioning joint adapter Aj on unsupervised knowledge of unlabeled target data, which can have a positive impact on target domain’s performance. 3.4 Data Selection Considering the Wasserstein-1 distance between the distributions generating source and target marginal representations PsX and PtX , which can be written as:   W (PsX , PtX ) = sup E [f (xs )] − E f (xt ) kf kL ≤1 There are several advantag"
2021.findings-acl.351,2020.acl-main.740,0,0.0567111,"Missing"
2021.findings-acl.351,P18-1048,0,0.0774131,"Missing"
2021.findings-acl.351,2020.nuse-1.5,1,0.905894,"computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related knowledge encoded in BERT’s representations (Aharoni and Goldberg, 2020), and methods to leverage it to improve performances on domain-specific tasks, such as pre-training on additional data (Gururangan et al., 2020), fine-tuning using intermediate tasks (Phang et al., 2018; Garg et al., 2020), and da"
2021.findings-acl.351,2020.emnlp-main.435,1,0.82688,"computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related knowledge encoded in BERT’s representations (Aharoni and Goldberg, 2020), and methods to leverage it to improve performances on domain-specific tasks, such as pre-training on additional data (Gururangan et al., 2020), fine-tuning using intermediate tasks (Phang et al., 2018; Garg et al., 2020), and da"
2021.findings-acl.351,P13-1008,0,0.0740003,"N component to achieve optimal alignment. The faraway source instances that induce the highest transportation costs are those out-of-distribution samples that may introduce noise and hurt adaptation performance. Accordingly, they are omitted from the domain-adversarial training process. The entire computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related kn"
2021.findings-acl.351,P17-1001,0,0.36331,"when applying adversarial training compare with simply finetuning BERT on in-domain data. One explanation is that the pre-training of BERT on massive corpora has already induces a somewhat general representation, thus DANN has little effect while the finetuning process using source dataset could cause over-fitting on the corresponding domain due to the immense capacity of the model. To this end, we propose fixing the parameters of the already universal language model while leveraging multiple adapter modules for domain-adversarial training process. More specifically, inspired by the works of Liu et al. (2017a) and Houlsby et al. (2019) on effective multi-task learning, we augment the pre-trained BERT model by adding three different adapters to create a shared-private architecture. Two source and target adapters which take as inputs data from their respective domains to capture private properties of each, and a joint adapter that encodes every sample in a subspace shared across domains through adversarial training. Orthogonality constraints together with a self-supervised auxiliary task are employed to ensure the representations of all adapters are informative while also attaining the above desire"
2021.findings-acl.351,P17-1164,0,0.248057,"when applying adversarial training compare with simply finetuning BERT on in-domain data. One explanation is that the pre-training of BERT on massive corpora has already induces a somewhat general representation, thus DANN has little effect while the finetuning process using source dataset could cause over-fitting on the corresponding domain due to the immense capacity of the model. To this end, we propose fixing the parameters of the already universal language model while leveraging multiple adapter modules for domain-adversarial training process. More specifically, inspired by the works of Liu et al. (2017a) and Houlsby et al. (2019) on effective multi-task learning, we augment the pre-trained BERT model by adding three different adapters to create a shared-private architecture. Two source and target adapters which take as inputs data from their respective domains to capture private properties of each, and a joint adapter that encodes every sample in a subspace shared across domains through adversarial training. Orthogonality constraints together with a self-supervised auxiliary task are employed to ensure the representations of all adapters are informative while also attaining the above desire"
2021.findings-acl.351,D19-6109,0,0.152837,"019) on effective multi-task learning, we augment the pre-trained BERT model by adding three different adapters to create a shared-private architecture. Two source and target adapters which take as inputs data from their respective domains to capture private properties of each, and a joint adapter that encodes every sample in a subspace shared across domains through adversarial training. Orthogonality constraints together with a self-supervised auxiliary task are employed to ensure the representations of all adapters are informative while also attaining the above desired properties. Recently, Ma et al. (2019) and Aharoni and Goldberg (2020) have shown that BERT’s representations are extremely effective at clustering text to their respective domains, and a small subset of good in-domain data can already provide significant boosts in target performance while the rest only provide little to no improvement, in some cases even degrade model’s out-of-domain generalization. Considering this, we explicitly find hard instances to leave out when learning to extract the domain-invariant features. Our data selection component estimates and minimizes the cost of transport between source and target marginal rep"
2021.findings-acl.351,2020.acl-main.681,0,0.0974027,"Missing"
2021.findings-acl.351,2021.naacl-main.3,1,0.893174,"Missing"
2021.findings-acl.351,N16-1034,1,0.667566,"ment. The faraway source instances that induce the highest transportation costs are those out-of-distribution samples that may introduce noise and hurt adaptation performance. Accordingly, they are omitted from the domain-adversarial training process. The entire computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related knowledge encoded in BERT’s representation"
2021.findings-acl.351,P19-1353,0,0.0145879,"is formulated as a binary classification problem in which the goal is to determine if the trigger word expresses an event, while the latter is a multi-class classification task that requires model to assign the predicted label into one of the pre-defined 34 event types (include 1 negative type). 4.1 Datasets TimeBank dataset (Pustejovsky et al., 2003) a fine-grained temporally annotated corpus of events and their positions and ordering in time. The text of the dataset were chosen from a wide range of sources from the news media domain. Events are annotated in a binary manner. LitBank dataset (Sims et al., 2019) a recently introduced corpus of literary events. The dataset contains excerpts of 100 literary works from the Project Gutenberg corpus. Labels for events are binary. 4020 System DAA-D DAA-W DAA-M DAA-S DAA In-domain(bn+nw) P R F 75.8 79.7 77.7 79.2 76.4 77.7 78.1 76.5 77.3 77.5 77.1 77.3 79.7 75.7 77.7 Out-of-domain (bc) P R F 74.4 76.8 75.5 77.8 73.5 75.6 80.4 71.0 75.4 78.7 72.4 75.4 78.5 75.6 76.9 Out-of-domain (cts) P R F 78.4 70.0 73.9 80.8 70.1 75.1 77.0 69.4 73.3 79.2 70.7 74.7 78.4 73.2 75.6 Out-of-domain (wl) P R F 67.2 57.1 61.7 70.2 53.7 60.9 68.9 55.1 61.2 65.5 57.9 61.5 66.2 60.3"
2021.findings-acl.351,P15-2060,1,0.821913,"task due to the intricate dependency among triggers, events, and contexts in linguistic data. The complication is further amplified by domain shift problem when text are collected from multiple different domains. The majority of prior approaches on ED relied on the basic supervised learning assumption where training and testing data follow the same distribution. Several works further evaluated their methods on cross-domain setting where their models were trained using data from one domain and tested on another, without leveraging any adaptation mechanism to alleviate the domain shift problem (Nguyen and Grishman, 2015; Yubo et al., 2015; Hong et al., 2018b). To this end, our work explores the general problem of domain adaptation for ED where data comes from two different source and target domains. In particular, we focus on the unsupervised setting that requires no annotations for target data, and the model has to learn to make use of both labeled source and unlabeled target samples to improve its performance on target domain. To our knowledge, this is the first work on unsupervised domain adaptation (UDA) for ED in the literature. The most prominent approach for UDA is a representation learning method bas"
2021.findings-acl.351,D16-1085,1,0.68341,"ordingly, they are omitted from the domain-adversarial training process. The entire computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related knowledge encoded in BERT’s representations (Aharoni and Goldberg, 2020), and methods to leverage it to improve performances on domain-specific tasks, such as pre-training on additional data (Gururangan et al., 2020), fine-tuni"
2021.findings-acl.351,2021.eacl-main.39,0,0.0558668,"Missing"
2021.findings-acl.351,2020.acl-main.522,0,0.0264017,"samples that may introduce noise and hurt adaptation performance. Accordingly, they are omitted from the domain-adversarial training process. The entire computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related knowledge encoded in BERT’s representations (Aharoni and Goldberg, 2020), and methods to leverage it to improve performances on domain-specific tasks,"
2021.findings-acl.351,N19-1105,0,0.0173796,"he diversity of these unlabeled text also pushes the network to be a good starting point for learning domain-invariant features, which would be lost if we fully fine-tune it on source domain task. Accordingly, we make use of a fixed pre-trained BERT model as the base of our adapters. Baseline Model As this is the first work on UDA for ED, this section aims to establish a baseline of the task for further research. Recent works have shown a substantial boost in performance for the standard supervised setting of ED by leveraging contextual embedding of large self-attention based language models (Wang et al., 2019; Lai et al., 2020c). Accordingly, we utilize a pre-trained BERT’s encoder, together with its domain-adversarial variant to create a strong baseline for the UDA setting. Without any domain adaptation mechanism, our BERT baseline only follows cross-domain evaluation setting as previous works. The model is fully fine-tuned on source domain dataset while at test time, data from target domain is used to evaluate its performance. On the other hand, the BERT+DANN baseline takes advantage of the availabel unlabeled target data through adversarial training. Specifically, a domain classification task i"
2021.findings-acl.351,2020.emnlp-main.639,0,0.0199821,"-IJCNLP 2021, pages 4015–4025 August 1–6, 2021. ©2021 Association for Computational Linguistics ture extractor, resulting in a not only discriminative but also domain-invariant joint representation for data from both domains. While DANN and its variants are very well-studied in computer vision’s domain adaption researches, their NLP counterparts are pale in comparison, especially for a newly established architecture like BERT. There have been only several works that adopted DANN to align the contextualized representations learned by BERT across domains (Lin et al., 2020; Naik and Ros´e, 2020; Wright and Augenstein, 2020). Lin et al. (2020) even observed negative effect when applying adversarial training compare with simply finetuning BERT on in-domain data. One explanation is that the pre-training of BERT on massive corpora has already induces a somewhat general representation, thus DANN has little effect while the finetuning process using source dataset could cause over-fitting on the corresponding domain due to the immense capacity of the model. To this end, we propose fixing the parameters of the already universal language model while leveraging multiple adapter modules for domain-adversarial training proc"
2021.findings-acl.351,N16-1033,0,0.0648449,"rce instances that induce the highest transportation costs are those out-of-distribution samples that may introduce noise and hurt adaptation performance. Accordingly, they are omitted from the domain-adversarial training process. The entire computation makes use of representations from source and target adapters, thus implicitly provides informative signals from domain-specific adapters to joint adapter without interrupting the joint representation learning procedure. 2 Related Work Prior ED works have focused on the in-domain setting (Li et al., 2013; Chen et al., 2015; Nguyen et al., 2016; Yang and Mitchell, 2016; Nguyen and Grishman, 2018; Sha et al., 2018; Liu et al., 2017b; Tong et al., 2020; Nguyen et al., 2021), the crossdomain evaluation (Nguyen and Grishman, 2016; Hong et al., 2018a), the few/low-shot learning scenario (Lai et al., 2020a,b). Our work is different from those prior work as we explore a new formulation for ED with unsupervised domain adaptation where unlabeled data in the target domain is utilized to improve domain-invariant representation learning. Recently, some efforts have been made to study the domain-related knowledge encoded in BERT’s representations (Aharoni and Goldberg,"
2021.findings-emnlp.325,W19-5039,0,0.0468386,"Missing"
2021.findings-emnlp.325,W19-1909,0,0.0523096,"Missing"
2021.findings-emnlp.325,N18-3011,0,0.0231078,"P tasks across five datasets. Generally, one main observation from the table is that equipping PLMs with DAKI significantly improve their performance on these biomedical tasks, as reflected in DAKI-BERT, DAKI-RoBERTa and DAKI-ALBERT, demonstrating the effectiveness of the architecture. Moreover, although DAKIBERT outperforms BERT across all metrics, it only performs comparably or poorer than ClinicalBERT, SciBERT and BioBERT. We conjecture that it is due to lack of the knowledge in their pre-training data, i.e., the MIMIC-III clinical notes (Johnson et al., 2016), the Semantic Scholar papers (Ammar et al., 2018), and the PubMed articles, respectively. Baselines We take three PLMs, i.e., BERT-base- Transferability Another advantage of DAKI is uncased (Devlin et al., 2019), RoBERTa-base (Liu transferability, due to its flexible architecture and et al., 2019), ALBERT-xxlarge-v2 (Lan et al., implementation. In this work, we have three 3861 Figure 3: Activation levels of the adapters KG, DS, SG over the downstream tasks. We calculate the softmax activations in the last layer for each adapter, and the activations are averaged over all instances in the test set. adapters and they are all pre-trained with AL"
2021.findings-emnlp.325,D19-1371,0,0.0879228,"formance over domain-specific texts is relatively various downstream tasks in different domains. However, existing domain-specific poor due to domain shifts (Ma et al., 2019). ConPLMs mostly rely on self-supervised learning sequently, recent studies construct domain-specific over large amounts of domain text, without PLMs through fine-tuning or pre-training from explicitly integrating domain-specific knowlscratch over domain corpora, such as BioBERT edge, which can be essential in many do(Lee et al., 2020), ClinicalBERT (Huang et al., mains. Moreover, in knowledge-sensitive ar2019), SciBERT (Beltagy et al., 2019), etc. eas such as the biomedical domain, knowledge is stored in multiple sources and forSince these PLMs are mostly pre-trained on mats, and existing biomedical PLMs either neunstructured free texts, a common issue among glect them or utilize them in a limited manthe aforementioned general and domain-specific ner. In this work, we introduce an architecture PLMs is their lack of specific structured knowledge, to integrate domain knowledge from diverse which results in their incompetence on knowledgesources into PLMs in a parameter-efficient driven tasks (Rogers et al., 2020). For instance, way"
2021.findings-emnlp.325,N19-1423,0,0.647997,"nowledge-specific adapters across ing objective for joint optimization. Despite the immultiple PLMs. proved performance of these knowledge-enriched 1 Introduction PLMs over downstream tasks, there are three limIn the past few years, large pre-trained language itations. First, these approaches, either training models (PLMs) have demonstrated superior per- from scratch or fine-tuning over off-the-shelf checkformance over various downstream tasks in nat- points, need to optimize the entire model, which ural language processing (NLP), such as BERT is quite expensive. Second, they mostly focus on (Devlin et al., 2019), RoBERTa (Liu et al., 2019), single-source knowledge incorporation, e.g., an enALBERT (Lan et al., 2019), GPT-3 (Brown et al., cyclopedia, and neglect knowledge from multiple 2020), etc. These PLMs mainly depend on self- sources. This limits the utilization of potential supervised pre-training on large amounts of textual knowledge, especially for knowledge-sensitive ar3855 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3855–3865 November 7–11, 2021. ©2021 Association for Computational Linguistics eas such as the biomedical domain where knowledge is stored in mult"
2021.findings-emnlp.325,2020.emnlp-main.372,0,0.124449,"used in a plug-and-play manner via DAKI. • Extensive experiments on different biomedical NLP tasks and datasets demonstrate the benefits of the proposed knowledge-specific adapters and DAKI. 2 Related Work This study is essentially related to two lines of research: knowledge integration for PLMs and domain-specific PLMs (biomedical PLMs in particular). There has been a surge of research on knowledge injection for PLMs in recent years (Yao et al., 2019; Zhang et al., 2019; Peters et al., 2019; Kim et al., 2020; Levine et al., 2020; Lauscher et al., 2020; Pereira et al., 2020; Sun et al., 2020; He et al., 2020a; Wang et al., 2021). These studies aim to integrate knowledge from an external knowledge source, e.g., Wikipedia, into PLMs by augmenting the training objective with a knowledge-driven regularization. As mentioned above, these methods are limited in the sense that they mostly focus on single-source knowledge, and require full model training. K-adapter (Wang et al., 2020) addresses some of these issues by introducing linguistic and factual adapters into RoBERTa, but the adapters are treated equally in their work. Also, general domain knowledge, such as factual knowledge (Zhang et al., 2019; S"
2021.findings-emnlp.325,W19-2011,0,0.0228111,"9), single-source knowledge incorporation, e.g., an enALBERT (Lan et al., 2019), GPT-3 (Brown et al., cyclopedia, and neglect knowledge from multiple 2020), etc. These PLMs mainly depend on self- sources. This limits the utilization of potential supervised pre-training on large amounts of textual knowledge, especially for knowledge-sensitive ar3855 Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3855–3865 November 7–11, 2021. ©2021 Association for Computational Linguistics eas such as the biomedical domain where knowledge is stored in multiple sources and formats (Jin et al., 2019; Lee et al., 2020). Third, most of existing knowledge integration approaches focus on general domain knowledge, while domain knowledge infusion for PLMs is underexplored. To address these limitations, we propose to perform knowledge integration for PLMs via adapters (Rebuffi et al., 2017; Houlsby et al., 2019; Pfeiffer et al., 2020, 2021; Wang et al., 2020). Basically, adapters are lightweight neural networks that are placed inside PLMs. When fine-tuning a PLM, the original parameters of the PLM are fixed and only the adapters are fine-tuned. This makes adapters a parameter-efficient alternat"
2021.findings-emnlp.325,2020.coling-main.153,0,0.238609,"tasks (Rogers et al., 2020). For instance, way. More specifically, we propose to ensome studies point out PLMs are insufficient to code domain knowledge via adapters, which well capture factual knowledge from text (Poerner are small bottleneck feed-forward networks inserted between intermediate transformer layet al., 2019; Wang et al., 2020, 2021). ers in PLMs. These knowledge adapters are To enrich PLMs with external knowledge, some pre-trained for individual domain knowledge efforts have been made recently (Yao et al., 2019; sources and integrated via an attention-based Zhang et al., 2019; Kim et al., 2020; Levine et al., knowledge controller to enrich PLMs. Tak2020; Wang et al., 2021). A common theme ing the biomedical domain as a case study, we explore three knowledge-specific adapters among these approaches is the incorporation of for PLMs based on the UMLS Metathesaurus an auxiliary knowledge-driven training objective. graph, the Wikipedia articles for diseases, and For instance, KG-BERT (Yao et al., 2019) intethe semantic grouping information for biomedgrates world/factual knowledge from Wikipedia ical concepts. Extensive experiments on differvia knowledge graph completion; KEPLER (Wang en"
2021.findings-emnlp.325,2020.deelio-1.5,0,0.0204119,"cepts. Such adapters serve as off-the-shelf modules and can be used in a plug-and-play manner via DAKI. • Extensive experiments on different biomedical NLP tasks and datasets demonstrate the benefits of the proposed knowledge-specific adapters and DAKI. 2 Related Work This study is essentially related to two lines of research: knowledge integration for PLMs and domain-specific PLMs (biomedical PLMs in particular). There has been a surge of research on knowledge injection for PLMs in recent years (Yao et al., 2019; Zhang et al., 2019; Peters et al., 2019; Kim et al., 2020; Levine et al., 2020; Lauscher et al., 2020; Pereira et al., 2020; Sun et al., 2020; He et al., 2020a; Wang et al., 2021). These studies aim to integrate knowledge from an external knowledge source, e.g., Wikipedia, into PLMs by augmenting the training objective with a knowledge-driven regularization. As mentioned above, these methods are limited in the sense that they mostly focus on single-source knowledge, and require full model training. K-adapter (Wang et al., 2020) addresses some of these issues by introducing linguistic and factual adapters into RoBERTa, but the adapters are treated equally in their work. Also, general domain kn"
2021.findings-emnlp.325,2021.ccl-1.108,0,0.0813402,"Missing"
2021.findings-emnlp.325,D19-6109,0,0.0243185,"nguage Models 1 Qiuhao Lu1 , Dejing Dou1,2 , and Thien Huu Nguyen1 Dept. of Computer and Information Science, University of Oregon, Eugene, OR, USA 2 Baidu Research {luqh, dou, thien}@cs.uoregon.edu Abstract data, e.g., Wikipedia, and can be conveniently applied to downstream tasks via fine-tuning. Despite Domain-specific pre-trained language modthe great success of these general PLMs, their perels (PLMs) have achieved great success over formance over domain-specific texts is relatively various downstream tasks in different domains. However, existing domain-specific poor due to domain shifts (Ma et al., 2019). ConPLMs mostly rely on self-supervised learning sequently, recent studies construct domain-specific over large amounts of domain text, without PLMs through fine-tuning or pre-training from explicitly integrating domain-specific knowlscratch over domain corpora, such as BioBERT edge, which can be essential in many do(Lee et al., 2020), ClinicalBERT (Huang et al., mains. Moreover, in knowledge-sensitive ar2019), SciBERT (Beltagy et al., 2019), etc. eas such as the biomedical domain, knowledge is stored in multiple sources and forSince these PLMs are mostly pre-trained on mats, and existing bio"
2021.findings-emnlp.325,2021.naacl-main.139,0,0.0612129,"Missing"
2021.findings-emnlp.325,W19-5006,0,0.0830872,"a et al., 2020), and linguistic knowledge (Levine et al., 2020) are prioritized in these studies, while domain knowledge is somewhat underexplored (Michalopoulos • We propose a novel architecture that in- et al., 2020). corporates Diverse Adapters for Knowledge Biomedical NLP continues to be an active area of Integration (DAKI) into PLMs. It integrates research in the past few years. There have been sevdomain knowledge from multiple sources eral biomedical PLMs proposed and have proven adaptively via an attention-based knowledge to be successful in various domain tasks (Lee 3856 et al., 2020; Peng et al., 2019; Huang et al., 2019; Alsentzer et al., 2019). As variants of BERT (Devlin et al., 2019) in the biomedical domain, these PLMs are mostly pre-trained on large amounts of domain-specific corpora, such as the PubMed texts (Peng et al., 2019; Lee et al., 2020) and clinical notes (Huang et al., 2019; Alsentzer et al., 2019), and do not explicitly incorporate domain knowledge in the pre-training stage. This work differs from the aforementioned studies in that we are the first to integrate biomedical domain-specific knowledge from multiple sources into PLMs via an adapter-based architecture. The know"
2021.findings-emnlp.325,2020.repl4nlp-1.8,0,0.01704,"rve as off-the-shelf modules and can be used in a plug-and-play manner via DAKI. • Extensive experiments on different biomedical NLP tasks and datasets demonstrate the benefits of the proposed knowledge-specific adapters and DAKI. 2 Related Work This study is essentially related to two lines of research: knowledge integration for PLMs and domain-specific PLMs (biomedical PLMs in particular). There has been a surge of research on knowledge injection for PLMs in recent years (Yao et al., 2019; Zhang et al., 2019; Peters et al., 2019; Kim et al., 2020; Levine et al., 2020; Lauscher et al., 2020; Pereira et al., 2020; Sun et al., 2020; He et al., 2020a; Wang et al., 2021). These studies aim to integrate knowledge from an external knowledge source, e.g., Wikipedia, into PLMs by augmenting the training objective with a knowledge-driven regularization. As mentioned above, these methods are limited in the sense that they mostly focus on single-source knowledge, and require full model training. K-adapter (Wang et al., 2020) addresses some of these issues by introducing linguistic and factual adapters into RoBERTa, but the adapters are treated equally in their work. Also, general domain knowledge, such as factu"
2021.findings-emnlp.325,D19-1005,0,0.0203823,"es, and the semantic grouping information for biomedical concepts. Such adapters serve as off-the-shelf modules and can be used in a plug-and-play manner via DAKI. • Extensive experiments on different biomedical NLP tasks and datasets demonstrate the benefits of the proposed knowledge-specific adapters and DAKI. 2 Related Work This study is essentially related to two lines of research: knowledge integration for PLMs and domain-specific PLMs (biomedical PLMs in particular). There has been a surge of research on knowledge injection for PLMs in recent years (Yao et al., 2019; Zhang et al., 2019; Peters et al., 2019; Kim et al., 2020; Levine et al., 2020; Lauscher et al., 2020; Pereira et al., 2020; Sun et al., 2020; He et al., 2020a; Wang et al., 2021). These studies aim to integrate knowledge from an external knowledge source, e.g., Wikipedia, into PLMs by augmenting the training objective with a knowledge-driven regularization. As mentioned above, these methods are limited in the sense that they mostly focus on single-source knowledge, and require full model training. K-adapter (Wang et al., 2020) addresses some of these issues by introducing linguistic and factual adapters into RoBERTa, but the adapt"
2021.findings-emnlp.325,2021.eacl-main.39,0,0.0717324,"Missing"
2021.findings-emnlp.325,2020.emnlp-demos.7,0,0.0678637,"Missing"
2021.findings-emnlp.325,2020.tacl-1.54,0,0.0215667,"ar2019), SciBERT (Beltagy et al., 2019), etc. eas such as the biomedical domain, knowledge is stored in multiple sources and forSince these PLMs are mostly pre-trained on mats, and existing biomedical PLMs either neunstructured free texts, a common issue among glect them or utilize them in a limited manthe aforementioned general and domain-specific ner. In this work, we introduce an architecture PLMs is their lack of specific structured knowledge, to integrate domain knowledge from diverse which results in their incompetence on knowledgesources into PLMs in a parameter-efficient driven tasks (Rogers et al., 2020). For instance, way. More specifically, we propose to ensome studies point out PLMs are insufficient to code domain knowledge via adapters, which well capture factual knowledge from text (Poerner are small bottleneck feed-forward networks inserted between intermediate transformer layet al., 2019; Wang et al., 2020, 2021). ers in PLMs. These knowledge adapters are To enrich PLMs with external knowledge, some pre-trained for individual domain knowledge efforts have been made recently (Yao et al., 2019; sources and integrated via an attention-based Zhang et al., 2019; Kim et al., 2020; Levine et"
2021.findings-emnlp.325,D18-1187,0,0.0583882,"Missing"
2021.findings-emnlp.325,P19-1139,0,0.138075,"ter-efficient driven tasks (Rogers et al., 2020). For instance, way. More specifically, we propose to ensome studies point out PLMs are insufficient to code domain knowledge via adapters, which well capture factual knowledge from text (Poerner are small bottleneck feed-forward networks inserted between intermediate transformer layet al., 2019; Wang et al., 2020, 2021). ers in PLMs. These knowledge adapters are To enrich PLMs with external knowledge, some pre-trained for individual domain knowledge efforts have been made recently (Yao et al., 2019; sources and integrated via an attention-based Zhang et al., 2019; Kim et al., 2020; Levine et al., knowledge controller to enrich PLMs. Tak2020; Wang et al., 2021). A common theme ing the biomedical domain as a case study, we explore three knowledge-specific adapters among these approaches is the incorporation of for PLMs based on the UMLS Metathesaurus an auxiliary knowledge-driven training objective. graph, the Wikipedia articles for diseases, and For instance, KG-BERT (Yao et al., 2019) intethe semantic grouping information for biomedgrates world/factual knowledge from Wikipedia ical concepts. Extensive experiments on differvia knowledge graph completio"
2021.mrl-1.6,P98-1012,0,0.299182,"lopment data and the other half for unlabeled data in the language discriminators. Similarly for the testing on KBP 2017, articles in KBP 2016 will be used for development and unlabeled data. Finally, to focus the evaluation of cross-lingual transfer learning, we employ golden event mentions in documents in this work. Following (Choubey and Huang, 2018; Huang et al., 2019), we employ the official KBP 2017 scorer (version 1.8) to obtain the coreference resolution performance for models. This evaluation script reports common performance metrics for ECR, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998) and CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b) and Average CoNLL (the average of four prior metrics). Hyper-parameters for the models are fine-tuned by Average CoNLL scores over development data. The suggested values from the fine-tuning involve: 5e-5 for the learning rate with the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 512 for the numbers of hidden units in the middle layers of the feed-forward language discriminator D, D1 and D2 (selected from [64, 128, 256, 512, 1024]); 1 2 α = 0.1, αdisc = 0.1, αdisc = 0.1, αdiver = 0.01, αconst = 0.01 for the trade-off paramete"
2021.mrl-1.6,P19-1409,0,0.073484,"ata are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models"
2021.mrl-1.6,Q18-1039,0,0.160846,"wn and arrested Sohel Rana. When loudspeakers at the rescue site announced his capture, local news reports said, the crowd broke out in cheers. An ECR system in information extraction (IE) should be able to recognize the coreference of the two event mentions associated with the trigger words “arrested” and “capture” in this text. 62 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 62–73 November 11, 2021. ©2021 Association for Computational Linguistics model baselines? Treating the source and target languages as the source and target domains in domain adaptation (Chen et al., 2018a, 2019; Keung et al., 2019), one can borrow the popular technique of domain adversarial neural networks (DANN) (Ganin et al., 2016; Fu et al., 2017) to induce better language-general representations for ECR, called language adversarial neural networks (LANN) to make it consistent with our language generalization problem. As such, in addition to traditional learning objectives (e.g., cross-entropy), the key idea of LANN is to introduce a language discriminator that seeks to differentiate representation vectors for text inputs from the source and target languages. To enhance the language genera"
2021.mrl-1.6,W09-2209,0,0.0510269,"led set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b),"
2021.mrl-1.6,W09-3208,0,0.0364161,"led set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b),"
2021.mrl-1.6,2020.acl-main.478,0,0.0191807,"ithin-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbi"
2021.mrl-1.6,S18-2001,0,0.0169137,"while sentences in test data are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent"
2021.mrl-1.6,P19-4007,0,0.131857,"clear, our work considers zero-resource cross-lingual learning that requires no labeled data for ECR in the target languages as well as human or machine generated parallel text. The systems in this work only have access to unlabeled text in the target languages to aid the cross-lingual learning for ECR. To our knowledge, this is the first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new problem of cross-lingual transfer lea"
2021.mrl-1.6,D19-1138,0,0.025207,". When loudspeakers at the rescue site announced his capture, local news reports said, the crowd broke out in cheers. An ECR system in information extraction (IE) should be able to recognize the coreference of the two event mentions associated with the trigger words “arrested” and “capture” in this text. 62 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 62–73 November 11, 2021. ©2021 Association for Computational Linguistics model baselines? Treating the source and target languages as the source and target domains in domain adaptation (Chen et al., 2018a, 2019; Keung et al., 2019), one can borrow the popular technique of domain adversarial neural networks (DANN) (Ganin et al., 2016; Fu et al., 2017) to induce better language-general representations for ECR, called language adversarial neural networks (LANN) to make it consistent with our language generalization problem. As such, in addition to traditional learning objectives (e.g., cross-entropy), the key idea of LANN is to introduce a language discriminator that seeks to differentiate representation vectors for text inputs from the source and target languages. To enhance the language generalization, models will attemp"
2021.mrl-1.6,N19-1423,0,0.17832,"languages (target languages). To be clear, our work considers zero-resource cross-lingual learning that requires no labeled data for ECR in the target languages as well as human or machine generated parallel text. The systems in this work only have access to unlabeled text in the target languages to aid the cross-lingual learning for ECR. To our knowledge, this is the first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new p"
2021.mrl-1.6,P18-2063,0,0.0205673,"19; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Bas"
2021.mrl-1.6,D13-1203,0,0.0202485,"h network will be first aligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses on crosslingual transfer learning fo"
2021.mrl-1.6,D12-1045,0,0.448392,"he source language) while sentences in test data are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu"
2021.mrl-1.6,I17-2072,1,0.927029,"system in information extraction (IE) should be able to recognize the coreference of the two event mentions associated with the trigger words “arrested” and “capture” in this text. 62 Proceedings of the 1st Workshop on Multilingual Representation Learning, pages 62–73 November 11, 2021. ©2021 Association for Computational Linguistics model baselines? Treating the source and target languages as the source and target domains in domain adaptation (Chen et al., 2018a, 2019; Keung et al., 2019), one can borrow the popular technique of domain adversarial neural networks (DANN) (Ganin et al., 2016; Fu et al., 2017) to induce better language-general representations for ECR, called language adversarial neural networks (LANN) to make it consistent with our language generalization problem. As such, in addition to traditional learning objectives (e.g., cross-entropy), the key idea of LANN is to introduce a language discriminator that seeks to differentiate representation vectors for text inputs from the source and target languages. To enhance the language generalization, models will attempt to generate representation vectors so the language discriminator is fooled, i.e., its performance is minimized to align"
2021.mrl-1.6,D17-1018,0,0.0228789,"ligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses on crosslingual transfer learning for ECR where traini"
2021.mrl-1.6,D13-1037,0,0.0229113,"oubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation l"
2021.mrl-1.6,P17-1004,0,0.0179203,"ation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine"
2021.mrl-1.6,C16-1114,0,0.0268238,"Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et"
2021.mrl-1.6,liu-etal-2014-supervised,0,0.024526,"les. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et"
2021.mrl-1.6,N19-1085,0,0.185594,"e Resolution with Multi-view Alignment and Optimal Transport Duy Phung1 , Hieu Minh Tran1 , Minh Van Nguyen2 , and Thien Huu Nguyen2 1 VinAI Research, Vietnam 2 Dept. of Computer and Information Science, University of Oregon, Eugene, OR, USA {v.duypv1,v.hieutm4}@vinai.io, {minhnv,thien}@cs.uoregon.edu Abstract Prior work on ECR assumes the monolingual setting where training and test data are presented in the same languages. Current state-of-the-art ECR systems thus rely on large monolingual datasets to train advanced models (Nguyen et al., 2016; Choubey and Huang, 2018; Lu and Ng, 2017, 2018; Huang et al., 2019) that are only annotated for popular languages (e.g., English). As document annotation for ECR is an expensive process, porting ECR models for English to other languages is crucial and appealing to enhance the accessibility of ECR systems. To this end, this paper explores cross-lingual transfer learning for ECR where models are trained on annotated documents in English (source language) and tested on documents from other languages (target languages). To be clear, our work considers zero-resource cross-lingual learning that requires no labeled data for ECR in the target languages as well as hum"
2021.mrl-1.6,2021.emnlp-main.440,1,0.841117,"Missing"
2021.mrl-1.6,C16-1308,0,0.0147211,"al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and"
2021.mrl-1.6,H05-1004,0,0.0538389,"nlabeled data in the language discriminators. Similarly for the testing on KBP 2017, articles in KBP 2016 will be used for development and unlabeled data. Finally, to focus the evaluation of cross-lingual transfer learning, we employ golden event mentions in documents in this work. Following (Choubey and Huang, 2018; Huang et al., 2019), we employ the official KBP 2017 scorer (version 1.8) to obtain the coreference resolution performance for models. This evaluation script reports common performance metrics for ECR, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998) and CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b) and Average CoNLL (the average of four prior metrics). Hyper-parameters for the models are fine-tuned by Average CoNLL scores over development data. The suggested values from the fine-tuning involve: 5e-5 for the learning rate with the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 512 for the numbers of hidden units in the middle layers of the feed-forward language discriminator D, D1 and D2 (selected from [64, 128, 256, 512, 1024]); 1 2 α = 0.1, αdisc = 0.1, αdisc = 0.1, αdiver = 0.01, αconst = 0.01 for the trade-off parameters in the loss function"
2021.mrl-1.6,D16-1038,0,0.022258,"ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, incl"
2021.mrl-1.6,P15-1138,0,0.0171163,"uang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for tex"
2021.mrl-1.6,2021.textgraphs-1.4,1,0.759919,"another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016;"
2021.mrl-1.6,D10-1048,0,0.0357544,"ges. Representation vectors from each network will be first aligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses o"
2021.mrl-1.6,2020.acl-main.681,0,0.0228985,"Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Baseline Model As this is the first work on cross-lingual transfer learning for ECR, this section aims to establish a baseline method for further research. In particular, recent work has shown that multilingual pre-trained language models with deep stacks of transformer layers, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), can provide strong baselines with competitive performance for zer"
2021.mrl-1.6,N12-1090,0,0.0255098,"uyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-in"
2021.mrl-1.6,P10-1142,0,0.0376624,"s from each network will be first aligned between source and target languages using the usual LANN technique. In addition, representation vectors from the two networks will be regularized to agree with each other over same examples in target languages. As demonstrated later, this regularization helps to penalize the alignment between coreferring examples in the source language and non-coreferring exam2 Related Work Regarding coreference resolution, our work is related to studies in entity coreference resolution that aim to resolve nouns phrases/mentions for entities (Raghunathan et al., 2010; Ng, 2010; Durrett and Klein, 2013; Lee et al., 2017; Joshi et al., 2019). This work focuses on event coreference resolution that is often considered as a more challenging task than entity resolution due to the more complex 63 gers located at we1 and we2 in W (1 ≤ e1 < e2 ≤ n). As such, the core problem in ECR is to perform a binary prediction to determine whether two event mentions we1 and we2 refer to the same event or not. An example in our ECR task thus involves an input tuple X = (W, e1 , e2 ) and a binary output variable y to indicate the coreference of we1 and we2 . This work focuses on crosslin"
2021.mrl-1.6,D19-1030,0,0.0513258,"Missing"
2021.mrl-1.6,2021.findings-acl.351,1,0.741977,"., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Baseline Model As this is the first work on cross-lingual transfer learning for ECR, this section aims to establish a baseline method for further research. In particular, recent work has shown that multilingual pre-trained language models with deep stacks of transformer layers, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), can provide strong baselines with competitive performance for zero-shot cross-lingua"
2021.mrl-1.6,2021.eacl-demos.10,1,0.779685,"Missing"
2021.mrl-1.6,2021.acl-long.374,1,0.697118,"model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is d"
2021.mrl-1.6,2021.wanlp-1.27,1,0.840068,"Missing"
2021.mrl-1.6,W19-2806,0,0.016874,"2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmalis et al., 2016; Fu et al., 2017; Kumar et al., 2018; Naik and Rose, 2020; Ngo et al., 2021). Compared to such work, our work explores a new dimension of adversarial networks for language-invariant representation learning for texts in ECR. 3 3.1 Baseline Model As this is"
2021.mrl-1.6,M95-1005,0,0.552904,"2017 articles for the development data and the other half for unlabeled data in the language discriminators. Similarly for the testing on KBP 2017, articles in KBP 2016 will be used for development and unlabeled data. Finally, to focus the evaluation of cross-lingual transfer learning, we employ golden event mentions in documents in this work. Following (Choubey and Huang, 2018; Huang et al., 2019), we employ the official KBP 2017 scorer (version 1.8) to obtain the coreference resolution performance for models. This evaluation script reports common performance metrics for ECR, including MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998) and CEAF-e (Luo, 2005), BLANC (Lee et al., 2012b) and Average CoNLL (the average of four prior metrics). Hyper-parameters for the models are fine-tuned by Average CoNLL scores over development data. The suggested values from the fine-tuning involve: 5e-5 for the learning rate with the Adam optimizer (selected from [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]); 512 for the numbers of hidden units in the middle layers of the feed-forward language discriminator D, D1 and D2 (selected from [64, 128, 256, 512, 1024]); 1 2 α = 0.1, αdisc = 0.1, αdisc = 0.1, αdiver = 0.01, αconst ="
2021.mrl-1.6,C18-1099,0,0.0250727,"ic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et al., 2016; Bousmal"
2021.mrl-1.6,D19-1077,0,0.128205,"systems in this work only have access to unlabeled text in the target languages to aid the cross-lingual learning for ECR. To our knowledge, this is the first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new problem of cross-lingual transfer learning for event coreference resolution (ECR) where models trained on data from a source language are adapted for evaluations in different target languages. We introduce the first ba"
2021.mrl-1.6,2020.repl4nlp-1.16,0,0.0200621,"e first work on cross-lingual transfer learning for event coreference resolution in the literature. Recent advances in contextualized word embeddings have featured multilingual pre-trained language models, e.g., multilingual BERT (Devlin et al., 2019), XLM-RoBERTa (Conneau et al., 2019), that overcome the vocabulary difference of languages and produce language-universal representations for cross-lingual transfer learning in different NLP tasks (Wu and Dredze, 2019; Subburathinam et al., 2019a). In fact, such pre-trained language models have set a new standard for multilingual learning in NLP (Wu and Dredze, 2020; Nguyen et al., 2021a), serving as the baseline models for our cross-lingual transfer learning problem for ECR in this work. How can we improve the cross-lingual performance of ECR models over multilingual language We study a new problem of cross-lingual transfer learning for event coreference resolution (ECR) where models trained on data from a source language are adapted for evaluations in different target languages. We introduce the first baseline model for this task based on XLM-RoBERTa, a state-of-the-art multilingual pre-trained language model. We also explore language adversarial neura"
2021.mrl-1.6,Q15-1037,0,0.0191121,"work focuses on crosslingual transfer learning for ECR where training data involve input documents W in English (the source language) while sentences in test data are presented in another language (the target language). To enable the zero-resource cross-lingual setting for ECR, our model takes two following inputs: Dsrc = {(Xi = (W i , ei1 , ei2 ), yi )}i=1..Nsrc as the training set with Nsrc labeled examples in the source language (English), and Dtar = {Xi = (W i , ei1 , ei2 )}i=Nsrc +1..Nsrc +Ntar as the unlabeled set in the target language with Ntar examples. structures of event mentions (Yang et al., 2015). For event coreference resolution, although there have been works on cross-document resolution (Lee et al., 2012a; Kenyon-Dean et al., 2018; Barhom et al., 2019; Phung et al., 2021), this work is more related to prior work on within-document ECR (Lu and Ng, 2018; Tran et al., 2021). In particular, previous within-document ECR methods have applied feature-based models for pairwise classifiers (Ahn, 2006; Chen et al., 2009; Cybulska and Vossen, 2015; Peng et al., 2016), spectral graph clustering (Chen and Ji, 2009b), information propagation (Liu et al., 2014), markov logic networks (Lu et al.,"
2021.mrl-1.6,C18-1037,0,0.0264128,"2014), markov logic networks (Lu et al., 2016), end-to-end modeling with event detection (Araki and Mitamura, 2015; Lu et al., 2016; Chen and Ng, 2016; Lu and Ng, 2017), and recent deep learning models (Nguyen et al., 2016; Choubey and Huang, 2018; Huang et al., 2019; Choubey et al., 2020; Tran et al., 2021). Our work is different from such prior work as we investigate a novel setting of cross-lingual transfer learning for ECR. Cross-lingual transfer learning has been studied for other NLP and IE tasks, including sentiment analysis (Chen et al., 2018b), relation extraction (Lin et al., 2017; Zou et al., 2018; Wang et al., 2018; Nguyen and Nguyen, 2021), event extraction (Chen and Ji, 2009a; Hsi et al., 2016; Subburathinam et al., 2019b; Nguyen et al., 2021b), and entity coreference resolution (Rahman and Ng, 2012; Hardmeier et al., 2013; Martins, 2015; Kundu et al., 2018; Urbizu et al., 2019). Compared to such prior work, this paper presents two novel approaches to improve the language generalization of representation vectors based on multi-view alignment and OT. Finally, our work involves LANN that bears some similarity with DANN models in domain adaptation research of machine learning (Ganin et"
2021.naacl-main.273,D14-1159,0,0.0616023,"Missing"
2021.naacl-main.273,2020.acl-main.95,0,0.020488,") for the nodes in N . To this end, we propose to utilize WordNet (Miller, 1995), a rich knowledge base for word meanings, to obtain external knowledge for the words in D. As such, WordNet involves a network of word meanings (i.e., synsets) that are connected to each other via various semantic relations (e.g., synonyms, hyponyms). Our first step to generate knowledge-based similarity scores involves mapping each word node ni ∈ D ∩ N to a synset node Mi in WordNet using a Word Sense Disambiguation (WSD) tool. In particular, we employ WordNet 3.0 and the stateof-the-art BERT-based WSD model in (Blevins and Zettlemoyer, 2020) to perform the word-synset mapping in this work. Afterward, we compute a knowledge-based similarity score astruct for each ij pair of word nodes ni and nj in D ∩ N using the structure-based similarity of their linked synsets Mi and Mj in WordNet (i.e., astruct = 0 if eiij ther ni or nj is not a word node in D ∩ N ). Accordingly, the Lin similarity measure (Lin et al., 1998) for synset nodes in WordNet is utilized for 2∗IC(LCS(Mi ,Mj )) this purpose: astruct = IC(Mi )+IC(M , where ij j) IC and LCS amount to the information content of synset nodes and the least common subsumer of two synsets in"
2021.naacl-main.273,W17-2711,0,0.262413,"mance for this task (Kadowaki et al., 2019; Liu et al., 2020). Despite the good performance, the existing deep learning methods for ECI are limited in that they only model the context at the sentence level, assuming the event mention pairs of interest to be in the same sentences (i.e., intra-sentence setting). On the one hand, this assumption fails to cover the inter-sentence scenario where the input pairs of event mentions can appear in different sentences in 1 Introduction the documents, e.g., in the recent EventStoryLine Event Causality Identification (ECI) is an important dataset for ECI (Caselli and Vossen, 2017). On the problem in Information Extraction that seeks to pre- other hand, the sole modeling of sentence context dict causal relation between a pair of events men- cannot benefit from the document-level informationed in text. For instance, in the sentence “The tion that can provide useful evidence to facilitate building was nearly destroyed by a fire early Tues- the causality prediction for events. An example day morning.”, an ECI system should be able to rec- can be seen in Figure 1 where the interested pair ognize the causal relation between the two events of event mentions involves damaged2"
2021.naacl-main.273,P17-2001,0,0.158003,"th small a causal relation respectively). Following (Gao weights/scores assigned by the learning process et al., 2018), we group documents according to in A are mostly noisy edges and should have mini- their topics and put the topics in the order based mal contribution to the induced representation vec- on their topic IDs. The documents in the last two tors. To this end, we propose to obtain a sparser topics are used for the development data while the version G 0 of G where edges with small weights remaining 20 documents are employed for a 5-fold 3484 Model OP (Caselli and Vossen, 2017) LSTM (Cheng and Miyao, 2017) Seq (Choubey and Huang, 2017) KnowDis* (Zuo et al., 2020) LR+ (Gao et al., 2019) LIP (Gao et al., 2019) BERT* (our implementation) Know* (Liu et al., 2020) RichGCN* (proposed) Intra-sentence P R F1 22.5 98.6 36.6 34.0 41.5 37.4 32.7 44.9 37.8 39.7 66.5 49.7 37.0 45.2 40.7 38.8 52.4 44.6 39.2 49.3 43.7 41.9 62.5 50.1 49.2 63.0 55.2 Inter-sentence P R F1 8.4 99.5 15.6 13.5 30.3 18.7 11.3 29.5 16.4 25.2 48.1 33.1 35.1 48.2 40.6 22.3 29.2 25.3 39.2 45.7 42.2 Intra + Inter P R F1 10.5 99.2 19.0 17.6 33.9 23.2 15.5 34.3 21.4 27.9 47.2 35.1 36.2 49.5 41.9 27.3 35.3 30.8 42.6 51.3 46.6 Table 1: Model"
2021.naacl-main.273,D17-1190,0,0.0662728,"Missing"
2021.naacl-main.273,D19-1498,0,0.0605125,"Missing"
2021.naacl-main.273,N19-1423,0,0.025429,"vated by our example in Figure to transform the words into representation vectors, 3481 tially far away from each other in D. As presented in the introduction, three types of information are exploited to design the edges E (or compute the interaction scores aij ) for G in our model, including the discourse-based, syntax-based and semantic2.1 Document Encoder based information. In the first step, we transform each word wi ∈ D Discourse-based Edges: As the input document into a representation vector xi using the contex- D can involve multiple sentences and event/entity tualized embeddings BERT (Devlin et al., 2019) mentions, understanding where they span and how (i.e., the BERTbase version). In particular, as BERT they relate to each other is crucial to effectively might split wi into several word-pieces, we employ encode the document for DECI. As such, we prothe average of the hidden vectors for the word- pose to exploit three types of discourse information pieces of wi in the last layer of BERT as the rep- to obtain the interaction graph G for D, i.e., the resentation vector xi for wi . To handle long docu- sentence boundary, the coreference structure, and ments with BERT, we divide D into segments of"
2021.naacl-main.273,D11-1027,0,0.105914,"gits applications for a wide range of problems in ing to predict causal relation in this case due to the natural language processing (NLP), including ma- long distance and the appearance of many irrelechine reading comprehension (Berant et al., 2014), vant words between damaged2 and quake2 in the future event forecasting (Hashimoto, 2019), and sentence. However, if a system relies on documentwhy-question answering (Oh et al., 2016). level information and recognizes the coreference The early approach for ECI has involved feature- of the event mention pairs (damaged2 , damaged1 ) based methods (Do et al., 2011; Hashimoto, 2019; and (quake2 , quake1 ), it can exploit the clear ev3480 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3480–3490 June 6–11, 2021. ©2021 Association for Computational Linguistics idence of “damaged1 due to the quake1 ” to infer the causal relation for damaged2 and quake2 . To fill this gap, this work aims to develop a deep learning model for document-level ECI (DECI) where input event mentions can reside in different sentences of an input document. As such, a major challenge"
2021.naacl-main.273,N19-1179,0,0.0679775,"w concentrating on searching for people who may be trapped under the rubble,&quot; said Rusli M . Saleh, the deputy district chief of Bener Meriah. He said at least 25 of the injured in his district were hospitalized in intensive care. As the quake hit, villagers in the area ran out of their homes in panic and screamed for help. &quot;I see many houses were damaged2 and their roofs fell onto some people,&quot; Bensu Elianita , a 22-year-old resident of Bukit Sama village in Central Aceh district, said shortly after the quake2 hit. … coreference Figure 1: An example for document-level ECI. Ning et al., 2018; Gao et al., 2019) while the recent approach has examined deep learning methods to deliver state-of-the-art performance for this task (Kadowaki et al., 2019; Liu et al., 2020). Despite the good performance, the existing deep learning methods for ECI are limited in that they only model the context at the sentence level, assuming the event mention pairs of interest to be in the same sentences (i.e., intra-sentence setting). On the one hand, this assumption fails to cover the inter-sentence scenario where the input pairs of event mentions can appear in different sentences in 1 Introduction the documents, e.g., in"
2021.naacl-main.273,P18-1086,0,0.0417122,"Missing"
2021.naacl-main.273,D19-1296,0,0.0445595,"between the two events of event mentions involves damaged2 and quake2 triggered by “destroyed” and “fire” (called event in the last (green) sentence. A system that only cause mentions), i.e., “fire” −−−→ “destroyed”. ECI finds considers sentence context might find it challengits applications for a wide range of problems in ing to predict causal relation in this case due to the natural language processing (NLP), including ma- long distance and the appearance of many irrelechine reading comprehension (Berant et al., 2014), vant words between damaged2 and quake2 in the future event forecasting (Hashimoto, 2019), and sentence. However, if a system relies on documentwhy-question answering (Oh et al., 2016). level information and recognizes the coreference The early approach for ECI has involved feature- of the event mention pairs (damaged2 , damaged1 ) based methods (Do et al., 2011; Hashimoto, 2019; and (quake2 , quake1 ), it can exploit the clear ev3480 Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3480–3490 June 6–11, 2021. ©2021 Association for Computational Linguistics idence of “damaged1 due t"
2021.naacl-main.273,P16-1135,0,0.0150633,"uce several information sources to enrich the interaction graphs based on discourse, syntax, and semantic information. The experiments confirm the effectiveness of the proposed information sources and models for DECI. In the future, we plan to extend our model to other related tasks, e.g., event coreference resolution (Nguyen et al., 2016). The early feature-based methods for ECI has explored different features and resources to improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “because”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal Acknowledgments patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), This research has been supported by the Army Reand weakly supervised data (Hashimoto, 2019). Al- search Office (ARO) grant W911NF-21-1-0112. though we also apply related features and resource This research is also based upon work supported by for ECI (e.g., syntax, WordNet), our model em- the Office of the Director of National Intelligence ploys such resources to build in"
2021.naacl-main.273,W17-2708,0,0.0178973,"c information. The experiments confirm the effectiveness of the proposed information sources and models for DECI. In the future, we plan to extend our model to other related tasks, e.g., event coreference resolution (Nguyen et al., 2016). The early feature-based methods for ECI has explored different features and resources to improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “because”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal Acknowledgments patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), This research has been supported by the Army Reand weakly supervised data (Hashimoto, 2019). Al- search Office (ARO) grant W911NF-21-1-0112. though we also apply related features and resource This research is also based upon work supported by for ECI (e.g., syntax, WordNet), our model em- the Office of the Director of National Intelligence ploys such resources to build interaction graphs (ODNI), Intelligence Advanced Research Projects for documents to induce more ab"
2021.naacl-main.273,D19-1590,0,0.0117775,"Meriah. He said at least 25 of the injured in his district were hospitalized in intensive care. As the quake hit, villagers in the area ran out of their homes in panic and screamed for help. &quot;I see many houses were damaged2 and their roofs fell onto some people,&quot; Bensu Elianita , a 22-year-old resident of Bukit Sama village in Central Aceh district, said shortly after the quake2 hit. … coreference Figure 1: An example for document-level ECI. Ning et al., 2018; Gao et al., 2019) while the recent approach has examined deep learning methods to deliver state-of-the-art performance for this task (Kadowaki et al., 2019; Liu et al., 2020). Despite the good performance, the existing deep learning methods for ECI are limited in that they only model the context at the sentence level, assuming the event mention pairs of interest to be in the same sentences (i.e., intra-sentence setting). On the one hand, this assumption fails to cover the inter-sentence scenario where the input pairs of event mentions can appear in different sentences in 1 Introduction the documents, e.g., in the recent EventStoryLine Event Causality Identification (ECI) is an important dataset for ECI (Caselli and Vossen, 2017). On the problem"
2021.naacl-main.273,2020.findings-emnlp.326,1,0.653441,"Missing"
2021.naacl-main.273,W13-4004,0,0.0177505,"the future, we plan to extend our model to other related tasks, e.g., event coreference resolution (Nguyen et al., 2016). The early feature-based methods for ECI has explored different features and resources to improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “because”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal Acknowledgments patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), This research has been supported by the Army Reand weakly supervised data (Hashimoto, 2019). Al- search Office (ARO) grant W911NF-21-1-0112. though we also apply related features and resource This research is also based upon work supported by for ECI (e.g., syntax, WordNet), our model em- the Office of the Director of National Intelligence ploys such resources to build interaction graphs (ODNI), Intelligence Advanced Research Projects for documents to induce more abstract represen- Activity (IARPA), via IARPA Contract No. 2019tations with GCNs. Recently, deep learning has 19051600006"
2021.naacl-main.273,P14-3002,0,0.412995,"4.6 39.2 49.3 43.7 41.9 62.5 50.1 49.2 63.0 55.2 Inter-sentence P R F1 8.4 99.5 15.6 13.5 30.3 18.7 11.3 29.5 16.4 25.2 48.1 33.1 35.1 48.2 40.6 22.3 29.2 25.3 39.2 45.7 42.2 Intra + Inter P R F1 10.5 99.2 19.0 17.6 33.9 23.2 15.5 34.3 21.4 27.9 47.2 35.1 36.2 49.5 41.9 27.3 35.3 30.8 42.6 51.3 46.6 Table 1: Model’s performance on EventStoryLine. The performance improvement of RichGCN over the baselines is significant with p &lt; 0.01. * designates models that use BERT embeddings. cross-validation evaluation, using the same data split in (Gao et al., 2019; Liu et al., 2020). For Causal-TimeBank (Mirza, 2014a), this dataset consists of 184 documents, 6813 events, and 318 of 7608 event mention pairs annotated with a causal relations. Following (Liu et al., 2020), we do a 10-fold cross-validation evaluation using the same data split for this dataset. Note that as in (Liu et al., 2020), we only evaluate the ECI performance for intra-sentence events in Causal-TimeBank as the number of inter-sentence event mention pairs with the causal relation is very small (i.e., only 18 pairs). We tune the hyperparameters for our model on the development data of EventStoryLine and use the chosen parameters to train"
2021.naacl-main.273,2020.acl-main.141,0,0.096944,"Missing"
2021.naacl-main.273,2021.wanlp-1.27,1,0.840296,"Missing"
2021.naacl-main.273,P18-1212,0,0.168834,"Missing"
2021.naacl-main.273,W14-4322,0,0.0234162,"l prediction. We introduce several information sources to enrich the interaction graphs based on discourse, syntax, and semantic information. The experiments confirm the effectiveness of the proposed information sources and models for DECI. In the future, we plan to extend our model to other related tasks, e.g., event coreference resolution (Nguyen et al., 2016). The early feature-based methods for ECI has explored different features and resources to improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “because”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal Acknowledgments patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), This research has been supported by the Army Reand weakly supervised data (Hashimoto, 2019). Al- search Office (ARO) grant W911NF-21-1-0112. though we also apply related features and resource This research is also based upon work supported by for ECI (e.g., syntax, WordNet), our model em- the Office of the Director of National Intelligence ploys"
2021.naacl-main.273,W14-0707,0,0.0230049,"l prediction. We introduce several information sources to enrich the interaction graphs based on discourse, syntax, and semantic information. The experiments confirm the effectiveness of the proposed information sources and models for DECI. In the future, we plan to extend our model to other related tasks, e.g., event coreference resolution (Nguyen et al., 2016). The early feature-based methods for ECI has explored different features and resources to improve the performance, including lexical and syntactic patterns (Hashimoto, 2019; Gao et al., 2019), causality cues/markers (e.g., “because”) (Riaz and Girju, 2014a; Hidey and McKeown, 2016), statistical co-occurrence of events (Beamer and Girju, 2009; Do et al., 2011; Hu et al., 2017), temporal Acknowledgments patterns (Mirza, 2014a; Ning et al., 2018), lexical semantics of events (Riaz and Girju, 2013, 2014b), This research has been supported by the Army Reand weakly supervised data (Hashimoto, 2019). Al- search Office (ARO) grant W911NF-21-1-0112. though we also apply related features and resource This research is also based upon work supported by for ECI (e.g., syntax, WordNet), our model em- the Office of the Director of National Intelligence ploys"
2021.naacl-main.273,2020.findings-emnlp.409,1,0.647378,"Missing"
2021.naacl-main.273,2020.coling-main.135,0,0.284862,"s/scores assigned by the learning process et al., 2018), we group documents according to in A are mostly noisy edges and should have mini- their topics and put the topics in the order based mal contribution to the induced representation vec- on their topic IDs. The documents in the last two tors. To this end, we propose to obtain a sparser topics are used for the development data while the version G 0 of G where edges with small weights remaining 20 documents are employed for a 5-fold 3484 Model OP (Caselli and Vossen, 2017) LSTM (Cheng and Miyao, 2017) Seq (Choubey and Huang, 2017) KnowDis* (Zuo et al., 2020) LR+ (Gao et al., 2019) LIP (Gao et al., 2019) BERT* (our implementation) Know* (Liu et al., 2020) RichGCN* (proposed) Intra-sentence P R F1 22.5 98.6 36.6 34.0 41.5 37.4 32.7 44.9 37.8 39.7 66.5 49.7 37.0 45.2 40.7 38.8 52.4 44.6 39.2 49.3 43.7 41.9 62.5 50.1 49.2 63.0 55.2 Inter-sentence P R F1 8.4 99.5 15.6 13.5 30.3 18.7 11.3 29.5 16.4 25.2 48.1 33.1 35.1 48.2 40.6 22.3 29.2 25.3 39.2 45.7 42.2 Intra + Inter P R F1 10.5 99.2 19.0 17.6 33.9 23.2 15.5 34.3 21.4 27.9 47.2 35.1 36.2 49.5 41.9 27.3 35.3 30.8 42.6 51.3 46.6 Table 1: Model’s performance on EventStoryLine. The performance improvem"
2021.naacl-main.273,P19-1432,1,0.813278,"Missing"
2021.naacl-main.3,2020.emnlp-main.435,1,0.644727,"instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from"
2021.naacl-main.3,D18-1307,0,0.038813,"Missing"
2021.naacl-main.3,P15-1017,0,0.34431,"uires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For ins"
2021.naacl-main.3,D14-1198,0,0.0438891,"Missing"
2021.naacl-main.3,Q16-1026,0,0.0399163,"only three possible values (i.e., B, I, and O) for the tags of the words. In particular, following (Lin et al., 2020), we first feed w into the pre-trained BERT encoder (Devlin et al., 2019) to obtain a sequence of vectors X = [x1 , x2 , . . . , xn ] to represent w. Here, each vector xi serves as the representation vector for the word wi ∈ w that is obtained by averaging the hidden vectors of the word-pieces of wi returned by BERT. Afterward, X is fed into two conditional random field (CRF) layers to determine the best BIO tag sequences for event mentions and event triggers for w, following (Chiu and Nichols, 2016). As such, the Viterbi algorithm is used to decode the input sentence while the negative log-likelihood losses are employed as the training objectives for the span detection component of the model. For trg convenience, let Lent span and Lspan be the negative log-likelihoods of the gold tag sequences for entity mentions and event triggers (respectively) for w. These terms will be included in the overall loss function of the model later. 3.2 tasks. As such, the prediction instances for EME and ETD, called entity and trigger instances, correspond directly to the entity mentions and event triggers"
2021.naacl-main.3,P13-1008,0,0.750015,"viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from the dependency that the Victim of a Die event has a high chance to Introduction Information Extraction (IE) is an important and challenging task in Natural Language Processing (NLP) that aims to extract structured inform"
2021.naacl-main.3,N19-1423,0,0.0383325,"nt triggers in w that would be used to form the nodes in the interaction graph between different instances of our four IE tasks for w. As such, we formulate the span detection 29 problems as sequence labeling tasks where each word wi in w is associated with two BIO tags to capture the span information for entity mentions and event triggers in w. Note that we do not predict entity types and event types at this step, leading to only three possible values (i.e., B, I, and O) for the tags of the words. In particular, following (Lin et al., 2020), we first feed w into the pre-trained BERT encoder (Devlin et al., 2019) to obtain a sequence of vectors X = [x1 , x2 , . . . , xn ] to represent w. Here, each vector xi serves as the representation vector for the word wi ∈ w that is obtained by averaging the hidden vectors of the word-pieces of wi returned by BERT. Afterward, X is fed into two conditional random field (CRF) layers to determine the best BIO tag sequences for event mentions and event triggers for w, following (Chiu and Nichols, 2016). As such, the Viterbi algorithm is used to decode the input sentence while the negative log-likelihood losses are employed as the training objectives for the span dete"
2021.naacl-main.3,2020.acl-main.713,0,0.126095,"onsidered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent work has considered joint four-task IE, using deep learning to produce state-of-the-art (SOTA) performance for the tasks (Wadden et al., 2019; Lin et al., 2020). However, there are still two problems that hinder further improvement of such models. First, at the instance level, an important component of deep learning models for joint IE involves the representation vectors of the instances that are used to perform the corresponding prediction tasks for IE in an input sentence (called predictive instance representations). For joint fourtask IE, we argue that there are inter-dependencies between predictive representation vectors of related instances for the four tasks that should be modeled to improve the performance for IE. For instance, the entity type"
2021.naacl-main.3,P19-1136,0,0.0325797,"Missing"
2021.naacl-main.3,N19-1308,0,0.0429031,"Missing"
2021.naacl-main.3,P16-1105,0,0.0240636,"turing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent work has considered joint four-task IE, using deep learning to produce state-of-the"
2021.naacl-main.3,D19-1041,0,0.0828176,"Missing"
2021.naacl-main.3,D14-1200,0,0.184343,"r instances of the four tasks. At the label level, GCNtype is responsible for capturing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent wo"
2021.naacl-main.3,N16-1034,1,0.946838,"Missing"
2021.naacl-main.3,C16-1215,0,0.0374214,"Missing"
2021.naacl-main.3,P15-2060,1,0.901627,"s). First, at the instance level, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence"
2021.naacl-main.3,P17-1085,0,0.0461339,"Missing"
2021.naacl-main.3,W15-1506,1,0.809111,"s). First, at the instance level, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence"
2021.naacl-main.3,N16-1033,0,0.28193,"tasks. At the label level, GCNtype is responsible for capturing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issues of prior joint IE work. Few recent work has considered joint fo"
2021.naacl-main.3,W09-1406,0,0.0516797,"t of Defense, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. This document does not contain technology or technical data controlled under either the U.S. International Traffic in Arms Regulations or the U.S. Export Administration Regulations. The early joint methods for IE have employed feature engineering to capture the dependencies between IE tasks, including Integer Linear Programming for Global Constraints (Roth and Yih, 2004; Li et al., 2011), Markov Logic Networks (Riedel et al., 2009; Venugopal et al., 2014), Structured Perceptron (Li et al., 2013, 2014; Miwa and Sasaki, 2014; Judea and Strube, 2016), and Graphical Models (Yu and Lam, 2010; Yang and Mitchell, 2016). Recently, the application of deep learning has facilitated the joint modeling for IE via shared parameter mechanisms across tasks. These joint models have focused on different subsets of the IE tasks, including EME and RE (Zheng et al., 2017; Katiyar and Cardie, 2017; Bekoulis et al., 2018; Fu et al., 2019; Luan et al., 2019; Sun et al., 2019; Veyseh et al., 2020b,a), event and temporal RE (Han et al., 2019),"
2021.naacl-main.3,C10-2160,0,0.0916288,"Missing"
2021.naacl-main.3,W04-2401,0,0.583024,"used to enrich the representations for instances of the four tasks. At the label level, GCNtype is responsible for capturing the connections between the types in the dependency graphs, thus helping the model learn the structural difference between the gold graph Ggold and the predicted graph Gpred . also be the Victim of an Attack event in the same sentence (i.e., type or label dependencies). To address these issues, some prior work has explored joint inference models where multiple tasks of IE are performed simultaneously for all task instances in a sentence, using both feature-based models (Roth and Yih, 2004; Li et al., 2013; Miwa and Sasaki, 2014; Yang and Mitchell, 2016) and recent deep learning models (Miwa and Bansal, 2016; Zhang et al., 2019). However, such prior work has mostly considered joint models for a subset of the four IE tasks (e.g., EME+RE or ETD+EAE), thus still suffering from the error propagation issue (with the missing tasks) and failing to fully exploit potential inter-dependencies between the four tasks. To this end, this work aims to design a single model to simultaneously solve the four IE tasks for each input sentence (joint four-task IE) to address the aforementioned issu"
2021.naacl-main.3,W15-3904,0,0.0321291,"evel, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance fo"
2021.naacl-main.3,P17-1113,0,0.0411689,"Missing"
2021.naacl-main.3,P19-1131,0,0.0435976,"Missing"
2021.naacl-main.3,P05-1053,0,0.107816,"s. prediction models). First, at the instance level, each IE task often requires predictions/classifications for multiple instances in a single input sentence. For instance, in RE, one often needs to predict relations for every pair of entity mentions (called relation instances) in the sentence while multiple word spans in the sentence can be viewed as multiple instances where event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencie"
2021.naacl-main.3,D14-1090,0,0.0263154,"U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein. This document does not contain technology or technical data controlled under either the U.S. International Traffic in Arms Regulations or the U.S. Export Administration Regulations. The early joint methods for IE have employed feature engineering to capture the dependencies between IE tasks, including Integer Linear Programming for Global Constraints (Roth and Yih, 2004; Li et al., 2011), Markov Logic Networks (Riedel et al., 2009; Venugopal et al., 2014), Structured Perceptron (Li et al., 2013, 2014; Miwa and Sasaki, 2014; Judea and Strube, 2016), and Graphical Models (Yu and Lam, 2010; Yang and Mitchell, 2016). Recently, the application of deep learning has facilitated the joint modeling for IE via shared parameter mechanisms across tasks. These joint models have focused on different subsets of the IE tasks, including EME and RE (Zheng et al., 2017; Katiyar and Cardie, 2017; Bekoulis et al., 2018; Fu et al., 2019; Luan et al., 2019; Sun et al., 2019; Veyseh et al., 2020b,a), event and temporal RE (Han et al., 2019), and ETD and EAE (Nguyen e"
2021.naacl-main.3,2020.acl-main.715,1,0.836939,"event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from the dependency that the Victim of a Die event has a high chance to Introduction Information Extraction (IE) is an important and challenging task in Natural Language Processing (NLP) that aims to extract structured information from unstructured texts. Following"
2021.naacl-main.3,2020.findings-emnlp.326,1,0.856589,"event type predictions have to be made in ETD (trigger instances). As such, most prior work on IE has performed predictions for instances in a sentence separately by treating each instance as one example in the dataset (Zhou et al., 2005; Nguyen and Grishman, 2015a; Santos and Guimaraes, 2015; Chen et al., 2015; Nguyen and Grishman, 2015b; Lai et al., 2020). Second, at the task level, prior work on IE tends to perform the four tasks in a pipelined approach where outputs from one task are used as inputs for other tasks (e.g., EAE is followed by EME and ETD) (Li et al., 2013; Chen et al., 2015; Veyseh et al., 2020c). Despite its popularity, the main issue of the independent prediction models is that they suffer from the error propagation between tasks and the failure to exploit the cross-task and cross-instance interdependencies within an input sentence to improve the performance for IE tasks. For instance, such systems are unable to benefit from the dependency that the Victim of a Die event has a high chance to Introduction Information Extraction (IE) is an important and challenging task in Natural Language Processing (NLP) that aims to extract structured information from unstructured texts. Following"
2021.semeval-1.47,2021.semeval-1.38,0,0.0385065,"quantity (i.e., [QT]), measured property (i.e., [PR]) and qualifier (i.e., [QL]) (best viewed in color). Introduction One of the key indicators of scientific writing is the quantities description of various experiments and results. While the mentions of all measurements could provide a rigorous understanding of the topic, it might make the reading and automatic processing of the text more difficult. As such, designing effective methods to recognize the mentions of measurements and also the conditions in which they are valid is necessary. According to the definition of the SemEval 2021 Task 8 (Harper et al., 2021), a measurement might consist of the following components: (i) Measure Entity: A span referring to an entity that one of its properties has been measured and its value is provided in the document; (ii) Measured Property: A span referring to the characteristics of an entity that has been measured; (iii) Quantity: A span in the document that refers to a value and possibly it comes with a unit; and (iv) Qualifier: A span referring to a condition in which more information about the Quantity, Measured Property or Measured Entity is provided. Figure 1 shows a sample document annotated with the afore"
2021.semeval-1.47,S18-1127,1,0.901263,"Missing"
2021.semeval-1.47,S17-2171,1,0.843726,"en the path representation, i.e., hp , and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to pr"
2021.semeval-1.47,2020.acl-main.141,0,0.0121964,"ods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed a novel regularization method based on Information Bottleneck to exclude noisy information from the input. Our experiments on the SemEval 2021 Task 8 reveal the effectiveness of the proposed model. 401 Acknowledgments This research has been supported by the Army Research Office (ARO) grant W911NF-21-1-0112. This research is also bas"
2021.semeval-1.47,P14-2012,1,0.802966,"the regularization component. However, instead of using Information Bottleneck, it directly decreases the similarity between the path representation, i.e., hp , and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE"
2021.semeval-1.47,P15-1062,1,0.8271,"t. However, instead of using Information Bottleneck, it directly decreases the similarity between the path representation, i.e., hp , and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced"
2021.semeval-1.47,D19-6203,1,0.812798,"and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measuremen"
2021.semeval-1.47,Q17-1008,0,0.0122545,"shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed a novel regularization method based on Information Bottleneck to exclude noisy information from the in"
2021.semeval-1.47,D18-1246,0,0.0329273,"onents of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed a novel regularization method based on Information Bottleneck to exclude noisy information from the input. Our experiment"
2021.semeval-1.47,P11-1053,0,0.0383277,"d model preserves the regularization component. However, instead of using Information Bottleneck, it directly decreases the similarity between the path representation, i.e., hp , and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We propos"
2021.semeval-1.47,2020.acl-main.715,1,0.693326,"i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed"
2021.semeval-1.47,P16-1123,0,0.0375449,"Missing"
2021.semeval-1.47,D15-1206,0,0.0294848,"sed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed a novel regularization method based on Information Bottleneck to exclude noisy information from the input. Our experiments on the SemEval"
2021.semeval-1.47,P15-2047,0,0.0218897,"Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed a novel regularization method based on Information Bottleneck to exclude noisy information from the input. Our experiments on the SemEval 2021 Task 8 reveal"
2021.semeval-1.47,P16-1105,0,0.0263793,"Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed a novel regularization method based on Information Bottleneck to exclude noisy information from the input. Our experiments on the SemEval 2021 Task 8 reveal the effectiveness of t"
2021.semeval-1.47,C14-1220,0,0.0382041,"irectly decreases the similarity between the path representation, i.e., hp , and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which"
2021.semeval-1.47,D18-1244,0,0.0123771,"on of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation between two measurement components. Furthermore, we proposed a novel regularization method based on Information Bottleneck to exclude noisy information from the input. Our experiments on the SemEval 2021 Task 8 reveal the effectiveness of the proposed model. 401 Acknowledgments This resea"
2021.semeval-1.47,D17-1004,0,0.0131131,"entation, i.e., hp , and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Conclusion We proposed a new model for the MRE task. The introduced model employs a dynamic path reasoning component which induces important context words to predict the relation b"
2021.semeval-1.47,P05-1053,0,0.0670348,"lldot , this ablated model preserves the regularization component. However, instead of using Information Bottleneck, it directly decreases the similarity between the path representation, i.e., hp , and the input document representation, i.e., hd , by replacing the Ldisc by Ldot = hp · hd . The results are presented in Table 2. This table shows that all components of the proposed model Related Work Measurement Relation Extraction (MRE) is one specific formulation of the general Relation Extraction (RE) task. In the literature, RE has been tackled by feature-based methods (Zelenko et al., 2003; Zhou et al., 2005; Sun et al., 2011; Nguyen and Grishman, 2014; Nguyen et al., 2015c) and advanced deep learning models (Zeng et al., 2014; Wang et al., 2016; Lee et al., 2017; Zhang et al., 2017; Nguyen et al., 2019; Jin et al., 2018; Veyseh et al., 2020b). Recently, structure-aware deep models have shown significant improvement for RE (Peng et al., 2017; Song et al., 2018; Xu et al., 2015; Liu et al., 2015; Miwa and Bansal, 2016; Nguyen and Grishman, 2018a; Zhang et al., 2018). For a thorough review of the prior works, refer to the recent work (Gupta et al., 2019; Nan et al., 2020; Veyseh et al., 2020a) 5 Co"
2021.textgraphs-1.4,J14-2004,0,0.0230399,"hn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us involve the joint models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target"
2021.textgraphs-1.4,2020.emnlp-main.435,1,0.774606,"Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us involve the joint models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020b), applying both sentence- and document-level graphs (Sahu et al., 2019; Tran et al., 2020; Nan et al., 2020; Tran and Nguyen, 2021; Nguyen et al., 2021). However, to our knowledge, none of the prior work has employed GCNs for ECR. 3 (Cybulska and Vossen, 2014) to evaluate the models in this work, the training phase directly utilizes the golden topics of the documents while the test phase applies the K-mean algorithm for document clustering as in (Barhom et al., 2019). Afterward, given a topic t 2 T with the corresp"
2021.textgraphs-1.4,W06-0901,0,0.0887941,"est dependency paths to build a pruned and argumentcustomized dependency tree to simultaneously contain event triggers, arguments and the important words in a single structure. Afterward, the structure will be exploited to learn richer representation vectors for CDECR. Second, for document representations, previous 2 Related Work ECR is considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions that require argument reasoning (Yang et al., 2015). Previous work for within-document event resolution includes pairwise classifiers (Ahn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan an"
2021.textgraphs-1.4,D12-1045,0,0.108041,"spatio-temporal information (Yang et al., 2015) (called event arguments). In particular, as event mentions might be presented in different sentences/documents, an important evidence for predicting the coreference of two event mentions is to realize that the two event mentions have the same participants in the real world and/or occur at the same location and time (i.e., same arguments). Motivated by this intuition, prior work for CDECR has attempted to jointly resolve crossdocument coreference for entities and events so the two tasks can mutually benefit from each other (iterative clustering) (Lee et al., 2012). In fact, this iterative and joint modeling approach has recently led to the state-of-the-art performance for CDECR (Barhom et al., 2019; Meged et al., 2020). Our model for CDECR follows this joint coreference resolution method; however, we advance it by introducing novel techniques to address two major limitations from previous work (Yang et al., 2015; Kenyon-Dean et al., 2018; Barhom et al., 2019), i.e., the inadequate mechanisms to capture the argument-related information for representing event mentions and the use of only lexical features to represent input documents. As the first limitat"
2021.textgraphs-1.4,P19-1409,0,0.0516596,"ent sentences/documents, an important evidence for predicting the coreference of two event mentions is to realize that the two event mentions have the same participants in the real world and/or occur at the same location and time (i.e., same arguments). Motivated by this intuition, prior work for CDECR has attempted to jointly resolve crossdocument coreference for entities and events so the two tasks can mutually benefit from each other (iterative clustering) (Lee et al., 2012). In fact, this iterative and joint modeling approach has recently led to the state-of-the-art performance for CDECR (Barhom et al., 2019; Meged et al., 2020). Our model for CDECR follows this joint coreference resolution method; however, we advance it by introducing novel techniques to address two major limitations from previous work (Yang et al., 2015; Kenyon-Dean et al., 2018; Barhom et al., 2019), i.e., the inadequate mechanisms to capture the argument-related information for representing event mentions and the use of only lexical features to represent input documents. As the first limitation with the event argumentrelated evidence, existing methods for CDECR have mainly captured the direct information of event arguments fo"
2021.textgraphs-1.4,P13-1008,0,0.0214351,"and “decided” in S3), it can realize the unwillingness of the subject for the position ending event in S1 and the self intent to leave the position for the event in S3. As such, this difference can help the system to reject the event coreference for S1 and S3. To this end, we propose to explicitly identify and capture important context words for event triggers and arguments in representation learning for CDECR. In particular, our motivation is based on the shortest dependency paths between event triggers and arguments that have been used to reveal important context words for their relations (Li et al., 2013; Sha et al., 2018; Veyseh et al., 2020a, 2021). As an example, Figure 1 shows the dependency tree of S1 where the shortest dependency path between “O’Brien” and “leaving” can successfully include the important context word “forced”. As such, for each event mention, we leverage the shortest dependency paths to build a pruned and argumentcustomized dependency tree to simultaneously contain event triggers, arguments and the important words in a single structure. Afterward, the structure will be exploited to learn richer representation vectors for CDECR. Second, for document representations, prev"
2021.textgraphs-1.4,P10-1143,0,0.0437172,"n includes pairwise classifiers (Ahn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us involve the joint models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020"
2021.textgraphs-1.4,W09-3208,0,0.208302,"ndency tree to simultaneously contain event triggers, arguments and the important words in a single structure. Afterward, the structure will be exploited to learn richer representation vectors for CDECR. Second, for document representations, previous 2 Related Work ECR is considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions that require argument reasoning (Yang et al., 2015). Previous work for within-document event resolution includes pairwise classifiers (Ahn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean"
2021.textgraphs-1.4,liu-etal-2014-supervised,0,0.227131,"riggers, arguments and the important words in a single structure. Afterward, the structure will be exploited to learn richer representation vectors for CDECR. Second, for document representations, previous 2 Related Work ECR is considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions that require argument reasoning (Yang et al., 2015). Previous work for within-document event resolution includes pairwise classifiers (Ahn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us"
2021.textgraphs-1.4,W09-4303,0,0.0480038,"ncy paths to build a pruned and argumentcustomized dependency tree to simultaneously contain event triggers, arguments and the important words in a single structure. Afterward, the structure will be exploited to learn richer representation vectors for CDECR. Second, for document representations, previous 2 Related Work ECR is considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions that require argument reasoning (Yang et al., 2015). Previous work for within-document event resolution includes pairwise classifiers (Ahn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Y"
2021.textgraphs-1.4,C16-1308,0,0.213722,"in a single structure. Afterward, the structure will be exploited to learn richer representation vectors for CDECR. Second, for document representations, previous 2 Related Work ECR is considered as a more challenging task than entity coreference resolution due to the more complex structures of event mentions that require argument reasoning (Yang et al., 2015). Previous work for within-document event resolution includes pairwise classifiers (Ahn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us involve the joint models for entity and e"
2021.textgraphs-1.4,H05-1004,0,0.403605,"entity coreference resolution separately. (vii) MCS (Meged et al., 2020): An extension of BSE where some re-ranking features are included. Note that BSE and MCS are the current state-ofthe-art (SOTA) models for CDECR on ECB+. For cross-document entity coreference resolution, we compare our model with the LEMMA and BSE models in (Barhom et al., 2019), the only works that report the performance for event mentions on ECB+ so far. Following (Barhom et al., 2019), we use the common coreference resolution metrics to evaluate the models in this work, including MUC (Vilain et al., 1995), B3 , CEAF-e (Luo, 2005), and CoNLL F1 (average of three previous metrics). The official CoNLL scorer in (Pradhan et al., 2014) is employed to compute these metrics. Tables 1 and 2 show the performance (F1 scores) of the models for cross-document resolution for entity and event mentions (respectively). Note that we also report the performance of a variant (called HGCN-DJ) of the proposed HGCN model where the cluster-based representations cluster(m) are excluded (thus separately doing event and entity resolution as BSE-DJ). Model LEMMA (Barhom et al., 2019) CV (Cybulska and Vossen, 2015b) KCP (Kenyon-Dean et al. 2019)"
2021.textgraphs-1.4,D17-1226,0,0.185281,"lustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us involve the joint models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020"
2021.textgraphs-1.4,P14-5010,0,0.00577612,"2019). Afterward, given a topic t 2 T with the corresponding document subset Dt ⇢ D, our CDECR model initializes the entity and event cluster configurations Et0 and Vt0 (respectively) where: Et0 involves withindocument clusters of the entity mentions in the documents in Dt , and Vt0 simply puts each event mention presented in Dt into its own cluster (lines 2 and 3 in Algorithm 1). In the training phase, Et0 is obtained from the golden within-document coreference information of the entity mentions (to reduce noise) while the within-document entity mention clusters returned by Stanford CoreNLP (Manning et al., 2014) are used for Et0 in the test phase, following (Barhom et al., 2019). For convenience, the sets of entity and event mentions in Dt are called MtE and MtV respectively. Algorithm 1 Training algorithm 1: for t 2 T do 2: Et0 Within-doc clusters of entity mentions 3: Vt0 Singleton event mentions in MtV 4: k 1 5: while 9 meaningful cluster-pair merge do 6: //Entities 7: Generate entity mention representations RE (mei , Vtk 1 ) for all mei 2 MtE 8: Compute entity mention-pair coreference scores SE (mei , mej ) 9: Train RE and SE using the gold entity mention clusters 10: Etk Agglomeratively cluster"
2021.textgraphs-1.4,cybulska-vossen-2014-using,0,0.129359,"te-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020b), applying both sentence- and document-level graphs (Sahu et al., 2019; Tran et al., 2020; Nan et al., 2020; Tran and Nguyen, 2021; Nguyen et al., 2021). However, to our knowledge, none of the prior work has employed GCNs for ECR. 3 (Cybulska and Vossen, 2014) to evaluate the models in this work, the training phase directly utilizes the golden topics of the documents while the test phase applies the K-mean algorithm for document clustering as in (Barhom et al., 2019). Afterward, given a topic t 2 T with the corresponding document subset Dt ⇢ D, our CDECR model initializes the entity and event cluster configurations Et0 and Vt0 (respectively) where: Et0 involves withindocument clusters of the entity mentions in the documents in Dt , and Vt0 simply puts each event mention presented in Dt into its own cluster (lines 2 and 3 in Algorithm 1). In the tra"
2021.textgraphs-1.4,2020.findings-emnlp.440,0,0.0877717,"ts, an important evidence for predicting the coreference of two event mentions is to realize that the two event mentions have the same participants in the real world and/or occur at the same location and time (i.e., same arguments). Motivated by this intuition, prior work for CDECR has attempted to jointly resolve crossdocument coreference for entities and events so the two tasks can mutually benefit from each other (iterative clustering) (Lee et al., 2012). In fact, this iterative and joint modeling approach has recently led to the state-of-the-art performance for CDECR (Barhom et al., 2019; Meged et al., 2020). Our model for CDECR follows this joint coreference resolution method; however, we advance it by introducing novel techniques to address two major limitations from previous work (Yang et al., 2015; Kenyon-Dean et al., 2018; Barhom et al., 2019), i.e., the inadequate mechanisms to capture the argument-related information for representing event mentions and the use of only lexical features to represent input documents. As the first limitation with the event argumentrelated evidence, existing methods for CDECR have mainly captured the direct information of event arguments for event mention repre"
2021.textgraphs-1.4,W15-0801,0,0.269355,"the more complex structures of event mentions that require argument reasoning (Yang et al., 2015). Previous work for within-document event resolution includes pairwise classifiers (Ahn, 2006; Chen et al., 2009), spectral graph clustering methods (Chen and Ji, 2009), information propagation (Liu et al., 2014), markov logic networks (Lu et al., 2016), and deep 33 learning (Nguyen et al., 2016). For only crossdocument event resolution, prior work has considered mention-pair classifiers for coreference that use granularities of event slots and lexical features of event mentions for the features (Cybulska and Vossen, 2015b,a). Within- and cross-document event coreference have also been solved simultaneously in previous work (Lee et al., 2012; Bejan and Harabagiu, 2010; Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us involve the joint models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspect"
2021.textgraphs-1.4,2020.acl-main.141,0,0.0177629,"and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020b), applying both sentence- and document-level graphs (Sahu et al., 2019; Tran et al., 2020; Nan et al., 2020; Tran and Nguyen, 2021; Nguyen et al., 2021). However, to our knowledge, none of the prior work has employed GCNs for ECR. 3 (Cybulska and Vossen, 2014) to evaluate the models in this work, the training phase directly utilizes the golden topics of the documents while the test phase applies the K-mean algorithm for document clustering as in (Barhom et al., 2019). Afterward, given a topic t 2 T with the corresponding document subset Dt ⇢ D, our CDECR model initializes the entity and event cluster configurations Et0 and Vt0 (respectively) where: Et0 involves withindocument clusters of the entity"
2021.textgraphs-1.4,2021.naacl-main.3,1,0.821356,"Missing"
2021.textgraphs-1.4,N19-1423,0,0.0894494,"Missing"
2021.textgraphs-1.4,S18-2001,0,0.425282,"me arguments). Motivated by this intuition, prior work for CDECR has attempted to jointly resolve crossdocument coreference for entities and events so the two tasks can mutually benefit from each other (iterative clustering) (Lee et al., 2012). In fact, this iterative and joint modeling approach has recently led to the state-of-the-art performance for CDECR (Barhom et al., 2019; Meged et al., 2020). Our model for CDECR follows this joint coreference resolution method; however, we advance it by introducing novel techniques to address two major limitations from previous work (Yang et al., 2015; Kenyon-Dean et al., 2018; Barhom et al., 2019), i.e., the inadequate mechanisms to capture the argument-related information for representing event mentions and the use of only lexical features to represent input documents. As the first limitation with the event argumentrelated evidence, existing methods for CDECR have mainly captured the direct information of event arguments for event mention representations, thus failing to explicitly encode other important context words in the sentences to reveal fine-grained nature of relations between arguments and triggers for ECR (Yang et al., 2015; Barhom et al., 2019). For in"
2021.textgraphs-1.4,N18-1202,0,0.0477154,"step is based on averaging mention Plinkage coreference scores: SC (ci , cj ) = 1 mi 2ci ,mj 2cj S⇤ (mi , mj ) (Barhom et al., |ci ||cj | 2019) where ⇤ can be E or V depending on whether ci and cj are entity or event clusters (respectively). Mention Representations: Let m be a mention (event or entity) in a sentence W = w1 , w2 , . . . , wn of n words (wi is the i-th word) where wa is the head word of m. To prepare W for the mention representation computation and achieve a fair comparison with (Barhom et al., 2019), we first convert each word wi 2 W into a vector xi using the ELMo embeddings (Peters et al., 2018). Here, xi is obtained by running the pre-trained ELMo model over W and averaging the hidden vectors for wi at the three layers in ELMo. This transforms W into a sequence of vectors X = x1 , x2 , . . . , xn for the next steps. The mention representations in our work are based on two major elements, i.e., the modeling of important context words for event triggers and arguments, and the induction of document presentations. Note that during the training process, the parameters of the representation and scoring functions for entities RE and SE (or for events with RV and SV ) are updated/optimized"
2021.textgraphs-1.4,M95-1005,0,0.691821,"tations, thus performing event and entity coreference resolution separately. (vii) MCS (Meged et al., 2020): An extension of BSE where some re-ranking features are included. Note that BSE and MCS are the current state-ofthe-art (SOTA) models for CDECR on ECB+. For cross-document entity coreference resolution, we compare our model with the LEMMA and BSE models in (Barhom et al., 2019), the only works that report the performance for event mentions on ECB+ so far. Following (Barhom et al., 2019), we use the common coreference resolution metrics to evaluate the models in this work, including MUC (Vilain et al., 1995), B3 , CEAF-e (Luo, 2005), and CoNLL F1 (average of three previous metrics). The official CoNLL scorer in (Pradhan et al., 2014) is employed to compute these metrics. Tables 1 and 2 show the performance (F1 scores) of the models for cross-document resolution for entity and event mentions (respectively). Note that we also report the performance of a variant (called HGCN-DJ) of the proposed HGCN model where the cluster-based representations cluster(m) are excluded (thus separately doing event and entity resolution as BSE-DJ). Model LEMMA (Barhom et al., 2019) CV (Cybulska and Vossen, 2015b) KCP"
2021.textgraphs-1.4,P14-2006,0,0.0149759,"E where some re-ranking features are included. Note that BSE and MCS are the current state-ofthe-art (SOTA) models for CDECR on ECB+. For cross-document entity coreference resolution, we compare our model with the LEMMA and BSE models in (Barhom et al., 2019), the only works that report the performance for event mentions on ECB+ so far. Following (Barhom et al., 2019), we use the common coreference resolution metrics to evaluate the models in this work, including MUC (Vilain et al., 1995), B3 , CEAF-e (Luo, 2005), and CoNLL F1 (average of three previous metrics). The official CoNLL scorer in (Pradhan et al., 2014) is employed to compute these metrics. Tables 1 and 2 show the performance (F1 scores) of the models for cross-document resolution for entity and event mentions (respectively). Note that we also report the performance of a variant (called HGCN-DJ) of the proposed HGCN model where the cluster-based representations cluster(m) are excluded (thus separately doing event and entity resolution as BSE-DJ). Model LEMMA (Barhom et al., 2019) CV (Cybulska and Vossen, 2015b) KCP (Kenyon-Dean et al. 2019) CKCP (Barhom et al., 2019) BSE-DJ (Barhom et al., 2019) BSE (Barhom et al., 2019) MCS (Meged et al., 2"
2021.textgraphs-1.4,Q15-1037,0,0.553743,"and time (i.e., same arguments). Motivated by this intuition, prior work for CDECR has attempted to jointly resolve crossdocument coreference for entities and events so the two tasks can mutually benefit from each other (iterative clustering) (Lee et al., 2012). In fact, this iterative and joint modeling approach has recently led to the state-of-the-art performance for CDECR (Barhom et al., 2019; Meged et al., 2020). Our model for CDECR follows this joint coreference resolution method; however, we advance it by introducing novel techniques to address two major limitations from previous work (Yang et al., 2015; Kenyon-Dean et al., 2018; Barhom et al., 2019), i.e., the inadequate mechanisms to capture the argument-related information for representing event mentions and the use of only lexical features to represent input documents. As the first limitation with the event argumentrelated evidence, existing methods for CDECR have mainly captured the direct information of event arguments for event mention representations, thus failing to explicitly encode other important context words in the sentences to reveal fine-grained nature of relations between arguments and triggers for ECR (Yang et al., 2015; Ba"
2021.textgraphs-1.4,P19-1423,0,0.0197259,"us involve the joint models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020b), applying both sentence- and document-level graphs (Sahu et al., 2019; Tran et al., 2020; Nan et al., 2020; Tran and Nguyen, 2021; Nguyen et al., 2021). However, to our knowledge, none of the prior work has employed GCNs for ECR. 3 (Cybulska and Vossen, 2014) to evaluate the models in this work, the training phase directly utilizes the golden topics of the documents while the test phase applies the K-mean algorithm for document clustering as in (Barhom et al., 2019). Afterward, given a topic t 2 T with the corresponding document subset Dt ⇢ D, our CDECR model initializes the entity and event cluster configurations Et0 and Vt0 (respectively) where: Et0 involves"
2021.textgraphs-1.4,2020.findings-emnlp.409,1,0.667444,"t models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020b), applying both sentence- and document-level graphs (Sahu et al., 2019; Tran et al., 2020; Nan et al., 2020; Tran and Nguyen, 2021; Nguyen et al., 2021). However, to our knowledge, none of the prior work has employed GCNs for ECR. 3 (Cybulska and Vossen, 2014) to evaluate the models in this work, the training phase directly utilizes the golden topics of the documents while the test phase applies the K-mean algorithm for document clustering as in (Barhom et al., 2019). Afterward, given a topic t 2 T with the corresponding document subset Dt ⇢ D, our CDECR model initializes the entity and event cluster configurations Et0 and Vt0 (respectively) where: Et0 involves withindocument clus"
2021.textgraphs-1.4,2021.naacl-main.273,1,0.735061,"ence resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020b), applying both sentence- and document-level graphs (Sahu et al., 2019; Tran et al., 2020; Nan et al., 2020; Tran and Nguyen, 2021; Nguyen et al., 2021). However, to our knowledge, none of the prior work has employed GCNs for ECR. 3 (Cybulska and Vossen, 2014) to evaluate the models in this work, the training phase directly utilizes the golden topics of the documents while the test phase applies the K-mean algorithm for document clustering as in (Barhom et al., 2019). Afterward, given a topic t 2 T with the corresponding document subset Dt ⇢ D, our CDECR model initializes the entity and event cluster configurations Et0 and Vt0 (respectively) where: Et0 involves withindocument clusters of the entity mentions in the docume"
2021.textgraphs-1.4,C16-1183,0,0.0157066,"and does not require special treatment for unannotated mentions (Barhom et al., 2019). Note that there is a different setup for ECB+ that is applied in (Yang et al., 2015) and (Choubey and Huang, 2017). In this setup, the full ECB+ dataset is employed, including the portions with known annotation errors. In test time, such prior work utilizes the predicted mentions from a mention extraction tool (Yang et al., 2015). To handle the partial annotation in ECB+, those prior work only evaluates the systems on the predicted mentions that are also annotated as the gold mentions. However, as shown by (Upadhyay et al., 2016), this ECB+ setup has several limitations (e.g., the ignorance of clusters with a single mention and the separate (v) Final Representation: Given the representation vectors learned so far, we form the final representation vector for m (RE (m, Vtk 1 ) or RV (m, Etk ) in lines 7 or 12 of Algorithm 1) by concatenating the following vectors: (1) The sentence- and document-level GCNbased representation vectors for m (i.e., sent(m) and doc(m)). (2) The cluster-based representation cluster(m) = [Arg0m , Arg1m , Locationm , Timem ]. Taking Arg0m as an example, it is computed by considering the mention"
2021.textgraphs-1.4,P19-1432,1,0.735534,"Adrian Bejan and Harabagiu, 2014; Yang et al., 2015; Choubey and Huang, 2017; Kenyon-Dean et al., 2018). The most related works to us involve the joint models for entity and event coreference resolution that use contextualized word embeddings to capture the dependencies between the two tasks and lead to the state-of-the-art performance for CDECR (Lee et al., 2012; Barhom et al., 2019; Meged et al., 2020). Finally, regarding the modeling perspective, our work is related to the models that use GCNs to learn representation vectors for different NLP tasks, e.g., event detection (Lai et al., 2020; Veyseh et al., 2019) and target opinion word extraction (Veyseh et al., 2020b), applying both sentence- and document-level graphs (Sahu et al., 2019; Tran et al., 2020; Nan et al., 2020; Tran and Nguyen, 2021; Nguyen et al., 2021). However, to our knowledge, none of the prior work has employed GCNs for ECR. 3 (Cybulska and Vossen, 2014) to evaluate the models in this work, the training phase directly utilizes the golden topics of the documents while the test phase applies the K-mean algorithm for document clustering as in (Barhom et al., 2019). Afterward, given a topic t 2 T with the corresponding document subset"
2021.textgraphs-1.4,2020.findings-emnlp.326,1,0.853888,"ze the unwillingness of the subject for the position ending event in S1 and the self intent to leave the position for the event in S3. As such, this difference can help the system to reject the event coreference for S1 and S3. To this end, we propose to explicitly identify and capture important context words for event triggers and arguments in representation learning for CDECR. In particular, our motivation is based on the shortest dependency paths between event triggers and arguments that have been used to reveal important context words for their relations (Li et al., 2013; Sha et al., 2018; Veyseh et al., 2020a, 2021). As an example, Figure 1 shows the dependency tree of S1 where the shortest dependency path between “O’Brien” and “leaving” can successfully include the important context word “forced”. As such, for each event mention, we leverage the shortest dependency paths to build a pruned and argumentcustomized dependency tree to simultaneously contain event triggers, arguments and the important words in a single structure. Afterward, the structure will be exploited to learn richer representation vectors for CDECR. Second, for document representations, previous 2 Related Work ECR is considered a"
2021.textgraphs-1.4,2020.emnlp-main.719,1,0.848229,"Missing"
2021.wanlp-1.27,P15-1017,0,0.0554856,"demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Li"
2021.wanlp-1.27,W09-2209,0,0.294419,"based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et a"
2021.wanlp-1.27,N19-1423,0,0.0256202,"d to the state-ofthe-art performance for different experiments scenarios for CEAE. In the future, we plan to apply the proposed model to other related tasks, e.g., crosslingual relation extraction (Veyseh et al., 2020). In addition, motivated by the recent introduction of high-performance multilingual NLP toolkits, e.g., Trankit (Nguyen et al., 2021), we expect to extend our work to other languages to better demonstrate the benefits of the proposed models. Finally, we will also explore the performance of our models when recent pre-trained multilingual language models, e.g., multilingual BERT (Devlin et al., 2019), are employed to encode input texts for different languages. Acknowledgments This research has been supported by the Army Research Office (ARO) grant W911NF-17-S-0002. This research is also based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA Contract No. 201919051600006 under the Better Extraction from Text Towards Enhanced Retrieval (BETTER) Program. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official p"
2021.wanlp-1.27,N15-1151,0,0.0236256,", 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as"
2021.wanlp-1.27,C16-1114,0,0.104667,"based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event f"
2021.wanlp-1.27,P08-1030,0,0.0752359,"eriments are conducted with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic st"
2021.wanlp-1.27,D18-1330,0,0.0627197,"Missing"
2021.wanlp-1.27,C10-1064,0,0.031916,"earning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , .."
2021.wanlp-1.27,D19-5532,1,0.841018,"ance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our wo"
2021.wanlp-1.27,2020.emnlp-main.435,1,0.745645,"bic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related"
2021.wanlp-1.27,D14-1198,0,0.0273177,"English to demonstrate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, whi"
2021.wanlp-1.27,P13-1008,0,0.0599007,"s for representation learning in this work. Finally, we conduct extensive experiments to demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et"
2021.wanlp-1.27,R11-1002,0,0.666743,"with Arabic, Chinese, and English to demonstrate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences acr"
2021.wanlp-1.27,P14-1055,0,0.0283731,"twardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence"
2021.wanlp-1.27,P19-1423,0,0.05824,"g for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role y ∗ of wa for the event triggered by wt . Following (Subburathinam et al., 2019), we use the UDPipe toolkit (Straka and Strakov´a, 2017) to obtain the universal dependency tree for W , the part of speech (POS) tag"
2021.wanlp-1.27,P17-1004,0,0.0888869,", 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word a"
2021.wanlp-1.27,K17-3009,0,0.103138,"Missing"
2021.wanlp-1.27,N19-1112,0,0.023469,"15; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role"
2021.wanlp-1.27,D19-1030,0,0.291797,"Missing"
2021.wanlp-1.27,D18-1156,0,0.0171188,"t Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In particular, with the multilingual word embeddings"
2021.wanlp-1.27,2020.findings-emnlp.409,1,0.795913,"Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role y ∗ of wa for the event triggered by wt . Following (Subburathinam et al., 2019), we use the UDPipe toolkit (Straka and Strakov´a, 2017) to obtain the universal dependency tree for W , the part of speech (POS) tags and BIO entity typ"
2021.wanlp-1.27,N19-1392,0,0.0510224,"Missing"
2021.wanlp-1.27,P18-2106,0,0.0564393,"Missing"
2021.wanlp-1.27,2021.eacl-demos.10,1,0.620789,"e introduce two novel sentence structures for cross-lingual EAE with GCNs based on the semantic similarity and the universal dependency relations of the words in the input sentences. The experiments demonstrate the benefits of the proposed sentence structures that lead to the state-ofthe-art performance for different experiments scenarios for CEAE. In the future, we plan to apply the proposed model to other related tasks, e.g., crosslingual relation extraction (Veyseh et al., 2020). In addition, motivated by the recent introduction of high-performance multilingual NLP toolkits, e.g., Trankit (Nguyen et al., 2021), we expect to extend our work to other languages to better demonstrate the benefits of the proposed models. Finally, we will also explore the performance of our models when recent pre-trained multilingual language models, e.g., multilingual BERT (Devlin et al., 2019), are employed to encode input texts for different languages. Acknowledgments This research has been supported by the Army Research Office (ARO) grant W911NF-17-S-0002. This research is also based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IA"
2021.wanlp-1.27,N16-1034,1,0.878003,"he proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In part"
2021.wanlp-1.27,P15-2060,1,0.870008,"trate the effectiveness of the proposed method for CEAE. 1 Introduction Event Argument Extraction (EAE) aims to classify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lin"
2021.wanlp-1.27,2020.acl-main.715,1,0.932968,"the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure mod"
2021.wanlp-1.27,P19-1432,1,0.845506,", 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e., an entity mention) (1 ≤ t, a ≤ N ). The goal of EAE is to predict the role y ∗ of wa for the event triggered by wt . Following (Subburathinam et al., 2019), we use the UDPipe toolkit (Straka and Strakov´a, 2017) to obtain the universal dependency tree for W , the part of speech (POS) tags and BIO entity type tags for the words in W . For convenience, let R"
2021.wanlp-1.27,C18-1099,0,0.109863,"itchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argument candidate (i.e.,"
2021.wanlp-1.27,D19-1584,0,0.231593,"ssify argument roles of entity mentions for events in text. For example, given the sentence “He died of injuries from a grenade attack by a fellow soldier”, the task requires systems to identify the entity mention “a fellow soldier” as the Agent of the event Die, which is triggered by the verb “died”. EAE is an important component of event extraction (EE) that has been extensively studied with different approaches (Ji and Grishman, 2008; Liao and Grishman, 2011a; Li et al., 2014; Nguyen and Grishman, 2015b; Nguyen et al., 2016; Nguyen and Grishman, 2018; Liu et al., 2018; Zhang et al., 2019b; Wang et al., 2019). Cross-lingual Event Argument Extraction (CEAE) is an instance of EAE that considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In particular, with the multilingual word embeddings, Subburathinam et al. (2019) develop a m"
2021.wanlp-1.27,N16-1033,0,0.0531917,"ion learning in this work. Finally, we conduct extensive experiments to demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2"
2021.wanlp-1.27,D09-1016,0,0.181809,"t all the structures A rel and A are fed into GCN models for representation learning in this work. Finally, we conduct extensive experiments to demonstrate the benefits of the proposed sentence structures, leading to the state-of-the-art performance for CEAE with Arabic, Chinese, and English as the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqu"
2021.wanlp-1.27,2020.findings-emnlp.326,1,0.929278,"the experiment languages. To our knowledge, this is the first work to examine semantic-based and relation-based structures for EAE. 2 Related Work EAE and EE have been extensively studied for English in the monolingual context of Event Extraction, featuring both the traditional machine learning models (Patwardhan and Riloff, 2009; Liao and Grishman, 2011b; Li et al., 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure mod"
2021.wanlp-1.27,D18-1244,0,0.0292328,"considers the setting where test languages (i.e., target languages) are different from training languages (i.e., source languages). The goal is to transfer knowledge in source languages, where data is abundant, to low-resource target languages. The previous work on CEAE (Subburathinam et al., 2019) has shown the existence of shared syntactic structures of sentences across languages, which are useful for cross-lingual transfer. In particular, with the multilingual word embeddings, Subburathinam et al. (2019) develop a model based on Graph Convolutional Networks (GCNs) (Kipf and Welling, 2017; Zhang et al., 2018), which operates on universal dependency trees to capture the shared structures. Notably, the use of the dependency trees of the sentences for GCNs in (Subburathinam et al., 2019) essentially treats the existence of the syntactic connections between the words in the universal dependency trees as the language-universal knowledge that can be exploited to bridge the gap between languages for EAE. In (Subburathinam et al., 2019), such syntactic connection existences are formalized via the adjacency matrices Adep = {adep ij }i,j=1..N of the dependency trees (i.e., N is the number of words in the in"
2021.wanlp-1.27,C18-1037,0,0.115389,", 2013; Yang and Mitchell, 2016) and the recent advanced deep learning models (Chen et al., 2015; Sha et al., 2018; Wang et al., 2019; Zhang et al., 2019a; Nguyen and Nguyen, 2019; Lai and Nguyen, 2019; Lai et al., 2020; Pouran Ben Veyseh et al., 2020). Only a few works have considered cross-lingual learning for EAE (Chen and Ji, 2009; Hsi et al., 2016; Subburathinam et al., 2019). Cross-lingual transfer learning has also been examined for the other related tasks of EAE, including multilingual relation extraction (Kim et al., 2010; Qian et al., 2014; Faruqui and Kumar, 2015; Lin et al., 2017; Zou et al., 2018; Wang et al., 2018) and semantic role labeling (Mulcaire et al., 2018, 2019; Liu et al., 2019). However, none of these works explores edge-based attention GCN as we do. Finally, our work is also related to the recent text structure models for other NLP tasks, including relation extraction (Sahu et al., 2019; Tran et al., 2020), event factuality prediction (Veyseh et al., 2019), and text summarization (Balachandran et al., 2020). 3 Model We formalize EAE as a multi-class classification problem. Let W = w1 , w2 , ..., wN be a sentence (of N words) with wt as the trigger word and wa as the argum"
2021.wnut-1.5,Q14-1022,0,0.0243768,"g the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works"
2021.wnut-1.5,N19-1423,0,0.0369462,"Abaseline is those computed for the model that always guesses the median. • Comparison on UDS-T: We compare the FineTempRel model in this work (called ONLSTM-GCN) with the best-reported models on the UDS-T dataset in (Vashishtha et al., 2019). In particular, we use the top four models in (Vashishtha et al., 2019) (called System1, System2, System3, and System4) as the baselines in this work. Table 1 reports the performance of the models. Note that in addition to the ELMo embeddings as in (Vashishtha et al., 2019), we also show the performance of the ON-LSTM-GCN model when the BERT embeddings (Devlin et al., 2019) (i.e., the base model) are employed to encode the sentences. Both ELMo and BERT are fine-tuned during training in this work. As we can see, using the same ELMo embeddings, the proposed model ON-LSTM-GCN significantly outperforms all the models in (Vashishtha et al., 2019) with substantial performance gap over different performance metrics and the two subtasks (i.e., event duration prediction and temporal relation prediction). This clearly demonstrates the effectiveness of the proposed model for FineTempRel. We also see that replacing ELMo with the BERT embeddings can help to improve the perfo"
2021.wnut-1.5,E17-2118,0,0.175331,"more useful context information for FineTempRel than the farther ones. For instance, Introduction An important step in event understanding involves identifying the temporal relations between events (i.e., TempRel), finding its applications in different natural language processing (NLP) systems such as question answering and timeline construction. A large volume of the prior works has focused on the classification setting for this problem where categorical temporal relations should be predicted for pairs of event-referring and/or time-referring expressions in text (i.e., categorical TempRel) (Dligach et al., 2017; Cheng and Miyao, 2017; Ning et al., 2019). For instance, in the sentence “The meeting to discuss the possible merger of the two financial companies lasted for two hours, eventually leading to their union yesterday.”, a system for TempRel should be able to realize that the “discussion” event happens before the “union” event (i.e., the categorical label of BEFORE). ∗ The first two authors contribute equally to this paper. 35 Proceedings of the 2021 EMNLP Workshop W-NUT: The Seventh Workshop on Noisy User-generated Text, pages 35–45 November 11, 2021. ©2021 Association for Computational Linguis"
2021.wnut-1.5,N13-1112,0,0.0739355,"Missing"
2021.wnut-1.5,W01-1313,0,0.185668,"(Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained langua"
2021.wnut-1.5,P19-1433,0,0.015995,"epresentation learning for FineTempRel. words for the representation vectors of the event mentions involve the syntactic neighboring words of the event mentions in the dependency trees. For instance, in our example, the words “lasted” and “two hours” are crucial to determine the duration for the event mention “meeting”. Note that although these words are far away from “meeting” in the sentence, they are directly connected to “meeting” in the dependency tree (i.e., the syntactic neighboring words). Second, for temporal relation prediction, our intuition is based on (Cheng and Miyao, 2017) and (Goyal and Durrett, 2019) that use the shortest dependency paths between the event mentions to capture the important context words for categorical TempRel (e.g., the word “leading” in our example). Motivated by these benefits of the dependency trees for FineTempRel, in this work, we propose to run Graph Convolutional Neural Networks (GCN) (Kipf and Welling, 2017; Nguyen and Grishman, 2018) over the dependency structures of the sentences to facilitate the incorporation of the dependency-based important context words into the representation vectors for FineTempRel. To our knowledge, this is the first work on using GCNs"
2021.wnut-1.5,W11-0116,0,0.0320814,"t al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al.,"
2021.wnut-1.5,S13-2002,0,0.0327634,"portant context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTem"
2021.wnut-1.5,K19-1062,0,0.172101,"elations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2"
2021.wnut-1.5,P14-2082,0,0.161812,"ecompose FineTempRel into two subtasks that would be solved jointly for a given pair of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, d"
2021.wnut-1.5,D19-1041,0,0.175158,"elations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2"
2021.wnut-1.5,W16-1701,0,0.0601497,"Missing"
2021.wnut-1.5,D17-1108,0,0.0974236,"ription (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al."
2021.wnut-1.5,P18-1212,0,0.0145996,"of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (D"
2021.wnut-1.5,D19-1642,0,0.0493625,"Rel than the farther ones. For instance, Introduction An important step in event understanding involves identifying the temporal relations between events (i.e., TempRel), finding its applications in different natural language processing (NLP) systems such as question answering and timeline construction. A large volume of the prior works has focused on the classification setting for this problem where categorical temporal relations should be predicted for pairs of event-referring and/or time-referring expressions in text (i.e., categorical TempRel) (Dligach et al., 2017; Cheng and Miyao, 2017; Ning et al., 2019). For instance, in the sentence “The meeting to discuss the possible merger of the two financial companies lasted for two hours, eventually leading to their union yesterday.”, a system for TempRel should be able to realize that the “discussion” event happens before the “union” event (i.e., the categorical label of BEFORE). ∗ The first two authors contribute equally to this paper. 35 Proceedings of the 2021 EMNLP Workshop W-NUT: The Seventh Workshop on Noisy User-generated Text, pages 35–45 November 11, 2021. ©2021 Association for Computational Linguistics in our running example, the word “lead"
2021.wnut-1.5,P17-1009,0,0.0191599,"s is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The f"
2021.wnut-1.5,P18-1122,0,0.013777,"of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (D"
2021.wnut-1.5,C16-1308,0,0.0288235,"et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of EL"
2021.wnut-1.5,P06-1095,0,0.0975168,"e argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning mo"
2021.wnut-1.5,S18-2018,0,0.0165623,"of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (D"
2021.wnut-1.5,P18-1049,0,0.0192044,"e fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event"
2021.wnut-1.5,W16-5706,0,0.0389344,"Missing"
2021.wnut-1.5,L16-1699,0,0.0357237,"Missing"
2021.wnut-1.5,C16-1007,0,0.0137213,"tasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duratio"
2021.wnut-1.5,N18-1202,0,0.0255135,"do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The first component in our model for FineTempRel aims to exploit the consistency between the syntax-based and model-based importance scores for the words in the input sentence to improve the representation vectors in the deep learning models for FineTempRel. In particular, the syntaxbased importance scores are supposed to evaluate the potential contributions of the words in W f"
2021.wnut-1.5,2021.naacl-main.3,1,0.820189,"Missing"
2021.wnut-1.5,P17-2035,0,0.0130308,"et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of r"
2021.wnut-1.5,2021.acl-long.374,1,0.76159,"et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The first component in ou"
2021.wnut-1.5,2021.naacl-main.273,1,0.72013,"FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W into the pre-trained language model ELMo (Peters et al., 2018) to produce a sequence of hidden vectors X = x1 , x2 , . . . , xN for W . Note that the hidden vector xi for wi ∈ W is the concatenation of the hidden vectors for wi in three layers of ELMo. 3.1 Syntax-Model Consistency The first component in our model for FineTempRel aims to exploit the consistency between the syntax"
2021.wnut-1.5,S13-2001,0,0.214353,"ha et al., 2019), we decompose FineTempRel into two subtasks that would be solved jointly for a given pair of events in this work, i.e., event duration prediction (i.e., predicting the durations of the events) and temporal relation prediction (i.e., predicting the start and end times of the events). First, for event duration prediction, we argue that the important context 2 Related Work Most of the previous work on TempRel has focused on the categorical setting using the TimeML standard for the datasets (i.e., TimeBank, TimeBankDense, Richer Event Description (RED)) (Pustejovsky et al., 2003; UzZaman et al., 2013; Cassidy et al., 2014; Minard et al., 2016; O’Gorman et al., 2016; Hong et al., 2016; Ning et al., 2018b,c). 36 (Vashishtha et al., 2019) is the first work to consider the fine-grained distinction for the temporal relations for events. Regarding TempRel methods, the early approaches has involved feature-based models (Mani et al., 2006; Bethard, 2013; Lin et al., 2015), the hybrid methods (D’Souza and Ng, 2013), sieve-based methods (i.e., CAEVO (Chambers et al., 2014), CATENA (Mirza and Tonelli, 2016)), structured learning methods (Ning et al., 2017), and Interger Linear Programming (Ning et a"
2021.wnut-1.5,P19-1280,0,0.0307981,"Missing"
2021.wnut-1.5,2020.acl-main.715,1,0.816482,"uce the information from the syntax-based importance scores into the models for FineTempRel by enforcing the similarity/consistency between the syntax-based and model-based importance scores for the words in the sentence. The motivation is to leverage the importance score consistency to guide the representation learning process of the deep learning models (using the extracted syntactic information) so more effective representation vectors for FineTempRel can be induced. In order to implement this idea, we utilize the Ordered-Neuron Long Short-Term Memory Networks (ON-LSTM) (Shen et al., 2019; Veyseh et al., 2020a) to facilitate the computation of the model-based importance scores and the effective integration of the syntax-based scores for better representation vectors for FineTempRel. For the second type of syntactic information, the main motivation is to leverage the syntactic dependency connections between the words to identify the important context words that should be encoded to compute effective representation vectors for the event mentions in the sentences. In particular, following (Vashishtha et al., 2019), we decompose FineTempRel into two subtasks that would be solved jointly for a given pa"
2021.wnut-1.5,2020.findings-emnlp.326,1,0.729854,"uce the information from the syntax-based importance scores into the models for FineTempRel by enforcing the similarity/consistency between the syntax-based and model-based importance scores for the words in the sentence. The motivation is to leverage the importance score consistency to guide the representation learning process of the deep learning models (using the extracted syntactic information) so more effective representation vectors for FineTempRel can be induced. In order to implement this idea, we utilize the Ordered-Neuron Long Short-Term Memory Networks (ON-LSTM) (Shen et al., 2019; Veyseh et al., 2020a) to facilitate the computation of the model-based importance scores and the effective integration of the syntax-based scores for better representation vectors for FineTempRel. For the second type of syntactic information, the main motivation is to leverage the syntactic dependency connections between the words to identify the important context words that should be encoded to compute effective representation vectors for the event mentions in the sentences. In particular, following (Vashishtha et al., 2019), we decompose FineTempRel into two subtasks that would be solved jointly for a given pa"
2021.wnut-1.5,P12-2044,0,0.0216999,"terger Linear Programming (Ning et al., 2018). Recently, deep learning models have been developed and shown promising results for TempRel (Dligach et al., 2017; Tourille et al., 2017; Cheng and Miyao, 2017; Meng and Rumshisky, 2018; Ning et al., 2019; Han et al., 2019a). The closet work to ours is (Vashishtha et al., 2019) that presents an attentionbased deep learning model for FineTempRel; however, it does not capture the syntactic structures of the sentences as we do in this work. Some previous works have also considered event duration modeling in text (Pan et al., 2007; Gusev et al., 2011; Williams and Katz, 2012; Filatova and Hovy, 2001) although they do not tie duration and temporal relations as we do. Finally, we also note related tasks that concern other types of relations between events/entities, including event coreference resolution (Lu et al., 2016; Nguyen et al., 2016; Lu and Ng, 2017; Tran et al., 2021), event causaltiy identification (Liu et al., 2020; Tran and Nguyen, 2021), and event argument extraction (Veyseh et al., 2020b; Nguyen et al., 2021). 3 To prepare the input sentence for the deep learning models and to achieve a fair comparison with (Vashishtha et al., 2019), we first send W i"
2021.wnut-1.6,P15-1017,0,0.0329001,"s with the multi-hop path reasoning, and information bottleneck to improve the generalization for EFP. Model-wise, our work bears some similarity with other NLP models that leverage syntactic structures and GCNs to encode input texts for different NLP tasks, including relation extraction (Zhang et al., 2018), joint information extraction (Nguyen et al., 2021), metaphor detection (Le et al., 2020), and rumor detection (Veyseh et al., 2019b). Finally, we also note some related tasks for EFP that seek to classify event trigger words in texts, including event detection (Nguyen and Grishman, 2015; Chen et al., 2015; Lai et al., 2020; Veyseh et al., 2021), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016) and uncertainty detection (Adel and Schütze, 2017). 3 Structure Generation The goal of this section is to generate the initial sentence structures that would be combined in the next steps to generate richer structures for representation learning in EFP. Formally, the sentence structures in this work can be seen as the importance score matrices of size N × N . Each cell (i, j) in these matrices contains a score to represent the importance of the contextual information from wj for t"
2021.wnut-1.6,J12-2003,0,0.0793905,"Missing"
2021.wnut-1.6,N19-1423,0,0.016586,"first compute the length di of the shortest path between wi and the trigger word wk (i.e., the distance) in T for all Model We formalize EFP as a regression problem in this work. In particular, given an input sentence W = w1 , w2 , . . . , wN of N words/tokens (i.e., wi is the i-th token) and an event mention with the trigger word located at the k-th position (i.e., wk ), we need to predict a real-valued score between -3 and +3 to indicate the factual degree for wk . In order to achieve a fair comparison with the prior work for EFP (Veyseh et al., 2019a), we first apply the BERTbase model in (Devlin et al., 2019) to obtain a pre-trained embedding vector xi for each word wi ∈ W . In particular, we run the BERTbase model over the input sentence W and use the hidden vector for the first wordpiece of wi in the last layer of BERT as the embedding vector xi (of 768 dimensions) for wi . This encoding step transforms W into a sequence of embedding vectors X = x1 , x2 , . . . , xN (called the input vectors) for the neural computation in the next steps. The EFP model in this work involves three major components: (i) structure generation, (iii) structure combination, and (iii) representation regularization. We w"
2021.wnut-1.6,W09-3012,0,0.0192204,"” and “brother”) that can be further extended to “Hagai”, “member”, and “confirmed” via the dependency connections for representation learning. Besides the multi-hop nature, we also note that the edges along the multihop path in this example contains both syntactic and semantic connections (i.e., heterogeneous edge types) that are necessary to identify the important context words for EFP. 2 Related Work Various methods have been proposed to solve EFP, including the early rule-based approaches (Nairn et al., 2006; Saurí, 2008; Lotan et al., 2013), the feature-based machine learning approaches (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), and the hybrid methods (Saurí and Pustejovsky, 2012; Qian et al., 2015). The recent work has featured deep learning as the state-of-the-art method for EFP. In particular, (Qian et al., 2018) presents a model based on Generative Adversarial Networks (GAN) while (Rudinger et al., 2018) applies Long-short Term Memory Networks (LSTM) over both the sequential order and the dependency tree of the input senMotivated by this limitation, in this work, we propose to learn the importance scores for the sentence structures, leveragin"
2021.wnut-1.6,2020.emnlp-main.435,1,0.78629,"p path reasoning, and information bottleneck to improve the generalization for EFP. Model-wise, our work bears some similarity with other NLP models that leverage syntactic structures and GCNs to encode input texts for different NLP tasks, including relation extraction (Zhang et al., 2018), joint information extraction (Nguyen et al., 2021), metaphor detection (Le et al., 2020), and rumor detection (Veyseh et al., 2019b). Finally, we also note some related tasks for EFP that seek to classify event trigger words in texts, including event detection (Nguyen and Grishman, 2015; Chen et al., 2015; Lai et al., 2020; Veyseh et al., 2021), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016) and uncertainty detection (Adel and Schütze, 2017). 3 Structure Generation The goal of this section is to generate the initial sentence structures that would be combined in the next steps to generate richer structures for representation learning in EFP. Formally, the sentence structures in this work can be seen as the importance score matrices of size N × N . Each cell (i, j) in these matrices contains a score to represent the importance of the contextual information from wj for the representation"
2021.wnut-1.6,E17-1003,0,0.0213854,"P models that leverage syntactic structures and GCNs to encode input texts for different NLP tasks, including relation extraction (Zhang et al., 2018), joint information extraction (Nguyen et al., 2021), metaphor detection (Le et al., 2020), and rumor detection (Veyseh et al., 2019b). Finally, we also note some related tasks for EFP that seek to classify event trigger words in texts, including event detection (Nguyen and Grishman, 2015; Chen et al., 2015; Lai et al., 2020; Veyseh et al., 2021), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016) and uncertainty detection (Adel and Schütze, 2017). 3 Structure Generation The goal of this section is to generate the initial sentence structures that would be combined in the next steps to generate richer structures for representation learning in EFP. Formally, the sentence structures in this work can be seen as the importance score matrices of size N × N . Each cell (i, j) in these matrices contains a score to represent the importance of the contextual information from wj for the representation vector of wi if this vector is used to create the features for factuality prediction (called the importance score for the pair (wi , wj )). Followi"
2021.wnut-1.6,D15-1189,0,0.153098,"“confirmed” via the dependency connections for representation learning. Besides the multi-hop nature, we also note that the edges along the multihop path in this example contains both syntactic and semantic connections (i.e., heterogeneous edge types) that are necessary to identify the important context words for EFP. 2 Related Work Various methods have been proposed to solve EFP, including the early rule-based approaches (Nairn et al., 2006; Saurí, 2008; Lotan et al., 2013), the feature-based machine learning approaches (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), and the hybrid methods (Saurí and Pustejovsky, 2012; Qian et al., 2015). The recent work has featured deep learning as the state-of-the-art method for EFP. In particular, (Qian et al., 2018) presents a model based on Generative Adversarial Networks (GAN) while (Rudinger et al., 2018) applies Long-short Term Memory Networks (LSTM) over both the sequential order and the dependency tree of the input senMotivated by this limitation, in this work, we propose to learn the importance scores for the sentence structures, leveraging Graph Transformer Networks (GTN) (Yun et al., 2019) to facilitate the"
2021.wnut-1.6,N18-1067,0,0.0327779,"Missing"
2021.wnut-1.6,N13-1091,0,0.0142141,"brother” (i.e., with the semantic connection between “family members” and “brother”) that can be further extended to “Hagai”, “member”, and “confirmed” via the dependency connections for representation learning. Besides the multi-hop nature, we also note that the edges along the multihop path in this example contains both syntactic and semantic connections (i.e., heterogeneous edge types) that are necessary to identify the important context words for EFP. 2 Related Work Various methods have been proposed to solve EFP, including the early rule-based approaches (Nairn et al., 2006; Saurí, 2008; Lotan et al., 2013), the feature-based machine learning approaches (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), and the hybrid methods (Saurí and Pustejovsky, 2012; Qian et al., 2015). The recent work has featured deep learning as the state-of-the-art method for EFP. In particular, (Qian et al., 2018) presents a model based on Generative Adversarial Networks (GAN) while (Rudinger et al., 2018) applies Long-short Term Memory Networks (LSTM) over both the sequential order and the dependency tree of the input senMotivated by this limitation, in this work, we propose to"
2021.wnut-1.6,L16-1699,0,0.0341587,"Missing"
2021.wnut-1.6,J12-2002,0,0.0316174,"for representation learning. Besides the multi-hop nature, we also note that the edges along the multihop path in this example contains both syntactic and semantic connections (i.e., heterogeneous edge types) that are necessary to identify the important context words for EFP. 2 Related Work Various methods have been proposed to solve EFP, including the early rule-based approaches (Nairn et al., 2006; Saurí, 2008; Lotan et al., 2013), the feature-based machine learning approaches (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), and the hybrid methods (Saurí and Pustejovsky, 2012; Qian et al., 2015). The recent work has featured deep learning as the state-of-the-art method for EFP. In particular, (Qian et al., 2018) presents a model based on Generative Adversarial Networks (GAN) while (Rudinger et al., 2018) applies Long-short Term Memory Networks (LSTM) over both the sequential order and the dependency tree of the input senMotivated by this limitation, in this work, we propose to learn the importance scores for the sentence structures, leveraging Graph Transformer Networks (GTN) (Yun et al., 2019) to facilitate the emergence of the effective multi-hop paths with hete"
2021.wnut-1.6,W06-3907,0,0.176416,"link “involvement” with “Basir’s brother” (i.e., with the semantic connection between “family members” and “brother”) that can be further extended to “Hagai”, “member”, and “confirmed” via the dependency connections for representation learning. Besides the multi-hop nature, we also note that the edges along the multihop path in this example contains both syntactic and semantic connections (i.e., heterogeneous edge types) that are necessary to identify the important context words for EFP. 2 Related Work Various methods have been proposed to solve EFP, including the early rule-based approaches (Nairn et al., 2006; Saurí, 2008; Lotan et al., 2013), the feature-based machine learning approaches (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), and the hybrid methods (Saurí and Pustejovsky, 2012; Qian et al., 2015). The recent work has featured deep learning as the state-of-the-art method for EFP. In particular, (Qian et al., 2018) presents a model based on Generative Adversarial Networks (GAN) while (Rudinger et al., 2018) applies Long-short Term Memory Networks (LSTM) over both the sequential order and the dependency tree of the input senMotivated by this limita"
2021.wnut-1.6,P17-2056,0,0.175777,"Extraction (IE), an event mention is represented via an anchor/trigger word that evokes an event in the input sentence. We study the problem of Event Factuality Prediction (EFP) that aims to identify the degrees of uncertainty/factuality for event mentions in text. Among others, EFP finds its applications in knowledge base construction to differentiate between factual and non-factual event mentions. In this work, we follow the recent regression formulation for EFP that seeks to predict a real-valued score in the range of [-3,3] to indicate the occurrence possibility for a given event mention (Stanovsky et al., 2017; Rudinger et al., 2018). For instance, in the sentence “He cannot go to the restaurant.”, “go” is the trigger word for an event mention with the factuality score of -3 (i.e., certainly not happened). Despite their success, a major limitation of the current deep learning models for EFP is their inability to capture the multi-hop paths between the words to produce the importance scores in the sentence structures for EFP. In particular, the current deep learning models for EFP have only focused on the direct connection/relation (i.e., one-hop path) between a pair of words to determine the import"
2021.wnut-1.6,2021.naacl-main.3,1,0.822446,"Missing"
2021.wnut-1.6,2021.acl-long.490,1,0.744773,"and information bottleneck to improve the generalization for EFP. Model-wise, our work bears some similarity with other NLP models that leverage syntactic structures and GCNs to encode input texts for different NLP tasks, including relation extraction (Zhang et al., 2018), joint information extraction (Nguyen et al., 2021), metaphor detection (Le et al., 2020), and rumor detection (Veyseh et al., 2019b). Finally, we also note some related tasks for EFP that seek to classify event trigger words in texts, including event detection (Nguyen and Grishman, 2015; Chen et al., 2015; Lai et al., 2020; Veyseh et al., 2021), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016) and uncertainty detection (Adel and Schütze, 2017). 3 Structure Generation The goal of this section is to generate the initial sentence structures that would be combined in the next steps to generate richer structures for representation learning in EFP. Formally, the sentence structures in this work can be seen as the importance score matrices of size N × N . Each cell (i, j) in these matrices contains a score to represent the importance of the contextual information from wj for the representation vector of wi if this v"
2021.wnut-1.6,P15-2060,1,0.802157,"earn the sentence structures with the multi-hop path reasoning, and information bottleneck to improve the generalization for EFP. Model-wise, our work bears some similarity with other NLP models that leverage syntactic structures and GCNs to encode input texts for different NLP tasks, including relation extraction (Zhang et al., 2018), joint information extraction (Nguyen et al., 2021), metaphor detection (Le et al., 2020), and rumor detection (Veyseh et al., 2019b). Finally, we also note some related tasks for EFP that seek to classify event trigger words in texts, including event detection (Nguyen and Grishman, 2015; Chen et al., 2015; Lai et al., 2020; Veyseh et al., 2021), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016) and uncertainty detection (Adel and Schütze, 2017). 3 Structure Generation The goal of this section is to generate the initial sentence structures that would be combined in the next steps to generate richer structures for representation learning in EFP. Formally, the sentence structures in this work can be seen as the importance score matrices of size N × N . Each cell (i, j) in these matrices contains a score to represent the importance of the contextual inform"
2021.wnut-1.6,P19-1432,1,0.0824454,"sentences (i.e., the cue words) and combine them appropriately to reveal the factuality for the event triggers. As the important context words might be distributed at different positions in the sentences, the current stateof-the-art deep learning models for EFP have relied on the sentence structures to facilitate the identification of the cue words. In particular, the sentence structures in the EFP models can be represented via the importance score matrices that involve cells to quantify the contribution of a context word for the representation vector computation of the current word for EFP (Veyseh et al., 2019a). The sentence structures would then be used to induce the representation vectors for the words to perform factuality prediction. Both syntactic and semantic structures of the sentences have been exploited in the deep learning models for EFP. As such, the syntactic structures are based on the direct connections between the words in the dependency parsing trees of the input sentences while the contextual similarities between the words are employed to form the semantic structures (Veyseh et al., 2019a). The goal of Event Factuality Prediction (EFP) is to determine the factual degree of an even"
2021.wnut-1.6,C10-2117,0,0.0182427,"at can be further extended to “Hagai”, “member”, and “confirmed” via the dependency connections for representation learning. Besides the multi-hop nature, we also note that the edges along the multihop path in this example contains both syntactic and semantic connections (i.e., heterogeneous edge types) that are necessary to identify the important context words for EFP. 2 Related Work Various methods have been proposed to solve EFP, including the early rule-based approaches (Nairn et al., 2006; Saurí, 2008; Lotan et al., 2013), the feature-based machine learning approaches (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), and the hybrid methods (Saurí and Pustejovsky, 2012; Qian et al., 2015). The recent work has featured deep learning as the state-of-the-art method for EFP. In particular, (Qian et al., 2018) presents a model based on Generative Adversarial Networks (GAN) while (Rudinger et al., 2018) applies Long-short Term Memory Networks (LSTM) over both the sequential order and the dependency tree of the input senMotivated by this limitation, in this work, we propose to learn the importance scores for the sentence structures, leveraging Graph Transformer Networ"
2021.wnut-1.6,D18-1244,0,0.0277673,"2019a) that linearly combines the syntactic and semantic structures for Graph Convolutional Neural Networks (GCN). We also employ syntactic and semantic structures for EFP in this work; however, our model presents novel techniques with triggerbased structure customization, GTNs to learn the sentence structures with the multi-hop path reasoning, and information bottleneck to improve the generalization for EFP. Model-wise, our work bears some similarity with other NLP models that leverage syntactic structures and GCNs to encode input texts for different NLP tasks, including relation extraction (Zhang et al., 2018), joint information extraction (Nguyen et al., 2021), metaphor detection (Le et al., 2020), and rumor detection (Veyseh et al., 2019b). Finally, we also note some related tasks for EFP that seek to classify event trigger words in texts, including event detection (Nguyen and Grishman, 2015; Chen et al., 2015; Lai et al., 2020; Veyseh et al., 2021), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016) and uncertainty detection (Adel and Schütze, 2017). 3 Structure Generation The goal of this section is to generate the initial sentence structures that would be combined in the"
C16-1218,P14-2013,0,0.567176,"pical coherence among the target entities referred by the entity mentions within the same document. This is undesirable as the topical coherence has been shown to be effective for EL in the previous work (Han et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 2310 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2310–2320, Osaka, Japan, December 11-17 2016. 2011; Hoffart et al., 2011; Ratinov et al., 2011; He et al., 2013b; Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015). (ii) The local approach might suffer from the data sparseness issue of unseen words/features, the difficulty of calibrating, and the failure to induce the underlying similarity structures at high levels of abstraction for EL (due to the extensive reliance on the hand-designed coarse features) (Sun et al., 2015; Francis-Landau et al., 2016). The first drawback of the local approach has been overcome by the global models in which all entity mentions (or a group of entity mentions) within a document are disambiguated simultaneously to obtain a coherent set of target enti"
C16-1218,W10-3503,0,0.437759,"Missing"
C16-1218,W06-1615,0,0.0661441,"els (except for the ACE dataset on Wikipedia 2014 and the WIKI dataset on Wikipedia 2016), thereby demonstrating the benefits of the joint modeling for local and global features via neural networks for EL in this work. 3.5 Domain Adaptation Experiments The purpose of this section is to further evaluate the models in the domain adaptation setting to investigate their cross-domain robustness for EL. It is often observed in many natural language processing tasks that the performance of a model trained on a source domain would degrade significantly when it is applied to a different target domain (Blitzer et al., 2006; Daume, 2007; McClosky et al., 2010; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). Such a performance loss originates from a variety of mismatches between the source and the target domains, including the differences in vocabulary, data distributions, styles etc. This has motivated the domain adaptation research that aims to improve the cross-domain performance of the models by adaptation techniques. One of the key strategies of the domain adaptation techniques is the search for the domain-independent features that are discriminative across different domains (Blitzer et al., 2006; Ji"
C16-1218,E06-1002,0,0.619818,"g the available context information in both the documents and the knowledge bases. The early approach for the ranking problem in EL has resolved the entity mentions in documents independently (the local approach), utilizing various discrete and hand-designed features/heuristics to measure the local mention-to-entity relatedness for ranking. These features are often specific to each entity mention and candidate entity, covering a wide range of linguistic and/or structured representations such as lexical and part-of-speech tags of context words, dependency paths, topical features, KB infoboxes (Bunescu and Pasca, 2006; Mendes et al., 2011; Cassidy et al., 2011; Ji and Grishman, 2011; Shen et al., 2014) etc. Although the local approach can exploit a rich set of discrete structures for EL, its limitation is twofold: (i) The independent ranking mechanism in the local approach overlooks the topical coherence among the target entities referred by the entity mentions within the same document. This is undesirable as the topical coherence has been shown to be effective for EL in the previous work (Han et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/"
C16-1218,D13-1184,0,0.0479497,"(Bunescu and Pasca, 2006; Milne and Witten, 2008; Zheng et al., 2010; Ji and Grishman, 2011; Mendes et al., 2011; Cassidy et al., 2011; Shen et al., 2014). In contrast, the global approach jointly maps all the entity mentions within documents to model the topical coherence. Various techniques have been exploited for capturing such semantic consistency, including Wikipedia category agreement (Cucerzan, 2007), Wikipedia link-based measures (Kulkarni et al., 2009; Hoffart et al., 2011; Shen et al., 2012), Point-wise Mutual Information measures (Ratinov et al., 2011), integer linear programming (Cheng and Roth, 2013), PageRank (Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015), stacked generalization (He et al., 2013a), to name a few. The entity linking techniques and systems have been actively evaluated at the NIST-organized Text Analysis Conference (Ji et al., 2014). Neural networks are applied to entity linking very recently. He et al. (2013b) learn enttiy representation via Stacked Denoising Auto-encoders. Sun et al. (2015) employ convolutional neural networks and neural tensor networks to model mentions, entities and contexts while Francis-Landau et al. (2016) combine CNN-based representations w"
C16-1218,D07-1074,0,0.612406,"internal structures of each separate mention-entity pair, covering the name string comparisons between the surfaces of the entity mentions and target candidates, entity popularity or entity type and so on (Bunescu and Pasca, 2006; Milne and Witten, 2008; Zheng et al., 2010; Ji and Grishman, 2011; Mendes et al., 2011; Cassidy et al., 2011; Shen et al., 2014). In contrast, the global approach jointly maps all the entity mentions within documents to model the topical coherence. Various techniques have been exploited for capturing such semantic consistency, including Wikipedia category agreement (Cucerzan, 2007), Wikipedia link-based measures (Kulkarni et al., 2009; Hoffart et al., 2011; Shen et al., 2012), Point-wise Mutual Information measures (Ratinov et al., 2011), integer linear programming (Cheng and Roth, 2013), PageRank (Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015), stacked generalization (He et al., 2013a), to name a few. The entity linking techniques and systems have been actively evaluated at the NIST-organized Text Analysis Conference (Ji et al., 2014). Neural networks are applied to entity linking very recently. He et al. (2013b) learn enttiy representation via Stacked Denoisin"
C16-1218,P07-1033,0,0.069154,"E dataset on Wikipedia 2014 and the WIKI dataset on Wikipedia 2016), thereby demonstrating the benefits of the joint modeling for local and global features via neural networks for EL in this work. 3.5 Domain Adaptation Experiments The purpose of this section is to further evaluate the models in the domain adaptation setting to investigate their cross-domain robustness for EL. It is often observed in many natural language processing tasks that the performance of a model trained on a source domain would degrade significantly when it is applied to a different target domain (Blitzer et al., 2006; Daume, 2007; McClosky et al., 2010; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). Such a performance loss originates from a variety of mismatches between the source and the target domains, including the differences in vocabulary, data distributions, styles etc. This has motivated the domain adaptation research that aims to improve the cross-domain performance of the models by adaptation techniques. One of the key strategies of the domain adaptation techniques is the search for the domain-independent features that are discriminative across different domains (Blitzer et al., 2006; Jiang, 2009; Pl"
C16-1218,Q14-1037,0,0.475289,"n to link other mentions in that document due to the semantic relatedness among them. For example, the appearances of “Manchester” and “Chelsea” as the football clubs in a document would make it more likely that the entity mention “Liverpool” in the same document is also a football club. Unfortunately, the coherence assumption of the global approach does not hold in some situations, necessitating the discrete/coarse features in the local approach as a mechanism to compensate for the potential exceptions of the coherence assumption (Ratinov et al., 2011; Hoffart et al., 2011; Sil et al., 2012; Durrett and Klein, 2014; Pershina et al., 2015). Consequently, the global approach is still subject to the second limitation of data sparseness of the local approach due to their use of discrete features. Recently, the surge of neural network (NN) models has presented an effective mechanism to mitigate the second limitation of the local approach. In such models, words are represented by continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013) and features for the entity mentions and candidate entities are automatically learnt from data. This essentially alleviates the data sparsene"
C16-1218,E14-1052,0,0.0329515,"Missing"
C16-1218,N16-1150,0,0.0631352,"Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2310–2320, Osaka, Japan, December 11-17 2016. 2011; Hoffart et al., 2011; Ratinov et al., 2011; He et al., 2013b; Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015). (ii) The local approach might suffer from the data sparseness issue of unseen words/features, the difficulty of calibrating, and the failure to induce the underlying similarity structures at high levels of abstraction for EL (due to the extensive reliance on the hand-designed coarse features) (Sun et al., 2015; Francis-Landau et al., 2016). The first drawback of the local approach has been overcome by the global models in which all entity mentions (or a group of entity mentions) within a document are disambiguated simultaneously to obtain a coherent set of target entities. The central idea is that the referent entities of some mentions in a document might in turn introduce useful information to link other mentions in that document due to the semantic relatedness among them. For example, the appearances of “Manchester” and “Chelsea” as the football clubs in a document would make it more likely that the entity mention “Liverpool”"
C16-1218,D15-1205,0,0.0184998,"ains should be related to each other. Eventually, we expect that the proposed model with global coherence features would be more robust to domain shifts than the local approach (Francis-Landau et al., 2016). 3.5.1 Dataset We use the ACE dataset to evaluate the cross-domain performance of the models. ACE involves documents in 6 different domains: broadcast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and webblogs (wl). Following the common practice of domain adaptation research on this dataset (Plank and Moschitti, 2013; Nguyen et al., 2015c; Gormley et al., 2015), we use news (the union of bn and nw) as the source domain and bc, cts, wl, un as four different target domains. We take half of bc as the development set and use the remaining data for testing. We note that news consists of formally written documents while a majority of the other domains is informal text, making the source and target domains very divergent in terms of vocabulary and styles (Plank and Moschitti, 2013). 3.5.2 Evaluation Table 3 compares Global-RNN with the neural network EL model in (Francis-Landau et al., 2016), the best reported model on the ACE dataset in the literature8 ."
C16-1218,D13-1041,0,0.0781351,"h overlooks the topical coherence among the target entities referred by the entity mentions within the same document. This is undesirable as the topical coherence has been shown to be effective for EL in the previous work (Han et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 2310 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2310–2320, Osaka, Japan, December 11-17 2016. 2011; Hoffart et al., 2011; Ratinov et al., 2011; He et al., 2013b; Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015). (ii) The local approach might suffer from the data sparseness issue of unseen words/features, the difficulty of calibrating, and the failure to induce the underlying similarity structures at high levels of abstraction for EL (due to the extensive reliance on the hand-designed coarse features) (Sun et al., 2015; Francis-Landau et al., 2016). The first drawback of the local approach has been overcome by the global models in which all entity mentions (or a group of entity mentions) within a document are disambiguated simultaneously to obt"
C16-1218,P13-2006,0,0.497707,"h overlooks the topical coherence among the target entities referred by the entity mentions within the same document. This is undesirable as the topical coherence has been shown to be effective for EL in the previous work (Han et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 2310 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2310–2320, Osaka, Japan, December 11-17 2016. 2011; Hoffart et al., 2011; Ratinov et al., 2011; He et al., 2013b; Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015). (ii) The local approach might suffer from the data sparseness issue of unseen words/features, the difficulty of calibrating, and the failure to induce the underlying similarity structures at high levels of abstraction for EL (due to the extensive reliance on the hand-designed coarse features) (Sun et al., 2015; Francis-Landau et al., 2016). The first drawback of the local approach has been overcome by the global models in which all entity mentions (or a group of entity mentions) within a document are disambiguated simultaneously to obt"
C16-1218,D11-1072,0,0.559865,"Missing"
C16-1218,P11-1115,0,0.243312,"owledge bases. The early approach for the ranking problem in EL has resolved the entity mentions in documents independently (the local approach), utilizing various discrete and hand-designed features/heuristics to measure the local mention-to-entity relatedness for ranking. These features are often specific to each entity mention and candidate entity, covering a wide range of linguistic and/or structured representations such as lexical and part-of-speech tags of context words, dependency paths, topical features, KB infoboxes (Bunescu and Pasca, 2006; Mendes et al., 2011; Cassidy et al., 2011; Ji and Grishman, 2011; Shen et al., 2014) etc. Although the local approach can exploit a rich set of discrete structures for EL, its limitation is twofold: (i) The independent ranking mechanism in the local approach overlooks the topical coherence among the target entities referred by the entity mentions within the same document. This is undesirable as the topical coherence has been shown to be effective for EL in the previous work (Han et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 2310 Proceedings of COLI"
C16-1218,P09-1114,0,0.0281284,"06; Daume, 2007; McClosky et al., 2010; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). Such a performance loss originates from a variety of mismatches between the source and the target domains, including the differences in vocabulary, data distributions, styles etc. This has motivated the domain adaptation research that aims to improve the cross-domain performance of the models by adaptation techniques. One of the key strategies of the domain adaptation techniques is the search for the domain-independent features that are discriminative across different domains (Blitzer et al., 2006; Jiang, 2009; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). These invariants serve as the connectors between different domains and help to transfer the knowledge from one domain to the others. For EL, we hypothesize that the global coherence is an effective domain-independent feature that would help to improve the crossdomain performance of the models. The intuition is that the entities mentioned in a document of any domains should be related to each other. Eventually, we expect that the proposed model with global coherence features would be more robust to domain shifts than the local approach ("
C16-1218,P14-1062,0,0.0134622,"a sparseness of the local approach due to their use of discrete features. Recently, the surge of neural network (NN) models has presented an effective mechanism to mitigate the second limitation of the local approach. In such models, words are represented by continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013) and features for the entity mentions and candidate entities are automatically learnt from data. This essentially alleviates the data sparseness problem of unseen words/features and helps to extract more effective features for EL in a given dataset (Kalchbrenner et al., 2014; Nguyen et al., 2016a). In practice, the features automatically induced by NN are combined with the discrete features in the local approach to extend their coverage for EL (Sun et al., 2015; Francis-Landau et al., 2016). However, as the previous NN models for EL are local, they cannot capture the global interdependence among the target entities in the same document (the first limitation of the local approach). Guided by these analyses, in this paper, we propose to use neural networks to model both the local mention-to-entity similarities and the global relatedness among target entities in an"
C16-1218,N10-1004,0,0.0111721,"Wikipedia 2014 and the WIKI dataset on Wikipedia 2016), thereby demonstrating the benefits of the joint modeling for local and global features via neural networks for EL in this work. 3.5 Domain Adaptation Experiments The purpose of this section is to further evaluate the models in the domain adaptation setting to investigate their cross-domain robustness for EL. It is often observed in many natural language processing tasks that the performance of a model trained on a source domain would degrade significantly when it is applied to a different target domain (Blitzer et al., 2006; Daume, 2007; McClosky et al., 2010; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). Such a performance loss originates from a variety of mismatches between the source and the target domains, including the differences in vocabulary, data distributions, styles etc. This has motivated the domain adaptation research that aims to improve the cross-domain performance of the models by adaptation techniques. One of the key strategies of the domain adaptation techniques is the search for the domain-independent features that are discriminative across different domains (Blitzer et al., 2006; Jiang, 2009; Plank and Moschitti, 2013"
C16-1218,P14-2012,1,0.853076,"016), thereby demonstrating the benefits of the joint modeling for local and global features via neural networks for EL in this work. 3.5 Domain Adaptation Experiments The purpose of this section is to further evaluate the models in the domain adaptation setting to investigate their cross-domain robustness for EL. It is often observed in many natural language processing tasks that the performance of a model trained on a source domain would degrade significantly when it is applied to a different target domain (Blitzer et al., 2006; Daume, 2007; McClosky et al., 2010; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). Such a performance loss originates from a variety of mismatches between the source and the target domains, including the differences in vocabulary, data distributions, styles etc. This has motivated the domain adaptation research that aims to improve the cross-domain performance of the models by adaptation techniques. One of the key strategies of the domain adaptation techniques is the search for the domain-independent features that are discriminative across different domains (Blitzer et al., 2006; Jiang, 2009; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). These invariants serve"
C16-1218,W15-1506,1,0.837489,"on for x, we first transform each word xi ∈ x into a real-valued, h-dimensional vector wi using the word embedding table E (Mikolov et al., 2013): wi = E[xi ]. This essentially converts the word sequence x into a sequence of vectors that is padded with zero vectors to form a fixed-length sequence of vectors w = (w1 , w2 , . . . , wn ) of length n. In the next step, we apply the convolution operation over w to generate the hidden vector sequence, that is then transformed by a non-linear function G and pooled by the sum function (Francis-Landau et al., 2016). Following the previous work on CNN (Nguyen and Grishman, (2015a; 2015b)), we utilize the set L of multiple window sizes to parameterize the convolution operation. Each window size l ∈ L corresponds to a convolution matrix Ml ∈ Rv×lh of dimensionality v. Eventually, the concatenation vector x ¯ of the resulting vectors for each window size in L would be used as the distributed representation for x: x¯ = L M n−l+1 X l∈L G(Ml wi:(i+l−1) ) i=1 where is the concatenation operation over the window set L and wi:(i+l−1) is the concatenation vector of the given word vectors. For convenience, let s¯i , c¯i , d¯i , t¯ij , ¯bij , t¯∗i and ¯b∗i be the distributed rep"
C16-1218,P15-2060,1,0.862736,"on for x, we first transform each word xi ∈ x into a real-valued, h-dimensional vector wi using the word embedding table E (Mikolov et al., 2013): wi = E[xi ]. This essentially converts the word sequence x into a sequence of vectors that is padded with zero vectors to form a fixed-length sequence of vectors w = (w1 , w2 , . . . , wn ) of length n. In the next step, we apply the convolution operation over w to generate the hidden vector sequence, that is then transformed by a non-linear function G and pooled by the sum function (Francis-Landau et al., 2016). Following the previous work on CNN (Nguyen and Grishman, (2015a; 2015b)), we utilize the set L of multiple window sizes to parameterize the convolution operation. Each window size l ∈ L corresponds to a convolution matrix Ml ∈ Rv×lh of dimensionality v. Eventually, the concatenation vector x ¯ of the resulting vectors for each window size in L would be used as the distributed representation for x: x¯ = L M n−l+1 X l∈L G(Ml wi:(i+l−1) ) i=1 where is the concatenation operation over the window set L and wi:(i+l−1) is the concatenation vector of the given word vectors. For convenience, let s¯i , c¯i , d¯i , t¯ij , ¯bij , t¯∗i and ¯b∗i be the distributed rep"
C16-1218,P15-1062,1,0.848157,"a document of any domains should be related to each other. Eventually, we expect that the proposed model with global coherence features would be more robust to domain shifts than the local approach (Francis-Landau et al., 2016). 3.5.1 Dataset We use the ACE dataset to evaluate the cross-domain performance of the models. ACE involves documents in 6 different domains: broadcast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and webblogs (wl). Following the common practice of domain adaptation research on this dataset (Plank and Moschitti, 2013; Nguyen et al., 2015c; Gormley et al., 2015), we use news (the union of bn and nw) as the source domain and bc, cts, wl, un as four different target domains. We take half of bc as the development set and use the remaining data for testing. We note that news consists of formally written documents while a majority of the other domains is informal text, making the source and target domains very divergent in terms of vocabulary and styles (Plank and Moschitti, 2013). 3.5.2 Evaluation Table 3 compares Global-RNN with the neural network EL model in (Francis-Landau et al., 2016), the best reported model on the ACE datas"
C16-1218,N16-1034,1,0.779583,"pproach due to their use of discrete features. Recently, the surge of neural network (NN) models has presented an effective mechanism to mitigate the second limitation of the local approach. In such models, words are represented by continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013) and features for the entity mentions and candidate entities are automatically learnt from data. This essentially alleviates the data sparseness problem of unseen words/features and helps to extract more effective features for EL in a given dataset (Kalchbrenner et al., 2014; Nguyen et al., 2016a). In practice, the features automatically induced by NN are combined with the discrete features in the local approach to extend their coverage for EL (Sun et al., 2015; Francis-Landau et al., 2016). However, as the previous NN models for EL are local, they cannot capture the global interdependence among the target entities in the same document (the first limitation of the local approach). Guided by these analyses, in this paper, we propose to use neural networks to model both the local mention-to-entity similarities and the global relatedness among target entities in an unified architecture."
C16-1218,N15-1026,0,0.538127,"entities referred by the entity mentions within the same document. This is undesirable as the topical coherence has been shown to be effective for EL in the previous work (Han et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 2310 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2310–2320, Osaka, Japan, December 11-17 2016. 2011; Hoffart et al., 2011; Ratinov et al., 2011; He et al., 2013b; Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015). (ii) The local approach might suffer from the data sparseness issue of unseen words/features, the difficulty of calibrating, and the failure to induce the underlying similarity structures at high levels of abstraction for EL (due to the extensive reliance on the hand-designed coarse features) (Sun et al., 2015; Francis-Landau et al., 2016). The first drawback of the local approach has been overcome by the global models in which all entity mentions (or a group of entity mentions) within a document are disambiguated simultaneously to obtain a coherent set of target entities. The central idea i"
C16-1218,P13-1147,0,0.136387,"WIKI dataset on Wikipedia 2016), thereby demonstrating the benefits of the joint modeling for local and global features via neural networks for EL in this work. 3.5 Domain Adaptation Experiments The purpose of this section is to further evaluate the models in the domain adaptation setting to investigate their cross-domain robustness for EL. It is often observed in many natural language processing tasks that the performance of a model trained on a source domain would degrade significantly when it is applied to a different target domain (Blitzer et al., 2006; Daume, 2007; McClosky et al., 2010; Plank and Moschitti, 2013; Nguyen and Grishman, 2014a). Such a performance loss originates from a variety of mismatches between the source and the target domains, including the differences in vocabulary, data distributions, styles etc. This has motivated the domain adaptation research that aims to improve the cross-domain performance of the models by adaptation techniques. One of the key strategies of the domain adaptation techniques is the search for the domain-independent features that are discriminative across different domains (Blitzer et al., 2006; Jiang, 2009; Plank and Moschitti, 2013; Nguyen and Grishman, 2014"
C16-1218,P11-1157,0,0.0255394,"Missing"
C16-1218,P11-1138,0,0.566842,"m in the local approach overlooks the topical coherence among the target entities referred by the entity mentions within the same document. This is undesirable as the topical coherence has been shown to be effective for EL in the previous work (Han et al., This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/ License details: http:// 2310 Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 2310–2320, Osaka, Japan, December 11-17 2016. 2011; Hoffart et al., 2011; Ratinov et al., 2011; He et al., 2013b; Alhelbawy and Gaizauskas, 2014; Pershina et al., 2015). (ii) The local approach might suffer from the data sparseness issue of unseen words/features, the difficulty of calibrating, and the failure to induce the underlying similarity structures at high levels of abstraction for EL (due to the extensive reliance on the hand-designed coarse features) (Sun et al., 2015; Francis-Landau et al., 2016). The first drawback of the local approach has been overcome by the global models in which all entity mentions (or a group of entity mentions) within a document are disambiguated simu"
C16-1218,D12-1011,0,0.0143572,"useful information to link other mentions in that document due to the semantic relatedness among them. For example, the appearances of “Manchester” and “Chelsea” as the football clubs in a document would make it more likely that the entity mention “Liverpool” in the same document is also a football club. Unfortunately, the coherence assumption of the global approach does not hold in some situations, necessitating the discrete/coarse features in the local approach as a mechanism to compensate for the potential exceptions of the coherence assumption (Ratinov et al., 2011; Hoffart et al., 2011; Sil et al., 2012; Durrett and Klein, 2014; Pershina et al., 2015). Consequently, the global approach is still subject to the second limitation of data sparseness of the local approach due to their use of discrete features. Recently, the surge of neural network (NN) models has presented an effective mechanism to mitigate the second limitation of the local approach. In such models, words are represented by continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013) and features for the entity mentions and candidate entities are automatically learnt from data. This essentially all"
C16-1218,P10-1040,0,0.0292972,"al approach as a mechanism to compensate for the potential exceptions of the coherence assumption (Ratinov et al., 2011; Hoffart et al., 2011; Sil et al., 2012; Durrett and Klein, 2014; Pershina et al., 2015). Consequently, the global approach is still subject to the second limitation of data sparseness of the local approach due to their use of discrete features. Recently, the surge of neural network (NN) models has presented an effective mechanism to mitigate the second limitation of the local approach. In such models, words are represented by continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013) and features for the entity mentions and candidate entities are automatically learnt from data. This essentially alleviates the data sparseness problem of unseen words/features and helps to extract more effective features for EL in a given dataset (Kalchbrenner et al., 2014; Nguyen et al., 2016a). In practice, the features automatically induced by NN are combined with the discrete features in the local approach to extend their coverage for EL (Sun et al., 2015; Francis-Landau et al., 2016). However, as the previous NN models for EL are local, they cannot capture the glo"
C16-1218,N10-1072,0,0.0165096,"ews. 4 Related Work Entity linking or disambiguation has been studied extensively in NLP research, falling broadly into two major approaches: local and global disambiguation. Both approaches share the goal of measuring the similarities between the entity mentions and the target candidates in the reference KB. The local paradigm focuses on the internal structures of each separate mention-entity pair, covering the name string comparisons between the surfaces of the entity mentions and target candidates, entity popularity or entity type and so on (Bunescu and Pasca, 2006; Milne and Witten, 2008; Zheng et al., 2010; Ji and Grishman, 2011; Mendes et al., 2011; Cassidy et al., 2011; Shen et al., 2014). In contrast, the global approach jointly maps all the entity mentions within documents to model the topical coherence. Various techniques have been exploited for capturing such semantic consistency, including Wikipedia category agreement (Cucerzan, 2007), Wikipedia link-based measures (Kulkarni et al., 2009; Hoffart et al., 2011; Shen et al., 2012), Point-wise Mutual Information measures (Ratinov et al., 2011), integer linear programming (Cheng and Roth, 2013), PageRank (Alhelbawy and Gaizauskas, 2014; Pers"
C18-1193,H05-1091,0,0.0760554,"ght lead to an incorrect impression to consider the sentence as actually positive. For instance, consider the following negative sentence with the words in the similar word lists written in bold3 : Marion Police Department have arrested TARGET , 20 , of Marion , in connection with the fatal hit. In this sentence, the extreme emphasis on “Police”, “TARGET” and “fatal” might lead to the incorrect prediction that this sentence is expressing a fatal event caused by police. In order to overcome this issue, we observe that police killing recognition can be seen as a relation identification problem (Bunescu and Mooney, 2005), attempting to decide whether the entities of interests (i.e, the “TARGET”) has a semantical relation of “killed by” with the similar words of “police” (if any) in the sentence or not. In such relation identification problem, it has been shown that the shortest dependency path connecting the two word of interests (i.e, the words “TARGET” and “police” in our case) in the dependency trees involve the most important context words for the problem (Bunescu and Mooney, 2005). Consequently, in this work, we propose to select the words along the shortest dependency paths between the entity name of in"
C18-1193,P07-1073,0,0.0271402,"vent types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence rep"
C18-1193,P15-1017,0,0.0470026,"To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce train"
C18-1193,P16-1046,0,0.0370437,"ment of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position embeddings and supervised attentions to inject external knowledge (i.e, the heuristics for guid"
C18-1193,P17-1020,0,0.0362323,"et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position embeddings and supervised attentions to i"
C18-1193,D17-1163,0,0.0856913,"Missing"
C18-1193,P14-1038,0,0.0168207,"for the problem of detecting police killings. To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, dis"
C18-1193,P16-1200,0,0.0253152,"killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position e"
C18-1193,P17-1164,0,0.495871,"ours is (Yang et al., 2016) that utilizes hierarchical LSTMs for text categorization. Our model also relies on hierarchical LSTMs, but it is designed for police killing detection, characterizing position embeddings and supervised attentions to inject external knowledge (i.e, the heuristics for guidance words). Finally, supervised attention mechanisms have been used recently for several natural language tasks. For machine translation, the attention guidance is based on word alignment (Mi et al., 2016; Liu et al., 2016) while entity mentions are chosen as the guidance words for event detection (Liu et al., 2017a). Our work in this paper is different as we consider supervised attention for police killing recognition using semantical word lists and dependency parsing trees (Schuster and Manning, 2016) to guide the attention components. Our model features hierarchical LSTMs to tackle distant supervision data that does not emerge in such prior work. 3 Model We formalize the problem of finding people killed by police as follows. Let D be a set of documents (corpus), E = {ei }N i=1 be the set of entities (people) whose names appear in D (N is the number of the entities in E), and C = {ci }N i=1 be the set"
C18-1193,D16-1249,0,0.447331,"nd relatively low weights to the other important context words in the sentences. Such failure to adequately capture those context words would potentially lead to incorrect predictions for the containers. This problem is stem from the use of the position embeddings to specify the names of interests that might put too much emphasis on the current names. In order to solve this problem, we propose to integrate the supervised attention mechanisms into the hierarchical LSTM model that help to bias the attention scores toward the heuristically important words in the sentences (supervised attention) (Mi et al., 2016). In particular, we rely on linguistic intuitions to heuristically select the informative context words for the problem of police killing detection. These words are then used to guide the attention computation via penalizing the model parameters that generate low attention scores for such guidance words. We investigate several heuristics to choose the guidance words based on semantical word lists and dependency trees. The experiments show that the supervised attention mechanism with those heuristics helps to improve the performance of the hierarchical LSTM model and yield the state-of-the-art"
C18-1193,P09-1113,0,0.483699,"police killings from text is a relatively new problem in machine learning research with no available training datasets to supervise the models. The only sources of supervision on which we can rely for this problem are the current databases that record the names of the police-killed victims in the past. Among these databases, the Fatal Encounters1 (FE) database has emerged as the most comprehensive database with a relatively large number of recorded victims (over 23,000 victims). In order to take advantage of this database, (Keith et al., 2017) employs distant supervision (Craven et al., 1999; Mintz et al., 2009) that extracts person names from a corpus and aligns them with the victim names in the database. The matched names are considered as corresponding to people killed by police (positive entities) while the non-matched names constitute the negative examples in a binary classification problem for names in police killing detection. As the name itself does not carry much information, each extracted name is associated with the set of sentences in which the name appears in the corpus. This set of sentences is called the sentence container for the corresponding name (person). The sentence containers al"
C18-1193,W15-1506,1,0.947701,"f detecting police killings. To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been u"
C18-1193,P15-2060,1,0.947652,"f detecting police killings. To the best of our knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been u"
C18-1193,D16-1085,1,0.85262,"knowledge, this is the first work that introduces supervised attention into the hierarchical LSTM models and employs semantical word lists and dependency trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extra"
C18-1193,N16-1034,1,0.946742,"trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke e"
C18-1193,W16-1618,1,0.912772,"trees to select guidance words. 2278 2 Related Work Although police killing recognition is a new task, it has some elements with the information extraction (IE) research of NLP that can be used to solve the task with some modifications. The most related IE task for police killing detection is event extraction that aims to detect events (i.e, marriage, attack, die etc.) in text (Li and Ji, 2014; Nguyen and Grishman, 2015b; Chen et al., 2015; Nguyen and Grishman, 2016b). Killings is one of the event types that the current event extraction systems can identify (Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke e"
C18-1193,reschke-etal-2014-event,0,0.0147358,"al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most related model to ours is (Yang et al., 2016) th"
C18-1193,L16-1376,0,0.0539323,"haracterizing position embeddings and supervised attentions to inject external knowledge (i.e, the heuristics for guidance words). Finally, supervised attention mechanisms have been used recently for several natural language tasks. For machine translation, the attention guidance is based on word alignment (Mi et al., 2016; Liu et al., 2016) while entity mentions are chosen as the guidance words for event detection (Liu et al., 2017a). Our work in this paper is different as we consider supervised attention for police killing recognition using semantical word lists and dependency parsing trees (Schuster and Manning, 2016) to guide the attention components. Our model features hierarchical LSTMs to tackle distant supervision data that does not emerge in such prior work. 3 Model We formalize the problem of finding people killed by police as follows. Let D be a set of documents (corpus), E = {ei }N i=1 be the set of entities (people) whose names appear in D (N is the number of the entities in E), and C = {ci }N i=1 be the set of sentence containers for the entities in E (i.e, ci is the set of sentences that contain the name of the entity ei in D). Each entity ei in E has a label yei ∈ {0, 1}, denoting whether ei h"
C18-1193,D12-1042,0,0.0181933,"Das et al., 2014; Li and Ji, 2014; Nguyen et al., 2016c), allowing the detection of police killing incidents when appropriate adaptations are introduced. Unfortunately, such adaptations result in poor performance for police killing recognition as shown in (Keith et al., 2017). Distant supervision is another element of IE that is employed in this research to generate training data for police killing detection. In particular, distant supervision has been used to produce training data for relation extraction (Craven et al., 1999; Bunescu and Mooney, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2012) and event extraction (Reschke et al., 2014). Hierarchical deep learning techniques that model both the word and sentence levels have been employed for several NLP tasks, including relation extraction (Lin et al., 2016), question answering (Choi et al., 2017) and extractive summarization (Cheng and Lapata, 2016). Such work often uses convolutional neural networks to operate at the work level. This is different from our proposed model for police killing detection that employs LSTMs and supervised attentions to acquire sentence representations for police killing recognition. Perhaps the most rel"
C18-1193,N16-1174,0,0.401786,"sentence level classifiers, the performance of the EM-based framework drops significantly. We attribute this problem to the limitation of the EM-based framework to train the non-convex classifiers of deep learning, causing the inability to exploit the automatically learnt representations from deep learning and necessitating the use of complicated and laborious feature engineering. In order to overcome this problem, we propose a novel deep learning framework for the problem of police killing recognition via hierarchical long short-term memory networks (LSTM) (Hochreiter and Schmidhuber, 1997; Yang et al., 2016). Our model does not make individual predictions on each sentence with the latent variables but involves a direct prediction to the name of interest based on its sentence container. Two layers of LSTMs are applied to model the sentence containers. The first LSTM layer learns the representations for the sentences in the containers by recurring over their words (the word level). The second LSTM layer, on the other hand, consumes the sentence representations (the sentence level) to produce container representations for police killing predictions. Attention mechanisms are then introduced into both"
D15-1298,P14-2009,0,0.445943,"TSLDA (Nguyen and Shirai, 2015b), ASUM (Jo and Oh, 2011), JST (Lin and He, 2009) and FACTS model (Lakkaraju et al., 2011). Recursive Neural Network (RNN) is a kind of deep neural network. Using distributed representations of words (aka word embedding) (Bengio et al., 2003; Hinton, 1986), RNN merges word representations to represent phrases or sentences. It is one of the best methods to predict sentiment labels for the phrases (Socher et al., 2011; Socher et al., 2012; Socher et al., 2013). AdaRNN (Adaptive Recursive Neural Network) is an extension of RNN for Twitter sentiment classification (Dong et al., 2014a; Dong et al., 2014b). This paper proposes a new method PhraseRNN for ABSA. It is an extended model of RNN and AdaRNN, which are briefly introduced in Section 2. The basic idea is to make the representation of the target aspect richer by using syntactic information from both the dependency and constituent trees of the sentence. 2 Recursive Neural Networks for ABSA In RNN and AdaRNN, given a sentence containing a target aspect, “binary dependency tree” is built from a dependency tree of the sentence. Intuitively, it represents syntactic relations associated with the aspect. Each word (leaf) or"
D15-1298,P15-1131,1,0.115791,"ine an attitude, opinion and emotions of people toward aspects in a sentence. For example, given a sentence “Except the design, the phone is bad for me”, the system should classify positive and negative as the sentiments for the aspects ‘design’ and ‘phone’, respectively. The simple approach is to calculate a sentiment score of a given aspect as the weighted sum of opinion scores, which are defined by a sentiment lexicon, of all words in the sentence (Liu and Zhang, 2012; Pang and Lee, 2008). This method is further improved by identifying the aspect-opinion relations using tree kernel method (Nguyen and Shirai, 2015a). Other researches have attempted to use unsupervised topic modeling methods. To identify the sentiment category of the aspect, topic models which can simultaneously exploit aspect and sentiment have been proposed, such as TSLDA (Nguyen and Shirai, 2015b), ASUM (Jo and Oh, 2011), JST (Lin and He, 2009) and FACTS model (Lakkaraju et al., 2011). Recursive Neural Network (RNN) is a kind of deep neural network. Using distributed representations of words (aka word embedding) (Bengio et al., 2003; Hinton, 1986), RNN merges word representations to represent phrases or sentences. It is one of the be"
D15-1298,D12-1110,0,0.0140339,"s. To identify the sentiment category of the aspect, topic models which can simultaneously exploit aspect and sentiment have been proposed, such as TSLDA (Nguyen and Shirai, 2015b), ASUM (Jo and Oh, 2011), JST (Lin and He, 2009) and FACTS model (Lakkaraju et al., 2011). Recursive Neural Network (RNN) is a kind of deep neural network. Using distributed representations of words (aka word embedding) (Bengio et al., 2003; Hinton, 1986), RNN merges word representations to represent phrases or sentences. It is one of the best methods to predict sentiment labels for the phrases (Socher et al., 2011; Socher et al., 2012; Socher et al., 2013). AdaRNN (Adaptive Recursive Neural Network) is an extension of RNN for Twitter sentiment classification (Dong et al., 2014a; Dong et al., 2014b). This paper proposes a new method PhraseRNN for ABSA. It is an extended model of RNN and AdaRNN, which are briefly introduced in Section 2. The basic idea is to make the representation of the target aspect richer by using syntactic information from both the dependency and constituent trees of the sentence. 2 Recursive Neural Networks for ABSA In RNN and AdaRNN, given a sentence containing a target aspect, “binary dependency tree"
D15-1298,D13-1170,0,0.0307939,"ntiment category of the aspect, topic models which can simultaneously exploit aspect and sentiment have been proposed, such as TSLDA (Nguyen and Shirai, 2015b), ASUM (Jo and Oh, 2011), JST (Lin and He, 2009) and FACTS model (Lakkaraju et al., 2011). Recursive Neural Network (RNN) is a kind of deep neural network. Using distributed representations of words (aka word embedding) (Bengio et al., 2003; Hinton, 1986), RNN merges word representations to represent phrases or sentences. It is one of the best methods to predict sentiment labels for the phrases (Socher et al., 2011; Socher et al., 2012; Socher et al., 2013). AdaRNN (Adaptive Recursive Neural Network) is an extension of RNN for Twitter sentiment classification (Dong et al., 2014a; Dong et al., 2014b). This paper proposes a new method PhraseRNN for ABSA. It is an extended model of RNN and AdaRNN, which are briefly introduced in Section 2. The basic idea is to make the representation of the target aspect richer by using syntactic information from both the dependency and constituent trees of the sentence. 2 Recursive Neural Networks for ABSA In RNN and AdaRNN, given a sentence containing a target aspect, “binary dependency tree” is built from a depe"
D15-1298,P14-5010,0,0.0049908,"cy tree (Dong et al., 2014a). PhraseRNN-1: our PhraseRNN with only one global function: G = H = g1 PhraseRNN-2: our PhraseRNN with two global functions. One for inner-phrase, the other for outer-phrase: G = g1 and H = h1 PhraseRNN-3: our PhraseRNN with multiple global functions: G = H = {g1 , · · · , gn } PhraseRNN-4: our PhraseRNN with two lists of global functions. One for inner-phrase, the other for outer-phrase: G = {g1 , · · · , gn } and H = {h1 , · · · , hm }     P (h1 |vl , vr , eout ) vl   = sof tmax βS  vr  ··· P (hm |vl , vr , eout ) eout 2512 Evaluation Stanford CoreNLP (Manning et al., 2014) is used to parse the sentence and obtain constituent and dependency trees. For RNN, AdaRNN and PhraseRNN, the optimal parameters, which minimize the error in the development set, are used for the sentiment classification of the test set. We set β = 1 for AdaRNN and PhraseRNN since it is reported that β = 1 is the best parameter (Dong et al., 2014a). The optimized number of composition functions n and m = n2 are selected by grid search with n = {2, 4, 6, 8, 10} on the development set. λ = 0.0001 is employed. Accuracy (A), Precision (P), Recall (R) and F-measure (F) are used as evaluation metri"
D16-1085,W06-0901,0,0.0361632,"other models on the source domain. This is consistent with the conclusions in Section 3.2 and further confirms the effectiveness of NC-CNN. More importantly, NC-CNN outperforms CNN and the other models on the target domains bc, cts and un, and performs comparably with CNN on wl. The performance improvement is significant on bc and un (p < 0.05), thereby verifying the robustness of NC-CNN for ED across domains. Second, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED ver"
D16-1085,W06-1615,0,0.155357,"Missing"
D16-1085,R15-1011,1,0.911002,"Missing"
D16-1085,R15-1010,1,0.893886,"Missing"
D16-1085,P15-1017,0,0.758339,"state-of-the-art systems. 1 Introduction The goal of event detection (ED) is to locate event triggers of some specified types in text. Triggers are generally single verbs or nominalizations that evoke the events of interest. This is an important and challenging task of information extraction in natural language processing (NLP), as the same event might appear in various expressions, and an expression might express different events depending on contexts. The current state-of-the-art systems for ED have involved the application of convolutional neural networks (CNN) (Nguyen and Grishman, 2015b; Chen et al., 2015) that automatically learn effective feature representations for ED from sentences. This has overcome the two fundamental limitations of the traditional feature-based methods for ED: (i) the complicated feature engineering for rich feature sets and (ii) the error propagation from the NLP toolkits and resources (i.e, parsers, part of speech taggers etc) that generate such features. The prior CNN models for ED are characterized by the temporal convolution operators that linearly map the vectors for the k-grams in the sentences into the feature space. Such k-gram vectors are obtained by concatenat"
D16-1085,P07-1033,0,0.0215556,"Missing"
D16-1085,P09-2093,0,0.0512251,"N. More importantly, NC-CNN outperforms CNN and the other models on the target domains bc, cts and un, and performs comparably with CNN on wl. The performance improvement is significant on bc and un (p < 0.05), thereby verifying the robustness of NC-CNN for ED across domains. Second, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen e"
D16-1085,P11-1113,0,0.123082,"valuation criteria follow those in (Nguyen and Grishman, 2015b). 3.2 The General Setting We compares the non-consecutive CNN model (NCCNN) with the state-of-the-art systems on the ACE 2005 dataset in Table 1. These systems include: 1) The feature-based systems with rich handdesigned feature sets, including: the MaxEnt model with local features in (Li et al., 2013) (MaxEnt); the structured perceptron model for joint beam search with local features (Joint+Local), and with both local and global features (Joint+Local+Global) in (Li et al., 2013); and the sentence-level and cross-entity models in (Hong et al., 2011). 2) The neural network models, i.e, the CNN model in (Nguyen and Grishman, 2015b) (CNN), the dynamic multi-pooling CNN model (DM-CNN) in (Chen et al., 2015) and the bidirectional recurrent neural networks (B-RNN) in (Nguyen et al., 2016a). 3) The probabilistic soft logic based model to capture the event-event correlation in (Liu et al., 2016). Methods Sentence-level in Hong et al (2011) MaxEnt (Li et al., 2013) Joint+Local (Li et al., 2013) Joint+Local+Global (Li et al., 2013) Cross-entity in Hong et al. (2011) † Probabilistic soft logic (Liu et al., 2016) † CNN (Nguyen and Grishman, 2015b) D"
D16-1085,N16-1056,0,0.059859,"ecent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidirectional recurrent neural networks to perform event trigger and argument labeling jointly, (Jagannatha and Yu, 2016) who extract event instances from health records with recurrent neural networks and (Nguyen et al., 2016b) who propose a two-stage training algorithm for event extension with neural networks. 4 We present a new CNN architecture for ED that exploits the non-consecutive convolution for sentences. Our evaluation of the proposed model on the general setting and the DA setting demonstrates the effectiveness of the non-consecutive mechanism. We achieve the state-of-the-art performance for ED in both settings. In the future, we plan to investigate the non-consecutive architecture on other problems su"
D16-1085,P08-1030,1,0.883064,"effectiveness of NC-CNN. More importantly, NC-CNN outperforms CNN and the other models on the target domains bc, cts and un, and performs comparably with CNN on wl. The performance improvement is significant on bc and un (p < 0.05), thereby verifying the robustness of NC-CNN for ED across domains. Second, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work"
D16-1085,D15-1180,0,0.0148629,"pose to improve the previous CNN models for ED by operating the convolution on all possible non-consecutive k-grams 886 Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 886–891, c Austin, Texas, November 1-5, 2016. 2016 Association for Computational Linguistics in the sentences. We aggregate the resulting convolution scores via the max-pooling function to unveil the most important non-consecutive k-grams for ED. The aggregation over all the possible nonconsecutive k-grams is made efficient with dynamic programming. Note that our work is related to (Lei et al., 2015) who employ the non-consecutive convolution for the sentence and news classification problems. Our work is different from (Lei et al., 2015) in that we model the relative distances of words to the trigger candidates in the sentences via position embeddings, while (Lei et al., 2015) use the absolute distances between words in the k-grams to compute the decay weights for aggregation. To the best of our knowledge, this is the first work on non-consecutive CNN for ED. We systematically evaluate the proposed model in the general setting as well as the domain adaptation setting. The experiment resul"
D16-1085,P13-1008,0,0.352819,"arameters and resources as (Nguyen and Grishman, 2015b) to ensure the compatible comparison. Specifically, we employ the window sizes in the set {2, 3, 4, 5} for the convolution operation with 150 filters for each window size. The window size of the trigger candidate is 31 while the dimensionality of the position embeddings and entity type embeddings is 50. We use word2vec from (Mikolov et al., 2013b) as the pretrained word embeddings. The other parameters include the dropout rate ⇢ = 0.5, the mini-batch size = 50, the predefined threshold for the l2 norms = 3. Following the previous studies (Li et al., 2013; Chen et al., 2015; Nguyen and Grishman, 2015b), we evaluate the models on the ACE 2005 corpus 2 : 0  i1 < i2 < . . . < ik  2n} 1 1 We ignore the base cases as they are trivial. with 33 event subtypes. In order to make it compatible, we use the same test set with 40 newswire articles, the same development set with 30 other documents and the same training set with the remaining 529 documents. All the data preprocessing and evaluation criteria follow those in (Nguyen and Grishman, 2015b). 3.2 The General Setting We compares the non-consecutive CNN model (NCCNN) with the state-of-the-art syste"
D16-1085,W15-4502,1,0.86005,"comparably with CNN on wl. The performance improvement is significant on bc and un (p < 0.05), thereby verifying the robustness of NC-CNN for ED across domains. Second, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidirectional recurrent neural networks to perform event trigger and argument labeling jo"
D16-1085,R11-1002,1,0.855704,"he other models on the target domains bc, cts and un, and performs comparably with CNN on wl. The performance improvement is significant on bc and un (p < 0.05), thereby verifying the robustness of NC-CNN for ED across domains. Second, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidirectional recurrent neura"
D16-1085,P11-1163,0,0.034387,"s and un, and performs comparably with CNN on wl. The performance improvement is significant on bc and un (p < 0.05), thereby verifying the robustness of NC-CNN for ED across domains. Second, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidirectional recurrent neural networks to perform event trigger and ar"
D16-1085,W15-1506,1,0.0835837,"mprovement over the current state-of-the-art systems. 1 Introduction The goal of event detection (ED) is to locate event triggers of some specified types in text. Triggers are generally single verbs or nominalizations that evoke the events of interest. This is an important and challenging task of information extraction in natural language processing (NLP), as the same event might appear in various expressions, and an expression might express different events depending on contexts. The current state-of-the-art systems for ED have involved the application of convolutional neural networks (CNN) (Nguyen and Grishman, 2015b; Chen et al., 2015) that automatically learn effective feature representations for ED from sentences. This has overcome the two fundamental limitations of the traditional feature-based methods for ED: (i) the complicated feature engineering for rich feature sets and (ii) the error propagation from the NLP toolkits and resources (i.e, parsers, part of speech taggers etc) that generate such features. The prior CNN models for ED are characterized by the temporal convolution operators that linearly map the vectors for the k-grams in the sentences into the feature space. Such k-gram vectors are o"
D16-1085,P15-2060,1,0.700861,"Missing"
D16-1085,P15-1062,1,0.455113,"Missing"
D16-1085,N16-1034,1,0.745221,"he feature-based systems with rich handdesigned feature sets, including: the MaxEnt model with local features in (Li et al., 2013) (MaxEnt); the structured perceptron model for joint beam search with local features (Joint+Local), and with both local and global features (Joint+Local+Global) in (Li et al., 2013); and the sentence-level and cross-entity models in (Hong et al., 2011). 2) The neural network models, i.e, the CNN model in (Nguyen and Grishman, 2015b) (CNN), the dynamic multi-pooling CNN model (DM-CNN) in (Chen et al., 2015) and the bidirectional recurrent neural networks (B-RNN) in (Nguyen et al., 2016a). 3) The probabilistic soft logic based model to capture the event-event correlation in (Liu et al., 2016). Methods Sentence-level in Hong et al (2011) MaxEnt (Li et al., 2013) Joint+Local (Li et al., 2013) Joint+Local+Global (Li et al., 2013) Cross-entity in Hong et al. (2011) † Probabilistic soft logic (Liu et al., 2016) † CNN (Nguyen and Grishman, 2015b) DM-CNN (Chen et al., 2015) B-RNN (Nguyen et al., 2016a) NC-CNN F 59.7 65.9 65.7 67.5 68.3 69.4 69.0 69.1 69.3 71.3 sentence-level information, it is still better than the other models that further exploit the document-level information fo"
D16-1085,W16-1618,1,0.812027,"he feature-based systems with rich handdesigned feature sets, including: the MaxEnt model with local features in (Li et al., 2013) (MaxEnt); the structured perceptron model for joint beam search with local features (Joint+Local), and with both local and global features (Joint+Local+Global) in (Li et al., 2013); and the sentence-level and cross-entity models in (Hong et al., 2011). 2) The neural network models, i.e, the CNN model in (Nguyen and Grishman, 2015b) (CNN), the dynamic multi-pooling CNN model (DM-CNN) in (Chen et al., 2015) and the bidirectional recurrent neural networks (B-RNN) in (Nguyen et al., 2016a). 3) The probabilistic soft logic based model to capture the event-event correlation in (Liu et al., 2016). Methods Sentence-level in Hong et al (2011) MaxEnt (Li et al., 2013) Joint+Local (Li et al., 2013) Joint+Local+Global (Li et al., 2013) Cross-entity in Hong et al. (2011) † Probabilistic soft logic (Liu et al., 2016) † CNN (Nguyen and Grishman, 2015b) DM-CNN (Chen et al., 2015) B-RNN (Nguyen et al., 2016a) NC-CNN F 59.7 65.9 65.7 67.5 68.3 69.4 69.0 69.1 69.3 71.3 sentence-level information, it is still better than the other models that further exploit the document-level information fo"
D16-1085,D09-1016,0,0.068529,"NC-CNN outperforms CNN and the other models on the target domains bc, cts and un, and performs comparably with CNN on wl. The performance improvement is significant on bc and un (p < 0.05), thereby verifying the robustness of NC-CNN for ED across domains. Second, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidi"
D16-1085,P13-1147,0,0.042707,"Missing"
D16-1085,N10-1123,0,0.082444,"approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidirectional recurrent neural networks to perform event trigger and argument labeling jointly, (Jagannatha and Yu, 2016) who extract event instances from health records with recurrent neural networks and (Nguyen et al., 2016b) who propose a two-stage training algorithm for event exten"
D16-1085,W09-1406,0,0.0606611,"d, the feature-based approach relies on linguistic intuition to design effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidirectional recurrent neural networks to perform event trigger and argument labeling jointly, (Jagannatha and Yu, 2016) who extract event instances from health records with recurrent neural networks and (Nguyen et al., 2016b) who propose a two-stage traini"
D16-1085,P10-1040,0,0.0247854,"limit the context of the trigger candidates to a fixed window size by trimming longer sentences and padding shorter sentences with a special token when necessary. Let 2n + 1 be the fixed window size, and W = [w0 , w1 , . . . , wn , . . . , w2n 1 , w2n ] be some trigger candidate where the current token is positioned in the middle of the window (token wn ). Before entering CNN, each token wi is first transformed into a real-valued vector xi using the concatenation of the following vectors: 1. The word embedding vector of wi : This is obtained by looking up a pre-trained word embedding table D (Turian et al., 2010; Mikolov et al., 2013a). 887 2. The position embedding vector of wi : We obtain this vector by looking up the position embedding table for the relative distance i n from the token wi to the current token wn . The position embedding table is initialized randomly. 3. The real-valued embedding vector for the entity type of wi : This vector is generated by looking up the entity type embedding table (initialized randomly) for the entity type of wi . Note that we employ the BIO annotation schema to assign entity type labels to each token in the sentences using the entity mention heads as in (Nguyen"
D16-1085,D14-1090,0,0.084659,"sign effective feature sets for statistical models for ED, ranging from the local sentence-level representations (Ahn, 2006; Li et al., 2013), to the higher level structures such as the cross-sentence or cross-event information (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Li et al., 2015). Some recent work on the feature-based approach has also investigated event trigger detection in the joint inference with event argument prediction (Riedel et al., 2009; Poon and Vanderwende, 2010; Li et al., 2013; Venugopal et al., 2014) to benefit from their inter-dependencies. Finally, neural networks have been introduced into ED very recently with the early work on convolutional neural networks (Nguyen and Grishman, 2015b; Chen et al., 2015). The other work includes: (Nguyen et al., 2016a) who employ bidirectional recurrent neural networks to perform event trigger and argument labeling jointly, (Jagannatha and Yu, 2016) who extract event instances from health records with recurrent neural networks and (Nguyen et al., 2016b) who propose a two-stage training algorithm for event extension with neural networks. 4 We present a"
D18-1517,W06-0901,0,0.40071,"Missing"
D18-1517,D12-1133,0,0.0165865,"set. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5 Conclusion We present a method that improves the performance of deep learning models for ED by training two different versions of the same network architecture for ED and WSD, while encouraging the knowledge transfer between the two versions via representation matching. The propose"
D18-1517,P17-1038,0,0.0599056,"67.6 ALT 65.1 66.4 MATCHING 71.2 69.0 (Nguyen and Grishman, 2016d) (Liu et al., 2017) (Liu et al., 2018) (Nguyen and Grishman, 2018a) NCNN 69.3 65.0 69.6 CNN+BiRNN 68.1 65.2 68.3 71.3* 71.9* 72.4* 73.1* Table 1: Performance on the ACE 2005 dataset. * indicates the use of entity mention annotation. Method CNN BiRNN SEPARATE 57.6 59.4 ALT 57.6 54.9 MATCHING 60.0 60.4 TAC TOP (Mitamura et al., 2015) (Nguyen and Grishman, 2018a) NCNN 58.3 48.5 60.0 CNN+BiRNN 58.0 57.5 60.7 58.4* 58.8* Table 2: Performance on the TAC 2015 dataset. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015),"
D18-1517,P15-1017,0,0.264598,"ntroduction An important aspect of natural language processing involves understanding events mentioned in text. Towards this end, event detection (ED) is the task of locating event triggers (usually verbs or nouns) within a given text, and classifying them among a given set of event types. This task remains challenging due to the inherent ambiguity and flexibility of natural languages. The current state-of-the-art methods for ED have involved applying deep learning (DL) models to automatically extract feature representations of the text, and then treating the task as a classification problem (Chen et al., 2015; Nguyen and Grishman, 2015b). The major intuition in this paper is that the task of ED is closely related to the task of word sense disambiguation (WSD) whose datasets can help to improve the performance of the DL models for ED. This is due to the goal of WSD to determine the sense of a word within a particular context, given a set of possible senses that the word can take on. Our intuition is based on the two following aspects: (i) Similar Context Modeling: Given a word in a context/sentence, both ED and WSD models need to select/predict a correct label in a list of candidate labels for the"
D18-1517,P15-1166,0,0.0491713,"Missing"
D18-1517,P15-2139,0,0.0283302,"e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5 Conclusion We present a method that improves the performance of deep learning models for ED by training two different versions of the same network architecture for ED and WSD, while encouraging the knowledge transfer between the two versions via representation matching. The proposed method produces better results across a variety of deep learning"
D18-1517,P16-2011,0,0.0659859,"Missing"
D18-1517,C16-1120,0,0.0605425,"is used to compute the representation vector R for the input sentence W with the token index p of interest as: R = M (W, p). 2.2 Multi-task Learning Models The previous section has described the deep learning methods that can be employed to train the models for ED and WSD separately. This section presents our proposed method to transfer the knowledge from the WSD dataset to improve the performance for ED. A typical method for transfer learning/multitask learning in NLP is to alternate the training process for the parameter-shared models of the related tasks (possibly with different datasets) (Guo et al., 2016; Li et al., 2015; Liu et al., 2016). For instance, in (Guo et al., 2016), the authors use the same deep learning model to learn the feature representations for the text inputs of two related tasks. This is then followed by task-specific output layers to perform the corresponding tasks. Note that the two tasks in (Guo et al., 2016) are provided with two different datasets of different text inputs, thereby being similar to the setting we consider in this work. In order to learn the parameters for this model, in each iteration, (Guo et al., 2016) select one of the tasks with some probabilities,"
D18-1517,P12-1110,0,0.029004,"le 2: Performance on the TAC 2015 dataset. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5 Conclusion We present a method that improves the performance of deep learning models for ED by training two different versions of the same network architecture for ED and WSD, while encouraging the knowledge transfer between the two versions"
D18-1517,J13-4006,0,0.0121428,"of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5 Conclusion We present a method that improves the performance of deep learning models for ED by training two different versions of the same network architecture for ED and WSD, while encouraging the knowledge transfer between the two versions via representation matching. The proposed method produces better"
D18-1517,P11-1113,0,0.224862,"Missing"
D18-1517,N16-1056,0,0.028035,"nd Grishman, 2016d) (Liu et al., 2017) (Liu et al., 2018) (Nguyen and Grishman, 2018a) NCNN 69.3 65.0 69.6 CNN+BiRNN 68.1 65.2 68.3 71.3* 71.9* 72.4* 73.1* Table 1: Performance on the ACE 2005 dataset. * indicates the use of entity mention annotation. Method CNN BiRNN SEPARATE 57.6 59.4 ALT 57.6 54.9 MATCHING 60.0 60.4 TAC TOP (Mitamura et al., 2015) (Nguyen and Grishman, 2018a) NCNN 58.3 48.5 60.0 CNN+BiRNN 58.0 57.5 60.7 58.4* 58.8* Table 2: Performance on the TAC 2015 dataset. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 20"
D18-1517,P08-1030,0,0.404864,"Missing"
D18-1517,N16-1179,0,0.0666944,"Missing"
D18-1517,P13-1008,0,0.361339,"Missing"
D18-1517,W15-4502,1,0.86371,"the representation vector R for the input sentence W with the token index p of interest as: R = M (W, p). 2.2 Multi-task Learning Models The previous section has described the deep learning methods that can be employed to train the models for ED and WSD separately. This section presents our proposed method to transfer the knowledge from the WSD dataset to improve the performance for ED. A typical method for transfer learning/multitask learning in NLP is to alternate the training process for the parameter-shared models of the related tasks (possibly with different datasets) (Guo et al., 2016; Li et al., 2015; Liu et al., 2016). For instance, in (Guo et al., 2016), the authors use the same deep learning model to learn the feature representations for the text inputs of two related tasks. This is then followed by task-specific output layers to perform the corresponding tasks. Note that the two tasks in (Guo et al., 2016) are provided with two different datasets of different text inputs, thereby being similar to the setting we consider in this work. In order to learn the parameters for this model, in each iteration, (Guo et al., 2016) select one of the tasks with some probabilities, sample a mini-bat"
D18-1517,D11-1109,0,0.0135743,"the TAC 2015 dataset. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5 Conclusion We present a method that improves the performance of deep learning models for ED by training two different versions of the same network architecture for ED and WSD, while encouraging the knowledge transfer between the two versions via representati"
D18-1517,P17-1164,0,0.0696089,"eal-valued vectors, which are then concatenated to form a vector representation xj for vj (Nguyen and Grishman, 2015b; Chen et al., 2015): 1. The word embedding of vj obtained by looking up the token vj in the pre-trained word embedding table (Mikolov et al., 2013a). 2. The position embedding vector for vj : obtained by looking up the relative distance j − n of vj with respect to the token of interest vn in a position embedding table (randomly initialized) (Chen et al., 2015; Nguyen and Grishman, 2015a). It is important to note that, different from the prior works (Nguyen and Grishman, 2015b; Liu et al., 2017), we do not include the entity type label of each token into its representation. This is a more realistic setting for our work as the golden entity mentions do not always exist in practice, especially for the datasets in WSD. Once each token vj is converted into the representation vector xj , the instance V becomes a sequence of vectors X = [x0 , x1 , . . . , xn , . . . , x2n−1 , x2n ] that would be fed into the one of the following deep learning models to learn a feature representation R for V . Typical Deep Learning Models for ED Computing the Feature Representations Consider a sentence W in"
D18-1517,Q13-1018,0,0.0405135,"Missing"
D18-1517,H94-1046,0,0.345127,"tures. Presumably, the objective function (2.2) can simultaneously improve the performance for both tasks of consideration. However, in our case of ED and WSD, it turns out this mechanism actually worsen the performance of the WSD models that were trained separately. We attribute this to the fact that the semantic differentiation in ED is more coarse-grained that that of WSD, causing the ineffectiveness of the datasets for ED to improve WSD performance. Eventually, we will just focus on the ED performance in the experiments. 3 Experiments 3.1 Parameters and Datasets We use the Semcor dataset (Miller et al., 1994) as the dataset for WSD in this work. This dataset was extracted from the Brown Corpus, and manually annotated with WordNet senses. We evaluate the models on two different datasets for ED: 1. ACE 2005: This dataset has 33 event subtypes. We use the same data split with We use the pre-trained word embeddings provided by (Nguyen and Grishman, 2016d). For CNN, NCNN and CNN+BiRNN, we employ filter sizes of {2, 3, 4, 5} with 300 filters for each size as in (Nguyen and Grishman, 2015b), while Gated Recurrent Units (Cho et al., 2014) with 300 hidden units are applied in BiRNN and CNN+BiRNN (as do (Ng"
D18-1517,W16-1618,1,0.917561,"wed by a max-pooling layer to generate the representation vector R for V . Multiple window values k are used to enhance the coverage of the model over the hidden k-grams in the context. 2. NCNN (Nguyen and Grishman, 2016d): This model is similar to CNN. The only difference is instead of running the convolution over the k consecutive vectors, NCNN convolutes over the k arbitrarily non-consecutive k vectors in V . This helps NCNN to explicitly model the non-consecutive words in the context to improve ED. 3. BiRNN: This is the bidirectional recurrent neural network (RNN) for event extraction in (Nguyen et al., 2016a). The model is composed of two recurrent neural networks (RNN), where one runs forward and the other runs backward through the input sequence V . The hidden vectors produced by the two networks are then concatenated at each position in the context. The vector at the position of n for the word of interest is used as the representation vector R for V . Due to the property of RNN, R encodes the information over the whole input V with a greater focus on vn . 4. CNN+BiRNN: In this model (Feng et al., 2016), X is passed through both a CNN and a BiRNN whose results are concatenated to produce the h"
D18-1517,W15-1506,1,0.553011,"rtant aspect of natural language processing involves understanding events mentioned in text. Towards this end, event detection (ED) is the task of locating event triggers (usually verbs or nouns) within a given text, and classifying them among a given set of event types. This task remains challenging due to the inherent ambiguity and flexibility of natural languages. The current state-of-the-art methods for ED have involved applying deep learning (DL) models to automatically extract feature representations of the text, and then treating the task as a classification problem (Chen et al., 2015; Nguyen and Grishman, 2015b). The major intuition in this paper is that the task of ED is closely related to the task of word sense disambiguation (WSD) whose datasets can help to improve the performance of the DL models for ED. This is due to the goal of WSD to determine the sense of a word within a particular context, given a set of possible senses that the word can take on. Our intuition is based on the two following aspects: (i) Similar Context Modeling: Given a word in a context/sentence, both ED and WSD models need to select/predict a correct label in a list of candidate labels for the word. For WSD, the candidat"
D18-1517,P15-2060,1,0.780634,"rtant aspect of natural language processing involves understanding events mentioned in text. Towards this end, event detection (ED) is the task of locating event triggers (usually verbs or nouns) within a given text, and classifying them among a given set of event types. This task remains challenging due to the inherent ambiguity and flexibility of natural languages. The current state-of-the-art methods for ED have involved applying deep learning (DL) models to automatically extract feature representations of the text, and then treating the task as a classification problem (Chen et al., 2015; Nguyen and Grishman, 2015b). The major intuition in this paper is that the task of ED is closely related to the task of word sense disambiguation (WSD) whose datasets can help to improve the performance of the DL models for ED. This is due to the goal of WSD to determine the sense of a word within a particular context, given a set of possible senses that the word can take on. Our intuition is based on the two following aspects: (i) Similar Context Modeling: Given a word in a context/sentence, both ED and WSD models need to select/predict a correct label in a list of candidate labels for the word. For WSD, the candidat"
D18-1517,D16-1085,1,0.955294,"ding words, and the n following words (padding or truncating when necessary). The tokens in the context are re-indexed to form an instance V = [v0 , v1 , . . . , vn , . . . , v2n−1 , v2n ], 4823 1. CNN: This is the convolutional neural networks in(Nguyen and Grishman, 2015b; Chen et al., 2015). It features convolution operations that are performed over the k consecutive vectors (k-grams) in X and followed by a max-pooling layer to generate the representation vector R for V . Multiple window values k are used to enhance the coverage of the model over the hidden k-grams in the context. 2. NCNN (Nguyen and Grishman, 2016d): This model is similar to CNN. The only difference is instead of running the convolution over the k consecutive vectors, NCNN convolutes over the k arbitrarily non-consecutive k vectors in V . This helps NCNN to explicitly model the non-consecutive words in the context to improve ED. 3. BiRNN: This is the bidirectional recurrent neural network (RNN) for event extraction in (Nguyen et al., 2016a). The model is composed of two recurrent neural networks (RNN), where one runs forward and the other runs backward through the input sequence V . The hidden vectors produced by the two networks are t"
D18-1517,D17-1120,0,0.0269285,"G 60.0 60.4 TAC TOP (Mitamura et al., 2015) (Nguyen and Grishman, 2018a) NCNN 58.3 48.5 60.0 CNN+BiRNN 58.0 57.5 60.7 58.4* 58.8* Table 2: Performance on the TAC 2015 dataset. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5 Conclusion We present a method that improves the performance of deep learning models for ED by training two dif"
D18-1517,K15-1037,0,0.0134441,"of entity mention annotation. Method CNN BiRNN SEPARATE 57.6 59.4 ALT 57.6 54.9 MATCHING 60.0 60.4 TAC TOP (Mitamura et al., 2015) (Nguyen and Grishman, 2018a) NCNN 58.3 48.5 60.0 CNN+BiRNN 58.0 57.5 60.7 58.4* 58.8* Table 2: Performance on the TAC 2015 dataset. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5 Conclusion We present a"
D18-1517,D14-1090,0,0.054002,"Missing"
D18-1517,P10-4014,0,0.0342052,"* indicates the use of entity mention annotation. Method CNN BiRNN SEPARATE 57.6 59.4 ALT 57.6 54.9 MATCHING 60.0 60.4 TAC TOP (Mitamura et al., 2015) (Nguyen and Grishman, 2018a) NCNN 58.3 48.5 60.0 CNN+BiRNN 58.0 57.5 60.7 58.4* 58.8* Table 2: Performance on the TAC 2015 dataset. * indicates the use of entity mention annotation. et al., 2016b,e; Chen et al., 2017), RNNs (Nguyen et al., 2016a; Jagannatha and Yu, 2016), and attention-based methods (Liu et al., 2017; Nguyen and Nguyen, 2018b). A similar trend exists in methods proposed for WSD, with feature based methods (Miller et al., 1994; Zhong and Ng, 2010; Taghipour and Ng, 2015) succeeded recently by deep learning methods (Yuan et al., 2016; Raganato et al., 2017). For multi-task learning in NLP, methods have been proposed for jointly modeling structured prediction tasks (Hatori et al., 2012; Li et al., 2011; Bohnet and Nivre, 2012; Henderson et al., 2013; Llu´ıs et al., 2013; Duong et al., 2015), and for sequence-to-sequence problems (Dong et al., 2015; Luong et al., 2015; Liu et al., 2016; Klerke et al., 2016). The prior work to solve multiple NLP tasks using an unified architecture includes (Collobert and Weston, 2008; Guo et al., 2016). 5"
D19-5532,W06-0901,0,0.849445,"ons) in text and classify them into specific types of interest. Event mentions are usually associated with an event trigger/anchor in the sentence of the event mentions, functioning as the main word to evoke the event. For instance, in the sentence ”She is going to leave to become chairman of Time Inc.”, an ED system should be able to recognize that the word “leave” is triggering an event of type “End-Position”. There have been two major approaches for ED in the literature. The first approach focuses on the development of linguistic features to feed into the statistical models (i.e., MaxEnt) (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction("
D19-5532,P15-2061,0,0.102425,"ntroduced to enhance event detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). However, the models proposed in these work cannot extend their operation to new event types. Regarding the new formulations for ED, previous studies(Bronstein et al., 2015; Peng et al., 2016) also examine keywords to specify event types. However, these studies do not investigate 3.2 Data Generation To facilitate the evaluation of the ED models in LFK for the new type extension setting, we need to obtain training and test/development datasets so the keyword sets of the examples in the test/development datasets define event types that are different from those specified by the keyword sets in the training datasets. To our best knowledge, there is no existing data following LFK setting, therefore, in this section, we present a process to automatically generate an E"
D19-5532,P17-1038,0,0.211925,"Missing"
D19-5532,P15-1017,0,0.76391,"the sentence ”She is going to leave to become chairman of Time Inc.”, an ED system should be able to recognize that the word “leave” is triggering an event of type “End-Position”. There have been two major approaches for ED in the literature. The first approach focuses on the development of linguistic features to feed into the statistical models (i.e., MaxEnt) (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction(Huang et al., 2018); however, the event types are specified via the possible roles of the arguments participating into the events in this work. It also uses complicated natural language processing toolkits, making it difficult to apply and rep"
D19-5532,P11-1113,0,0.186451,"predict whether the word xa in S expresses the event type specified by K or not (i.e., a binary classification problem to decide whether the context matches the event keywords or not). An example in LFK thus has the form (X, xa , K, Y ) where Y is either 1 or 0 to indicate the match of X and K. Related work In the last decade, many machine learning systems have been introduced to solve ED. Before the era of the deep neural networks, these systems are mainly based on supervised learning using extensive feature engineering with the machine learning frameworks (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Riedel et al., 2009; Riedel and McCallum, 2011a,b; Miwa et al., 2014; Li et al., 2014, 2015). Recently, many advanced deep learning methods were introduced to enhance event detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). H"
D19-5532,P18-1201,0,0.450693,"; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction(Huang et al., 2018); however, the event types are specified via the possible roles of the arguments participating into the events in this work. It also uses complicated natural language processing toolkits, making it difficult to apply and replicate the settings. Our work emphasizes the simplicity in the setting for new type extension to facilitate future research. Finally, extending ED to the new type is investigated using real examples as new event types (Nguyen et al., 2016c). However, it requires a large number of examples to perform well. Our work instead requires only a few keywords to help the models achi"
D19-5532,W16-1618,1,0.929053,"is going to leave to become chairman of Time Inc.”, an ED system should be able to recognize that the word “leave” is triggering an event of type “End-Position”. There have been two major approaches for ED in the literature. The first approach focuses on the development of linguistic features to feed into the statistical models (i.e., MaxEnt) (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction(Huang et al., 2018); however, the event types are specified via the possible roles of the arguments participating into the events in this work. It also uses complicated natural language processing toolkits, making it difficult to apply and replicate the settings."
D19-5532,P08-1030,0,0.891603,"t and classify them into specific types of interest. Event mentions are usually associated with an event trigger/anchor in the sentence of the event mentions, functioning as the main word to evoke the event. For instance, in the sentence ”She is going to leave to become chairman of Time Inc.”, an ED system should be able to recognize that the word “leave” is triggering an event of type “End-Position”. There have been two major approaches for ED in the literature. The first approach focuses on the development of linguistic features to feed into the statistical models (i.e., MaxEnt) (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction(Huang et al., 2018); ho"
D19-5532,D14-1198,0,0.201768,"binary classification problem to decide whether the context matches the event keywords or not). An example in LFK thus has the form (X, xa , K, Y ) where Y is either 1 or 0 to indicate the match of X and K. Related work In the last decade, many machine learning systems have been introduced to solve ED. Before the era of the deep neural networks, these systems are mainly based on supervised learning using extensive feature engineering with the machine learning frameworks (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Riedel et al., 2009; Riedel and McCallum, 2011a,b; Miwa et al., 2014; Li et al., 2014, 2015). Recently, many advanced deep learning methods were introduced to enhance event detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). However, the models proposed in these work cannot extend their operation to new event ty"
D19-5532,P15-2060,1,0.930579,"d to solve ED. Before the era of the deep neural networks, these systems are mainly based on supervised learning using extensive feature engineering with the machine learning frameworks (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Riedel et al., 2009; Riedel and McCallum, 2011a,b; Miwa et al., 2014; Li et al., 2014, 2015). Recently, many advanced deep learning methods were introduced to enhance event detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). However, the models proposed in these work cannot extend their operation to new event types. Regarding the new formulations for ED, previous studies(Bronstein et al., 2015; Peng et al., 2016) also examine keywords to specify event types. However, these studies do not investigate 3.2 Data Generation To facilitate the evaluation of the ED models in LFK for the new type extension setting,"
D19-5532,P13-1008,0,0.763946,"8 }, and 33 event subtypes S = {s1 , s2 , . . . , s33 }. There is also a special type/subtype of “Other” indicating the non-event 244 instances (Other ∈ / S) . As each event subtype in ACE 2005 is associated with one event type, let Ci be the set of subtypes corresponding to the type ti ∈ T . Also, let Kj be the set of trigger words for the event mentions of the subtype sj ∈ S. K is collected from training set of ACE 2005. To generate the training and test/development datasets, we first split the documents in ACE 2005 into three parts Dtrain , Dtest and Ddev following the previous work on ED (Li et al., 2013). They would contain event mentions for all the possible event types and subtypes in T and S. Assume that we want to extend the system to a new event type ttarget ∈ T , we need a train set without ttarget . So, we remove every event mention whose subtype belongs to Ctarget from Dtrain . Whereas, samples with subtypes in Ctarget ∪ {Other} are kept in Dtest and Ddev . The results of this re0 0 moval process are called as Dtrain , Dtest and 0 Ddev (from Dtrain , Dtest and Ddev , respectively). They will be used to generate the actual training/test/development datasets for LFK, respectively. Speci"
D19-5532,D16-1085,1,0.921619,"Missing"
D19-5532,W15-4502,1,0.936204,"Missing"
D19-5532,P10-1081,0,0.0363336,"o specific types of interest. Event mentions are usually associated with an event trigger/anchor in the sentence of the event mentions, functioning as the main word to evoke the event. For instance, in the sentence ”She is going to leave to become chairman of Time Inc.”, an ED system should be able to recognize that the word “leave” is triggering an event of type “End-Position”. There have been two major approaches for ED in the literature. The first approach focuses on the development of linguistic features to feed into the statistical models (i.e., MaxEnt) (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction(Huang et al., 2018); however, the event types ar"
D19-5532,D16-1038,0,0.0454374,"nt detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). However, the models proposed in these work cannot extend their operation to new event types. Regarding the new formulations for ED, previous studies(Bronstein et al., 2015; Peng et al., 2016) also examine keywords to specify event types. However, these studies do not investigate 3.2 Data Generation To facilitate the evaluation of the ED models in LFK for the new type extension setting, we need to obtain training and test/development datasets so the keyword sets of the examples in the test/development datasets define event types that are different from those specified by the keyword sets in the training datasets. To our best knowledge, there is no existing data following LFK setting, therefore, in this section, we present a process to automatically generate an ED dataset for LFK se"
D19-5532,P17-1164,0,0.536778,"ecome chairman of Time Inc.”, an ED system should be able to recognize that the word “leave” is triggering an event of type “End-Position”. There have been two major approaches for ED in the literature. The first approach focuses on the development of linguistic features to feed into the statistical models (i.e., MaxEnt) (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction(Huang et al., 2018); however, the event types are specified via the possible roles of the arguments participating into the events in this work. It also uses complicated natural language processing toolkits, making it difficult to apply and replicate the settings. Our work emphasizes"
D19-5532,W09-1406,0,0.0232416,"e word xa in S expresses the event type specified by K or not (i.e., a binary classification problem to decide whether the context matches the event keywords or not). An example in LFK thus has the form (X, xa , K, Y ) where Y is either 1 or 0 to indicate the match of X and K. Related work In the last decade, many machine learning systems have been introduced to solve ED. Before the era of the deep neural networks, these systems are mainly based on supervised learning using extensive feature engineering with the machine learning frameworks (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Riedel et al., 2009; Riedel and McCallum, 2011a,b; Miwa et al., 2014; Li et al., 2014, 2015). Recently, many advanced deep learning methods were introduced to enhance event detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). However, the models pr"
D19-5532,D18-1517,1,0.904354,"Missing"
D19-5532,D11-1001,0,0.0153973,"ses the event type specified by K or not (i.e., a binary classification problem to decide whether the context matches the event keywords or not). An example in LFK thus has the form (X, xa , K, Y ) where Y is either 1 or 0 to indicate the match of X and K. Related work In the last decade, many machine learning systems have been introduced to solve ED. Before the era of the deep neural networks, these systems are mainly based on supervised learning using extensive feature engineering with the machine learning frameworks (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Riedel et al., 2009; Riedel and McCallum, 2011a,b; Miwa et al., 2014; Li et al., 2014, 2015). Recently, many advanced deep learning methods were introduced to enhance event detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). However, the models proposed in these work cannot"
D19-5532,P11-1163,0,0.0587882,"est. Event mentions are usually associated with an event trigger/anchor in the sentence of the event mentions, functioning as the main word to evoke the event. For instance, in the sentence ”She is going to leave to become chairman of Time Inc.”, an ED system should be able to recognize that the word “leave” is triggering an event of type “End-Position”. There have been two major approaches for ED in the literature. The first approach focuses on the development of linguistic features to feed into the statistical models (i.e., MaxEnt) (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; McClosky et al., 2011). The second approach, on the other hand, relies on deep learning (i.e., convolutional neural networks (CNN)) to automatically induce features from data (Chen et al., 2015; Nguyen et al., 2016a; Liu et al., 2017; Lu and 243 Proceedings of the 2019 EMNLP Workshop W-NUT: The 5th Workshop on Noisy User-generated Text, pages 243–248 c Hong Kong, Nov 4, 2019. 2019 Association for Computational Linguistics the new type extension setting as we do in this. Recently, zero-shot learning is employed for new types in event extraction(Huang et al., 2018); however, the event types are specified via the poss"
D19-5532,W11-1807,0,0.0196043,"ses the event type specified by K or not (i.e., a binary classification problem to decide whether the context matches the event keywords or not). An example in LFK thus has the form (X, xa , K, Y ) where Y is either 1 or 0 to indicate the match of X and K. Related work In the last decade, many machine learning systems have been introduced to solve ED. Before the era of the deep neural networks, these systems are mainly based on supervised learning using extensive feature engineering with the machine learning frameworks (Ahn, 2006; Ji and Grishman, 2008; Hong et al., 2011; Riedel et al., 2009; Riedel and McCallum, 2011a,b; Miwa et al., 2014; Li et al., 2014, 2015). Recently, many advanced deep learning methods were introduced to enhance event detectors such as distributed word embedding (Chen et al., 2015; Nguyen et al., 2016b; Liu et al., 2017; Nguyen and Nguyen, 2019), convolutional neural networks (Chen et al., 2015, 2017; Nguyen and Grishman, 2015; Nguyen et al., 2016b; Nguyen and Grishman, 2018), recurrent neural networks (Nguyen et al., 2016b; Sha et al., 2018), and the attention mechanism (Liu et al., 2017; Nguyen and Nguyen, 2018b; Liu et al., 2018). However, the models proposed in these work cannot"
D19-6203,W16-3009,0,0.0451508,"Missing"
D19-6203,W18-2311,0,0.0355959,"Missing"
D19-6203,H05-1091,0,0.829015,"tand how the entities are related to each other in the documents. In the literature, this problem is formalized as relation extraction (RE), an important task in information extraction. RE aims to identify the semantic relationships between two entity mentions within the same sentences in text. Due to its important applications on many areas of natural language processing (e.g., question answering, knowledge base construction), RE has been actively studied in the last decade, featuring a variety of feature-based or kernel-based models for this problem (Zelenko et al., 2002; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen et al., 2009). Recently, the introduction of deep learning has produced a new generation of models for RE with 18 Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 18–27 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 the input. The goal is to predict the semantic relation between these two entity mentions according to some predefined set of relations. Formally, let W = [w1 , w2 , . . . , wn ] be the input sentence wher"
D19-6203,C10-1018,0,0.829447,"her in the documents. In the literature, this problem is formalized as relation extraction (RE), an important task in information extraction. RE aims to identify the semantic relationships between two entity mentions within the same sentences in text. Due to its important applications on many areas of natural language processing (e.g., question answering, knowledge base construction), RE has been actively studied in the last decade, featuring a variety of feature-based or kernel-based models for this problem (Zelenko et al., 2002; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen et al., 2009). Recently, the introduction of deep learning has produced a new generation of models for RE with 18 Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 18–27 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 the input. The goal is to predict the semantic relation between these two entity mentions according to some predefined set of relations. Formally, let W = [w1 , w2 , . . . , wn ] be the input sentence where n is the number of tokens and wi is t"
D19-6203,P16-1105,0,0.548297,"the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which each vector tends to capture the specific context information for a word in that sentence. Such word-specific representation sequence is then f"
D19-6203,S13-2057,0,0.0173866,"ed into two separate sets (i.e., the training set and the validation set). BB3 also include a test set; however, the relation types for the examples in this test set are not provided. In order to obtain the performance of the models on the test set, the performers need to submit their system outputs to an official API that would evaluate the output and return the model performance. We train the models in this work on the training data and employ the official API to obtain their test set performance to be reported in the experiments for this dataset. Following the prior work on these datasets (Chowdhury and Lavelli, 2013; Lever and Jones, 2016; Zhou et al., 2018; Le et al., 2018), we use the micro-averaged F1 scores as the performance measure in the experiments to ensure a compatible comparison. FDEP 1 = max-poolai ∈SDP 1(M1 ,M2 ) (ai ) FEN T −DEP 1 = [FDEP 1 , FEN T −ON LY ] Once the overall representation vector F for the input sentence W and the two entity mentions of interest has been produced, we feed it into a feed-forward neural network with a softmax layer in the end to obtain the probability distribution P (y|W, M1 , M2 ) = feed-forward(F ) over the possible relation types for our RE problem. This pr"
D19-6203,W18-2314,0,0.0622919,"-of-the-art performance on many different benchmark datasets (Zeng et al., 2014; dos Santos et al., 2015; Xu et al., 2015; Liu et al., 2015; Zhou et al., 2016; Wang et al., 2016; Zhang et al., 2017, 2018b). The advantage of deep learning over the previous approaches for RE is the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation componen"
D19-6203,W16-3002,0,0.063042,"Missing"
D19-6203,P15-1061,0,0.567064,"e options for such components in the following sections. 2.2 The Representation Component for RE Given the input sequence of vectors V = [v1 , v2 , . . . , vn ], the next step in the deep learning models for RE is to transform this vector sequence into a more abstract vector sequence A = [a1 , a2 , . . . , an ] so ai would capture the underlying representation for the context information specific to the i-th word in the sentence. In this work, we examine the following typical architectures to obtain such an abstract sequence A for V : 1. CNN (Zeng et al., 2014; Nguyen and Grishman, 2015b; dos Santos et al., 2015): CNN is one of the early deep learning models for RE. It involves an 1D convolution layer over the input vector sequence V with multiple window sizes for the filters. CNN produces a sequence of vectors in which each vector capture some n-grams specific to a word in the sentence. This sequence of vectors is used as A for our purpose. 2. BiLSTM (Nguyen and Grishman, 2015a): In BiLSTM, two Long-short Term Memory Networks (LSTM) are run over the input vector sequence V in the forward and backward direction. The hidden vectors generated at the position i by the two networks are then concatenated t"
D19-6203,W15-1506,1,0.935855,"; Wang et al., 2016; Zhang et al., 2017, 2018b). The advantage of deep learning over the previous approaches for RE is the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which each vector tends to capture"
D19-6203,D09-1143,0,0.0389433,"In the literature, this problem is formalized as relation extraction (RE), an important task in information extraction. RE aims to identify the semantic relationships between two entity mentions within the same sentences in text. Due to its important applications on many areas of natural language processing (e.g., question answering, knowledge base construction), RE has been actively studied in the last decade, featuring a variety of feature-based or kernel-based models for this problem (Zelenko et al., 2002; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen et al., 2009). Recently, the introduction of deep learning has produced a new generation of models for RE with 18 Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 18–27 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 the input. The goal is to predict the semantic relation between these two entity mentions according to some predefined set of relations. Formally, let W = [w1 , w2 , . . . , wn ] be the input sentence where n is the number of tokens and wi is the ith word/token in W"
D19-6203,D18-1250,0,0.229712,"sequence of vectors is used as A for our purpose. 2. BiLSTM (Nguyen and Grishman, 2015a): In BiLSTM, two Long-short Term Memory Networks (LSTM) are run over the input vector sequence V in the forward and backward direction. The hidden vectors generated at the position i by the two networks are then concatenated to constitute the abstract vector ai for this position. Due to the recurrent nature, ai involves the context information over the whole input sentence W although a greater focus is put on the context of the current word. 3. BiLSTM-CNN: This models resembles the MASS model presented in (Le et al., 2018). It first applies a bidirectional LSTM layer over the input sequence V whose results are further processed by a Convolutional Neural Network (CNN) layer as in CNN. We also use the output of the CNN layer as the abstract vector sequence A for this model. 4. BiLSTM-GCNN (Zhang et al., 2018b): Similar to BiLSTM-CNN, BiLSTM-GCNN also first employs a bidirectional LSTM network to abstract the input vector sequence V . However, in the second step, different from BiLSTM-CNN, BiLSTMGCNN introduces a Graph Convolutional Neural 2.3 The Pooling Component for RE The goal of the pooling component is to ag"
D19-6203,P11-1053,0,0.842044,"related to each other in the documents. In the literature, this problem is formalized as relation extraction (RE), an important task in information extraction. RE aims to identify the semantic relationships between two entity mentions within the same sentences in text. Due to its important applications on many areas of natural language processing (e.g., question answering, knowledge base construction), RE has been actively studied in the last decade, featuring a variety of feature-based or kernel-based models for this problem (Zelenko et al., 2002; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen et al., 2009). Recently, the introduction of deep learning has produced a new generation of models for RE with 18 Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 18–27 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 the input. The goal is to predict the semantic relation between these two entity mentions according to some predefined set of relations. Formally, let W = [w1 , w2 , . . . , wn ] be the input sentence where n is the number"
D19-6203,N18-1080,0,0.387214,"many different benchmark datasets (Zeng et al., 2014; dos Santos et al., 2015; Xu et al., 2015; Liu et al., 2015; Zhou et al., 2016; Wang et al., 2016; Zhang et al., 2017, 2018b). The advantage of deep learning over the previous approaches for RE is the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning"
D19-6203,P16-1200,0,0.0250144,". The advantage of deep learning over the previous approaches for RE is the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which each vector tends to capture the specific context information for"
D19-6203,P15-2047,0,0.326704,"Missing"
D19-6203,P16-1123,0,0.472654,"Missing"
D19-6203,C16-1138,0,0.229098,"for deep relation extraction on the same setting. In the experiments, we find that syntactic information (i.e., dependency parsing) can be exploited to provide the best pooling strategies for biomedical RE. In fact, our experiments also suggest that it is more beneficial to apply the syntactic information in the pooling component of the deep learning models for biomedical RE than that in the representation component. This is different from most of the prior work on relation extraction that has only employed the syntactic information in the representation component of the deep learning models (Xu et al., 2016; Miwa and Bansal, 2016). Based on the syntax-based pooling mechanism, we achieve the state-of-the-art performance on two benchmark datasets for biomedical RE. 2 2.1 Input Vector Representation In order to encode the positions and the entity types of the two entity mentions in the input sentence, following (Zhang et al., 2018b), we first replace the tokens in the entity mentions M1 and M2 with the special tokens of format M1 -Type1 and M2 -Type2 respectively (Type1 and Type2 represent the entity types of M1 and M2 respectively). The purpose of this replacement is to help the models to abstract"
D19-6203,D15-1206,0,0.272494,"Missing"
D19-6203,W02-1010,0,0.425759,"entities in text, it is crucial to understand how the entities are related to each other in the documents. In the literature, this problem is formalized as relation extraction (RE), an important task in information extraction. RE aims to identify the semantic relationships between two entity mentions within the same sentences in text. Due to its important applications on many areas of natural language processing (e.g., question answering, knowledge base construction), RE has been actively studied in the last decade, featuring a variety of feature-based or kernel-based models for this problem (Zelenko et al., 2002; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen et al., 2009). Recently, the introduction of deep learning has produced a new generation of models for RE with 18 Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 18–27 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 the input. The goal is to predict the semantic relation between these two entity mentions according to some predefined set of relations. Formally, let W = [w1 ,"
D19-6203,D15-1203,0,0.48593,"t al., 2017, 2018b). The advantage of deep learning over the previous approaches for RE is the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which each vector tends to capture the specific contex"
D19-6203,C14-1220,0,0.804017,"; Zhou et al., 2016; Wang et al., 2016; Zhang et al., 2017, 2018b). The advantage of deep learning over the previous approaches for RE is the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which e"
D19-6203,D17-1186,0,0.0136087,"deep learning over the previous approaches for RE is the ability to automatically learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which each vector tends to capture the specific context information for a word in that sente"
D19-6203,D18-1244,0,0.234362,"ed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which each vector tends to capture the specific context information for a word in that sentence. Such word-specific representation sequence is then fed into the second pooling component (e.g., max pooling) that aggregates the representation vectors to obtain an overall vector to represent the whol"
D19-6203,D17-1004,0,0.583532,"cally learn effective features for the sentences from data via various network architectures. The same trend has also been observed for RE in the biomedical domain where deep learning is gaining more and more attention from the research community (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). The typical deep learning models for RE have involved Convolutional Neural Networks (CNN) (Zeng et al., 2014; Nguyen and Grishman, 2015b; Zeng et al., 2015; Lin et al., 2016; Zeng et al., 2017), Recurrent Neural Networks (RNN), (Miwa and Bansal, 2016; Zhang et al., 2017), Transformer (self-attention) networks (Verga et al., 2018), and Graph Convolutional Neural Networks (GCNN) (Zhang et al., 2018b). There are two major common components in such deep learning models for RE, i.e., the representation component and the pooling component. First, in the representation component, some deep learning architectures are employed to compute a sequence of vectors to represent an input sentence for RE for which each vector tends to capture the specific context information for a word in that sentence. Such word-specific representation sequence is then fed into the second po"
D19-6203,P05-1053,0,0.935285,"s crucial to understand how the entities are related to each other in the documents. In the literature, this problem is formalized as relation extraction (RE), an important task in information extraction. RE aims to identify the semantic relationships between two entity mentions within the same sentences in text. Due to its important applications on many areas of natural language processing (e.g., question answering, knowledge base construction), RE has been actively studied in the last decade, featuring a variety of feature-based or kernel-based models for this problem (Zelenko et al., 2002; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010; Nguyen et al., 2009). Recently, the introduction of deep learning has produced a new generation of models for RE with 18 Proceedings of the 10th International Workshop on Health Text Mining and Information Analysis (LOUHI 2019), pages 18–27 c Hong Kong, November 3, 2019. 2019 Association for Computational Linguistics https://doi.org/10.18653/v1/D19-62 the input. The goal is to predict the semantic relation between these two entity mentions according to some predefined set of relations. Formally, let W = [w1 , w2 , . . . , wn ]"
D19-6203,P16-2034,0,0.0557972,"omponent of the deep learning models for biomedical RE. 4 Traditional work on RE has mostly used feature engineering with syntactical information for statistical or kernel based classifiers (Zelenko et al., 2002; Zhou et al., 2005; Bunescu and Mooney, 2005; Sun et al., 2011; Chan and Roth, 2010). Recently, deep learning has been shown to advance many benchmark datasets for this RE problem due to its representation learning capacity. The typical architectures for such deep learning models involve CNN, LSTM, the attention mechanism and their variants (Zeng et al., 2014; dos Santos et al., 2015; Zhou et al., 2016; Wang et al., 2016; Nguyen and Grishman, 2015a; Miwa and Bansal, 2016; Zhang et al., 2017, 2018b). Deep learning has also been applied to biomedical RE in the last couple of years and started to demonstrate much potentials for this area (Mehryary et al., 2016; Bj¨orne and Salakoski, 2018; Nguyen and Verspoor, 2018; Verga et al., 2018). Pooling is a common and crucial component in most of the deep learning models for RE. (Nguyen and Grishman, 2015b; dos Santos et al., 2015) apply the pooling operation over the whole sentence for RE while Zeng et al. (2015) proposes the dynamic pooling mechanis"
I17-2072,C14-1220,0,0.0140055,"oken’s chunk type. The size of embedding table is (|C |+ 1) ∗ dc , where |C |is the number of chunk types, 3 Model We formulate the relation extraction task as a classification problem over all entity pairs (relation candidates) in a sentence. The overall structure of the model is shown in Figure 1. The model will first convert a relation candidate into a fixed-length matrix, then uses a singlelayer Convolutional Neural Network (CNN) with dropout to learn its hidden representation repr. On top of repr, it uses two decoders: a fullyconnected layer with dropout for predicting the relation type (Zeng et al., 2014) (Section 3.1), and another decoder with domain adversarial neural network(Ganin and Lempitsky, 2015) to predict its domain. The additional domain-adversarial decoder is used to enforce the feature layer to be domain-invariant (Section 3.2). 3.1 CNN-based Encoder-Decoder Model for Relations Each sentence is truncated or padded to a fixed length (ls ) of tokens. Each token of the text is then 426 and dc is the embedding dimension. On dep path embedding: For each token, we have a vector to indicate whether the token is on the dependency path between the two entities. The vector size is dd . The"
I17-2072,P05-1053,0,0.0354718,"or Relation Extraction with Domain Adversarial Neural Network Lisheng Fu Thien Huu Nguyen∗ Bonan Min† Ralph Grishman New York University, New York, NY, USA {lisheng, grishman}@cs.nyu.edu ∗ University of Oregon, Eugene, OR, USA thien@cs.uoregon.edu † Raytheon BBN Technologies, Cambridge, MA, USA bonan.min@raytheon.com Abstract laborious to obtain, not to mention that relation mentions are sparse in the text. Take ACE 2004 as an example, Personal/Social relations appear only once on average per document. Such a method will not scale to the open-ended set of possible domains. Among the features (Zhou et al., 2005) used for relation extraction, shortest dependency path can be applied cross-domain while argument-specific features (e.g., entity types, lexical forms) are likely to be more domain-specific. We hypothesize that it is possible to learn both domain-invariant and domain-specific representations with neural networks, and use the domain-invariant representation for many new domains. In this paper, we propose to use a Domain Adversarial Neural Network (DANN) (Ganin and Lempitsky, 2015; Ajakan et al., 2014) to learn a domain-invariant representation for relations. Our contributions are twofold: Rela"
I17-2072,W06-1615,0,0.145208,"n features by itself and that requires no labels in targets. 1 Introduction Relation Extraction (RE) captures the semantic relation between two entities within a sentence, such as the Located relation between e1 and e2 in the sentence: “in the &lt;e2&gt;West Bank&lt;/e2&gt;, a &lt;e1&gt;passenger &lt;/e1&gt;was wounded when an Israeli bus came under fire.” The same relation might be expressed differently across diverse documents, topics and genres. We often observed that a relation extractor’s performance degrades when applied to a domain other than the domain it is trained on. A simple method for domain adaptation (Blitzer et al., 2006; Daume, 2007; Jing and Zhai, 2007) is to construct a labeled dataset for the target domain, and then adjust a trained model with it. This is inefficient for relations - annotation is • Experiments on the ACE domains show that our approach improves on the state-of-the-art across all domains. In the rest of the paper, we will first briefly summarize related work, then describe the model (Section 3). We will present experimental results and conclusion at the end. 2 Related Work There has been a lot of research on domain adaptation in natural language processing (Blitzer et al., 2006; Daume, 2007"
I17-2072,P07-1033,0,0.0462532,"nd that requires no labels in targets. 1 Introduction Relation Extraction (RE) captures the semantic relation between two entities within a sentence, such as the Located relation between e1 and e2 in the sentence: “in the &lt;e2&gt;West Bank&lt;/e2&gt;, a &lt;e1&gt;passenger &lt;/e1&gt;was wounded when an Israeli bus came under fire.” The same relation might be expressed differently across diverse documents, topics and genres. We often observed that a relation extractor’s performance degrades when applied to a domain other than the domain it is trained on. A simple method for domain adaptation (Blitzer et al., 2006; Daume, 2007; Jing and Zhai, 2007) is to construct a labeled dataset for the target domain, and then adjust a trained model with it. This is inefficient for relations - annotation is • Experiments on the ACE domains show that our approach improves on the state-of-the-art across all domains. In the rest of the paper, we will first briefly summarize related work, then describe the model (Section 3). We will present experimental results and conclusion at the end. 2 Related Work There has been a lot of research on domain adaptation in natural language processing (Blitzer et al., 2006; Daume, 2007; Jing and Zh"
I17-2072,D15-1205,0,0.0654979,"fully connected layers. The GRL is defined as an identity function with reversed gradient for backpropagation. For input layer x: d GRL(x) = x, dx GRL(x) = −I where I is the identity matrix. We use a binary cross-entropy loss for the domain classifier: NsP +Nt {di log(dˆi ) + (1 − di )log(1 − Ldomain = 4 Experiements 4.1 Dataset We use the ACE 2005 dataset to evaluate domain adaptation by dividing its articles from its six genres into respective domains: broadcast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and weblogs (wl). Previous work (Gormley et al., 2015; Nguyen and Grishman, 2016) uses newswire (bn & nw) as the training set, half of bc as the development set, the other half of bc, cts and wl as the test sets. We use the same data split. Our model requires unlabeled target domain instances. To meet this requirement and avoid train-on-test, we also split cts and wl when adapting to them. For all three test domains, we use half of the dataset as the development set, and the other half as the test set (Table 1). We use the same training set and the same preprocessing. This results in 43,497 entity pairs for training. We also use the same label s"
I17-2072,P07-1034,0,0.164687,"res no labels in targets. 1 Introduction Relation Extraction (RE) captures the semantic relation between two entities within a sentence, such as the Located relation between e1 and e2 in the sentence: “in the &lt;e2&gt;West Bank&lt;/e2&gt;, a &lt;e1&gt;passenger &lt;/e1&gt;was wounded when an Israeli bus came under fire.” The same relation might be expressed differently across diverse documents, topics and genres. We often observed that a relation extractor’s performance degrades when applied to a domain other than the domain it is trained on. A simple method for domain adaptation (Blitzer et al., 2006; Daume, 2007; Jing and Zhai, 2007) is to construct a labeled dataset for the target domain, and then adjust a trained model with it. This is inefficient for relations - annotation is • Experiments on the ACE domains show that our approach improves on the state-of-the-art across all domains. In the rest of the paper, we will first briefly summarize related work, then describe the model (Section 3). We will present experimental results and conclusion at the end. 2 Related Work There has been a lot of research on domain adaptation in natural language processing (Blitzer et al., 2006; Daume, 2007; Jing and Zhai, 2007; Glorot et al"
I17-2072,P14-2012,1,0.872462,"ere has been a lot of research on domain adaptation in natural language processing (Blitzer et al., 2006; Daume, 2007; Jing and Zhai, 2007; Glorot et al., 2011; Ajakan et al., 2014; 425 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 425–429, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP Ganin and Lempitsky, 2015). Most of the existing domain adaptation methods are based on discrete feature representations and linear classifiers. There is also recent work on domain adaptation for relation extraction including feature-based systems (Nguyen and Grishman, 2014; Nguyen et al., 2014) and kernelbased system (Plank and Moschitti, 2013). Nguyen and Grishman (2014) and Nguyen et al. (2014) both require a few labels in the target domain. Our proposed method can perform domain adaptation without target labels. Some other methods also do not have such requirement. Plank and Moschitti (2013) designed the semantic syntactic tree kernel (SSTK) to learn cross-domain patterns. Nguyen et al. (2015b) constructed a case study comparing feature-based methods and kernel-based models. They presented some effective features and kernels (e.g. word embedding).We share th"
N16-1034,W06-0901,0,0.0632536,"Missing"
N16-1034,P14-1023,0,0.0168519,"indow of 2 for the local features, and the feed-forward neural networks with one hidden layer for F trg , F arg and F binary (the size of the hidden layers are 600, 600 and 300 respectively). Finally, for training, we use the mini-batch size = 50 and the parameter for the Frobenius norms = 3. These parameter values are either inherited from the prior research (Nguyen and Grishman, 2015b; Chen et al., 2015) or selected according to the validation data. We pre-train the word embeddings from the English Gigaword corpus utilizing the word2vec toolkit4 (modified to add the C-CBOW model). Following Baroni et al. (2014), we employ the context window of 5, the subsampling of the frequent words set to 1e-05 and 10 negative samples. We evaluate the model with the ACE 2005 corpus. For the purpose of comparison, we use the same data split as the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Nguyen and Grishman, 2015b; Chen et al., 2015). This data split includes 40 newswire articles (672 sentences) for the test set, 30 other documents (836 sentences) for the development set and 529 remaining documents (14,849 sentences) for the training set. Also, 4 https://code.google.com/p/word"
N16-1034,P15-1017,0,0.470371,"cameraman as the Target argument for the event Attack with their local features. The joint approach can overcome this issue by relying on the global features to encode the fact that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. Despite the advantages presented above, the joint system by Li et al. (2013) suffers from the lack of generalization over the unseen words/features and the inability to extract the underlying structures for EE (due to its discrete representation from the handcrafted feature set) (Nguyen and Grishman, 2015b; Chen et al., 2015). The most successful pipelined system for EE to date (Chen et al., 2015) addresses these drawbacks of the joint system by Li et al. (2013) via dynamic multi-pooling convolutional neural networks (DMCNN). In this system, words are represented by the continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013a) and features are automatically learnt from data by the DMCNN, thereby alleviating the unseen word/feature problem and extracting more effective features for the given dataset. However, as the system by Chen et al. (2015) is pipelined, it still suffers from"
N16-1034,P09-2093,0,0.0233377,"Missing"
N16-1034,P11-1113,0,0.350837,"Missing"
N16-1034,P08-1030,1,0.809113,"ter for the Frobenius norms = 3. These parameter values are either inherited from the prior research (Nguyen and Grishman, 2015b; Chen et al., 2015) or selected according to the validation data. We pre-train the word embeddings from the English Gigaword corpus utilizing the word2vec toolkit4 (modified to add the C-CBOW model). Following Baroni et al. (2014), we employ the context window of 5, the subsampling of the frequent words set to 1e-05 and 10 negative samples. We evaluate the model with the ACE 2005 corpus. For the purpose of comparison, we use the same data split as the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Nguyen and Grishman, 2015b; Chen et al., 2015). This data split includes 40 newswire articles (672 sentences) for the test set, 30 other documents (836 sentences) for the development set and 529 remaining documents (14,849 sentences) for the training set. Also, 4 https://code.google.com/p/word2vec/ we follow the criteria of the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015) to judge the correctness of the predicted event mentions. 5.2 Memory Vector/Matrices This section evaluates the effectiveness o"
N16-1034,D14-1181,0,0.00360714,"triggers and argument roles: C(T, A, X, E) = − log P (T, A|X, E) = − log P (T |X, E) − log P (A|T, X, E) n X trg =− log Pi;t∗ − i=1 n X i I(ti 6= “Other”) i=1 k X j=1 arg log Pij;a∗ ij where I is the indicator function. We apply the stochastic gradient descent algorithm with mini-batches and the AdaDelta update rule (Zeiler, 2012). The gradients are computed using back-propagation. During training, besides the weight matrices, we also optimize the word and entity type embedding tables to achieve the optimal states. Finally, we rescale the weights whose Frobenius norms exceed a hyperparameter (Kim, 2014; Nguyen and Grishman, 2015a). 4 Word Representation Following the prior work (Nguyen and Grishman, 2015b; Chen et al., 2015), we pre-train word embeddings from a large corpus and employ them to initialize the word embedding table. One of the models to train word embeddings have been proposed in Mikolov et al. (2013a; 2013b) that introduce two log-linear models, i.e the continuous bag305 of-words model (CBOW) and the continuous skipgram model (SKIP-GRAM). The CBOW model attempts to predict the current word based on the average of the context word vectors while the SKIPGRAM model aims to predic"
N16-1034,P13-1008,0,0.157368,"articipating into such events. This is an important and challenging task of information extraction in natural language processing (NLP), as the same event might be present in various expressions, and an expression might expresses different events in different contexts. There are two main approaches to EE: (i) the joint approach that predicts event triggers and arguments for sentences simultaneously as a structured prediction problem, and (ii) the pipelined approach that first performs trigger prediction and then identifies arguments in separate stages. The most successful joint system for EE (Li et al., 2013) is based on the structured perceptron algorithm with a large set of local and global features1 . These features are designed to capture the discrete structures that are intuitively helpful for EE using the NLP toolkits (e.g., part of speech tags, dependency and constituent tags). The advantages of such a joint system are twofold: (i) mitigating the error propagation from the upstream component (trigger identification) to the downstream classifier (argument identification), and (ii) benefiting from the the inter-dependencies among event triggers and argument roles via global features. For exam"
N16-1034,D14-1198,0,0.0615326,"Missing"
N16-1034,P10-1081,1,0.602342,"orms = 3. These parameter values are either inherited from the prior research (Nguyen and Grishman, 2015b; Chen et al., 2015) or selected according to the validation data. We pre-train the word embeddings from the English Gigaword corpus utilizing the word2vec toolkit4 (modified to add the C-CBOW model). Following Baroni et al. (2014), we employ the context window of 5, the subsampling of the frequent words set to 1e-05 and 10 negative samples. We evaluate the model with the ACE 2005 corpus. For the purpose of comparison, we use the same data split as the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Nguyen and Grishman, 2015b; Chen et al., 2015). This data split includes 40 newswire articles (672 sentences) for the test set, 30 other documents (836 sentences) for the development set and 529 remaining documents (14,849 sentences) for the training set. Also, 4 https://code.google.com/p/word2vec/ we follow the criteria of the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015) to judge the correctness of the predicted event mentions. 5.2 Memory Vector/Matrices This section evaluates the effectiveness of the memory vector and m"
N16-1034,R11-1002,1,0.897403,"mention. ACE annotates 8 types and 33 subtypes (e.g., Attack, Die, Start-Position) for event mentions that also correspond to the types and subtypes of the event triggers. Each event subtype has its own set of roles to be filled by the event arguments. For instance, the roles for the Die event include Place, Victim and Time. The total number of roles for all the event subtypes is 36. Given an English text document, an event extraction system needs to recognize event triggers with specific subtypes and their corresponding arguments with the roles for each sentence. Following the previous work (Liao and Grishman, 2011; Li et al., 2013; Chen et al., 2015), we assume that the argument candidates (i.e, the entity mentions, temporal expressions and values) are provided (by the ACE annotation) to the event extraction systems. 2 http://projects.ldc.upenn.edu/ace 3 Model We formalize the EE task as follow. Let W = w1 w2 . . . wn be a sentence where n is the sentence length and wi is the i-th token. Also, let E = e1 , e2 , . . . , ek be the entity mentions3 in this sentence (k is the number of the entity mentions and can be zero). Each entity mention comes with the offsets of the head and the entity type. We furth"
N16-1034,P11-1163,0,0.265714,"Missing"
N16-1034,W15-1506,1,0.433652,"oach might fail to recognize cameraman as the Target argument for the event Attack with their local features. The joint approach can overcome this issue by relying on the global features to encode the fact that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. Despite the advantages presented above, the joint system by Li et al. (2013) suffers from the lack of generalization over the unseen words/features and the inability to extract the underlying structures for EE (due to its discrete representation from the handcrafted feature set) (Nguyen and Grishman, 2015b; Chen et al., 2015). The most successful pipelined system for EE to date (Chen et al., 2015) addresses these drawbacks of the joint system by Li et al. (2013) via dynamic multi-pooling convolutional neural networks (DMCNN). In this system, words are represented by the continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013a) and features are automatically learnt from data by the DMCNN, thereby alleviating the unseen word/feature problem and extracting more effective features for the given dataset. However, as the system by Chen et al. (2015) is pipelined, i"
N16-1034,P15-2060,1,0.885827,"oach might fail to recognize cameraman as the Target argument for the event Attack with their local features. The joint approach can overcome this issue by relying on the global features to encode the fact that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence. Despite the advantages presented above, the joint system by Li et al. (2013) suffers from the lack of generalization over the unseen words/features and the inability to extract the underlying structures for EE (due to its discrete representation from the handcrafted feature set) (Nguyen and Grishman, 2015b; Chen et al., 2015). The most successful pipelined system for EE to date (Chen et al., 2015) addresses these drawbacks of the joint system by Li et al. (2013) via dynamic multi-pooling convolutional neural networks (DMCNN). In this system, words are represented by the continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013a) and features are automatically learnt from data by the DMCNN, thereby alleviating the unseen word/feature problem and extracting more effective features for the given dataset. However, as the system by Chen et al. (2015) is pipelined, i"
N16-1034,D09-1016,0,0.0598437,"Missing"
N16-1034,N10-1123,0,0.0610405,"Missing"
N16-1034,D11-1001,0,0.0188606,"Missing"
N16-1034,W11-1807,0,0.0351499,"Missing"
N16-1034,W09-1406,0,0.0324773,"Missing"
N16-1034,P10-1040,0,0.0736485,"sented above, the joint system by Li et al. (2013) suffers from the lack of generalization over the unseen words/features and the inability to extract the underlying structures for EE (due to its discrete representation from the handcrafted feature set) (Nguyen and Grishman, 2015b; Chen et al., 2015). The most successful pipelined system for EE to date (Chen et al., 2015) addresses these drawbacks of the joint system by Li et al. (2013) via dynamic multi-pooling convolutional neural networks (DMCNN). In this system, words are represented by the continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013a) and features are automatically learnt from data by the DMCNN, thereby alleviating the unseen word/feature problem and extracting more effective features for the given dataset. However, as the system by Chen et al. (2015) is pipelined, it still suffers from the inherent limitations of error propagation and failure to exploit the inter-dependencies between event triggers and argument roles (Li et al., 2013). Finally, we notice that the discrete features, shown to be helpful in the previous studies for EE (Li et al., 2013), are not considered in Chen et al. (2015). Guided"
N16-1034,D14-1090,0,0.135969,"Missing"
P14-2012,W10-2604,0,0.0639616,"s and Regularization for Domain Adaptation of Relation Extraction Thien Huu Nguyen Computer Science Department New York University New York, NY 10003 USA thien@cs.nyu.edu Ralph Grishman Computer Science Department New York University New York, NY 10003 USA grishman@cs.nyu.edu Abstract source domain) into a new model which can perform well on new domains (the target domains). The consequences of linguistic variation between training and testing data on NLP tools have been studied extensively in the last couple of years for various NLP tasks such as Part-of-Speech tagging (Blitzer et al., 2006; Huang and Yates, 2010; Schnabel and Sch¨utze, 2014), named entity recognition (Daum´e III, 2007) and sentiment analysis (Blitzer et al., 2007; Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011), etc. Unfortunately, there is very little work on domain adaptation for RE. The only study explicitly targeting this problem so far is by Plank and Moschitti (2013) who find that the out-of-domain performance of kernel-based relation extractors can be improved by embedding semantic similarity information generated from word clustering and latent semantic analysis (LSA) into syntactic tree kernels. Although thi"
P14-2012,W06-1615,0,0.954812,"ng Word Representations and Regularization for Domain Adaptation of Relation Extraction Thien Huu Nguyen Computer Science Department New York University New York, NY 10003 USA thien@cs.nyu.edu Ralph Grishman Computer Science Department New York University New York, NY 10003 USA grishman@cs.nyu.edu Abstract source domain) into a new model which can perform well on new domains (the target domains). The consequences of linguistic variation between training and testing data on NLP tools have been studied extensively in the last couple of years for various NLP tasks such as Part-of-Speech tagging (Blitzer et al., 2006; Huang and Yates, 2010; Schnabel and Sch¨utze, 2014), named entity recognition (Daum´e III, 2007) and sentiment analysis (Blitzer et al., 2007; Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011), etc. Unfortunately, there is very little work on domain adaptation for RE. The only study explicitly targeting this problem so far is by Plank and Moschitti (2013) who find that the out-of-domain performance of kernel-based relation extractors can be improved by embedding semantic similarity information generated from word clustering and latent semantic analysis (LSA) into syntactic tre"
P14-2012,N07-1015,0,0.819416,"We systematically explore various ways to apply word embeddings and show the best adaptation improvement by combining word cluster and word embedding information. Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data distributions, the RE performance of these s"
P14-2012,P07-1056,0,0.0748457,"niversity New York, NY 10003 USA thien@cs.nyu.edu Ralph Grishman Computer Science Department New York University New York, NY 10003 USA grishman@cs.nyu.edu Abstract source domain) into a new model which can perform well on new domains (the target domains). The consequences of linguistic variation between training and testing data on NLP tools have been studied extensively in the last couple of years for various NLP tasks such as Part-of-Speech tagging (Blitzer et al., 2006; Huang and Yates, 2010; Schnabel and Sch¨utze, 2014), named entity recognition (Daum´e III, 2007) and sentiment analysis (Blitzer et al., 2007; Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011), etc. Unfortunately, there is very little work on domain adaptation for RE. The only study explicitly targeting this problem so far is by Plank and Moschitti (2013) who find that the out-of-domain performance of kernel-based relation extractors can be improved by embedding semantic similarity information generated from word clustering and latent semantic analysis (LSA) into syntactic tree kernels. Although this idea is interesting, it suffers from two major limitations: + It does not incorporate word cluster information at diff"
P14-2012,P04-3022,0,0.0125361,"embeddings and clustering on adapting feature-based relation extraction systems. We systematically explore various ways to apply word embeddings and show the best adaptation improvement by combining word cluster and word embedding information. Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distributi"
P14-2012,J92-4003,0,0.093496,"based RE systems. After that, we evaluate the effectiveness of these lexical feature groups for word embedding augmentation individually and incrementally according to the rank of importance. For each of these group combinations, we assess the system performance with different numbers of dimensions for both C&W and HLBL word embeddings. Let M1 and M2 be the first and second mentions in the relation. Table 1 describes the lexical feature groups. Word Representations We consider two types of word representations and use them as additional features in our DA system, namely Brown word clustering (Brown et al., 1992) and word embeddings (Bengio et al., 2001). While word clusters can be recognized as an one-hot vector representation over a small vocabulary, word embeddings are dense, lowdimensional, and real-valued vectors (distributed representations). Each dimension of the word embeddings expresses a latent feature of the words, hopefully reflecting useful semantic and syntactic regularities (Turian et al., 2010). We investigate word embeddings induced by two typical language models: Collobert and Weston (2008) embeddings (C&W) (Collobert and Weston, 2008; Turian et al., 2010) and Hierarchical log-biline"
P14-2012,H05-1091,0,0.568775,"ement by combining word cluster and word embedding information. Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data distributions, the RE performance of these systems tends to degrade dramatically (Plank and Moschitti, 2013). This is where we need to resort to dom"
P14-2012,C10-1018,0,0.68633,"ore various ways to apply word embeddings and show the best adaptation improvement by combining word cluster and word embedding information. Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data distributions, the RE performance of these systems tends to degrad"
P14-2012,D09-1143,0,0.0345313,"ffectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data distributions, the RE performance of these systems tends to degrade dramatically (Plank and Moschitti, 2013). This is where we need to resort to domain adaptation techniques (DA) to adapt a model trained on one domain (the 68 Proceedings"
P14-2012,P07-1033,0,0.242837,"Missing"
P14-2012,P13-1147,0,0.811978,"w domains (the target domains). The consequences of linguistic variation between training and testing data on NLP tools have been studied extensively in the last couple of years for various NLP tasks such as Part-of-Speech tagging (Blitzer et al., 2006; Huang and Yates, 2010; Schnabel and Sch¨utze, 2014), named entity recognition (Daum´e III, 2007) and sentiment analysis (Blitzer et al., 2007; Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011), etc. Unfortunately, there is very little work on domain adaptation for RE. The only study explicitly targeting this problem so far is by Plank and Moschitti (2013) who find that the out-of-domain performance of kernel-based relation extractors can be improved by embedding semantic similarity information generated from word clustering and latent semantic analysis (LSA) into syntactic tree kernels. Although this idea is interesting, it suffers from two major limitations: + It does not incorporate word cluster information at different levels of granularity. In fact, Plank and Moschitti (2013) only use the 10-bit cluster prefix in their study. We will demonstrate later that the adaptability of relation extractors can benefit significantly from the addition"
P14-2012,C08-1088,0,0.254676,"e demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data distributions, the RE performance of these systems tends to degrade dramatically (Plank and Moschitti, 2013). This is where we need to resort to domain adaptation techniques (DA) to adapt a model trained on one doma"
P14-2012,Q14-1002,0,0.0330316,"Missing"
P14-2012,D12-1110,0,0.0198885,"presentation for domain adaptation of RE. More importantly, we show empirically that word embeddings and word clusters capture different information and their combination would further improve the adaptability of relation extractors. 2 3 Related Work Although word embeddings have been successfully employed in many NLP tasks (Collobert and Weston, 2008; Turian et al., 2010; Maas and Ng, 2010), the application of word embeddings in RE is very recent. Kuksa et al. (2010) propose an abstraction-augmented string kernel for bio-relation extraction via word embeddings. In the surge of deep learning, Socher et al. (2012) and Khashabi (2013) use pre-trained word embeddings as input for Matrix-Vector Recursive Neural Networks (MV-RNN) to learn compositional structures for RE. However, none of these works evaluate word embeddings for domain adaptation of RE which is our main focus in this paper. Regarding domain adaptation, in representation learning, Blitzer et al. (2006) propose structural correspondence learning (SCL) while Huang and Yates (2010) attempt to learn a multi-dimensional feature representation. Unfortunately, these methods require unlabeled target domain data which are unavailable in our single-sy"
P14-2012,P11-1053,1,0.854437,"pply word embeddings and show the best adaptation improvement by combining word cluster and word embedding information. Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data distributions, the RE performance of these systems tends to degrade dramatically (Pla"
P14-2012,P10-1040,0,0.412106,"Missing"
P14-2012,P06-1104,0,0.0226561,"ormation. Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data distributions, the RE performance of these systems tends to degrade dramatically (Plank and Moschitti, 2013). This is where we need to resort to domain adaptation techniques (DA) to adapt a model"
P14-2012,P05-1053,0,0.798826,"feature-based relation extraction systems. We systematically explore various ways to apply word embeddings and show the best adaptation improvement by combining word cluster and word embedding information. Finally, we demonstrate the effectiveness of regularization for the adaptability of relation extractors. 1 Introduction The goal of Relation Extraction (RE) is to detect and classify relation mentions between entity pairs into predefined relation types such as Employment or Citizenship relationships. Recent research in this area, whether feature-based (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011) or kernelbased (Zelenko et al., 2003; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Qian et al., 2008; Nguyen et al., 2009), attempts to improve the RE performance by enriching the feature sets from multiple sentence analyses and knowledge resources. The fundamental assumption of these supervised systems is that the training data and the data to which the systems are applied are sampled independently and identically from the same distribution. When there is a mismatch between data"
P15-1062,H05-1091,0,0.148681,"ompare the tree kernel-based and the feature-based method for RE in a compatible way, on the same resources and settings, to gain insights into which kind of system is more robust to domain changes. Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeti"
P15-1062,P07-1073,0,0.0249017,"ompatible way, on the same resources and settings, to gain insights into which kind of system is more robust to domain changes. Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the"
P15-1062,C10-1018,0,0.0199233,"t the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 635–644, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics chitti (2"
P15-1062,P07-1033,0,0.543746,"Missing"
P15-1062,W10-2604,0,0.0185843,"14), and Nguyen and Grishman (2015) employ word embeddings in the framework of convolutional neural networks for relation classification and extraction, respectively. Sterckx et al. (2014) utilize word embeddings to reduce noise of training data in distant supervision. Kuksa et al. (2010) present a string kernel for bio-relation extraction with word embeddings, and Yu et al. (2014; 2015) study the factor-based compositional embedding models. However, none of this work examines word embeddings for tree kernels as well as domain adaptation as we do. Regarding DA, in the unsupervised DA setting, Huang and Yates (2010) attempt to learn multidimensional feature representations while Blitzer et al. (2006) introduce structural correspondence learning. Daum´e (2007) proposes an easy adaptation framework (EA) while Xiao and Guo (2013) present a log-bilinear language adaptation technique in the supervised DA setting. Unfortunately, all of this work assumes some prior (in the form of either labeled or unlabeled data) on the target domains for the sequential labeling tasks, in contrast to our single-system unsupervised DA setting for relation extraction. An alternative method that is also popular to DA is instance"
P15-1062,N07-1015,0,0.246901,"rror analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 635–644, c Beijing, China, July 26-31, 2015. 2015 Association for Computational"
P15-1062,D10-1115,0,0.0295108,"der the following methods to obtain the semantic representation Vi from the word embeddings of the context words of Ri (assuming d is the dimensionality of the word embeddings): HEAD: Vi = the concatenation of the word embeddings of the two entity mention heads of Ri . This representation is inherited from Nguyen and Grishman (2014) that only examine embeddings at the word level separately for the feature-based method without considering the compositionality embeddings of relation mentions. The dimensionality of HEAD is 2d. According to the principle of compositionality (Werning et al., 2006; Baroni and Zamparelli, 2010; Paperno et al., 2014), the meaning of a complex expression is determined by the meanings of its components and the rules to combine them. We study the following two compositionality embeddings for relation mentions that can be generated from the embeddings of the context words: PHRASE: Vi = the mean of the embeddings of the words contained in the PET tree Ti of Ri . Although this composition is simple, it is in fact competitive to the more complicated methods based on recursive neural networks (Socher et al., 2012b; Blacoe and Lapata, 2012; Sterckx et al., 2014) on representing phrase semant"
P15-1062,P07-1034,0,0.625569,"rror analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 635–644, c Beijing, China, July 26-31, 2015. 2015 Association for Computational"
P15-1062,P04-3022,0,0.0514675,"system is more robust to domain changes. Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 635–644, c Beij"
P15-1062,D12-1050,0,0.0269934,"ciple of compositionality (Werning et al., 2006; Baroni and Zamparelli, 2010; Paperno et al., 2014), the meaning of a complex expression is determined by the meanings of its components and the rules to combine them. We study the following two compositionality embeddings for relation mentions that can be generated from the embeddings of the context words: PHRASE: Vi = the mean of the embeddings of the words contained in the PET tree Ti of Ri . Although this composition is simple, it is in fact competitive to the more complicated methods based on recursive neural networks (Socher et al., 2012b; Blacoe and Lapata, 2012; Sterckx et al., 2014) on representing phrase semantics. TREE: This is motivated by the training of recursive neural networks (Socher et al., 2012a) for semantic compositionality and attempts to aggregate the context words embeddings syntactically. In particular, we compute an embedding for every node in the PET tree in a bottom-up manner. The embeddings of the leaves are the embeddings of the words associated with them while the embeddings of the internal nodes are the means of the embeddings of their children nodes. We use the embeddings of the root of the PET tree to represent the relation"
P15-1062,W06-1615,0,0.38594,"ional neural networks for relation classification and extraction, respectively. Sterckx et al. (2014) utilize word embeddings to reduce noise of training data in distant supervision. Kuksa et al. (2010) present a string kernel for bio-relation extraction with word embeddings, and Yu et al. (2014; 2015) study the factor-based compositional embedding models. However, none of this work examines word embeddings for tree kernels as well as domain adaptation as we do. Regarding DA, in the unsupervised DA setting, Huang and Yates (2010) attempt to learn multidimensional feature representations while Blitzer et al. (2006) introduce structural correspondence learning. Daum´e (2007) proposes an easy adaptation framework (EA) while Xiao and Guo (2013) present a log-bilinear language adaptation technique in the supervised DA setting. Unfortunately, all of this work assumes some prior (in the form of either labeled or unlabeled data) on the target domains for the sequential labeling tasks, in contrast to our single-system unsupervised DA setting for relation extraction. An alternative method that is also popular to DA is instance weighting (Jiang and Zhai, 2007b). However, as shown by Plank and Moschitti (2013), in"
P15-1062,P07-1056,0,0.36694,"Missing"
P15-1062,P14-2012,1,0.114933,"stem trained on some source domain to perform well on new target domains. We here focus on the unsupervised domain adaptation (i.e., no labeled target data) and singlesystem DA (Petrov and McDonald, 2012; Plank and Moschitti, 2013), i.e., building a single system that is able to cope with different, yet related target domains. While DA has been investigated extensively in the last decade for various natural language processing (NLP) tasks, the examination of DA for RE is only very recent. To the best of our knowledge, there have been only three studies on DA for RE (Plank and Moschitti, 2013; Nguyen and Grishman, 2014; Nguyen et al., 2014). Of these, Nguyen et al. (2014) follow the supervised DA paradigm and assume some labeled data in the target domains. In contrast, Plank and Moschitti (2013) and Nguyen and Grishman (2014) work on the unsupervised DA. In our view, unsupervised DA is more challenging, but more realistic and practical for RE as we usually do not know which target domains we need to work on in advance, thus cannot expect to possess labeled data of the target domains. Our current work therefore focuses on the single-system unsupervised DA. Besides, note that this setting tries to construct a"
P15-1062,W15-1506,1,0.63793,"ngton Post is reporting she shot several Iraqi soldiers before she was captured and she was shot herself , too.”. However, as the syntactical structure of X1 is more similar to X2’s, and is remarkably different from X3 as well as the other closest phrases (ranked from 2nd to 8th), the new kernel function Knew would still prefer X2 due to its trade-off between syntax and semantics. 6 Related work Word embeddings are only applied to RE recently. Socher et al. (2012b) use word embeddings as input for matrix-vector recursive neural networks in relation classification while Zeng et al. (2014), and Nguyen and Grishman (2015) employ word embeddings in the framework of convolutional neural networks for relation classification and extraction, respectively. Sterckx et al. (2014) utilize word embeddings to reduce noise of training data in distant supervision. Kuksa et al. (2010) present a string kernel for bio-relation extraction with word embeddings, and Yu et al. (2014; 2015) study the factor-based compositional embedding models. However, none of this work examines word embeddings for tree kernels as well as domain adaptation as we do. Regarding DA, in the unsupervised DA setting, Huang and Yates (2010) attempt to l"
P15-1062,D09-1143,0,0.0167878,"es and settings, to gain insights into which kind of system is more robust to domain changes. Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Nat"
P15-1062,P14-1076,0,0.0259328,"Missing"
P15-1062,N15-1155,0,0.124471,"Missing"
P15-1062,C14-1220,0,0.048275,"the sentence “The Washington Post is reporting she shot several Iraqi soldiers before she was captured and she was shot herself , too.”. However, as the syntactical structure of X1 is more similar to X2’s, and is remarkably different from X3 as well as the other closest phrases (ranked from 2nd to 8th), the new kernel function Knew would still prefer X2 due to its trade-off between syntax and semantics. 6 Related work Word embeddings are only applied to RE recently. Socher et al. (2012b) use word embeddings as input for matrix-vector recursive neural networks in relation classification while Zeng et al. (2014), and Nguyen and Grishman (2015) employ word embeddings in the framework of convolutional neural networks for relation classification and extraction, respectively. Sterckx et al. (2014) utilize word embeddings to reduce noise of training data in distant supervision. Kuksa et al. (2010) present a string kernel for bio-relation extraction with word embeddings, and Yu et al. (2014; 2015) study the factor-based compositional embedding models. However, none of this work examines word embeddings for tree kernels as well as domain adaptation as we do. Regarding DA, in the unsupervised DA setting, Hua"
P15-1062,P06-1104,0,0.394474,"method for RE in a compatible way, on the same resources and settings, to gain insights into which kind of system is more robust to domain changes. Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Lingu"
P15-1062,P13-1147,1,0.0781232,", New York University, New York, NY 10003, USA § Center for Language Technology, University of Copenhagen, Denmark thien@cs.nyu.edu,bplank@cst.dk,grishman@cs.nyu.edu Abstract of the traditional RE techniques degrades significantly in such a domain mismatch case (Plank and Moschitti, 2013). To alleviate this performance loss, we need to resort to domain adaptation (DA) techniques to adapt a system trained on some source domain to perform well on new target domains. We here focus on the unsupervised domain adaptation (i.e., no labeled target data) and singlesystem DA (Petrov and McDonald, 2012; Plank and Moschitti, 2013), i.e., building a single system that is able to cope with different, yet related target domains. While DA has been investigated extensively in the last decade for various natural language processing (NLP) tasks, the examination of DA for RE is only very recent. To the best of our knowledge, there have been only three studies on DA for RE (Plank and Moschitti, 2013; Nguyen and Grishman, 2014; Nguyen et al., 2014). Of these, Nguyen et al. (2014) follow the supervised DA paradigm and assume some labeled data in the target domains. In contrast, Plank and Moschitti (2013) and Nguyen and Grishman ("
P15-1062,P05-1052,1,0.231135,"Missing"
P15-1062,C08-1088,0,0.0525648,"on the same resources and settings, to gain insights into which kind of system is more robust to domain changes. Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International J"
P15-1062,P05-1053,0,0.690766,". Our results and error analysis shows that the tree kernel-based method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 635–644, c Beijing, China, July 26-31, 2015. 2015 Associa"
P15-1062,D12-1110,0,0.0862588,"According to the principle of compositionality (Werning et al., 2006; Baroni and Zamparelli, 2010; Paperno et al., 2014), the meaning of a complex expression is determined by the meanings of its components and the rules to combine them. We study the following two compositionality embeddings for relation mentions that can be generated from the embeddings of the context words: PHRASE: Vi = the mean of the embeddings of the words contained in the PET tree Ti of Ri . Although this composition is simple, it is in fact competitive to the more complicated methods based on recursive neural networks (Socher et al., 2012b; Blacoe and Lapata, 2012; Sterckx et al., 2014) on representing phrase semantics. TREE: This is motivated by the training of recursive neural networks (Socher et al., 2012a) for semantic compositionality and attempts to aggregate the context words embeddings syntactically. In particular, we compute an embedding for every node in the PET tree in a bottom-up manner. The embeddings of the leaves are the embeddings of the words associated with them while the embeddings of the internal nodes are the means of the embeddings of their children nodes. We use the embeddings of the root of the PET tree"
P15-1062,P11-1053,1,0.953305,"ed method outperforms the feature-based approach. 1 Introduction Relation Extraction (RE) is an important aspect of information extraction that aims to discover the semantic relationships between two entity mentions appearing in the same sentence. Previous research on RE has followed either the kernelbased approach (Zelenko et al., 2003; Bunescu and Mooney, 2005; Zhao and Grishman, 2005; Zhang et al., 2006; Bunescu, 2007; Qian et al., 2008; Nguyen et al., 2009) or the feature-based approach (Kambhatla, 2004; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007a; Chan and Roth, 2010; Sun et al., 2011). Usually, in such supervised machine learning systems, it is assumed that the training data and the data to which the RE system is applied to are sampled independently and identically from the same distribution. This assumption is often violated in reality and exemplified in the fact that the performance 635 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 635–644, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics chitti (2013) consider the d"
P15-1062,P10-1040,0,0.610192,"e of research. Therefore, this is actually the first attempt to compare the two methods (tree kernel-based and feature-based) on the same settings. To ease the comparison for future work and circumvent the Zigglebottom pitfall (Pedersen, 2008), the entire setup and package is available.1 cation of word clusters and word embeddings for DA of RE on the feature-based method. Although word clusters (Brown et al., 1992) have been employed by both studies to improve the performance of relation extractors across domains, the application of word embeddings (Bengio et al., 2003; Mnih and Hinton, 2008; Turian et al., 2010) for DA of RE is only examined in the feature-based method and never explored in the tree kernelbased method so far, giving rise to the first question we want to address in this paper: (i) Can word embeddings help the tree kernelbased methods on DA for RE and more importantly, in which way can we do it effectively? This question is important as word embeddings are real valued vectors, while the tree kernel-based methods rely on the symbolic matches or mismatches of concrete labels in the parse trees to compute the kernels. It is unclear at the first glance how to encode word embeddings into th"
P15-1062,I08-2119,0,0.0156253,"ing between relation classes and their inverses) but Nguyen and Grishman (2014) disregard this relation direction. Finally, we note that although both studies evaluate their systems on the ACE 2005 dataset, they actually have different dataset partitions. In order to overcome this limitation, we conduct an evaluation in which the two methods are directed to use the same resources and settings, and are thus compared in a compatible manner to achieve an insight on their effectiveness for DA of RE. In fact, the problem of incompatible comparison is unfortunately very common in the RE literature (Wang, 2008; Plank and Moschitti, 2013) and we believe there is a need to tackle this increasing confusion in this line of research. Therefore, this is actually the first attempt to compare the two methods (tree kernel-based and feature-based) on the same settings. To ease the comparison for future work and circumvent the Zigglebottom pitfall (Pedersen, 2008), the entire setup and package is available.1 cation of word clusters and word embeddings for DA of RE on the feature-based method. Although word clusters (Brown et al., 1992) have been employed by both studies to improve the performance of relation"
P15-1062,J92-4003,0,\N,Missing
P15-1062,P14-1009,0,\N,Missing
P15-1062,D13-1170,0,\N,Missing
P15-1062,J08-3010,0,\N,Missing
P15-1131,baccianella-etal-2010-sentiwordnet,0,0.0400338,"4: Notations in JST Definition Dirichlet prior vectors distribution over words # of topics # of sentiments message and sentiment specific topic distribution topic word in the message d sentiment label message specific sentiment distribution # of words in the message d # of messages 5.4 TSLDA-based Method We use our TSLDA model to capture the topics and sentiments simultaneously. First, a rule-based algorithm is applied to identify the category of each word in the documents. Consecutive nouns are considered as topic words. If a word is not a noun and in a list of opinion words in SentiWordNet (Baccianella et al., 2010), it is considered as an opinion word. The rest of words are classified as background words. tion model. Two methods are used to extract the pairs of topic-sentiment from the message board. One is a latent topic based model called JST (Lin and He, 2009). The other is TSLDA discussed in Section 3. This subsection introduces the method using the former. We consider each message as a mixture of hidden topics and sentiments. JST model is used to extract topics and sentiments simultaneously. Figure 2 shows the graphical model representation of JST. Notations in Figure 2 are shown in Table 4. In LDA"
P15-1131,P13-2005,0,0.0443229,"orted either weak or strong predictive capabilities (Bollen et al., 2011). Therefore, how to use opinions in social media for stock price predictions is still an open problem. Our contributions are summarized as follows: 1354 1. We propose a new feature “topic-sentiment” for the stock market prediction model. 2. We propose a new topic model, Topic Sentiment Latent Dirichlet Allocation (TSLDA), which can capture the topic and sentiment simultaneously. 3. Large scale evaluation. Most of the previous researches are limited on predicting for one stock (Bollen et al., 2011; Qian and Rasheed, 2007; Si et al., 2013), and the number of instances (transaction dates) in a test set is rather low such as 14 or 15 instances (Bollen Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1354–1364, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics et al., 2011; Vu et al., 2012). With only a few instances in the test set, the conclusion might be insufficient. This is the first research that shows good prediction results on evaluation of many stocks using a test set con"
P15-1131,P14-5010,0,0.00140541,"are pricet−1 and pricet−2 which are the price movements (up, down) at the transaction dates t − 1, t − 2, respectively. 5.2 LDA-based Method In this model, we consider each message as a mixture of hidden topics. LDA is a generative probabilistic model of a corpus 1 . The basic idea is that documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over words. Hidden topics of LDA are incorporated into the prediction model as follows. First, stop words are removed from the messages, and all the words are lemmatized by Stanford CoreNLP (Manning et al., 2014). Topics are inferred by Gibbs Sampling with 1000 iterations. Next, the probability of each topic for each message is calculated. For each transaction date t, the probability of each topic is defined as the average of the probabilities of the topic in all messages posted on that transaction date. Features used for training SVM are pricet−1 , pricet−2 , ldai,t and ldai,t−1 . ldai,t and ldai,t−1 are the probabilities of the topic i (i ∈ {1, · · · , K}) for the transaction dates t and t − 1. The number of the topics K is empirically determined as explained in Subsection 6.1. 5.3 JST-based Method"
P15-1131,W12-5503,0,0.0347044,"capture the topic and sentiment simultaneously. 3. Large scale evaluation. Most of the previous researches are limited on predicting for one stock (Bollen et al., 2011; Qian and Rasheed, 2007; Si et al., 2013), and the number of instances (transaction dates) in a test set is rather low such as 14 or 15 instances (Bollen Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1354–1364, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics et al., 2011; Vu et al., 2012). With only a few instances in the test set, the conclusion might be insufficient. This is the first research that shows good prediction results on evaluation of many stocks using a test set consisting of many transaction dates. The rest of the paper is organized as follows. Section 2 introduces some previous approaches on sentiment analysis for stock prediction. Section 3 explains our model for sentiment analysis by simultaneously inferring the topic and sentiment in the text. Section 4 describes two kinds of datasets required for stock prediction. Section 5 describes our prediction models an"
P15-1131,P13-1086,0,0.0506955,"ing the sentiments in the textual content with the historical prices through the linear regression model. Most of the previous work primarily used the bag-of-words as text representation that are incorporated into the prediction model. Schumaker and Chen tried to use different textual representations such as bag-of-words, noun phrases and named entities for financial news (Schumaker and Chen, 2009b). However, the textual representations are just the words or named entity tags, not exploiting the mood information so much. A novel tree representation based on semantic frame parsers is proposed (Xie et al., 2013). By using stock prices from Yahoo Finance, they annotated all the news in a transaction date with going up or down categories. However, the weakness of this assumption is that all the news in one day will have the same category. In addition, this is a task of text classification, not stock prediction. Naive Bayes was used to classify messages from message boards into three classes: buy, hold and sell (Antweiler and Frank, 2004). They were integrated into the regression model. However, they concluded that their model does not successfully predict stock returns. A method to measure collective h"
P15-1131,D10-1006,0,0.0098357,"and Oh, 2011). Joint sentiment/topic model (JST) is another model to detect the sentiment and topic simultaneously, which was applied for movie review dataset (Lin and He, 2009). These models assume that each word is generated from a joint topic and sentiment distribution. It means that these models do not distinguish the topic word and opinion word distributions. Besides the general opinion words, topic models considering aspect-specific opinion words were also proposed. MaxEnt-LDA hybrid model can jointly discover both aspects and aspectspecific opinion words on a restaurant review dataset (Zhao et al., 2010), while FACTS, CFACTS, FACTS-R, and CFACTS-R model were proposed for sentiment analysis on a product review data (Lakkaraju et al., 2011). However, one of the weaknesses of these methods is that there is only one opinion word distribution corresponding to one topic (aspect). It makes difficult to know which sentiment (e.g. positive or negative) is expressed by the opinion words on that topic. To overcome this drawback, we propose a new topic model called Topic Sentiment Latent Dirichlet Allocation (TSLDA), which estimates different opinion word distributions for individual sentiment categories"
P15-2060,P10-1081,1,0.801338,"ng backpropagation; regularization is implemented by a dropout (Kim, 2014; Hinton et al., 2012), and training is done via stochastic gradient descent with shuffled mini-batches and the AdaDelta update rule (Zeiler, 2012; Kim, 2014). During the training, we also optimize the weights of the three embedding tables at the same time to reach an effective state (Kim, 2014). 3 3.1 (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaning 529 documents (14,849 sentences) as the previous studies on this dataset (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013b). The ACE 2005 corpus has 33 event subtypes that, along with one class “None” for the non-trigger tokens, constitutes a 34-class classification problem. In order to evaluate the effectiveness of the position embeddings and the entity type embeddings, Table 1 reports the performance of the proposed CNN on the development set when these embeddings are either included or excluded from the systems. With the large margins of performance, it is very clear from the table that the position embeddings are crucial while the entity embeddings are also very useful for CNNs on ED. System"
P15-2060,W06-1615,0,0.644493,"hese features to be fed into statistical classifiers. Although this approach has achieved the top performance (Hong et al., 2011; Li et al., 2013b), it suffers from at least two issues: (i) The choice of features is a manual process and requires linguistic intuition as well as domain expertise, implying additional studies for new application domains and limiting the capacity to quickly adapt to these new domains. (ii) The supervised NLP toolkits and resources for feature extraction might involve errors (either due to the imperfect nature or the performance loss of the toolkits on new domains (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010)), probably propagated to the final event detector. This paper presents a convolutional neural network (LeCun et al., 1988; Kalchbrenner et al., 2014) for the ED task that automatically learns features from sentences, and minimizes the dependence on supervised toolkits and resources for features, thus alleviating the error propagation and improving the performance for this task. Due to the emerging interest of the NLP community in deep learning recently, CNNs have been studied extensively and applied effectively in various tasks: semantic parsing (Yih"
P15-2060,R11-1002,1,0.907637,"Missing"
P15-2060,N10-1004,0,0.0248636,"classifiers. Although this approach has achieved the top performance (Hong et al., 2011; Li et al., 2013b), it suffers from at least two issues: (i) The choice of features is a manual process and requires linguistic intuition as well as domain expertise, implying additional studies for new application domains and limiting the capacity to quickly adapt to these new domains. (ii) The supervised NLP toolkits and resources for feature extraction might involve errors (either due to the imperfect nature or the performance loss of the toolkits on new domains (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010)), probably propagated to the final event detector. This paper presents a convolutional neural network (LeCun et al., 1988; Kalchbrenner et al., 2014) for the ED task that automatically learns features from sentences, and minimizes the dependence on supervised toolkits and resources for features, thus alleviating the error propagation and improving the performance for this task. Due to the emerging interest of the NLP community in deep learning recently, CNNs have been studied extensively and applied effectively in various tasks: semantic parsing (Yih et al., 2014), search query retrieval (She"
P15-2060,P11-1163,0,0.359711,"Missing"
P15-2060,P07-1033,0,0.238303,"Missing"
P15-2060,P09-2093,0,0.18052,"er was killed in New Jersey today”, an event detection system should be able to recognize the word “killed” as a trigger for the event “Die”. This task is quite challenging, as the same event might appear in the form of various trigger expressions and an expression might represent different events in different contexts. ED is a crucial component in the overall task of event extraction, which also involves event argument discovery. Recent systems for event extraction have employed either a pipeline architecture with separate classifiers for trigger and argument labeling (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan 1 https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/ english-events-guidelines-v5.4.3.pdf 365 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 365–371, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Figure 1: Convolutional Neural Network for Event Detection. along with its context in the sentence constitute an event trigger candidate or an example in multiclass classification terms. In order to prepare for"
P15-2060,P14-2012,1,0.889927,"Missing"
P15-2060,W15-1506,1,0.560299,"oken xi to the current token x0 . In practice, we initialize this table randomly. - Entity Type Embedding Table: If we further know the entity mentions and their entity types2 in the sentence, we can also capture this information for each token by looking up the entity type embedding table (initialized randomly) using the entity type associated with each token. We employ the BIO annotation scheme to assign entity type labels to each token in the trigger candidate 2014), name tagging and semantic role labeling (Collobert et al., 2011), relation classification and extraction (Zeng et al., 2014; Nguyen and Grishman, 2015). However, to the best of our knowledge, this is the first work on event detection via CNNs so far. First, we evaluate CNNs for ED in the general setting and show that CNNs, though not requiring complicated feature engineering, can still outperform the state-of-the-art feature-based methods extensively relying on the other supervised modules and manual resources for features. Second, we investigate CNNs in a domain adaptation (DA) setting for ED. We demonstrate that CNNs significantly outperform the traditional featurebased methods with respect to generalization performance across domains due"
P15-2060,P11-1113,0,0.753052,"joint inference architecture that performs the two subtasks at the same time to benefit from their inter-dependencies (Riedel and McCallum, 2011a; Riedel and McCallum, 2011b; Li et al., 2013b; Venugopal et al., 2014). Both approaches have coped with the ED task by elaborately hand-designing a large set of features (feature engineering) and utilizing the existing supervised natural language processing (NLP) toolkits and resources (i.e name tagger, parsers, gazetteers etc) to extract these features to be fed into statistical classifiers. Although this approach has achieved the top performance (Hong et al., 2011; Li et al., 2013b), it suffers from at least two issues: (i) The choice of features is a manual process and requires linguistic intuition as well as domain expertise, implying additional studies for new application domains and limiting the capacity to quickly adapt to these new domains. (ii) The supervised NLP toolkits and resources for feature extraction might involve errors (either due to the imperfect nature or the performance loss of the toolkits on new domains (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010)), probably propagated to the final event detector. This paper pre"
P15-2060,D09-1016,0,0.330518,"Missing"
P15-2060,P13-1147,0,0.0146567,"obal features in Li et al. (2013b) CNN1: CNN without any external features 63.7 65.6 67.6 Table 3: Performance with Predicted Entity Mentions and Types. data in some source domain and learning models that can work well on target domains. The target domains are supposed to be so dissimilar from the source domain that the learning techniques would suffer from a significant performance loss when trained on the source domain and applied to the target domains. To make it clear, we address the unsupervised DA problem in this section, i.e no training data in the target domains (Blitzer et al., 2006; Plank and Moschitti, 2013). The fundamental reason for the performance loss of the featurebased systems on the target domains is twofold: (i) The behavioral changes of features across domains: As domains differ, some features might be informative in the source domain but become less relevant in the target domains and vice versa. (ii) The propagated errors of the pre-processing toolkits for lower-level tasks (POS tagging, name tagging, parsing etc) to extract features: These pre-processing toolkits are also known to degrade when shifted to target domains (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010), i"
P15-2060,D11-1001,0,0.0186566,"Missing"
P15-2060,P08-1030,1,0.369163,"entence “A police officer was killed in New Jersey today”, an event detection system should be able to recognize the word “killed” as a trigger for the event “Die”. This task is quite challenging, as the same event might appear in the form of various trigger expressions and an expression might represent different events in different contexts. ED is a crucial component in the overall task of event extraction, which also involves event argument discovery. Recent systems for event extraction have employed either a pipeline architecture with separate classifiers for trigger and argument labeling (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan 1 https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/ english-events-guidelines-v5.4.3.pdf 365 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 365–371, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Figure 1: Convolutional Neural Network for Event Detection. along with its context in the sentence constitute an event trigger candidate or an example in multiclass classification terms. In o"
P15-2060,W11-1807,0,0.0147348,"Missing"
P15-2060,D14-1181,0,0.00826551,"in this paper, we always include ACE timex and values. 366 using the heads of the entity mentions. For each token xi , the vectors obtained from the three look-ups above are concatenated into a single vector xi to represent the token. As a result, the original event trigger x is transformed into a matrix x = [x−w , x−w+1 , . . . , x0 , . . . , xw−1 , xw ] of size mt × (2w + 1) (mt is the dimensionality of the concatenated vectors of the tokens). The matrix representation x is then passed through a convolution layer, a max pooling layer and a softmax at the end to perform classification (like (Kim, 2014; Kalchbrenner et al., 2014)). In the convolution layer, we have a set of feature maps (filters) {f1 , f2 , . . . , fn } for the convolution operation. Each feature map fi corresponds to some window size k and can be essentially seen as a weight matrix of size mt × k. Figure 1 illustrates the proposed CNN. The gradients are computed using backpropagation; regularization is implemented by a dropout (Kim, 2014; Hinton et al., 2012), and training is done via stochastic gradient descent with shuffled mini-batches and the AdaDelta update rule (Zeiler, 2012; Kim, 2014). During the training, we also"
P15-2060,P10-1040,0,0.0286579,"rter sentences with a special token when necessary. Let 2w + 1 be the fixed window size, and x = [x−w , x−w+1 , . . . , x0 , . . . , xw−1 , xw ] be some trigger candidate where the current token is positioned in the middle of the window (token x0 ). Before entering the CNNs, each token xi is transformed into a real-valued vector by looking up the following embedding tables to capture different characteristics of the token: - Word Embedding Table (initialized by some pre-trained word embeddings): to capture the hidden semantic and syntactic properties of the tokens (Collobert and Weston, 2008; Turian et al., 2010). - Position Embedding Table: to embed the relative distance i of the token xi to the current token x0 . In practice, we initialize this table randomly. - Entity Type Embedding Table: If we further know the entity mentions and their entity types2 in the sentence, we can also capture this information for each token by looking up the entity type embedding table (initialized randomly) using the entity type associated with each token. We employ the BIO annotation scheme to assign entity type labels to each token in the trigger candidate 2014), name tagging and semantic role labeling (Collobert et"
P15-2060,P13-1145,0,0.0880761,"chitecture that performs the two subtasks at the same time to benefit from their inter-dependencies (Riedel and McCallum, 2011a; Riedel and McCallum, 2011b; Li et al., 2013b; Venugopal et al., 2014). Both approaches have coped with the ED task by elaborately hand-designing a large set of features (feature engineering) and utilizing the existing supervised natural language processing (NLP) toolkits and resources (i.e name tagger, parsers, gazetteers etc) to extract these features to be fed into statistical classifiers. Although this approach has achieved the top performance (Hong et al., 2011; Li et al., 2013b), it suffers from at least two issues: (i) The choice of features is a manual process and requires linguistic intuition as well as domain expertise, implying additional studies for new application domains and limiting the capacity to quickly adapt to these new domains. (ii) The supervised NLP toolkits and resources for feature extraction might involve errors (either due to the imperfect nature or the performance loss of the toolkits on new domains (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010)), probably propagated to the final event detector. This paper presents a convoluti"
P15-2060,D14-1090,0,0.137255,"Missing"
P15-2060,P13-1008,0,0.572837,"chitecture that performs the two subtasks at the same time to benefit from their inter-dependencies (Riedel and McCallum, 2011a; Riedel and McCallum, 2011b; Li et al., 2013b; Venugopal et al., 2014). Both approaches have coped with the ED task by elaborately hand-designing a large set of features (feature engineering) and utilizing the existing supervised natural language processing (NLP) toolkits and resources (i.e name tagger, parsers, gazetteers etc) to extract these features to be fed into statistical classifiers. Although this approach has achieved the top performance (Hong et al., 2011; Li et al., 2013b), it suffers from at least two issues: (i) The choice of features is a manual process and requires linguistic intuition as well as domain expertise, implying additional studies for new application domains and limiting the capacity to quickly adapt to these new domains. (ii) The supervised NLP toolkits and resources for feature extraction might involve errors (either due to the imperfect nature or the performance loss of the toolkits on new domains (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010)), probably propagated to the final event detector. This paper presents a convoluti"
P15-2060,P14-2105,0,0.00673781,"2006; Daum´e III, 2007; McClosky et al., 2010)), probably propagated to the final event detector. This paper presents a convolutional neural network (LeCun et al., 1988; Kalchbrenner et al., 2014) for the ED task that automatically learns features from sentences, and minimizes the dependence on supervised toolkits and resources for features, thus alleviating the error propagation and improving the performance for this task. Due to the emerging interest of the NLP community in deep learning recently, CNNs have been studied extensively and applied effectively in various tasks: semantic parsing (Yih et al., 2014), search query retrieval (Shen et al., 2014), semantic matching (Hu et al., 2014), sentence modeling and classification (Kalchbrenner et al., 2014; Kim, We study the event detection problem using convolutional neural networks (CNNs) that overcome the two fundamental limitations of the traditional feature-based approaches to this task: complicated feature engineering for rich feature sets and error propagation from the preceding stages which generate these features. The experimental results show that the CNNs outperform the best reported feature-based systems in the general setting as well as t"
P15-2060,C14-1220,0,0.0678473,"distance i of the token xi to the current token x0 . In practice, we initialize this table randomly. - Entity Type Embedding Table: If we further know the entity mentions and their entity types2 in the sentence, we can also capture this information for each token by looking up the entity type embedding table (initialized randomly) using the entity type associated with each token. We employ the BIO annotation scheme to assign entity type labels to each token in the trigger candidate 2014), name tagging and semantic role labeling (Collobert et al., 2011), relation classification and extraction (Zeng et al., 2014; Nguyen and Grishman, 2015). However, to the best of our knowledge, this is the first work on event detection via CNNs so far. First, we evaluate CNNs for ED in the general setting and show that CNNs, though not requiring complicated feature engineering, can still outperform the state-of-the-art feature-based methods extensively relying on the other supervised modules and manual resources for features. Second, we investigate CNNs in a domain adaptation (DA) setting for ED. We demonstrate that CNNs significantly outperform the traditional featurebased methods with respect to generalization per"
P15-2060,P14-1062,0,\N,Missing
P19-1411,C18-1048,0,0.109479,"guments (Qin et al., 2017). This is demonstrated in the Penn Discourse Treebank dataset (PDTB) (Prasad et al., 2008), a major benchmark dataset for IDRR, where the annotators first inject the connectives between the arguments (called the “implicit connectives”) to aid the relation assignment of the arguments later (Qin et al., 2017). Motivated by the relevance of connectives for IDRR, some recent work on deep learning has explored methods to transfer the knowledge from the implicit connectives to support discourse relation prediction using the multi-task learning frameworks (Qin et al., 2017; Bai and Zhao, 2018). The typical approach is to simultaneously predict the discourse relations and the implicit connectives for the input arguments in which the model parameters for the two prediction tasks are shared/tied to allow the knowledge transfer (Liu et al., 2016; Wu et al., 2016; Lan et al., 2017; 4201 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4201–4207 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics Bai and Zhao, 2018). Unfortunately, such multitask learning models for IDRR share the limitation of failing"
P19-1411,D15-1262,0,0.0200047,"he connectives and relations for IDRR. In the experiments, we extensively demonstrate that the novel embeddings of connectives and relations along with the proposed mechanisms significantly improve the multi-task learning models for IDRR. We achieve the state-of-theart performance for IDRR over several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Zhou et al., 2010) employ a pipelined appro"
P19-1411,P16-1163,0,0.703411,"This work focuses on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument 1 (i.e., the Cause relation) in this case. This is a challenging problem as the models need to rely solely on the text of the arguments to predict accurate discourse relations. The problem would become more manageable if connective/marker cues (i"
P19-1411,N18-1013,0,0.702496,"IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument 1 (i.e., the Cause relation) in this case. This is a challenging problem as the models need to rely solely on the text of the arguments to predict accurate discourse relations. The problem would become more manageable if connective/marker cues (i.e., “but”, “so”) are provided to connect the two arguments according to their"
P19-1411,D14-1168,0,0.0254994,"ebank dataset). 1 Introduction Discourse parsing reveals the discourse units (i.e., text spans, sentences, clauses) of the documents and how such units are related to each others to improve the coherence. This work focuses on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument 1 (i.e., the Cause relation) in this case. T"
P19-1411,D13-1070,0,0.013307,"ral settings of the benchmark dataset (i.e., the Penn Discourse Treebank dataset). 1 Introduction Discourse parsing reveals the discourse units (i.e., text spans, sentences, clauses) of the documents and how such units are related to each others to improve the coherence. This work focuses on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is"
P19-1411,D09-1036,0,0.685071,"g and representation distinction for the embeddings of the connectives and relations for IDRR. In the experiments, we extensively demonstrate that the novel embeddings of connectives and relations along with the proposed mechanisms significantly improve the multi-task learning models for IDRR. We achieve the state-of-theart performance for IDRR over several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature"
P19-1411,D16-1130,0,0.630246,"Missing"
P19-1411,C18-1046,0,0.735928,"Missing"
P19-1411,P14-1092,0,0.0173163,"nchmark dataset (i.e., the Penn Discourse Treebank dataset). 1 Introduction Discourse parsing reveals the discourse units (i.e., text spans, sentences, clauses) of the documents and how such units are related to each others to improve the coherence. This work focuses on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument"
P19-1411,C18-1193,1,0.888122,"Missing"
P19-1411,Q15-1024,0,0.234579,"el 2 for 16 types of relations and level 3 for subtypes. We consider different settings for PDTB that have been studied in the previous research to achieve a comparable and comprehensive comparison, including the one-versus-others binary classifications for the first level (leading to four different datasets for the relations Comparison, Contingency, Expansion and Temporal), the muti-class classification setting for the first level (i.e., 4-way classification) and the multi-class classification for the second level (i.e., 11-way classification for the most popular types) (Pitler et al., 2009; Ji and Eisenstein, 2015b; Qin et al., 2017). Each setting has its own training, development and test datasets. For the 11-way classification setting, we further consider two popular ways to split the PDTB dataset, i.e., PDTB-Lin in (Lin et al., 2009) that use sections 2-21, 22 and 23 for the training, development and test datasets respectively, and PDTB-Ji (Ji and Eisenstein, 2015b; Bai and Zhao, 2018) where sections 2-20, 0-1, and 21-22 constitute the training, development and test datasets. In order to obtain the mapping between connectives and relations in the datasets, we rely on the association of the implicit"
P19-1411,N16-1034,1,0.905386,"Missing"
P19-1411,D15-1264,0,0.0170984,"d mechanisms significantly improve the multi-task learning models for IDRR. We achieve the state-of-theart performance for IDRR over several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Zhou et al., 2010) employ a pipelined approach to first predict the connectives and then assign discourse relations accordingly while (Lan et al., 2013) use the connective-relation mapping to automati"
P19-1411,C18-1049,0,0.0115821,"taset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Zhou et al., 2010) employ a pipelined approach to first predict the connectives and then assign discourse relations accordingly while (Lan et al., 2013) use the connective-relation mapping to automatically generate synthetic data. For the recent work on deep learning for IDRR, (Liu et al., 2016; Wu et al., 2016; Lan et al., 2017; Bai and Zhao, 2018) simultaneously predict co"
P19-1411,D17-1134,0,0.804506,"tion recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument 1 (i.e., the Cause relation) in this case. This is a challenging problem as the models need to rely solely on the text of the arguments to predict accurate discourse relations. The problem would become more manageable if connective/marker cues (i.e., “but”, “so”) are provided to connect the two argume"
P19-1411,P13-1047,0,0.0197248,"rove the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Zhou et al., 2010) employ a pipelined approach to first predict the connectives and then assign discourse relations accordingly while (Lan et al., 2013) use the connective-relation mapping to automatically generate synthetic data. For the recent work on deep learning for IDRR, (Liu et al., 2016; Wu et al., 2016; Lan et al., 2017; Bai and Zhao, 2018) simultaneously predict connectives and relations assuming the shared parameters of the deep learning models while (Qin et al., 2017) develop adversarial networks to encourage the relation models to mimic the features learned from the connective incorporation. However, none of these work employs embeddings of connectives and relations to transfer knowledge with the connective-relation mapping and d"
P19-1411,W16-1618,1,0.887973,"Missing"
P19-1411,W15-1506,1,0.879351,"Missing"
P19-1411,P15-2060,1,0.872653,"Missing"
P19-1411,C10-2172,0,0.0291923,"the embeddings of the connectives and relations for IDRR. In the experiments, we extensively demonstrate that the novel embeddings of connectives and relations along with the proposed mechanisms significantly improve the multi-task learning models for IDRR. We achieve the state-of-theart performance for IDRR over several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Zhou et al., 2010) e"
P19-1411,N18-1202,0,0.0608345,"agnostic to the encoder model M to generate the vector representation V for A1 and A2 . In order to ensure a fair comparison with the recent work on multi-task learning for IDRR, in this work, we employ the best encoder model M presented in (Bai and Zhao, 2018), a recent state-of-the-art multi-task learning model for this problem. We refer the reader to (Bai and Zhao, 2018) for the full description of the encoder. Essentially, this encoder first converts the words in the arguments A1 and A2 into vectors using the word embedding word2vec in (Mikolov et al., 2013b), the word embedding ELMo in (Peters et al., 2018) and the subword embeddings. This transforms the arguments into matrices that are sent to stacks of convolutional neural networks (Nguyen and Grishman, 2015a,b) augmented with gated linear units and residual connections. Each CNN layer produces two hidden matrices corresponding to the two input arguments over which the co-attention and max-pooling mechanisms are applied to obtain a part of the representation vector V with the current CNN layer. 3.2 Knowledge Transferring via Relation and Connective Embeddings As we have mentioned in the introduction, each implicit connective in C can be associ"
P19-1411,P09-1077,0,0.807503,"both knowledge sharing and representation distinction for the embeddings of the connectives and relations for IDRR. In the experiments, we extensively demonstrate that the novel embeddings of connectives and relations along with the proposed mechanisms significantly improve the multi-task learning models for IDRR. We achieve the state-of-theart performance for IDRR over several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relation"
P19-1411,prasad-etal-2008-penn,0,0.81526,"ld become more manageable if connective/marker cues (i.e., “but”, “so”) are provided to connect the two arguments according to their discourse relations (Qin et al., 2017). In the example above, it is beneficial for the models to know that “because” can be a connective of the two arguments that is consistent with their discourse relation (i.e., Cause). In fact, a human annotator can also benefit from the connectives between arguments when he or she needs to assign discourse relations for pairs of arguments (Qin et al., 2017). This is demonstrated in the Penn Discourse Treebank dataset (PDTB) (Prasad et al., 2008), a major benchmark dataset for IDRR, where the annotators first inject the connectives between the arguments (called the “implicit connectives”) to aid the relation assignment of the arguments later (Qin et al., 2017). Motivated by the relevance of connectives for IDRR, some recent work on deep learning has explored methods to transfer the knowledge from the implicit connectives to support discourse relation prediction using the multi-task learning frameworks (Qin et al., 2017; Bai and Zhao, 2018). The typical approach is to simultaneously predict the discourse relations and the implicit conn"
P19-1411,C16-1180,0,0.203384,"on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument 1 (i.e., the Cause relation) in this case. This is a challenging problem as the models need to rely solely on the text of the arguments to predict accurate discourse relations. The problem would become more manageable if connective/marker cues (i.e., “but”, “so”)"
P19-1411,D16-1246,0,0.849284,"on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument 1 (i.e., the Cause relation) in this case. This is a challenging problem as the models need to rely solely on the text of the arguments to predict accurate discourse relations. The problem would become more manageable if connective/marker cues (i.e., “but”, “so”)"
P19-1411,P10-1073,0,0.0226376,"on distinction for the embeddings of the connectives and relations for IDRR. In the experiments, we extensively demonstrate that the novel embeddings of connectives and relations along with the proposed mechanisms significantly improve the multi-task learning models for IDRR. We achieve the state-of-theart performance for IDRR over several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Z"
P19-1411,P99-1006,0,0.258514,"ge transfer that yield the state-of-the-art performance for IDRR on several settings of the benchmark dataset (i.e., the Penn Discourse Treebank dataset). 1 Introduction Discourse parsing reveals the discourse units (i.e., text spans, sentences, clauses) of the documents and how such units are related to each others to improve the coherence. This work focuses on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know t"
P19-1411,P17-2042,0,0.0126553,"r several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Zhou et al., 2010) employ a pipelined approach to first predict the connectives and then assign discourse relations accordingly while (Lan et al., 2013) use the connective-relation mapping to automatically generate synthetic data. For the recent work on deep learning for IDRR, (Liu et al., 2016; Wu et al., 2016; Lan et al., 2017;"
P19-1411,D14-1196,0,0.0178788,"roduction Discourse parsing reveals the discourse units (i.e., text spans, sentences, clauses) of the documents and how such units are related to each others to improve the coherence. This work focuses on the task of implicit discourse relation recognition (IDRR), aiming to identify the discourse relations (i.e., cause, contrast) between adjacent text spans in documents. IDRR is a fundamental problem in discourse analysis (Knott, 2014; Webber et al., 1999) with important applications on question answering (Liakata et al., 2013; Jansen et al., 2014) and text summarization (Gerani et al., 2014; Yoshida et al., 2014), to name a few. Due it its importance, IDRR is being studied actively in the literature, leading to the recent advances for this problem based on deep learning (Chen et al., 2016; Qin et al., 2016; Zhang et al., 2016; Lan et al., 2017; Dai and Huang, 2018). ∗ Corresponding author. Consider the two following text spans (called arguments) taken from (Qin et al., 2017) as an example: Argument 1: Never mind. Argument 2: You already know the answer. An IDRR model should be able to recognize that argument 2 is the cause of argument 1 (i.e., the Cause relation) in this case. This is a challenging pr"
P19-1411,D15-1266,0,0.634239,"ong with the proposed mechanisms significantly improve the multi-task learning models for IDRR. We achieve the state-of-theart performance for IDRR over several settings of the benchmark dataset PDTB. 2 Related Work There have been many research on IDRR since the creation of the PDTB dataset (Prasad et al., 2008). The early work has manually designed various features for IDRR (Pitler et al., 2009; Lin et al., 2009; Wang et al., 2010; Zhou et al., 2010; Braud and Denis, 2015; Lei et al., 2018) while the recent approach has applied deep learning to significantly improve the performance of IDRR (Zhang et al., 2015; Ji et al., 2015a; Chen et al., 2016; Liu et al., 2016; Qin et al., 2016; Zhang et al., 2016; Cai and Zhao, 2017; Lan et al., 2017; Wu et al., 2017; Dai and Huang, 2018; Kishimoto et al., 2018). The most related work to ours in this paper involves the multi-task learning models for IDRR that employ connectives as the auxiliary labels for the prediction of the discourse relations. For the feature-based approach, (Zhou et al., 2010) employ a pipelined approach to first predict the connectives and then assign discourse relations accordingly while (Lan et al., 2013) use the connective-relation ma"
P19-1432,E17-1003,0,0.146383,"Missing"
P19-1432,J12-2003,0,0.298383,"Missing"
P19-1432,W09-3012,0,0.238493,"affinity matrices of the sentences are induced from Long Short-Term Memory networks (LSTM) that are then linearly integrated with the syntactic affinity matrices of the dependency trees to produce the enriched affinity matrices for GCNs in EFP. The extensive experiments show that the proposed model is very effective for EFP. 2 Related Work EFP is one of the fundamental tasks in Information Extraction. The early work on this problem has employed the rule-based approaches (Nairn et al., 2006; Saur´ı, 2008; Lotan et al., 2013) or the machine learning approaches (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), or the hybrid approaches of both (Saur´ı and Pustejovsky, 2012; Qian et al., 2015). Recently, deep learning has been applied to solve EFP. (Qian et al., 2018) employ Generative Adversarial Networks (GANs) for EFP while (Rudinger et al., 2018) utilize LSTMs for both sequential and dependency representations of the input sentences. Finally, deep learning has also been considered for the related tasks of EFP, including event detection (Nguyen and Grishman, 2015b; Nguyen et al., 2016b; Lu and Nguyen, 2018; Nguyen and Nguyen,"
P19-1432,D15-1189,0,0.181804,"he writers. In order for the event mentions to be useful (i.e., for knowledge extraction tasks), it is important to determine their factual certainty so the actual event mentions can be retrieved (i.e., the event factuality prediction problem (EFP)). In this work, we focus on the recent regression formulation of EFP that aims to predict a real score in the range of [-3,+3] to quantify the occurrence possibility of a given event mention (Stanovsky et al., 2017; Rudinger et al., 2018). This provides more meaningful information for the downstream tasks than the classification formulation of EFP (Lee et al., 2015). For instance, the word “left” in the sentence “She left yesterday.” would express an event that certainly happened (i.e., corresponding to a score of +3 in the benchmark datasets) while the event mention associated with “leave” in the sentence “She forgot to leave yesterday.” would certainly not happen (i.e., a score of -3). EFP is a challenging problem as different context words might jointly participate to reveal the factuality of the event mentions (i.e., the cue words), possibly located at different parts of the sentences and scattered far away from the anchor words of the events. There"
P19-1432,N13-1091,0,0.204354,"Missing"
P19-1432,D18-1517,1,0.853579,"ly designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), or the hybrid approaches of both (Saur´ı and Pustejovsky, 2012; Qian et al., 2015). Recently, deep learning has been applied to solve EFP. (Qian et al., 2018) employ Generative Adversarial Networks (GANs) for EFP while (Rudinger et al., 2018) utilize LSTMs for both sequential and dependency representations of the input sentences. Finally, deep learning has also been considered for the related tasks of EFP, including event detection (Nguyen and Grishman, 2015b; Nguyen et al., 2016b; Lu and Nguyen, 2018; Nguyen and Nguyen, 2019), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016g), uncertainty detection (Adel and Sch¨utze, 2017), modal sense classification (Marasovic and Frank, 2016) and entity detection (Nguyen et al., 2016d). 3 Model The formal definition of the EFP task is as follows. Let (x1 , x2 , . . . , xn ) be a sentence that contains some event mention of interest, where n is the number of words/tokens and xi is the i-th token in the sentence. Also, let k be the position of the anchor word in this sentence (i.e., token xk ). For EFP, the goal is to assign a rea"
P19-1432,W16-1613,0,0.0161827,"cently, deep learning has been applied to solve EFP. (Qian et al., 2018) employ Generative Adversarial Networks (GANs) for EFP while (Rudinger et al., 2018) utilize LSTMs for both sequential and dependency representations of the input sentences. Finally, deep learning has also been considered for the related tasks of EFP, including event detection (Nguyen and Grishman, 2015b; Nguyen et al., 2016b; Lu and Nguyen, 2018; Nguyen and Nguyen, 2019), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016g), uncertainty detection (Adel and Sch¨utze, 2017), modal sense classification (Marasovic and Frank, 2016) and entity detection (Nguyen et al., 2016d). 3 Model The formal definition of the EFP task is as follows. Let (x1 , x2 , . . . , xn ) be a sentence that contains some event mention of interest, where n is the number of words/tokens and xi is the i-th token in the sentence. Also, let k be the position of the anchor word in this sentence (i.e., token xk ). For EFP, the goal is to assign a real number in the range of [-3, +3] to quantify the degree to which the current event mention has happened. There are three major components in the EFP model pro4394 posed in this work, i.e., (i) sentence enc"
P19-1432,L16-1699,0,0.190316,"Missing"
P19-1432,W06-3907,0,0.228247,"airs of words, thus facilitating the integration of syntactic and semantic information. In the proposed model, the semantic affinity matrices of the sentences are induced from Long Short-Term Memory networks (LSTM) that are then linearly integrated with the syntactic affinity matrices of the dependency trees to produce the enriched affinity matrices for GCNs in EFP. The extensive experiments show that the proposed model is very effective for EFP. 2 Related Work EFP is one of the fundamental tasks in Information Extraction. The early work on this problem has employed the rule-based approaches (Nairn et al., 2006; Saur´ı, 2008; Lotan et al., 2013) or the machine learning approaches (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), or the hybrid approaches of both (Saur´ı and Pustejovsky, 2012; Qian et al., 2015). Recently, deep learning has been applied to solve EFP. (Qian et al., 2018) employ Generative Adversarial Networks (GANs) for EFP while (Rudinger et al., 2018) utilize LSTMs for both sequential and dependency representations of the input sentences. Finally, deep learning has also been considered for the related tasks of"
P19-1432,N16-1034,1,0.923734,"oordination. In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively. Our experiments demonstrate the advantage of the proposed model for EFP. 1 I will seeing after need treatment the others when I back care medical of Figure 1: The dependency tree of the sentence “I will, after seeing the treatment of others, go back when I need medical care.”. Introduction Events are often presented in sentences via the indication of anchor/trigger words (i.e., the main words to evoke the events, called event mentions) (Nguyen et al., 2016a). Event mentions can appear with varying degrees of uncertainty/factuality to reflect the intent of the writers. In order for the event mentions to be useful (i.e., for knowledge extraction tasks), it is important to determine their factual certainty so the actual event mentions can be retrieved (i.e., the event factuality prediction problem (EFP)). In this work, we focus on the recent regression formulation of EFP that aims to predict a real score in the range of [-3,+3] to quantify the occurrence possibility of a given event mention (Stanovsky et al., 2017; Rudinger et al., 2018). This pro"
P19-1432,W16-1618,1,0.941894,"oordination. In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively. Our experiments demonstrate the advantage of the proposed model for EFP. 1 I will seeing after need treatment the others when I back care medical of Figure 1: The dependency tree of the sentence “I will, after seeing the treatment of others, go back when I need medical care.”. Introduction Events are often presented in sentences via the indication of anchor/trigger words (i.e., the main words to evoke the events, called event mentions) (Nguyen et al., 2016a). Event mentions can appear with varying degrees of uncertainty/factuality to reflect the intent of the writers. In order for the event mentions to be useful (i.e., for knowledge extraction tasks), it is important to determine their factual certainty so the actual event mentions can be retrieved (i.e., the event factuality prediction problem (EFP)). In this work, we focus on the recent regression formulation of EFP that aims to predict a real score in the range of [-3,+3] to quantify the occurrence possibility of a given event mention (Stanovsky et al., 2017; Rudinger et al., 2018). This pro"
P19-1432,P15-2060,1,0.843846,"3) or the machine learning approaches (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), or the hybrid approaches of both (Saur´ı and Pustejovsky, 2012; Qian et al., 2015). Recently, deep learning has been applied to solve EFP. (Qian et al., 2018) employ Generative Adversarial Networks (GANs) for EFP while (Rudinger et al., 2018) utilize LSTMs for both sequential and dependency representations of the input sentences. Finally, deep learning has also been considered for the related tasks of EFP, including event detection (Nguyen and Grishman, 2015b; Nguyen et al., 2016b; Lu and Nguyen, 2018; Nguyen and Nguyen, 2019), event realis classification (Mitamura et al., 2015; Nguyen et al., 2016g), uncertainty detection (Adel and Sch¨utze, 2017), modal sense classification (Marasovic and Frank, 2016) and entity detection (Nguyen et al., 2016d). 3 Model The formal definition of the EFP task is as follows. Let (x1 , x2 , . . . , xn ) be a sentence that contains some event mention of interest, where n is the number of words/tokens and xi is the i-th token in the sentence. Also, let k be the position of the anchor word in this sentence (i.e., toke"
P19-1432,D14-1162,0,0.0858119,"The proposed model - syntax structure (λ = 1) - semantic structure (λ = 0) - structure induction component - BERT - attention in prediction FactBank MAE r 0.310 0.903 0.314 0.867 0.337 0.832 0.352 0.821 0.342 0.831 0.312 0.890 UW MAE r 0.438 0.830 0.442 0.801 0.449 0.782 0.457 0.735 0.462 0.751 0.441 0.821 Meantime MAE r 0.204 0.702 0.251 0.658 0.288 0.604 0.305 0.582 0.315 0.570 0.221 0.695 UDS-IH2 MAE r 0.726 0.909 0.753 0.893 0.798 0.862 0.855 0.828 0.896 0.817 0.737 0.899 Table 3: Correlation (r) and MAE for different model configurations. The model without BERT (i.e., - BERT) uses Glove (Pennington et al., 2014) as in (Rudinger et al., 2018). deep learning (Rudinger et al., 2018). Table 1 shows the performance. Importantly, to achieve a fair comparison, we obtain the actual implementation of the current state-of-the-art EFP models from (Rudinger et al., 2018), introduce the BERT embeddings as the inputs for those models and compare them with the proposed models (i.e., the rows with “+BERT”). Following the prior work, we use MAE (Mean Absolute Error), and r (Pearson Correlation) as the performance measures. In the table, we distinguish two methods to train the models investigated in the previous work:"
P19-1432,C10-2117,0,0.0746553,"f the sentences are induced from Long Short-Term Memory networks (LSTM) that are then linearly integrated with the syntactic affinity matrices of the dependency trees to produce the enriched affinity matrices for GCNs in EFP. The extensive experiments show that the proposed model is very effective for EFP. 2 Related Work EFP is one of the fundamental tasks in Information Extraction. The early work on this problem has employed the rule-based approaches (Nairn et al., 2006; Saur´ı, 2008; Lotan et al., 2013) or the machine learning approaches (with manually designed features) (Diab et al., 2009; Prabhakaran et al., 2010; De Marneffe et al., 2012; Lee et al., 2015), or the hybrid approaches of both (Saur´ı and Pustejovsky, 2012; Qian et al., 2015). Recently, deep learning has been applied to solve EFP. (Qian et al., 2018) employ Generative Adversarial Networks (GANs) for EFP while (Rudinger et al., 2018) utilize LSTMs for both sequential and dependency representations of the input sentences. Finally, deep learning has also been considered for the related tasks of EFP, including event detection (Nguyen and Grishman, 2015b; Nguyen et al., 2016b; Lu and Nguyen, 2018; Nguyen and Nguyen, 2019), event realis classi"
P19-1432,N18-1067,0,0.133086,"Missing"
P19-1432,J12-2002,0,0.239961,"Missing"
P19-1432,P17-2056,0,0.208059,"the events, called event mentions) (Nguyen et al., 2016a). Event mentions can appear with varying degrees of uncertainty/factuality to reflect the intent of the writers. In order for the event mentions to be useful (i.e., for knowledge extraction tasks), it is important to determine their factual certainty so the actual event mentions can be retrieved (i.e., the event factuality prediction problem (EFP)). In this work, we focus on the recent regression formulation of EFP that aims to predict a real score in the range of [-3,+3] to quantify the occurrence possibility of a given event mention (Stanovsky et al., 2017; Rudinger et al., 2018). This provides more meaningful information for the downstream tasks than the classification formulation of EFP (Lee et al., 2015). For instance, the word “left” in the sentence “She left yesterday.” would express an event that certainly happened (i.e., corresponding to a score of +3 in the benchmark datasets) while the event mention associated with “leave” in the sentence “She forgot to leave yesterday.” would certainly not happen (i.e., a score of -3). EFP is a challenging problem as different context words might jointly participate to reveal the factuality of the eve"
W15-1506,W06-1615,0,0.120351,"often performed by existing natural language processing (NLP) modules. 39 Proceedings of NAACL-HLT 2015, pages 39–48, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics While these methods allow the RE systems to inherit the knowledge discovered by the NLP community for the pre-processing tasks, they might be subject to the error propagation introduced by the imperfect quality of the supervised NLP toolkits. For instance, all the tasks mentioned in the pipeline above are known to suffer from a performance loss when they are applied to out-of-domain data (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010), causing the collapse of the RE systems based on them. In this paper, we target an independent RE system that both avoids complicated feature engineering and minimizes the reliance on the supervised NLP modules for features, potentially alleviating the error propagation and advancing our performance in this area. To be concrete, our relation extraction system is provided only with raw sentences marked with the positions of the two entities of interest1 . The only elements we can derive from this structure are the words, the n-grams and their positions"
W15-1506,H05-1091,0,0.53247,"aking relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-designed itself includes tokenization, part of speech tagging, chunking, name tagging as well as parsing, often performed by existin"
W15-1506,C10-1018,0,0.13533,"on, on the other hand, often comes with a tremendously unbalanced dataset where the number of the non-relation examples far exceeds the others, making relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipel"
W15-1506,P04-1054,0,0.0466908,"es far exceeds the others, making relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-designed itself includes tokenization, part of speech tagging, chunking, name tagging as well as parsing,"
W15-1506,P07-1033,0,0.0341814,"Missing"
W15-1506,N07-1015,0,0.0400894,"ass. Relation extraction, on the other hand, often comes with a tremendously unbalanced dataset where the number of the non-relation examples far exceeds the others, making relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The ling"
W15-1506,P11-1055,0,0.0356559,"in Section 5. 2 Related Work As our present work focuses on the supervised framework for relation extraction, we concentrate on the supervised systems in this section. Besides the supervised systems (either feature-based or kernelbased) mentioned above, some recent systems have employed the distant supervision (DS) approach for relation extraction. This approach is essentially similar to the traditional systems in representing relation mentions but attempts to generate training data automatically by leveraging large knowledge bases of facts and corpus (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). Regarding neural networks, their first application to NLP is language modeling which has been useful to learn distributed representations (embeddings) for words (Bengio et al., 2001; Mnih and Hinton, 2007; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013). These word embeddings have opened a new direction for many other NLP tasks grounded on neural networks. Some of them are mentioned above. Other than that, a class of recursive neural networks (RNNs) and neural tensor networks are proposed for paraphrase detection (Socher e"
W15-1506,P14-1062,0,0.202045,"elements we can derive from this structure are the words, the n-grams and their positions in the sentences, suggesting a paradigm in which relation mentions are represented by features that depend on these elements. Eventually, word embeddings that are capable of capturing latent semantic and syntactic properties of words (Bengio et al., 2001; Mnih and Hinton, 2007; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013) and convolutional neural networks (CNNs) that are able to recognize specific classes of n-gram and induce more abstract representations (Kalchbrenner et al., 2014) are a natural combination one should apply to obtain more effective representations for RE in this setting. Convolutional neural networks (dating back to the 1980s) are a type of feed-forward artificial neural networks whose layers are formed by a convolution operation followed by a pooling operation (LeCun et al., 1988; Kalchbrenner et al., 2014). Recently, with the emerging interests of the community in deep learning, CNNs have been revived and effectively applied in various NLP tasks, including semantic parsing (Yih et al., 2014), search query retrieval (Shen et al., 2014), sentence modeli"
W15-1506,P04-3022,0,0.15341,"ples. The non-relation examples, therefore, can be treated as a usual relation class. Relation extraction, on the other hand, often comes with a tremendously unbalanced dataset where the number of the non-relation examples far exceeds the others, making relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical"
W15-1506,D14-1181,0,0.272335,"ain more effective representations for RE in this setting. Convolutional neural networks (dating back to the 1980s) are a type of feed-forward artificial neural networks whose layers are formed by a convolution operation followed by a pooling operation (LeCun et al., 1988; Kalchbrenner et al., 2014). Recently, with the emerging interests of the community in deep learning, CNNs have been revived and effectively applied in various NLP tasks, including semantic parsing (Yih et al., 2014), search query retrieval (Shen et al., 2014), sentence modeling and classification (Kalchbrenner et al., 2014; Kim, 2014), name tagging and semantic role labeling (Collobert et al., 2011). For relation classification and extraction, there are two very recent works on CNNs for relation classification (Liu et al., 2013)2 and (Zeng et al., 2014); however, to the best of our knowledge, there has been no work on employing CNNs for relation extraction so far. This paper is the first attempt to fill in that gap and serves as a baseline for future research in this area. Our convolutional neural network is built upon that of Kalchbrenner et al. (2014) and Kim (2014) which are originally proposed for sentence classificati"
W15-1506,N10-1004,0,0.0145528,"uage processing (NLP) modules. 39 Proceedings of NAACL-HLT 2015, pages 39–48, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics While these methods allow the RE systems to inherit the knowledge discovered by the NLP community for the pre-processing tasks, they might be subject to the error propagation introduced by the imperfect quality of the supervised NLP toolkits. For instance, all the tasks mentioned in the pipeline above are known to suffer from a performance loss when they are applied to out-of-domain data (Blitzer et al., 2006; Daum´e III, 2007; McClosky et al., 2010), causing the collapse of the RE systems based on them. In this paper, we target an independent RE system that both avoids complicated feature engineering and minimizes the reliance on the supervised NLP modules for features, potentially alleviating the error propagation and advancing our performance in this area. To be concrete, our relation extraction system is provided only with raw sentences marked with the positions of the two entities of interest1 . The only elements we can derive from this structure are the words, the n-grams and their positions in the sentences, suggesting a paradigm i"
W15-1506,P09-1113,0,0.656407,"uation in Section 4 and finally conclude in Section 5. 2 Related Work As our present work focuses on the supervised framework for relation extraction, we concentrate on the supervised systems in this section. Besides the supervised systems (either feature-based or kernelbased) mentioned above, some recent systems have employed the distant supervision (DS) approach for relation extraction. This approach is essentially similar to the traditional systems in representing relation mentions but attempts to generate training data automatically by leveraging large knowledge bases of facts and corpus (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). Regarding neural networks, their first application to NLP is language modeling which has been useful to learn distributed representations (embeddings) for words (Bengio et al., 2001; Mnih and Hinton, 2007; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013). These word embeddings have opened a new direction for many other NLP tasks grounded on neural networks. Some of them are mentioned above. Other than that, a class of recursive neural networks (RNNs) and neural tensor networks are"
W15-1506,D14-1070,0,0.0110704,"Missing"
W15-1506,P14-2012,1,0.876358,"a tremendously unbalanced dataset where the number of the non-relation examples far exceeds the others, making relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-designed itself includes tok"
W15-1506,D09-1143,0,0.0127323,"uses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-designed itself includes tokenization, part of speech tagging, chunking, name tagging as well as parsing, often performed by existing natural language processing (NLP) modules. 39 Proceedings of NAACL-HLT 2015, pages 39–48, c Denver, Color"
W15-1506,P13-1147,0,0.0568758,"Missing"
W15-1506,C08-1088,0,0.0725268,"ur present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-designed itself includes tokenization, part of speech tagging, chunking, name tagging as well as parsing, often performed by existing natural language processing (NLP) modules. 39 Proceedings of NAACL-HLT 2015, pages 3"
W15-1506,D12-1110,0,0.30152,"009; Turian et al., 2010; Mikolov et al., 2013). These word embeddings have opened a new direction for many other NLP tasks grounded on neural networks. Some of them are mentioned above. Other than that, a class of recursive neural networks (RNNs) and neural tensor networks are proposed for paraphrase detection (Socher et al., 2011), parsing (Socher et al., 2013a), sentiment analysis (Socher et al., 2013b), knowledge base completion (Socher et al., 2013c), question answering (Mohit et al., 2014) etc. Among these RNN systems, the study that is most related to our relation extraction problem is Socher et al. (2012) that learns compositional vector representations for phrases and sentences through syntactic parse trees and applies these representations for relation classification. However, this 41 method inherently requires syntactic parse trees in contrast to our target of avoiding use of any external features and resources for RC. 3 Convolutional Neural Network for Relation Extraction Our convolutional neural network for relation extraction consists of four main layers: (i) the look-up tables to encode words in sentences by real-valued vectors, (ii) the convolutional layer to recognize ngrams, (iii) th"
W15-1506,P13-1045,0,0.015865,"). Regarding neural networks, their first application to NLP is language modeling which has been useful to learn distributed representations (embeddings) for words (Bengio et al., 2001; Mnih and Hinton, 2007; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013). These word embeddings have opened a new direction for many other NLP tasks grounded on neural networks. Some of them are mentioned above. Other than that, a class of recursive neural networks (RNNs) and neural tensor networks are proposed for paraphrase detection (Socher et al., 2011), parsing (Socher et al., 2013a), sentiment analysis (Socher et al., 2013b), knowledge base completion (Socher et al., 2013c), question answering (Mohit et al., 2014) etc. Among these RNN systems, the study that is most related to our relation extraction problem is Socher et al. (2012) that learns compositional vector representations for phrases and sentences through syntactic parse trees and applies these representations for relation classification. However, this 41 method inherently requires syntactic parse trees in contrast to our target of avoiding use of any external features and resources for RC. 3 Convolutional Neur"
W15-1506,D13-1170,0,0.0351732,"to the best of our knowledge, there has been no work on employing CNNs for relation extraction so far. This paper is the first attempt to fill in that gap and serves as a baseline for future research in this area. Our convolutional neural network is built upon that of Kalchbrenner et al. (2014) and Kim (2014) which are originally proposed for sentence classification and modeling. We adapt the network for relation extraction by introducing the position embeddings to encode the relative distances of the words in the sentence to the two entities of interest. Compared to the models in Liu et al. (2013) and Zeng et al. (2014) for relation classification that apply a single window size, our model for relation extraction incorporates various window sizes for convolutional filters, allowing the network to capture wider ranges of n-grams to be helpful for relation extraction. In addition, rather than initializing the word embeddings randomly as do Liu et al. (2013) and fixing the randomly generated position embeddings during training as do Zeng et al. (2014), we use pretrained word embeddings for initialization and optimize both word embeddings and position embeddings as model parameters. More i"
W15-1506,P11-1053,1,0.646626,", often comes with a tremendously unbalanced dataset where the number of the non-relation examples far exceeds the others, making relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-"
W15-1506,P14-2011,0,0.0411358,"Missing"
W15-1506,D12-1042,0,0.141651,"Work As our present work focuses on the supervised framework for relation extraction, we concentrate on the supervised systems in this section. Besides the supervised systems (either feature-based or kernelbased) mentioned above, some recent systems have employed the distant supervision (DS) approach for relation extraction. This approach is essentially similar to the traditional systems in representing relation mentions but attempts to generate training data automatically by leveraging large knowledge bases of facts and corpus (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). Regarding neural networks, their first application to NLP is language modeling which has been useful to learn distributed representations (embeddings) for words (Bengio et al., 2001; Mnih and Hinton, 2007; Collobert and Weston, 2008; Mnih and Hinton, 2009; Turian et al., 2010; Mikolov et al., 2013). These word embeddings have opened a new direction for many other NLP tasks grounded on neural networks. Some of them are mentioned above. Other than that, a class of recursive neural networks (RNNs) and neural tensor networks are proposed for paraphrase detection (Socher et al., 2011), parsing (S"
W15-1506,P10-1040,0,0.0269226,"Missing"
W15-1506,P14-2105,0,0.0196539,"of n-gram and induce more abstract representations (Kalchbrenner et al., 2014) are a natural combination one should apply to obtain more effective representations for RE in this setting. Convolutional neural networks (dating back to the 1980s) are a type of feed-forward artificial neural networks whose layers are formed by a convolution operation followed by a pooling operation (LeCun et al., 1988; Kalchbrenner et al., 2014). Recently, with the emerging interests of the community in deep learning, CNNs have been revived and effectively applied in various NLP tasks, including semantic parsing (Yih et al., 2014), search query retrieval (Shen et al., 2014), sentence modeling and classification (Kalchbrenner et al., 2014; Kim, 2014), name tagging and semantic role labeling (Collobert et al., 2011). For relation classification and extraction, there are two very recent works on CNNs for relation classification (Liu et al., 2013)2 and (Zeng et al., 2014); however, to the best of our knowledge, there has been no work on employing CNNs for relation extraction so far. This paper is the first attempt to fill in that gap and serves as a baseline for future research in this area. Our convolutional neural networ"
W15-1506,C14-1220,0,0.811561,"ation followed by a pooling operation (LeCun et al., 1988; Kalchbrenner et al., 2014). Recently, with the emerging interests of the community in deep learning, CNNs have been revived and effectively applied in various NLP tasks, including semantic parsing (Yih et al., 2014), search query retrieval (Shen et al., 2014), sentence modeling and classification (Kalchbrenner et al., 2014; Kim, 2014), name tagging and semantic role labeling (Collobert et al., 2011). For relation classification and extraction, there are two very recent works on CNNs for relation classification (Liu et al., 2013)2 and (Zeng et al., 2014); however, to the best of our knowledge, there has been no work on employing CNNs for relation extraction so far. This paper is the first attempt to fill in that gap and serves as a baseline for future research in this area. Our convolutional neural network is built upon that of Kalchbrenner et al. (2014) and Kim (2014) which are originally proposed for sentence classification and modeling. We adapt the network for relation extraction by introducing the position embeddings to encode the relative distances of the words in the sentence to the two entities of interest. Compared to the models in L"
W15-1506,P06-1104,0,0.0235243,"actical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-designed itself includes tokenization, part of speech tagging, chunking, name tagging as well as parsing, often performed by existing natural language processing (NLP) modules. 39"
W15-1506,P05-1053,0,0.977313,"ore, can be treated as a usual relation class. Relation extraction, on the other hand, often comes with a tremendously unbalanced dataset where the number of the non-relation examples far exceeds the others, making relation extraction more challenging but more practical than relation classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machine"
W15-1506,D07-1076,0,0.00899967,"n classification. Our present work focuses on the relation extraction task with an unbalanced corpus. In the last decade, the relation extraction literature has been dominated by two methods, distinguished by the nature of the relation representation: the feature-based method (Kambhatla, 2004; Boschee et al., 2005; Zhou et al., 2005; Grishman et al., 2005; Jiang and Zhai, 2007; Chan and Roth, 2010; Sun et al., 2011; Nguyen and Grishman, 2014) and the kernel-based method (Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005a; Bunescu and Mooney, 2005b; Zhang et al., 2006; Zhou et al., 2007; Qian et al., 2008; Nguyen et al., 2009; Sun and Han, 2014). The common characteristic of these methods is the leverage of a large body of linguistic analysis and knowledge resources to transform relation mentions into some rich representation to be used by some statistical classifier such as Support Vector Machines (SVM) or Maximum Entropy (MaxEnt). The linguistic analysis pipeline which is hand-designed itself includes tokenization, part of speech tagging, chunking, name tagging as well as parsing, often performed by existing natural language processing (NLP) modules. 39 Proceedings of NAAC"
W15-1506,S10-1006,0,\N,Missing
W15-4502,P13-1008,0,0.172747,"ntext in ED. In this work, all AMR parse graphs are automatically generated from the first published AMR parser, JAMR (Flanigan et al., 2014). 3 Experiments 4.1 Dataset and Evaluation Metric We evaluate our system with above presented features over the ACE 2005 corpus. For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaining 529 documents (14, 849 sentences) as the previous studies on this dataset (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013b). Following the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013b), a trigger candidate is counted as correct if its event subtype and offsets match those of a reference trigger. The ACE 2005 corpus has 33 event subtypes that, along with one class “Other” for the non-trigger tokens, constitutes a 34-class classification problem in this work. Finally we use Precision (P), Recall (R), and F-measure (F1 ) to evaluate the performance. Table 2 presents the overall performance of the systems with gold-standard entity mention and Framework and Featur"
W15-4502,W06-0901,0,0.363076,"Missing"
W15-4502,P10-1081,1,0.890682,"only used to represent context in ED. In this work, all AMR parse graphs are automatically generated from the first published AMR parser, JAMR (Flanigan et al., 2014). 3 Experiments 4.1 Dataset and Evaluation Metric We evaluate our system with above presented features over the ACE 2005 corpus. For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaining 529 documents (14, 849 sentences) as the previous studies on this dataset (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013b). Following the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013b), a trigger candidate is counted as correct if its event subtype and offsets match those of a reference trigger. The ACE 2005 corpus has 33 event subtypes that, along with one class “Other” for the non-trigger tokens, constitutes a 34-class classification problem in this work. Finally we use Precision (P), Recall (R), and F-measure (F1 ) to evaluate the performance. Table 2 presents the overall performance of the systems with gold-standard entity mention and Fra"
W15-4502,W13-2322,0,0.0400666,"Missing"
W15-4502,R11-1002,1,0.927597,"Missing"
W15-4502,N15-1114,0,0.0103745,", including methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptrons (Li et al., 2013b), and dual decomposition (Riedel and McCallum (2009; 2011a; 2011b)). However, all of these methods as mentioned above have not exploited the knowledge captured in the AMR. A growing number of researchers are studying how to incorporate the knowledge encoded in the AMR parse and representations to help solve other NLP problems, such as entity linking (Pan et al., 2015), machine translation (Jones et al., 2015), and summarization (Liu et al., 2015). Especially the appearance of the first published AMR parser (Flanigan et al., 2014) will benefit and spur a lot of new research conducted using AMR. Discussion Applying the AMR features separately, we find that the features extracted from the sibling nodes are the best predictors of correctness, which indicates that the contexts of sibling nodes associated with the AMR tags can provide better evidence for word sense disambiguation of the trigger candidate as needed for event type classification. Features from the parent node and children nodes are also significant contributors. Performance o"
W15-4502,dorr-etal-1998-thematic,0,0.0693321,"Missing"
W15-4502,P11-1163,0,0.040647,"Missing"
W15-4502,P14-1134,0,0.243288,"be syntactic “sugar” and are not explicitly represented in AMR, except for the semantic relations they signal. Hence, it assigns the same AMR parse graph to sentences that have the same basic meaning.3 Compared to traditional dependency parsing and semantic role labeling, the nodes in AMR are entities instead of words, and the edge types are much more fine-grained. AMR thus captures deeper meaning compared with other representations which are more commonly used to represent context in ED. In this work, all AMR parse graphs are automatically generated from the first published AMR parser, JAMR (Flanigan et al., 2014). 3 Experiments 4.1 Dataset and Evaluation Metric We evaluate our system with above presented features over the ACE 2005 corpus. For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaining 529 documents (14, 849 sentences) as the previous studies on this dataset (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013b). Following the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013b), a trigg"
W15-4502,J05-1004,0,0.0338394,"ure 1: Two equivalent ways of representing the AMR parse graph, and the corresponding feature AMR parse for the example sentence, “The acquivalues, for trigger candidate “acquisition”, from sition of Edison GE will boost AIG’s annual life the above example AMR graph. insurance revenue.” boost-01 Improve Event Detection with Abstract Meaning Representation ARG0 ARG1 4 In this section, we will compare our MaxEnt classifiers using both baseline features and additional proposed AMR features with the state-of-the-art systems on the blind test set, and then discuss the results in more detail. 2002; Palmer et al., 2005). For example, a phrase like “bond investor” is represented using the frame “invest-01”, even though no verbs appear. In addition, many function words (determiners, prepositions) are considered to be syntactic “sugar” and are not explicitly represented in AMR, except for the semantic relations they signal. Hence, it assigns the same AMR parse graph to sentences that have the same basic meaning.3 Compared to traditional dependency parsing and semantic role labeling, the nodes in AMR are entities instead of words, and the edge types are much more fine-grained. AMR thus captures deeper meaning co"
W15-4502,N15-1119,0,0.0309298,") of baseline and AMR on a subset of event types. 4.2 has worked on joint models, including methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptrons (Li et al., 2013b), and dual decomposition (Riedel and McCallum (2009; 2011a; 2011b)). However, all of these methods as mentioned above have not exploited the knowledge captured in the AMR. A growing number of researchers are studying how to incorporate the knowledge encoded in the AMR parse and representations to help solve other NLP problems, such as entity linking (Pan et al., 2015), machine translation (Jones et al., 2015), and summarization (Liu et al., 2015). Especially the appearance of the first published AMR parser (Flanigan et al., 2014) will benefit and spur a lot of new research conducted using AMR. Discussion Applying the AMR features separately, we find that the features extracted from the sibling nodes are the best predictors of correctness, which indicates that the contexts of sibling nodes associated with the AMR tags can provide better evidence for word sense disambiguation of the trigger candidate as needed for event type classification. Features from the"
W15-4502,P09-2093,0,0.0487434,"Missing"
W15-4502,D09-1016,0,0.0224803,"Missing"
W15-4502,P11-1113,0,0.102381,"shed AMR parser, JAMR (Flanigan et al., 2014). 3 Experiments 4.1 Dataset and Evaluation Metric We evaluate our system with above presented features over the ACE 2005 corpus. For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaining 529 documents (14, 849 sentences) as the previous studies on this dataset (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013b). Following the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013b), a trigger candidate is counted as correct if its event subtype and offsets match those of a reference trigger. The ACE 2005 corpus has 33 event subtypes that, along with one class “Other” for the non-trigger tokens, constitutes a 34-class classification problem in this work. Finally we use Precision (P), Recall (R), and F-measure (F1 ) to evaluate the performance. Table 2 presents the overall performance of the systems with gold-standard entity mention and Framework and Features To compare our proposed AMR features with the previous approaches, we implemented a Maximum Ent"
W15-4502,N10-1123,0,0.0178759,"Missing"
W15-4502,D11-1001,0,0.024998,"Missing"
W15-4502,P08-1030,1,0.682387,"ons which are more commonly used to represent context in ED. In this work, all AMR parse graphs are automatically generated from the first published AMR parser, JAMR (Flanigan et al., 2014). 3 Experiments 4.1 Dataset and Evaluation Metric We evaluate our system with above presented features over the ACE 2005 corpus. For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaining 529 documents (14, 849 sentences) as the previous studies on this dataset (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013b). Following the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2013b), a trigger candidate is counted as correct if its event subtype and offsets match those of a reference trigger. The ACE 2005 corpus has 33 event subtypes that, along with one class “Other” for the non-trigger tokens, constitutes a 34-class classification problem in this work. Finally we use Precision (P), Recall (R), and F-measure (F1 ) to evaluate the performance. Table 2 presents the overall performance of the systems with gold-standa"
W15-4502,W11-1807,0,0.0180918,"Missing"
W15-4502,W09-1406,0,0.0383609,"Missing"
W15-4502,kingsbury-palmer-2002-treebank,0,0.0917821,"Missing"
W15-4502,D12-1092,0,0.0248754,"Missing"
W15-4502,P13-1145,0,0.0316416,"Missing"
W15-4502,C12-1083,0,\N,Missing
W16-1618,W06-0901,0,0.0379377,"concepts or topics covered by the corresponding event types in the ACE 2005 corpus. As we can see from the 5 Taken from the ACE 2005 Annotation Guideline 163 Defined by the annotation guideline. plan to apply the two-stage algorithm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of"
W16-1618,W06-1615,0,0.0242467,"abeled instances for each event type in the training data. Unfortunately, this setting does not reflect the real world situation very well. In practice, we often have a large amount of training data for some old event types but are interested in extracting instances of a new event type. The new event type is only specified by a small set of seed instances provided by clients (the event type extension setting). How can we effectively leverage the training data of old event types to facilitate the extraction of the new event type? Inspired by the work on transfer learning and domain adaptation (Blitzer et al., 2006; Jiang and Zhai, 2007; Daume III, 2007; Jiang, 2009), in this paper, we systematically evaluate the representative methods (i.e, the feature based model and the CNN model) for ED to gain an insight into which kind of method performs better in the new extension setting. In addition, we propose a two-stage algorithm to train a CNN model that effectively learns and transfers the knowledge from the old event types for the extraction of the target type. We study the event detection problem in the new type extension setting. In particular, our task involves identifying the event instances of a targ"
W16-1618,D14-1199,0,0.034208,"Missing"
W16-1618,P15-1017,0,0.447118,"he feature-based approach that has dominated the ED research in the last decade (Ji and Grishman, 2008; Gupta and Ji, 2009; Liao and Grishman, 2011; McClosky et al., 2011; Riedel and McCallum, 2011; Li et al., 2013; Venugopal et al., 2014). The second approach, on the other hand, is proposed very recently and uses convolutional neural networks (CNN) to exploit the continuous representations of words. These continuous representations have been shown to effectively capture the underlying structures of a sentence, thereby significantly improving the performance for ED (Nguyen and Grishman, 2015; Chen et al., 2015). The previous research has mainly focused on building an ED system in a supervised setting. The performance of such systems strongly depends on a sufficient amount of labeled instances for each event type in the training data. Unfortunately, this setting does not reflect the real world situation very well. In practice, we often have a large amount of training data for some old event types but are interested in extracting instances of a new event type. The new event type is only specified by a small set of seed instances provided by clients (the event type extension setting). How can we effect"
W16-1618,P07-1033,0,0.0333017,"Missing"
W16-1618,P09-2093,0,0.0127275,"ken from the ACE 2005 Annotation Guideline 163 Defined by the annotation guideline. plan to apply the two-stage algorithm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to l"
W16-1618,P11-1113,0,0.20635,"he two-stage algorithm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utilize these embeddings"
W16-1618,P08-1030,1,0.37819,"e can see from the 5 Taken from the ACE 2005 Annotation Guideline 163 Defined by the annotation guideline. plan to apply the two-stage algorithm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use"
W16-1618,P09-1114,0,0.107311,"fortunately, this setting does not reflect the real world situation very well. In practice, we often have a large amount of training data for some old event types but are interested in extracting instances of a new event type. The new event type is only specified by a small set of seed instances provided by clients (the event type extension setting). How can we effectively leverage the training data of old event types to facilitate the extraction of the new event type? Inspired by the work on transfer learning and domain adaptation (Blitzer et al., 2006; Jiang and Zhai, 2007; Daume III, 2007; Jiang, 2009), in this paper, we systematically evaluate the representative methods (i.e, the feature based model and the CNN model) for ED to gain an insight into which kind of method performs better in the new extension setting. In addition, we propose a two-stage algorithm to train a CNN model that effectively learns and transfers the knowledge from the old event types for the extraction of the target type. We study the event detection problem in the new type extension setting. In particular, our task involves identifying the event instances of a target type that is only specified by a small set of seed"
W16-1618,P13-1008,0,0.566443,"involves event argument discovery. There have been two major approaches to ED in the literature. The first approach extensively leverages linguistic analysis and knowledge resources to capture the discrete structures for ED, focusing on the combination of various properties 1 most often a single verb or nominalization 158 Proceedings of the 1st Workshop on Representation Learning for NLP, pages 158–165, c Berlin, Germany, August 11th, 2016. 2016 Association for Computational Linguistics entropy (MaxEnt) and classified as the type T or not. In this work, we employ the feature set for ED from (Li et al., 2013), which is the state-of-the-art FET. The experimental results show that this two-stage algorithm significantly outperforms the traditional methods in the type extension setting for ED and demonstrates the benefit of CNN in transfer learning. To our knowledge, this is the first work on the type extension setting as well as on transferring knowledge with neural networks for ED of natural language processing. 2 3.2 In a CNN for ED, we limit the context of the trigger candidates to a fixed window size by trimming longer sentences and padding shorter sentences with a special token when necessary. L"
W16-1618,D14-1198,0,0.0351828,"entence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utilize these embeddings as features in statistical classifiers. Chen et al. (2015) apply dynamic multi-pooling CNNs for EE in a pipelined framework, while Nguyen et al. (2016) propose joint event extraction using recurrent neural networks. Finally, domain adaptation and transfer learning have been studied extensively for variou"
W16-1618,P10-1081,1,0.725734,"fined by the annotation guideline. plan to apply the two-stage algorithm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains"
W16-1618,R11-1002,1,0.880877,"uideline. plan to apply the two-stage algorithm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utiliz"
W16-1618,P10-1040,0,0.0179284,"might only be partial and not necessarily include all the trigger words of type T in D. Also, we call DN the set of the negative instances generated from D under this setting (to be discussed in more details later). In general, DN might contains unannotated trigger words of T (false negatives), making this task more challenging. Eventually, our goal is to learn an event detector for T , leveraging the training data DT , DA and DN for both the target and auxiliary types. Note that our work is related to Jiang (2009) who studies the relation type extension problem. 3 1. Word Embedding Table E (Turian et al., 2010; Mikolov et al., 2013a; Mikolov et al., 2013b). 2. Position Embedding Table: to embed the relative distance i of xi to the current token x0 . 3. Entity Type Embedding Table: to capture the entity type information for each token. Following Nguyen and Grishman (2015), we assign the entity type labels to each token using the heads of the entity mentions in x with the BIO schema. As a result, the original event trigger candidate x is transformed into a matrix x = [x−w , x−w+1 , . . . , x0 , . . . , xw−1 , xw ]. This matrix will serve as the input for CNN. Models for Event Detection In this sectio"
W16-1618,N10-1004,0,0.0148524,"Missing"
W16-1618,D14-1090,0,0.109324,"rly research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utilize these embeddings as features in statistical classifiers. Chen et al. (2015) apply dynamic multi-pooling CNNs for EE in a pipelined framework, while Nguyen et al. (2016) propose joint event extraction using recurrent neural networks. Finally, domain adaptation and t"
W16-1618,P11-1163,0,0.0172154,"thm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utilize these embeddings as features in statisti"
W16-1618,P14-2012,1,0.527304,"Missing"
W16-1618,P15-2060,1,0.307446,"azetteers. This is called the feature-based approach that has dominated the ED research in the last decade (Ji and Grishman, 2008; Gupta and Ji, 2009; Liao and Grishman, 2011; McClosky et al., 2011; Riedel and McCallum, 2011; Li et al., 2013; Venugopal et al., 2014). The second approach, on the other hand, is proposed very recently and uses convolutional neural networks (CNN) to exploit the continuous representations of words. These continuous representations have been shown to effectively capture the underlying structures of a sentence, thereby significantly improving the performance for ED (Nguyen and Grishman, 2015; Chen et al., 2015). The previous research has mainly focused on building an ED system in a supervised setting. The performance of such systems strongly depends on a sufficient amount of labeled instances for each event type in the training data. Unfortunately, this setting does not reflect the real world situation very well. In practice, we often have a large amount of training data for some old event types but are interested in extracting instances of a new event type. The new event type is only specified by a small set of seed instances provided by clients (the event type extension setting"
W16-1618,P15-1062,1,0.900189,"Missing"
W16-1618,N16-1034,1,0.371819,"the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utilize these embeddings as features in statistical classifiers. Chen et al. (2015) apply dynamic multi-pooling CNNs for EE in a pipelined framework, while Nguyen et al. (2016) propose joint event extraction using recurrent neural networks. Finally, domain adaptation and transfer learning have been studied extensively for various NLP tasks, including part of speech tagging (Blitzer et al., 2006), name tagging (Daume III, 2007), parsing (McClosky et al., 2010), relation extraction (Plank and Moschitti, 2013; Nguyen and Grishman, 2014; Nguyen et al., 2015a), to name a few. For event extraction, Miwa et al. (2013) study instance weighting and stacking models while Riedel and McCallum (2011b) examine joint models with domain adaptation. However, none of them studies the"
W16-1618,D09-1016,0,0.0113689,"5 Annotation Guideline 163 Defined by the annotation guideline. plan to apply the two-stage algorithm to other tasks such as relation extension to further verify its effectiveness. table, the Meet and Phone-Write subtypes or topics of Contact are quite separate from those of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a c"
W16-1618,P13-1147,0,0.0300964,"Missing"
W16-1618,N10-1123,0,0.0141137,"7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utilize these embeddings as features in statistical classifiers. Chen et al. (2015) apply dynamic multi-pooling CNNs for EE in a pipelined framework, while Nguyen et al. (2016) propose joint event extraction using recurrent neural networks. Finally"
W16-1618,D11-1001,0,0.0243931,"Missing"
W16-1618,W11-1807,0,0.0518334,"Missing"
W16-1618,W09-1406,0,0.0191274,"of the other types. 7 Related Work References Early research on event extraction has primarily focused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). Afterward, higher level features have been found to improve the performance (Ji and Grishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Some recent research has proposed joint models for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Vanderwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011b)). The application of neural networks to EE is very recent. In particular, Zhou et al. (2014) and Boros et al. (2014) use neural networks to learn word embeddings from a corpus of specific domains and then directly utilize these embeddings as features in statistical classifiers. Chen et al. (2015) apply dynamic multi-pooling CNNs for EE in a pipelined framework, while Nguyen et al. (2016) propose joint event extraction using recurr"
W18-6126,W14-2907,0,0.177062,"Missing"
W18-6126,P13-1147,0,0.0250685,"ture representation layer even though the relation schemas are different. We use ACE05 and ERE datasets as our case study for experiments. The multi-task model obtains significant improvement on both datasets. 1 2 Related Work Relation extraction is typically reduced to a classification problem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic re"
W18-6126,W15-0812,0,0.0147816,"ents did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic relationships between two entities. For example, there is Physical.Located relationship between Smith and Brazil in the sentence: Smith went to a conference in Brazil. Relation extraction is a crucial task for many applications such as knowledge base population. Several relation schemas and annotated corpora have been developed such as the Automatic Content Extraction (ACE), and the Entities, Relations and Events (ERE) annotation (Song et al., 2015). These schemas share some similarity, but differ in details. A relation type may exist in one schema but not in another. An example might be annotated as different types in different datasets. For example, Part-whole.Geographical relations in ACE05 are annotated as Physcial.Located relations in ERE. Most of these corpora are relatively small. Models trained on a single corpus may be biased or overfitted towards the corpus. Despite the difference in relation schemas, we hypothesize that we can learn a more general rep1 https://catalog.ldc.upenn.edu/LDC2006T06 We use 6 LDC releases combined: LD"
W18-6126,P15-2139,0,0.0761717,"Missing"
W18-6126,D15-1203,0,0.208795,"Missing"
W18-6126,I17-2072,1,0.946739,"Relation extraction is typically reduced to a classification problem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic relationships between two entities. For example, there is Physical.Located relationship between Smith and Brazil in the sentence: Smith went to a conference in Brazil. Relation extraction is a crucial task for many appl"
W18-6126,C14-1220,0,0.746591,"ignificant improvement on both datasets. 1 2 Related Work Relation extraction is typically reduced to a classification problem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic relationships between two entities. For example, there is Physical.Located relationship between Smith and Brazil in the sentence: Smith went to a conference in Br"
W18-6126,Y15-1009,0,0.0193064,"a classification problem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic relationships between two entities. For example, there is Physical.Located relationship between Smith and Brazil in the sentence: Smith went to a conference in Brazil. Relation extraction is a crucial task for many applications such as knowledge base population. S"
W18-6126,D15-1205,0,0.180496,"Missing"
W18-6126,P05-1053,0,0.0990245,"gularization by adversarial training. The additional corpora feeding the encoder can help to learn a better feature representation layer even though the relation schemas are different. We use ACE05 and ERE datasets as our case study for experiments. The multi-task model obtains significant improvement on both datasets. 1 2 Related Work Relation extraction is typically reduced to a classification problem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and"
W18-6126,P07-1034,0,0.0138097,"ersarial training. The additional corpora feeding the encoder can help to learn a better feature representation layer even though the relation schemas are different. We use ACE05 and ERE datasets as our case study for experiments. The multi-task model obtains significant improvement on both datasets. 1 2 Related Work Relation extraction is typically reduced to a classification problem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et"
W18-6126,P16-2034,0,0.358936,"oblem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic relationships between two entities. For example, there is Physical.Located relationship between Smith and Brazil in the sentence: Smith went to a conference in Brazil. Relation extraction is a crucial task for many applications such as knowledge base population. Several relation sch"
W18-6126,I17-1068,1,0.890146,"Missing"
W18-6126,P16-1105,0,0.212293,"machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic relationships between two entities. For example, there is Physical.Located relationship between Smith and Brazil in the sentence: Smith went to a conference in Brazil. Relation extraction is a crucial task for many applications such as knowledge base population. Several relation schemas and annotated corpo"
W18-6126,W15-1506,1,0.956821,"both datasets. 1 2 Related Work Relation extraction is typically reduced to a classification problem. A supervised machine learning model is designed and trained on a single dataset to predict the relation type of pairs of entities. Traditional methods rely on linguistic or semantic features (Zhou et al., 2005; Jing and Zhai, 2007), or kernels based on syntax or sequences (Bunescu and Mooney, 2005a,b; Plank and Moschitti, 2013) to represent sentences of relations. More recently, deep neural nets start to show promising results. Most rely on convolutional neural nets (Zeng et al., 2014, 2015; Nguyen and Grishman, 2015, 2016; Fu et al., 2017) or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations. Our supervised base model will be similar to (Zhou et al., 2016). Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016; Fu et al., 2017) that require additional parsers. Introduction Relations represent specific semantic relationships between two entities. For example, there is Physical.Located relationship between Smith and Brazil in the sentence: Smith went to a conference in Brazil. Relation extraction is a cr"
