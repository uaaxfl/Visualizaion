S15-2053,{S}em{E}val-2015 Task 15: A {CPA} dictionary-entry-building task,2015,11,3,5,0,25266,vit baisa,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes the first SemEval task to explore the usen of Natural Language Processing systems for building dictionaryn entries, in the framework of Corpus Pattern Analysis. CPA is an corpus-driven technique which provides tools and resources ton identify and represent unambiguously the main semantic patternsn in which words are used. Task 15 draws on the Patternn Dictionary of English Verbs (www.pdev.org.uk), for the targetedn lexical entries, and on the British National Corpus for then input text. Dictionary entry building is split into threen subtasks which all start from the same concordance sample: 1)n CPA parsing, where arguments and their syntactic and semanticn categories have to be identified, 2) CPA clustering, in whichn sentences with similar patterns have to be clustered and 3) CPAn automatic lexicography where the structure of patterns have ton be constructed automatically. Subtask 1 attracted 3 teams,n though none could beat the baseline (rule-based system).n Subtask 2 attracted 2 teams, one of which beat the baselinen (majority-class classifier). Subtask 3 did not attract anyn participant. The task has produced a major semanticn multidataset resource which includes data for 121 verbs andn about 17,000 annotated sentences, and which is freelyn accessible."
W14-5146,{H}indi Word Sketches,2014,0,1,5,0,38334,anil eragani,Proceedings of the 11th International Conference on Natural Language Processing,0,None
kilgarriff-etal-2014-extrinsic,Extrinsic Corpus Evaluation with a Collocation Dictionary Task,2014,17,5,1,1,37221,adam kilgarriff,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The NLP researcher or application-builder often wonders {``}what corpus should I use, or should I build one of my own? If I build one of my own, how will I know if I have done a good job?{''} Currently there is very little help available for them. They are in need of a framework for evaluating corpora. We develop such a framework, in relation to corpora which aim for good coverage of `general language{'}. The task we set is automatic creation of a publication-quality collocations dictionary. For a sample of 100 headwords of Czech and 100 of English, we identify a gold standard dataset of (ideally) all the collocations that should appear for these headwords in such a dictionary. The datasets are being made available alongside this paper. We then use them to determine precision and recall for a range of corpora, with a range of parameters."
temnikova-etal-2014-sublanguage,Sublanguage Corpus Analysis Toolkit: A tool for assessing the representativeness and sublanguage characteristics of corpora,2014,11,4,6,0,23303,irina temnikova,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Sublanguages are varieties of language that form ÂsubsetsÂ of the general language, typically exhibiting particular types of lexical, semantic, and other restrictions and deviance. SubCAT, the Sublanguage Corpus Analysis Toolkit, assesses the representativeness and closure properties of corpora to analyze the extent to which they are either sublanguages, or representative samples of the general language. The current version of SubCAT contains scripts and applications for assessing lexical closure, morphological closure, sentence type closure, over-represented words, and syntactic deviance. Its operation is illustrated with three case studies concerning scientific journal articles, patents, and clinical records. Materials from two language families are analyzedâEnglish (Germanic), and Bulgarian (Slavic). The software is available at sublanguage.sourceforge.net under a liberal Open Source license."
E14-2014,Finding Terms in Corpora for Many Languages with the {S}ketch {E}ngine,2014,11,12,2,1,14162,milovs jakubivcek,Proceedings of the Demonstrations at the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Term candidates for a domain, in a language, can be found by xe2x80xa2 taking a corpus for the domain, and a refer- ence corpus for the language xe2x80xa2 identifying the grammatical shape of a term in the language xe2x80xa2 tokenising, lemmatising and POS-tagging both corpora xe2x80xa2 identifying (and counting) the items in each corpus which match the grammatical shape xe2x80xa2 for each item in the domain corpus, compar- ing its frequency with its frequency in the refence corpus. Then, the items with the highest frequency in the domain corpus in comparison to the reference cor- pus will be the top term candidates. None of the steps above are unusual or innova- tive for NLP (see, e. g., (Aker et al., 2013), (Go- jun et al., 2012)). However it is far from trivial to implement them all, for numerous languages, in an environment that makes it easy for non- programmers to find the terms in a domain. This is what we have done in the Sketch Engine (Kilgarriff et al., 2004), and will demonstrate. In this abstract we describe how we addressed each of the stages above."
2014.tc-1.16,Terminology finding in the {S}ketch {E}ngine: an evaluation,2014,-1,-1,1,1,37221,adam kilgarriff,Proceedings of Translating and the Computer 36,0,None
2013.tc-1.9,Terminology finding in the Sketch engine,2013,-1,-1,1,1,37221,adam kilgarriff,Proceedings of Translating and the Computer 35,0,None
ambati-etal-2012-word,Word Sketches for {T}urkish,2012,18,9,3,0,34684,bharat ambati,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Word sketches are one-page, automatic, corpus-based summaries of a word's grammatical and collocational behaviour. In this paper we present word sketches for Turkish. Until now, word sketches have been generated using a purpose-built finite-state grammars. Here, we use an existing dependency parser. We describe the process of collecting a 42 million word corpus, parsing it, and generating word sketches from it. We evaluate the word sketches in comparison with word sketches from a language independent sketch grammar on an external evaluation task called topic coherence, using Turkish WordNet to derive an evaluation set of coherent topics."
W11-2838,Helping Our Own: The {HOO} 2011 Pilot Shared Task,2011,2,114,2,0,42377,robert dale,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"The aim of the Helping Our Own (HOO) Shared Task is to promote the development of automated tools and techniques that can assist authors in the writing task, with a specific focus on writing within the natural language processing community. This paper reports on the results of a pilot run of the shared task, in which six teams participated. We describe the nature of the task and the data used, report on the results achieved, and discuss some of the things we learned that will guide future versions of the task."
Y10-1086,Fast Syntactic Searching in Very Large Corpora for Many Languages,2010,-1,-1,2,1,14162,milovs jakubivcek,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,None
W10-4236,Helping Our Own: Text Massaging for Computational Linguistics as a New Shared Task,2010,8,39,2,0,42377,robert dale,Proceedings of the 6th International Natural Language Generation Conference,0,"In this paper, we propose a new shared task called HOO: Helping Our Own. The aim is to use tools and techniques developed in computational linguistics to help people writing about computational linguistics. We describe a text-to-text generation scenario that poses challenging research questions, and delivers practical outcomes that are useful in the first case to our own community and potentially much more widely. Two specific factors make us optimistic that this task will generate useful outcomes: one is the availability of the ACL Anthology, a large corpus of the target text type; the other is that CL researchers who are non-native speakers of English will be motivated to use prototype systems, providing informed and precise feedback in large quantity. We lay out our plans in detail and invite comment and critique with the aim of improving the nature of the planned exercise."
N10-2006,"A Detailed, Accurate, Extensive, Available {E}nglish Lexical Database",2010,10,5,1,1,37221,adam kilgarriff,Proceedings of the {NAACL} {HLT} 2010 Demonstration Session,0,"We present an English lexical database which is fuller, more accurate and more consistent than any other. We believe this to be so because the project has been well-planned, with a 12-month intensive planning phase prior to the lexicography beginning; well-resourced, employing a team of fifteen highly experienced lexicographers for a thirty-month main phase; it has had access to the latest corpus and dictionary-editing technology; it has not been constrained to meet any goals other than an accurate description of the language; and it has been led by a team with singular experience in delivering high-quality and innovative resources. The lexicon will be complete in Summer 2010 and will be available for NLP groups, on terms designed to encourage its research use."
kilgarriff-etal-2010-corpus,A Corpus Factory for Many Languages,2010,18,54,1,1,37221,adam kilgarriff,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"For many languages there are no large, general-language corpora available. Until the web, all but the institutions could do little but shake their heads in dismay as corpus-building was long, slow and expensive. But with the advent of the Web it can be highly automated and thereby fast and inexpensive. We have developed a Âcorpus factoryÂ where we build large corpora. In this paper we describe the method we use, and how it has worked, and how various problems were solved, for eight languages: Dutch, Hindi, Indonesian, Norwegian, Swedish, Telugu, Thai and Vietnamese. We use the BootCaT method: we take a set of 'seed words' for the language from Wikipedia. Then, several hundred times over, we * randomly select three or four of the seed words * send as a query to Google or Yahoo or Bing, which returns a 'search hits' page * gather the pages that Google or Yahoo point to and save the text. This forms the corpus, which we then * 'clean' (to remove navigation bars, advertisements etc) * remove duplicates * tokenise and (if tools are available) lemmatise and part-of-speech tag * load into our corpus query tool, the Sketch Engine The corpora we have developed are available for use in the Sketch Engine corpus query tool."
ivanova-etal-2008-evaluating,Evaluating a {G}erman Sketch Grammar: A Case Study on Noun Phrase Case,2008,11,7,4,0,47984,kremena ivanova,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Word sketches are part of the Sketch Engine corpus query system. They represent automatic, corpus-derived summaries of the wordsÂ grammatical and collocational behaviour. Besides the corpus itself, word sketches require a sketch grammar, a regular expression-based shallow grammar over the part-of-speech tags, to extract evidence for the properties of the targeted words from the corpus. The paper presents a sketch grammar for German, a language which is not strictly configurational and which shows a considerable amount of case syncretism, and evaluates its accuracy, which has not been done for other sketch grammars. The evaluation focuses on NP case as a crucial part of the German grammar. We present various versions of NP definitions, so demonstrating the influence of grammar detail on precision and recall."
baroni-etal-2008-cleaneval,{C}leaneval: a Competition for Cleaning Web Pages,2008,5,65,3,0.755408,12129,marco baroni,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Cleaneval is a shared task and competitive evaluation on the topic of cleaning arbitrary web pages, with the goal of preparing web data for use as a corpus for linguistic and language technology research and development. The first exercise took place in 2007. We describe how it was set up, results, and lessons learnt"
P07-2011,An efficient algorithm for building a distributional thesaurus (and other {S}ketch {E}ngine developments),2007,14,30,2,0,14164,pavel rychly,Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,0,"Gorman and Curran (2006) argue that thesaurus generation for billion-word corpora is problematic as the full computation takes many days. We present an algorithm with which the computation takes under two hours. We have created, and made publicly available, thesauruses based on large corpora for (at time of writing) seven major world languages. The development is implemented in the Sketch Engine (Kilgarriff et al., 2004).n n Another innovative development in the same tool is the presentation of the grammatical behaviour of a word against the background of how all other words of the same word class behave. Thus, the English noun constraint occurs 75% in the plural. Is this a salient lexical fact? To form a judgement, we need to know the distribution for all nouns. We use histograms to present the distribution in a way that is easy to grasp."
J07-1010,Last Words: Googleology is Bad Science,2007,7,3,1,1,37221,adam kilgarriff,Computational Linguistics,0,None
W06-1705,Annotated Web as corpus,2006,21,7,4,0,6341,paul rayson,Proceedings of the 2nd International Workshop on Web as Corpus,0,This paper presents a proposal to facilitate the use of the annotated web as corpus by alleviating the annotation bottleneck for corpus data drawn from the web. We describe a framework for large-scale distributed corpus annotation using peer-to-peer (P2P) technology to meet this need. We also propose to annotate a large reference corpus in order to evaluate this framework. This will allow us to investigate the affordances offered by distributed techniques to ensure replicability of linguistic research based on web-derived corpora.
W06-1421,Shared-Task Evaluations in {HLT}: Lessons for {NLG},2006,4,15,2,0,26421,anja belz,Proceedings of the Fourth International Natural Language Generation Conference,0,"While natural language generation (NLG) has a strong evaluation tradition, in particular in userbased and task-oriented evaluation, it has never evaluated different approaches and techniques by comparing their performance on the same tasks (shared-task evaluation, STE). NLG is characterised by a lack of consolidation of results, and by isolation from the rest of NLP where STE is now standard. It is, moreover, a shrinking field (state-of-the-art MT and summarisation no longer perform generation as a subtask) which lacks the kind of funding and participation that natural language understanding (NLU) has attracted."
E06-2001,Large Linguistically-Processed Web Corpora for Multiple Languages,2006,5,96,2,0.755408,12129,marco baroni,Demonstrations,0,"The Web contains vast amounts of linguistic data. One key issue for linguists and language technologists is how to access it. Commercial search engines give highly compromised access. An alternative is to crawl the Web ourselves, which also allows us to remove duplicates and near-duplicates, navigational material, and a range of other kinds of non-linguistic matter. We can also tokenize, lemmatise and part-of-speech tag the corpus, and load the data into a corpus query tool which supports sophisticated linguistic queries. We have now done this for German and Italian, with corpus sizes of over 1 billion words in each case. We provide Web access to the corpora in our query tool, the Sketch Engine."
2006.eamt-1.31,{W}eb{B}oot{C}a{T}. Instant Domain-Specific Corpora to Support Human Translators,2006,3,34,2,0.755408,12129,marco baroni,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,"We present a web service to aid translators by quicklyn producing corpora for specialist areas, in any of a range ofn languages, from the web. The underlying BootCaT tools haven already been extensively used: here, we present a version whichn is easy for non-technical people to use as all they need do isn fill in a web form. The corpus, once produced, can be eithern downloaded or loaded into the Sketch Engine, a corpus queryn tool, for further exploration. Reference corpora are used ton identify the key terms in the specialist domain."
I05-3007,{C}hinese {S}ketch {E}ngine and the Extraction of Grammatical Collocations,2005,9,21,2,0,1504,churen huang,Proceedings of the Fourth {SIGHAN} Workshop on {C}hinese Language Processing,0,"This paper introduces a new technology for collocation extraction in Chinese. Sketch Engine (Kilgarriff et al., 2004) has proven to be a very effective tool for automatic description of lexical information, including collocation extraction, based on large-scale corpus. The original work of Sketch Engine was based on BNC. We extend Sketch Engine to Chinese based on Gigaword corpus from LDC. We discuss the available functions of the prototype Chinese Sketch Engine (CSE) as well as the robustness of language-independent adaptation of Sketch Engine. We conclude by discussing how Chinese-specific linguistic information can be incorporated to improve the"
W04-0807,The Senseval-3 {E}nglish lexical sample task,2004,3,195,3,0,1124,rada mihalcea,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper presents the task definition, resources, participating systems, and comparative results for the English lexical sample task, which was organized as part of the SENSEVAL-3 evaluation exercise. The task drew the participation of 27 teams from around the world, with a total of 47 systems."
W03-2808,No-bureaucracy evaluation,2003,5,2,1,1,37221,adam kilgarriff,"Proceedings of the {EACL} 2003 Workshop on Evaluation Initiatives in Natural Language Processing: are evaluation methods, metrics and resources reusable?",0,"Senseval is a series of evaluation exercises for Word Sense Disambiguation. The core design is in accordance with the MUC and TREC model of quantitative, developer-oriented (rather than user-oriented) evaluation. The first was in 1998, with tasks for three languages and 25 participating research teams, the second in 2001, with tasks for twelve languages, thirty-five participating research teams and over 90 participating systems. The third is currently in planning. The scale of the resources developed is indicated in Table 1 (reproduced from (Edmonds and Kil-garriff, 2002))."
W03-2202,An Evaluation of a Lexicographers{'} Workbench: building lexicons for Machine Translation,2003,8,4,2,0,43094,rob koeling,"Proceedings of the 7th International {EAMT} workshop on {MT} and other language technology tools, Improving {MT} through other language technology tools, Resource and tools for building {MT} at {EACL} 2003",0,"NLP system developers and corpus lexicographers would both benefit from a tool for finding and organizing the distinctive patterns of use of words in texts. Such a tool would be an asset for both language research and lexicon development, particularly for lexicons for Machine Translation (MT). We have developed the WASPBENCH, a tool that (1) presents a word sketch, a summary of the corpus evidence for a word, to the lexicographer; (2) supports the lexicographer in analysing the word into its distinct meanings and (3) uses the lexicographer's analysis as the input to a state-of-the-art word sense disambiguation algorithm, the output of which is a word expert for the word which can then disambiguate new instances of the word. In this paper we describe a set of evaluation experiments, designed to establish whether waspbench can be used to save time and improve performance in the development of a lexicon for Machine Translation or other NLP application."
J03-3001,Introduction to the Special Issue on the Web as Corpus,2003,39,470,1,1,37221,adam kilgarriff,Computational Linguistics,0,"The Web, teeming as it is with language data, of all manner of varieties and languages, in vast quantity and freely available, is a fabulous linguists' playground. This special issue of Computational Linguistics explores ways in which this dream is being explored."
E03-2007,{WASPBENCH}: a lexicographer{'}s workbench incorporating state-of-the-art word sense disambiguation,2003,9,6,1,1,37221,adam kilgarriff,Demonstrations,0,"Human Language Technologies (HLT) need dictionaries, to tell them what words mean and how they behave. People making dictionaries (lexicographers) need HLT, to help them identify how words behave so they can make better dictionaries. Thus a potential for synergy exists across the range of lexical data - in the construction of headword lists, for spelling correction, phonetics, morphology and syntax, but nowhere more than for semantics, and in particular the vexed question of how a word's meaning should be analysed into distinct senses. HLT needs all the help it can get from dictionaries, because it is a very hard problem to identify which meaning of a word applies. Lexicographers need all the help they can get because the analysis of meaning is the second hardest part of their job (Kilgarriff, 1998), it occupies a large share of their working hours, and it is one where, currently, they have very little to go on beyond intuition and other dictionaries."
S01-1004,{E}nglish Lexical Sample Task Description,2001,2,79,1,1,37221,adam kilgarriff,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"The English lexical sample task (adjectives and nouns) for SENSEVAL 2 was set up according to the same principles as for SENSEVAL-1, as reported in (Kilgarriff and Rosenzweig, 2000). (Adjectives and nouns only, because the data preparation for the verbs lexical sample was undertaken alongside that for the English all-words task, and is reported in Palmer et al (this volume). All discussion below up to the Results section covers only adjectives and nouns.)"
S01-1037,{WASP}-{B}ench: a Lexicographic Tool Supporting Word Sense Disambiguation,2001,5,13,2,0,52622,david tugwell,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"We present WASP-Bench: a novel approach to Word Sense Disambiguation, also providing a semi-automatic environment for a lexicographer to compose dictionary entries based on corpus evidence. For WSD, involving lexicographers tackles the twin obstacles to high accuracy: paucity of training data and insufficiently explicit dictionaries. For lexicographers, the computational environment fills the need for a corpus workbench which supports WSD. Results under simulated lexicographic use on the English lexical-sample task show precision comparable with supervised systems, without using the laboriously-prepared training data."
2001.mtsummit-papers.34,{WASP}-Bench: an {MT} lexicographers{'} workstation supporting state-of-the-art lexical disambiguation,2001,8,26,1,1,37221,adam kilgarriff,Proceedings of Machine Translation Summit VIII,0,"Most MT lexicography is devoted to developing rules of the kind, {``}in context C, translate source-language word S as target-language word T{''}. Very many such rules are required, producing them is laborious, and MT companies standardly spend large sums on it. We present the WASP-Bench, a lexicographer's workstation for the rapid and semi-automatic development of such rule-sets. The WASP-Bench makes use of a large source-language corpus and state-of-the-art techniques for Word Sense Disambiguation. We show that the WSD accuracy is on a par with the best results published to date, with the advantage that the WASP-Bench, unlike other high- performance systems, does not require a sense-disambiguated training corpus as input. The WASP-Bench is designed to fit readily with MT companies' working practices, as it may be used for as many or as few source language words as present disambiguation problems for a given target."
kilgarriff-rosenzweig-2000-english,{E}nglish Senseval: Report and Results,2000,2,76,1,1,37221,adam kilgarriff,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"There are now many computer programs for automatically determining which sense a word is being used in. One would like to be able to say which were better, which worse, and also which words, or varieties of language, presented particular problems to which programs. In 1998 a first evaluation exercise, SENSEVAL, took place. The English component of the exercise is described, and results presented."
kilgarriff-yallop-2000-whats,What{'}s in a Thesaurus?,2000,21,49,1,1,37221,adam kilgarriff,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"We first describe four varieties of thesaurus: (1) Roget-style, produced to help people find synonyms when they are writing; (2) WordNet and EuroWordNet; (3) thesauruses produced (manually) to support information retrieval systems; and (4) thesauruses produced automatically from corpora. We then contrast thesauruses and dictionaries, and present a small experiment in which we look at polysemy in relation to thesaurus structure. It has sometimes been assumed that different dictionary senses for a word that are close in meaning will be near neighbours in the thesaurus. This hypothesis is explored, using as inputs the hierarchical structure of WordNet 1.5 and a mapping between WordNet senses and the senses of another dictionary. The experiment shows that pairs of xe2x80x98lexicographically closexe2x80x99 meanings are frequently found in different parts of the hierarchy. In the first part of the paper, we present different varieties of thesaurus. In the second part, we contrast thesaurus word senses with dictionary word senses and present a small experiment in which we explore whether xe2x80x98lexicographically closexe2x80x99 meanings are often close in the WordNet network."
erjavec-etal-2000-concede,The Concede Model for Lexical Databases,2000,6,18,4,0,15753,tomavz erjavec,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The value of language resources is greatly enhanced if they share a common markup with an explicit minimal semantics. Achieving this goal for lexical databases is difficult, as large-scale resources can realistically only be obtained by up-translation from pre-existing dictionaries, each with its own proprietary structure. This paper describes the approach we have taken in the Concede project, which aims to develop compatible lexical databases for six Central and Eastern European languages. Starting with sample entries from original presentation-oriented electronic representations of dictionaries, we transformed the data into an intermediate TEI-compatible representation to provide a common baseline for evaluating and comparing the dictionaries. We then developed a more restrictive encoding, formalised as an XML DTD with a clearly-defined semantic interpretation. We present this DTD and discuss a sample conversion from TEI, together with an application which hyperlinks a HTML representation of the dictionary to on-line concordancing over a corpus."
E99-1046,95{\\%} Replicability for Manual Word Sense Tagging,1999,4,18,1,1,37221,adam kilgarriff,Ninth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
W98-1506,Measures for Corpus Similarity and Homogeneity,1998,15,40,1,1,37221,adam kilgarriff,Proceedings of the Third Conference on Empirical Methods for Natural Language Processing,0,"How similar are two corpora? A measure of corpus similarity would be very useful for NLP for many purposes, such as estimating the work involved in porting a system from one domain to another. First, we discuss difculties in identifying what we mean by xe2x80x98corpus similarityxe2x80x99: human similarity judgements are not negrained enough, corpus similarity is inherently multidimensional, and similarity can only be interpreted in the light of corpus homogeneity. We then present an operational denition of corpus similarity which addresses or circumvents the problems, using purposebuilt sets of iknown-similarity corporai. These KSC sets can be used to evaluate the measures. We evaluate the measures described in the literature, including three variants of the information theoretic measure xe2x80x98perplexityxe2x80x99. A -based measure, using word frequencies, is shown to be the best of those tested."
W97-0122,Using Word Frequency Lists to Measure Corpus Homogeneity and Similarity between Corpora,1997,8,57,1,1,37221,adam kilgarriff,Fifth Workshop on Very Large Corpora,0,"How similar are two corpora? A measure of corpus similarity would be very useful for lexicography and language engineering. Word frequency lists are cheap and easy to generate so a measure based on them would be of use as a quick guide in many circumstances; for example, to judge how a newly available corpus related to existing resources, or how easy it might be to port an NLP system designed to work with one text type to work with another. We show that corpus similarity can only be interpreted in the light of corpus homogeneity. The paper presents a measure, based on the XX 2 statistic, for measuring both corpus similarity and corpus homogeneity. The measure is compared with a rank-based measure and shown to outperform it. Some results are presented. A method for evaluating the accuracy of the measure is introduced and some results of using the measure are presented."
E93-1026,Inheriting Verb Alternations,1993,20,12,1,1,37221,adam kilgarriff,Sixth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"The paper shows how the verbal lexicon can be formalised in a way that captures and exploits generalisations about the alternation behaviour of verb classes. An alternation is a pattern in which a number of words share the same relationship between a pair of senses. The alternations captured are ones where the different senses specify different relationships between syntactic complements and semantic arguments, as between bake in John is baking the cake and The cake is baking. The formal language used is DATR. The lexical entries it builds are as specified in HPSG. The complex alternation behaviour shared between families of verbs is elegantly represented in a way that makes generalisations explicit, avoids redundancy, and offers practical benefits to computational lexicographers."
