2020.lrec-1.407,The {E}uropean Language Technology Landscape in 2020: Language-Centric and Human-Centric {AI} for Cross-Cultural Communication in Multilingual {E}urope,2020,4,1,6,0.274201,60,georg rehm,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Multilingualism is a cultural cornerstone of Europe and firmly anchored in the European treaties including full language equality. However, language barriers impacting business, cross-lingual and cross-cultural communication are still omnipresent. Language Technologies (LTs) are a powerful means to break down these barriers. While the last decade has seen various initiatives that created a multitude of approaches and technologies tailored to Europe{'}s specific needs, there is still an immense level of fragmentation. At the same time, AI has become an increasingly important concept in the European Information and Communication Technology area. For a few years now, AI {--} including many opportunities, synergies but also misconceptions {--} has been overshadowing every other topic. We present an overview of the European LT landscape, describing funding programmes, activities, actions and challenges in the different countries with regard to LT, including the current state of play in industry and the LT market. We present a brief overview of the main LT-related activities on the EU level in the last ten years and develop strategic guidance with regard to four key dimensions."
2020.lrec-1.413,{E}uropean Language Grid: An Overview,2020,11,6,15,0.274201,60,georg rehm,Proceedings of the 12th Language Resources and Evaluation Conference,0,"With 24 official EU and many additional languages, multilingualism in Europe and an inclusive Digital Single Market can only be enabled through Language Technologies (LTs). European LT business is dominated by hundreds of SMEs and a few large players. Many are world-class, with technologies that outperform the global players. However, European LT business is also fragmented {--} by nation states, languages, verticals and sectors, significantly holding back its impact. The European Language Grid (ELG) project addresses this fragmentation by establishing the ELG as the primary platform for LT in Europe. The ELG is a scalable cloud platform, providing, in an easy-to-integrate way, access to hundreds of commercial and non-commercial LTs for all European languages, including running tools and services as well as data sets and resources. Once fully operational, it will enable the commercial and non-commercial European LT community to deposit and upload their technologies and data sets into the ELG, to deploy them through the grid, and to connect with other resources. The ELG will boost the Multilingual Digital Single Market towards a thriving European LT community, creating new jobs and opportunities. Furthermore, the ELG project organises two open calls for up to 20 pilot projects. It also sets up 32 national competence centres and the European LT Council for outreach and coordination purposes."
2020.lrec-1.497,{U}niversal {D}ependencies v2: An Evergrowing Multilingual Treebank Collection,2020,17,3,4,0,10682,joakim nivre,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. The annotation consists in a linguistically motivated word segmentation; a morphological layer comprising lemmas, universal part-of-speech tags, and standardized morphological features; and a syntactic layer focusing on syntactic relations between predicates, arguments and modifiers. In this paper, we describe version 2 of the universal guidelines (UD v2), discuss the major changes from UD v1 to UD v2, and give an overview of the currently available treebanks for 90 languages."
2020.lrec-1.641,{P}rague Dependency Treebank - Consolidated 1.0,2020,-1,-1,1,1,17503,jan hajivc,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present a richly annotated and genre-diversified language resource, the Prague Dependency Treebank-Consolidated 1.0 (PDT-C 1.0), the purpose of which is - as it always been the case for the family of the Prague Dependency Treebanks - to serve both as a training data for various types of NLP tasks as well as for linguistically-oriented research. PDT-C 1.0 contains four different datasets of Czech, uniformly annotated using the standard PDT scheme (albeit not everything is annotated manually, as we describe in detail here). The texts come from different sources: daily newspaper articles, Czech translation of the Wall Street Journal, transcribed dialogs and a small amount of user-generated, short, often non-standard language segments typed into a web translator. Altogether, the treebank contains around 180,000 sentences with their morphological, surface and deep syntactic annotation. The diversity of the texts and annotations should serve well the NLP applications as well as it is an invaluable resource for linguistic research, including comparative studies regarding texts of different genres. The corpus is publicly and freely available."
W19-7805,Parallel Dependency Treebank Annotated with Interlinked Verbal Synonym Classes and Roles,2019,0,0,4,0.9977,23434,zdevnka urevsova,"Proceedings of the 18th International Workshop on Treebanks and Linguistic Theories (TLT, SyntaxFest 2019)",0,None
L18-1136,Tools for Building an Interlinked Synonym Lexicon Network,2018,0,0,4,1,23434,zdevnka urevsova,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1206,Bridging the {LAPPS} {G}rid and {CLARIN},2018,0,0,4,0,17752,erhard hinrichs,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1227,Creating a Verb Synonym Lexicon Based on a Parallel Corpus,2018,0,0,4,1,23434,zdevnka urevsova,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1247,Diacritics Restoration Using Neural Networks,2018,16,2,4,0,226,jakub naplava,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"Diacritics restoration problem is defined as correct insertion of diacritic marks into a sentence without changing the context of a particular sentence. Changing a letter in a text can cause the meaning of the word to change, and therefore the meaning of the whole sentence. This kind of problem is common among languages that use Latin alphabet such as the Slovak language. Our goal is to develop an artificial neural network that can restore diacritic errors made by a human or a computer. For this purpose, we chose state of the art architecture of recurrent neural network. Our results prove that neural network is able to restore diacritics with 97 % accuracy on given Slovak corpus. The accuracy test on a text from a different genre, however, has shown a lower accuracy of 76%."
L18-1551,{S}ume{C}zech: Large {C}zech News-Based Summarization Dataset,2018,0,1,6,0.964912,228,milan straka,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
K18-2001,{C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to {U}niversal {D}ependencies,2018,0,1,2,0,5828,daniel zeman,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"Every year, the Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2018, one of two tasks was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on test input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. This shared task constitutes a 2nd edition{---}the first one took place in 2017 (Zeman et al., 2017); the main metric from 2017 has been kept, allowing for easy comparison, also in 2018, and two new main metrics have been used. New datasets added to the Universal Dependencies collection between mid-2017 and the spring of 2018 have contributed to increased difficulty of the task this year. In this overview paper, we define the task and the updated evaluation methodology, describe data preparation, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems."
D18-1532,{L}emma{T}ag: Jointly Tagging and Lemmatizing for Morphologically Rich Languages with {BRNN}s,2018,25,3,4,0,30694,daniel kondratyuk,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We present LemmaTag, a featureless neural network architecture that jointly generates part-of-speech tags and lemmas for sentences by using bidirectional RNNs with character-level and word-level embeddings. We demonstrate that both tasks benefit from sharing the encoding part of the network, predicting tag subcategories, and using the tagger output as an input to the lemmatizer. We evaluate our model across several languages with complex morphology, which surpasses state-of-the-art accuracy in both part-of-speech tagging and lemmatization in Czech, German, and Arabic."
C18-1208,Synonymy in Bilingual Context: The {C}z{E}ng{C}lass Lexicon,2018,0,1,4,1,23434,zdevnka urevsova,Proceedings of the 27th International Conference on Computational Linguistics,0,"This paper describes CzEngClass, a bilingual lexical resource being built to investigate verbal synonymy in bilingual context and to relate semantic roles common to one synonym class to verb arguments (verb valency). In addition, the resource is linked to existing resources with the same of a similar aim: English and Czech WordNet, FrameNet, PropBank, VerbNet (SemLink), and valency lexicons for Czech and English (PDT-Vallex, Vallex, and EngVallex). There are several goals of this work and resource: (a) to provide gold standard data for automatic experiments in the future (such as automatic discovery of synonym classes, word sense disambiguation, assignment of classes to occurrences of verbs in text, coreferential linking of verb and event arguments in text, etc.), (b) to build a core (bilingual) lexicon linked to existing resources, for comparative studies and possibly for training automatic tools, and (c) to enrich the annotation of a parallel treebank, the Prague Czech English Dependency Treebank, which so far contained valency annotation but has not linked synonymous senses of verbs together. The method used for extracting the synonym classes is a semi-automatic process with a substantial amount of manual work during filtering, role assignment to classes and individual Class members{'} arguments, and linking to the external lexical resources. We present the first version with 200 classes (about 1800 verbs) and evaluate interannotator agreement using several metrics."
K17-3001,{C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to {U}niversal {D}ependencies,2017,28,32,4,0,5828,daniel zeman,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems."
W16-3810,Enriching a Valency Lexicon by Deverbative Nouns,2016,-1,-1,2,1,23435,eva fuvcikova,Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces ({G}ram{L}ex),0,"We present an attempt to automatically identify Czech deverbative nouns using several methods that use large corpora as well as existing lexical resources. The motivation for the task is to extend a verbal valency (i.e., predicate-argument) lexicon by adding nouns that share the valency properties with the base verb, assuming their properties can be derived (even if not trivially) from the underlying verb by deterministic grammatical rules. At the same time, even in inflective languages, not all deverbatives are simply created from their underlying base verb by regular lexical derivation processes. We have thus developed hybrid techniques that use both large parallel corpora and several standard lexical resources. Thanks to the use of parallel corpora, the resulting sets contain also synonyms, which the lexical derivation rules cannot get. For evaluation, we have manually created a small, 100-verb gold data since no such dataset was initially available for Czech."
W16-1812,Inherently Pronominal Verbs in {C}zech: Description and Conversion Based on Treebank Annotation,2016,0,0,3,1,23434,zdevnka urevsova,Proceedings of the 12th Workshop on Multiword Expressions,0,None
L16-1251,Fostering the Next Generation of {E}uropean Language Technology: Recent Developments â Emerging Initiatives â Challenges and Opportunities,2016,5,1,2,0.454545,60,georg rehm,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"META-NET is a European network of excellence, founded in 2010, that consists of 60 research centres in 34 European countries. One of the key visions and goals of META-NET is a truly multilingual Europe, which is substantially supported and realised through language technologies. In this article we provide an overview of recent developments around the multilingual Europe topic, we also describe recent and upcoming events as well as recent and upcoming strategy papers. Furthermore, we provide overviews of two new emerging initiatives, the CEF.AT and ELRC activity on the one hand and the Cracking the Language Barrier federation on the other. The paper closes with several suggested next steps in order to address the current challenges and to open up new opportunities."
L16-1262,{U}niversal {D}ependencies v1: A Multilingual Treebank Collection,2016,0,257,5,0,10682,joakim nivre,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages."
L16-1483,{QTL}eap {WSD}/{NED} Corpora: Semantic Annotation of Parallel Corpora in Six Languages,2016,9,5,4,0,16264,arantxa otegi,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This work presents parallel corpora automatically annotated with several NLP tools, including lemma and part-of-speech tagging, named-entity recognition and classification, named-entity disambiguation, word-sense disambiguation, and coreference. The corpora comprise both the well-known Europarl corpus and a domain-specific question-answer troubleshooting corpus on the IT domain. English is common in all parallel corpora, with translations in five languages, namely, Basque, Bulgarian, Czech, Portuguese and Spanish. We describe the annotated corpora and the tools used for annotation, as well as annotation statistics for each language. These new resources are freely available and will help research on semantic processing for machine translation and cross-lingual transfer."
L16-1630,Towards Comparability of Linguistic Graph {B}anks for Semantic Parsing,2016,20,7,7,0,2623,stephan oepen,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We announce a new language resource for research on semantic parsing, a large, carefully curated collection of semantic dependency graphs representing multiple linguistic traditions. This resource is called SDP{\textasciitilde}2016 and provides an update and extension to previous versions used as Semantic Dependency Parsing target representations in the 2014 and 2015 Semantic Evaluation Exercises. For a common core of English text, this third edition comprises semantic dependency graphs from four distinct frameworks, packaged in a unified abstract format and aligned at the sentence and token levels. SDP 2016 is the first general release of this resource and available for licensing from the Linguistic Data Consortium in May 2016. The data is accompanied by an open-source SDP utility toolkit and system results from previous contrastive parsing evaluations against these target representations."
L16-1680,"{UDP}ipe: Trainable Pipeline for Processing {C}o{NLL}-{U} Files Performing Tokenization, Morphological Analysis, {POS} Tagging and Parsing",2016,0,47,2,1,228,milan straka,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Automatic natural language processing of large texts often presents recurring challenges in multiple languages: even for most advanced tasks, the texts are first processed by basic processing steps {--} from tokenization to parsing. We present an extremely simple-to-use tool consisting of one binary and one model (per language), which performs these tasks for multiple languages without the need for any other external data. UDPipe, a pipeline processing CoNLL-U-formatted files, performs tokenization, morphological analysis, part-of-speech tagging, lemmatization and dependency parsing for nearly all treebanks of Universal Dependencies 1.2 (namely, the whole pipeline is currently available for 32 out of 37 treebanks). In addition, the pipeline is easily trainable with training data in CoNLL-U format (and in some cases also with additional raw corpora) and requires minimal linguistic knowledge on the users{'} part. The training code is also released."
C16-2009,Joint search in a bilingual valency lexicon and an annotated corpus,2016,7,0,2,1,23435,eva fuvcikova,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"In this paper and the associated system demo, we present an advanced search system that allows to perform a joint search over a (bilingual) valency lexicon and a correspondingly annotated linked parallel corpus. This search tool has been developed on the basis of the Prague Czech-English Dependency Treebank, but its ideas are applicable in principle to any bilingual parallel corpus that is annotated for dependencies and valency (i.e., predicate-argument structure), and where verbs are linked to appropriate entries in an associated valency lexicon. Our online search tool consolidates more search interfaces into one, providing expanded structured search capability and a more efficient advanced way to search, allowing users to search for verb pairs, verbal argument pairs, their surface realization as recorded in the lexicon, or for their surface form actually appearing in the linked parallel corpus. The search system is currently under development, and is replacing our current search tool available at \url{http://lindat.mff.cuni.cz/services/CzEngVallex}, which could search the lexicon but the queries cannot take advantage of the underlying corpus nor use the additional surface form information from the lexicon(s). The system is available as open source."
2016.eamt-2.1,{T}ecto{MT} {--} a deep linguistic core of the combined Cimera {MT} system,2016,-1,-1,5,0.488867,227,martin popel,Proceedings of the 19th Annual Conference of the European Association for Machine Translation: Projects/Products,0,None
W15-2111,Using Parallel Texts and Lexicons for Verbal Word Sense Disambiguation,2015,31,4,3,0.795455,2976,ondvrej duvsek,Proceedings of the Third International Conference on Dependency Linguistics (Depling 2015),0,"We present a system for verbal Word Sense Disambiguation (WSD) that is able to exploit additional information from parallel texts and lexicons. It is an extension of our previous WSD method (Dusek et al., 2014), which gave promising results but used only monolingual features. In the follow-up work described here, we have explored two additional ideas: using English-Czech bilingual resources (as features only xe2x80x93 the task itself remains a monolingual WSD task), and using a xe2x80x9chybridxe2x80x9d approach, adding features extracted both from a parallel corpus and from manually aligned bilingual valency lexicon entries, which contain subcategorization information. Albeit not all types of features proved useful, both ideas and additions have led to significant improvements for both languages explored."
W15-1613,Bilingual {E}nglish-{C}zech Valency Lexicon Linked to a Parallel Corpus,2015,14,5,4,1,23434,zdevnka urevsova,Proceedings of The 9th Linguistic Annotation Workshop,0,"This paper presents a resource and the associated annotation process used in a project of interlinking Czech and English verbal translational equivalents based on a parallel, richly annotated dependency treebank containing also valency and semantic roles, namely the Prague Czech-English Dependency Treebank. One of the main aims of this project is to create a high-quality and relatively large empirical base which could be used both for linguistic comparative research as well as for natural language processing applications, such as machine translation or cross-language sense disambiguation. This paper describes the resulting lexicon, CzEngVallex, and the process of building it, as well some interesting observations and statistics already obtained."
S15-2153,{S}em{E}val 2015 Task 18: Broad-Coverage Semantic Dependency Parsing,2015,-1,-1,7,0,2623,stephan oepen,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,None
W14-5808,Comparing {C}zech and {E}nglish {AMR}s,2014,17,1,1,1,17503,jan hajivc,Proceedings of Workshop on Lexical and Grammatical Resources for Language Processing,0,"This paper describes in detail the differences between Czech and English annotation using the Abstract Meaning Representation scheme, which stresses the use of ontologies (and semantically-oriented verbal lexicons) and relations based on meaning or ontological content rather than semantics or syntax. The basic xe2x80x9csloganxe2x80x9d of the AMR specification clearly states that AMR is not an interlingua, yet it is expected that many relations as well as structures constructed from these relations will be similar or even identical across languages. In our study, we have investigated 100 sentences in English and their translations into Czech, annotated manually by AMRs, with the goal to describe the differences and if possible, to classify them into two main categories: those which are merely convention differences and thus can be unified by changing such conventions in the AMR annotation guidelines, and those which are so deeply rooted in the language structure that the level of abstraction which is inherent in the current AMR scheme does not allow for such unification."
W14-3326,Machine Translation of Medical Texts in the Khresmoi Project,2014,37,10,2,0.795455,2976,ondvrej duvsek,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"This paper presents the participation of the Charles University team in the WMT 2014 Medical Translation Task. Our systems are developed within the Khresmoi project, a large integrated project aiming to deliver a multi-lingual multi-modal search and access system for biomedical information and documents. Being involved in the organization of the Medical Translation Task, our primary goal is to set up a baseline for both its subtasks (summary translation and query translation) and for all translation directions. Our systems are based on the phrasebased Moses system and standard methods for domain adaptation. The constrained/unconstrained systems differ in the training data only."
W14-2902,Verbal Valency Frame Detection and Selection in {C}zech and {E}nglish,2014,26,4,2,0.795455,2976,ondvrej duvsek,"Proceedings of the Second Workshop on {EVENTS}: Definition, Detection, Coreference, and Representation",0,"We present a supervised learning method for verbal valency frame detection and selection, i.e., a specific kind of word sense disambiguation for verbs based on subcategorization information, which amounts to detecting mentions of events in text. We use the rich dependency annotation present in the Prague Dependency Treebanks for Czech and English, taking advantage of several analysis tools (taggers, parsers) developed on these datasets previously. The frame selection is based on manually created lexicons accompanying these treebanks, namely on PDT-Vallex for Czech and EngVallex for English. The results show that verbal predicate detection is easier for Czech, but in the subsequent frame selection task, better results have been achieved for English."
S14-2008,{S}em{E}val 2014 Task 8: Broad-Coverage Semantic Dependency Parsing,2014,30,71,6,0,2623,stephan oepen,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"Task 18 at SemEval 2015 defines Broad-Coverage Semantic Dependency Parsing (SDP) as the problem of recovering sentence-internal predicatexe2x80x93argument relationships for all content words, i.e. the sema ..."
P14-5003,"Open-Source Tools for Morphology, Lemmatization, {POS} Tagging and Named Entity Recognition",2014,20,57,3,0,229,jana strakova,Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We present two recently released opensource taggers: NameTag is a free software for named entity recognition (NER) which achieves state-of-the-art performance on Czech; MorphoDiTa (Morphological Dictionary and Tagger) performs morphological analysis (with lemmatization), morphological generation, tagging and tokenization with state-of-the-art results for Czech and a throughput around 10-200K words per second. The taggers can be trained for any language for which annotated data exist, but they are specifically designed to be efficient for inflective languages, Both tools are free software under LGPL license and are distributed along with trained linguistic models which are free for non-commercial use under the CC BY-NC-SA license. The releases include standalone tools, C libraries with Java, Python and Perl bindings and web services."
xue-etal-2014-interlingua,"Not an Interlingua, But Close: Comparison of {E}nglish {AMR}s to {C}hinese and {C}zech",2014,18,10,3,0,10294,nianwen xue,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Abstract Meaning Representations (AMRs) are rooted, directional and labeled graphs that abstract away from morpho-syntactic idiosyncrasies such as word category (verbs and nouns), word order, and function words (determiners, some prepositions). Because these syntactic idiosyncrasies account for many of the cross-lingual differences, it would be interesting to see if this representation can serve, e.g., as a useful, minimally divergent transfer layer in machine translation. To answer this question, we have translated 100 English sentences that have existing AMRs into Chinese and Czech to create AMRs for them. A cross-linguistic comparison of English to Chinese and Czech AMRs reveals both cases where the AMRs for the language pairs align well structurally and cases of linguistic divergence. We found that the level of compatibility of AMR between English and Chinese is higher than between English and Czech. We believe this kind of comparison is beneficial to further refining the annotation standards for each of the three languages and will lead to more compatible annotation guidelines between the languages."
rehm-etal-2014-strategic,"The Strategic Impact of {META}-{NET} on the Regional, National and International Level",2014,47,2,15,0.454545,60,georg rehm,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This article provides an overview of the dissemination work carried out in META-NET from 2010 until early 2014; we describe its impact on the regional, national and international level, mainly with regard to politics and the situation of funding for LT topics. This paper documents the initiativeÂs work throughout Europe in order to boost progress and innovation in our field."
de-smedt-etal-2014-clara,{CLARA}: A New Generation of Researchers in Common Language Resources and Their Applications,2014,68,0,10,0,17515,koenraad smedt,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"CLARA (Common Language Resources and Their Applications) is a Marie Curie Initial Training Network which ran from 2009 until 2014 with the aim of providing researcher training in crucial areas related to language resources and infrastructure. The scope of the project was broad and included infrastructure design, lexical semantic modeling, domain modeling, multimedia and multimodal communication, applications, and parsing technologies and grammar models. An international consortium of 9 partners and 12 associate partners employed researchers in 19 new positions and organized a training program consisting of 10 thematic courses and summer/winter schools. The project has resulted in new theoretical insights as well as new resources and tools. Most importantly, the project has trained a new generation of researchers who can perform advanced research and development in language resources and technologies."
uresova-etal-2014-multilingual,Multilingual Test Sets for Machine Translation of Search Queries for Cross-Lingual Information Retrieval in the Medical Domain,2014,11,4,2,0.9588,23434,zdevnka urevsova,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents development and test sets for machine translation of search queries in cross-lingual information retrieval in the medical domain. The data consists of the total of 1,508 real user queries in English translated to Czech, German, and French. We describe the translation and review process involving medical professionals and present a baseline experiment where our data sets are used for tuning and evaluation of a machine translation system."
Q13-1034,Joint Morphological and Syntactic Analysis for Richly Inflected Languages,2013,50,49,6,0,16528,bernd bohnet,Transactions of the Association for Computational Linguistics,0,"Joint morphological and syntactic analysis has been proposed as a way of improving parsing accuracy for richly inflected languages. Starting from a transition-based model for joint part-of-speech tagging and dependency parsing, we explore different ways of integrating morphological features into the model. We also investigate the use of rule-based morphological analyzers to provide hard or soft lexical constraints and the use of word clusters to tackle the sparsity of lexical features. Evaluation on five morphologically rich languages (Czech, Finnish, German, Hungarian, and Russian) shows consistent improvements in both morphological and syntactic accuracy for joint prediction over a pipeline model, with further improvements thanks to lexical constraints and word clusters. The final results improve the state of the art in dependency parsing for all languages."
zeman-etal-2012-hamledt,{H}amle{DT}: To Parse or Not to Parse?,2012,24,34,7,0,5828,daniel zeman,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We propose HamleDT â HArmonized Multi-LanguagE Dependency Treebank. HamleDT is a compilation of existing dependency treebanks (or dependency conversions of other treebanks), transformed so that they all conform to the same annotation style. While the license terms prevent us from directly redistributing the corpora, most of them are easily acquirable for research purposes. What we provide instead is the software that normalizes tree structures in the data obtained by the user from their original providers."
hajic-etal-2012-announcing,Announcing {P}rague {C}zech-{E}nglish {D}ependency {T}reebank 2.0,2012,5,27,1,1,17503,jan hajivc,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We introduce a substantial update of the Prague Czech-English Dependency Treebank, a parallel corpus manually annotated at the deep syntactic layer of linguistic representation. The English part consists of the Wall Street Journal (WSJ) section of the Penn Treebank. The Czech part was translated from the English source sentence by sentence. This paper gives a high level overview of the underlying linguistic theory (the so-called tectogrammatical annotation) with some details of the most important features like valency annotation, ellipsis reconstruction or coreference."
2010.iwslt-keynotes.3,Resources for adding semantics to machine translation,2010,0,0,1,1,17503,jan hajivc,Proceedings of the 7th International Workshop on Spoken Language Translation: Plenaries,0,None
W09-1201,The {C}o{NLL}-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages,2009,26,269,1,1,17503,jan hajivc,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"For the 11th straight year, the Conference on Computational Natural Language Learning has been accompanied by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2009, the shared task was dedicated to the joint parsing of syntactic and semantic dependencies in multiple languages. This shared task combines the shared tasks of the previous five years under a unique dependency-based formalism similar to the 2008 task. In this paper, we define the shared task, describe how the data sets were created and show their quantitative properties, report the results and summarize the approaches of the participating systems."
E09-1087,Semi-Supervised Training for the Averaged Perceptron {POS} Tagger,2009,14,60,2,1,46309,drahomira spoustova,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"This paper describes POS tagging experiments with semi-supervised training as an extension to the (supervised) averaged perceptron algorithm, first introduced for this task by (Collins, 2002). Experiments with an iterative training on standard-sized supervised (manually annotated) dataset (106 tokens) combined with a relatively modest (in the order of 108 tokens) unsupervised (plain) data in a bagging-like fashion showed significant improvement of the POS classification task on typologically different languages, yielding better than state-of-the-art results for English and Czech (4.12 % and 4.86 % relative error reduction, respectively; absolute accuracies being 97.44 % and 95.89 %)."
W08-0319,Phrase-Based and Deep Syntactic {E}nglish-to-{C}zech Statistical Machine Translation,2008,19,25,2,0.0767709,292,ondvrej bojar,Proceedings of the Third Workshop on Statistical Machine Translation,0,This paper describes our two contributions to WMT08 shared task: factored phrase-based model using Moses and a probabilistic tree-transfer model at a deep syntactic layer.
spoustova-etal-2008-validating,Validating the Quality of Full Morphological Annotation,2008,4,1,3,1,46309,drahomira spoustova,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,In our paper we present a methodology used for low-cost validation of quality of Part-of-Speech annotation of the Prague Dependency Treebank based on multiple re-annotation of data samples carefully selected with the help of several different Part-of-Speech taggers.
W07-1709,The Best of Two Worlds: Cooperation of Statistical and Rule-Based Taggers for {C}zech,2007,20,83,2,1,46309,drahomira spoustova,Proceedings of the Workshop on {B}alto-{S}lavonic Natural Language Processing,0,"Several hybrid disambiguation methods are described which combine the strength of hand-written disambiguation rules and statistical taggers. Three different statistical (HMM, Maximum-Entropy and Averaged Perceptron) taggers are used in a tagging experiment using Prague Dependency Tree-bank. The results of the hybrid systems are better than any other method tried for Czech tagging so far."
P06-1119,Leveraging Reusability: Cost-Effective Lexical Acquisition for Large-Scale Ontology Translation,2006,13,5,4,0,49992,craig murray,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Thesauri and ontologies provide important value in facilitating access to digital archives by representing underlying principles of organization. Translation of such resources into multiple languages is an important component for providing multilingual access. However, the specificity of vocabulary terms in most ontologies precludes fully-automated machine translation using general-domain lexical resources. In this paper, we present an efficient process for leveraging human translations when constructing domain-specific lexical resources. We evaluate the effectiveness of this process by producing a probabilistic phrase dictionary and translating a thesaurus of 56,000 concepts used to catalogue a large archive of oral histories. Our experiments demonstrate a cost-effective technique for accurate machine translation of large ontologies."
novak-hajic-2006-perspectives,Perspectives of Turning {P}rague Dependency Treebank into a Knowledge Base,2006,7,1,2,0,46826,vaclav novak,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Recently, the Prague Dependency Treebank 2.0 (PDT 2.0) has emerged as the largest text corpora annotated on the level of tectogrammatical representation (Âlinguistic meaningÂ) described in Sgall et al. (2004) and containing about 0.8 milion words (see Hajic (2004)). We hope that this level of annotation is so close to the meaning of the utterances contained in the corpora that it should enable us to automatically transform texts contained in the corpora to the form of knowledge base, usable for information extraction, question answering, summarization, etc. We can use Multilayered Extended Semantic Networks (MultiNet) described in Helbig (2006) as the target formalism. In this paper we discuss the suitability of such approach and some of the main issues that will arise in the process. In section 1, we introduce formalisms underlying PDT 2.0 and MultiNet, in section 2. We describe the role MultiNet can play in the system of Functional Generative Description (FGD), section 3 discusses issues of automatic conversion to MultiNet and section 4 gives some conclusions."
2006.eamt-1.18,Leveraging Recurrent Phrase Structure in Large-scale Ontology Translation,2006,-1,-1,4,0,49992,craig murray,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,None
H05-1066,Non-Projective Dependency Parsing using Spanning Tree Algorithms,2005,21,705,4,0,10634,ryan mcdonald,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs. Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n3) time. More surprisingly, the representation is extended naturally to non-projective parsing using Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967) MST algorithm, yielding an O(n2) parsing algorithm. We evaluate these methods on the Prague Dependency Treebank using online large-margin learning techniques (Crammer et al., 2003; McDonald et al., 2005) and show that MST parsing increases efficiency and accuracy for languages with non-projective dependencies."
2005.eamt-1.11,{P}rague {C}zech-{E}nglish dependency treebank: resource for structure-based {MT},2005,-1,-1,3,1,40099,martin vcmejrek,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,None
psutka-etal-2004-issues,Issues in Annotation of the {C}zech Spontaneous Speech Corpus in the {MALACH} project,2004,4,12,3,0,29872,josef psutka,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,The paper present the issues encountered in processing spontaneous Czech speech in the MALACH project. Specific problems connected with a frequent occurrence of colloquial words in spontaneous Czech are analyzed; a partial solution is proposed and experimentally
cmejrek-etal-2004-prague,{P}rague {C}zech-{E}nglish {D}ependency {T}reebank. Syntactically Annotated Resources for Machine Translation,2004,9,32,4,1,40099,martin vcmejrek,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper introduces the Prague Czech-English Dependency Treebank (PCEDT), a new Czech-English parallel resource suitable for experiments in structural machine translation. We describe the process of building the core parts of the resources xe2x80x93 a bilingual syntactically annotated corpus and translation dictionaries. A part of the Penn Treebank has been translated into Czech, the dependency annotation of the Czech translation has been done automatically from plain text. The annotation of Penn Treebank has been tranformed into dependency annotation scheme. A subset of corresponding Czech and English sentences has been annotated by humans. First experiments in Czech-English machine translation using these data have already been carried out. The resources being created at Charles University in Prague are scheduled for release as Linguistic Data Consortium data collection in 2004."
2003.mtsummit-papers.21,A simple multilingual machine translation system,2003,-1,-1,1,1,17503,jan hajivc,Proceedings of Machine Translation Summit IX: Papers,0,"The multilingual machine translation system described in the first part of this paper demonstrates that the translation memory (TM) can be used in a creative way for making the translation process more automatic (in a way which in fact does not depend on the languages used). The MT system is based upon exploitation of syntactic similarities between more or less related natural languages. It currently covers the translation from Czech to Slovak, Polish and Lithuanian. The second part of the paper also shows that one of the most popular TM based commercial systems, TRADOS, can be used not only for the translation itself, but also for a relatively fast and natural method of evaluation of the translation quality of MT systems."
W02-2231,Tectogrammatical representation: towards a minimal transfer in machine translation,2002,8,4,1,1,17503,jan hajivc,Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+6),0,"The Prague Dependency Treebank (PDT, as described, e.g., in (Hajic, 1998) or more recently in (Hajic, Pajas and Vidova Hladka, 2001)) is a project of linguistic annotation of approx. 1.5 million word corpus of naturally occurring written Czech on three levels (xe2x80x9clayersxe2x80x9d) of complexity and depth: morphological, analytical, and tectogrammatical. The aim of the project is to have a reference corpus annotated by using the accumulated findings of the Prague School as much as possible, while simultaneously showing (by experiments, mainly of statistical nature) that such a framework is not only theoretically interesting but possibly also of practical use. In this contribution we want to show that the deepest (tectogrammatical) layer of representation of sentence structure we use, which represents xe2x80x9clinguistic meaningxe2x80x9d as described in (Sgall, Hajicova and Panevova, 1986) and which also records certain aspects of discourse structure, has certain properties that can be effectively used in machine translation1 for languages of quite different nature at the transfer stage. We believe that such representation not only minimizes the xe2x80x9cdistancexe2x80x9d between languages at this layer, but also delegates individual language phenomena where they belong to whether it is the analysis, transfer or generation processes, regardless of methods used for performing these steps."
1999.eamt-1.12,Machine translation of very closely related languages,1999,-1,-1,1,1,17503,jan hajivc,EAMT Workshop: EU and the new languages,0,None
P98-1080,Tagging Inflective Languages: Prediction of Morphological Categories for a Rich Structured Tagset,1998,5,118,1,1,17503,jan hajivc,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"p u r p o s e s , i t h a s b e e n t a g g e d b y o u r t a g g e r ; e r r o r s a r e p r i n t e d u n d e r l i n e d a n d c o r r e c t i o n s a r e s h o w n . } Hlavnfm/AAIS7 .... IA-probl4mem/NNIS7 ..... A--"
1995.mtsummit-1.23,"Machine Translation in the {C}zech {R}epublic: history, methods, systems",1995,-1,-1,1,1,17503,jan hajivc,Proceedings of Machine Translation Summit V,0,None
