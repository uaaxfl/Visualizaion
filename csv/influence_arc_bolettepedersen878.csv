2016.gwc-1.30,A00-2006,0,0.217945,"Missing"
2016.gwc-1.30,alvez-etal-2008-complete,0,0.0258999,"bers of the current inventory, which we postulate by identifying semantically coherent groups of synsets. We cover the expansion of the already-established supernsense inventory for nouns and verbs, the addition of coarse supersenses for adjectives in absence of a canonical supersense inventory, and supersenses for verbal satellites. We evaluate the viability of the new senses examining the annotation agreement, frequency and co-ocurrence patterns. 1 Introduction Coarse word-sense disambiguation is a well established discipline (Segond et al., 1997; Peters et al., 1998; Lapata and Brew, 2004; Alvez et al., 2008; Izquierdo et al., 2009) that has acquired more momentum in the latter years under the name of supersense tagging (SST). SST uses a coarse sense inventory to label spans of variable word length (Ciaramita and Johnson, 2003; Ciaramita and Altun, 2006; Johannsen et al., 2014). This coarse sense inventory is obtained from the list of WordNet first beginners, i.e. the names of the lexicographer files that hold the synsets. However, lexicographer files were devised for practical reasons, namely as an organization method for the development of WordNet (Miller, 1990; Gross and Miller, 1990; Fellbaum"
2016.gwc-1.30,J12-3005,0,0.0564994,"Missing"
2016.gwc-1.30,W06-1670,0,0.0468962,"tives in absence of a canonical supersense inventory, and supersenses for verbal satellites. We evaluate the viability of the new senses examining the annotation agreement, frequency and co-ocurrence patterns. 1 Introduction Coarse word-sense disambiguation is a well established discipline (Segond et al., 1997; Peters et al., 1998; Lapata and Brew, 2004; Alvez et al., 2008; Izquierdo et al., 2009) that has acquired more momentum in the latter years under the name of supersense tagging (SST). SST uses a coarse sense inventory to label spans of variable word length (Ciaramita and Johnson, 2003; Ciaramita and Altun, 2006; Johannsen et al., 2014). This coarse sense inventory is obtained from the list of WordNet first beginners, i.e. the names of the lexicographer files that hold the synsets. However, lexicographer files were devised for practical reasons, namely as an organization method for the development of WordNet (Miller, 1990; Gross and Miller, 1990; Fellbaum, 1990), and not as final target categories to annotate with or disambiguate from. Nevertheless, the organization of lexicographer files is semantically motivated, and supersenses have proven useful for natural language processing such as metaphor de"
2016.gwc-1.30,W03-1022,0,0.206469,"coarse supersenses for adjectives in absence of a canonical supersense inventory, and supersenses for verbal satellites. We evaluate the viability of the new senses examining the annotation agreement, frequency and co-ocurrence patterns. 1 Introduction Coarse word-sense disambiguation is a well established discipline (Segond et al., 1997; Peters et al., 1998; Lapata and Brew, 2004; Alvez et al., 2008; Izquierdo et al., 2009) that has acquired more momentum in the latter years under the name of supersense tagging (SST). SST uses a coarse sense inventory to label spans of variable word length (Ciaramita and Johnson, 2003; Ciaramita and Altun, 2006; Johannsen et al., 2014). This coarse sense inventory is obtained from the list of WordNet first beginners, i.e. the names of the lexicographer files that hold the synsets. However, lexicographer files were devised for practical reasons, namely as an organization method for the development of WordNet (Miller, 1990; Gross and Miller, 1990; Fellbaum, 1990), and not as final target categories to annotate with or disambiguate from. Nevertheless, the organization of lexicographer files is semantically motivated, and supersenses have proven useful for natural language pro"
2016.gwc-1.30,W97-0802,0,0.0931647,"Missing"
2016.gwc-1.30,W14-0107,0,0.020603,"iented towards conveying sense denotation that connotation. Hence, we suggest a new supersense A . FUNCTION to give account for function-related senses, what in the terminology of Pustejovsky (1991) would be the telic role. We observe that the ALLGEMEIN (‘general’) category of GermaNet and Tsvetkov et al’s MISCEL LANEOUS hold similar senses. 5.4 Satellites When annotating nouns in Section 3, we annotate continuous NER-like spans. But verb-headed multiwords pose a challenge because they are not necessarily continuous, and pose attested challenges for their annotation and automatic recognition (Hoppermann and Hinrichs, 2014; Baldwin, 2005b; Baldwin, 2005a). We use three satellite tags; S . COLLOCATION, S . PARTICLE and S . REFLPRON (for reflexive pronouns). While the particle distinction is more relevant for satellite-framed languages (Talmy, 1985) like Germanic languages, light-verb constructions are pervasive in many languages, also characteristically verb-framed languages like Spanish or French, where we find verb-headed multiwords like llevar a cabo (lit. ‘take to ending’, ‘carry out’) or avoir l’air (lit. ‘to have the air’, ‘seem’), respectively. A similar approach has been used by Schneider and Smith (2015"
2016.gwc-1.30,E09-1045,0,0.0514391,"Missing"
2016.gwc-1.30,S14-1001,1,0.83293,"Missing"
2016.gwc-1.30,kipper-etal-2006-extending,0,0.0477719,"h. This metric aims at justifying having document as an NER label, where span identification is as relevant as proper labeling. We believe the frequency of document-name named entities makes a good case for considering the N . DOCUMENT class as an addition to the SSI and to NER. However, we do not find enough support to recommend a N . LANGUAGE supersense and prefer using the original N . COMMUNICATION instead. 5.2 Verbs Verbs are central to the theory of lexical semantics, yet their semantic characterization has been closer to the syntax-semantics interface (Levin, 1993; Kipper et al., 2000; Kipper et al., 2006). In this aspect, the wordnet SSI for verbs is very different, e.g. verbs like jump or displace are of the V. MOTION, even though their argument structures are very different. Nevertheless, verbal sense alternations are often associated with different argument structures (Grimshaw, 1990). The V. CHANGE supersense is populated with semantically disparate categories and is very difficult to annotate, even though it is a very frequent sense, both in terms of annotated words and of synsets adscribed to it. According to Fellbaum (1990), ‘the concept of change is flexible enough to accomodate verbs"
2016.gwc-1.30,J04-1003,0,0.0595355,"s are extensions of members of the current inventory, which we postulate by identifying semantically coherent groups of synsets. We cover the expansion of the already-established supernsense inventory for nouns and verbs, the addition of coarse supersenses for adjectives in absence of a canonical supersense inventory, and supersenses for verbal satellites. We evaluate the viability of the new senses examining the annotation agreement, frequency and co-ocurrence patterns. 1 Introduction Coarse word-sense disambiguation is a well established discipline (Segond et al., 1997; Peters et al., 1998; Lapata and Brew, 2004; Alvez et al., 2008; Izquierdo et al., 2009) that has acquired more momentum in the latter years under the name of supersense tagging (SST). SST uses a coarse sense inventory to label spans of variable word length (Ciaramita and Johnson, 2003; Ciaramita and Altun, 2006; Johannsen et al., 2014). This coarse sense inventory is obtained from the list of WordNet first beginners, i.e. the names of the lexicographer files that hold the synsets. However, lexicographer files were devised for practical reasons, namely as an organization method for the development of WordNet (Miller, 1990; Gross and Mi"
2016.gwc-1.30,N01-1009,0,0.176692,"Missing"
2016.gwc-1.30,W15-0114,0,0.0665215,"Missing"
2016.gwc-1.30,W97-0811,0,0.148135,"e supersense inventory. All new supersenses are extensions of members of the current inventory, which we postulate by identifying semantically coherent groups of synsets. We cover the expansion of the already-established supernsense inventory for nouns and verbs, the addition of coarse supersenses for adjectives in absence of a canonical supersense inventory, and supersenses for verbal satellites. We evaluate the viability of the new senses examining the annotation agreement, frequency and co-ocurrence patterns. 1 Introduction Coarse word-sense disambiguation is a well established discipline (Segond et al., 1997; Peters et al., 1998; Lapata and Brew, 2004; Alvez et al., 2008; Izquierdo et al., 2009) that has acquired more momentum in the latter years under the name of supersense tagging (SST). SST uses a coarse sense inventory to label spans of variable word length (Ciaramita and Johnson, 2003; Ciaramita and Altun, 2006; Johannsen et al., 2014). This coarse sense inventory is obtained from the list of WordNet first beginners, i.e. the names of the lexicographer files that hold the synsets. However, lexicographer files were devised for practical reasons, namely as an organization method for the develo"
2016.gwc-1.30,W15-2005,1,0.604712,"ry genres that are used for information extraction, without sacrificing its adequacy for more usual domains. Generally speaking, another corpus choice would yield a different supersense expansion. Metrics This section describes the metrics applied to the supersense-annotated corpus in order to assess the distribution of the new supersenses. 4.1 Sense-wise agreement variation Inter-annotator agreement is a source of information on the reliability of semantic categories (Lopez de Lacalle and Agirre, 2015). In this section, we examine the variation in agreement for noun and verb supersenses. Cf. Olsen et al. (2015) for a more detailed account. Figures 1 and 2 portray the variation of agreement across noun and verb supersenses. Each cell in the matrix indicates the probability of a token being annotated with a row-column tuple of supersenses (ri , c j ) by the two annotators. The matrix is normalized row-wise, and each row describes the probability distribution of a certain supersense ri to be annotated with any other supersense c j . When ri and c j have the same value, annotators agree. Rows are sorted in descending order of agreement, i.e. the size of the ri = c j box on the diagonal. The larger the b"
2016.gwc-1.30,W09-2402,0,0.0258818,"rdnets is irregular. If, as stated in Section 1, NER compatibility is a favorable side effect of SST, we consider improved NER compatiblity of the new SSI as a plus. Even though NER inventories are application dependent (cf. Nadeau and Sekine (2007) for a survey), our reference is the de facto standard CONLL inventory (Tjong Kim Sang and De Meulder, 2003), with the labels P ERSON, L OCATION and O RGANIZATION, as well as a M ISCELLA NEOUS label, needed for full coverage but not present in e.g. the 7-label inventory of MUC-7 (Chinchor and Robinson, 1997). Concrete meaning is easier to annotate (Passonneau et al., 2009) and can be the easiest to extend with new senses. As a matter of fact, the concrete N . ARTIFACT supersense is the one that yields more new supersenses in our analysis, namely N . BUILDING , N . CONTAINER and N . VEHICLE . In particular, N . BUILDING extends N . ARTIFACT because artifactual locations, already noted as a semantic type the SIMPLE ontology (Lenci et al., 2000), like houses and highways are very often predicated as locations (following locative prepositions, etc.) instead of having the typical distribution of artifacts, i.e. with the verb use or the preposition with. Moreover, N"
2016.gwc-1.30,P14-1024,0,0.0618987,"ained from the list of WordNet first beginners, i.e. the names of the lexicographer files that hold the synsets. However, lexicographer files were devised for practical reasons, namely as an organization method for the development of WordNet (Miller, 1990; Gross and Miller, 1990; Fellbaum, 1990), and not as final target categories to annotate with or disambiguate from. Nevertheless, the organization of lexicographer files is semantically motivated, and supersenses have proven useful for natural language processing such as metaphor detection or relation extraction (Ciaramita and Johnson, 2003; Tsvetkov et al., 2014a; Søgaard et al., 2015). According to Ciaramita and Altun (2006), supersenses extend the named entity recognition (NER) inventory so that the predictions of an SST model subsume the output of NER. Schneider et al. (2015) provide a full SSI for prepositions. The current supersense inventory (henceforth SSI) enjoys de facto standardness, but in spite of its potential usefulness, it is used acritically. The current SSI provides 26 noun supersenes and 15 verb supersenses. Adjective and adverb lexicographer files are disregarded. We provide a revision of the SSI by an extension of its supersenses"
2016.gwc-1.30,tsvetkov-etal-2014-augmenting-english,0,0.0911162,"ained from the list of WordNet first beginners, i.e. the names of the lexicographer files that hold the synsets. However, lexicographer files were devised for practical reasons, namely as an organization method for the development of WordNet (Miller, 1990; Gross and Miller, 1990; Fellbaum, 1990), and not as final target categories to annotate with or disambiguate from. Nevertheless, the organization of lexicographer files is semantically motivated, and supersenses have proven useful for natural language processing such as metaphor detection or relation extraction (Ciaramita and Johnson, 2003; Tsvetkov et al., 2014a; Søgaard et al., 2015). According to Ciaramita and Altun (2006), supersenses extend the named entity recognition (NER) inventory so that the predictions of an SST model subsume the output of NER. Schneider et al. (2015) provide a full SSI for prepositions. The current supersense inventory (henceforth SSI) enjoys de facto standardness, but in spite of its potential usefulness, it is used acritically. The current SSI provides 26 noun supersenes and 15 verb supersenses. Adjective and adverb lexicographer files are disregarded. We provide a revision of the SSI by an extension of its supersenses"
2016.gwc-1.30,J91-4003,0,0.622463,"icle reviewed all the N . COMMUNICATION spans and classified them in three categories, two of them mapped from the EWN top ontology, N . DOCUMENT and N . LANGUAGE , and a third back-off category for N . COMMUNICATION. Notice how, in spite of having spawned three senses (N . CONTAINER, N . VEHICLE and N . BUILDING ), N . ARTIFACT is still a very frequent supersense. The document-language distinction is a highlevel type in the SIMPLE ontology (Lenci et al., 2000). Note that these two new communication subsenses do not solve the artifact-information ambiguity commonly found in lexical semantics (Pustejovsky, 1991). While N . LANGUAGE has more often an eventual reading (e.g. conversation, remark), N . DOCUMENT refers more often to works and other entities with a non-temporal denotation. We also use N . LANGUAGE for the metalinguistic usage of words (e.g. ‘The word drizzle sounds funny’). This re-annotation produces examples like the following: N . INSTITUTION , H. C. Andersen er jo verdensberømt , fordi hans forfatterskab/N . DOCUMENT er blevet oversat til alle sprog/N . LANGUAGE . H. C. Andersen is world famous, because his writing has been translated to all languages. Out of the 1513 N . COMMUNICATION"
2016.gwc-1.30,N15-1177,0,0.0134478,"ermann and Hinrichs, 2014; Baldwin, 2005b; Baldwin, 2005a). We use three satellite tags; S . COLLOCATION, S . PARTICLE and S . REFLPRON (for reflexive pronouns). While the particle distinction is more relevant for satellite-framed languages (Talmy, 1985) like Germanic languages, light-verb constructions are pervasive in many languages, also characteristically verb-framed languages like Spanish or French, where we find verb-headed multiwords like llevar a cabo (lit. ‘take to ending’, ‘carry out’) or avoir l’air (lit. ‘to have the air’, ‘seem’), respectively. A similar approach has been used by Schneider and Smith (2015). The intention of these tags is to help isolate the head of a verb-headed multiword. We assign the sense label to the syntactic head, even though a light verb construction would be arguably best headed by its introduced noun. In this manner, gøre grin af (‘make fun of’) would be labeled as gøre/V. COMMUNICATION grin/S . COLLOCATION af /S . COLLOCATION’, and we thus avoid giving gøre (‘make’) the V. CREATION sense. 6 Conclusions and further work We suggest an extension of the SSI for the three main lexical parts of speech. We obtain new supersenses using a mapping from ontological types, and e"
2016.gwc-1.30,W15-1612,0,0.0152077,"development of WordNet (Miller, 1990; Gross and Miller, 1990; Fellbaum, 1990), and not as final target categories to annotate with or disambiguate from. Nevertheless, the organization of lexicographer files is semantically motivated, and supersenses have proven useful for natural language processing such as metaphor detection or relation extraction (Ciaramita and Johnson, 2003; Tsvetkov et al., 2014a; Søgaard et al., 2015). According to Ciaramita and Altun (2006), supersenses extend the named entity recognition (NER) inventory so that the predictions of an SST model subsume the output of NER. Schneider et al. (2015) provide a full SSI for prepositions. The current supersense inventory (henceforth SSI) enjoys de facto standardness, but in spite of its potential usefulness, it is used acritically. The current SSI provides 26 noun supersenes and 15 verb supersenses. Adjective and adverb lexicographer files are disregarded. We provide a revision of the SSI by an extension of its supersenses using the Danish wordnet as starting point. This revision is empirically backed by four evaluation criteria, namely inter-annotator agreement, sense frequency after adjucation, sense coocurrence, and NER compliance (whene"
2018.gwc-1.21,E09-1045,0,0.0600592,"Missing"
2018.gwc-1.21,J04-1003,0,0.0602406,"nt and wsd performance. 1 Lexical resources and word sense disambiguation (WSD) Dealing with finegrained lexical sense inventories in NLP is a challenging task. Selecting the correct sense in a specific context is incredibly hard when word meaning is richly described with subtle and detailed sense distinctions as found in most wordnets and lexica. To this end, coarse-grained word-sense disambiguation has become a well-established discipline over the years. One way to obtain a coarsegrained sense inventory is to cluster existing inventories either manually or automatically (Peters el al. 1998, Lapata & Brew 2004, Alvez et al. 2008, Izquierdo et al. 2009, McCarthy et al. 2016). In recent years, also so-called supersense tagging has become popular where WordNet's first beginners 1 are applied as a cross-lingual sense inventory. In recent experiments on Danish cor1 Cf. https://wordnet.princeton.edu/man/lexnames.5WN.html pora we achieved state of the art results in both annotator agreement and automatic supersense tagging (Alonso et al. 2015 and 2015b, Pedersen et al. 2016). Nevertheless, our experiments also demonstrated that the inventory was not particularly well suited for our purpose. First of all,"
2018.gwc-1.21,J99-4008,0,0.0126775,"in structure – which is well-argued and also to our knowledge normal practice in lexicography – indicates why reuse of existing lexical resources in NLP is not just a straight-forward task. It also indicates that more than one experiment should preferably be performed; one where clusters are only established within main senses, and one where clustering also takes place across main senses (see Section 3). Figure 3: Slag in DanNet in its 'cape' sense and corresponding semantic relations All synsets in DanNet are further assigned a complex ontological type following The EuroWordNet top-ontology (Vossen 1999) as depicted below in Figure 4 and 5. Origin Natural Living Plant Human Creature Animal Artefact Form Substance 2.2 Senses in DanNet Senses in DanNet are organized in terms of synsets as in standard in wordnets (Fellbaum 1998). Each synset is assigned an ontological type based on EuroWordNets' top ontology, cf. Vossen 1999). In contrast to the structure of a conventional dictionary where senses are typically organized in main and subsenses, the synsets that constitute the wordnet all have equal status. Further, each synset is inter-related to other synsets via semantic relations as shown in Fi"
2018.gwc-1.21,W15-1806,1,0.811981,"Missing"
2018.gwc-1.21,P13-4001,0,0.0671179,"Missing"
2018.gwc-1.21,W15-1831,0,0.0223372,"discipline over the years. One way to obtain a coarsegrained sense inventory is to cluster existing inventories either manually or automatically (Peters el al. 1998, Lapata & Brew 2004, Alvez et al. 2008, Izquierdo et al. 2009, McCarthy et al. 2016). In recent years, also so-called supersense tagging has become popular where WordNet's first beginners 1 are applied as a cross-lingual sense inventory. In recent experiments on Danish cor1 Cf. https://wordnet.princeton.edu/man/lexnames.5WN.html pora we achieved state of the art results in both annotator agreement and automatic supersense tagging (Alonso et al. 2015 and 2015b, Pedersen et al. 2016). Nevertheless, our experiments also demonstrated that the inventory was not particularly well suited for our purpose. First of all, the inventory proved too coarse in a considerable number of cases (see Alonso et al. 2016 for a discussion), and secondly, the set did not facilitate annotations across part-of-speech as in the case of de-verbal nouns resulting in unbalanced annotations between nouns and verbs. In the present work, we pursue a slightly different path by returning to the monolingually and corpus-defined sense inventory of our monolingual lexical re"
2018.gwc-1.40,2016.gwc-1.9,1,0.86482,"Missing"
2018.gwc-1.40,bel-etal-2000-simple,0,0.161384,"Missing"
2018.gwc-1.40,2018.gwc-1.21,1,0.813552,"Missing"
2019.gwc-1.16,C16-1010,0,0.0182711,"sibility to determine the desired type of semantic relation. At a later stage, when a more substantial part of the vocabulary has been linked, we will consider whether to follow for example Joshi et al. (2012) who generate lists of potential linking candidates with a heuristic based measure by pruning and ranking information from bilingual dictionaries. Better results are achieved with this measure when a number of links are already established. This approach could potentially be implemented when being able to utilize the high-quality established links to PWN already made by language experts. Arcan et al. (2016) use existing relations across wordnets and parallel corpora to identify contextual information for wordnet senses, and thereby expand the wordnets. Such an approach could also be adapted in our case and, again, build on the established links. The approach of McCrae et al. (2017) for linking English-German knowledge graphs combines machine translation and cross-lingual ontology alignment. This approach, which makes use of the NAISC tool (McCrae et al. 2018), could be adapted for linking DanNet to PWN, and tested on the established links. It would require high-quality machine translation and su"
2019.gwc-1.16,W14-0142,0,0.0581444,"Missing"
2019.gwc-1.16,2018.gwc-1.22,0,0.0415752,"Missing"
2019.gwc-1.16,W99-0507,1,0.223261,"newly completed dictionary of Danish, accessible in a machine-readable version and with genus proximum information explicitly specified for each sense definition (DDO). The motivation for a monolingual approach seemed obvious since by taking this approach we were enabled to compile the wordnet in a rather efficient and semi-automatic fashion using the genus proximum of the dictionary as the driving factor. The result was a resource truly based on the Danish language and vocabulary and not biased by English. The SIMPLE lexicons (cf. Lenci et al. 2000) and particularly the Danish version of it (Pedersen & Keson 1999, Pedersen & Paggio 2004) have also influenced the construction of DanNet in the sense that it includes qualia information 1 such as the telic (PURPOSE) and the agentive role (ORIGIN), roles which corresponded well with the content of the word definitions in DDO. Qualia roles are encoded in DanNet in terms of relations such as used_for, made_by and concerns as well as by means of features such as SEX and CONNOTATION. Apart from these additional features, DanNet follows wordnet standards wrt. relation types and synset structure, and all synsets are tagged with EuroWordNet Top Ontology types (Vo"
2019.gwc-1.16,W13-5616,1,0.906693,"bias, should be realistic. To this end, we have been much inspired by the work around the Polish wordnet, plWordNet (Maziarz et a. 2014), a resource which is compiled monolingually in a fashion comparable to that of DanNet and subsequently merged with PWN. Thus, much of the linking experiences resembled in i.e. Rudnicka et al. (2012) such as differences in taxonomies/structures have counterparts in our work even if the difficulties are not exactly the same. 2 Driven by the METANET/METANORD initiatives (cf. www.meta-net.eu) where we wanted to validate wordnets across the Nordic countries (cf. Pedersen et al. 2013), we initiated the merge with PWN by focusing on Princeton Core wordnet (http://wordnetcode.princeton.edu/standofffiles/core-wordnet.txt) which is a subset 5,000 central concepts of English. Going from English to Danish, these concepts where linked semi-automatically to DanNet and missing concepts where established in the Danish resource. A bilingual dictionary was used as a first automatic lookup and link suggestion for the core concepts and from here on the encoder could accept or modify the proposed links applying a wizard-like routine in the encoding tool. When embarking in 2018 the ELEXIS"
2019.gwc-1.16,J99-4008,0,0.260741,"n ‘cooperative society’, ‘cooperative store’. There seems to be a tendency that such terms are not lexicalized in English to the same degree and thus not present in PWN. 6 The linking tool For the linking from DanNet to PWN (which is currently ongoing) we apply the wordnet editing system WordnetLoom 2.0 (Naskręt et al. 2017). WordnetLoom is a graph-based system where several users can access and edit the nodes (lexical units) edges (semantic relations), and synsets as well as view glosses and usage examples. The complex ontological types of the synsets (following The EuroWordNet top-ontology (Vossen 1999)) are also visible in the accustomed version suitable for browsing DanNet, developed by Tomasz Naskręt 5 and adapted by Mitchell J. Seaton 6. An advantage of the system is that users can view and directly edit the relations in the interface, avoiding problems on manual editing of a wordnet representation file. As seen at the top of Figure 7, multiple bars of slices of the wordnet graph can be open at the same time, and are found by a given search query to the left. The results can, in the DanNet adjusted version, be filtered by part-ofspeech, synsets, supersenses, lexical units, and lexicons."
2020.globalex-1.8,N15-1132,0,0.0195236,"guages. A downside is that the induced senses are not humanly readable or easy to link to lexical resources; this limits their applicability. An incorporation of valuable high-quality resources, e.g., wordnets, in unsupervised methods can augment the sense representations with additional lexical information, especially for non-frequent word senses. The combination of contextual and knowledge-based information can be established by joint training (Faralli et al., 2016; Johansson and Nieto-Pi˜na, 2015; Mancini et al., 2017), or by postprocessing normal word embeddings (Rothe and Sch¨utze, 2017; Bhingardive et al., 2015; Chen et al., 2014; Pilehvar and Collier, 2016; Camacho-Collados et al., 2016). Alternatively, Saedi et al. (2018) successfully converted a semantic network (WordNet) into a semantic space, where the semantic affinity of two words is stronger when they are closer in the semantic network (in terms of paths). They tested the resulting representations in a semantic similarity task and found a significant improvement compared to a regular word2vec space. The study also indicated that the more semantic relations included from the semantic network, the better the result. Bhingardive et al. (2015) d"
2020.globalex-1.8,D14-1110,0,0.0277182,"the induced senses are not humanly readable or easy to link to lexical resources; this limits their applicability. An incorporation of valuable high-quality resources, e.g., wordnets, in unsupervised methods can augment the sense representations with additional lexical information, especially for non-frequent word senses. The combination of contextual and knowledge-based information can be established by joint training (Faralli et al., 2016; Johansson and Nieto-Pi˜na, 2015; Mancini et al., 2017), or by postprocessing normal word embeddings (Rothe and Sch¨utze, 2017; Bhingardive et al., 2015; Chen et al., 2014; Pilehvar and Collier, 2016; Camacho-Collados et al., 2016). Alternatively, Saedi et al. (2018) successfully converted a semantic network (WordNet) into a semantic space, where the semantic affinity of two words is stronger when they are closer in the semantic network (in terms of paths). They tested the resulting representations in a semantic similarity task and found a significant improvement compared to a regular word2vec space. The study also indicated that the more semantic relations included from the semantic network, the better the result. Bhingardive et al. (2015) detected the most fr"
2020.globalex-1.8,N15-1164,0,0.0607709,"Missing"
2020.globalex-1.8,K17-1012,0,0.0176243,"4)) do not rely on existing large datasets; they are are thus suitable for lower-resourced languages. A downside is that the induced senses are not humanly readable or easy to link to lexical resources; this limits their applicability. An incorporation of valuable high-quality resources, e.g., wordnets, in unsupervised methods can augment the sense representations with additional lexical information, especially for non-frequent word senses. The combination of contextual and knowledge-based information can be established by joint training (Faralli et al., 2016; Johansson and Nieto-Pi˜na, 2015; Mancini et al., 2017), or by postprocessing normal word embeddings (Rothe and Sch¨utze, 2017; Bhingardive et al., 2015; Chen et al., 2014; Pilehvar and Collier, 2016; Camacho-Collados et al., 2016). Alternatively, Saedi et al. (2018) successfully converted a semantic network (WordNet) into a semantic space, where the semantic affinity of two words is stronger when they are closer in the semantic network (in terms of paths). They tested the resulting representations in a semantic similarity task and found a significant improvement compared to a regular word2vec space. The study also indicated that the more semantic"
2020.globalex-1.8,W15-1806,1,0.818348,"l., 2015; Chen et al., 2014; Pilehvar and Collier, 2016; Camacho-Collados et al., 2016). Alternatively, Saedi et al. (2018) successfully converted a semantic network (WordNet) into a semantic space, where the semantic affinity of two words is stronger when they are closer in the semantic network (in terms of paths). They tested the resulting representations in a semantic similarity task and found a significant improvement compared to a regular word2vec space. The study also indicated that the more semantic relations included from the semantic network, the better the result. Bhingardive et al. (2015) detected the most frequent senses by comparing the target word embedding in a word embedding model with constructed sense representations based on synset information represented in a word embedding model. Our work is also related to Ustalov et al. (2018) who proposed a synset-averaged sense-embedding approach to WSD for an under-resourced language (Russian). They evaluate the system’s clustering on a goldstandard with an average number of word senses of 3.2 4. Five word embedding experiments For a number of years up to now, embeddings have been ubiquitous in computational approaches to numero"
2020.globalex-1.8,W04-0807,0,0.0973587,"anish as a lower-resourced language and presents existing semantic resources that are available for our task. In Section 3, we present related work, and in Section 4 we describe our five experiments in detail. Section 5 and 6 describe and discuss our results, and in Section 7 we conclude and outline plans for future work. The effective handling of sense ambiguity in Natural Language Processing (NLP) is an extremely challenging task, as is well described in the literature (Kilgarriff, 1997; Agirre and Edmonds, 2006; Palmer et al., 2004; Navigli and Di Marco, 2013; Edmonds and Kilgarriff, 2002; Mihalcea et al., 2004; Pradhan et al., 2007). In this paper, we focus on a lower-resourced language, Danish, with the hypothesis that if we can compile sense inventories that both correlate well with human interpretations of word meaning and are well-reflected statistically in large corpora, we would have made a first and important step towards an improved and useful sense inventory: not too fine-grained, but still capturing the essential meaning differences that are relevant in language processing. We investigate this hypothesis by building sense representations from word embeddings using wordnet-associated data."
2020.globalex-1.8,J13-3008,0,0.0405417,"Missing"
2020.globalex-1.8,D14-1113,0,0.0392712,"task and not for most frequent sense detection or on a gold standard. The work provides a detailed investigation of which information types from DanNet improve our WSD results, and with more focus on the role of example sentences than seen in related work. Related Work Both supervised and unsupervised methods to represent words and word senses have been widely explored in NLP, especially given the popularity of word embeddings. Unsupervised approaches to obtain not only word embeddings, but also sense embeddings (such as SenseGram (Pelevina et al., 2017), Adagram (Bartunov et al., 2016), and Neelakantan et al. (2014)) do not rely on existing large datasets; they are are thus suitable for lower-resourced languages. A downside is that the induced senses are not humanly readable or easy to link to lexical resources; this limits their applicability. An incorporation of valuable high-quality resources, e.g., wordnets, in unsupervised methods can augment the sense representations with additional lexical information, especially for non-frequent word senses. The combination of contextual and knowledge-based information can be established by joint training (Faralli et al., 2016; Johansson and Nieto-Pi˜na, 2015; Ma"
2020.globalex-1.8,W18-4003,0,0.0414074,"Missing"
2020.globalex-1.8,W04-2807,0,0.136977,"th dictionary senses. The paper is structured as follows: Section 2 describes Danish as a lower-resourced language and presents existing semantic resources that are available for our task. In Section 3, we present related work, and in Section 4 we describe our five experiments in detail. Section 5 and 6 describe and discuss our results, and in Section 7 we conclude and outline plans for future work. The effective handling of sense ambiguity in Natural Language Processing (NLP) is an extremely challenging task, as is well described in the literature (Kilgarriff, 1997; Agirre and Edmonds, 2006; Palmer et al., 2004; Navigli and Di Marco, 2013; Edmonds and Kilgarriff, 2002; Mihalcea et al., 2004; Pradhan et al., 2007). In this paper, we focus on a lower-resourced language, Danish, with the hypothesis that if we can compile sense inventories that both correlate well with human interpretations of word meaning and are well-reflected statistically in large corpora, we would have made a first and important step towards an improved and useful sense inventory: not too fine-grained, but still capturing the essential meaning differences that are relevant in language processing. We investigate this hypothesis by b"
2020.globalex-1.8,L16-1136,1,0.841564,"emantic relations which lexicographers have chosen as being the defining relation for each particular concept. This approach sheds light on the extent to which the hand-picked words in the synsets are actually representative of the processed corpus data. It is not possible at this stage to evaluate an unsupervised word sense induction (WSI) system for Danish with curated open-source data. However, with a knowledge-based system, where the sense representations are linked to lexical entries, it is possible to evaluate with the semantically annotated data available for Danish, the SemDaX Corpus (Pedersen et al., 2016). This corpus is annotated with dictionary senses. The paper is structured as follows: Section 2 describes Danish as a lower-resourced language and presents existing semantic resources that are available for our task. In Section 3, we present related work, and in Section 4 we describe our five experiments in detail. Section 5 and 6 describe and discuss our results, and in Section 7 we conclude and outline plans for future work. The effective handling of sense ambiguity in Natural Language Processing (NLP) is an extremely challenging task, as is well described in the literature (Kilgarriff, 199"
2020.globalex-1.8,2018.gwc-1.21,1,0.880575,"in a WSD lexical sample task. For the experiments, we represent wordnet synset information from the Danish wordnet, DanNet (Pedersen et al., 2009), in a word embedding model. We test five dif2. Danish as a lower-resourced language Semantic processing of lower-resourced languages is a challenging enterprise typically calling for combined methods of applying both supervised and unsupervised methods in combination with language transfer from richerresourced languages. For Danish we have now a number of standard semantic resources and tools such as a wordnet and SemDaX corpus, a framenet lexicon (Pedersen et al., 2018b), several word embedding models (Sørensen and Nimb, 2018), and a preliminary sense tagger (Martinez Alonso et al., 2015). However, the size and accessibility of the resources as well as the evaluation datasets accompanying them typically constitute a bottleneck. 45 Figure 1: The method used to build the synset embeddings. For instance, the wordnet, DanNet, which contains 65,000 synsets, is open-source, but the links from DanNet to the complete sense inventory of The Danish Dictionary is not. Our work requires this key, which necessitated connecting the dictionary labels to DanNet synsets thr"
2020.globalex-1.8,L18-1378,1,0.76173,"in a WSD lexical sample task. For the experiments, we represent wordnet synset information from the Danish wordnet, DanNet (Pedersen et al., 2009), in a word embedding model. We test five dif2. Danish as a lower-resourced language Semantic processing of lower-resourced languages is a challenging enterprise typically calling for combined methods of applying both supervised and unsupervised methods in combination with language transfer from richerresourced languages. For Danish we have now a number of standard semantic resources and tools such as a wordnet and SemDaX corpus, a framenet lexicon (Pedersen et al., 2018b), several word embedding models (Sørensen and Nimb, 2018), and a preliminary sense tagger (Martinez Alonso et al., 2015). However, the size and accessibility of the resources as well as the evaluation datasets accompanying them typically constitute a bottleneck. 45 Figure 1: The method used to build the synset embeddings. For instance, the wordnet, DanNet, which contains 65,000 synsets, is open-source, but the links from DanNet to the complete sense inventory of The Danish Dictionary is not. Our work requires this key, which necessitated connecting the dictionary labels to DanNet synsets thr"
2020.globalex-1.8,D16-1174,0,0.0208871,"are not humanly readable or easy to link to lexical resources; this limits their applicability. An incorporation of valuable high-quality resources, e.g., wordnets, in unsupervised methods can augment the sense representations with additional lexical information, especially for non-frequent word senses. The combination of contextual and knowledge-based information can be established by joint training (Faralli et al., 2016; Johansson and Nieto-Pi˜na, 2015; Mancini et al., 2017), or by postprocessing normal word embeddings (Rothe and Sch¨utze, 2017; Bhingardive et al., 2015; Chen et al., 2014; Pilehvar and Collier, 2016; Camacho-Collados et al., 2016). Alternatively, Saedi et al. (2018) successfully converted a semantic network (WordNet) into a semantic space, where the semantic affinity of two words is stronger when they are closer in the semantic network (in terms of paths). They tested the resulting representations in a semantic similarity task and found a significant improvement compared to a regular word2vec space. The study also indicated that the more semantic relations included from the semantic network, the better the result. Bhingardive et al. (2015) detected the most frequent senses by comparing t"
2020.globalex-1.8,S07-1016,0,0.00949046,"ced language and presents existing semantic resources that are available for our task. In Section 3, we present related work, and in Section 4 we describe our five experiments in detail. Section 5 and 6 describe and discuss our results, and in Section 7 we conclude and outline plans for future work. The effective handling of sense ambiguity in Natural Language Processing (NLP) is an extremely challenging task, as is well described in the literature (Kilgarriff, 1997; Agirre and Edmonds, 2006; Palmer et al., 2004; Navigli and Di Marco, 2013; Edmonds and Kilgarriff, 2002; Mihalcea et al., 2004; Pradhan et al., 2007). In this paper, we focus on a lower-resourced language, Danish, with the hypothesis that if we can compile sense inventories that both correlate well with human interpretations of word meaning and are well-reflected statistically in large corpora, we would have made a first and important step towards an improved and useful sense inventory: not too fine-grained, but still capturing the essential meaning differences that are relevant in language processing. We investigate this hypothesis by building sense representations from word embeddings using wordnet-associated data. In order to assess the"
2020.globalex-1.8,W18-3016,0,0.0410544,"their applicability. An incorporation of valuable high-quality resources, e.g., wordnets, in unsupervised methods can augment the sense representations with additional lexical information, especially for non-frequent word senses. The combination of contextual and knowledge-based information can be established by joint training (Faralli et al., 2016; Johansson and Nieto-Pi˜na, 2015; Mancini et al., 2017), or by postprocessing normal word embeddings (Rothe and Sch¨utze, 2017; Bhingardive et al., 2015; Chen et al., 2014; Pilehvar and Collier, 2016; Camacho-Collados et al., 2016). Alternatively, Saedi et al. (2018) successfully converted a semantic network (WordNet) into a semantic space, where the semantic affinity of two words is stronger when they are closer in the semantic network (in terms of paths). They tested the resulting representations in a semantic similarity task and found a significant improvement compared to a regular word2vec space. The study also indicated that the more semantic relations included from the semantic network, the better the result. Bhingardive et al. (2015) detected the most frequent senses by comparing the target word embedding in a word embedding model with constructed"
2020.globalex-1.8,L18-1164,0,0.0251576,"is stronger when they are closer in the semantic network (in terms of paths). They tested the resulting representations in a semantic similarity task and found a significant improvement compared to a regular word2vec space. The study also indicated that the more semantic relations included from the semantic network, the better the result. Bhingardive et al. (2015) detected the most frequent senses by comparing the target word embedding in a word embedding model with constructed sense representations based on synset information represented in a word embedding model. Our work is also related to Ustalov et al. (2018) who proposed a synset-averaged sense-embedding approach to WSD for an under-resourced language (Russian). They evaluate the system’s clustering on a goldstandard with an average number of word senses of 3.2 4. Five word embedding experiments For a number of years up to now, embeddings have been ubiquitous in computational approaches to numerous NLP tasks. While word embeddings, such as word2vec (Mikolov et al., 2013), have been central in NLP research touching on lexical semantics, other forms of embeddings, from character to paragraph to multimodal, have proven to be flexible, often multi-pu"
2020.lrec-1.395,I13-1057,0,0.0253544,"reated dynamically for semantic relationship annotation. scribed our methodology in Section 3, we further elaborate on the challenges of sense annotation in Section 4. We evaluate the datasets in Section 5 and finally, conclude the paper in Section 6. 2. Related work Aligning senses across lexical resources has been attempted in several lexicographical milieus over the recent years. Such resources mainly include open-source dictionaries, WordNet and collaboratively-curated resources, such as Wikipedia. The latter has been shown to be reliable resources to construct accurate sense classifiers (Dandala et al., 2013). There has been a significant body of research in aligning English resources, particularly, Princeton WordNet with Wikipedia (including (Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011; McCrae, 2018)), with the Longman Dictionary of Contemporary English and with Roget’s thesaurus (Kwong, 1998), with Wiktionary3 (Meyer and Gurevych, 2011) or with the Oxford Dictionary of English (Navigli, 2006). Meyer and Gurevych (2011) also present a manually-annotated dataset for WSA between the English WordNet and Wiktionary. On the other hand, there are a fewer number of m"
2020.lrec-1.395,erjavec-fiser-2006-building,0,0.137609,"Missing"
2020.lrec-1.395,E12-1059,0,0.155275,"geneity in content, which makes aligning information across resources and languages a challenging task. Word sense alignment (WSA) is a more specific task of linking dictionary content at sense level which has been proved to be beneficial in various NLP tasks, such as wordsense disambiguation (Navigli and Ponzetto, 2012), semantic role labeling (Palmer, 2009) and information extraction (Moro et al., 2013). Moreover, combining LSRs can enhance domain coverage in terms of the number of lexical items and types of lexical-semantic information (Shi and 1 Mihalcea, 2005; Ponzetto and Navigli, 2010; Gurevych et al., 2012). Given the current progress of artificial intelligence and the usage of data to train neural networks, annotated data with specific features play a crucial role to tackle data-driven challenges, particularly in NLP. In recent years, a few efforts have been made to create gold-standard dataset, i.e., a dataset of instances used for learning and fitting parameters, for aligning senses across monolingual resources including collaboratively-curated ones such as Wikipedia2 , and expert-made ones such as WordNet. However, the previous work is limited to a handful of languages and much of it is not"
2020.lrec-1.395,W97-0800,0,0.569498,"2011; McCrae, 2018)), with the Longman Dictionary of Contemporary English and with Roget’s thesaurus (Kwong, 1998), with Wiktionary3 (Meyer and Gurevych, 2011) or with the Oxford Dictionary of English (Navigli, 2006). Meyer and Gurevych (2011) also present a manually-annotated dataset for WSA between the English WordNet and Wiktionary. On the other hand, there are a fewer number of manually aligned monolingual resources in other languages. For instance, there have been considerable efforts in aligning lexical semantic resources (LSRs) in German, particularly, the GermaNet–the German Wordnet (Hamp and Feldweg, 1997) with the German Wiktionary (Henrich et al., 2011), with the German Wikipedia (Henrich et al., 2012) and with the Digital Dictionary of the German Language (Digitales W¨orterbuch der Deutschen Sprache (Klein and Geyken, 2010)) (Henrich et al., 2014). Gurevych et al. (2012) present UKB–a large-scale lexical-semantic resource containing pairwise sense alignments between a subset of nine resources in English and German which are mapped to a uniform representation. For Danish, aligning senses across modern lexical resources has been carried out in several projects in recent years (Pedersen et al.,"
2020.lrec-1.395,W14-0109,0,0.0200074,"resent a manually-annotated dataset for WSA between the English WordNet and Wiktionary. On the other hand, there are a fewer number of manually aligned monolingual resources in other languages. For instance, there have been considerable efforts in aligning lexical semantic resources (LSRs) in German, particularly, the GermaNet–the German Wordnet (Hamp and Feldweg, 1997) with the German Wiktionary (Henrich et al., 2011), with the German Wikipedia (Henrich et al., 2012) and with the Digital Dictionary of the German Language (Digitales W¨orterbuch der Deutschen Sprache (Klein and Geyken, 2010)) (Henrich et al., 2014). Gurevych et al. (2012) present UKB–a large-scale lexical-semantic resource containing pairwise sense alignments between a subset of nine resources in English and German which are mapped to a uniform representation. For Danish, aligning senses across modern lexical resources has been carried out in several projects in recent years (Pedersen et al., 2018), and a next natural step is to link these to historical Danish dictionaries. 3 https://www.wiktionary.org/ Pedersen et al. (2009) describe the semi-automatic compilation of a WordNet for Danish, DanNet, based on a monolingual dictionary, the"
2020.lrec-1.395,bel-etal-2000-simple,1,0.672745,"Missing"
2020.lrec-1.395,Q13-1013,0,0.110061,"nment of LSRs and applied it to the production of a three-way alignment of the English WordNet, Wikipedia and Wiktionary. Niemann and Gurevych (2011) propose a threshold-based Personalized PageRank method for extracting a set of Wikipedia articles as alignment candidates and automatically aligning them with WordNet synsets. This method yields a sense inventory of higher coverage in comparison to taxonomy mapping techniques where Wikipedia categories are aligned to WordNet synsets (Ponzetto and Navigli, 2009). Matuschek and Gurevych present the Dijkstra-WSA algorithm as a graph-based approach (Matuschek and Gurevych, 2013) and a machine learning approach where features such as sense distances and gloss similarities are used for the task of WSA (Matuschek and Gurevych, 2014). It should be noted that all of these approaches produce results that are of lower reliability than gold standard datasets such as the ones presented in this paper. 3233 3. Methodology The main goal of the current study is to provide semantic relationships between two sets of senses for the same lemmas in two monolingual dictionaries. As an example, Figure 1 illustrates the senses for the entry “clog” (verb) in the English WordNet (Miller, 1"
2020.lrec-1.395,C14-1025,0,0.31488,"ose a threshold-based Personalized PageRank method for extracting a set of Wikipedia articles as alignment candidates and automatically aligning them with WordNet synsets. This method yields a sense inventory of higher coverage in comparison to taxonomy mapping techniques where Wikipedia categories are aligned to WordNet synsets (Ponzetto and Navigli, 2009). Matuschek and Gurevych present the Dijkstra-WSA algorithm as a graph-based approach (Matuschek and Gurevych, 2013) and a machine learning approach where features such as sense distances and gloss similarities are used for the task of WSA (Matuschek and Gurevych, 2014). It should be noted that all of these approaches produce results that are of lower reliability than gold standard datasets such as the ones presented in this paper. 3233 3. Methodology The main goal of the current study is to provide semantic relationships between two sets of senses for the same lemmas in two monolingual dictionaries. As an example, Figure 1 illustrates the senses for the entry “clog” (verb) in the English WordNet (Miller, 1995) (left) and the Webster’s Dictionary 1913 (Webster and Slater, 1828) (right). For further clarification, we provide two case studies of Danish and Ita"
2020.lrec-1.395,2018.gwc-1.8,1,0.745977,"Section 6. 2. Related work Aligning senses across lexical resources has been attempted in several lexicographical milieus over the recent years. Such resources mainly include open-source dictionaries, WordNet and collaboratively-curated resources, such as Wikipedia. The latter has been shown to be reliable resources to construct accurate sense classifiers (Dandala et al., 2013). There has been a significant body of research in aligning English resources, particularly, Princeton WordNet with Wikipedia (including (Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011; McCrae, 2018)), with the Longman Dictionary of Contemporary English and with Roget’s thesaurus (Kwong, 1998), with Wiktionary3 (Meyer and Gurevych, 2011) or with the Oxford Dictionary of English (Navigli, 2006). Meyer and Gurevych (2011) also present a manually-annotated dataset for WSA between the English WordNet and Wiktionary. On the other hand, there are a fewer number of manually aligned monolingual resources in other languages. For instance, there have been considerable efforts in aligning lexical semantic resources (LSRs) in German, particularly, the GermaNet–the German Wordnet (Hamp and Feldweg, 19"
2020.lrec-1.395,I11-1099,0,0.152048,"he recent years. Such resources mainly include open-source dictionaries, WordNet and collaboratively-curated resources, such as Wikipedia. The latter has been shown to be reliable resources to construct accurate sense classifiers (Dandala et al., 2013). There has been a significant body of research in aligning English resources, particularly, Princeton WordNet with Wikipedia (including (Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011; McCrae, 2018)), with the Longman Dictionary of Contemporary English and with Roget’s thesaurus (Kwong, 1998), with Wiktionary3 (Meyer and Gurevych, 2011) or with the Oxford Dictionary of English (Navigli, 2006). Meyer and Gurevych (2011) also present a manually-annotated dataset for WSA between the English WordNet and Wiktionary. On the other hand, there are a fewer number of manually aligned monolingual resources in other languages. For instance, there have been considerable efforts in aligning lexical semantic resources (LSRs) in German, particularly, the GermaNet–the German Wordnet (Hamp and Feldweg, 1997) with the German Wiktionary (Henrich et al., 2011), with the German Wikipedia (Henrich et al., 2012) and with the Digital Dictionary of t"
2020.lrec-1.395,miller-gurevych-2014-wordnet,0,0.125981,"Missing"
2020.lrec-1.395,P06-1014,0,0.254458,"ies, WordNet and collaboratively-curated resources, such as Wikipedia. The latter has been shown to be reliable resources to construct accurate sense classifiers (Dandala et al., 2013). There has been a significant body of research in aligning English resources, particularly, Princeton WordNet with Wikipedia (including (Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011; McCrae, 2018)), with the Longman Dictionary of Contemporary English and with Roget’s thesaurus (Kwong, 1998), with Wiktionary3 (Meyer and Gurevych, 2011) or with the Oxford Dictionary of English (Navigli, 2006). Meyer and Gurevych (2011) also present a manually-annotated dataset for WSA between the English WordNet and Wiktionary. On the other hand, there are a fewer number of manually aligned monolingual resources in other languages. For instance, there have been considerable efforts in aligning lexical semantic resources (LSRs) in German, particularly, the GermaNet–the German Wordnet (Hamp and Feldweg, 1997) with the German Wiktionary (Henrich et al., 2011), with the German Wikipedia (Henrich et al., 2012) and with the Digital Dictionary of the German Language (Digitales W¨orterbuch der Deutschen S"
2020.lrec-1.395,W11-0122,0,0.627617,"ally, conclude the paper in Section 6. 2. Related work Aligning senses across lexical resources has been attempted in several lexicographical milieus over the recent years. Such resources mainly include open-source dictionaries, WordNet and collaboratively-curated resources, such as Wikipedia. The latter has been shown to be reliable resources to construct accurate sense classifiers (Dandala et al., 2013). There has been a significant body of research in aligning English resources, particularly, Princeton WordNet with Wikipedia (including (Ruiz-Casado et al., 2005; Ponzetto and Navigli, 2010; Niemann and Gurevych, 2011; McCrae, 2018)), with the Longman Dictionary of Contemporary English and with Roget’s thesaurus (Kwong, 1998), with Wiktionary3 (Meyer and Gurevych, 2011) or with the Oxford Dictionary of English (Navigli, 2006). Meyer and Gurevych (2011) also present a manually-annotated dataset for WSA between the English WordNet and Wiktionary. On the other hand, there are a fewer number of manually aligned monolingual resources in other languages. For instance, there have been considerable efforts in aligning lexical semantic resources (LSRs) in German, particularly, the GermaNet–the German Wordnet (Hamp"
2020.lrec-1.395,P10-1154,0,0.289699,"nces in structure and heterogeneity in content, which makes aligning information across resources and languages a challenging task. Word sense alignment (WSA) is a more specific task of linking dictionary content at sense level which has been proved to be beneficial in various NLP tasks, such as wordsense disambiguation (Navigli and Ponzetto, 2012), semantic role labeling (Palmer, 2009) and information extraction (Moro et al., 2013). Moreover, combining LSRs can enhance domain coverage in terms of the number of lexical items and types of lexical-semantic information (Shi and 1 Mihalcea, 2005; Ponzetto and Navigli, 2010; Gurevych et al., 2012). Given the current progress of artificial intelligence and the usage of data to train neural networks, annotated data with specific features play a crucial role to tackle data-driven challenges, particularly in NLP. In recent years, a few efforts have been made to create gold-standard dataset, i.e., a dataset of instances used for learning and fitting parameters, for aligning senses across monolingual resources including collaboratively-curated ones such as Wikipedia2 , and expert-made ones such as WordNet. However, the previous work is limited to a handful of language"
2020.lrec-1.395,roventini-ruimy-2008-mapping,0,0.0409542,"the semantic level of a quadripartite Italian lexicon. Its structure is inspired by Generative Lexicon theory (Pustejovsky, 1995) and in particular the notion of qualia structure which is used to organise the Semantic Units (SemUs) which constitute the basic structures representing word-sense. SIMPLE contains 20,000 SemUs and we used the definitions of these SemUs for the task. Both lexicons share a set of common “base concepts” that provided the basis of a previous (semi-)automatic mapping of the two lexicons on the basis of their respective ontological organisations (Roventini et al., 2007; Roventini and Ruimy, 2008). Although this mapping did not make the five-fold distinction, i.e., exact, narrower, broader, related, and none, it did constitute a useful starting point and a basis for comparison for the task. The teams that had originally compiled IWN and SIMPLE shared many members in common and so, the definitions for corresponding senses across the two lexicons are sometimes very similar or differ solely on the basis of an extra clause. This made it easy to determine, in many cases, if two senses were ‘exact’ matches or if one was ‘broader’ or ‘narrower’ than the other by just comparing strings. The ap"
2020.lrec-1.395,roventini-etal-2000-italwordnet,0,0.0791879,"Missing"
2020.lrec-1.395,roventini-etal-2002-integrating,0,0.0935961,"n incapacitated adult). An opposite case where the historical sense is ‘narrower’ than the modern one can be illustrated by the adjective spids (‘sharp’) where ODS describes two specific senses, one about sound and another one about smell, while DDO merges the two senses into one: ‘pungent in an unpleasant way (about smell, taste or sound)’. 4.2. ItalWordNet and SIMPLE Regarding Italian, the team at ILC-CNR chose ItalWordNet (IWN) and SIMPLE, two Italian language lexical resources which had been previously developed in the institute. The former, IWN, is a lexical semantic network for Italian (Roventini et al., 2002) which is part of the WordNet family (Miller, 1995). As such it is organised around the notion of a synset of word senses and the network structure based on lexical-semantic relations which hold between senses across synsets. The 50,000 Italian synsets contained in IWN are linked to the Princeton Wordnet. The latter resource, SIMPLE, constitutes the semantic level of a quadripartite Italian lexicon. Its structure is inspired by Generative Lexicon theory (Pustejovsky, 1995) and in particular the notion of qualia structure which is used to organise the Semantic Units (SemUs) which constitute the"
2020.lrec-1.395,P07-2041,0,0.0611602,"ce, SIMPLE, constitutes the semantic level of a quadripartite Italian lexicon. Its structure is inspired by Generative Lexicon theory (Pustejovsky, 1995) and in particular the notion of qualia structure which is used to organise the Semantic Units (SemUs) which constitute the basic structures representing word-sense. SIMPLE contains 20,000 SemUs and we used the definitions of these SemUs for the task. Both lexicons share a set of common “base concepts” that provided the basis of a previous (semi-)automatic mapping of the two lexicons on the basis of their respective ontological organisations (Roventini et al., 2007; Roventini and Ruimy, 2008). Although this mapping did not make the five-fold distinction, i.e., exact, narrower, broader, related, and none, it did constitute a useful starting point and a basis for comparison for the task. The teams that had originally compiled IWN and SIMPLE shared many members in common and so, the definitions for corresponding senses across the two lexicons are sometimes very similar or differ solely on the basis of an extra clause. This made it easy to determine, in many cases, if two senses were ‘exact’ matches or if one was ‘broader’ or ‘narrower’ than the other by ju"
2020.lrec-1.395,2019.gwc-1.37,1,0.782709,"onary, the Danish Dictionary (Den Danske Ordbog (DDO)). Later, the semantic links between these two resources facilitated the compilation of a comprehensive thesaurus (Den Danske Begrebsordbog) (Nimb et al., 2014). The semantic links between thesaurus and dictionary made it possible to combine verb groups and dictionary valency information, used as input for the compilation of the Danish FrameNet Lexicon (Nimb, 2018). Furthermore, they constitute the basis for the automatically integrated information on related words in DDO, on the fly for each dictionary sense (Nimb et al., 2018). Similarly, Simov et al. (2019) report the manual mapping of the Bulgarian Word-Net BTB-WN with the Bulgarian Wikipedia. Given the amount of the effort required to construct and maintain expert-made resources, various solutions have been proposed to automatically link and merge existing LSRs at different levels. LSRs being very diverse in domain coverage (Meyer, 2010; Burgun and Bodenreider, 2001), previous works have focused on methods to increase domain coverage, enrich sense representations and decrease sense granularity (Miller, 2016). Miller and Gurevych (2014) describe a technique for constructing an n-way alignment o"
2020.lrec-1.407,gavrilidou-etal-2012-meta,1,0.919419,"Missing"
2020.lrec-1.407,2020.lrec-1.420,1,0.860379,"Missing"
2020.lrec-1.407,L18-1213,1,0.894888,"Missing"
2020.lrec-1.407,piperidis-etal-2014-meta,1,0.824391,"ween 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META-NET results (Rehm and Uszkoreit, 2012), funded a"
2020.lrec-1.407,piperidis-2012-meta,1,0.92358,"n 34 European countries. META-NET was, between 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META"
2020.lrec-1.407,L16-1251,1,0.865781,"Missing"
2020.lrec-1.407,2020.lrec-1.413,1,0.785764,"Missing"
2020.lrec-1.585,N09-1003,0,0.0695869,"Missing"
2020.lrec-1.585,W17-5304,0,0.0146208,"similarity on a spectrum, and that it might therefore be problematic to rate different semantic relations on the same scale (Avraham and Goldberg, 2016; Faruqui et al., 2016). This speaks to the fact that semantic similarity is an intuitive concept that is difficult to quantify or model. To achieve a less artificial insight into the way humans conceptualize meaning and distribution, supplementing similarity experiments with methods in psycholinguistics, such as semantic priming or neural activation patterns, might give a more accurate insight into the cognitive reality of semantic similarity (Auguste et al., 2017; Bakarov, 2018). It might also be worth considering whether the choice of a relatively fine-grained scale of similarity from 0 to 6 is suitable for computational purposes; considering similarity as a binary classification task or using a 0-3 interval might raise the inter-annotator agreement while still give a sufficient picture of similarity for the purposes of word embedding evaluation. Finally, a specific issue with our dataset is its small size, which makes it difficult to ensure that the query inventory covers a linguistically representative sample of the Danish language, and therefore,"
2020.lrec-1.585,W16-2519,0,0.0169446,"cted to consider similarity on a scale of synonymousness, this only guarantees a relatively well defined notion about pairs with obviously highly synonymous meanings, but it does not necessarily specify whether antonyms should be considered more or less similar than related pairs, or whether cohyponyms can in fact be considered more in the relatedness category than the similarity one, given their low scores on the dataset. This suggests that participants do not consider similarity on a spectrum, and that it might therefore be problematic to rate different semantic relations on the same scale (Avraham and Goldberg, 2016; Faruqui et al., 2016). This speaks to the fact that semantic similarity is an intuitive concept that is difficult to quantify or model. To achieve a less artificial insight into the way humans conceptualize meaning and distribution, supplementing similarity experiments with methods in psycholinguistics, such as semantic priming or neural activation patterns, might give a more accurate insight into the cognitive reality of semantic similarity (Auguste et al., 2017; Bakarov, 2018). It might also be worth considering whether the choice of a relatively fine-grained scale of similarity from 0 to"
2020.lrec-1.585,P14-1023,0,0.0476109,"hose methods don’t transfer more generally; how well a word embedding does at one machine learning task doesn’t 2 The word embedding query is generated using the dsl word embedding model (Sørensen and Nimb, 2018) with the Gensim ˇ uˇrek and Sojka, 2010) library(Reh˚ predict how well it will do at another task of a completely different nature (Bakarov, 2018; Schnabel et al., 2015). In contrast, a much more varied set of methods is those of intrinsic evaluation, which use experiments from cognitive sciences and psycholinguistics to directly explore syntactic or semantic relations between words (Baroni et al., 2014; Hill et al., 2015). Typically, such experiments involve a pre-selected query inventory consisting of word pairs that are then judged based on some criteria of semantic quality, yielding an aggregate score that functions as an absolute gold standard for evaluating the quality of semantic models. Such experiments usually involve crowd sourcing, although automatic extraction of linguistic information through annotated corpora or wordnets have recently become more common (Tsvetkov et al., 2015). Within the group of intrinsic methods of evaluation, the use of word similarity judgements is by far"
2020.lrec-1.585,W16-2502,0,0.339624,"tems such as ‘car’ and ‘train’ share numerous common properties, namely being vehicles and consisting of similar parts, and are thus functionally similar. To put it in more formal terms, the semantic relations that best represents similarity defined in this way is that of near synonymy (‘smart / intelligent’, ‘happiness / joy’ etc), and to a lesser extend hypernym/hyponym and co-hyponym pairs (‘bee / insect’, ‘cat / dog’), while related but dissimilar pairs are best described by the relation of meronymy (‘knife / blade’) or the concept of association, also sometimes termed topical similarity (Batchkarov et al., 2016). In this paper, semantic similarity will be defined as the extend to which two words both occur in similar contexts and express similar meanings. As a consequence of this definition, 3 https://github.com/fnielsen/dasem/tree/ master/dasem/data/wordsim353-da antonym pairs (‘short / long’, ‘interesting / boring’) should also be considered dissimilar and given a low similarity rating, challenging the model’s tendency to give high scores to antonym pairs. The assumption that antonym pairs are semantically dissimilar is henceforth taken for granted, because this lets us compare our dataset directly"
2020.lrec-1.585,Q17-1010,0,0.0358857,"ia and the language has been identified by a language detection tool. The dsl embeddings from (Sørensen and Nimb, 2018) are trained using CBOW features on a Danish corpus containing roughly 920 million running words at the time of training, spanning over a variety of text types from between 1982 and 2017, namely newswire, extracts from magazines, transcripts from the Danish parlament, and fiction. The model is trained over 500 features with a symmetric context window size of 5 and a minimum word count of 5 for all word form types. The remaining three word embeddings are trained with fastText (Bojanowski et al., 2017). The wiki embeddings 8 are 300 dimensional and were trained with Skip-Gram on the Danish Wikipedia, the cc embeddings 9 (Grave et al., 2018) are 300 dimensional and were trained with CBOW on the Danish Wikipedia and CommonCrawl, where the language of text was identified with a language detection tool, and the sketchengine word embeddings are 100 dimensional and were trained with Skip-Gram on approximately 2 billion tokens of Danish web text, gathered by SketchEngine10 . All the word embeddings have been evaluated on Danish Similarity Dataset and the Danish Wordsim353. We report the Spearman’s"
2020.lrec-1.585,N19-1423,0,0.0121215,". Most recent gold standard initiatives address the issue of polysemy by considering words with respect to a context. Namely, Pilehvar and Camacho-Collados (2019) presents a dataset for evaluating context-sensitive word embeddings, in which a target word is evaluated with respect to two contexts represented by text examples. The two text examples then receive a binary label that indicates whether the occurrence of the target word corresponds to the same or a different meaning. Such similarity datasets allow for intrinsic evaluation of the newer contextual word embeddings (Peters et al., 2018; Devlin et al., 2019) as these models rely on the context of a word as a basis for forming word representations. Currently no such pretrained model exists for Danish, however constructing a dataset with words in context would be an interesting research direction to allow for future pretrained Danish contextual word embedding models. Alternatively, in other gold standards, such as the one constructed by Schnabel et al. (2015), participants are asked to rank the similarity of a target word with respect to the query words in a specific word embedding model. While this seems undesirable as a general model-agnostic met"
2020.lrec-1.585,P18-1128,0,0.0140456,"st processing The post-processing of the collected data consisted of dealing with missing values in the data, calibration, and normalization of the mean similarity scores. Subsequently, since 4.1. Results The data 4.1.1. Inter-annotator agreement Researchers typically report inter-annotator agreement as the mean Spearman rank correlation coefficient over all pairwise comparisons; either by calculating the correlation of each participant with every other participant or by comparing each participant to the overall gold standard, i.e. the mean similarity score over all items (Hill et al., 2015) (Dror et al., 2018). This captures the fact that similarity is measured on a continuous scale, which contrasts with many other NLP tasks where variables are categorical, in which cases Cohen’s Kappa is used instead (Batchkarov et al., 2016). Figure 2 shows the pairwise correlations between all annotators compared with the correlations between each pair and the (almost) gold standard for the dataset. In general, all annotators rank fairly highly measured against the similarity gold standards„ the values ranging from a minimum of 0.62 to a maximum of 0.92, with a mean score of 0.82. The pairwise correlations are s"
2020.lrec-1.585,W16-2506,0,0.0438236,"Missing"
2020.lrec-1.585,L18-1550,0,0.0367554,"tures on a Danish corpus containing roughly 920 million running words at the time of training, spanning over a variety of text types from between 1982 and 2017, namely newswire, extracts from magazines, transcripts from the Danish parlament, and fiction. The model is trained over 500 features with a symmetric context window size of 5 and a minimum word count of 5 for all word form types. The remaining three word embeddings are trained with fastText (Bojanowski et al., 2017). The wiki embeddings 8 are 300 dimensional and were trained with Skip-Gram on the Danish Wikipedia, the cc embeddings 9 (Grave et al., 2018) are 300 dimensional and were trained with CBOW on the Danish Wikipedia and CommonCrawl, where the language of text was identified with a language detection tool, and the sketchengine word embeddings are 100 dimensional and were trained with Skip-Gram on approximately 2 billion tokens of Danish web text, gathered by SketchEngine10 . All the word embeddings have been evaluated on Danish Similarity Dataset and the Danish Wordsim353. We report the Spearman’s ρ correlation coefficient along with the OOV-rate in Table 3. Model evaluations 6 We evaluate six Danish word embeddings all trained with ei"
2020.lrec-1.585,J15-4004,0,0.0746939,"ansfer more generally; how well a word embedding does at one machine learning task doesn’t 2 The word embedding query is generated using the dsl word embedding model (Sørensen and Nimb, 2018) with the Gensim ˇ uˇrek and Sojka, 2010) library(Reh˚ predict how well it will do at another task of a completely different nature (Bakarov, 2018; Schnabel et al., 2015). In contrast, a much more varied set of methods is those of intrinsic evaluation, which use experiments from cognitive sciences and psycholinguistics to directly explore syntactic or semantic relations between words (Baroni et al., 2014; Hill et al., 2015). Typically, such experiments involve a pre-selected query inventory consisting of word pairs that are then judged based on some criteria of semantic quality, yielding an aggregate score that functions as an absolute gold standard for evaluating the quality of semantic models. Such experiments usually involve crowd sourcing, although automatic extraction of linguistic information through annotated corpora or wordnets have recently become more common (Tsvetkov et al., 2015). Within the group of intrinsic methods of evaluation, the use of word similarity judgements is by far the oldest and most"
2020.lrec-1.585,D15-1242,0,0.0193625,"pplied to a wide variety of tasks without modification, research indicates that it may be beneficial for particular downstream tasks to specialize the model for either similarity or relatedness depending on the downstream task; namely, for applications such as topic modelling or document classification, it might be more interesting to know that ‘seat’ is associated with ‘car’ rather than knowing that ‘car’ is a hyponym of ‘vehicle’, whereas if machine translation, POS tagging, or synonymy detection is the application, relations of similarity are more relevant to achieving an accurate output. (Kiela et al., 2015) demonstrated this by using additional semantic resources to specialize word embeddings for either similarity or relatedness and subsequently comparing the retrofitted models with the unspecified learning approach on a range of extrinsic evaluation tasks, which resulted in a significant improvement on document classification and synonym detection with the tweaked models than with the unspecified approach. For this reason, it is useful for datasets that function as evaluation benchmarks of word embeddings to be explicit about which of these components they measure. However, as hinted earlier, t"
2020.lrec-1.585,N18-1202,0,0.0423802,"ords to ‘radikal’ 11 . Most recent gold standard initiatives address the issue of polysemy by considering words with respect to a context. Namely, Pilehvar and Camacho-Collados (2019) presents a dataset for evaluating context-sensitive word embeddings, in which a target word is evaluated with respect to two contexts represented by text examples. The two text examples then receive a binary label that indicates whether the occurrence of the target word corresponds to the same or a different meaning. Such similarity datasets allow for intrinsic evaluation of the newer contextual word embeddings (Peters et al., 2018; Devlin et al., 2019) as these models rely on the context of a word as a basis for forming word representations. Currently no such pretrained model exists for Danish, however constructing a dataset with words in context would be an interesting research direction to allow for future pretrained Danish contextual word embedding models. Alternatively, in other gold standards, such as the one constructed by Schnabel et al. (2015), participants are asked to rank the similarity of a target word with respect to the query words in a specific word embedding model. While this seems undesirable as a gene"
2020.lrec-1.585,N19-1128,0,0.0185918,"ining corpora of the models than the one measured by the DS dataset; namely, the pair ‘yderlig / radikal’, in which radikal can both denote ‘radical’ and a large Danish political party. In this case, the word yderlig (‘extreme’) suggests that ‘radical’ should be selected by the annotators as the prefered meaning. However, the dsl embeddings suggests ‘konservativ’ and ‘socialdemokratisk’ (‘conservative’ and ‘social democratic’ as the 2 most similar words to ‘radikal’ 11 . Most recent gold standard initiatives address the issue of polysemy by considering words with respect to a context. Namely, Pilehvar and Camacho-Collados (2019) presents a dataset for evaluating context-sensitive word embeddings, in which a target word is evaluated with respect to two contexts represented by text examples. The two text examples then receive a binary label that indicates whether the occurrence of the target word corresponds to the same or a different meaning. Such similarity datasets allow for intrinsic evaluation of the newer contextual word embeddings (Peters et al., 2018; Devlin et al., 2019) as these models rely on the context of a word as a basis for forming word representations. Currently no such pretrained model exists for Dani"
2020.lrec-1.585,D15-1036,0,0.185735,"ts performance on downstream tasks; i.e. it evaluates the ability of word embeddings to be used as feature vectors in a supervised machine learning task. Those tasks are usually computationally expensive, and it is widely agreed upon that those methods don’t transfer more generally; how well a word embedding does at one machine learning task doesn’t 2 The word embedding query is generated using the dsl word embedding model (Sørensen and Nimb, 2018) with the Gensim ˇ uˇrek and Sojka, 2010) library(Reh˚ predict how well it will do at another task of a completely different nature (Bakarov, 2018; Schnabel et al., 2015). In contrast, a much more varied set of methods is those of intrinsic evaluation, which use experiments from cognitive sciences and psycholinguistics to directly explore syntactic or semantic relations between words (Baroni et al., 2014; Hill et al., 2015). Typically, such experiments involve a pre-selected query inventory consisting of word pairs that are then judged based on some criteria of semantic quality, yielding an aggregate score that functions as an absolute gold standard for evaluating the quality of semantic models. Such experiments usually involve crowd sourcing, although automat"
2020.lrec-1.585,D15-1243,0,0.0202926,"gnitive sciences and psycholinguistics to directly explore syntactic or semantic relations between words (Baroni et al., 2014; Hill et al., 2015). Typically, such experiments involve a pre-selected query inventory consisting of word pairs that are then judged based on some criteria of semantic quality, yielding an aggregate score that functions as an absolute gold standard for evaluating the quality of semantic models. Such experiments usually involve crowd sourcing, although automatic extraction of linguistic information through annotated corpora or wordnets have recently become more common (Tsvetkov et al., 2015). Within the group of intrinsic methods of evaluation, the use of word similarity judgements is by far the oldest and most represented evaluation metric in the literature (Bakarov, 2018; Faruqui et al., 2016). The word similarity method is based on the idea that distances between two word vectors in some embedding space can be assessed based on human judgements on the semantic distances between two words, usually normalized to a continuous scale in the interval 01. In the most common evaluation tasks, participants are given a set of manually selected word pairs and asked to assess the degree o"
2021.gwc-1.31,W19-0406,0,0.246278,"to DanNet such as thematic and sentiment information. Finally in Section 6 we conclude. 2. Adjectives in wordnets and similar resources Adjectives are generally recognized as being indeed very challenging to categorize from a lexical-semantic perspective, mainly because of their plasticity in the sense that they have an extreme ability to take colour from their surroundings. In other words, a core semantic description which is somewhat stable across a certain number of contexts seems even more difficult to provide for adjectives than for other content words (cf. Cruse 1986; Pustejovsky 1995; Bick 2019; Peters & Peters, 2000; and others). While the structuring feature of wordnets is basically the hyponymy relation between synsets, it has been argued that adjectives are maybe better characterized by their polarity and antonymy relations, their scalarity, their connotation (positive, negative), or simply by the semantics of the external argument (typically a noun) that they prototypically affiliate to. Consequently, in many wordnets adjectives are to some extent only rudimentarily described and with a not too specific taxonomic labeling. This can be seen as a pragmatic approach in order to be"
2021.gwc-1.31,bel-etal-2000-simple,0,0.243264,"a specific class hierarchy for adjectives of around 100 types relating basically to the semantics of the prototypical external argument of the adjective. Maziarz et al. (2015) describes a set of adjective relations in the Polish WordNet 2.0 based on the principles of especially PWN and EuroWordNet combined with specific lexico-semantic features of the Polish language. Bick (2019) also suggests an annotation scheme of approx 100 taxonomically structured tags partly based on the semantics of the external argument (such as Human, Action, and Semiotic product etc.). In comparison, Peters & Peters (2000) provides a slightly different description model for adjectives with a primary distinction between Intentional (as in former president) and Extensional (as in American president), respectively, and a further subdivision according to meaning components such as social, physical, temporal, intensifying etc. The model was developed for the computational lexicon project SIMPLE (Lenci et al. 2001), but was to our knowledge never implemented at a larger scale maybe due to its complexity. Previous pilot studies on the Danish adjectival data (Nimb & Pedersen 2012) support the idea that the semantics of"
2021.gwc-1.31,peters-peters-2000-treatment,0,0.641032,"such as thematic and sentiment information. Finally in Section 6 we conclude. 2. Adjectives in wordnets and similar resources Adjectives are generally recognized as being indeed very challenging to categorize from a lexical-semantic perspective, mainly because of their plasticity in the sense that they have an extreme ability to take colour from their surroundings. In other words, a core semantic description which is somewhat stable across a certain number of contexts seems even more difficult to provide for adjectives than for other content words (cf. Cruse 1986; Pustejovsky 1995; Bick 2019; Peters & Peters, 2000; and others). While the structuring feature of wordnets is basically the hyponymy relation between synsets, it has been argued that adjectives are maybe better characterized by their polarity and antonymy relations, their scalarity, their connotation (positive, negative), or simply by the semantics of the external argument (typically a noun) that they prototypically affiliate to. Consequently, in many wordnets adjectives are to some extent only rudimentarily described and with a not too specific taxonomic labeling. This can be seen as a pragmatic approach in order to be able to cope with thei"
alonso-etal-2012-voting,W99-0512,0,\N,Missing
alonso-etal-2012-voting,markert-nissim-2002-towards,0,\N,Missing
alonso-etal-2012-voting,bel-etal-2000-simple,1,\N,Missing
alonso-etal-2012-voting,N01-1010,0,\N,Missing
alonso-etal-2012-voting,N07-2002,1,\N,Missing
alonso-etal-2012-voting,E09-1005,0,\N,Missing
alonso-etal-2012-voting,E09-1045,0,\N,Missing
alonso-etal-2012-voting,W04-1908,0,\N,Missing
alonso-etal-2012-voting,C04-1133,0,\N,Missing
alonso-etal-2012-voting,W09-3716,0,\N,Missing
alonso-etal-2012-voting,J03-2004,0,\N,Missing
alonso-etal-2012-voting,H92-1045,0,\N,Missing
alonso-etal-2012-voting,S10-1005,0,\N,Missing
alonso-etal-2012-voting,pustejovsky-etal-2006-towards,0,\N,Missing
alonso-etal-2012-voting,jezek-quochi-2010-capturing,0,\N,Missing
de-smedt-etal-2014-clara,Y12-1015,0,\N,Missing
de-smedt-etal-2014-clara,W11-2153,0,\N,Missing
de-smedt-etal-2014-clara,W12-3903,0,\N,Missing
de-smedt-etal-2014-clara,W11-2605,0,\N,Missing
de-smedt-etal-2014-clara,W13-1728,0,\N,Missing
de-smedt-etal-2014-clara,R11-1041,1,\N,Missing
de-smedt-etal-2014-clara,W11-4647,0,\N,Missing
de-smedt-etal-2014-clara,W13-2907,1,\N,Missing
de-smedt-etal-2014-clara,W11-4604,1,\N,Missing
de-smedt-etal-2014-clara,P13-1054,1,\N,Missing
de-smedt-etal-2014-clara,Y12-1014,0,\N,Missing
de-smedt-etal-2014-clara,P11-3013,0,\N,Missing
de-smedt-etal-2014-clara,ramasamy-zabokrtsky-2012-prague,0,\N,Missing
de-smedt-etal-2014-clara,W13-2805,0,\N,Missing
de-smedt-etal-2014-clara,larasati-2012-identic,0,\N,Missing
de-smedt-etal-2014-clara,alonso-etal-2012-voting,1,\N,Missing
de-smedt-etal-2014-clara,W12-3410,0,\N,Missing
de-smedt-etal-2014-clara,drobac-etal-2014-heuristic,1,\N,Missing
de-smedt-etal-2014-clara,P13-2127,1,\N,Missing
de-smedt-etal-2014-clara,W11-4406,0,\N,Missing
de-smedt-etal-2014-clara,dione-2014-pruning,0,\N,Missing
de-smedt-etal-2014-clara,R11-2019,0,\N,Missing
de-smedt-etal-2014-clara,W12-6304,0,\N,Missing
de-smedt-etal-2014-clara,W14-1203,1,\N,Missing
de-smedt-etal-2014-clara,W12-5017,0,\N,Missing
de-smedt-etal-2014-clara,lis-2012-polish,0,\N,Missing
de-smedt-etal-2014-clara,W14-0808,0,\N,Missing
de-smedt-etal-2014-clara,schumann-2012-knowledge,0,\N,Missing
de-smedt-etal-2014-clara,C12-1065,1,\N,Missing
de-smedt-etal-2014-clara,dione-2012-morphological,0,\N,Missing
de-smedt-etal-2014-clara,escartin-2012-design,0,\N,Missing
de-smedt-etal-2014-clara,W12-2019,1,\N,Missing
de-smedt-etal-2014-clara,lenkiewicz-etal-2012-avatech,1,\N,Missing
de-smedt-etal-2014-clara,W11-3302,1,\N,Missing
de-smedt-etal-2014-clara,escartin-2014-chasing,0,\N,Missing
de-smedt-etal-2014-clara,W12-0503,0,\N,Missing
de-smedt-etal-2014-clara,W13-5411,1,\N,Missing
de-smedt-etal-2014-clara,gebre-etal-2012-towards,1,\N,Missing
henriksen-etal-2014-encompassing,pedersen-etal-2010-merging,1,\N,Missing
henriksen-etal-2014-encompassing,W14-0147,0,\N,Missing
henriksen-etal-2014-encompassing,W13-5616,1,\N,Missing
L16-1136,J08-4004,0,0.173758,"an blogs and chat, probably because the language of these text types is intrinsically more complex and contains more abstract concepts (for a detailed study on domain differences in the annotations see Olsen et al. 2015). Figure 2 shows how each noun supersense is represented disagreement-wise in the corpus. The rows in the disagreement plot are sorted after the size of the diagonal value. Rows with many large, spread boxes indicate supersenses with low agreement which need a closer examination or more precise guidelines. For 2 http://wordnet.princeton.edu/wordnet/man/lexnames.5WN.ht ml 3 Cf. Artstein & Poesio 2008 for discussion of agreement scores in computational linguistics. 843 instance, the supersenses n.person and n.institution seem to be hard for the annotators to distinguish from each other, whereas n.disease has proven easy to identify. a set of precise guidelines defining the sense structuring principles. In rough terms, these principles were based on the distinctions between core and subsenses as defined by Cruse (2000:110ff). Among several types of regular relations between senses, Cruse defines four types where the senses might be of the same ontological type (and therefore candidates of c"
L16-1136,brown-etal-2010-number,0,0.026183,"ent words are annotated (so-called lexical sample corpora). As discussed in Ide & Wilks (2007), Kilgarriff (2007) and others, defining appropriate sense inventories for annotation and word sense disambiguation tasks is however a very hard task. The need for coarser and more manageable sense inventories has emerged, partly driven by poor sense annotator agreement scores in the aforementioned annotations. This has resulted in a series of annotation experiments applying manually and automatically clustered senses, as seen in Agirre & Lacalle (2003), Palmer et al. (2007), Passonneau et al. (2012) Brown et al. (2010), de Melo et al. (2012), and others. The need for “light weight” semantic annotations has led researchers to focus also on very coarse word sense annotation applying so-called supersenses that are derived from the list of WordNet’s first beginners or lexicographical files. This approach is becoming a de facto standard in recent years (Ciaramita & Johnson 2003, Qiu et al. 2011, Schneider et al. 2012). In the SemDaX corpus we include both supersense annotations and lexical sample annotations with fine-grained and automatically clustered senses for a selected set of highly ambiguous nouns. All an"
L16-1136,S14-1001,1,0.848737,"Missing"
L16-1136,W15-1831,1,0.907794,"that the coarse-grained supersense scheme is quite manageable to the annotators resulting in an acceptable agreement of 0.62 applying Krippendorff’s α. However, as shown in the dispersion plot in Figure 1 the scheme leaves room for improvements and adjustments; i.e. some particular supersenses prove very hard to agree upon. Further, the considerable information loss in the coarse annotations should be addressed in future extrinsic evaluations; for instance, it can be questioned to which extent we actually capture the practically relevant ambiguities with this coarse scheme; see also Martínez Alonso et al. 2015 for a first attempt of inducing a supersense tagger from our 6 Note that the supersense scheme is not directly comparable to the fine-grained schemes since the annotation tasks differ (all-word vs. lexical sample). 845 supersense annotations. This leads us to the finer-grained dictionary-driven annotations of highly ambiguous nouns that we described in Section 4. Here we can conclude that a clustered annotation scheme based on an ontologically driven collapsing of subsenses performs substantially better than a fully fine-grained scheme (disregarding here the better chance of agreeing on few t"
L16-1136,W15-1806,1,0.857672,"Missing"
L16-1136,2016.gwc-1.30,1,0.534761,"Missing"
L16-1136,W15-2005,1,0.784725,"Missing"
L16-1136,passonneau-etal-2012-masc,0,0.047019,"Missing"
L16-1136,E14-1078,1,0.850484,"flecting formal distinctions or logical relations between senses of the word in question. Not only does doubly annotated data provide valuable feedback regarding the annotation schemes, we also think that it can help us improve our learning algorithms. Our corpus is about one fifth of the size of SemCor. However, as mentioned, a large part of the data has been doubly annotated and later adjudicated. We make available both the final adjucated version and the individual annotations in order to facilitate research that deals with the linguistic information that resides in agreement variation. In Plank et al. (2014) and Martínez Alonso et al. (2015a) we present an algorithm that learns regularizers from small seeds of doubly annotated data. In future work we will apply SemDaX for further experiments along the same lines. Finally, our project includes a pilot study on the compilation of a Danish framenet (similar to the well-known Berkeley FrameNet, cf. https://framenet.icsi.berkeley.edu/fndrupal/). This part of the project has been embarked recently by focusing on the approx. 1/3 of the sentences of our corpus where cognition and communication verbs are present (identified via the previously mentioned su"
L16-1136,P12-2050,0,0.0982508,"ations. This has resulted in a series of annotation experiments applying manually and automatically clustered senses, as seen in Agirre & Lacalle (2003), Palmer et al. (2007), Passonneau et al. (2012) Brown et al. (2010), de Melo et al. (2012), and others. The need for “light weight” semantic annotations has led researchers to focus also on very coarse word sense annotation applying so-called supersenses that are derived from the list of WordNet’s first beginners or lexicographical files. This approach is becoming a de facto standard in recent years (Ciaramita & Johnson 2003, Qiu et al. 2011, Schneider et al. 2012). In the SemDaX corpus we include both supersense annotations and lexical sample annotations with fine-grained and automatically clustered senses for a selected set of highly ambiguous nouns. All annotations in the corpus rely on the combined wordnet and dictionary resources: DanNet (cf. Pedersen 2009 et al.) and a comprehensive monolingual, corpus-based dictionary of modern Danish, Den Danske Ordbog (DDO, Hjorth et al. 2005), which share sense identifies. The aim of the corpus is twofold: i) to assess the reliability of the different sense annotation schemes in terms of different levels of gr"
L16-1136,P13-4001,0,0.0740307,"Missing"
L16-1136,J99-4008,0,0.0763419,"Missing"
L16-1136,W14-0132,0,0.160111,"Missing"
L16-1136,W03-1022,0,\N,Missing
L18-1378,L16-1136,1,0.763918,"nyms and near synonyms of skælde ud ‘to scold’. Having detected a group of closely related verbs and verbal nouns and furthermore supplied the verbs with valency patterns from DDO via the common id numbers, the editor would search for an appropriate frame in BFN and assign this to the particular group (shown in Figure 3). In this way, a relative large framenet lexicon is being compiled with relatively little effort2. In order to easily access examples which would evoke frames relating to communication and cognition, we took advantage of the coarse sense annotations available in SemDax corpus (Pedersen et al 2016) and extracted all sentences annotated with either cognition and communication events (or both)3. This extraction also enabled us to prove whether a frame lexicon based on thesaurus vocabulary was actually extensive enough. Not surprisingly, however, not all groups were equally easy to assign frames to since the relation between DT and BFN was obviously not one-to-one in all semantic areas. A classic example is the discrepancy related to antonymous word senses such as remembering and forgetting which are covered by one frame (seen as the We used an open source, browser-based framenet annotatio"
L18-1378,P15-1109,0,0.0218073,"ce. The top frames subsume a total of 6 distinct frames, making this a 6way multinomial classification problem. However, for some verbs, frames were missing because the specific sense had not been foreseen in the frame lexicon based on the DT vocabulary. The largest part of these were ad hoc (figurative) senses not to be included in the frame lexicon (nor in the dictionaries), but there were also cases which led us to expand the lexicon, e.g. cognition verbs with communication senses in corpus but not included in the thesaurus chapters on 2384 Inspired by recent semantic parsing models, e.g., Zhou and Xu (2015), we use a set of binary deep, bidirectional Long Short Term Memory (LSTM) networks to predict frame labels. Each network predicts a single label, and we evaluate each network individually by computing sentence-level F1-scores. English-Danish Ours Statement 0.31 Opinion 0.16 Telling 0.13 Text_creation 0.08 Becoming_aware 0.06 Certainty 0.08 In the following, we report implementation details and results for our experiments in the frame prediction task. We ran experiments in three setups.    Table 1: Supervised and unsupervised F1-scores for the 6 most frequent frames. First, we trained the m"
L18-1378,candito-etal-2014-developing,0,0.304605,"Missing"
L18-1378,heppin-gronostaj-2012-rocky,0,0.0192275,"ncluding verbal nouns and annotated with type 08 (acts) and semantic relations. We rely on two assumptions:  that our frame lexicon will ease annotation considerably since a very limited set of possible frames for a given word is presented to the annotator via the annotation tool, and  that BFN frames for English can be more or less directly transferred to Danish; in other words, that the same frame elements or semantic roles can be identified in a Danish textual context with a particular frame. (A similar approach is taken for most other framenets being built for a number of languages, cf. Heppin & Gronostaj 2012, 2014 for Swedish, Candito et al. 2014 for French, Ohara 2014 for Japanese). In order to test this approach, we annotated 440 sentences from the corpus with their corresponding frames and frame elements. The sentences from SemDax cover a variety of text types such as blog, chat, forum, magazine, Parliament debates (written down by professionals), and newswire, of which the latter constitutes almost half of the corpus. Figure 3: Mapping Berkeley frames onto thematically ordered verb groups from DT, in this case synonyms and near synonyms of skælde ud ‘to scold’. Having detected a group of clos"
L18-1378,D12-1127,0,0.035249,"Missing"
L18-1378,2016.gwc-1.30,1,0.861399,"Missing"
L18-1378,ohara-2014-relating,0,0.0194793,"ons. We rely on two assumptions:  that our frame lexicon will ease annotation considerably since a very limited set of possible frames for a given word is presented to the annotator via the annotation tool, and  that BFN frames for English can be more or less directly transferred to Danish; in other words, that the same frame elements or semantic roles can be identified in a Danish textual context with a particular frame. (A similar approach is taken for most other framenets being built for a number of languages, cf. Heppin & Gronostaj 2012, 2014 for Swedish, Candito et al. 2014 for French, Ohara 2014 for Japanese). In order to test this approach, we annotated 440 sentences from the corpus with their corresponding frames and frame elements. The sentences from SemDax cover a variety of text types such as blog, chat, forum, magazine, Parliament debates (written down by professionals), and newswire, of which the latter constitutes almost half of the corpus. Figure 3: Mapping Berkeley frames onto thematically ordered verb groups from DT, in this case synonyms and near synonyms of skælde ud ‘to scold’. Having detected a group of closely related verbs and verbal nouns and furthermore supplied th"
L18-1378,E17-1072,1,0.71927,"ntic areas of motion, emotion, communication and cognition. Figure 1: A wordnet (DanNet), a framenet and a semantically annotated corpus (SemDax) expanded from two dictionaries via common sense ids The paper is organized as follows. Below we sketch out how we, in order to test the strength of the lexical working method, started by compiling a pilot frame lexicon based on only two selected semantic domains in existing lexica (Section 2). Section 3 describes how we used the resulting set of frames to annotate selected languages (cf. Pedersen et al. 2009, Nimb et al. 2017, Johannsen et al. 2015, Levy et al. 2017). In order to enable this combination of methods, quite a lot of effort has been put into relating the resources to international standards (see for instance Martinez et al. 2016). 1 The Danish frame lexicon is now freely available at https://github.com/dsldk/dansk-frame-net. It will be presented in more detail at The International FrameNet Workshop 2018, Multilingual FrameNets and Constructions at LREC 2018 (Nimb, submitted for review). Most recently, effort has been put into compiling a Danish Berkeley style (Ruppenhofer et al. 2016) frame lexicon (BFN) by extracting semantic data from The 2"
navarretta-etal-2004-human,J90-1003,0,\N,Missing
navarretta-etal-2004-human,bel-etal-2000-simple,0,\N,Missing
nimb-pedersen-2012-towards,kunze-2000-extension,0,\N,Missing
P13-2127,J08-4004,0,0.183848,"20 171 298 82 95 140 139 U 7 54 25 22 48 91 83 69 47 V 3 8 0 3 3 53 44 54 40 B 4 48 25 19 45 38 39 15 7 Table 3: Literal, Metonymic and Underspecified sense distributions, and underspecified senses broken down in Voting and Backoff Average observed agreement (Ao ) is the mean across examples for the proportion of matching senses assigned by the annotators. Krippendorff’s alpha is an aggregate measure that takes chance disagreement in consideration and accounts for the replicability of an annotation scheme. There are large differences in α across datasets. The scheme can only provide reliable (Artstein and Poesio, 2008) annotations (α &gt; 0.6) for one dot type2 . This indicates that not all dot types are equally easy to annotate, regardless of the kind of annotator. In spite of the number and type of annotators, the Location/Organization dot type gives fairly high agreement values for a semantic task, and this behavior is consistent across languages. The columns labelled L, M and U in Table 3 provide the sense distributions for each dot type. The preference for the underspecified sense varies greatly, from the very infrequent for English in Animal/Meat to the two Danish datasets where the underspecified sense"
P13-2127,J12-3005,0,0.0920653,"s, the results in terms of inter-encoder agreement, and the sense distributions obtained with two methods: majority voting with a theory-compliant backoff strategy, and MACE, an unsupervised system to choose the most likely sense from all the annotations. 1 ´ Nuria Bel Universitat Pompeu Fabra Barcelona (Spain) nuria.bel@upf.edu Introduction This article shows the annotation task of a corpus in English, Danish and Spanish for regular polysemy. Regular polysemy (Apresjan, 1974; Pustejovsky, 1995; Briscoe et al., 1995; Nunberg, 1995) has received a lot of attention in computational linguistics (Boleda et al., 2012; Rumshisky et al., 2007; Shutova, 2009). The lack of available senseannotated gold standards with underspecification is a limitation for NLP applications that rely on dot types1 (Rumshisky et al., 2007; Poibeau, 2006; Pustejovsky et al., 2009). Our goal is to obtain human-annotated corpus data to study regular polysemy and to detect it in an automatic manner. We have collected a corpus of annotated examples in English, Danish and Spanish to study the alternation between senses and the cases of underspecification, including a contrastive study between languages. Here we describe the annotation"
P13-2127,W09-3716,0,0.0271131,"the annotations. 1 ´ Nuria Bel Universitat Pompeu Fabra Barcelona (Spain) nuria.bel@upf.edu Introduction This article shows the annotation task of a corpus in English, Danish and Spanish for regular polysemy. Regular polysemy (Apresjan, 1974; Pustejovsky, 1995; Briscoe et al., 1995; Nunberg, 1995) has received a lot of attention in computational linguistics (Boleda et al., 2012; Rumshisky et al., 2007; Shutova, 2009). The lack of available senseannotated gold standards with underspecification is a limitation for NLP applications that rely on dot types1 (Rumshisky et al., 2007; Poibeau, 2006; Pustejovsky et al., 2009). Our goal is to obtain human-annotated corpus data to study regular polysemy and to detect it in an automatic manner. We have collected a corpus of annotated examples in English, Danish and Spanish to study the alternation between senses and the cases of underspecification, including a contrastive study between languages. Here we describe the annotation process, its results in terms of inter-encoder agreement, and the sense distributions obtained with two methods: majority voting with a theory-compliant backoff strategy and, MACE an unsupervised system to choose the most likely sense from all"
P13-2127,gonzalez-agirre-etal-2012-multilingual,0,0.0239491,"responding dot type. In spite of a part of the annotation being made with a contrastive study in mind, no parallel text was used to avoid using translated text. For English and Danish we used freely available reference corpora (Ide and Macleod, 2001; Andersen et al., 2002) and, for Spanish, a corpus built from newswire and technical text (Vivaldi, 2009). For most of the English examples we used the words in Rumshisky (2007), except for Location/Organization. For Danish and Spanish we translated the words from English. We expanded the lists using each language’s wordnet (Pedersen et al., 2009; Gonzalez-Agirre et al., 2012) as thesaurus to make the total of occurrences reach 500 after we had removed homonyms and other forms of semantic variation outside of the purview of regular polysemy. For Location/Organization we have used highfrequency names of geopolitical locations from each of the corpora. Many of them are corpusspecific (e.g. Madrid is more frequent in the Spanish corpus) but a set of words is shared: Afghanistan, Africa, America, China, England, Europe,Germany, London. Every dot type has its particularities that we had to deal with. For instance, English has lexical alFigure 1: Screen capture for a Mec"
P13-2127,N13-1132,0,0.0505433,"Missing"
P13-2127,P09-3001,0,0.0176863,"ement, and the sense distributions obtained with two methods: majority voting with a theory-compliant backoff strategy, and MACE, an unsupervised system to choose the most likely sense from all the annotations. 1 ´ Nuria Bel Universitat Pompeu Fabra Barcelona (Spain) nuria.bel@upf.edu Introduction This article shows the annotation task of a corpus in English, Danish and Spanish for regular polysemy. Regular polysemy (Apresjan, 1974; Pustejovsky, 1995; Briscoe et al., 1995; Nunberg, 1995) has received a lot of attention in computational linguistics (Boleda et al., 2012; Rumshisky et al., 2007; Shutova, 2009). The lack of available senseannotated gold standards with underspecification is a limitation for NLP applications that rely on dot types1 (Rumshisky et al., 2007; Poibeau, 2006; Pustejovsky et al., 2009). Our goal is to obtain human-annotated corpus data to study regular polysemy and to detect it in an automatic manner. We have collected a corpus of annotated examples in English, Danish and Spanish to study the alternation between senses and the cases of underspecification, including a contrastive study between languages. Here we describe the annotation process, its results in terms of inter-"
P13-2127,D08-1027,0,0.254133,"Missing"
P13-2127,J03-2004,0,0.0295571,") (ANC): a) Manuel died in exile in 1932 in England. b) England was being kept busy with other concerns c) England was, after all, an important wine market In case a), England refers to the English territory (Location), whereas in b) it refers arguably to England as a political entity (Organization). The third case refers to both. The ability of certain words to switch between semantic types in a predictable manner is referred to as regular polysemy. Unlike other forms of meaning variation caused by metaphor or homonymy, regular polysemy is considered to be caused by metonymy (Apresjan, 1974; Lapata and Lascarides, 2003). Regular polysemy is different from other forms of polysemy in that both senses can be active at the same in a predicate, which we refer to as underspecification. Underspecified instances can be broken down in: 1. Contextually complex: England was, after all, an important wine market 2. Zeugmatic, in which two mutually exclusive readings are coordinated: England is conservative and rainy 3. Vague, in which no contextual element enforces a reading: The case of England is similar We present the result of an annotation task on regular polysemy for a series of semantic classes or dot types in Eng"
P13-2127,markert-nissim-2002-towards,0,0.152885,"locations from each of the corpora. Many of them are corpusspecific (e.g. Madrid is more frequent in the Spanish corpus) but a set of words is shared: Afghanistan, Africa, America, China, England, Europe,Germany, London. Every dot type has its particularities that we had to deal with. For instance, English has lexical alFigure 1: Screen capture for a Mechanical Turk annotation instance or HIT This annotation scheme is designed with the intention of capturing literal, metonymic and underspecified senses, and we use an inventory of three possible answers, instead of using Markert and Nissim’s (Markert and Nissim, 2002; Nissim and Markert, 2005) approach with fine-grained sense distinctions, which are potentially more difficult to annotate and resolve automatically. Markert and Nissim acknowledge a mixed sense they define as being literal and metonymic at the same time. For English we used Amazon Mechanical Turk (AMT) with five annotations per example by turkers certified as Classification Masters. Using AMT provides annotations very quickly, possibly at the expense of reliability, but it has been proven suitable for sense-disambiguation task (Snow et al., 2008). Moreover, it is not possible to obtain annot"
P13-2127,D12-1017,0,0.0680757,"Table 5 breaks down the five annotations that each example received by turkers in literal, metonymic and underspecified. The last two columns show the sense tag provided by voting or MACE. Example d) e) f) g) h) i) j) L 2 3 1 2 2 3 1 M 2 1 2 2 2 0 2 U 1 1 2 1 1 2 2 VOTING U L M U U L M Conclusions MACE L U U M M U U 9 Table 5: Annotation summary and sense tags for the examples in this section Further work After collecting annotated data, the natural next step is to attempt class-based word-sense disambiguation (WSD) to predict the senses in Tables 3 and 4 using a state-of-the-art system like Nastase et al. (2012). We will consider a sense-assignment method (voting or MACE) as more appropriate if it provides the sense tags that are easiest to learn by our WSD system. However, learnability is only one possible parameter for quality, and we also want to develop an expert-annotated gold standard to compare our data against. We also consider the possibility of developing a sense-assignment method that relies both on the theoretical assumption behind the voting scheme and the latent-variable approach used by MACE. Just by looking at the table it is not immediate which method is preferable to assign sense ta"
pedersen-2006-query,braasch-olsen-2004-sto,0,\N,Missing
pedersen-etal-2008-merging,bel-etal-2000-simple,0,\N,Missing
pedersen-etal-2008-merging,braasch-olsen-2004-sto,1,\N,Missing
pedersen-etal-2010-merging,W09-4645,0,\N,Missing
pedersen-paggio-2002-semantic,bel-etal-2000-simple,0,\N,Missing
rehm-etal-2014-strategic,P07-2045,0,\N,Missing
rehm-etal-2014-strategic,piperidis-etal-2014-meta,1,\N,Missing
rehm-etal-2014-strategic,piperidis-2012-meta,1,\N,Missing
vasiljevs-etal-2012-creation,steinberger-etal-2006-jrc,0,\N,Missing
vasiljevs-etal-2012-creation,W11-3314,1,\N,Missing
vasiljevs-etal-2012-creation,W11-4643,1,\N,Missing
vasiljevs-etal-2012-creation,borin-etal-2012-open,1,\N,Missing
W09-4623,esuli-sebastiani-2006-sentiwordnet,0,0.0593729,"Missing"
W09-4623,J99-4008,0,0.0533242,"Missing"
W09-4623,bel-etal-2000-simple,0,\N,Missing
W11-4604,E09-1005,0,0.0130194,"which is related to the lack of strategies to capture meaning underspecification. 3 State of the art The computational study of systematic polysemy has been geared to the collapsing of senses (Vossen et al., 1999; Buitelaar, 1998; Tomuro, 2001) prior to Word Sense Disambiguation (WSD). The best performance in WSD is obtained by supervised methods that require a very large amount of annotated learning data. The other main approach is to use a lexical knowledge base such as WordNet and a PageRank algorithm to compute the most likely sense in the sense enumeration of the lexical knowledge base (Agirre and Soroa, 2009). WordNet does not include the Location/Organization alternation in geopolitical locations, so the task at hands falls outside the traditional scope of WSD. The field of Named Entity Recognition (NER) shows two different approaches to regular-polysemy based sense alternations. In their account, Johannessen et al. (2005) differentiate what they call the Form over Function and the Function over Form strategy. Some NER systems assign a constant value to a word type, enforcing what Finkel et al. (2005) call label consistency, namely Form over Function. The Function over Form strategy, however, ass"
W11-4604,P05-1045,0,0.00423742,"ithm to compute the most likely sense in the sense enumeration of the lexical knowledge base (Agirre and Soroa, 2009). WordNet does not include the Location/Organization alternation in geopolitical locations, so the task at hands falls outside the traditional scope of WSD. The field of Named Entity Recognition (NER) shows two different approaches to regular-polysemy based sense alternations. In their account, Johannessen et al. (2005) differentiate what they call the Form over Function and the Function over Form strategy. Some NER systems assign a constant value to a word type, enforcing what Finkel et al. (2005) call label consistency, namely Form over Function. The Function over Form strategy, however, assigns a semantic type to the analyzed word depending on how it behaves in each context and is analogous to the work exposed in this article. A class of nominals that shows regular polysemy and is well studied is the deverbal noun (destruction, examination), which has distinct grammatical features that can help pinpoint its reading as either process or result, as covered in theory by Grimshaw (1990) and computationally acknowledged by Peris et al. (2009). There is also recent work in the identificati"
W11-4604,H92-1045,0,0.0794082,"lgarrif et al, 2004), which has only been used to establish the nominal word space. No other external resources like FrameNet or WordNet have been used, following Markert and Nissim’s (2009) claim that grammatical features tend to be the most discriminating features. For similar remarks, cf. Peris (2009), Rumshisky (2007). The hypotheses that regular polysemy alternations are often determined at subphrasal level can contradict traditional WSD algorithms like Page Rank, which have a larger scope of analysis. Selection of metonymical senses falls outside of the One-sense-per-discourse approach (Gale et al., 1992), since such approach has been phrased reLexical and grammatical features Figure 1: word sketch for ""country"" 21 Hector Martinez Alonso, Nuria Bel and Bolette Sandford Pedersen ´ 5.2 Following Joanis et al. (2006), the occurrences have been characterized in order to assess the amount of semantic information that their distributional data can provide. The total size of the feature space is of 317 binary features, divided as follows: 1. NP-traits (6 features): which describe the internal structure of the NP where t appears. The features indicate the presence of an adjective in the NP, of a commo"
W11-4604,J03-2004,0,0.0527164,"Missing"
W11-4604,S10-1005,0,0.0215225,"ng on how it behaves in each context and is analogous to the work exposed in this article. A class of nominals that shows regular polysemy and is well studied is the deverbal noun (destruction, examination), which has distinct grammatical features that can help pinpoint its reading as either process or result, as covered in theory by Grimshaw (1990) and computationally acknowledged by Peris et al. (2009). There is also recent work in the identification of metonymy (Markert and Nissim, 2009) as well as other Generative-Lexicon based sensedisambiguation works, such as Rumshisky et al. (2007) or Pustejovsky et al. (2010). Disambiguation systems, however, are still coping with the need of a representation and recognition of underspecification (Pustejovsky, 2009). The SIMPLE lexicon (Lenci et al., 2000) is a GL-compliant lexicon for twelve European languages. It describes its lexical items in terms of their position within a type ontology as well as 19 Hector Martinez Alonso, Nuria Bel and Bolette Sandford Pedersen ´ a qualia structure. SIMPLE list the Geopolitical Location class as a class associated to a complex type <Location,Human_Group>, which expresses the dot-type ambiguity of words of this class. Words"
W11-4604,N01-1010,0,0.0157248,"which can be seen a kind of underspecification. In spite of the GL's computational perspective, Natural Language Processing (NLP) implementations that examine the actual computational feasibility of the GL are few. Moreover, there is no overt attempt to identify the possible three behaviors of a dot type, as the dot predication has not been computationally tackled, which is related to the lack of strategies to capture meaning underspecification. 3 State of the art The computational study of systematic polysemy has been geared to the collapsing of senses (Vossen et al., 1999; Buitelaar, 1998; Tomuro, 2001) prior to Word Sense Disambiguation (WSD). The best performance in WSD is obtained by supervised methods that require a very large amount of annotated learning data. The other main approach is to use a lexical knowledge base such as WordNet and a PageRank algorithm to compute the most likely sense in the sense enumeration of the lexical knowledge base (Agirre and Soroa, 2009). WordNet does not include the Location/Organization alternation in geopolitical locations, so the task at hands falls outside the traditional scope of WSD. The field of Named Entity Recognition (NER) shows two different a"
W11-4604,W99-0512,0,0.0491728,"ible senses as most salient, as in k), which can be seen a kind of underspecification. In spite of the GL's computational perspective, Natural Language Processing (NLP) implementations that examine the actual computational feasibility of the GL are few. Moreover, there is no overt attempt to identify the possible three behaviors of a dot type, as the dot predication has not been computationally tackled, which is related to the lack of strategies to capture meaning underspecification. 3 State of the art The computational study of systematic polysemy has been geared to the collapsing of senses (Vossen et al., 1999; Buitelaar, 1998; Tomuro, 2001) prior to Word Sense Disambiguation (WSD). The best performance in WSD is obtained by supervised methods that require a very large amount of annotated learning data. The other main approach is to use a lexical knowledge base such as WordNet and a PageRank algorithm to compute the most likely sense in the sense enumeration of the lexical knowledge base (Agirre and Soroa, 2009). WordNet does not include the Location/Organization alternation in geopolitical locations, so the task at hands falls outside the traditional scope of WSD. The field of Named Entity Recogni"
W11-4604,bel-etal-2000-simple,1,0.673715,"on, examination), which has distinct grammatical features that can help pinpoint its reading as either process or result, as covered in theory by Grimshaw (1990) and computationally acknowledged by Peris et al. (2009). There is also recent work in the identification of metonymy (Markert and Nissim, 2009) as well as other Generative-Lexicon based sensedisambiguation works, such as Rumshisky et al. (2007) or Pustejovsky et al. (2010). Disambiguation systems, however, are still coping with the need of a representation and recognition of underspecification (Pustejovsky, 2009). The SIMPLE lexicon (Lenci et al., 2000) is a GL-compliant lexicon for twelve European languages. It describes its lexical items in terms of their position within a type ontology as well as 19 Hector Martinez Alonso, Nuria Bel and Bolette Sandford Pedersen ´ a qualia structure. SIMPLE list the Geopolitical Location class as a class associated to a complex type <Location,Human_Group>, which expresses the dot-type ambiguity of words of this class. Words that are considered geopolitical locations can be proper (Africa, Boston, China) or common (city, nation, state, etc) nouns. 4 Experiment We propose a classification experiment that id"
W11-4604,C10-1006,1,\N,Missing
W13-5616,bhattacharyya-2010-indowordnet,0,0.0392967,"omplete or missing synsets in one or another of the wordnets (Tufis, Ion & Ide 2004). Other works included mapping algorithms for aligning, tuning and validating wordnets as presented in Daudé, Padró & Rigau 1999, & Daudé, Padró & Rigau 2003 and several others. More recent collaborative wordnet projects include MultiWordNet (http://multiwordnet.itc.it) which relates Italian and Princeton wordnets, Asian WordNet which also applies the expand method for several Asian languages through a common management interface (Robkop et al. 2010), and IndoWordNet which include a series of Indian languages (Bhattacharyya 2010). Last but not least should be mentioned a recent initiative, Open Multilingual WordNet http://casta-net.jp/~kuribayashi/multi/ which aligns wordnets available through the Global WordNet Association’s WordNet Grid (http://www.globalwordnet.org/gwa/gwa_grid.html). In contrast, several recent European wordnets that have typically been compiled on a more local basis apply the merge technique (cf. Derwojedowa 2008, Borin & Forsberg 2010, Pedersen et al. 2009) applying monolingual language resources such as existing dictionaries and corpora as the initial source. There are obvious risks related to"
W13-5616,W99-0603,0,0.160623,"Missing"
W13-5616,W11-4643,1,0.771943,"Ties (wordties.cst.dk) is a web interface developed to visualize monolingual wordnets as well as their alignments with the other wordnets, cf. Figure 1. In this browser the user can chose either of the (currently four) relevant wordnets as a source language and see how a concept is linked to its sister wordnets. Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 152 of 474] Figure 1: Introductory screen of WordTies WordTies builds on a monolingual browser, AndreOrd, which was built to browse DanNet, cf. Johannsen & Pedersen (2011). In this browser, the semantic relations are made available in a more graphical fashion compared to what is found in most other wordnet browsers which tend to focus primarily on visualizing the hyponymy structure of the wordnet. The particular choice of graph very compactly encodes large numbers of relations – each represented by its own colour – and thus gives a good overview of the general structure of the wordnet. In order to make room for all relations in the graph – also the inherited ones –, only one representative sense is visualized per synset. However, all senses are presented below"
W13-5616,W05-1715,0,0.035094,"nd the agentive role (purpose and origin). Qualia roles are encoded in DanNet in terms of relations such as used_for and made_by as well as by means of features such as SEX and CONNOTATION. DanNet is licensed under the Princeton WordNet licence. 3.5 Swedish wordnet (Swesaurus) Swesaurus (Borin & Forsberg 2010, Borin & Forsberg 2011) is a Swedish wordnet developed at Språkbanken, University of Gothenburg. It is being built by reusing lexical-semantic relations collected from a number of pre-existing, freely available lexical resources: SALDO (Borin & Forsberg 2009), SDB (Järborg 2001), Synlex (Kann & Rosell 2006), and Swedish Wiktionary. A novel feature of Swesaurus is its fuzzy synsets derived from the graded synonymy relations of Synlex. Swesaurus and several other lexical resources are available for download and inspection at http://spraakbanken.gu.se/karp. Swesaurus is an integral part of a large and diverse lexical macroresource compiled in the Swedish FrameNet++ project (Borin et al. 2010). It includes 13,724 senses and is licensed under a CC-BY license. Due to its slightly different structure, Swesaurus is currently only partly visible through WordTies. 3.6 Norwegian Wordnet A Norwegian Wordnet"
W13-5616,pedersen-etal-2010-merging,1,0.766177,"linguistic grounds (corpora and existing lexica) for that particular language. On the other hand, such wordnets typically differ so much from Princeton WordNet in structure that a merge becomes indeed very hard and extremely complex. These differences originate partly from different language cultures, partly from different levels of specialization depending on the source material used. For instance, a typical feature of wordnets based on monolingual lexica is that they adopt a perspective which is more geared towards the layman and therefore typically not so deep in taxonomical structure (cf. Pedersen et al. 2010). Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 149 of 474] 3 Status of wordnets in the Nordic and Baltic countries 3.1 About META-NORD During the last decade, linguistic resources have grown rapidly for all EU languages, including lesser-resourced languages such as the Nordic and Baltic ones. However they have typically been located in different places, have developed in different standards and in many cases were not well documented. The META-NORD project has aimed to establish an open linguistic i"
W13-5616,tufis-etal-2004-word,0,0.0851173,"Missing"
W13-5616,bel-etal-2000-simple,0,\N,Missing
W13-5619,borin-etal-2012-korp,1,0.920055,"SCARRIE lexicon, and the Lithuanian Standard language lexical database. Terminology resources, such as the Icelandic Term Bank and UHR’s Termbase for Norwegian higher education institutions, have been converted into TBX 16 format (Term Base eXchange; ISO 30042:2008; Melby 2012). Most of the corpus resources uploaded are now available in TEI-compatible formats. A specific example of how this format harmonisation has enhanced interoperability is the relative ease 17 with which the open-source Korp corpus processing and presentation platform, developed in Sweden at the University of Gothenburg (Borin et al. 2012)18, has been deployed in Finland by the University of Helsinki for their Finnish corpora 19. Content model conversion/mapping/linking, e.g., harmonising POS tagsets among corpora, or linking word senses among lexical resources with different sense granularities. The Danish STO lexicon, the Swedish lexicons developed at Språkbanken, University of Gothenburg, and Swedish corpus annotations have been partly linked to the ISOCAT DCR (Data Category Registry; ISO 12620:2009; Windhouwer and Wright 2012), although no explicit attempt has been made to use the same categories across the languages, excep"
W13-5619,borin-etal-2012-open,1,0.870902,"Missing"
W13-5619,braasch-olsen-2004-sto,1,0.846342,"Missing"
W13-5619,broeder-etal-2010-data,0,0.0283968,"Missing"
W13-5619,francopoulo-etal-2006-lexical,0,0.0900195,"Missing"
W13-5619,gavrilidou-etal-2012-meta,0,0.0140866,"talogue of the pan-European infrastructure12. Besides META-SHARE repositories, we have a natural interest to integrate into our infrastructure several existing collections and databases of specific linguistic resources, such as term banks and treebanks. These repositories are collections of language resources, where each individual resource is a candidate to be listed in the META-SHARE catalogue. This could be done manually by entering all resource descriptions in the META-SHARE editor or by exporting the metadata from the respective repository, converting it into META-SHARE compliant schema (Gavrilidou et al., 2012), and importing into META-SHARE node. However, such approaches are time-consuming and need regular manual updates. Our proposed and implemented solution for this infrastructure is to integrate complex linguistic resources or repositories of resources by adapting them to relevant data access and sharing specifications and interlinking them with META-SHARE. This means that a language resourcespecific repository could seamlessly become a part of the META-SHARE network by enabling the harvesting of metadata through the META-SHARE communication protocol and ensuring the mapping of the respective da"
W13-5619,W13-5616,1,0.879624,"Missing"
W13-5619,piperidis-2012-meta,0,0.0205972,"chnology systems make it vital to develop both an open infrastructure and a more coherent research cooperation in order to spur greater sharing and reuse of language resources. 4 The table is also available at http://www.meta-net.eu/whitepapers/key-results-and-cross-language-comparison Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013); Linköping Electronic Conference Proceedings #85 [page 198 of 474] 3 META-SHARE infrastructure in the Baltic and Nordic countries For distribution and sharing of language resources, the distributed online platform META-SHARE (Piperidis, 2012) is used. It consists of independent META-SHARE nodes set up in different countries and interlinked into a federated repository. This freely accessible distributed online infrastructure provides facilities for describing, storing, preserving of language resources, and making them publicly available. Among various language data that can be considered useful for different purposes, META-SHARE places a strong focus on language data that are important in language technology development for building applications that are useful to EU citizens, primarily in their everyday communication and informati"
W13-5619,W11-3314,1,0.83743,"Missing"
W13-5619,varadi-etal-2008-clarin,0,0.0150457,"e often hard to find and difficult to use. Resources are dispersed among different institutions and local repositories, and they are often coded in proprietary formats lacking interoperability and uniformity. There are also restricted or unclear intellectual property rights. These factors are major stumbling blocks for the development and research of language technology. To overcome these difficulties, the Nordic and Baltic countries play a leading role in pan-European activities regarding the creation of the European open linguistic infrastructure. Major progress is achieved by the CLARIN 1 (Váradi et al., 2008) initiative creating a language resource infrastructure for research in humanities. Another complementary infrastructure is under development by the META-NET network2 focusing on the practical needs of developers, users, and researchers of multilingual resources. The Baltic and Nordic countries are active participants in both — CLARIN and META-NET — networks. Official languages of these countries (Danish, Estonian, Finnish, Icelandic, Latvian, Lithuanian, Norwegian, and Swedish), as well as other languages spoken in these countries, are under-resourced in respect to availability of at least so"
W13-5619,W01-1506,0,\N,Missing
W15-1806,W06-1670,0,0.0494196,", and it has mostly been limited to English newswire and literature (namely running on SemCor and SensEval data).9 Nevertheless, the interest in applying word-sense disambiguation techniques to reduced, coarser sense inventories has been a topic since the development of the first wordnets (Peters et al., 1998). Kohomban and Lee (2005) and Kohomban and Lee (2007) also propose to use lexicographer file identifers from Princeton WordNet senses (supersenses) and, in addition, discuss how to retrieve fine-grained senses from those predictions. The task of supersense tagging was first introduced by Ciaramita and Altun (2006), who used a structured perceptron trained and evaluated on S EM C OR via 5-fold cross validation. Johannsen et al. (2014) extend the SST approach to the Twitter domain, and include the usage of word embeddings in their feature representation. Supersenses have been used as features in various tasks, such as preposition sense disambiguation, noun compound interpretation, metaphor detection and relation extraction (Ye and Baldwin, 2007; Tratz and Hovy, 2010; Tsvetkov et al., 2013; Søgaard et al., 2015). Schneider et al. (2012) annotated supersenses on Arabic Wikipedia articles . Princeton WordNe"
W15-1806,W97-0802,0,0.0681552,"embeddings in their feature representation. Supersenses have been used as features in various tasks, such as preposition sense disambiguation, noun compound interpretation, metaphor detection and relation extraction (Ye and Baldwin, 2007; Tratz and Hovy, 2010; Tsvetkov et al., 2013; Søgaard et al., 2015). Schneider et al. (2012) annotated supersenses on Arabic Wikipedia articles . Princeton WordNet only provides a fully developed taxonomy of supersenses for verbs and nouns. Tsvetkov et al. (2014) propose an extension for adjectives, along the lines of the adjective sense of the German wordnet(Hamp and Feldweg, 1997). To the best of our knowledge, the current work is the first SST approach to Danish, which also extends to less canonical, characteristically webbased text types like chats or fora. 7 Conclusions We have presented a resource for SST that includes an extension of the English supersense inventory that can be used for any language, plus three additional tags that give account for characteristics of the syntax-semantics interface of a satellite-framing language like Danish. We have conducted an annotation task on 1,500 sentences, reaching 0.63 κ score after refining the annotation guidelines. Aft"
W15-1806,S14-1001,1,0.877501,"Missing"
W15-1806,P05-1005,0,0.0094743,"7.8 39.3 34.3 39.8 37.0 64.7 55.0 28.8 46.2 33.3 32.6 34.2 SAT. COLL SAT. PARTICLE SAT. REFLPRON 37.9 59.4 69.6 7.7 47.9 76.4 Table 11: Performance for extended noun and verb supersenses, and satellites. 6 Related work There has been relatively little previous work on supersense tagging, and it has mostly been limited to English newswire and literature (namely running on SemCor and SensEval data).9 Nevertheless, the interest in applying word-sense disambiguation techniques to reduced, coarser sense inventories has been a topic since the development of the first wordnets (Peters et al., 1998). Kohomban and Lee (2005) and Kohomban and Lee (2007) also propose to use lexicographer file identifers from Princeton WordNet senses (supersenses) and, in addition, discuss how to retrieve fine-grained senses from those predictions. The task of supersense tagging was first introduced by Ciaramita and Altun (2006), who used a structured perceptron trained and evaluated on S EM C OR via 5-fold cross validation. Johannsen et al. (2014) extend the SST approach to the Twitter domain, and include the usage of word embeddings in their feature representation. Supersenses have been used as features in various tasks, such as p"
W15-1806,H94-1046,0,0.0286344,"in that the labels are comprised within spans of one or more tokens. NER, however, only recognizes a handful of entity types 1 The data is available at clarin.dk under Danish Supersense Corpus and does not extend beyond nouns, while supersenses may be defined for all part of speech and permit more granular semantic distinctions. While coarse-grained semantic types find use in a range of applications, such as information retrieval, question answering (QA), and relation extraction, one of the main intended uses of the annotated corpus is building a semantic concordancer in the style of SemCor (Miller et al., 1994). We base our annotation effort on the set of supersenses derived from Princeton Wordnet, which makes our annotations interoperable across many languages through the already existing linkings to Princeton Wordnet. However, we found several cases where the Princeton supersenses made overly broad distinctions that caused large groups of lexemes to be grouped together (e.g. buildings and vehicles falling under the ARTIFACT class). The original sense inventory comprises a total of 41 senses, spread over 26 noun senses, and 15 verb senses, plus a single “catch-all” sense for adjectives, which is gr"
W15-1806,P12-2050,0,0.21141,"redictions. The task of supersense tagging was first introduced by Ciaramita and Altun (2006), who used a structured perceptron trained and evaluated on S EM C OR via 5-fold cross validation. Johannsen et al. (2014) extend the SST approach to the Twitter domain, and include the usage of word embeddings in their feature representation. Supersenses have been used as features in various tasks, such as preposition sense disambiguation, noun compound interpretation, metaphor detection and relation extraction (Ye and Baldwin, 2007; Tratz and Hovy, 2010; Tsvetkov et al., 2013; Søgaard et al., 2015). Schneider et al. (2012) annotated supersenses on Arabic Wikipedia articles . Princeton WordNet only provides a fully developed taxonomy of supersenses for verbs and nouns. Tsvetkov et al. (2014) propose an extension for adjectives, along the lines of the adjective sense of the German wordnet(Hamp and Feldweg, 1997). To the best of our knowledge, the current work is the first SST approach to Danish, which also extends to less canonical, characteristically webbased text types like chats or fora. 7 Conclusions We have presented a resource for SST that includes an extension of the English supersense inventory that can b"
W15-1806,N03-1033,0,0.0302794,"kov, 2012), which consists of newspapers, magazines, oral debates, blogs, and social media.3 Table 4 lists the amount of training data (1,500 sentences in total) currently annotated for each domain. We describe each domain in terms of its average sentence length (SL) and proportion of tokens per type, namely the average amount of repetitions for a certain type. The final release will be made up of 600 sentences from all of the domains in Table 4, plus the test section of the Danish Dependency Treebank (Buch-Kromann et al., 2003). All the data has been POS-tagged using the Stanford POS-tagger (Toutanova et al., 2003) trained on the Danish PAROLE corpus.4 Note that we strictly use predicted POS instead of goldstandard to provide a more realistic setup for the evaluation of our system in Section 5. 3.2 Annotation guidelines Sense inventory The guidelines for the supersense annotation comprise the list of supersenses provided with an explanation and examples for each supersense. 3 http://cst.ku.dk/Workshop311012/sprogtekno2012.pdf 4 http://korpus.dsl.dk/e-resurser/paroledoc en.pdf Application rules The second part of the guidelines consists of a set of more specific rules for each part of speech. The rules f"
W15-1806,S10-1049,0,0.102102,"n addition, discuss how to retrieve fine-grained senses from those predictions. The task of supersense tagging was first introduced by Ciaramita and Altun (2006), who used a structured perceptron trained and evaluated on S EM C OR via 5-fold cross validation. Johannsen et al. (2014) extend the SST approach to the Twitter domain, and include the usage of word embeddings in their feature representation. Supersenses have been used as features in various tasks, such as preposition sense disambiguation, noun compound interpretation, metaphor detection and relation extraction (Ye and Baldwin, 2007; Tratz and Hovy, 2010; Tsvetkov et al., 2013; Søgaard et al., 2015). Schneider et al. (2012) annotated supersenses on Arabic Wikipedia articles . Princeton WordNet only provides a fully developed taxonomy of supersenses for verbs and nouns. Tsvetkov et al. (2014) propose an extension for adjectives, along the lines of the adjective sense of the German wordnet(Hamp and Feldweg, 1997). To the best of our knowledge, the current work is the first SST approach to Danish, which also extends to less canonical, characteristically webbased text types like chats or fora. 7 Conclusions We have presented a resource for SST th"
W15-1806,W13-0906,0,0.0474527,"w to retrieve fine-grained senses from those predictions. The task of supersense tagging was first introduced by Ciaramita and Altun (2006), who used a structured perceptron trained and evaluated on S EM C OR via 5-fold cross validation. Johannsen et al. (2014) extend the SST approach to the Twitter domain, and include the usage of word embeddings in their feature representation. Supersenses have been used as features in various tasks, such as preposition sense disambiguation, noun compound interpretation, metaphor detection and relation extraction (Ye and Baldwin, 2007; Tratz and Hovy, 2010; Tsvetkov et al., 2013; Søgaard et al., 2015). Schneider et al. (2012) annotated supersenses on Arabic Wikipedia articles . Princeton WordNet only provides a fully developed taxonomy of supersenses for verbs and nouns. Tsvetkov et al. (2014) propose an extension for adjectives, along the lines of the adjective sense of the German wordnet(Hamp and Feldweg, 1997). To the best of our knowledge, the current work is the first SST approach to Danish, which also extends to less canonical, characteristically webbased text types like chats or fora. 7 Conclusions We have presented a resource for SST that includes an extensio"
W15-1806,tsvetkov-etal-2014-augmenting-english,0,0.0802991,"d cross validation. Johannsen et al. (2014) extend the SST approach to the Twitter domain, and include the usage of word embeddings in their feature representation. Supersenses have been used as features in various tasks, such as preposition sense disambiguation, noun compound interpretation, metaphor detection and relation extraction (Ye and Baldwin, 2007; Tratz and Hovy, 2010; Tsvetkov et al., 2013; Søgaard et al., 2015). Schneider et al. (2012) annotated supersenses on Arabic Wikipedia articles . Princeton WordNet only provides a fully developed taxonomy of supersenses for verbs and nouns. Tsvetkov et al. (2014) propose an extension for adjectives, along the lines of the adjective sense of the German wordnet(Hamp and Feldweg, 1997). To the best of our knowledge, the current work is the first SST approach to Danish, which also extends to less canonical, characteristically webbased text types like chats or fora. 7 Conclusions We have presented a resource for SST that includes an extension of the English supersense inventory that can be used for any language, plus three additional tags that give account for characteristics of the syntax-semantics interface of a satellite-framing language like Danish. We"
W15-1806,S07-1051,0,0.246823,"s (supersenses) and, in addition, discuss how to retrieve fine-grained senses from those predictions. The task of supersense tagging was first introduced by Ciaramita and Altun (2006), who used a structured perceptron trained and evaluated on S EM C OR via 5-fold cross validation. Johannsen et al. (2014) extend the SST approach to the Twitter domain, and include the usage of word embeddings in their feature representation. Supersenses have been used as features in various tasks, such as preposition sense disambiguation, noun compound interpretation, metaphor detection and relation extraction (Ye and Baldwin, 2007; Tratz and Hovy, 2010; Tsvetkov et al., 2013; Søgaard et al., 2015). Schneider et al. (2012) annotated supersenses on Arabic Wikipedia articles . Princeton WordNet only provides a fully developed taxonomy of supersenses for verbs and nouns. Tsvetkov et al. (2014) propose an extension for adjectives, along the lines of the adjective sense of the German wordnet(Hamp and Feldweg, 1997). To the best of our knowledge, the current work is the first SST approach to Danish, which also extends to less canonical, characteristically webbased text types like chats or fora. 7 Conclusions We have presented"
W15-1806,P13-4001,0,0.134357,"Missing"
W15-1806,W15-2005,1,0.785087,"etaProceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 22 Domain Blog Chat Forum Magazine Newswire Parliament SL tokens types Sentences 16.44 14.61 20.51 19.45 17.43 31.21 2.95 3.70 3.85 2.95 3.28 5.00 100 200 200 200 600 200 Table 4: Supersense tagging data sets. tion is annotated in the corpus in the following way: han satte(VERB . COMMUNICATION) ham p˚a(COLL) plads(COLL). 3 Annotation process This section the describes the annotation task for supersenses, including detailes on corpus, guidelines and resulting agreement scores. For further information, cf. Olsen et al. (2015). 3.1 Corpus We have chosen to annotate from the Danish CLARIN Reference Corpus (Asmussen and Halskov, 2012), which consists of newspapers, magazines, oral debates, blogs, and social media.3 Table 4 lists the amount of training data (1,500 sentences in total) currently annotated for each domain. We describe each domain in terms of its average sentence length (SL) and proportion of tokens per type, namely the average amount of repetitions for a certain type. The final release will be made up of 600 sentences from all of the domains in Table 4, plus the test section of the Danish Dependency Tree"
W15-2005,W15-2000,0,0.180083,"Missing"
W15-2005,P13-4001,0,0.176245,"Missing"
W15-2005,J08-4004,0,0.223422,"roup n.phenomenon n.cognition n.building n.act n.artifact n.attribute n.communication n.person n.time n.institution n.body Table 4: Inter-annotator agreement κ across domains together with the percentage of double annotated files. This feed was published Tuesday September 21 at 10:00 and is saved under My garden. You can follow all comments to this feed via the RSS 2.0 feed. Figure 3: Disagreement for noun senses in NEWSWIRE . In such cases the annotators reached a consensus on how to tag the blog-specific metadata. Table 4 shows that even if agreement results are generally good for the task (Artstein and Poesio, 2008), not all textual domains are equally easy to annotate. NEWSWIRE and PARLIAMENT show the lowest agreement, which is a somewhat surprising finding, because these texts are the most canonical and elaborate and thus arguably easier to understand and annotate. FORUM has 300 sentences, unlike the other domains, which have double the amount. This difference has an impact in the chance-correction measure of the κ coefficient, making the chance-adjustment more severe. However, NEWSWIRE has more semantic types than e.g. BLOG (see Figure 3, 4 and 5), and the more varied the text, the more difficult it w"
W15-2005,brown-etal-2010-number,0,0.39602,"Missing"
W15-2005,W03-1022,0,0.350322,"Missing"
W15-2005,de-melo-etal-2012-empirical,0,0.0579156,"Missing"
W15-2005,H92-1045,0,0.609943,"the EuroWordNet top ontology as described in Pedersen et al. (2009) and Vossen (1998), have enabled us to automatically the word senses defined for the Danish vocabulary onto the cross-lingual supersenses. These are based on the Princeton Wordnet lexicographical classes1 and have become a popular choice for coarse-grained sense tagging with the advantage of being applicable across languages. 1 Introduction It is commonly observed that word meanings vary substantially across textual domains, so that an appropriate sense inventory for one domain may be inappropriate or insufficient for another (Gale et al., 1992). This essential quality of the lexicon poses a huge challenge to natural language processing and underlines the need for developing systems that are generally less sensitive to domain shifts. The present work is framed within a project that deals with sense inventories of different granularity and across textual domains. The overall goal is to discover what sense inventories and algorithms are manageable for annotation purposes and useful for automatic sense 1 https://wordnet.princeton.edu/man/ lexnames.5WN.html Sussi Olsen, Bolette S. Pedersen, Héctor Martínez Alonso and Anders Johannsen 201"
W15-2005,W15-1806,1,0.848138,"Missing"
W15-2005,W15-1831,1,0.564731,"Missing"
