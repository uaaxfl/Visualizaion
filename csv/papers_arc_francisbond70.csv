2021.gwc-1.5,Taboo {W}ordnet,2021,-1,-1,1,1,6126,francis bond,Proceedings of the 11th Global Wordnet Conference,0,"This paper describes the development of an online lexical resource to help detection systems regulate and curb the use of offensive words online. With the growing prevalence of social media platforms, many conversations are now conducted on- line. The increase of online conversations for leisure, work and socializing has led to an increase in harassment. In particular, we create a specialized sense-based vocabulary of Japanese offensive words for the Open Multilingual Wordnet. This vocabulary expands on an existing list of Japanese offen- sive words and provides categorization and proper linking to synsets within the multilingual wordnet. This paper then discusses the evaluation of the vocabulary as a resource for representing and classifying offensive words and as a possible resource for offensive word use detection in social media."
2021.gwc-1.11,The {G}lobal{W}ord{N}et Formats: Updates for 2020,2021,-1,-1,3,0.122884,1255,john mccrae,Proceedings of the 11th Global Wordnet Conference,0,"The Global Wordnet Formats have been introduced to enable wordnets to have a common representation that can be integrated through the Global WordNet Grid. As a result of their adoption, a number of shortcomings of the format were identified, and in this paper we describe the extensions to the formats that address these issues. These include: ordering of senses, dependencies between wordnets, pronunciation, syntactic modelling, relations, sense keys, metadata and RDF support. Furthermore, we provide some perspectives on how these changes help in the integration of wordnets."
2021.gwc-1.12,Intrinsically Interlingual: The Wn Python Library for Wordnets,2021,-1,-1,2,0.380435,6141,michael goodman,Proceedings of the 11th Global Wordnet Conference,0,"This paper introduces Wn, a new Python library for working with wordnets. Unlike previous libraries, Wn is built from the beginning to accommodate multiple wordnets {---} for multiple languages or multiple versions of the same wordnet {---} while retaining the ability to query and traverse them independently. It is also able to download and incorporate wordnets published online. These features are made possible through Wn{'}s adoption of standard formats and methods for interoperability, namely the WN-LMF schema (Vossen et al., 2013; Bond et al., 2020) and the Collaborative Interlingual Index (Bond et al., 2016). Wn is open-source, easily available, and well-documented."
2021.gwc-1.22,{O}de{N}et: Compiling a {G}erman{W}ord{N}et from other Resources,2021,-1,-1,2,0,6174,melanie siegel,Proceedings of the 11th Global Wordnet Conference,0,"The Princeton WordNet for the English language has been used worldwide in NLP projects for many years. With the OMW initiative, wordnets for different languages of the world are being linked via identifiers. The parallel development and linking allows new multilingual application perspectives. The development of a wordnet for the German language is also in this context. To save development time, existing resources were combined and recompiled. The result was then evaluated and improved. In a relatively short time a resource was created that can be used in projects and continuously improved and extended."
2021.gwc-1.32,Teaching Through Tagging {---} Interactive Lexical Semantics,2021,-1,-1,1,1,6126,francis bond,Proceedings of the 11th Global Wordnet Conference,0,"In this paper we discuss an ongoing effort to enrich students{'} learning by involving them in sense tagging. The main goal is to lead students to discover how we can represent meaning and where the limits of our current theories lie. A subsidiary goal is to create sense tagged corpora and an accompanying linked lexicon (in our case wordnets). We present the results of tagging several texts and suggest some ways in which the tagging process could be improved. Two authors of this paper present their own experience as students. Overall, students reported that they found the tagging an enriching experience. The annotated corpora and changes to the wordnet are made available through the NTU multilingual corpus and associated wordnets (NTU-MC)."
2021.gwc-1.34,Testing agreement between lexicographers: A case of homonymy and polysemy,2021,-1,-1,2,0,6131,marek maziarz,Proceedings of the 11th Global Wordnet Conference,0,"In this paper we compare Oxford Lexico and Merriam Webster dictionaries with Princeton WordNet with respect to the description of semantic (dis)similarity between polysemous and homonymous senses that could be inferred from them. WordNet lacks any explicit description of polysemy or homonymy, but as a network of linked senses it may be used to compute semantic distances between word senses. To compare WordNet with the dictionaries, we transformed sample entry microstructures of the latter into graphs and cross-linked them with the equivalent senses of the former. We found that dictionaries are in high agreement with each other, if one considers polysemy and homonymy altogether, and in moderate concordance, if one focuses merely on polysemy descriptions. Measuring the shortest path lengths on WordNet gave results comparable to those on the dictionaries in predicting semantic dissimilarity between polysemous senses, but was less felicitous while recognising homonymy."
2020.mmw-1.3,{E}nglish {W}ord{N}et 2020: Improving and Extending a {W}ord{N}et for {E}nglish using an Open-Source Methodology,2020,-1,-1,4,0.130215,1255,john mccrae,Proceedings of the LREC 2020 Workshop on Multimodal Wordnets (MMW2020),0,"WordNet, while one of the most widely used resources for NLP, has not been updated for a long time, and as such a new project English WordNet has arisen to continue the development of the model under an open-source paradigm. In this paper, we detail the second release of this resource entitled {``}English WordNet 2020{''}. The work has focused firstly, on the introduction of new synsets and senses and developing guidelines for this and secondly, on the integration of contributions from other projects. We present the changes in this edition, which total over 15,000 changes over the previous release."
2020.lrec-1.46,Automated Writing Support Using Deep Linguistic Parsers,2020,-1,-1,6,0.85574,6143,luis costa,Proceedings of the 12th Language Resources and Evaluation Conference,0,"This paper introduces a new web system that integrates English Grammatical Error Detection (GED) and course-specific stylistic guidelines to automatically review and provide feedback on student assignments. The system is being developed as a pedagogical tool for English Scientific Writing. It uses both general NLP methods and high precision parsers to check student assignments before they are submitted for grading. Instead of generalized error detection, our system aims to identify, with high precision, specific classes of problems that are known to be common among engineering students. Rather than correct the errors, our system generates constructive feedback to help students identify and correct them on their own. A preliminary evaluation of the system{'}s in-class performance has shown measurable improvements in the quality of student assignments."
2020.lrec-1.389,Linking the {TUFS} Basic Vocabulary to the Open Multilingual {W}ordnet,2020,-1,-1,1,1,6126,francis bond,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We describe the linking of the TUFS Basic Vocabulary Modules, created for online language learning, with the Open Multilingual Wordnet. The TUFS modules have roughly 500 lexical entries in 30 languages, each with the lemma, a link across the languages, an example sentence, usage notes and sound files. The Open Multilingual Wordnet has 34 languages (11 shared with TUFS) organized into synsets linked by semantic relations, with examples and definitions for some languages. The links can be used to (i) evaluate existing wordnets, (ii) add data to these wordnets and (iii) create new open wordnets for Khmer, Korean, Lao, Mongolian, Russian, Tagalog, Urdua nd Vietnamese"
2020.lrec-1.390,Some Issues with Building a Multilingual {W}ordnet,2020,-1,-1,1,1,6126,francis bond,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper we discuss the experience of bringing together over 40 different wordnets. We introduce some extensions to the GWA wordnet LMF format proposed in Vossen et al. (2016) and look at how this new information can be displayed. Notable extensions include: confidence, corpus frequency, orthographic variants, lexicalized and non-lexicalized synsets and lemmas, new parts of speech, and more. Many of these extensions already exist in multiple wordnets {--} the challenge was to find a compatible representation. To this end, we introduce a new version of the Open Multilingual Wordnet (Bond and Foster, 2013), that integrates a new set of tools that tests the extensions introduced by this new format, while also ensuring the integrity of the Collaborative Interlingual Index (CILI: Bond et al., 2016), avoiding the same new concept to be introduced through multiple projects."
D19-6013,Commonsense inference in human-robot communication,2019,0,0,4,0,26481,aliaksandr huminski,Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing,0,"Natural language communication between machines and humans are still constrained. The article addresses a gap in natural language understanding about actions, specifically that of understanding commands. We propose a new method for commonsense inference (grounding) of high-level natural language commands into specific action commands for further execution by a robotic system. The method allows to build a knowledge base that consists of a large set of commonsense inferences. The preliminary results have been presented."
2019.gwc-1.31,{E}nglish {W}ord{N}et 2019 {--} An Open-Source {W}ord{N}et for {E}nglish,2019,-1,-1,3,0.153915,1255,john mccrae,Proceedings of the 10th Global Wordnet Conference,0,"We describe the release of a new wordnet for English based on the Princeton WordNet, but now developed under an open-source model. In particular, this version of WordNet, which we call English WordNet 2019, which has been developed by multiple people around the world through GitHub, fixes many errors in previous wordnets for English. We give some details of the changes that have been made in this version and give some perspectives about likely future changes that will be made as this project continues to evolve."
2019.gwc-1.44,Testing {Z}ipf{'}s meaning-frequency law with wordnets as sense inventories,2019,-1,-1,1,1,6126,francis bond,Proceedings of the 10th Global Wordnet Conference,0,"According to George K. Zipf, more frequent words have more senses. We have tested this law using corpora and wordnets of English, Spanish, Portuguese, French, Polish, Japanese, Indonesian and Chinese. We have proved that the law works pretty well for all of these languages if we take - as Zipf did - mean values of meaning count and averaged ranks. On the other hand, the law disastrously fails in predicting the number of senses for a single lemma. We have also provided the evidence that slope coefficients of Zipfian log-log linear model may vary from language to language."
2019.gwc-1.46,A Comparison of Sense-level Sentiment Scores,2019,-1,-1,1,1,6126,francis bond,Proceedings of the 10th Global Wordnet Conference,0,"In this paper, we compare a variety of sense-tagged sentiment resources, including SentiWordNet, ML-Senticon, plWordNet emo and the NTU Multilingual Corpus. The goal is to investigate the quality of the resources and see how well the sentiment polarity annotation maps across languages."
2019.gwc-1.49,{G}eo{N}ames {W}ordnet (geown): extracting wordnets from {G}eo{N}ames,2019,-1,-1,1,1,6126,francis bond,Proceedings of the 10th Global Wordnet Conference,0,"This paper introduces a new multilingual lexicon of geographical place names. The names are based on (and linked to) the GeoNames collection. Each location is treated as a new synset, which is linked by instance{\_}hypernym to a small set of supertypes. These supertypes are linked to the collaborative interlingual index, based on mappings from GeoDomainWordnet. If a location is already in the interlingual index, then it is also linked to the entry, using mappings from the Geo-Wordnet. Finally, if GeoNames places the location in a larger location, this is linked using the mero{\_}location link. Wordnets can be built for any language in GeoNames, we give results for those wordnets in the Open Multilingual Wordnet. We discuss how it is mapped and the characteristics of the extracted wordnets."
2019.gwc-1.50,New Polysemy Structures in Wordnets Induced by Vertical Polysemy,2019,-1,-1,4,0,17448,ahti lohk,Proceedings of the 10th Global Wordnet Conference,0,"This paper aims to study auto-hyponymy and auto-troponymy relations (or vertical polysemy) in 11 wordnets uploaded into the new Open Multilingual Wordnet (OMW) webpage. We investigate how vertical polysemy forms polysemy structures (or sense clusters) in semantic hierarchies of the wordnets. Our main results and discoveries are new polysemy structures that have not previously been associated with vertical polysemy, along with some inconsistencies of semantic relations analysis in the studied wordnets, which should not be there. In the case study, we turn attention to polysemy structures in the Estonian Wordnet (version 2.2.0), analyzing them and giving the lexicographers comments. In addition, we describe the detection algorithm of polysemy structures and an overview of the state of polysemy structures in 11 wordnets."
L18-1522,Toward An Epic Epigraph Graph,2018,0,0,1,1,6126,francis bond,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
2018.gwc-1.19,The Company They Keep: Extracting {J}apanese Neologisms Using Language Patterns,2018,9,0,3,1,31040,james breen,Proceedings of the 9th Global Wordnet Conference,0,"We describe an investigation into the identification and extraction of unrecorded potential lexical items in Japanese text by detecting text passages containing selected language patterns typically associated with such items. We identified a set of suitable patterns, then tested them with two large collections of text drawn from the WWW and Twitter. Samples of the extracted items were evaluated, and it was demonstrated that the approach has considerable potential for identifying terms for later lexicographic analysis."
2018.gwc-1.24,Lexical Perspective on {W}ordnet to {W}ordnet Mapping,2018,14,0,2,0.790354,6142,ewa rudnicka,Proceedings of the 9th Global Wordnet Conference,0,"The paper presents a feature-based model of equivalence targeted at (manual) sense linking between Princeton WordNet and plWordNet. The model incorporates insights from lexicographic and translation theories on bilingual equivalence and draws on the results of earlier synset-level mapping of nouns between Princeton WordNet and plWordNet. It takes into account all basic aspects of language such as form, meaning and function and supplements them with (parallel) corpus frequency and translatability. Three types of equivalence are distinguished, namely strong, regular and weak depending on the conformity with the proposed features. The presented solutions are language-neutral and they can be easily applied to language pairs other than Polish and English. Sense-level mapping is a more fine-grained mapping than the existing synset mappings and is thus of great potential to human and machine translation."
2018.gwc-1.32,Multilingual {W}ordnet sense Ranking using nearest context,2018,-1,-1,2,0,31050,umamaheswari vasanthakumar,Proceedings of the 9th Global Wordnet Conference,0,"In this paper, we combine methods to estimate sense rankings from raw text with recent work on word embeddings to provide sense ranking estimates for the entries in the Open Multilingual WordNet (OMW). The existing Word2Vec pre-trained models from Polygot2 are only built for single word entries, we, therefore, re-train them with multiword expressions from the wordnets, so that multiword expressions can also be ranked. Thus this trained model gives embeddings for both single words and multiwords. The resulting lexicon gives a WSD baseline for five languages. The results are evaluated for Semcor sense corpora for 5 languages using Word2Vec and Glove models. The Glove model achieves an average accuracy of 0.47 and Word2Vec achieves 0.31 for languages such as English, Italian, Indonesian, Chinese and Japanese. The experimentation on OMW sense ranking proves that the rank correlation is generally similar to the human ranking. Hence distributional semantics can aid in Wordnet Sense Ranking."
2018.gwc-1.35,Automatic Identification of Basic-Level Categories,2018,11,0,2,0,31052,chad mills,Proceedings of the 9th Global Wordnet Conference,0,"Basic-level categories have been shown to be both psychologically significant and useful in a wide range of practical applications. We build a rule-based system to identify basic-level categories in WordNet, achieving 77{\%} accuracy on a test set derived from prior psychological experiments. With additional annotations we found our system also has low precision, in part due to the existence of many categories that do not fit into the three classes (superordinate, basic-level, and subordinate) relied on in basic-level category research."
2018.gwc-1.41,Enchancing the Collaborative Interlingual Index for Digital Humanities: Cross-linguistic Analysis in the Domain of Theology,2018,-1,-1,4,0,27418,laura slaughter,Proceedings of the 9th Global Wordnet Conference,0,"We aim to support digital humanities work related to the study of sacred texts. To do this, we propose to build a cross-lingual wordnet within the do-main of theology. We target the Collaborative Interlingual Index (CILI) directly instead of each individual wordnet. The paper presents background for this proposal: (1) an overview of concepts relevant to theology and (2) a summary of the domain-associated issues observed in the Princeton WordNet (PWN). We have found that definitions for concepts in this domain can be too restrictive, inconsistent, and unclear. Necessary synsets are missing, with the PWN being skewed towards Christianity. We argue that tackling problems in a single domain is a better method for improving CILI. By focusing on a single topic rather than a single language, this will result in the proper construction of definitions, romanization/translation of lemmas, and also improvements in use of/creation of a cross-lingual domain hierarchy."
2018.gwc-1.46,"Putting Figures on Influences on {M}oroccan {D}arija from {A}rabic, {F}rench and {S}panish using the {W}ord{N}et",2018,0,0,2,0,2776,khalil mrini,Proceedings of the 9th Global Wordnet Conference,0,"Moroccan Darija is a variant of Arabic with many influences. Using the Open Multilingual WordNet (OMW), we compare the lemmas in the Moroccan Darija Wordnet (MDW) with the standard Arabic, French and Spanish ones. We then compared the lemmas in each synset with their translation equivalents. Transliteration is used to bridge alphabet differences and match lemmas in the closest phonological way. The results put figures on the similarity Moroccan Darija has with Arabic, French and Spanish: respectively 42.0{\%}, 2.8{\%} and 2.2{\%}."
2018.gwc-1.50,Toward Constructing the National Cancer Institute Thesaurus Derived {W}ord{N}et (ncit{WN}),2018,0,0,3,0,31063,amanda hicks,Proceedings of the 9th Global Wordnet Conference,0,"We describe preliminary work in the creation of the first specialized vocabulary to be integrated into the Open Multilingual Wordnet (OMW). The NCIt Derived WordNet (ncitWN) is based on the National Cancer Institute Thesaurus (NCIt), a controlled biomedical terminology that includes formal class restrictions and English definitions developed by groups of clinicians and terminologists. The ncitWN is created by converting the NCIt to the WordNet Lexical Markup Framework and adding semantic types. We report the development of a prototype ncitWN and first steps towards integrating it into the OMW."
W17-5901,{NTUCLE}: Developing a Corpus of Learner {E}nglish to Provide Writing Support for Engineering Students,2017,-1,-1,8,0,16693,roger winder,Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications ({NLPTEA} 2017),0,"This paper describes the creation of a new annotated learner corpus. The aim is to use this corpus to develop an automated system for corrective feedback on students{'} writing. With this system, students will be able to receive timely feedback on language errors before they submit their assignments for grading. A corpus of assignments submitted by first year engineering students was compiled, and a new error tag set for the NTU Corpus of Learner English (NTUCLE) was developed based on that of the NUS Corpus of Learner English (NUCLE), as well as marking rubrics used at NTU. After a description of the corpus, error tag set and annotation process, the paper presents the results of the annotation exercise as well as follow up actions. The final error tag set, which is significantly larger than that for the NUCLE error categories, is then presented before a brief conclusion summarising our experience and future plans."
W16-4914,Syntactic Well-Formedness Diagnosis and Error-Based Coaching in Computer Assisted Language Learning using Machine Translation,2016,0,1,2,1,6143,luis costa,Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications ({NLPTEA}2016),0,"We present a novel approach to Computer Assisted Language Learning (CALL), using deep syntactic parsers and semantic based machine translation (MT) in diagnosing and providing explicit feedback on language learners{'} errors. We are currently developing a proof of concept system showing how semantic-based machine translation can, in conjunction with robust computational grammars, be used to interact with students, better understand their language errors, and help students correct their grammar through a series of useful feedback messages and guided language drills. Ultimately, we aim to prove the viability of a new integrated rule-based MT approach to disambiguate students{'} intended meaning in a CALL system. This is a necessary step to provide accurate coaching on how to correct ungrammatical input, and it will allow us to overcome a current bottleneck in the field {---} an exponential burst of ambiguity caused by ambiguous lexical items (Flickinger, 2010). From the users{'} interaction with the system, we will also produce a richly annotated Learner Corpus, annotated automatically with both syntactic and semantic information."
S16-1203,{USAAR} at {S}em{E}val-2016 Task 13: Hyponym Endocentricity,2016,22,10,2,0.528949,10447,liling tan,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
P16-1143,{L}ex{S}em{T}m: A Semantic Dataset Based on All-words Unsupervised Sense Distribution Learning,2016,35,14,5,0,27822,andrew bennett,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
L16-1386,The Open Linguistics Working Group: Developing the Linguistic Linked Open Data Cloud,2016,16,11,3,0.153915,1255,john mccrae,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The Open Linguistics Working Group (OWLG) brings together researchers from various fields of linguistics, natural language processing, and information technology to present and discuss principles, case studies, and best practices for representing, publishing and linking linguistic data collections. A major outcome of our work is the Linguistic Linked Open Data (LLOD) cloud, an LOD (sub-)cloud of linguistic resources, which covers various linguistic databases, lexicons, corpora, terminologies, and metadata repositories. We present and summarize five years of progress on the development of the cloud and of advancements in open data in linguistics, and we describe recent community activities. The paper aims to serve as a guideline to orient and involve researchers with the community and/or Linguistic Linked Open Data."
L16-1685,Wow! What a Useful Extension! Introducing Non-Referential Concepts to {W}ordnet,2016,9,2,2,1,6143,luis costa,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper we present the ongoing efforts to expand the depth and breath of the Open Multilingual Wordnet coverage by introducing two new classes of non-referential concepts to wordnet hierarchies: interjections and numeral classifiers. The lexical semantic hierarchy pioneered by Princeton Wordnet has traditionally restricted its coverage to referential and contentful classes of words: such as nouns, verbs, adjectives and adverbs. Previous efforts have been employed to enrich wordnet resources including, for example, the inclusion of pronouns, determiners and quantifiers within their hierarchies. Following similar efforts, and motivated by the ongoing semantic annotation of the NTU-Multilingual Corpus, we decided that the four traditional classes of words present in wordnets were too restrictive. Though non-referential, interjections and classifiers possess interesting semantics features that can be well captured by lexical resources like wordnets. In this paper, we will further motivate our decision to include non-referential concepts in wordnets and give an account of the current state of this expansion."
2016.gwc-1.8,Multilingual Sense Intersection in a Parallel Corpus with Diverse Language Families,2016,-1,-1,2,0,36113,giulia bonansinga,Proceedings of the 8th Global WordNet Conference (GWC),0,"Supervised methods for Word Sense Disambiguation (WSD) benefit from high-quality sense-annotated resources, which are lacking for many languages less common than English. There are, however, several multilingual parallel corpora that can be inexpensively annotated with senses through cross-lingual methods. We test the effectiveness of such an approach by attempting to disambiguate English texts through their translations in Italian, Romanian and Japanese. Specifically, we try to find the appropriate word senses for the English words by comparison with all the word senses associated to their translations. The main advantage of this approach is in that it can be applied to any parallel corpus, as long as large, high-quality inter-linked sense inventories exist for all the languages considered."
2016.gwc-1.9,{CILI}: the Collaborative Interlingual Index,2016,0,15,1,1,6126,francis bond,Proceedings of the 8th Global WordNet Conference (GWC),0,"This paper introduces the motivation for and design of the Collaborative InterLingual Index (CILI). It is designed to make possible coordination between multiple loosely coupled wordnet projects. The structure of the CILI is based on the Interlingual index first proposed in the EuroWordNet project with several pragmatic extensions: an explicit open license, definitions in English and links to wordnets in the Global Wordnet Grid."
2016.gwc-1.33,Identifying and Exploiting Definitions in {W}ordnet {B}ahasa,2016,-1,-1,2,1,17395,david moeljadi,Proceedings of the 8th Global WordNet Conference (GWC),0,"This paper describes our attempts to add Indonesian definitions to synsets in the Wordnet Bahasa (Nurril Hirfana Mohamed Noor et al., 2011; Bond et al., 2014), to extract semantic relations between lemmas and definitions for nouns and verbs, such as synonym, hyponym, hypernym and instance hypernym, and to generally improve Wordnet. The original, somewhat noisy, definitions for Indonesian came from the Asian Wordnet project (Riza et al., 2010). The basic method of extracting the relations is based on Bond et al. (2004). Before the relations can be extracted, the definitions were cleaned up and tokenized. We found that the definitions cannot be completely cleaned up because of many misspellings and bad translations. However, we could identify four semantic relations in 57.10{\%} of noun and verb definitions. For the remaining 42.90{\%}, we propose to add 149 new Indonesian lemmas and make some improvements to Wordnet Bahasa and Wordnet in general."
2016.gwc-1.36,Mapping and Generating Classifiers using an Open {C}hinese Ontology,2016,-1,-1,2,1,6143,luis costa,Proceedings of the 8th Global WordNet Conference (GWC),0,"In languages such as Chinese, classifiers (CLs) play a central role in the quantification of noun-phrases. This can be a problem when generating text from input that does not specify the classifier, as in machine translation (MT) from English to Chinese. Many solutions to this problem rely on dictionaries of noun-CL pairs. However, there is no open large-scale machine-tractable dictionary of noun-CL associations. Many published resources exist, but they tend to focus on how a CL is used (e.g. what kinds of nouns can be used with it, or what features seem to be selected by each CL). In fact, since nouns are open class words, producing an exhaustive definite list of noun-CL associations is not possible, since it would quickly get out of date. Our work tries to address this problem by providing an algorithm for automatic building of a frequency based dictionary of noun-CL pairs, mapped to concepts in the Chinese Open Wordnet (Wang and Bond, 2013), an open machine-tractable dictionary for Chinese. All results will released under an open license."
2016.gwc-1.59,Toward a truly multilingual {G}lobal{W}ordnet Grid,2016,-1,-1,2,0,5469,piek vossen,Proceedings of the 8th Global WordNet Conference (GWC),0,"In this paper, we describe a new and improved Global Wordnet Grid that takes advantage of the Collaborative InterLingual Index (CILI). Currently, the Open Multilingal Wordnet has made many wordnets accessible as a single linked wordnet, but as it used the Princeton Wordnet of English (PWN) as a pivot, it loses concepts that are not part of PWN. The technical solution to this, a central registry of concepts, as proposed in the EuroWordnet project through the InterLingual Index, has been known for many years. However, the practical issues of how to host this index and who decides what goes in remained unsolved. Inspired by current practice in the Semantic Web and the Linked Open Data community, we propose a way to solve this issue. In this paper we define the principles and protocols for contributing to the Grid. We tested them on two use cases, adding version 3.1 of the Princeton WordNet to a CILI based on 3.0 and adding the Open Dutch Wordnet, to validate the current set up. This paper aims to be a call for action that we hope will be further discussed and ultimately taken up by the whole wordnet community."
W15-4105,Passive and Pervasive Use of Bilingual Dictionary in Statistical Machine Translation,2015,21,4,3,0.666667,10447,liling tan,Proceedings of the Fourth Workshop on Hybrid Approaches to Translation ({H}y{T}ra),0,There are two primary approaches to the use bilingual dictionary in statistical machine translation: (i) the passive approach of appending the parallel training data with a bilingual dictionary and (ii) the pervasive approach of enforcing translation as per the dictionary entries when decoding. Previous studies have shown that both approaches provide external lexical knowledge to statistical machine translation thus improving translation quality. We empirically investigate the effects of both approaches on the same dataset and provide further insights on how lexical information can be reinforced in statistical machine translation.
W15-3302,Building an {HPSG}-based {I}ndonesian Resource Grammar ({INDRA}),2015,25,4,2,1,17395,david moeljadi,Proceedings of the Grammar Engineering Across Frameworks ({GEAF}) 2015 Workshop,0,"This paper presents the creation and the initial stage development of a broadcoverage Indonesian Resource Grammar (INDRA) within the framework of Head Driven Phrase Structure Grammar (HPSG) (Pollard and Sag, 1994) and Minimal Recursion Semantics (MRS) (Copestake et al., 2005). At the present stage, INDRA focuses on verbal constructions and subcategorization since they are fundamental for argument and event structure. Verbs in INDRA were semi-automatically acquired from the English Resource Grammar (ERG) (Flickinger, 2000) via Wordnet Bahasa (Nurril Hirfana Mohamed Noor et al., 2011; Bond et al., 2014). In the future, INDRA will be used in the development process of machine translation. A preliminary evaluation of INDRA on the MRS test-suite shows promising coverage."
W15-3303,An {HPSG}-based Shared-Grammar for the {C}hinese Languages: {ZHONG} [|],2015,36,1,3,0,36790,zhenzhen fan,Proceedings of the Grammar Engineering Across Frameworks ({GEAF}) 2015 Workshop,0,"This paper introduces our attempts to model the Chinese language using HPSG and MRS. Chinese refers to a family of various languages including Mandarin Chinese, Cantonese, Min, etc. These languages share a large amount of structure, though they may differ in orthography, lexicon, and syntax. To model these, we are building a family of grammars: ZHONG [ ]. This grammar contains instantiations of various Chinese languages, sharing descriptions where possible. Currently we have prototype grammars for Cantonese and Mandarin in both simplified and traditional script, all based on a common core. The grammars also have facilities for robust parsing, sentence generation, and unknown word handling."
P15-4002,{IMI} {---} A Multilingual Semantic Annotation Environment,2015,18,2,1,1,6126,francis bond,Proceedings of {ACL}-{IJCNLP} 2015 System Demonstrations,0,"Semantic annotated parallel corpora, though rare, play an increasingly important role in natural language processing. These corpora provide valuable data for computational tasks like sense-based machine translation and word sense disambiguation, but also to contrastive linguistics and translation studies. In this paper we present the ongoing development of a web-based corpus semantic annotation environment that uses the Open Multilingual Wordnet (Bond and Foster, 2013) as a sense inventory. The system includes interfaces to help coordinating the annotation project and a corpus browsing interface designed specifically to meet the needs of a semantically annotated corpus. The tool was designed to build the NTU-Multilingual Corpus (Tan and Bond, 2012). For the past six years, our tools have been tested and developed in parallel with the semantic annotation of a portion of this corpus in Chinese, English, Japanese and Indonesian. The annotation system is released under an open source license (MIT)."
P15-4013,{OMWE}dit - The Integrated Open Multilingual {W}ordnet Editing System,2015,14,1,2,1,6143,luis costa,Proceedings of {ACL}-{IJCNLP} 2015 System Demonstrations,0,"Wordnets play a central role in many natural language processing tasks. This paper introduces a multilingual editing system for the Open Multilingual Wordnet (OMW: Bond and Foster, 2013). Wordnet development, like most lexicographic tasks, is slow and expensive. Moving away from the original Princeton Wordnet (Fellbaum, 1998) development workflow, wordnet creation and expansion has increasingly been shifting towards an automated and/or interactive system facilitated task. In the particular case of human edition/expansion of wordnets, a few systems have been developed to aid the lexicographersxe2x80x99 work. Unfortunately, most of these tools have either restricted licenses, or have been designed with a particular language in mind. We present a webbased system that is capable of multilingual browsing and editing for any of the hundreds of languages made available by the OMW. All tools and guidelines are freely available under an open license."
W14-0106,Bringing together over- and under- represented languages: Linking {W}ord{N}et to the {SIL} Semantic Domains,2014,17,1,3,0,38879,muhammad rosman,Proceedings of the Seventh Global {W}ordnet Conference,0,"We have created an open-source mapping between the SILxe2x80x99s semantic domains (used for rapid lexicon building and organization for under-resourced languages) and WordNet, the standard resource for lexical semantics in natural language processing. We show that the resources complement each other, and suggest ways in which the mapping can be improved even further. The semantic domains give more general domain and associative links, which wordnet still has few of, while wordnet gives explicit semantic relations between senses, which the domains lack."
W14-0125,Parse Ranking with Semantic Dependencies and {W}ord{N}et,2014,22,0,4,0,38900,xiaocheng yin,Proceedings of the Seventh Global {W}ordnet Conference,0,"In this paper, we investigate which features are useful for ranking semantic representations of text. We show that two methods of generalization improved results: extended grand-parenting and supertypes. The models are tested on a subset of SemCor that has been annotated with both Dependency Minimal Recursion Semantic representations and WordNet senses. Using both types of features gives a significant improvement in whole sentence parse selection accuracy over the baseline model."
W14-0132,A Survey of {W}ord{N}et Annotated Corpora,2014,43,16,2,0,36141,tommaso petrolito,Proceedings of the Seventh Global {W}ordnet Conference,0,"This paper surveys the current state of wordnet sense annotated corpora. We look at corpora in any language, and describe them in terms of accessibility and usefulness. We finally discuss possibilities in increasing the interoperability of the corpora, especially across languages."
W14-0154,Issues in building {E}nglish-{C}hinese parallel corpora with {W}ord{N}ets.,2014,19,2,1,1,6126,francis bond,Proceedings of the Seventh Global {W}ordnet Conference,0,"We discuss some of the issues in producing sense-tagged parallel corpora: including pre-processing, adding new entries and linking. We have preliminary results for three genres: stories, essays and tourism web pages, in both Chinese and English."
S14-2094,{S}ensible: {L}2 Translation Assistance by Emulating the Manual Post-Editing Process,2014,14,2,4,1,10447,liling tan,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper describes the Post-Editor Z system submitted to the L2 writing assistant task in SemEval-2014. The aim of task is to build a translation assistance system to translate untranslated sentence fragments. This is not unlike the task of post-editing where human translators improve machine-generated translations. Post-Editor Z emulates the manual process of post-editing by (i) crawling and extracting parallel sentences that contain the untranslated fragments from a Web-based translation memory, (ii) extracting the possible translations of the fragments indexed by the translation memory and (iii) applying simple cosine-based sentence similarity to rank possible translations for the untranslated fragment."
ho-etal-2014-identifying,Identifying Idioms in {C}hinese Translations,2014,12,0,4,0,39656,wan ho,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Optimally, a translated text should preserve information while maintaining the writing style of the original. When this is not possible, as is often the case with figurative speech, a common practice is to simplify and make explicit the implications. However, in our investigations of translations from English to another language, English-to-Chinese texts were often found to include idiomatic expressions (usually in the form of Chengyu {\ae}ÂÂ{\`e} Ì) where there were originally no idiomatic, metaphorical, or even figurative expressions. We have created an initial small lexicon of Chengyu, with which we can use to find all occurrences of Chengyu in a given corpus, and will continue to expand the database. By examining the rates and patterns of occurrence across four genres in the NTU Multilingual Corpus, a resource may be created to aid machine translation or, going further, predict Chinese translational trends in any given genre."
wang-bond-2014-building,Building The Sense-Tagged Multilingual Parallel Corpus,2014,24,1,2,1,11705,shan wang,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"Sense-annotated parallel corpora play a crucial role in natural language processing. This paper introduces our progress in creating such a corpus for Asian languages using English as a pivot, which is the first such corpus for these languages. Two sets of tools have been developed for sequential and targeted tagging, which are also easy to set up for any new language in addition to those we are annotating. This paper also briefly presents the general guidelines for doing this project. The current results of monolingual sense-tagging and multilingual linking are illustrated, which indicate the differences among genres and language pairs. All the tools, guidelines and the manually annotated corpus will be freely available at compling.ntu.edu.sg/ntumc."
C14-2019,{NTU}-{MC} Toolkit: Annotating a Linguistically Diverse Corpus,2014,8,4,2,1,10447,liling tan,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: System Demonstrations",0,"The NTU-MC Toolkit is a compilation of tools to annotate the Nanyang Technological University - Multilingual Corpus (NTU-MC). The NTU-MC is a parallel corpora of linguistically diverse languages (Arabic, English, Indonesian, Japanese, Korean, Mandarin Chinese, Thai and Vietnamese). The NTU-MC thrives on the mantra of more data is better data and more annotation is better information. Other than increasing parallel data from diverse language pairs, annotating the corpus with various layers of information allows corpora linguists to discover linguistic phenomena and provides computational linguists with pre-annotated features for various NLP tasks. In addition to the agglomeration existing tools into a single python wrapper library, we have implemented three tools (Mini-segmenter, GaChalign and Indotag) that (i) provides users with varying analysis of the corpus, (ii) improves the state-of-art performance and (iii) reimplements a previously unavailable annotation tool as a free and open tool. This paper briefly describes the wrapper classes available in the toolkit and introduces and demonstrates the usage of the Mini-segmenter, GaChalign and Indotag."
W13-4302,Building the {C}hinese Open {W}ordnet ({COW}): Starting from Core Synsets,2013,16,19,2,1,11705,shan wang,Proceedings of the 11th Workshop on {A}sian Language Resources,0,"Princeton WordNet (PWN) is one of the most influential resources for semantic descriptions, and is extensively used in natural language processing. Based on PWN, three Chinese wordnets have been developed: Sinica Bilingual Ontological Wordnet (BOW), Southeast University WordNet (SEW), and Taiwan University WordNet (CWN). We used SEW to sense-tag a corpus, but found some issues with coverage and precision. We decided to make a new Chinese wordnet based on SEW to increase the coverage and accuracy. In addition, a small scale Chinese wordnet was constructed from open multilingual wordnet (OMW) using data from Wiktionary (WIKT). We then merged SEW and WIKT. Starting from core synsets, we formulated guidelines for the new Chinese Open Wordnet (COW). We compared the five Chinese wordnets, which shows that COW is currently the best, but it still has room for further improvement, especially with polysemous words. It is clear that building an accurate semantic resource for a language is not an easy task, but through consistent efforts, we will be able to achieve it. COW is released under the same license as the PWN, an open license that freely allows use, adaptation and redistribution."
W13-2319,Developing Parallel Sense-tagged Corpora with Wordnets,2013,25,7,1,1,6126,francis bond,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"Semantically annotated corpora play an important role in natural language processing. This paper presents the results of a pilot study on building a sense-tagged parallel corpus, part of ongoing construction of aligned corpora for four languages (English, Chinese, Japanese, and Indonesian) in four domains (story, essay, news, and tourism) from the NTU-Multilingual Corpus. Each subcorpus is first sensetagged using a wordnet and then these synsets are linked. Upon the completion of this project, all annotated corpora will be made freely available. The multilingual corpora are designed to not only provide data for NLP tasks like machine translation, but also to contribute to the study of translation shift and bilingual lexicography as well as the improvement of monolingual wordnets."
S13-2030,{XLING}: Matching Query Sentences to a Parallel Corpus using Topic Models for {WSD},2013,0,5,2,1,10447,liling tan,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes the XLING system participation in SemEval-2013 Crosslingual Word Sense Disambiguation task. The XLING system introduces a novel approach to skip the sense disambiguation step by matching query sentences to sentences in a parallel corpus using topic models; it returns the word alignments as the translation for the target polysemous words. Although, the topic-model base matching underperformed, the matching approach showed potential in the simple cosine-based surface similarity matching."
P13-1133,Linking and Extending an Open Multilingual {W}ordnet,2013,25,111,1,1,6126,francis bond,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We create an open multilingual wordnet with large wordnets for over 26 languages and smaller ones for 57 languages. It is made by combining wordnets with open licences, data from Wiktionary and the Unicode Common Locale Data Repository. Overall there are over 2 million senses for over 100 thousand concepts, linking over 1.4 million words in hundreds of languages."
Y12-1028,Comparing Classifier use in {C}hinese and {J}apanese,2012,7,0,2,0,41962,yue ting,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,Numeral classifiers present a challenge to successful machine translation. We investigate two numeral classifier languages: Mandarin Chinese and Japanese. This paper presents a quantitative analysis of classifier translations between these two languages to better understand differences in classifier usage.
W12-4203,Enriching Parallel Corpora for Statistical Machine Translation with Semantic Negation Rephrasing,2012,19,11,2,0,33898,dominikus wetzel,"Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"This paper presents an approach to improving performance of statistical machine translation by automatically creating new training data for difficult to translate phenomena. In particular this contribution is targeted towards tackling the poor performance of a state-of-the-art system on negated sentences. The corpus expansion is achieved by high quality rephrasing of existing sentences to their negated counterparts making use of semantic transfer. The method is designed to work on both sides of the parallel corpus while preserving the alignment. Our results show an overall improvement of 0.16 BLEU points, with a statistically significant increase of 1.63 BLEU points when tested on only negated test data."
W12-4208,Extracting Semantic Transfer Rules from Parallel Corpora with {SMT} Phrase Aligners,2012,14,0,2,1,35297,petter haugereid,"Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"This paper presents two procedures for extracting transfer rules from parallel corpora for use in a rule-based Japanese-English MT system. First a shallow method where the parallel corpus is lemmatized before it is aligned by a phrase aligner, and then a deep method where the parallel corpus is parsed by deep parsers before the resulting predicates are aligned by phrase aligners. In both procedures, the phrase tables produced by the phrase aligners are used to extract semantic transfer rules. The procedures were employed on a 10 million word Japanese English parallel corpus and 190,000 semantic transfer rules were extracted."
U12-1009,Segmentation and Translation of {J}apanese Multi-word Loanwords,2012,12,1,3,1,31040,james breen,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"The Japanese language has absorbed large numbers of loanwords from many languages, in particular English. As well as using single loanwords, compound nouns, multiword expressions (MWEs), etc. constructed from loanwords can be found in use in very large quantities. In this paper we describe a system which has been developed to segment Japanese loanword MWEs and construct likely English translations. The system, which leverages the availability of large bilingual dictionaries of loanwords and English n-gram corpora, achieves high levels of accuracy in discriminating between single loanwords and MWEs, and in segmenting MWEs. It also generates useful translations of MWEs, and has the potential to being a major aid to lexicographers in this area."
P12-2025,Cross-lingual Parse Disambiguation based on Semantic Correspondence,2012,13,2,2,0,1785,lea frermann,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We present a system for cross-lingual parse disambiguation, exploiting the assumption that the meaning of a sentence remains unchanged during translation and the fact that different languages have different ambiguities. We simultaneously reduce ambiguity in multiple languages in a fully automatic way. Evaluation shows that the system reliably discards dispreferred parses from the raw parser output, which results in a pre-selection that can speed up manual treebanking."
Y11-1027,Creating the Open {W}ordnet {B}ahasa,2011,10,23,3,0,43944,nurril noor,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"This paper outlines the creation of the Wordnet Bahasa as a resource for the study of lexical semantics in the Malay language. It is created by combining information from several lexical resources: the French-English-Malay dictionary FEM, the KAmus Melayu- Inggeris KAMI, and wordnets for English, French and Chinese. Construction went through three steps: (i) automatic building of word candidates; (ii ) evaluation and selection of accept- able candidates from merging of lexicons; (iii) final hand ch eck of the 5,000 core synsets. Our Wordnet Bahasa is only in the first phase of building a full fledged wordNet and needs to be further expanded, however it is already large enough to be useful for sense tagging both Malay and Indonesian."
Y11-1038,Building and Annotating the Linguistically Diverse {NTU}-{MC} ({NTU}-Multilingual Corpus),2011,29,5,2,1,10447,liling tan,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"The NTU-MC compilation taps on the linguistic diversity of multilingual texts available within Singapore. The current version of NTU-MC contains 375,000 words (15,000 sentences) in 6 languages (English, Chinese, Japanese, Korean, Indonesian and Vietnamese) from 6 language families (Indo-European, Sino-Tibetan, Japonic, Korean as a language isolate, Austronesian and Austro-Asiatic). The NTU-MC is annotated with a layer of monolingual annotation (POS tags) and cross-lingual annotation (sentence-level alignments). The diverse language data and cross-lingual annotations provide valuable information on linguistic diversity for traditional linguistic research as well as natural language processing tasks. This paper describes the corpus compilation process with the evaluation of the monolingual and cross-lingual annotations of the corpus data. The corpus is available under the Creative Commons - Attribute 3.0 Unported license (CC by)."
W11-0814,Extracting Transfer Rules for Multiword Expressions from Parallel Corpora,2011,19,8,2,1,35297,petter haugereid,Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,0,This paper presents a procedure for extracting transfer rules for multiword expressions from parallel corpora for use in a rule based Japanese-English MT system. We show that adding the multi-word rules improves translation quality and sketch ideas for learning more such rules.
J11-1011,"Book Review: Language, Technology, and Society by Richard Sproat",2011,-1,-1,1,1,6126,francis bond,Computational Linguistics,0,None
W10-3219,Development of the {K}orean Resource Grammar: Towards Grammar Customization,2010,15,3,3,1,15853,sanghoun song,Proceedings of the Eighth Workshop on {A}sian Language Resouces,0,"The Korean Resource Grammar (KRG) is a computational open-source grammar of Korean (Kim and Yang, 2003) that has been constructed within the DELPH-IN consortium since 2003. This paper reports the second phase of the KRG development that moves from a phenomenabased approach to grammar customization using the LinGO Grammar Matrix. This new phase of development not only improves the parsing efficiency but also adds generation capacity, which is necessary for many NLP applications."
W09-3401,Enhancing the {J}apanese {W}ord{N}et,2009,20,72,1,1,6126,francis bond,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"The Japanese WordNet currently has 51,000 synsets with Japanese entries. In this paper, we discuss three methods of extending it: increasing the cover, linking it to examples in corpora and linking it to other resources (SUMO and GoiTaikei). In addition, we outline our plans to make it more useful by adding Japanese definition sentences to each synset. Finally, we discuss how releasing the corpus under an open license has led to the construction of interfaces in a variety of programming languages."
W09-3026,Online Search Interface for the {S}ejong {K}orean-{J}apanese Bilingual Corpus and Auto-interpolation of Phrase Alignment,2009,3,1,2,1,15853,sanghoun song,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"A user-friendly interface to search bilingual resources is of great help to NLP developers as well as pure-linguists. Using bilingual resources is difficult for linguists who are unfamiliar with computation, which hampers capabilities of bilingual resources. NLP developers sometimes need a kind of workbench to check their resources. The online interface this paper introduces can satisfy these needs. In order to implement the interface, this research deals with how to align Korean and Japanese phrases and interpolates them into the original bilingual corpus in an automatic way."
P09-2028,Using Generation for Grammar Analysis and Error Detection,2009,9,6,2,0.380435,6141,michael goodman,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"We demonstrate that the bidirectionality of deep grammars, allowing them to generate as well as parse sentences, can be used to automatically and effectively identify errors in the grammars. The system is tested on two implemented HPSG grammars: Jacy for Japanese, and the ERG for English. Using this system, we were able to increase generation coverage in Jacy by 18% (45% to 63%) with only four weeks of grammar development."
D09-1097,Hypernym Discovery Based on Distributional Similarity and Hierarchical Structures,2009,21,40,7,0,300,ichiro yamada,Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,0,"This paper presents a new method of developing a large-scale hyponymy relation database by combining Wikipedia and other Web documents. We attach new words to the hyponymy database extracted from Wikipedia by using distributional similarity calculated from documents on the Web. For a given target word, our algorithm first finds k similar words from the Wikipedia database. Then, the hypernyms of these k similar words are assigned scores by considering the distributional similarities and hierarchical distances in the Wikipedia database. Finally, new hyponymy relations are output according to the scores. In this paper, we tested two distributional similarities. One is based on raw verb-noun dependencies (which we call RVD), and the other is based on a large-scale clustering of verb-noun dependencies (called CVD). Our method achieved an attachment accuracy of 91.0% for the top 10,000 relations, and an attachment accuracy of 74.5% for the top 100,000 relations when using CVD. This was a far better outcome compared to the other baseline approaches. Excluding the region that had very high scores, CVD was found to be more effective than RVD. We also confirmed that most relations extracted by our method cannot be extracted merely by applying the well-known lexico-syntactic patterns to Web documents."
bond-etal-2008-boot,Boot-Strapping a {W}ord{N}et Using Multiple Existing {W}ord{N}ets,2008,12,28,1,1,6126,francis bond,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,In this paper we describe the construction of an illustrated Japanese Wordnet. We bootstrap the Wordnet using existing multiple existing wordnets in order to deal with the ambiguity inherent in translation. We illustrate it with pictures from the Open Clip Art Library.
isahara-etal-2008-development,Development of the {J}apanese {W}ord{N}et,2008,6,79,2,0,15925,hitoshi isahara,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"After a long history of compilation of our own lexical resources, EDR Japanese/English Electronic Dictionary, and discussions with major players on development of various WordNets, Japanese National Institute of Information and Communications Technology started developing the Japanese WordNet in 2006 and will publicly release the first version, which includes both the synset in Japanese and the annotated Japanese corpus of SemCor, in June 2008. As the first step in compiling the Japanese WordNet, we added Japanese equivalents to synsets of the Princeton WordNet. Of course, we must also add some synsets which do not exist in the Princeton WordNet, and must modify synsets in the Princeton WordNet, in order to make the hierarchical structure of Princeton synsets represent thesaurus-like information found in the Japanese language, however, we will address these tasks in a future study. We then translated English sentences which are used in the SemCor annotation into Japanese and annotated them using our Japanese WordNet. This article describes the overview of our project to compile Japanese WordNet and other resources which relate to our Japanese WordNet."
kanzaki-etal-2008-extraction,Extraction of Attribute Concepts from {J}apanese Adjectives,2008,7,4,2,0,15923,kyoko kanzaki,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We describe various syntactic and semantic conditions for finding abstractnouns which refer to concepts of adjectives from a text, in an attempt to explore the creation of a thesaurus from text. Depending on usages, six kinds of syntactic patterns are shown. In the syntactic and semantic conditions an omission of an abstract noun is mainly used, but in addition, various linguistic clues are needed. We then compare our results with synsets of Japanese WordNet. From a viewpoint of Japanese WordNet, the degree of agreement of ?Attribute? between our data and Japanese WordNet was 22{\%}. On the other hand, the total number of differences of obtained abstract nouns was 267. From a viewpoint of our data,the degree of agreement of abstract nouns between our data and Japanese WordNet was 54{\%}."
I08-2108,{MRD}-based Word Sense Disambiguation: Further Extending {L}esk,2008,12,14,3,0.142021,1468,timothy baldwin,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"This paper reconsiders the task of MRDbased word sense disambiguation, in extending the basic Lesk algorithm to investigate the impact onWSD performance of different tokenisation schemes, scoring mechanisms, methods of gloss extension and filtering methods. In experimentation over the Lexeed Sensebank and the Japanese Senseval2 dictionary task, we demonstrate that character bigrams with sense-sensitive gloss extension over hyponyms and hypernyms enhances WSD performance."
2008.iwslt-papers.2,Improving statistical machine translation by paraphrasing the training data.,2008,21,30,1,1,6126,francis bond,Proceedings of the 5th International Workshop on Spoken Language Translation: Papers,0,"Large amounts of training data are essential for training statistical machine translations systems. In this paper we show how training data can be expanded by paraphrasing one side. The new data is made by parsing then generating using a precise HPSG based grammar, which gives sentences with the same meaning, but minor variations in lexical choice and word order. In experiments with Japanese and English, we showed consistent gains on the Tanaka Corpus with less consistent improvement on the IWSLT 2005 evaluation data."
2008.amta-govandcom.3,Sharing User Dictionaries Across Multiple Systems with {UTX}-{S},2008,-1,-1,1,1,6126,francis bond,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Government and Commercial Uses of MT,0,"Careful tuning of user-created dictionaries is indispensable when using a machine translation system for computer aided translation. However, there is no widely used standard for user dictionaries in the Japanese/English machine translation market. To address this issue, AAMT (the Asia-Pacific Association for Machine Translation) has established a specification of sharable dictionaries (UTX-S: Universal Terminology eXchange -- Simple), which can be used across different machine translation systems, thus increasing the interoperability of language resources. UTX-S is simpler than existing specifications such as UPF and OLIF. It was explicitly designed to make it easy to (a) add new user dictionaries and (b) share existing user dictionaries. This facilitates rapid user dictionary production and avoids vendor tie in. In this study we describe the UTX-Simple (UTX-S) format, and show that it can be converted to the user dictionary formats for five commercial English-Japanese MT systems. We then present a case study where we (a) convert an on-line glossary to UTX-S, and (b) produce user dictionaries for five different systems, and then exchange them. The results show that the simplified format of UTX-S can be used to rapidly build dictionaries. Further, we confirm that customized user dictionaries are effective across systems, although with a slight loss in quality: on average, user dictionaries improved the translations for 44.8{\%} of translations with the systems they were built for and 37.3{\%} of translations for different systems. In ongoing work, AAMT is using UTX-S as the format in building up a user community for producing, sharing, and accumulating user dictionaries in a sustainable way."
W07-1204,Exploiting Semantic Information for {HPSG} Parse Selection,2007,26,28,2,1,44776,sanae fujita,{ACL} 2007 Workshop on Deep Linguistic Processing,0,"In this paper we present a framework for experimentation on parse selection using syntactic and semantic features. Results are given for syntactic features, dependency relations and the use of semantic classes."
D07-1050,Word Sense Disambiguation Incorporating Lexical and Structural Semantic Information,2007,21,14,2,1,29830,takaaki tanaka,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We present results that show that incorporating lexical and structural semantic information is effective for word sense disambiguation. We evaluated the method by using precise information from a large treebank and an ontology automatically created from dictionary sentences. Exploiting rich semantic and structural information improves precision 2xe2x80x903%. The most gains are seen with verbs, with an improvement of 5.7% over a model using only bag of words and n-gram features."
2007.tmi-papers.17,Combining resources for open source machine translation,2007,19,4,2,1,31491,eric nichols,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"In this paper, we present a Japanesexe2x86x92English machine translation system that combines rule-based and statistical translation. Our system is unique in that all of its components are freely available as open source software. We describe the development of the rule-based translation engine including transfer rule acquisition from an open bilingual dictionary. We also show how translations from both translation engines are combined through a simple ranking mechanism and compare their outputs."
W06-1106,Sentence Comparison Using Robust {M}inimal {R}ecursion {S}emantics and an Ontology,2006,14,5,2,0,39167,rebecca dridan,Proceedings of the Workshop on Linguistic Distances,0,"We design and test a sentence comparison method using the framework of Robust Minimal Recursion Semantics which allows us to utilise the deep parse information produced by Jacy, a Japanese HPSG based parser and the lexical information available in our ontology. Our method was used for both paraphrase detection and also for answer sentence selection for question answering. In both tasks, results showed an improvement over Bag-of-Words, as well as providing extra information useful to the applications."
W06-0608,The Hinoki Sensebank {---} A Large-Scale Word Sense Tagged Corpus of {J}apanese {---},2006,11,7,2,1,29830,takaaki tanaka,Proceedings of the Workshop on Frontiers in Linguistically Annotated Corpora 2006,0,"Semantic information is important for precise word sense disambiguation system and the kind of semantic analysis used in sophisticated natural language processing such as machine translation, question answering, etc. There are at least two kinds of semantic information: lexical semantics for words and phrases and structural semantics for phrases and sentences.n n We have built a Japanese corpus of over three million words with both lexical and structural semantic information. In this paper, we focus on our method of annotating the lexical semantics, that is building a word sense tagged corpus and its properties."
W06-0502,Multilingual Ontology Acquisition from Multiple {MRD}s,2006,18,10,2,1,31491,eric nichols,Proceedings of the 2nd Workshop on Ontology Learning and Population: Bridging the Gap between Text and Knowledge,0,"In this paper, we outline the development of a system that automatically constructs ontologies by extracting knowledge from dictionary definition sentences using Robust Minimal Recursion Semantics (RMRS). Combining deep and shallow parsing resource through the common formalism of RMRS allows us to extract ontological relations in greater quantity and quality than possible with any of the methods independently. Using this method, we construct ontologies from two different Japanese lexicons and one English lexicon. We then link them to existing, handcrafted ontologies, aligning them at the word-sense level. This alignment provides a representative evaluation of the quality of the relations being extracted. We present the results of this ontology construction and discuss how our system was designed to handle multiple lexicons and languages."
P06-4017,An Implemented Description of {J}apanese: The {L}exeed Dictionary and the {H}inoki Treebank,2006,8,3,3,1,44776,sanae fujita,Proceedings of the {COLING}/{ACL} 2006 Interactive Presentation Sessions,0,"In this paper we describe the current state of a new Japanese lexical resource: the Hinoki treebank. The treebank is built from dictionary definition sentences, and uses an HPSG based Japanese grammar to encode both syntactic and semantic information. It is combined with an ontology based on the definition sentences to give a detailed sense level description of the most familiar 28,000 words of Japanese."
P05-1041,High Precision {T}reebanking{---}{B}lazing Useful Trees Using {POS} Information,2005,17,13,2,1,29830,takaaki tanaka,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"In this paper we present a quantitative and qualitative analysis of annotation in the Hinoki treebank of Japanese, and investigate a method of speeding annotation by using part-of-speech tags. The Hinoki treebank is a Redwoods-style treebank of Japanese dictionary definition sentences. 5,000 sentences are annotated by three different annotators and the agreement evaluated. An average agreement of 65.4% was found using strict agreement, and 83.5% using labeled precision. Exploiting POS tags allowed the annotators to choose the best parse with 19.5% fewer decisions."
I05-6004,Integration of a Lexical Type Database with a Linguistically Interpreted Corpus,2005,15,1,2,0,26950,chikara hashimoto,Proceedings of the Sixth International Workshop on Linguistically Interpreted Corpora ({LINC}-2005),0,"We have constructed a large scale and detailed database of lexical types in Japanese from a treebank that includes detailed linguistic information. The database helps treebank annotators and grammar developers to share precise knowledge about the grammatical status of words that constitute the treebank, allowing for consistent large scale treebanking and grammar development. In this paper, we report on the motivation and methodology of the database construction."
2005.mtsummit-papers.1,Extracting Representative Arguments from Dictionaries for Resolving Zero Pronouns,2005,10,2,3,0,49596,shigeko nariyama,Proceedings of Machine Translation Summit X: Papers,0,"We propose a method to alleviate the problem of referential granularity for Japanese zero pronoun resolution. We use dictionary definition sentences to extract {`}representative{'} arguments of predicative definition words; e.g. {`}arrest{'} is likely to take police as the subject and criminal as its object. These representative arguments are far more informative than {`}person{'} that is provided by other valency dictionaries. They are auto-extracted using both Shallow parsing and Deep parsing for greater quality and quantity. Initial results are highly promising, obtaining more specific information about selectional preferences. An architecture of zero pronoun resolution using these representative arguments is described."
2005.mtsummit-papers.22,{SEM}-{I} Rational {MT}: Enriching Deep Grammars with a Semantic Interface for Scalable Machine Translation,2005,11,15,5,0,26293,dan flickinger,Proceedings of Machine Translation Summit X: Papers,0,"In the LOGON machine translation system where semantic transfer using Minimal Recursion Semantics is being developed in conjunction with two existing broad-coverage grammars of Norwegian and English, we motivate the use of a grammar-specific semantic interface (SEM-I) to facilitate the construction and maintenance of a scalable translation engine. The SEM-I is a theoretically grounded component of each grammar, capturing several classes of lexical regularities while also serving the crucial engineering function of supplying a reliable and complete specification of the elementary predications the grammar can realize. We make extensive use of underspecification and type hierarchies to maximize generality and precision."
2005.mtsummit-osmtw.3,Open Source Machine Translation with {DELPH}-{IN},2005,0,27,1,1,6126,francis bond,Workshop on open-source machine translation,0,The Deep Linguistic Processing with HPSG Initiative (DELPH-IN) provides the infrastructure needed to produce open-source semantic transfer-based...
W04-2206,A Method of Creating New Bilingual Valency Entries using Alternations,2004,11,2,2,1,44776,sanae fujita,Proceedings of the Workshop on Multilingual Linguistic Resources,0,"We present a method that uses alternation data to add new entries to an existing bilingual valency lexicon. If the existing lexicon has only one half of the alternation, then our method constructs the other half. The new entries have detailed information about argument structure and selectional restrictions. In this paper we focus on one class of alternations, but our method is applicable to any alternation. We were able to increase the coverage of the causative alternation to 98%, and the new entries gave an overall improvement in translation quality of 32%."
W04-1901,The Hinoki Treebank. Working Toward Text Understanding,2004,27,2,1,1,6126,francis bond,Proceedings of the 5th International Workshop on Linguistically Interpreted Corpora,0,None
copestake-etal-2004-lexicon,A Lexicon Module for a Grammar Development Environment,2004,7,11,4,0.395461,6790,ann copestake,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,Past approaches to developing an effective lexicon component in a grammar development environment have suffered from a number of usability and efficiency issues. We present a lexical database module currently in use by a number of grammar development projects. The database module presented addresses issues which have caused problems in the past and the power of a database architecture provides a number of practical advantages as well as a solid framework for future extension.
C04-1193,Acquiring an Ontology for a Fundamental Vocabulary,2004,16,14,1,1,6126,francis bond,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"In this paper we describe the extraction of thesaurus information from parsed dictionary definition sentences. The main data for our experiments comes from Lexeed, a Japanese semantic dictionary, and the Hinoki treebank built on it. The dictionary is parsed using a head-driven phrase structure grammar of Japanese. Knowledge is extracted from the semantic representation (Minimal Recursion Semantics). This makes the extraction process language independent."
2004.tmi-1.6,An automatic method of creating valency entries using plain bilingual dictionaries,2004,7,5,2,1,44776,sanae fujita,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
W03-1010,A Plethora of Methods for Learning {E}nglish Countability,2003,14,20,2,0.419286,1468,timothy baldwin,Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,0,"This paper compares a range of methods for classifying words based on linguistic diagnostics, focusing on the task of learning countabilities for English nouns. We propose two basic approaches to feature representation: distribution-based representation, which simply looks at the distribution of features in the corpus data, and agreement-based representation which analyses the level of token-wise agreement between multiple preprocessor systems. We additionally compare a single multiclass classifier architecture with a suite of binary classifiers, and combine analyses from multiple preprocessors. Finally, we present and evaluate a feature selection method."
P03-1059,Learning the Countability of {E}nglish Nouns from Corpus Data,2003,16,46,2,0.419286,1468,timothy baldwin,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"This paper describes a method for learning the countability preferences of English nouns from raw text corpora. The method maps the corpus-attested lexico-syntactic properties of each noun onto a feature vector, and uses a suite of memory-based classifiers to predict membership in 4 countability classes. We were able to assign countability to English nouns with a precision of 94.6%."
2003.mtsummit-papers.3,Evaluation of a method of creating new valency entries,2003,-1,-1,1,1,6126,francis bond,Proceedings of Machine Translation Summit IX: Papers,0,"Information on subcategorization and selectional restrictions is important for natural language processing tasks such as deep parsing, rule-based machine translation and automatic summarization. In this paper we present a method of adding detailed entries to a bilingual dictionary, based on information in an existing valency dictionary. The method is based on two assumptions: words with similar meaning have similar subcategorization frames and selectional restrictions; and words with the same translations have similar meanings. Based on these assumptions, new valency entries are constructed from words in a plain bilingual dictionary, using entries with similar source-language meaning and the same target-language translations. We evaluate the effects of various measures of similarity in increasing accuracy."
W02-1608,Extending the Coverage of a Valency Dictionary,2002,6,3,2,1,44776,sanae fujita,{COLING}-02: Machine Translation in Asia,0,"Information on subcategorization and selectional restrictions is very important for natural language processing in tasks such as monolingual parsing, accurate rule-based machine translation and automatic summarization. However, adding this detailed information to a valency dictionary is both time consuming and costly.In this paper we present a method of assigning valency information and selectional restrictions to entries in a bilingual dictionary, based on information in an existing valency dictionary. The method is based on two assumptions: words with similar meaning have similar subcategorization frames and selectional restrictions; and words with the same translations have similar meanings. Based on these assumptions, new valency entries are constructed for words in a plain bilingual dictionary, using entries with similar source-language meaning and the same target-language translations. We evaluate the effects of various measures of similarity."
shirai-etal-2002-towards,Towards a Thesaurus of Predicates,2002,4,2,3,0.594716,51459,satoshi shirai,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"We propose a thesaurus of predicates that can help to resolve pre-editing and/or post-editing problems in machine translation environments. It differs from earlier approaches such as conventional dictionaries in that we are aiming to link a wide range of near-synonyms and paraphrases. We are compiling such similar examples through both introspection and the use of translation data, giving us a large collection of monolingual and bilingual equivalences. This thesaurus enables the following machine translation techniques. (a) Unification of synonymous expressions in the source language (source language paraphrasing). (b) Conversion of homonymous expressions to more easily translated ones (source language rewriting). (c) Development of expressions appearing in the target language into various expressions (target language paraphrasing)."
copestake-etal-2002-multiword,Multiword expressions: linguistic precision and reusability,2002,4,52,4,0.395461,6790,ann copestake,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper discusses the approach to multiword expressions being adopted in the LinGO English Resource Grammar (http://lingo.stanford.edu), a broad-scale bidirectional grammar of English in the HPSG framework. We discuss how the lexicon of multiword expressions is encoded in a database and describe the implications for building a reusable lexical resource."
C02-1052,Using an Ontology to Determine {E}nglish Countability,2002,12,18,1,1,6126,francis bond,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"In this paper we show to what degree the countability of English nouns is predictable from their semantics. We found that at 78% of nouns' countability could be predicted using an ontology of 2,710 nodes. We also show how this predictability can be used to aid non-native speakers to determine the countability of English nouns when building a bilingual machine translation lexicon."
2002.tmi-tmiw.2,Toward a science of machine translation,2002,10,3,1,1,6126,francis bond,Workshop on machine translation roadmap,0,None
2002.tmi-papers.2,Alternation-based lexicon reconstruction,2002,10,2,2,0.419286,1468,timothy baldwin,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"This research is aimed at developing a hierarchical alternation-based lexical architecture for machine translation. The proposed architecture makes extensive use of information sharing in describing valency frames through derivational links from base frames, rather than as independent entities. This has advantages in descriptive exe2x80x90ciency, robustness and maintainability. The lexicon being developed is built up automatically from the Japanese component of an existing Japanese-English machine translation lexicon. The reconstruction process consists of analysing consistencies in selectional restrictions between valency frames, and postulating alternations where selectional restrictions are preserved on matching case slots; this was found to perform at 60.9% accuracy. All alternation candidates are incorporated into the flnal-version lexicon as derivational links, and expanded out at run time."
2002.tmi-papers.6,A method of adding new entries to a valency dictionary by exploiting existing lexical resources,2002,-1,-1,2,1,44776,sanae fujita,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
2001.mtsummit-papers.10,Design and construction of a machine-tractable {J}apanese-{M}alay dictionary,2001,6,22,1,1,6126,francis bond,Proceedings of Machine Translation Summit VIII,0,"We present a method for combining two bilingual dictionaries to make a third, using one language as a pivot. In this case we combine a Japanese-English dictionary with a Malay-English dictionary, to produce a Japanese-Malay dictionary suitable for use in a machine translation system. Our method differs from previous methods in its use of semantic classes to rank translation equivalents: word pairs with compatible semantic classes are preferred to those with dissimilar classes. We also experiment with the use of two pivot languages. We have made a prototype dictionary of over 75,000 pairs."
W00-1701,Semantic Annotation of a {J}apanese Speech Corpus,2000,9,1,2,0,51230,john fry,Proceedings of the {COLING}-2000 Workshop on Semantic Annotation and Intelligent Content,0,"This paper describes the semantic annotations we are performing on the CallHome Japanese corpus of spontaneous, unscripted telephone conversations (LDC, 1996). Our annotations include (i) semantic classes for all nouns and verbs; (ii) verb senses for all main verbs; and (iii) relations between main verbs and their complements in the same utterance. Our semantic tagset is taken from NTT's Goi-Taikei semantic lexicon and ontology (Ikehara et al., 1997). A pilot study demonstrates that the verb sense tagging can be efficiently performed by native Japanese speakers using computer-generated HTML forms, and that good inter-annotator reliability can be obtained in the right conditions."
W00-0708,Memory-Based Learning for Article Generation,2000,14,57,2,0,53749,guido minnen,Fourth Conference on Computational Natural Language Learning and the Second Learning Language in Logic Workshop,0,"Article choice can pose difficult problems in applications such as machine translation and automated summarization. In this paper, we investigate the use of corpus data to collect statistical generalizations about article use in English in order to be able to generate articles automatically to supplement a symbolic generator. We use data from the Penn Treebank as input to a memory-based learner (TiMBL 3.0; Daelemans et al., 2000) which predicts whether to generate an article with respect to an English base noun phrase. We discuss competitive results obtained using a variety of lexical, syntactic and semantic features that play an important role in automated article generation."
C00-1014,Reusing an ontology to generate numeral classifiers,2000,8,16,1,1,6126,francis bond,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"In this paper, we present a solution to the problem of generating Japanese numeral classifiers using semantic classes from an ontology. Most nouns must take a numeral classifier when they are quantified in languages such as Chinese, Japanese, Korean, Malay and Thai. In order to select an appropriate classifier, we propose an algorithm which associates classifiers with semantic classes and uses inheritance to list only those classifiers which have to be listed. It generates sortal classifiers with an accuracy of 81%. We reuse the ontology provided by Goi-Taikei---a Japanese lexicon, and show that it is a reasonable choice for this task, requiring information to be entered for less than 6% of individual nouns."
1999.tmi-1.21,A valency dictionary architecture for Machine Translation,1999,14,12,2,0.344678,1468,timothy baldwin,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1999.mtsummit-1.66,{ALT}-{J}/{M} a prototype {J}apanese-to-{M}alay translation system,1999,6,5,2,1,54027,kentaro ogura,Proceedings of Machine Translation Summit VII,0,"In this report we introduce ALT-J/M: a prototype Japanese-to-Malay translation system. The system is a semantic transfer based system that uses the same translation engine as ALT-J/E, a Japanese-to-English system."
P98-1023,Anchoring Floating Quantifiers in {J}apanese-to-{E}nglish Machine Translation,1998,12,3,1,1,6126,francis bond,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"In this paper we present an algorithm to anchor floating quantifiers in Japanese, a language in which quantificational nouns and numeral-classifier combinations can appear separated from the noun phrase they quantify. The algorithm differentiates degree and event modifiers from nouns that quantify noun phrases. It then finds a suitable anchor for such floating quantifiers. To do this, the algorithm considers the part of speech of the quantifier and the target, the semantic relation between them, the case marker of the antecedent and the meaning of the verb that governs the two constituents. The algorithm has been implemented and tested in a rule-based Japanese-to-English machine translation system, with an accuracy of 76% and a recall of 97%."
C98-1023,Anchoring Floating Quantifiers in {J}apanese-to-{E}nglish Machine Translation,1998,12,3,1,1,6126,francis bond,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"In this paper we present an algorithm to anchor floating quantifiers in Japanese, a language in which quantificational nouns and numeral-classifier combinations can appear separated from the noun phrase they quantify. The algorithm differentiates degree and event modifiers from nouns that quantify noun phrases. It then finds a suitable anchor for such floating quantifiers. To do this, the algorithm considers the part of speech of the quantifier and the target, the semantic relation between them, the case marker of the antecedent and the meaning of the verb that governs the two constituents. The algorithm has been implemented and tested in a rule-based Japanese-to-English machine translation system, with an accuracy of 76% and a recall of 97%."
1997.tmi-1.7,Temporal expressions in {J}apanese-to-{E}nglish machine translation,1997,-1,-1,1,1,6126,francis bond,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1997.tmi-1.11,{E}nglish adverb processing in {J}apanese-to-{E}nglish machine translation,1997,0,0,3,1,54027,kentaro ogura,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
C96-1023,Classifiers in {J}apanese-to-{E}nglish Machine Translation,1996,11,15,1,1,6126,francis bond,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"This paper proposes an analysis of classifiers into four major types: UNIT, METRIC, GROUP and SPECIES, based on properties of both Japanese and English. The analysis makes possible a uniform and straightforward treatment of noun phrases headed by classifiers in Japanese-to-English machine translation, and has been implemented in the MT system ALT-J/E. Although the analysis is based on the characteristics of, and differences between, Japanese and English, it is shown to be also applicable to the unrelated language Thai."
1995.tmi-1.1,Noun Phrase Reference in {J}apanese to {E}nglish Machine Translation,1995,-1,-1,1,1,6126,francis bond,Proceedings of the Sixth Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
C94-1002,Countability and Number in {J}apanese to {E}nglish Machine Translation,1994,4,31,1,1,6126,francis bond,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper presents a heuristic method that uses information in the Japanese text along with knowledge of English countability and number stored in transfer dictionaries to determine the countability and number of English noun phrases. Incorporating this method into the machine translation system ALT-J/E, helped to raise the percentage of noun phrases generated with correct use of articles and number from 65% to 73%."
A94-1032,Automatic Aquisition of Semantic Attributes for User Defined Words m {J}apanese to {E}nglish Machine Translation,1994,3,0,4,0,47595,satoru ikehara,Fourth Conference on Applied Natural Language Processing,0,This paper proposes a method that automatically acquires the SAs (semantic attributes) of user defined words. Applying this method to the compilation of a user dictionary targeting newspaper article sentences and sentences of software design documents has revealed that the automatically determined SAs include 50 to 80% of the correct attributes. Translation experiments confirmed that the automatically acquired SAs improved translation quality by 6-13%.
A94-1035,{E}nglish Adverb Generation in {J}apanese to {E}nglish Machine Translation,1994,2,1,2,0,54027,kentaro ogura,Fourth Conference on Applied Natural Language Processing,0,"This paper proposes an English adverb ordering method based on adverb grammatical functions (subjuncts, adjuncts, disjuncts and conjuncts) and meanings (process, space, time etc.), preferred positions in sentences (initial, medial, end, pre, post), and priorities between adverbs with the same preferred position."
