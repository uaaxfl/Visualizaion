2021.emnlp-main.826,A New Representation for Span-based {CCG} Parsing,2021,-1,-1,2,0,10254,yoshihide kato,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"This paper proposes a new representation for CCG derivations. CCG derivations are represented as trees whose nodes are labeled with categories strictly restricted by CCG rule schemata. This characteristic is not suitable for span-based parsing models because they predict node labels independently. In other words, span-based models may generate invalid CCG derivations that violate the rule schemata. Our proposed representation decomposes CCG derivations into several independent pieces and prevents the span-based parsing models from violating the schemata. Our experimental result shows that an off-the-shelf span-based parser with our representation is comparable with previous CCG parsers."
2020.lrec-1.87,Relation between Degree of Empathy for Narrative Speech and Type of Responsive Utterance in Attentive Listening,2020,-1,-1,4,0,16787,koichiro ito,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Nowadays, spoken dialogue agents such as communication robots and smart speakers listen to narratives of humans. In order for such an agent to be recognized as a listener of narratives and convey the attitude of attentive listening, it is necessary to generate responsive utterances. Moreover, responsive utterances can express empathy to narratives and showing an appropriate degree of empathy to narratives is significant for enhancing speaker{'}s motivation. The degree of empathy shown by responsive utterances is thought to depend on their type. However, the relation between responsive utterances and degrees of the empathy has not been explored yet. This paper describes the classification of responsive utterances based on the degree of empathy in order to explain that relation. In this research, responsive utterances are classified into five levels based on the effect of utterances and literature on attentive listening. Quantitative evaluations using 37,995 responsive utterances showed the appropriateness of the proposed classification."
2020.emnlp-main.218,Parsing Gapping Constructions Based on Grammatical and Semantic Roles,2020,-1,-1,2,1,10254,yoshihide kato,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,A gapping construction consists of a coordinated structure where redundant elements are elided from all but one conjuncts. This paper proposes a method of parsing sentences with gapping to recover elided elements. The proposed method is based on constituent trees annotated with grammatical and semantic roles that are useful for identifying elided elements. Our method outperforms the previous method in terms of F-measure and recall.
P19-1530,{PTB} Graph Parsing with Tree Approximation,2019,0,0,2,1,10254,yoshihide kato,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"The Penn Treebank (PTB) represents syntactic structures as graphs due to nonlocal dependencies. This paper proposes a method that approximates PTB graph-structured representations by trees. By our approximation method, we can reduce nonlocal dependency identification and constituency parsing into single tree-based parsing. An experimental result demonstrates that our approximation method with an off-the-shelf tree-based constituency parser significantly outperforms the previous methods in nonlocal dependency identification."
Y18-1030,Model-Theoretic Incremental Interpretation Based on {D}iscourse {R}epresentation {T}heory,2018,0,0,2,1,10254,yoshihide kato,"Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation",0,None
L18-1676,Statistical Analysis of Missing Translation in Simultaneous Interpretation Using A Large-scale Bilingual Speech Corpus,2018,0,0,3,0,30281,zhongxi cai,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
P16-1088,Transition-Based Left-Corner Parsing for Identifying {PTB}-Style Nonlocal Dependencies,2016,29,3,2,1,10254,yoshihide kato,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,This paper proposes a left-corner parser which can identify nonlocal dependencies. Our parser integrates nonlocal dependency identification into a transition-based system. We use a structured perceptron which enables our parser to utilize global features captured by nonlocal dependencies. An experimental result demonstrates that our parser achieves a good balance between constituent parsing and nonlocal dependency identification.
L16-1244,Correcting Errors in a Treebank Based on Tree Mining,2016,4,1,3,0,34983,kanta suzuki,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper provides a new method to correct annotation errors in a treebank. The previous error correction method constructs a pseudo parallel corpus where incorrect partial parse trees are paired with correct ones, and extracts error correction rules from the parallel corpus. By applying these rules to a treebank, the method corrects errors. However, this method does not achieve wide coverage of error correction. To achieve wide coverage, our method adopts a different approach. In our method, we consider that an infrequent pattern which can be transformed to a frequent one is an annotation error pattern. Based on a tree mining technique, our method seeks such infrequent tree patterns, and constructs error correction rules each of which consists of an infrequent pattern and a corresponding frequent pattern. We conducted an experiment using the Penn Treebank. We obtained 1,987 rules which are not constructed by the previous method, and the rules achieved good precision."
W15-4709,{J}apanese Word Reordering Executed Concurrently with Dependency Parsing and Its Evaluation,2015,10,0,4,1,16789,tomohiro ohno,Proceedings of the 15th {E}uropean Workshop on Natural Language Generation ({ENLG}),0,This paper proposes a method for reordering words in a Japanese sentence based on concurrent execution with dependency parsing so that the sentence becomes more readable. Our contributions are summarized as follows: (1) we extend a probablistic model used in the previous work which concurrently performs word reordering and dependency parsing; (2) we conducted an evaluation experiment using our semi-automatically constructed evaluation data so that sentences in the data are more likely to be spontaneously written by natives than the automatically constructed evaluation data in the previous work.
S15-1032,Incremental Semantic Construction Using Normal Form {CCG} Derivation,2015,26,0,2,1,10254,yoshihide kato,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"This paper proposes a method of incrementally constructing semantic representations. Our method is based on Steedmanxe2x80x99s Combinatory Categorial Grammar (CCG), which has a transparent correspondence between the syntax and semantics. In our method, a derivation for a sentence is constructed in an incremental fashion and the corresponding semantic representation is derived synchronously. Our method uses normal form CCG derivation. This is the difference between our approach and previous ones. Previous approaches use most left-branching derivation called incremental derivation, but they cannot process coordinate structures incrementally. Our method overcomes this problem."
C14-1112,{J}apanese Word Reordering Integrated with Dependency Parsing,2014,15,1,4,0,36589,kazushi yoshida,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Although Japanese has relatively free word order, Japanese word order is not completely arbitrary and has some sort of preference. Since such preference is incompletely understood, even native Japanese writers often write Japanese sentences which are grammatically well-formed but not easy to read. This paper proposes a method for reordering words in a Japanese sentence so that the sentence becomes more readable. Our method can identify more suitable word order than conventional word reordering methods by concurrently performing dependency parsing and word reordering instead of sequentially performing the two processing steps. As the result of an experiment on word reordering using newspaper articles, we confirmed the effectiveness of our method."
W13-5710,Dependency Structure for Incremental Parsing of {J}apanese and Its Application,2013,0,0,2,1,16789,tomohiro ohno,Proceedings of the 13th International Conference on Parsing Technologies ({IWPT} 2013),0,None
W10-4335,Coherent Back-Channel Feedback Tagging of In-Car Spoken Dialogue Corpus,2010,7,4,3,0,45096,yuki kamiya,Proceedings of the {SIGDIAL} 2010 Conference,0,"This paper describes the design of a back-channel feedback corpus and its evaluation, aiming at realizing in-car spoken dialogue systems with high responsiveness. We constructed our corpus by annotating the existing in-car spoken dialogue data with back-channel feedback timing information in an off-line environment. Our corpus can be practically used in developing dialogue systems which can provide verbal back-channel feedbacks. As the results of our evaluation, we confirmed that our proposed design enabled the construction of back-channel feedback corpora with high coherency and naturalness."
P10-2014,Correcting Errors in a Treebank Based on Synchronous Tree Substitution Grammar,2010,10,13,2,1,10254,yoshihide kato,Proceedings of the {ACL} 2010 Conference Short Papers,0,"This paper proposes a method of correcting annotation errors in a treebank. By using a synchronous grammar, the method transforms parse trees containing annotation errors into the ones whose errors are corrected. The synchronous grammar is automatically induced from the treebank. We report an experimental result of applying our method to the Penn Treebank. The result demonstrates that our method corrects syntactic annotation errors with high precision."
kamiya-etal-2010-construction,Construction of Back-Channel Utterance Corpus for Responsive Spoken Dialogue System Development,2010,7,2,3,0,45096,yuki kamiya,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In spoken dialogues, if a spoken dialogue system does not respond at all during userÂs utterances, the user might feel uneasy because the user does not know whether or not the system has recognized the utterances. In particular, back-channel utterances, which the system outputs as voices such as ÂyeahÂ and Âuh huhÂ in English have important roles for a driver in in-car speech dialogues because the driver does not look owards a listener while driving. This paper describes construction of a back-channel utterance corpus and its analysis to develop the system which can output back-channel utterances at the proper timing in the responsive in-car speech dialogue. First, we constructed the back-channel utterance corpus by integrating the back-channel utterances that four subjects provided for the driverÂs utterances in 60 dialogues in the CIAIR in-car speech dialogue corpus. Next, we analyzed the corpus and revealed the relation between back-channel utterance timings and information on bunsetsu, clause, pause and rate of speech. Based on the analysis, we examined the possibility of detecting back-channel utterance timings by machine learning technique. As the result of the experiment, we confirmed that our technique achieved as same detection capability as a human."
murata-etal-2010-construction,Construction of Chunk-Aligned Bilingual Lecture Corpus for Simultaneous Machine Translation,2010,7,0,3,0,16788,masaki murata,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"With the development of speech and language processing, speech translation systems have been developed. These studies target spoken dialogues, and employ consecutive interpretation, which uses a sentence as the translation unit. On the other hand, there exist a few researches about simultaneous interpreting, and recently, the language resources for promoting simultaneous interpreting research, such as the publication of an analytical large-scale corpus, has been prepared. For the future, it is necessary to make the corpora more practical toward realization of a simultaneous interpreting system. In this paper, we describe the construction of a bilingual corpus which can be used for simultaneous lecture interpreting research. Simultaneous lecture interpreting systems are required to recognize translation units in the middle of a sentence, and generate its translation at the proper timing. We constructed the bilingual lecture corpus by the following steps. First, we segmented sentences in the lecture data into semantically meaningful units for the simultaneous interpreting. And then, we assigned the translations to these units from the viewpoint of the simultaneous interpreting. In addition, we investigated the possibility of automatically detecting the simultaneous interpreting timing from our corpus."
kozawa-etal-2010-collection,Collection of Usage Information for Language Resources from Academic Articles,2010,6,0,4,1,30018,shunsuke kozawa,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Recently, language resources (LRs) are becoming indispensable for linguistic researches. However, existing LRs are often not fully utilized because their variety of usage is not well known, indicating that their intrinsic value is not recognized very well either. Regarding this issue, lists of usage information might improve LR searches and lead to their efficient use. In this research, therefore, we collect a list of usage information for each LR from academic articles to promote the efficient utilization of LRs. This paper proposes to construct a text corpus annotated with usage information (UI corpus). In particular, we automatically extract sentences containing LR names from academic articles. Then, the extracted sentences are annotated with usage information by two annotators in a cascaded manner. We show that the UI corpus contributes to efficient LR searches by combining the UI corpus with a metadata database of LRs and comparing the number of LRs retrieved with and without the UI corpus."
D10-1087,Automatic Comma Insertion for {J}apanese Text Generation,2010,9,3,3,0,16788,masaki murata,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"This paper proposes a method for automatically inserting commas into Japanese texts. In Japanese sentences, commas play an important role in explicitly separating the constituents, such as words and phrases, of a sentence. The method can be used as an elemental technology for natural language generation such as speech recognition and machine translation, or in writing-support tools for non-native speakers. We categorized the usages of commas and investigated the appearance tendency of each category. In this method, the positions where commas should be inserted are decided based on a machine learning approach. We conducted a comma insertion experiment using a text corpus and confirmed the effectiveness of our method."
P09-2011,Incremental Parsing with Monotonic Adjoining Operation,2009,9,0,2,1,10254,yoshihide kato,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"This paper describes an incremental parser based on an adjoining operation. By using the operation, we can avoid the problem of infinite local ambiguity in incremental parsing. This paper further proposes a restricted version of the adjoining operation, which preserves lexical dependencies of partial parse trees. Our experimental results showed that the restriction enhances the accuracy of the incremental parsing."
P09-1060,Linefeed Insertion into {J}apanese Spoken Monologue for Captioning,2009,11,5,3,1,16789,tomohiro ohno,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"To support the real-time understanding of spoken monologue such as lectures and commentaries, the development of a captioning system is required. In monologues, since a sentence tends to be long, each sentence is often displayed in multi lines on one screen, it is necessary to insert linefeeds into a text so that the text becomes easy to read. This paper proposes a technique for inserting linefeeds into a Japanese spoken monologue text as an elemental technique to generate the readable captions. Our method appropriately inserts linefeeds into a sentence by machine learning, based on the information such as dependencies, clause boundaries, pauses and line length. An experiment using Japanese speech data has shown the effectiveness of our technique."
kozawa-etal-2008-automatic,Automatic Acquisition of Usage Information for Language Resources,2008,10,5,4,1,30018,shunsuke kozawa,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Recently, language resources (LRs) are becoming indispensable for linguistic research. Unfortunately, it is not easy to find their usages by searching the web even though they must be described in the Internet or academic articles. This indicates that the intrinsic value of LRs is not recognized very well. In this research, therefore, we extract a list of usage information for each LR to promote the efficient utilization of LRs. In this paper, we proposed a method for extracting a list of usage information from academic articles by using rules based on syntactic information. The rules are generated by focusing on the syntactic features that are observed in the sentences describing usage information. As a result of experiments, we achieved 72.9{\%} in recall and 78.4{\%} in precision for the closed test and 60.9{\%} in recall and 72.7{\%} in precision for the open test."
tohyama-etal-2008-construction-metadata,Construction of a Metadata Database for Efficient Development and Use of Language Resources,2008,2,2,4,1,46266,hitomi tohyama,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The National Institute of Information and Communications Technology (NICT) and Nagoya University have been jointly constructing a large scale database named SHACHI by collecting detailed meta-information on language resources (LRs) in Asia and Western countries, for the purpose of effectively combining LRs. The purpose of this project is to investigate languages, tag sets, and formats compiled in LRs throughout the world, to systematically store LR metadata, to create a search function for this information, and to ultimately utilize all this for a more efficient development of LRs. This metadata database contains more than 2,000 compiled LRs such as corpora, dictionaries, thesauruses and lexicons, forming a large scale metadata of LRs archive. Its metadata, an extended version of OLAC metadata set conforming to Dublin Core, which contain detailed meta-information, have been collected semi-automatically. This paper explains the design and the structure of the metadata database, as well as the realization of the catalogue search tool. Additionally, the website of this database is now open to the public and accessible to all Internet users."
ono-etal-2008-construction,Construction and Analysis of Word-level Time-aligned Simultaneous Interpretation Corpus,2008,10,5,3,0,48373,takahiro ono,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper, quantitative analyses of the delay in Japanese-to-English (J-E) and English-to-Japanese (E-J) interpretations are described. The Simultaneous Interpretation Database of Nagoya University (SIDB) was used for the analyses. Beginning time and end time of each word were provided to the corpus using HMM-based phoneme segmentation, and the time lag between the corresponding words was calculated as the word-level delay. Word-level delay was calculated for 3,722 pairs and 4,932 pairs of words for J-E and E-J interpretations, respectively. The analyses revealed that J-E interpretation has much larger delay than E-J interpretation and that the difference of word order between Japanese and English affect the degree of delay."
C08-2030,Construction of an Infrastructure for Providing Users with Suitable Language Resources,2008,0,1,4,1,46266,hitomi tohyama,Coling 2008: Companion volume: Posters,0,"Our research organization has been constructing a large scale database named SHACHI by collecting detailed meta information on language resources (LRs) in Asia and Western countries. The metadata database contains more than 2,000 compiled LRs such as corpora, dictionaries, thesauruses and lexicons, forming a large scale metadata of LRs archive. Its metadata, an extended version of OLAC metadata set conforming to Dublin Core, have been collected semi-automatically. This paper explains the design and the structure of the metadata database, as well as the realization of the catalogue search tool."
P06-2088,Simultaneous {E}nglish-{J}apanese Spoken Language Translation Based on Incremental Dependency Parsing and Transfer,2006,14,8,2,0,30282,koichiro ryu,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"This paper proposes a method for incrementally translating English spoken language into Japanese. To realize simultaneous translation between languages with different word order, such as English and Japanese, our method utilizes the feature that the word order of a target language is flexible. To resolve the problem of generating a grammatically incorrect sentence, our method uses dependency structures and Japanese dependency constraints to determine the word order of a translation. Moreover, by considering the fact that the inversion of predicate expressions occurs more frequently in Japanese spoken language, our method takes advantage of a predicate inversion to resolve the problem that Japanese has the predicate at the end of a sentence. Furthermore, our method includes the function of canceling an inversion by restating a predicate when the translation is incomprehensible due to the inversion. We implement a prototype translation system and conduct an experiment with all 578 sentences in the ATIS corpus. The results indicate improvements in comparison to two other methods."
P06-1022,Dependency Parsing of {J}apanese Spoken Monologue Based on Clause Boundaries,2006,21,8,2,1,16789,tomohiro ohno,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"Spoken monologues feature greater sentence length and structural complexity than do spoken dialogues. To achieve high parsing performance for spoken monologues, it could prove effective to simplify the structure by dividing a sentence into suitable language units. This paper proposes a method for dependency parsing of Japanese monologues based on sentence segmentation. In this method, the dependency parsing is executed in two stages: at the clause level and the sentence level. First, the dependencies within a clause are identified by dividing a sentence into clauses and executing stochastic dependency parsing for each clause. Next, the dependencies over clause boundaries are identified stochastically, and the dependency structure of the entire sentence is thus completed. An experiment using a spoken monologue corpus shows this method to be effective for efficient dependency parsing of Japanese monologue sentences."
irie-etal-2006-layered,Layered Speech-Act Annotation for Spoken Dialogue Corpus,2006,18,0,2,0,50135,yuki irie,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes the design of speech act tags for spoken dialogue corpora and its evaluation. Compared with the tags used for conventional corpus annotation, the proposed speech intention tag is specialized enough to determine system operations. However, detailed information description increases tag types. This causes an ambiguous tag selection. Therefore, we have designed an organization of tags, with focusing attention on layered tagging and context-dependent tagging. Over 35,000 utterance units in the CIAIR corpus have been tagged by hand. To evaluate the reliability of the intention tag, a tagging experiment was conducted. The reliability of tagging is evaluated by comparing the tagging among some annotators using kappa value. As a result, we confirmed that reliable data could be built. This corpus with speech intention tag could be widely used from basic research to applications of spoken dialogue. In particular, this would play an important role from the viewpoint of practical use of spoken dialogue corpora."
ohno-etal-2006-syntactically,A Syntactically Annotated Corpus of {J}apanese Spoken Monologue,2006,8,4,2,1,16789,tomohiro ohno,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Recently, monologue data such as lecture and commentary by professionals have been considered as valuable intellectual resources, and have been gathering attention. On the other hand, in order to use these monologue data effectively and efficiently, it is necessary for the monologue data not only just to be accumulated but also to be structured. This paper describes the construction of a Japanese spoken monologue corpus in which dependency structure is given to each utterance. Spontaneous monologue includes a lot of very long sentences composed of two or more clauses. In these sentences, there may exist the subject or the adverb common to multi-clauses, and it may be considered that the subject or adverb depend on multi-predicates. In order to give the dependency information in a real fashion, our research allows that a bunsetsu depends on multiple bunsetsus."
tohyama-matsubara-2006-collection,Collection of Simultaneous Interpreting Patterns by Using Bilingual Spoken Monologue Corpus,2006,4,8,2,1,46266,hitomi tohyama,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The manual quantitative analysis of CIAIR simultaneous interpretation corpus and the collection of interpreting patterns This paper provides an investigation of simultaneous interpreting patterns using a bilingual spoken monologue corpus. 4,578 pairs of English-Japanese aligned utterances in CIAIR simultaneous interpretation database were used. This investigation is the largest scale as the observation of simultaneous interpreting speech. The simultaneous interpreters are required to generate the target speech simultaneously with the source speech. Therefore, they have various kinds of strategies to raise simultaneity. In this investigation, the simultaneous interpreting patterns with high frequency and high flexibility were extracted from the corpus. As a result, we collected 203 cases out of aligned utterances in which simultaneous interpretersÂf strategies for raising simultaneity were observed. These 203 cases could be categorized into 12 types of interpreting pattern. It was clarified that 4.5 percent of the English-Japanese monologue data were fitted in those interpreting patterns. These interpreting patterns can be expected to be used as interpreting rules of simultaneous machine interpretation."
kato-etal-2006-corpus,A Corpus Search System Utilizing Lexical Dependency Structure,2006,4,1,2,1,10254,yoshihide kato,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper presents a corpus search system utilizing lexical dependency structure. The user's query consists of lexical dependency structure. The user's query consists of a sequence of keywords. For a given query, the system automatically generates the dependency structure patterns which consist of keywords in the query, and returns the sentences whose dependency structures match the generated patterns. The dependency structure patterns are generated by using two operations: combining and interpolation, which utilize dependency structures in the searched corpus. The operations enable the system to generate only the dependency structure patterns that occur in the corpus. The system achieves simple and intuitive corpus search and it is enough linguistically sophisticated to utilize structural information."
I05-4006,Construction of Structurally Annotated Spoken Dialogue Corpus,2005,7,1,2,0,50995,shingo kato,Proceedings of the Fifth Workshop on {A}sian Language Resources ({ALR}-05) and First Symposium on {A}sian Language Resources Network ({ALRN}),0,"This paper describes the structural annotation of a spoken dialogue corpus. By statistically dealing with the corpus, the automatic acquisition of dialoguestructural rules is achieved. The dialogue structure is expressed as a binary tree and 789 dialogues consisting of 8150 utterances in the CIAIR speech corpus are annotated. To evaluate the scalability of the corpus for creating dialogue-structural rules, a dialogue parsing experiment was conducted."
W04-0302,Stochastically Evaluating the Validity of Partial Parse Trees in Incremental Parsing,2004,14,7,2,1,10254,yoshihide kato,Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together,0,"This paper proposes a method for evaluating the validity of partial parse trees constructed in incremental parsing. Our method is based on stochastic incremental parsing, and it incrementally evaluates the validity for each partial parse tree on a word-by-word basis. In our method, incremental parser returns partial parse trees at the point where the validity for the partial parse tree becomes greater than a threshold. Our technique is effective for improving the accuracy of incremental parsing."
W03-2112,Example-based Spoken Dialogue System using {WOZ} System Log,2003,13,26,3,0,52632,hiroya murao,Proceedings of the Fourth {SIG}dial Workshop of Discourse and Dialogue,0,None
matsubara-etal-2002-bilingual,Bilingual Spoken Monologue Corpus for Simultaneous Machine Interpretation Research,2002,0,24,1,1,10255,shigeki matsubara,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
kawaguchi-etal-2002-multi,Multi-Dimensional Data Acquisition for Integrated Acoustic Information Research,2002,7,15,2,1,50136,nobuo kawaguchi,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The Center for Integrated Acoustic Information Research (CIAIR) at Nagoya University has been collecting various kinds of speech corpora for both of acoustic modeling and speech modeling. The corpora include multi-media data collection in moving-car environment, collection of children's voice while video gaming, room acoustics at multiple points, head related transfer functions of multiple subjects, and simultaneous interpretation of the speech between English and Japanese. This paper introduces these multi-dimensional data acquisition activities in CIAIR, and gives the basic information of the collected databases."
C02-1107,Example-based Speech Intention Understanding and Its Application to In-Car Spoken Dialogue System,2002,7,10,1,1,10255,shigeki matsubara,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper proposes a method of speech intention understanding based on dialogue examples. The method uses a spoken dialogue corpus with intention tags to regard the intention of each input utterance as that of the sentence to which it is the most similar in the corpus. The degree of similarity is calculated according to the degree of correspondence in morphemes and dependencies between sentences, and it is weighted by the dialogue context information. An experiment on inference of utterance intentions using a large-scale in-car spoken dialogue corpus of CIAIR has shown 68.9% accuracy. Furthermore, we have developed a prototype system of in-car spoken dialogue processing for a restaurant retrieval task based on our method, and confirmed the feasiblity of the system."
C02-1136,Stochastic Dependency Parsing of Spontaneous {J}apanese Spoken Language,2002,5,13,1,1,10255,shigeki matsubara,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper describes the characteristic features of dependency structures of Japanese spoken language by investigating a spoken dialogue corpus, and proposes a stochastic approach to dependency parsing. The method can robustly cope with inversion phenomena and bunsetsus which don't have the head bunsetsu by relaxing the syntactic dependency constraints. The method acquires in advance the probabilities of dependencies from a spoken dialogue corpus tagged with dependency structures, and provides the most plausible dependency structure for each utterance on the basis of the probabilities. An experiment on dependency parsing for driver's utterances in CIAIR in-car spoken dialogue corpus has been made. The experimental result has shown our method to be effective for robust parsing of spoken language."
W01-1825,Efficient Incremental Dependency Parsing,2001,0,2,2,1,10254,yoshihide kato,Proceedings of the Seventh International Workshop on Parsing Technologies,0,None
1997.tmi-1.4,Utilizing extra-grammatical phenomena in incremental {E}nglish-{J}apanese machine translation,1997,-1,-1,1,1,10255,shigeki matsubara,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
