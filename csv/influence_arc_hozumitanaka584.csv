1997.iwpt-1.16,P93-1005,0,0.0808478,"Missing"
1997.iwpt-1.16,J93-1002,0,0.171651,"d associates a probability with each parse derivation, given by the product of the probability of each change included in the derivation. Further, they also described an algorithm to handle this model within the GLR parsing framework, gaining parse efficiency. However, since their probabilistic model in itself is not intimately coupled with the GLR parsing algorithm, their model needs an additional complex algorithm for training. On the other hand, Briscoe and Carroll proposed the distribution of probabilities directly to each action in an LR table to realize mildly context-sensitive parsing' [3] . Their model overcomes the drawback of context insensitivity of PCFGs by estimating the probability of each LR parsing action according to its left (i.e. LR parse state) and right context (i.e. next input symbol) . The probability of each parse derivation is computed as the product of the probability assigned to each action included in the derivation. Unlike the approach of 1 By ""a mildly context-sensitive model"" , we mean a model that is moderately more context-sensitive than context-free models such as PCFGs, but not a fully context-sensitive one, which would b e intractable in both train"
1997.iwpt-1.16,P96-1025,0,0.0949265,"Missing"
1997.iwpt-1.16,W96-0112,0,0.0992357,"Missing"
1997.iwpt-1.16,E91-1004,0,0.038428,"Missing"
1997.iwpt-1.16,C92-2066,0,0.046663,"Missing"
1997.iwpt-1.16,1995.iwpt-1.26,0,0.157225,"Missing"
1997.mtsummit-papers.13,J85-2001,0,0.027667,"ed researchers and research activities which can be seen in the increasing number of the research institutes in the recent years. We learned a lot from the collaboration research across languages and we still hope that it will be a rigorous step for the future MT R&D in this region. Though the MT systems are still far from the extreme goal of the perfect translation, it can be observed that the MT systems are actually used to support information retrieval from the Internet. 1 Introduction Machine translation R&D activities became in sight after the Japanese national MT project, the Mu-project [7]. Multi-lingual Machine Translation (MMT) project was one of the multi-national R&D activities that made a great contribution to the natural language processing community in Asian countries. Many institutes for MT R&D in this region have been established thereafter. Both government and private sectors realize the necessity and the possibility in developing the MT. Though there is a bottleneck in raising the translation accuracy of the MT, users can be satisfied by the speed of translation and user-friendly interface which can somehow support in retrieving information through the Internet. In J"
1999.mtsummit-1.80,C94-1093,0,0.0216485,"rser can work using any tag set and grammar, and using the same input bracketing, we obtain corpus that shares partial syntactic structure. 1 2 2.1 Introduction The ready availability of large corpora, especially bracketed corpora, facilitates corpus-based research such as probabilistic parsing. However each corpus has its own part-of-speech tag sets and notation schemes. Corpusbased markup schemes can become customized to a specific corpus, and incompatible with other corpora with different tag sets or notation schemes. A number of morphological information mapping methods have been proposed [5] [6] [1]. Mapping systems have rewrite rules that are derived automatically or manually, and map part-of-speech tags word by word. But mapping between part-of-speech tags, for example noun to pronoun, cannot be performed because of the large numbers of words with multiple parts-of-speech. Conventional rewrite rules consider - 543- Our Method Two Layered Grammar First of all, let us look at examples of a parse tree. (Figs. 1,2) These two trees describe possible syntactic structures of the Japanese sentence kare ga watashi ni atarashii jisho wo kure ta “He gave me a new dictionary”, where the au"
1999.tmi-1.20,J98-1006,0,0.014156,", ACC stands for the accusative case. Parallels can be drawn between this general method and the conceptual similarity metric of Palmer & Wu (1995). 3 199 Table 3: A fragment of the case marker alternation matrix Note that in the current formulation, we give consideration only to verb sense disambiguation and choose not to independently disambiguate case fillers. Clearly, there is scope to augment this unidirectional verb-driven approach and potentially improve the precision of VSD through intra-case slot local and intra-clausal topical disambiguation techniques (Yarowsky 1994; Ng & Lee 1996; Leacock et al. 1998), as well as through consideration of domain (Wilks & Stevenson 1998), which are left as topics for future research. Case marker alternation Surface case alternates derive from the canonical case marker type(s), and argument status of the target case slot. In the current implementation, this is represented simply as a matrix of possible case marker alternations for each canonical case marker, for a given argument type. This matrix has been developed based around the relative degrees of freedom of case marker alternation outlined in Table 1, in that whereas a complement-type nominative case mar"
1999.tmi-1.20,1997.tmi-1.1,0,0.091756,"Missing"
1999.tmi-1.20,1997.tmi-1.18,0,0.0821482,"Missing"
1999.tmi-1.20,P96-1006,0,0.0173427,"s c1..n: 2 Here, ACC stands for the accusative case. Parallels can be drawn between this general method and the conceptual similarity metric of Palmer & Wu (1995). 3 199 Table 3: A fragment of the case marker alternation matrix Note that in the current formulation, we give consideration only to verb sense disambiguation and choose not to independently disambiguate case fillers. Clearly, there is scope to augment this unidirectional verb-driven approach and potentially improve the precision of VSD through intra-case slot local and intra-clausal topical disambiguation techniques (Yarowsky 1994; Ng & Lee 1996; Leacock et al. 1998), as well as through consideration of domain (Wilks & Stevenson 1998), which are left as topics for future research. Case marker alternation Surface case alternates derive from the canonical case marker type(s), and argument status of the target case slot. In the current implementation, this is represented simply as a matrix of possible case marker alternations for each canonical case marker, for a given argument type. This matrix has been developed based around the relative degrees of freedom of case marker alternation outlined in Table 1, in that whereas a complement-ty"
1999.tmi-1.20,P98-2228,0,0.0146882,"en this general method and the conceptual similarity metric of Palmer & Wu (1995). 3 199 Table 3: A fragment of the case marker alternation matrix Note that in the current formulation, we give consideration only to verb sense disambiguation and choose not to independently disambiguate case fillers. Clearly, there is scope to augment this unidirectional verb-driven approach and potentially improve the precision of VSD through intra-case slot local and intra-clausal topical disambiguation techniques (Yarowsky 1994; Ng & Lee 1996; Leacock et al. 1998), as well as through consideration of domain (Wilks & Stevenson 1998), which are left as topics for future research. Case marker alternation Surface case alternates derive from the canonical case marker type(s), and argument status of the target case slot. In the current implementation, this is represented simply as a matrix of possible case marker alternations for each canonical case marker, for a given argument type. This matrix has been developed based around the relative degrees of freedom of case marker alternation outlined in Table 1, in that whereas a complement-type nominative case marker (ga) can commonly alternate with any of a range of case markers i"
1999.tmi-1.20,H93-1052,0,0.0987019,"Missing"
1999.tmi-1.20,P94-1013,0,0.0127256,"onal constraints c1..n: 2 Here, ACC stands for the accusative case. Parallels can be drawn between this general method and the conceptual similarity metric of Palmer & Wu (1995). 3 199 Table 3: A fragment of the case marker alternation matrix Note that in the current formulation, we give consideration only to verb sense disambiguation and choose not to independently disambiguate case fillers. Clearly, there is scope to augment this unidirectional verb-driven approach and potentially improve the precision of VSD through intra-case slot local and intra-clausal topical disambiguation techniques (Yarowsky 1994; Ng & Lee 1996; Leacock et al. 1998), as well as through consideration of domain (Wilks & Stevenson 1998), which are left as topics for future research. Case marker alternation Surface case alternates derive from the canonical case marker type(s), and argument status of the target case slot. In the current implementation, this is represented simply as a matrix of possible case marker alternations for each canonical case marker, for a given argument type. This matrix has been developed based around the relative degrees of freedom of case marker alternation outlined in Table 1, in that whereas"
2001.mtsummit-papers.28,E99-1024,0,0.0261657,"Missing"
2001.mtsummit-papers.28,C00-2102,0,0.0346535,"Missing"
2001.mtsummit-papers.28,P94-1013,0,0.11332,"Missing"
2001.mtsummit-papers.28,P95-1026,0,0.0291228,"Missing"
baldwin-etal-2002-enhanced,J97-4001,0,\N,Missing
baldwin-etal-2002-enhanced,W99-0902,1,\N,Missing
bilac-etal-2004-evaluating,C02-1140,1,\N,Missing
C00-1006,W99-0902,1,\N,Missing
C00-1006,C92-4203,0,\N,Missing
C00-1006,C94-1101,0,\N,Missing
C00-1006,C94-1014,0,\N,Missing
C02-1059,P92-1008,0,0.126265,"ny ways of dealing with selfcorrection have been proposed, these have limitations in both detecting and correcting for this phenomenon. In this paper, we propose a method to overcome these problems in Japanese speech dialog. We evaluate the proposed method using our speech dialog corpus and discuss its limitations and the work that remains to be done. 1 Introduction Self-correction, or speech repair, is a major source of the dis uencies that speech dialog systems have to resolve. Since Hindle (1983), there have been many proposals as to how speech dialog systems can deal with self-correction (Bear et al., 1992; Nakatani and Hirschberg, 1993; Den, 1997; Nakano and Shimazu, 1998; Core and Schubert, 1999). Through self-monitoring, human speakers can instantly correct their mistakes during an utterance (Levelt, 1989). Therefore, we can detect selfcorrection with local models such as the Repair Interval Model (RIM) proposed by Nakatani and Hirschberg (1993). Most work has used the same model or models similar to the RIM. The RIM divides the self-correction into three intervals, reparandum (RPD), dis uency (DF), and repair (RP), and assumes that these three intervals appear in the order of  . . . RPD DF"
C02-1059,P99-1053,0,0.317329,"th detecting and correcting for this phenomenon. In this paper, we propose a method to overcome these problems in Japanese speech dialog. We evaluate the proposed method using our speech dialog corpus and discuss its limitations and the work that remains to be done. 1 Introduction Self-correction, or speech repair, is a major source of the dis uencies that speech dialog systems have to resolve. Since Hindle (1983), there have been many proposals as to how speech dialog systems can deal with self-correction (Bear et al., 1992; Nakatani and Hirschberg, 1993; Den, 1997; Nakano and Shimazu, 1998; Core and Schubert, 1999). Through self-monitoring, human speakers can instantly correct their mistakes during an utterance (Levelt, 1989). Therefore, we can detect selfcorrection with local models such as the Repair Interval Model (RIM) proposed by Nakatani and Hirschberg (1993). Most work has used the same model or models similar to the RIM. The RIM divides the self-correction into three intervals, reparandum (RPD), dis uency (DF), and repair (RP), and assumes that these three intervals appear in the order of  . . . RPD DF RP . . . ."" For example, [I want]RPD [uh]DF [I want]RP a window seat."" However, human speake"
C02-1059,P83-1019,0,0.275278,"human-human dialog. Self-correction (or speech-repair) is a particularly problematic phenomenon. Although many ways of dealing with selfcorrection have been proposed, these have limitations in both detecting and correcting for this phenomenon. In this paper, we propose a method to overcome these problems in Japanese speech dialog. We evaluate the proposed method using our speech dialog corpus and discuss its limitations and the work that remains to be done. 1 Introduction Self-correction, or speech repair, is a major source of the dis uencies that speech dialog systems have to resolve. Since Hindle (1983), there have been many proposals as to how speech dialog systems can deal with self-correction (Bear et al., 1992; Nakatani and Hirschberg, 1993; Den, 1997; Nakano and Shimazu, 1998; Core and Schubert, 1999). Through self-monitoring, human speakers can instantly correct their mistakes during an utterance (Levelt, 1989). Therefore, we can detect selfcorrection with local models such as the Repair Interval Model (RIM) proposed by Nakatani and Hirschberg (1993). Most work has used the same model or models similar to the RIM. The RIM divides the self-correction into three intervals, reparandum (RP"
C02-1140,baldwin-etal-2002-enhanced,1,0.673826,"ack) transliteration. 2.2 Generating and grading readings In order to generate a set of plausible readings we ﬁrst extract all dictionary entries containing kanji, and for each entry perform the following steps: 1. Segment the kanji string into minimal morphophonemic units3 and align each resulting unit with the corresponding reading. For this purpose, we modiﬁed the TF-IDF based method proposed by Baldwin and Tanaka (2000) to accept bootstrap data. 2. Perform conjugational, phonological and morphological analysis of each segment–reading pair and standardize the reading to canonical form (see Baldwin et al. (2002) for full details). In particular, we consider gemination (onbin) and sequential voicing (rendaku) as the most commonly-occurring phonological alternations in kanji compound formation (Tsujimura, 1996)4 . The canonical reading for a given seg3 A unit is not limited to one character. For example, verbs and adjectives commonly have conjugating suﬃces that are treated as part of the same segment. 4 In the previous example of happyou “announcement” the underlying reading of individual characters are hatsu and hyou respectively. When the compound is formed, hatsu seg correctly identify word bounda"
C02-1140,C00-1050,0,0.0669998,"Missing"
C02-1140,C94-1032,0,0.0431085,"Missing"
C02-1140,C96-2206,0,0.0543478,"Missing"
C02-1140,J98-4003,0,\N,Missing
C04-1086,kang-choi-2000-automatic,0,\N,Missing
C04-1086,C02-1099,0,\N,Missing
C04-1086,W02-2017,0,\N,Missing
C04-1086,W98-1005,0,\N,Missing
C04-1086,P00-1037,0,\N,Missing
C04-1086,J01-3002,0,\N,Missing
C04-1086,J98-4003,0,\N,Missing
C80-1058,T78-1030,0,0.0399031,"Missing"
C80-1058,C80-1004,0,0.0615431,"Missing"
C80-1058,H89-1033,0,0.0493463,"Missing"
C80-1058,J78-3038,0,\N,Missing
C88-2136,C86-1001,0,0.0673329,"Missing"
C88-2136,J83-1005,0,0.233852,"Missing"
C88-2136,J81-4003,0,\N,Missing
C90-2053,W89-0234,1,0.631155,"Missing"
C90-2053,P81-1022,0,0.0751731,"Missing"
C90-2053,J87-1004,0,\N,Missing
C92-1062,P81-1022,0,0.0407128,"Missing"
C92-1062,C90-2004,0,0.0180354,"tractive in t h a t it can be simply added on top of logic grammars that are directly available in Prolog. However, the main drawback in using top down recursive descent parsing methods is that it might result in an infinite loop for left recursive grammars. The recent version using Static Discontinuity Grammars(SDG)[5] augmented with Abramson&apos;s metarules can solve this problem by adding loop control as a constraint on parsing. According to the comparison tests reported in [2], the approach appears to be considerably faster than Popowich&apos;s FIGG. Another approach of Bottom-up filtering strategy[4] attempts to reduce the nondeterminism in parsing. Different ID rules are constrained to have at most one category in common and the knowledge of the leftmost constituent is used for phrase level initialization. As an investigation of our approach, we have implemented a small parser, called GHW, using SlCStus prolog on a Sun 3-60 workstation. To reduce spurious parses, the parser adopts the technique of the left-corner parsing method to detect the edges that canACTESDECOLlNG-92.NAN&apos;I~.23-28hofrr 1992 406 not start a constituent in the bottom-up rules invoking stage. The technique is similar to"
C92-1062,J85-4001,0,\N,Missing
C94-2139,C90-2067,0,0.0234214,"In such cases, we have several category collocations from a single word collocation, some of which are incorrect. TILe choices arc as follows; (1) use word collocations with all words is assigned a single category. (2) equally distribute frequency of word collcations to all possible category collocations [4] (3) calculate the probability of each category collocation and distribute frequency based on these probabilities; the probability of collocations are calculated by using method (2) [4] (4) determine the correct category collocation by using statistical methods other than word collocations [2, 10, 9, 6] Fortunately, there are few words that are itssigned multiple categories in BGH. Therefore, we use method (1). Word collocations containing words with multiple categories represent about 1/3 of the corpus. If we used other thesauruses, which assign multiple categories to more words, we would need to use method (2), (3), or (4). 2.3 Counting Occurrence gory Collocations of CateAfter assigning the thesaurus categories to words, wc count occurrence frequencies of category collocations as follows: 1. collect word collocations, at this time we collect only patterns of word collocations, but we do n"
C94-2139,C92-2070,0,0.0454175,"Missing"
C94-2139,P91-1036,0,\N,Missing
C94-2139,C94-2125,0,\N,Missing
C94-2139,C92-2099,0,\N,Missing
C94-2139,P91-1030,0,\N,Missing
C94-2139,P90-1034,0,\N,Missing
C96-1012,P92-1032,0,0.411131,"Missing"
C96-1012,C94-1049,0,0.155908,"Missing"
C96-1012,P91-1034,0,0.395741,"Missing"
C96-1012,J94-4003,0,0.176682,"Missing"
C96-1012,P95-1026,0,0.135131,"Missing"
C96-2208,C94-1101,0,0.182285,"Missing"
C96-2208,P90-1032,0,0.220697,"Missing"
C96-2208,J90-1003,0,\N,Missing
E99-1013,J90-1003,0,0.100414,"gory as w. 2.3 2.3.1 Corpus-based Thesaurus Co-occurrence-based Thesaurus This method is based on the assumption that a pair of words that frequently occur together in the same document are related to the same subject. Therefore word co-occurrence information can be used to identify semantic relationships between words (Schutze and Pederson, 1997; Schutze and Pederson, 1994). We use mutual information as a 95 tool for computing similarity between words. Mutual information compares the probability of the co-occurence of words a and b with the independent probabilities of occurrence of a and b (Church and Hanks, 1990). P(a, b) I(a, b) = log P(a)P(b) where the probabilities of P(a) and P(b) are estimated by counting the number of occurrences of a and b in documents and normalizing over the size of vocabulary in the documents. The joint probability is estimated by counting the number of times that word a co-occurs with b and is also normalized over the size of the vocabulary. 2.3.2 S y n t a c t i c a l l y - b a s e d T h e s a u r u s In contrast to the previous section, this method attempts to gather term relations on the basis of linguistic relations and not document cooccurrence statistics. Words appear"
E99-1013,P90-1034,0,0.0614803,"he size of vocabulary in the documents. The joint probability is estimated by counting the number of times that word a co-occurs with b and is also normalized over the size of the vocabulary. 2.3.2 S y n t a c t i c a l l y - b a s e d T h e s a u r u s In contrast to the previous section, this method attempts to gather term relations on the basis of linguistic relations and not document cooccurrence statistics. Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class (Lin, 1998; Grefenstette, 1994; Grefenstette, 1992; Ruge, 1992; Hindle, 1990). First, all the documents are parsed using the Apple Pie Parser. The Apple Pie Parser is a natural language syntactic analyzer developed by Satoshi Sekine at New York University (Sekine and Grishman, 1995). The parser is a bottom-up probabilistic chart parser which finds the parse tree with the best score by way of the best-first search algorithm. Its grammar is a semi-context sensitive grammar with two non-terminals and was automatically extracted from Penn Tree Bank syntactically tagged corpus developed at the University of Pennsylvania. The parser generates a syntactic tree in the manner o"
E99-1013,P98-2127,0,0.267177,"Thesaurus (Chapman, 1977), words are classified according to the ideas they express, and these categories of ideas are numbered in sequence. The terms within a category are further organized by part of speech (nouns, verbs, adjectives, adverbs, prepositions, conjunctions, and interjections). Figure 2 shows a fragment of Roget&apos;s category. In this case, our similarity measure treat all the words in Roger as features. A word w possesses the feature f if f and w belong to the same Roget category. The similarity between two words is then defined as the Dice coefficient of the two feature vectors (Lin, 1998). sim(wl,w2) = 21R(wl) n R(w~)l tn(w,)l + In(w )l where R(w) is the set of words that belong to the same Roget category as w. 2.3 2.3.1 Corpus-based Thesaurus Co-occurrence-based Thesaurus This method is based on the assumption that a pair of words that frequently occur together in the same document are related to the same subject. Therefore word co-occurrence information can be used to identify semantic relationships between words (Schutze and Pederson, 1997; Schutze and Pederson, 1994). We use mutual information as a 95 tool for computing similarity between words. Mutual information compares"
E99-1013,1995.iwpt-1.26,0,0.0154909,".3.2 S y n t a c t i c a l l y - b a s e d T h e s a u r u s In contrast to the previous section, this method attempts to gather term relations on the basis of linguistic relations and not document cooccurrence statistics. Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class (Lin, 1998; Grefenstette, 1994; Grefenstette, 1992; Ruge, 1992; Hindle, 1990). First, all the documents are parsed using the Apple Pie Parser. The Apple Pie Parser is a natural language syntactic analyzer developed by Satoshi Sekine at New York University (Sekine and Grishman, 1995). The parser is a bottom-up probabilistic chart parser which finds the parse tree with the best score by way of the best-first search algorithm. Its grammar is a semi-context sensitive grammar with two non-terminals and was automatically extracted from Penn Tree Bank syntactically tagged corpus developed at the University of Pennsylvania. The parser generates a syntactic tree in the manner of a Penn Tree Bank bracketing. Figure 3 shows a parse tree produced by this parser. The main technique used by the parser is the best-first search. Because the grammar is probabilistic, it is enough to find"
E99-1013,C98-2122,0,\N,Missing
I05-2019,bird-etal-2002-tabletrans,0,0.019609,"ocessing research for the last decade. Particularly, syntactically annotated corpora (treebanks), such as Penn Treebank (Marcus et al., 1993), Negra Corpus (Skut et al., 1997) and EDR Corpus (Jap, 1994), contribute to improve the performance of morpho-syntactic analysis systems. It is notorious, however, that building a large treebank is labor intensive and time consuming work. In addition, it is quite difficult to keep quality and consistency of a large treebank. To remedy this problem, there have been many attempts to develop software tools for annotating treebanks (Plaehn and Brants, 2000; Bird et al., 2002). 108 • Annotation plug-in module: This module helps to choose a correct syntactic structure from candidate structures. • Retrieval plug-in module: This module retrieves similar sentences to a sentence in question from already annotated sentences in the treebank. These two plug-in modules work cooperatively in the Eclipse framework. For example, information can be transferred easily between these two modules in a copy-and-past manner. Furthermore, since they are implemented as Eclipse plugin modules, these functionalities can also interact with other plug-in modules and Eclipse native features"
I05-2019,J93-2004,0,0.0268136,"helps annotators to choose a correct syntactic structure of a sentence from outputs of a parser, allowing the annotators to retrieve similar sentences in the treebank for referring to their structures. To realize the tight coupling of annotation and retrieval, eBonsai has been implemented as the following two plug-in modules of an universal tool platform: Eclipse (The Eclipse Foundation, 2001). 1 Introduction Statistical approach has been a main stream of natural language processing research for the last decade. Particularly, syntactically annotated corpora (treebanks), such as Penn Treebank (Marcus et al., 1993), Negra Corpus (Skut et al., 1997) and EDR Corpus (Jap, 1994), contribute to improve the performance of morpho-syntactic analysis systems. It is notorious, however, that building a large treebank is labor intensive and time consuming work. In addition, it is quite difficult to keep quality and consistency of a large treebank. To remedy this problem, there have been many attempts to develop software tools for annotating treebanks (Plaehn and Brants, 2000; Bird et al., 2002). 108 • Annotation plug-in module: This module helps to choose a correct syntactic structure from candidate structures. • R"
I05-2019,A97-1014,0,0.112172,"syntactic structure of a sentence from outputs of a parser, allowing the annotators to retrieve similar sentences in the treebank for referring to their structures. To realize the tight coupling of annotation and retrieval, eBonsai has been implemented as the following two plug-in modules of an universal tool platform: Eclipse (The Eclipse Foundation, 2001). 1 Introduction Statistical approach has been a main stream of natural language processing research for the last decade. Particularly, syntactically annotated corpora (treebanks), such as Penn Treebank (Marcus et al., 1993), Negra Corpus (Skut et al., 1997) and EDR Corpus (Jap, 1994), contribute to improve the performance of morpho-syntactic analysis systems. It is notorious, however, that building a large treebank is labor intensive and time consuming work. In addition, it is quite difficult to keep quality and consistency of a large treebank. To remedy this problem, there have been many attempts to develop software tools for annotating treebanks (Plaehn and Brants, 2000; Bird et al., 2002). 108 • Annotation plug-in module: This module helps to choose a correct syntactic structure from candidate structures. • Retrieval plug-in module: This modu"
I05-2019,1993.iwpt-1.10,0,0.00985978,"and Eclipse native features such as CVS. Figure 1: A snapshot of eBonsai                                                                                                            Figure 2: A workflow of annotation using eBonsai 109 2 Annotating treebanks Figure 2 shows a workflow of annotating a treebank using eBonsai. 1. An annotator picks a sentence to annotate from plain-text corpora. 2. The MSLR parser (Tanaka et al., 1993) performs syntactic analysis of the sentence. 3. The annotator chooses a correct syntactic structure from the output of the parser. If necessary, retrieval of structures in the treebank is available in this step. 4. The annotator adds the chosen syntactic structure to the treebank. The coverage of Japanese grammar used in the MSLR parser is fairly wide. The number of grammar rules of the current system is almost 3,000. That means we have a lot of outputs as a result of syntactic analysis in step 2. These structures are represented in terms of a special data structure called packed shared fores"
I05-2019,yoshida-etal-2004-retrieving,1,0.815903,"ually put constraints to narrow down to a correct structure considering the meaning of a sentence. However, there are cases in which it is difficult to pin down a correct one by referring to only that sentence. Annotators can consult the system to retrieve the similar structure of sentences in the treebank. The retrieval plug-in module provides annotators such functionality. The retrieval plugin module receives a syntactic structure as a query and provides a list of sentences which include the given structure. The retrieval plug-in module has been realized with the method proposed by Yoshida (Yoshida et al., 2004). The method is based on Yoshikawa’s method (Yoshikawa et al., 2001) which was originally proposed for handling XML documents effectively by using relational database (RDB) systems. Yoshida adopted Yoshikawa’s method to deal with syntactic structures in the database. Since an XML document can be represented as a tree, Yoshikawa’s method is also applicable to deal with syntactic structures. Figure 4: An input query for retrieval An input query is given as a tree as shown in Figure 4. The structure is then translated into a SQL query and the retrieval is performed. A query involving a large numb"
I05-4002,J93-2004,0,\N,Missing
I05-4002,J94-4001,0,\N,Missing
I05-4002,W02-2016,0,\N,Missing
I05-4002,P03-1054,0,\N,Missing
I05-4002,J05-1003,0,\N,Missing
I05-4002,C04-1056,0,\N,Missing
I05-4002,W04-3224,0,\N,Missing
J98-4002,P91-1034,0,0.0172838,"Missing"
J98-4002,P94-1020,0,0.00915099,"ough experiments on about one thousand sentences. Compared to experiments with other example sampling methods, our method reduced both the overhead for supervision and the overhead for search, without the degeneration of the performance of the system. 1. Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993). Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995). The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst [1987]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules. Our verb sense disa"
J98-4002,J94-4003,0,0.0096378,"d sentences. Compared to experiments with other example sampling methods, our method reduced both the overhead for supervision and the overhead for search, without the degeneration of the performance of the system. 1. Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993). Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995). The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst [1987]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules. Our verb sense disambiguation system is based on such a"
J98-4002,P96-1042,0,0.41794,"s. During this phase, a human expert supervises samples, that is, provides the correct interpretation for the verbs appearing in the samples. Thereafter, samples are simply incorporated into the database without any computational overhead (as would be associated with globally reestimating parameters in statistics-based systems), meaning that the system can be trained on the remaining examples (the ""residue"") for the next iteration. Iterating between these two 1 Note that these problems are associated with corpus-based approaches in general, and have been identified by a number of researchers (Engelson and Dagan 1996; Lewis and Gale 1994; Uramoto 1994a; Yarowsky 1995). 574 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling sampling ~WSD~sD outu t ~ ~ : ( ~ ~ Figure 1 Flow of control of the example sampling system. phases, the system progressively enhances the database. Note that the selective sampiing procedure gives us an optimally informative database of a given size irrespective of the stage at which processing is terminated. Several researchers have proposed this type of approach for NLP applications. Engelson and Dagan (1996) proposed a committee-based sampling method, which is currently applied to"
J98-4002,C96-1012,1,0.808889,"to experiments with other example sampling methods, our method reduced both the overhead for supervision and the overhead for search, without the degeneration of the performance of the system. 1. Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993). Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995). The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst [1987]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules. Our verb sense disambiguation system is based on such an approach, that is"
J98-4002,C94-2122,0,0.00946794,"tion because the verb in the input is disambiguated by superimposing the sense of the verb appearing in the example of highest similarity.3 The similarity between an input and an example is estimated based on the similarity between case •lers marked with the same case. Furthermore, since the restrictions imposed by the case fillers in choosing the verb sense are not equally selective, Fujii et al. (1996) proposed a weighted case contribution to disambiguation (CCD) of the verb senses. This CCD factor is taken into account 2 Note that unlike the automatic acquisition of word sense definitions (Fukumoto and Tsujii 1994; Pustejovsky and Boguraev 1993; Utsuro 1996; Zernik 1989), the task of the system is to identify the best matched category with a given input, from candidates. 3 In this paper, we use ""example-based systems"" to refer to systems based on nearest neighbor resolution. predefined 576 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling © nominative accusative Figure 3 The semantic ranges of the nominative and accusative for the verb toru. nq-mc~nc Cs~,c~ nc3-rnllc3 v &,;3 -- v ~s3,c2 ~s3,C3- -- V (S3) J database -- (?) G,c2 (s~)l Figure 4 An input and the database. w h e n c o m p u t i n g the s"
J98-4002,P92-1032,0,0.0186836,"Missing"
J98-4002,P91-1019,0,0.0194231,"approaches to word sense disambiguation should be further investigated, this experimental result gives us good motivation to explore example-based verb sense disambiguation approaches, i.e., to introduce the notion of selective sampling into them. 2.4 Enhancement of Verb Sense Disambiguation Let us discuss how further enhancements to our example-based verb sense disambiguation system could be made. First, since inputs are simple sentences, information for word sense disambiguation is inadequate in some cases. External information such as the discourse or domain dependency of each word sense (Guthrie et al. 1991; Nasukawa 1993; Yarowsky 1995) is expected to lead to system improvement. Second, some idiomatic expressions represent highly restricted collocations, and overgeneralizing them semantically through the use of a thesaurus can cause further errors. Possible solutions would include one proposed by Uramoto, in which idiomatic expressions are described separately in the database so that the system can control their overgeneralization (Uramoto 1994b). Third, a number of existing NLP tools such as JUMAN (a morphological analyzer) (Matsumoto et al. 1993) and QJP (a morphological and syntactic analyze"
J98-4002,P90-1034,0,0.0202315,"ion have been proposed, for example, by Yarowsky (1992). 578 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling IIII I I I kare kanojo (he) (she) otoko joshu hisho kane heya kippu uma (man) (assistant) (secretary)(money) (room) (ticket) (horse) Figure 5 A fragment of the Bunruigoihyo thesaurus. statistical factors, although statistical factors are calculated in terms of the predicate argument structure in which each noun appears. Predicate argument structures, which consist of complements (case filler nouns and case markers) and verbs, have also been used in the task of noun classification (Hindle 1990). This can be expressed by Equation (3), where ff is the vector for the noun in question, and items ti represent the statistics for predicate argument structures including n. ff = (h, t2,..., ti . . . . ) (3) In regard to ti, we used the notion of TF. IDF (Salton and McGill 1983). TF (term frequency) gives each context (a case marker/verb pair) importance proportional to the number of times it occurs with a given noun. The rationale behind IDF (inverse document frequency) is that contexts that rarely occur over collections of nouns are valuable, and that therefore the IDF of a context is inver"
J98-4002,C92-2101,0,0.0102778,"Missing"
J98-4002,C96-2104,0,0.0251221,"sukawa 1993; Yarowsky 1995) is expected to lead to system improvement. Second, some idiomatic expressions represent highly restricted collocations, and overgeneralizing them semantically through the use of a thesaurus can cause further errors. Possible solutions would include one proposed by Uramoto, in which idiomatic expressions are described separately in the database so that the system can control their overgeneralization (Uramoto 1994b). Third, a number of existing NLP tools such as JUMAN (a morphological analyzer) (Matsumoto et al. 1993) and QJP (a morphological and syntactic analyzer) (Kameda 1996) could broaden the coverage of our system, as inputs are currently limited to simple, morphologically analyzed sentences. Finally, it should be noted that in Japanese, case markers can be omitted or topicalized (for example, marked with postposition wa), an issue which our framework does not currently consider. 3. Example Sampling Algorithm 3.1 Overview Let us look again at Figure 1 in Section 1. In this figure, ""WSD outputs"" refers to a corpus in which each sentence is assigned an expected verb interpretation during the WSD phase. In the training phase, the system stores supervised samples (w"
J98-4002,H93-1051,0,0.0535285,"Missing"
J98-4002,W96-0208,0,0.0139467,"ly one verb sense remains. W h e n more than one verb sense is selected for any given m e t h o d (or none of them remains, for the rule-based method), the system simply selects the verb sense that appears most frequently in the database, s In the experiment, we conducted sixfold cross-validation, that is, we divided the training/test data into six equal parts, and conducted six trials in which a different 7 A number of experimental results have shown the effectiveness of the Naive-Bayes method for word sense disambiguation (Gale, Church, and Yarowsky 1993; Leacock, Towell, and Voorhees 1993; Mooney 1996; Ng 1997; Pedersen, Bruce, and Wiebe 1997). 8 One may argue that this goes against the basis of the rule-based method, in that, given a proper threshold value for the association degree, the system could improve on accuracy (potentially sacrificing coverage), and that the trade-off between coverage and accuracy is therefore a more appropriate evaluation criterion. However, our trials on the rule-based method with different threshold values did not show significant correlation between the improvement of accuracy and the degeneration of coverage. 581 Computational Linguistics Volume 24, Number"
J98-4002,1993.tmi-1.15,0,0.0285586,"ense disambiguation should be further investigated, this experimental result gives us good motivation to explore example-based verb sense disambiguation approaches, i.e., to introduce the notion of selective sampling into them. 2.4 Enhancement of Verb Sense Disambiguation Let us discuss how further enhancements to our example-based verb sense disambiguation system could be made. First, since inputs are simple sentences, information for word sense disambiguation is inadequate in some cases. External information such as the discourse or domain dependency of each word sense (Guthrie et al. 1991; Nasukawa 1993; Yarowsky 1995) is expected to lead to system improvement. Second, some idiomatic expressions represent highly restricted collocations, and overgeneralizing them semantically through the use of a thesaurus can cause further errors. Possible solutions would include one proposed by Uramoto, in which idiomatic expressions are described separately in the database so that the system can control their overgeneralization (Uramoto 1994b). Third, a number of existing NLP tools such as JUMAN (a morphological analyzer) (Matsumoto et al. 1993) and QJP (a morphological and syntactic analyzer) (Kameda 1996"
J98-4002,W97-0323,0,0.0563667,"ense remains. W h e n more than one verb sense is selected for any given m e t h o d (or none of them remains, for the rule-based method), the system simply selects the verb sense that appears most frequently in the database, s In the experiment, we conducted sixfold cross-validation, that is, we divided the training/test data into six equal parts, and conducted six trials in which a different 7 A number of experimental results have shown the effectiveness of the Naive-Bayes method for word sense disambiguation (Gale, Church, and Yarowsky 1993; Leacock, Towell, and Voorhees 1993; Mooney 1996; Ng 1997; Pedersen, Bruce, and Wiebe 1997). 8 One may argue that this goes against the basis of the rule-based method, in that, given a proper threshold value for the association degree, the system could improve on accuracy (potentially sacrificing coverage), and that the trade-off between coverage and accuracy is therefore a more appropriate evaluation criterion. However, our trials on the rule-based method with different threshold values did not show significant correlation between the improvement of accuracy and the degeneration of coverage. 581 Computational Linguistics Volume 24, Number 4 Table 2"
J98-4002,P96-1006,0,0.0285131,"verhead for search, without the degeneration of the performance of the system. 1. Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993). Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995). The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst [1987]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules. Our verb sense disambiguation system is based on such an approach, that is, an example-based approach. A preliminary experiment showed that our system performs well when compared with sys"
J98-4002,C94-1049,0,0.00878414,"h, without the degeneration of the performance of the system. 1. Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993). Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995). The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst [1987]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules. Our verb sense disambiguation system is based on such an approach, that is, an example-based approach. A preliminary experiment showed that our system performs well when compared with systems based on other a"
J98-4002,A97-1056,0,0.0176876,"Missing"
J98-4002,E95-1016,0,0.0189486,"allow only those nouns dominated by the given class in the thesaurus structure as verb complements. In order to identify appropriate thesaurus classes, we used the association measure proposed by Resnik (1993), which computes the information-theoretic association degree between case fillers and thesaurus classes, for each verb sense (Equation (7)). 6 P(rls, c) A(s,c,r) = P(rls, c) • log p(rlc) (7) 6 Note that previous research has applied this technique to tasks other than verb sense disambiguation, such as syntactic disambiguation (Resnik 1993) and disambiguation of case filler noun senses (Ribas 1995). 580 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling Here, A(s, c, r) is the association degree between verb sense s and class r (selectional restriction candidate) with respect to case c. P(rls, c) is the conditional probability that a case filler example associated with case c of sense s is d o m i n a t e d b y class r in the thesaurus. P(rlc ) is the conditional probability that a case filler example for case c (disregarding verb sense) is d o m i n a t e d b y class r. Each probability is estimated based on training data. We used the semantic classes defined in the Bunruigoihyo thes"
J98-4002,C94-2114,0,0.257712,"erformance of the system. 1. Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993). Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995). The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst [1987]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules. Our verb sense disambiguation system is based on such an approach, that is, an example-based approach. A preliminary experiment showed that our system performs well when compared with systems based on other approaches, and motivated * De"
J98-4002,C96-2163,0,0.0117674,"perimposing the sense of the verb appearing in the example of highest similarity.3 The similarity between an input and an example is estimated based on the similarity between case •lers marked with the same case. Furthermore, since the restrictions imposed by the case fillers in choosing the verb sense are not equally selective, Fujii et al. (1996) proposed a weighted case contribution to disambiguation (CCD) of the verb senses. This CCD factor is taken into account 2 Note that unlike the automatic acquisition of word sense definitions (Fukumoto and Tsujii 1994; Pustejovsky and Boguraev 1993; Utsuro 1996; Zernik 1989), the task of the system is to identify the best matched category with a given input, from candidates. 3 In this paper, we use ""example-based systems"" to refer to systems based on nearest neighbor resolution. predefined 576 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling © nominative accusative Figure 3 The semantic ranges of the nominative and accusative for the verb toru. nq-mc~nc Cs~,c~ nc3-rnllc3 v &,;3 -- v ~s3,c2 ~s3,C3- -- V (S3) J database -- (?) G,c2 (s~)l Figure 4 An input and the database. w h e n c o m p u t i n g the score for each sense of the verb in question."
J98-4002,C94-2169,0,0.127069,"E TU(x = s) (13) sEK 3.4 Enhancement of Computation In this section, we discuss how to enhance the computation associated with our example sampling algorithm. First, we note that computation of TU(x = s) in Equation (11) above becomes time consuming because the system is required to search the whole set of unsupervised examples for examples whose interpretation certainty will increase after x is used for training. To avoid this problem, we could apply a method used in efficient database search techniques, by which the system can search for neighbor examples of x with optimal time complexity (Utsuro et al. 1994). However, in this section, we will explain another efficient algorithm to identify neighbors of x, in which neighbors of case fillers are considered to be given directly by the thesaurus structure. 12 The basic idea is the following: the system searches for neighbors of each case filler of x instead of x as a whole, and merges them as a set of neighbors of x. Note that by dividing examples along the lines of each case filler, we can retrieve neighbors based on the structure of the Bunruigoihyo thesaurus (instead of the conceptual semantic space as in Figure 7). Let Nx=s,c be a subset of unsup"
J98-4002,C92-2070,0,0.0363747,"pace model"" (VSM) (Frakes and Baeza-Yates 1992; Leacock, Towell, and Voorhees 1993; Salton and McGill 1983; Sch/itze 1992), which has a long history of application in information retrieval (IR) and text categorization (TC) tasks. In the case of IR/TC, VSM is used to compute the similarity between documents, which is represented by a vector comprising statistical factors of content words in a document. Similarly, in our case, each noun is represented by a vector comprising 4 Different types of application of hand-crafted thesauri to word sense disambiguation have been proposed, for example, by Yarowsky (1992). 578 Fujii, Inui, Tokunaga, and Tanaka Selective Sampling IIII I I I kare kanojo (he) (she) otoko joshu hisho kane heya kippu uma (man) (assistant) (secretary)(money) (room) (ticket) (horse) Figure 5 A fragment of the Bunruigoihyo thesaurus. statistical factors, although statistical factors are calculated in terms of the predicate argument structure in which each noun appears. Predicate argument structures, which consist of complements (case filler nouns and case markers) and verbs, have also been used in the task of noun classification (Hindle 1990). This can be expressed by Equation (3), wh"
J98-4002,P95-1026,0,0.654354,"he system. 1. Introduction Word sense disambiguation is a potentially crucial task in many NLP applications, such as machine translation (Brown, Della Pietra, and Della Pietra 1991), parsing (Lytinen 1986; Nagao 1994) and text retrieval (Krovets and Croft 1992; Voorhees 1993). Various corpus-based approaches to word sense disambiguation have been proposed (Bruce and Wiebe 1994; Charniak 1993; Dagan and Itai 1994; Fujii et al. 1996; Hearst 1991; Karov and Edelman 1996; Kurohashi and Nagao 1994; Li, Szpakowicz, and Matwin 1995; Ng and Lee 1996; Niwa and Nitta 1994; Sch~itze 1992; Uramoto 1994b; Yarowsky 1995). The use of corpus-based approaches has grown with the use of machine-readable text, because unlike conventional rule-based approaches relying on hand-crafted selectional rules (some of which are reviewed, for example, by Hirst [1987]), corpus-based approaches release us from the task of generalizing observed phenomena through a set of rules. Our verb sense disambiguation system is based on such an approach, that is, an example-based approach. A preliminary experiment showed that our system performs well when compared with systems based on other approaches, and motivated * Department of Libra"
J98-4002,C92-2107,0,\N,Missing
S01-1013,P01-1004,1,0.766483,"in IN;,.., and le~ (IN;,..) is the character bigram length of IN;,... 2 B1gram frequency is weighted according to character type: a bigram made up entirely of hiragana charact~rs (gener_ally used in functional words/ particles) is given a weight of 0.2 and all other bigrams a weight of 1. Note that Dice&apos;s Coefficient ignores segment order, and that each string is thus treated as a ""bag of character bigrams"". Our choice of the combination of Dice&apos;s Coefficient, character-based indexing and character higrams (rather than any other n-gram order or mixed n-gram model) is based on the findings of Baldwin (2001b; 2001a), who compared character- and wordbased indexing in combination with both segment order-sensitive and bag-of-words similarity measures and with various n-gram models. As a result of extensive evaluation, Baldwin found the combination of character bigram-based indexing and a bagof-words method (in the form of either the vector space model or Dice&apos;s Coefficient) to be optimal. Our choice of Dice&apos;s Coefficient over the vector space m?del is due to the vector space model tending to bhthely prefer shorter strings in cases of low-level character overlap, and the ability of Dice&apos;s Coefficien"
S01-1013,H92-1045,0,0.0170499,"by the analysis of punctuation. These clause-level instances served as the inputs for the str·uctur·al method. We 2 freqTR;(e) 56 and len(TRi) are defined similarly. inputs with translation records is undesirable as high levels of spurious matches can be expected outside the scope of the original translation record expression. Inter-comparison of full inputs, on the other hand, provides a primitive model of domain similarity. Assuming that high similarity correlates with a high level of domain correspondence, we can apply a cross-lingual corollary of the ""one sense per discourse"" observation (Gale et al., 1992) in stipulating that a given word will be translated consistently within a given domain. By ascertaining that a given input closely resembles a second input, we can use the combined translation retrieval results for the two inputs to hone in on the optimal translation for the two. We term this procedure domain-based similarity consolidation. The overall retrieval process thus involves: (1) carrying out standard translation retrieval based on the abbreviated input, (2) using the original test set to determine the full input string most similar to the current input, and (3) performing translatio"
shirai-etal-2000-semi,W96-0112,0,\N,Missing
shirai-etal-2000-semi,W98-1510,1,\N,Missing
shirai-etal-2000-semi,J93-2004,0,\N,Missing
shirai-etal-2000-semi,E99-1026,0,\N,Missing
shirai-etal-2000-semi,P96-1025,0,\N,Missing
shirai-etal-2000-semi,W98-1511,0,\N,Missing
shirai-etal-2002-towards,1999.tmi-1.21,1,\N,Missing
shirai-etal-2002-towards,2001.mtsummit-road.1,0,\N,Missing
W03-1107,W00-1016,0,\N,Missing
W03-1107,W02-1904,0,\N,Missing
W03-1107,P01-1026,0,\N,Missing
W03-1611,P01-1008,0,0.0245794,"ntact” means, although it is the core of the definition. On what basis could we consider different linguistic expressions denoting the same meaning? This becomes a crucial question when finding paraphrases automatically. In past research, various types of clues have been used to find paraphrases. For example, Shinyama et al. tried to find paraphrases assuming that two sentences sharing many Named Entities and a similar structure are likely to be paraphrases of each other (Shinyama et al., 2002). Barzilay and McKeown assume that two translations from the same original text contain paraphrases (Barzilay and McKeown, 2001). Torisawa used subcategorization information of verbs to paraphrase Japanese noun phrase construction “NP1 no NP2 ” into a noun phrase with a relative clause (Torisawa, 2001). Most of previous work on paraphrasing took corpus-based approach with notable exceptions of Jacquemin (Jacquemin et al., 1997; Jacquemin, 1999) and Katz (Katz, 1997). In particular, text alignment technique is generally used to find sentence level paraphrases (Shimohata and Sumita, 2002; Barzilay and Lee, 2002). In this paper, we follow the corpus-based approach and propose a method to find paraphrases of a Japanese nou"
W03-1611,shimohata-sumita-2002-automatic,0,0.0462492,"to, 1999). The query expansion works well for single-word index terms, but more sophisticated techniques are necessary for larger index units, such as phrases. The effectiveness of phrasal indexing has recently drawn researchers’ attention (Lewis, 1992; Mitra et al., 1997; Tokunaga et al., 2002). However, query expansion of phrasal index terms has not been fully investigated yet (Jacquemin et al., 1997). To deal with variations of linguistic expressions, paraphrasing has recently been studied for various applications of natural language processing, such as machine translation (Mitamura, 2001; Shimohata and Sumita, 2002), dialog systems (Ebert et al., 2001), QA systems (Katz, 1997) and information extraction (Shinyama et al., 2002). Paraphrasing is defined as a process of transforming an expression into another while keeping its meaning intact. However, it is difficult to define what “keeping its meaning intact” means, although it is the core of the definition. On what basis could we consider different linguistic expressions denoting the same meaning? This becomes a crucial question when finding paraphrases automatically. In past research, various types of clues have been used to find paraphrases. For example"
W03-1611,W01-1608,0,0.0307897,"single-word index terms, but more sophisticated techniques are necessary for larger index units, such as phrases. The effectiveness of phrasal indexing has recently drawn researchers’ attention (Lewis, 1992; Mitra et al., 1997; Tokunaga et al., 2002). However, query expansion of phrasal index terms has not been fully investigated yet (Jacquemin et al., 1997). To deal with variations of linguistic expressions, paraphrasing has recently been studied for various applications of natural language processing, such as machine translation (Mitamura, 2001; Shimohata and Sumita, 2002), dialog systems (Ebert et al., 2001), QA systems (Katz, 1997) and information extraction (Shinyama et al., 2002). Paraphrasing is defined as a process of transforming an expression into another while keeping its meaning intact. However, it is difficult to define what “keeping its meaning intact” means, although it is the core of the definition. On what basis could we consider different linguistic expressions denoting the same meaning? This becomes a crucial question when finding paraphrases automatically. In past research, various types of clues have been used to find paraphrases. For example, Shinyama et al. tried to find parap"
W03-1611,P97-1004,0,0.460149,"the basis of surface string matching. To remedy this problem, the current information retrieval system adopts query expansion techniques which replace a query term with a set of its synonyms (BaezaYates and Riberto-Neto, 1999). The query expansion works well for single-word index terms, but more sophisticated techniques are necessary for larger index units, such as phrases. The effectiveness of phrasal indexing has recently drawn researchers’ attention (Lewis, 1992; Mitra et al., 1997; Tokunaga et al., 2002). However, query expansion of phrasal index terms has not been fully investigated yet (Jacquemin et al., 1997). To deal with variations of linguistic expressions, paraphrasing has recently been studied for various applications of natural language processing, such as machine translation (Mitamura, 2001; Shimohata and Sumita, 2002), dialog systems (Ebert et al., 2001), QA systems (Katz, 1997) and information extraction (Shinyama et al., 2002). Paraphrasing is defined as a process of transforming an expression into another while keeping its meaning intact. However, it is difficult to define what “keeping its meaning intact” means, although it is the core of the definition. On what basis could we consider"
W03-1611,P95-1026,0,0.00447346,"not sufficient for evaluating the quality of the paraphrases. However, it reflects relatedness between the input noun phrase 4.3 Contextual information We assume that phrases sharing the same Kanzi characters likely represent the same meaning. Therefore they could be paraphrases of each other. However, even though a Kanzi denotes a certain meaning, its meaning is often ambiguous. This problem is similar to word sense ambiguities, which have been studied for many years. To solve this problem, we adopt an idea one sense per collocation which was introduced in word sense disambiguation research (Yarowsky, 1995). Considering a newspaper article in which the retrieved passage and the input noun phrase is included as the context, the context similarity is taken into account for ranking paraphrase candidates. More concretely, context similarity is calculated by following procedure. 1. For each paraphrase candidate, a context vector is constructed from the newspaper article containing the passage from which the candidate is derived. The article is morphologically analyzed and content words are extracted to make the context vector. The tf · idf metric is used for term weighting. 2. Since the input is give"
W03-1611,W02-1022,0,\N,Missing
W03-1611,P99-1044,0,\N,Missing
W96-0105,P91-1034,0,0.0225877,"). S =XUT (5) We introduce a utility function TUF(x), which computes the training utility figure for an example x. The sampling algorithm gives preference to examples of maximum utility, by way of equation (6). arg max TUF(x) (6) xEX We will explain in the following sections how one could estimate TUF, based on the estimation of the certainty figure of an interpretation. Ideally the sampling size, i.e. the number of samples selected at each iteration would be such as to avoid retraining of similar examples. It should be noted that this can be a critical problem for statistics-based approaches [1, 3, 18, 20, 24], as the reconstruction of statistic classifiers is expensive. However, example-based systems [5, 12, 21] do not require the reconstruction of the system, but examples have to be stored in the database. It also should be noted that in each iteration, the system needs only compute the similarity between each example x belonging to X and the newly stored example, instead of every example belonging to T, because of the following reasons: • storing an example of verb sense interpretation senses, 61 si, will not affect the score of other verb • if the system memorizes the current score of si for ea"
W96-0105,J94-4003,0,0.0277881,"). S =XUT (5) We introduce a utility function TUF(x), which computes the training utility figure for an example x. The sampling algorithm gives preference to examples of maximum utility, by way of equation (6). arg max TUF(x) (6) xEX We will explain in the following sections how one could estimate TUF, based on the estimation of the certainty figure of an interpretation. Ideally the sampling size, i.e. the number of samples selected at each iteration would be such as to avoid retraining of similar examples. It should be noted that this can be a critical problem for statistics-based approaches [1, 3, 18, 20, 24], as the reconstruction of statistic classifiers is expensive. However, example-based systems [5, 12, 21] do not require the reconstruction of the system, but examples have to be stored in the database. It also should be noted that in each iteration, the system needs only compute the similarity between each example x belonging to X and the newly stored example, instead of every example belonging to T, because of the following reasons: • storing an example of verb sense interpretation senses, 61 si, will not affect the score of other verb • if the system memorizes the current score of si for ea"
W96-0105,1993.mtsummit-1.10,0,0.0328193,"is small in both figure l l - a and ll-b. However, in the situation as in figure ll-b, since (a) the task of distinction between the verb senses 1 and 2 is easier, and (b) instances where the sense ambiguity of case fillers corresponds to distinct verb senses will be rare, training using either ""xl"" or ""x2"" will be less effective than as in figure ll-a. It should also be noted that since Bunruigoihyo is a relatively small-sized thesaurus and does not enumerate many word senses, this problem is not critical in our case. However, given other existing thesauri like the EDR electronic dictionary [4] or WordNet [15], these two situations should be strictly differentiated. 6 Conclusion In this paper we proposed an example sampling method for example-based verb sense disambiguation. We also reported on the system&apos;s performance by way of experiments. The experiments showed that our method, which is based on the notion of training utility, has reduced the overhead for the training of the system, as well as the size of the database. As pointed out in section 1, the generalization of examples [8, 19] is another method for reducing the size of the database. Whether coupling these two methods wou"
W96-0105,C96-1012,1,0.79323,"x. The sampling algorithm gives preference to examples of maximum utility, by way of equation (6). arg max TUF(x) (6) xEX We will explain in the following sections how one could estimate TUF, based on the estimation of the certainty figure of an interpretation. Ideally the sampling size, i.e. the number of samples selected at each iteration would be such as to avoid retraining of similar examples. It should be noted that this can be a critical problem for statistics-based approaches [1, 3, 18, 20, 24], as the reconstruction of statistic classifiers is expensive. However, example-based systems [5, 12, 21] do not require the reconstruction of the system, but examples have to be stored in the database. It also should be noted that in each iteration, the system needs only compute the similarity between each example x belonging to X and the newly stored example, instead of every example belonging to T, because of the following reasons: • storing an example of verb sense interpretation senses, 61 si, will not affect the score of other verb • if the system memorizes the current score of si for each x, the system simply needs to compare it with the newly computed score between x and the newly stored"
W96-0105,P92-1032,0,0.0179473,"cles. Each of the sentences in the training/test data used 64 in our experiment contained one or several complement(s) followed by one of the ten verbs enumerated in table 2. In table 2, the column of ""English gloss"" describes typical English translations of the Japanese verbs. The column of "" # of sentences"" denotes the number of sentences in the corpus, "" # of senses"" denotes the number of verb senses based on IPAL, and ""lower bound"" denotes the precision gained by using a naive method, where the system systematically chooses the most frequently appearing interpretation in the training data [6]. Table 2: The corpus used for the experiments verb II English gloss ataeru kakeru kuwaeru noru osameru tsukuru torn umu wakaru yameru total [I # of sentences # of senses lower bound give hang add ride govern make take bear offspring understand stop 136 160 167 126 108 126 84 90 60 54 4 29 5 10 8 15 29 2 5 2 66.9 25.6 53.9 45.2 25.0 19.8 26.2 81.1 48.3 59.3 -- 1111 -- 43.7 We at first estimated the system&apos;s performance by its precision, that is the ratio of the number of correct outputs, compared to the number of inputs. In this experiment, we set = 0.5 in equation (7), and k = 1 in equation ("
W96-0105,C92-2101,0,0.216335,"with respect to the correctness of the answer. Dagan et al. proposed a committee-based sampling method, which is currently applied to HMM training for part-of-speech tagging [2]. This method selects samples based on the training utility factor of the examples, i.e. the informativity of the data with respect to future training. However, as all these methods are implemented for statistics-based models, there is a need to explore how to formalize and map these concepts into the examplebased approach. With respect to problem 3, a possible solution would be the generalization of redundant examples [8, 19]. However, such an approach implies a significant overhead for the manual training of each example prior to the generalization. This shortcoming is precisely what our approach allows to avoid: reducing both the overhead as well as the size of the database. Section 2 briefly describes our method for a verb sense disambiguation system. The next Section 3 elaborates on the example sampling method, while section 4 reports on the results of our experiment. Before concluding in section 6, discussion is added in section 5. 57 2 E x a m p l e - b a s e d verb sense disambiguation s y s t e m suri kano"
W96-0105,C94-1049,0,0.0253196,"). S =XUT (5) We introduce a utility function TUF(x), which computes the training utility figure for an example x. The sampling algorithm gives preference to examples of maximum utility, by way of equation (6). arg max TUF(x) (6) xEX We will explain in the following sections how one could estimate TUF, based on the estimation of the certainty figure of an interpretation. Ideally the sampling size, i.e. the number of samples selected at each iteration would be such as to avoid retraining of similar examples. It should be noted that this can be a critical problem for statistics-based approaches [1, 3, 18, 20, 24], as the reconstruction of statistic classifiers is expensive. However, example-based systems [5, 12, 21] do not require the reconstruction of the system, but examples have to be stored in the database. It also should be noted that in each iteration, the system needs only compute the similarity between each example x belonging to X and the newly stored example, instead of every example belonging to T, because of the following reasons: • storing an example of verb sense interpretation senses, 61 si, will not affect the score of other verb • if the system memorizes the current score of si for ea"
W96-0105,P95-1026,0,0.0470033,"). S =XUT (5) We introduce a utility function TUF(x), which computes the training utility figure for an example x. The sampling algorithm gives preference to examples of maximum utility, by way of equation (6). arg max TUF(x) (6) xEX We will explain in the following sections how one could estimate TUF, based on the estimation of the certainty figure of an interpretation. Ideally the sampling size, i.e. the number of samples selected at each iteration would be such as to avoid retraining of similar examples. It should be noted that this can be a critical problem for statistics-based approaches [1, 3, 18, 20, 24], as the reconstruction of statistic classifiers is expensive. However, example-based systems [5, 12, 21] do not require the reconstruction of the system, but examples have to be stored in the database. It also should be noted that in each iteration, the system needs only compute the similarity between each example x belonging to X and the newly stored example, instead of every example belonging to T, because of the following reasons: • storing an example of verb sense interpretation senses, 61 si, will not affect the score of other verb • if the system memorizes the current score of si for ea"
W96-0105,C92-2107,0,\N,Missing
W97-0803,A92-1013,0,0.0584445,"Missing"
W97-0803,P93-1024,0,0.251123,"Missing"
W97-0803,P93-1023,0,0.0593941,"Missing"
W97-0803,P90-1034,0,0.136806,"Missing"
W97-0803,A94-1027,1,0.887039,"Missing"
W97-0803,C96-2161,0,0.149207,"Missing"
W97-0803,C96-2212,0,0.0605532,"Missing"
W97-0803,C92-2070,0,0.10255,"Missing"
W97-0803,P92-1053,0,\N,Missing
W98-0704,W97-0809,0,0.0240824,"results in a significant improvement of information retrieval performance. 1 Introduction Development of WordNet began in 1985 at Princeton University (Miller, 1990). A team lead by Prof. George Miller aimed to create a source of lexical knowledge whose organization would reflect some of the recent findings of psycholinguistic research into the human lexicon. WordNet has been used in numerous natural language processing, such as part of speech tagging (Segond et al., 97), word sense disambiguation (Resnik, 1995), text categorization (Gomez-Hidalgo and Rodriguez, 1997), information extraction (Chai and Biermann, 1997), and so on with considerable success. However the usefulness of WordNet in information retrieval applications has been debatable. Information retrieval is concerned with locating documents relevant to a user&apos;s information needs from a collection of documents. The user describes his/her information needs with a query which consists of a number of words. The information retrieval system compares the query with documents in the collection and returns the documents that are likely to satisfy the user&apos;s information requirements. A fundamental weakness of current information retrieval methods is th"
W98-0704,W97-0806,0,0.0137169,"information retrieval test collections show that our method results in a significant improvement of information retrieval performance. 1 Introduction Development of WordNet began in 1985 at Princeton University (Miller, 1990). A team lead by Prof. George Miller aimed to create a source of lexical knowledge whose organization would reflect some of the recent findings of psycholinguistic research into the human lexicon. WordNet has been used in numerous natural language processing, such as part of speech tagging (Segond et al., 97), word sense disambiguation (Resnik, 1995), text categorization (Gomez-Hidalgo and Rodriguez, 1997), information extraction (Chai and Biermann, 1997), and so on with considerable success. However the usefulness of WordNet in information retrieval applications has been debatable. Information retrieval is concerned with locating documents relevant to a user&apos;s information needs from a collection of documents. The user describes his/her information needs with a query which consists of a number of words. The information retrieval system compares the query with documents in the collection and returns the documents that are likely to satisfy the user&apos;s information requirements. A fundamental weakn"
W98-0704,P90-1034,0,0.0399144,"Voorhees (Voorhees, 1994) have proposed an expansion method using WordNet. Our method differs from theirs in that we enrich the coverage of WordNet using two methods of automatic thesatmm construction, and we weight the expausion term appropriately so that it can accommodate the polysemous word problem. Although Stairmand (Stairmand, 1997) and Richardson (Richardson and Smeaton, 1995) have proposed the use of WordNet in information retrieval, they did not used WordNet in the query expansion framework. Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie (Hindle, 1990), although Hindle did not apply it to information retrieval. Instead, he used mutual information statistics as a Similarity coefficient, wheras we used the Dice coefficient for normalization purposes. Hindle only extracted the subject-verb and the object-verb predicatearguments, while we also extract adjective-noun predicate-arguments. Our weighting method follows the Qiu 36 method (Qiu and Frei, 1993), except that Qiu used it to expand terms only from a single automatically constructed thesarus and did not consider the use of more than one thesaurus. 7 Conclusions This paper analyzed why the"
W98-0704,J91-1002,0,0.0241408,"Missing"
W98-0704,W95-0105,0,0.0420743,"Missing"
W98-0704,1995.iwpt-1.26,0,0.02587,"Missing"
W98-0704,W97-0811,0,\N,Missing
W98-1227,J93-1002,0,0.094636,"Missing"
W98-1227,J95-3002,0,0.0137466,"nstruct a bigram LR table, and then discussed the advantage of our method, comparing our method to the bigram and trigram language models. The principle advantage over the bigram language model is that, in using a bigram LR table, we can combine both local probabilistic connection constraints (bigram constraints) and global constraints (CFG). Our method is applicable not only to natural language processing but also speech recognition. We are currently testing our method using a largesized grammar containing dictionary rules for speech recognition. Su et al. (Suet al., 1991) and Chiang et al. (Chiang et al., 1995) have proposed a very interesting corpus-based natural language processing method that takes account not only of lexical, syntactic, and semantic scores concurrently, but also contextsensitivity in the language model. However, their method seems to suffer from difficulty in acquiring probabilities from a given corpus. Wright (Wright, 1990) developed a method of distributing the probability of each PCFG rule to each action in an LR table. However, this method only calculates syntactic scores of parsing trees based on a context-free framework. Briscoe and Carroll (Briscoe and Carroll., 1993) att"
W98-1227,1997.iwpt-1.16,1,0.798343,"set consists of 1320 sentences, which contain 13311 preterminals. The CFG used is a phrase contextfree grammar used in speech recognition tasks, and the number of rules and preterminals is 777 and 407, respectively. As is evident from Table 5, the use of a bigram LR table decreases the test-set perplexity from 6.50 to 5.99. Note that in this experiment, we used the LALR table generation algorithm2 to construct the bigram LR table. Despite the disadvantages of 2In the case of LALR tables, the sum of the probabihties of all the possible parsing trees generated by a given CFG may be less than 1 (Inui et al., 1997). A Method of Incorporating Bigram Constraints LALR tables, the bigram LR table has better performance than the simple bigram language model, showing the effectiveness of a bigram LR table. On the other hand, the perplexity of the trigram language model is smaller than that of the bigram LR table. However, with regard to data sparseness, the bigram LR table is better than the trigram language model because bigram constraints are more easily acquired from a given corpus than trigram constraints. Although the experiment described above is concerned with natural language processing, our method is"
W98-1510,1997.iwpt-1.16,1,0.671327,"that we don&apos;t cousider any lexical association, VC estimate• the probability of its derivation as follows. Fignre 1: A parse derivation for an input string &quot;11Ji!c/J&quot;;&apos; 1 ii: ]t~t.: (She ate a pie)&quot; 2.1 P(taR) &quot;&apos;P(ta!Av.1&apos;) P(t.abeR, ta)&quot;&apos; P(tabeV) ing a wide range of existing syntactic-based language modeling frameworks, from simple PCFG models to more context-sensitive models including those proposed in [2, 13, 19]. Am.olg these, we, at present, use probabilistic GLil (PGLH.) language modeling, which is given by incorpo~ rating probabilistic distributions into the GLR parsing framework [10, 21]. The advantages of PGLR modeling are (a) PGLR. models are mildly context~sensitive, compared with PCFG models, and (b) PGLR. models inherently capture both structural preferences and POS bigram statistics, which meets our integration requirement. For further discussion, see [10]. &apos;l&apos;(gaR, tabe, ta) &quot;&apos; P(gal&apos;r[h(tabe,[Pr,Pz])]) P(oR, ga, tabe, ta) &quot;&apos; P(oPz[h(tabe, [l&apos;r :ga, Pz])]) The lexical model P(WIR) is the product of the probability of each lexical derivation li ·-7 Wi, where 11 E L (L C R) is the POS tag of w; E W: =II l&apos;(w;R,w 1 , ... ,w 1_1) (5) (G) where h(h, [s1, ... , sn]) is"
W98-1510,E91-1004,0,0.0223692,"ile maintaining the probabilistically wcll-foundedness of the overall model. ta (PAST) -; tabe (eat) -+ ga (NO III) (ACC) ·-+ kanojo (she) -; pai (pie) --t o First, for each lcxieal item that we don&apos;t cousider any lexical association, VC estimate• the probability of its derivation as follows. Fignre 1: A parse derivation for an input string &quot;11Ji!c/J&quot;;&apos; 1 ii: ]t~t.: (She ate a pie)&quot; 2.1 P(taR) &quot;&apos;P(ta!Av.1&apos;) P(t.abeR, ta)&quot;&apos; P(tabeV) ing a wide range of existing syntactic-based language modeling frameworks, from simple PCFG models to more context-sensitive models including those proposed in [2, 13, 19]. Am.olg these, we, at present, use probabilistic GLil (PGLH.) language modeling, which is given by incorpo~ rating probabilistic distributions into the GLR parsing framework [10, 21]. The advantages of PGLR modeling are (a) PGLR. models are mildly context~sensitive, compared with PCFG models, and (b) PGLR. models inherently capture both structural preferences and POS bigram statistics, which meets our integration requirement. For further discussion, see [10]. &apos;l&apos;(gaR, tabe, ta) &quot;&apos; P(gal&apos;r[h(tabe,[Pr,Pz])]) P(oR, ga, tabe, ta) &quot;&apos; P(oPz[h(tabe, [l&apos;r :ga, Pz])]) The lexical model P(WIR) is t"
W98-1510,J96-1002,0,0.0088305,"Missing"
W98-1510,P95-1037,0,0.159717,"Missing"
W98-1510,P93-1005,0,0.0208939,"ile maintaining the probabilistically wcll-foundedness of the overall model. ta (PAST) -; tabe (eat) -+ ga (NO III) (ACC) ·-+ kanojo (she) -; pai (pie) --t o First, for each lcxieal item that we don&apos;t cousider any lexical association, VC estimate• the probability of its derivation as follows. Fignre 1: A parse derivation for an input string &quot;11Ji!c/J&quot;;&apos; 1 ii: ]t~t.: (She ate a pie)&quot; 2.1 P(taR) &quot;&apos;P(ta!Av.1&apos;) P(t.abeR, ta)&quot;&apos; P(tabeV) ing a wide range of existing syntactic-based language modeling frameworks, from simple PCFG models to more context-sensitive models including those proposed in [2, 13, 19]. Am.olg these, we, at present, use probabilistic GLil (PGLH.) language modeling, which is given by incorpo~ rating probabilistic distributions into the GLR parsing framework [10, 21]. The advantages of PGLR modeling are (a) PGLR. models are mildly context~sensitive, compared with PCFG models, and (b) PGLR. models inherently capture both structural preferences and POS bigram statistics, which meets our integration requirement. For further discussion, see [10]. &apos;l&apos;(gaR, tabe, ta) &quot;&apos; P(gal&apos;r[h(tabe,[Pr,Pz])]) P(oR, ga, tabe, ta) &quot;&apos; P(oPz[h(tabe, [l&apos;r :ga, Pz])]) The lexical model P(WIR) is t"
W98-1510,H94-1048,0,0.0696817,"Missing"
W98-1510,P96-1025,0,0.155593,"Missing"
W98-1510,C92-2065,0,0.0419749,"Missing"
W98-1510,P97-1003,0,0.058909,"ng A) we rank its pars&lt;~ dr:rlYations according to the joint distribution J&apos;(H, lr). where H1 is a word sequence candidate for A, and R is a parse derivation candidate for H-- whos(&apos; terminal symbols constitute a POS tag scquc-;nce L (see Figure 1 2 ). We first. decompose 1&apos;( fl. lr) • Pmbabilistically well-fottnded semantics: The language model used in a statistical parser should have probabilistically well-founclecl semantics) whieh vould a.lso facilitate the anal:,&apos;·· sis of the model&apos;s behavior. , 1 For further discussion, see [8]. This is also tlH&apos; case with recent works such as [3] and [5] due to t.hc lad&lt; of modularity of statistical types. &apos;-Although syntactic structure. R is represented af&apos; a dependency structure in this figure, our framework 80 into two submodels, the syntactic model l&apos;(R) and the lexical model P(WR): P(R, W) = P(R) · P(WR) depends only on a certain small part of its whole context. We first assume that syntactic structure R in P(wiiR,w 1 , .. . ,wi_- 1 ) can always be reduced to l; ( E R), which allows us to deal with the lexical model separately from the syntactic model. The question then is which subset C of { ·uJI, ... , Wi-l} has the strongest influen"
W98-1510,H92-1027,0,0.075636,"Missing"
W98-1510,1995.iwpt-1.26,0,0.109798,"Missing"
W98-1510,W96-0112,0,\N,Missing
W98-1510,C92-2066,0,\N,Missing
W98-1510,1991.iwpt-1.22,0,\N,Missing
W99-0902,J94-4003,0,0.0265373,"nment paradigm between the two input segments, it is possible to apply the scoring and learning methods proposed herein in their existing forms. Note, however, that in the case of translation pair extraction, there is a real possibility of the alignment mapping being many-to-many, and crossing over of alignment is expected to occur readily. In fact, it may occur t h a t there is a residue of unaligned segments in either or both languages, as could easily occur if one language included zero anaphora. It may, therefore, be desirable to apply a dynamic threshold on the discriminative ratio (cf. (Dagan and Itai, 1994)) to accept only those translation pairs with sufficiently high statistical confidence, for example. 6 Conclusion In this paper, we proposed an adaptation of the TF-IDF model to Japanese grapheme-phoneme alignment. We then went on to extend the basic statistical method to devise a fully unsupervised learning method, by way of a two discrimination-based metrics and incremental refinement of the statistical model. Experimentation suggested t h a t the proposed learning method marginally outperforms both a baseline rule-based method and the nonincremental statistical method. Items of future resea"
W99-0902,H91-1026,0,0.0124554,"s monotonically decreasing when averaged over the given corridor, in practice local maximums do exist, attributable to the situation where re-training of the statistical model produces inflation of the m a x i m u m discriminative value. 5 Other a p p l i c a t i o n s of this research Other than the constraints described in Section 2 and frequency determination techniques, the proposed methodology is theoretically scalable to any domain where two streams of chunked information require alignment. This suggests applications to the extraction of translation pairs from aligned bilingual corpora (Gale and Church, 1991; Kupiec, 1993; Smadja et al., 1996), where the system input would be made up of aligned strings (generally sentences) in the two languages. Given t h a t we can devise some way of creating an alignment paradigm between the two input segments, it is possible to apply the scoring and learning methods proposed herein in their existing forms. Note, however, that in the case of translation pair extraction, there is a real possibility of the alignment mapping being many-to-many, and crossing over of alignment is expected to occur readily. In fact, it may occur t h a t there is a residue of unaligne"
W99-0902,P93-1003,0,0.0168673,"ing when averaged over the given corridor, in practice local maximums do exist, attributable to the situation where re-training of the statistical model produces inflation of the m a x i m u m discriminative value. 5 Other a p p l i c a t i o n s of this research Other than the constraints described in Section 2 and frequency determination techniques, the proposed methodology is theoretically scalable to any domain where two streams of chunked information require alignment. This suggests applications to the extraction of translation pairs from aligned bilingual corpora (Gale and Church, 1991; Kupiec, 1993; Smadja et al., 1996), where the system input would be made up of aligned strings (generally sentences) in the two languages. Given t h a t we can devise some way of creating an alignment paradigm between the two input segments, it is possible to apply the scoring and learning methods proposed herein in their existing forms. Note, however, that in the case of translation pair extraction, there is a real possibility of the alignment mapping being many-to-many, and crossing over of alignment is expected to occur readily. In fact, it may occur t h a t there is a residue of unaligned segments in"
W99-0902,J96-1001,0,0.0147695,"ged over the given corridor, in practice local maximums do exist, attributable to the situation where re-training of the statistical model produces inflation of the m a x i m u m discriminative value. 5 Other a p p l i c a t i o n s of this research Other than the constraints described in Section 2 and frequency determination techniques, the proposed methodology is theoretically scalable to any domain where two streams of chunked information require alignment. This suggests applications to the extraction of translation pairs from aligned bilingual corpora (Gale and Church, 1991; Kupiec, 1993; Smadja et al., 1996), where the system input would be made up of aligned strings (generally sentences) in the two languages. Given t h a t we can devise some way of creating an alignment paradigm between the two input segments, it is possible to apply the scoring and learning methods proposed herein in their existing forms. Note, however, that in the case of translation pair extraction, there is a real possibility of the alignment mapping being many-to-many, and crossing over of alignment is expected to occur readily. In fact, it may occur t h a t there is a residue of unaligned segments in either or both languag"
W99-0902,J97-4001,0,\N,Missing
Y00-1002,1999.tmi-1.21,1,0.891206,"Missing"
Y00-1002,1999.tmi-1.20,1,0.705777,"reater cohesion that those in the other two regions. If selectional restrictions are given this degree of specificity, it must mean that the associated case slot is highly specialised in its usage and that the lexicographer encoding the selectional restrictions is confident as to the demarkation of use of that case slot. A match at this high level of specialisation tends to have greater credibility than a match at a higher level, and point to genuine case slot correspondence. Figure 1: Semantic density We model semantic density-based match quality according to case slot restrictiveness (CSR) (Baldwin & Tanaka 1999). The degree of CSR of a given node x subsuming nodes 1 1 ,12 ,...1,, is estimated as: CSR(x) = (4) 2_,i =i tree_depth(x, where tree depth is defined as the number of nodes between the subtree root x and subsumed leaf inclusive. This produces the desired ranking for the above figure of 0 < CSR(R i ) < CSR(R2) < CSR(R3 ) < 1. We balance up the degree of semantic density against the degree of backing-off required to achieve that semantic density, using the mq function as for (m2 ). The combined score for case slots a 11 and b with selectional restrictions a l , a 2 , ...ax , ...ak and b 1 , b 2"
Y00-1002,H92-1086,0,0.0373678,"e processes are sufficient to cluster together analytic, but not synthetic and lexical alternations. The next step (step 2) is to collapse together all combined alternations from step 1, for which the SUFF component is covered by a single lexical/conjugational paradigm. Lexical paradigms are a classification of transitive/intransitive and causative/non-causative verb pairs according to derivational affix. An example of such a derivational affix pair is -e-/-ar-, as seen for such verbs as haz&quot;// &quot;star tTRANS&quot; and sonaerul sonawaru &quot;to provide&quot; / &quot;be endowed with&quot; imerul hazimaru &quot;to start (see Jacobsen (1992:pp 258-68) for a thorough listing of such affix pairs). The only conjugational paradigms currently considered are the passive and synthetic causative. All alternations governed by a common lexical/conjugational paradigm are clustered together into one common alternation, with SUFF describing the paradigm applied in the clustering process. Note that there is no overlap between the particular paradigms currently targeted, such that ambiguity as to the applicable paradigm type can never occur. In the final step of alternation clustering (step 3), we score up &quot;sub-alternations&quot; based on the outpu"
Y00-1002,P98-1099,0,0.0213682,"Missing"
Y00-1002,P98-2247,0,0.064881,"Missing"
Y00-1002,C98-2242,0,\N,Missing
Y00-1002,C98-1096,0,\N,Missing
yoshida-etal-2004-retrieving,J93-2004,0,\N,Missing
