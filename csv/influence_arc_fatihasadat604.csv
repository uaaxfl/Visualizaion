2006.bcs-1.7,W98-1005,0,0.0270469,"is the omission of diacritics and vowels (fatha, damma, kasra, shaddah, sukuun) in almost all the Arabic writings. The information contained in unvocalized Arabic writing is not sufficient to give a reader, who is unfamiliar with the language, sufficient information for accurate pronunciation. If encountered with a new name, the omission of diacritics even might confuse native speakers. Diacritics are considered to be one of the main causes of ambiguity when dealing with Arabic proper nouns. 2. RELATED WORK There have been different approaches to transliteration dependent on the application. Stalls and Knight (1998) present an Arabic-to-English back-transliteration system based on the source-channel framework. The transliteration process is based on a generative model of how an English name is transliterated into English. This model has three components P(w), P(e|w) and P(a|e). P(w) is a typical unigram model that generates English word sequences according to their unigram probabilities. A given English word sequence w is converted to its corresponding phoneme sequence e with probability P(e|w). Finally, an English phoneme sequence e is converted into an Arabic letter sequence according to the probabilit"
2006.bcs-1.7,W05-0822,1,0.873539,"Missing"
2006.jeptalnrecital-poster.23,J90-2002,0,0.601185,"Missing"
2006.jeptalnrecital-poster.23,2003.mtsummit-papers.15,1,0.841473,"Missing"
2006.jeptalnrecital-poster.23,koen-2004-pharaoh,0,0.14163,"Missing"
2006.jeptalnrecital-poster.23,2005.mtsummit-papers.11,0,0.0436754,"Missing"
2006.jeptalnrecital-poster.23,W05-0820,0,0.0221996,"Missing"
2006.jeptalnrecital-poster.23,2002.jeptalnrecital-long.2,0,0.0726745,"Missing"
2006.jeptalnrecital-poster.23,P00-1056,0,0.156796,"Missing"
2006.jeptalnrecital-poster.23,P02-1038,0,0.0750405,"Missing"
2006.jeptalnrecital-poster.23,N04-1021,0,0.0385281,"Missing"
2006.jeptalnrecital-poster.23,P02-1040,0,0.0928412,"Missing"
2006.jeptalnrecital-poster.23,W05-0822,1,0.856627,"Missing"
2012.amta-caas14.10,W06-2810,0,0.0705746,"Missing"
2012.amta-caas14.10,W11-1212,0,0.0377799,"Missing"
2012.amta-caas14.10,J93-2003,0,0.0252116,"Missing"
2012.amta-caas14.10,declerck-etal-2006-multilingual,0,0.0712159,"Missing"
2012.amta-caas14.10,1998.amta-tutorials.5,0,0.0456587,"different languages that are not translations of each other” (Bowker and Pearson, 2002), but contains texts from the same domain. Comparable corpora have several obvious advantages over parallel corpora. They are available on the Web in large quantities for many languages and domains and many texts with similar content are produced every day (e.g. multilingual news feeds) (Skadiņa et al, 2010), but they are not organized. Also, bilingual lexicons are the key component of all cross-lingual NLP applications such as machine translation (Och and Ney, 2003) and crosslanguage information retrieval (Grefenstette, 1998). Parallel texts – as the most important resource in statistical machine translation (SMT) – appear to be limited in quantity, genre and language coverage. Providing more comparable corpora essentially boosts the coverage and the quality of machine translation system, especially for lesscovered languages and domains. In this paper we describe the extraction process of large comparable corpora and bilingual lexicons for Arabic and French language from a multilingual web-based encyclopedia, Wikipedia. We propose to build bilingual resources as follows: first comparable corpora from Wikipedia usi"
2012.amta-caas14.10,N10-1063,0,0.01734,"cordance with fast growth of Wikipedia, many works have been published in the last years focused on its use and exploitation for multilingual tasks in natural language processing: in this paper, our main concern is the use of Wikipedia as a source of comparable corpora and bilingual lexicon extraction. Li et al. (2010) consider Wikipedia as a comparable corpus, they align articles pairs based on inter-language links for the extraction of parallel sentences. Patry and Langlais (2011) also concentrate on documents pairs that are linked across language for extracting parallel documents. However, Smith et al. (2010) and Mohammadi and QasemAghaee (2010) use inter-language link to 74 identify aligned comparable Wikipedia documents. Sadat (2010) proposes an approach to build comparable corpora from Wikipedia encyclopedia. First, the author considers a preliminary query Q in a source language to input in Wikipedia search engine. The resulting document is used as a first document for the corpus in the source language. The usage of the inter-language link in the target language for this document leads to a corpus in a target language. Following this first step and exploiting the links in the same document as w"
2012.amta-caas14.10,N07-1025,0,0.0268377,"tions (e.g., DSM-IV redirects to Diagnostic and Statistical Manual of Mental Disorders), Alternative spellings or punctuation (e.g. Al-Jazeera redirects to Al Jazeera), etc. Link Texts This is a link to another page in Wikipedia. The link text can correspond to the title of the target article (the syntax will be: [[article title]]), or differ from the title of the target article (with the following syntax: [[article title |link text]]). As a rich and free resource, Wikipedia has been successfully used as an external resource in many natural language processing tasks (Buscaldi and Rosso, 2006; Mihalcea, 2007; Nakayama et al., 2007). 3 State of the Art In accordance with fast growth of Wikipedia, many works have been published in the last years focused on its use and exploitation for multilingual tasks in natural language processing: in this paper, our main concern is the use of Wikipedia as a source of comparable corpora and bilingual lexicon extraction. Li et al. (2010) consider Wikipedia as a comparable corpus, they align articles pairs based on inter-language links for the extraction of parallel sentences. Patry and Langlais (2011) also concentrate on documents pairs that are linked across lan"
2012.amta-caas14.10,J03-1002,0,0.0145644,"omparable corpora. Comparable corpora are “sets of texts in different languages that are not translations of each other” (Bowker and Pearson, 2002), but contains texts from the same domain. Comparable corpora have several obvious advantages over parallel corpora. They are available on the Web in large quantities for many languages and domains and many texts with similar content are produced every day (e.g. multilingual news feeds) (Skadiņa et al, 2010), but they are not organized. Also, bilingual lexicons are the key component of all cross-lingual NLP applications such as machine translation (Och and Ney, 2003) and crosslanguage information retrieval (Grefenstette, 1998). Parallel texts – as the most important resource in statistical machine translation (SMT) – appear to be limited in quantity, genre and language coverage. Providing more comparable corpora essentially boosts the coverage and the quality of machine translation system, especially for lesscovered languages and domains. In this paper we describe the extraction process of large comparable corpora and bilingual lexicons for Arabic and French language from a multilingual web-based encyclopedia, Wikipedia. We propose to build bilingual reso"
2012.amta-caas14.10,2010.jeptalnrecital-demonstration.6,1,0.821532,"Missing"
2012.amta-caas14.10,skadina-etal-2012-collecting,0,0.0505863,"Missing"
2012.amta-caas14.10,C96-2141,0,0.104461,"g them. The preprocessing step consists of removing all Arabic and French stop words. The step of word alignment presents several challenges. First, the alignments are not necessarily contiguous. Two consecutive words in the source sentence can be aligned with two words arbitrarily distant from the target sentence. This is called distortion. Second, a source language word can be aligned to many words in the target language; that is defined as fertility. The alignment of words of each title is based on IBM models [1, 2, 3, 4, 5] (Brown et al., 1993) in combination with the Hidden Markov Model (Vogel et al., 1996). These standard models have already proven their effectiveness in many researches. The five IBM models estimate the probability P(fr|ar) and P(ar|fr), for which fr is a French word and ar is an Arabic word. Each model is based on the parameters estimated by the previous model and incorporates new features such as distortion, fertility, etc. The Hidden Markov Model (HMM usually appointed) (Vogel et al., 1996) is an improvement of IBM2 model. It explicitly models the distance between the alignment of the current word and an alignment of the previous word. We used the open source toolkit GIZA++"
2013.mtsummit-wpt.5,W06-2810,0,0.08973,"Missing"
2013.mtsummit-wpt.5,2011.eamt-1.5,0,0.0210503,"s using the combined SMT with rule-based MT (Ehara, 2007; Wang, 2009; Jin, 2010). In order to obtain a large coverage without losing quality in the translation, Espana-Bonet et al. (2011) proposed a combination between a grammar-based multilingual translation system and a specialized SMT system. Enache et al. (2012) presented a hybrid translation system specifically designed to deal with patent translation. Indeed, the patent language follows a formal style adequate to be analysed with a grammar, but at the same time uses a rich and particular vocabulary adequate to be gathered statistically. Ceausu et al. (2011) presented a number of methods for adapting SMT to the patent domain. They proposed some patent-specific preprocessing to resolve the problem of long sentences and references to elements in figure. Ma et al. (2011) made changes to the SMT training procedure in order to better handle the special characteristics of patent data. He demonコンタクトホール 61 内に (i.e., here, in the contacth all 61 of the second, ) will have a proper segmentation as follows:|ここ |で|は|、 |第 2 |の |コンタク ト |ホール |6 1 |内 |に |. We used Mecab tool (Kudo, 2002) to segment the Japanese texts. English pre-processing simply included down-"
2013.mtsummit-wpt.5,2012.eamt-1.61,0,0.0208078,"Missing"
2013.mtsummit-wpt.5,J03-3002,0,0.04983,", a development data set of 2,000 pairs of bilingual sentences in Japanese and English and a test data set of 2,300 pairs of patent sentences in Japanese. Furthermore, a set of 2,300 patent sentences in English is released at the end of the evaluations, to be considered as a reference set of the Japanese test sentences. 5 Parallel Corpora Extraction from Wikipedia In most previous works on extraction of parallel sentences or phrases from comparable corpora, some coarse document-level similarity is used to determine which document pairs contain parallel data. For identifying similar web pages, Resnik and Smith (2003) compare the HTML structure. Munteanu and Marcu (2005) use publication date and vector-based similarity (after projecting words through a bilingual dictionary) to identify similar news articles. Wikipedia is an online collaborative encyclopaedia available for a wide variety of languages. There are 24 language editions with at least 100,000 articles. Currently (May 2013), the English Wikipedia is the largest one with over then 4 millions articles. Whereas, Japanese Wikipedia contains approximately 862,000 articles2. Wikipedia contains annotated article alignments. Indeed, articles on the same t"
2013.mtsummit-wpt.5,2011.mtsummit-wpt.7,0,0.0730463,"parts: an introductory phrase and the body of the claim usually linked by a conjunction. It is in the body of the claim where there is the 1 http://ntcir.nii.ac.jp/PatentMT-2/ 34 Proceedings of the 5th Workshop on Patent Translation, Nice, September 2, 2013. Yokoyama, S., ed. © 2013 Rahma Sellami, Fatiha Sadat, Lamia Hadrich Belguith. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CC-BY-ND. speciﬁc legal description of the exact invention. Therefore, claims are written in a specific style and use a very speciﬁc vocabulary of the patent domain (Espana-Bonet et al, 2011). Some of the patent document characteristics make MT easier, e.g., the presence of wellstructured sentences and less ambiguity of word meanings. On the other hand, some characteristics become challenges for MT, e.g., long and complicated sentence structures, technical terminology and new terms that are originally defined by patent applicants. Compared to the newswire Japanese text data, the Japanese patent text has some specific characteristics such as legalese, technical terminology and long sentences. Also, patent text includes significantly more special strings that are not written in Japa"
2013.mtsummit-wpt.5,J82-2005,0,0.764414,"Missing"
2013.mtsummit-wpt.5,N10-1063,0,0.0144965,"ied with a wide range of lexical and semantic information such as part of speech, word sense, gloss, etymology, pronunciation, declension, examples, sample quotations, translations, collocations, derived terms, and usage notes. In the current research, we have used the English Wiktionary since it contains more entries than the Japanese one; thus, we extracted all English terms having translations in Japanese. In total, we have extracted 1,528,475 pairs of English-Japanese terms. This process was based on the XML version of the English Wiktionary available online 5 and created by Sajous et al. (2010). Each entry in the XML Wiktionary contains an English term and its translations, gloss, POS, etc. In our experiments, we have considered the alternative translation of a term to be likely equal. We can envisage attributing a score for each alternative using a disambiguation technique based on a statistical probability, which will consider the context of a term in the training corpus and the semantic information proposed by the Wiktionary. 7 We re-implemented our system described in Sadat et al. (2013); we implemented a 5-gram language model instead of a 3-gram language model. Our results were"
2013.mtsummit-wpt.5,2011.mtsummit-wpt.8,0,0.0856555,"Missing"
2013.mtsummit-wpt.5,W02-2016,0,0.172305,"Missing"
2013.mtsummit-wpt.5,J05-4003,0,0.0331979,"sentences in Japanese and English and a test data set of 2,300 pairs of patent sentences in Japanese. Furthermore, a set of 2,300 patent sentences in English is released at the end of the evaluations, to be considered as a reference set of the Japanese test sentences. 5 Parallel Corpora Extraction from Wikipedia In most previous works on extraction of parallel sentences or phrases from comparable corpora, some coarse document-level similarity is used to determine which document pairs contain parallel data. For identifying similar web pages, Resnik and Smith (2003) compare the HTML structure. Munteanu and Marcu (2005) use publication date and vector-based similarity (after projecting words through a bilingual dictionary) to identify similar news articles. Wikipedia is an online collaborative encyclopaedia available for a wide variety of languages. There are 24 language editions with at least 100,000 articles. Currently (May 2013), the English Wikipedia is the largest one with over then 4 millions articles. Whereas, Japanese Wikipedia contains approximately 862,000 articles2. Wikipedia contains annotated article alignments. Indeed, articles on the same topic in different languages are connected via “Interla"
2013.mtsummit-wpt.5,2007.mtsummit-wpt.4,0,0.128235,"Missing"
2013.mtsummit-wpt.5,P03-1021,0,0.0255307,"Missing"
2013.mtsummit-wpt.5,J03-1002,0,0.00744663,"Missing"
2013.mtsummit-wpt.5,2001.mtsummit-papers.68,0,0.165165,"tructures, technical terminology and new terms that are originally defined by patent applicants. Compared to the newswire Japanese text data, the Japanese patent text has some specific characteristics such as legalese, technical terminology and long sentences. Also, patent text includes significantly more special strings that are not written in Japanese characters, such as English words, patent numbers, mathematical expressions and abbreviation names for materials. 3 strates that the re-training of the LM with patent text and the use of more features to the MT system improved the BLEU scores (Papineni et al., 2001) significantly. Komachi et al. (2008) proposed a semisupervised approach to acquire domain speciﬁc translation knowledge from the collection of Wikipedia. He has extracted a bilingual lexicon based on article tiles related by inter-language link and then applied the graph theoretic algorithm, regularized Laplacian, to ﬁnd the most relevant translation pairs to the Patent domain. 4 MT System Basic Description Our approach on statistical machine translation for Japanese and English pairs of languages is described as follows. First, a pre-processing step is performed on the source language, in or"
2015.jeptalnrecital-demonstration.6,M98-1028,0,0.211063,"Missing"
2015.jeptalnrecital-demonstration.6,E03-1015,0,0.0896109,"Missing"
2017.jeptalnrecital-demo.13,J98-4003,0,0.459484,"Missing"
2017.jeptalnrecital-demo.13,P07-2045,0,0.0106118,"Missing"
2017.jeptalnrecital-demo.13,P02-1040,0,0.105153,"Missing"
2017.jeptalnrecital-demo.13,W16-3702,0,0.0302922,"Missing"
2019.jeptalnrecital-court.15,N18-1127,0,0.0285393,"Missing"
2019.jeptalnrecital-court.15,baumann-pierrehumbert-2014-using,0,0.0233076,"Missing"
2019.jeptalnrecital-court.15,P18-1246,0,0.0810145,"âches : MS tagging, PoS tagging et NE recognition. 1. Le PoS tagging consiste à étiqueter chaque mot dans la phrase avec sa partie de discours (Nom, Adjective, etc.). Pour le domaine source, nous utilisons la partie WSJ du PTB (Marcus et al., 1993), annotée avec l’ensemble d’étiquettes du PTB. Et nous évaluons le performances du fine-tuning sur trois corpus des Tweets : TPoS (Ritter et al., 2011), annoté également avec l’ensemble d’étiquettes du PTB ; ARK (Owoputi et al., 2013) annoté avec un ensemble de 25 classes conçues pour les textes des RS ; et TweeBank, récemment proposé par Liu et al. (2018) et annoté avec l’ensemble d’étiquettes universelles. 2. Le MS tagging consiste à étiqueter chaque mot de la phrase avec une étiquette morphosyntactique, où la partie de discours est enrichie avec les informations morphologiques du mot. Comme illustré sur la figure 2, chaque lettre de l’étiquette représente une catégorie. La première position représente la partie de discours et les autres positions représentent des catégories morphosyntactiques, comme le nombre, le genre, etc. Nous utilisons les données fournies par la compagne d’évaluation MTT du Vardial18 (Zampieri et al., 2018), contenant u"
2019.jeptalnrecital-court.15,W17-4418,0,0.0212492,"Missing"
2019.jeptalnrecital-court.15,D17-1256,0,0.0280633,"Missing"
2019.jeptalnrecital-court.15,N18-1088,0,0.0208919,"Missing"
2019.jeptalnrecital-court.15,P16-1101,0,0.0447356,"Missing"
2019.jeptalnrecital-court.15,J93-2004,0,0.0648395,"Missing"
2019.jeptalnrecital-court.15,L18-1446,1,0.858465,"Missing"
2019.jeptalnrecital-court.15,W18-3927,1,0.888953,"Missing"
2019.jeptalnrecital-court.15,N19-1416,1,0.786681,"Missing"
2019.jeptalnrecital-court.15,D16-1046,0,0.0385885,"Missing"
2019.jeptalnrecital-court.15,N13-1039,0,0.0197473,"Missing"
2019.jeptalnrecital-court.15,D14-1162,0,0.0783083,"Missing"
2019.jeptalnrecital-court.15,N18-1202,0,0.0707121,"Missing"
2019.jeptalnrecital-court.15,D11-1141,0,0.0951193,"Missing"
2019.jeptalnrecital-court.15,W03-0419,0,0.462222,"Missing"
2019.jeptalnrecital-court.15,W18-3904,0,0.0614354,"Missing"
2020.amta-research.15,2020.lrec-1.312,0,0.653233,"or. This layer is built with bidirectional LSTM (Long-Short Term Memory) (Hochreiter and Schmidhuber, 1997). h = tanh(WhW · XW + WhC · XC + bh ) Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track (1) Page 167 The output layer o calculates the activation function as an output function and displays the output hypothesis. o = sof tmax(Wo · h + bo ) (2) 4 Experiments 4.1 Data Preparation We train our NMT model by using the Nunavut Hansard for Inuktitut-English (third edition). As described in Joanis et al. (2020), this corpus contains 1,293,348 sentences, 5,433 sentences and 6,139 sentences for the training, development and testing sets, respectively (Table 2). Dataset Inuktitut English #tokens 20,657,477 10,962,904 #train 1,293,348 1,293,348 #dev 5,433 5,433 #test 6,139 6,139 Table 2: Statistics of Nunavut Hansard Inuktitut-English parallel corpus 3.0 In order to pre-train the (bi-)character-based and word-based embeddings for Inuktitut, these Nunavut Hansard datasets were used with the word2vec toolkit (Mikolov et al., 2013) with a dimension of 50 and 30 for word-based and (bi-)character-based embed"
2020.amta-research.15,P18-4020,0,0.0118022,"yer to encode the input sequences and a dimension size of 200 for the hidden layer. The Adam optimizer (Kingma and Ba, 2014) was used to learn the network’s weights with a learning rate of 0.001. In the BPE subword segmentation, we used subword-nmt (Sennrich et al., 2016) toolkit to create a BPE joint source-target vocabulary with dimension of 30,000. In the preprocessing step, we used Moses (Koehn et al., 2007) tokenizer in all experiments and Moses preprocessing scripts to clean the training data with a threshold of 50 words by sentences and without repetitive sentences. We used Marian-nmt (Junczys-Dowmunt et al., 2018) to train our Transformer-based NMT with the following hyper-parameters settings: 6layer depth for both encoder and decoder, embedding dimension of 512, 2048 units in hidden 2 Github repository: https://github.com/NgocTanLE/Inuktitut-English-NMT Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Track Page 168 layers in the feed-forward networks, optimizer with SGD, an initial learning rate of 0.0003. We run 50 iterations (#max epochs) with an early stopping based on the cross-entropy scores for the validatio"
2020.amta-research.15,N18-1005,0,0.209861,"Missing"
2020.amta-research.15,P07-2045,0,0.0117553,"er toolkit (Yang et al., 2017) to train our Inuktitut word segmenter. The model is composed of 2-layer bi-directional Long Short-term Memory (LSTM) cells, with a dimension size of 50 for the projection layer to encode the input sequences and a dimension size of 200 for the hidden layer. The Adam optimizer (Kingma and Ba, 2014) was used to learn the network’s weights with a learning rate of 0.001. In the BPE subword segmentation, we used subword-nmt (Sennrich et al., 2016) toolkit to create a BPE joint source-target vocabulary with dimension of 30,000. In the preprocessing step, we used Moses (Koehn et al., 2007) tokenizer in all experiments and Moses preprocessing scripts to clean the training data with a threshold of 50 words by sentences and without repetitive sentences. We used Marian-nmt (Junczys-Dowmunt et al., 2018) to train our Transformer-based NMT with the following hyper-parameters settings: 6layer depth for both encoder and decoder, embedding dimension of 512, 2048 units in hidden 2 Github repository: https://github.com/NgocTanLE/Inuktitut-English-NMT Proceedings of the 14th Conference of the Association for Machine Translation in the Americas October 6 - 9, 2020, Volume 1: MT Research Tra"
2020.amta-research.15,K15-2004,0,0.264858,"ts and evaluations. Finally, in section 5, we present our conclusion and some perspectives for future research. 2 Related work Farley (2012) developed a morphological analyzer for Inuktitut, which makes use of a finitestate transducer and hand-crafted rules. This Uqa·Ila·Ut project (Uqailaut)1 is a rule-based system that involves regular morphological variations of about 3200 head, 350 lexical, and 1500 grammatical morphemes, with heuristics for ranking the various readings. Inspired by the Uqailaut project of Farley (2012), Micher (2017) applied a segmental recurrent neural network approach (Kong et al., 2015) from the output of this morphological analyzer for Inuktitut. The development of MT systems for Indigenous languages have followed the trends in the field, with rule-based, statistical-based and neural network-based approaches. Micher (2018) applied the Byte Pair Encoding (BPE) algorithm (Sennrich et al., 2016) pre-processing both the English and Inuktitut sides of the Nunavut Hansard corpus, in the Inuktitut to English direction, reported a BLEU score of 30.35. NMT approaches use neural networks architectures that are fed with very big amounts of parallel texts. However, these resources are"
2020.amta-research.15,C18-1222,0,0.235197,"Missing"
2020.amta-research.15,C18-1006,0,0.216343,"d using a set of rich features and by leveraging (bi-)character-based and word-based pretrained embeddings from large-scale raw corpora. Second, we incorporated this pre-processing step into our first Neural Machine Translation system. Our evaluations showed promising results and performance improvements in the context of low-resource Inuktitut-English neural machine translation. 1 Introduction In the Americas, there are a wide range of linguistic families about 140 linguistic families in the world. About 900 different Indigenous languages spoken in the Americas approximately are reported in (Mager et al., 2018). In Canada, there is a great diversity of Indigenous languages, grouped into 12 language families, that have been central to the history of First Nations people, M´etis and Inuit in Canada and continue to play a vital role to this day (Rice, 2011). This research paper focuses on Inuktitut, one of the Indigenous polysynthetic languages spoken in Northern Canada and the development of a Neural Machine Translation (NMT) for Inuktitut-English. The main objective and motivation of this project is the revitalization and preservation of Indigenous languages and cultural heritage through major tasks"
2020.amta-research.15,W17-0114,0,0.130021,"escribe our methodology. Then, in section 4, we present our experiments and evaluations. Finally, in section 5, we present our conclusion and some perspectives for future research. 2 Related work Farley (2012) developed a morphological analyzer for Inuktitut, which makes use of a finitestate transducer and hand-crafted rules. This Uqa·Ila·Ut project (Uqailaut)1 is a rule-based system that involves regular morphological variations of about 3200 head, 350 lexical, and 1500 grammatical morphemes, with heuristics for ranking the various readings. Inspired by the Uqailaut project of Farley (2012), Micher (2017) applied a segmental recurrent neural network approach (Kong et al., 2015) from the output of this morphological analyzer for Inuktitut. The development of MT systems for Indigenous languages have followed the trends in the field, with rule-based, statistical-based and neural network-based approaches. Micher (2018) applied the Byte Pair Encoding (BPE) algorithm (Sennrich et al., 2016) pre-processing both the English and Inuktitut sides of the Nunavut Hansard corpus, in the Inuktitut to English direction, reported a BLEU score of 30.35. NMT approaches use neural networks architectures that are"
2020.amta-research.15,W18-4807,0,0.016473,"fted rules. This Uqa·Ila·Ut project (Uqailaut)1 is a rule-based system that involves regular morphological variations of about 3200 head, 350 lexical, and 1500 grammatical morphemes, with heuristics for ranking the various readings. Inspired by the Uqailaut project of Farley (2012), Micher (2017) applied a segmental recurrent neural network approach (Kong et al., 2015) from the output of this morphological analyzer for Inuktitut. The development of MT systems for Indigenous languages have followed the trends in the field, with rule-based, statistical-based and neural network-based approaches. Micher (2018) applied the Byte Pair Encoding (BPE) algorithm (Sennrich et al., 2016) pre-processing both the English and Inuktitut sides of the Nunavut Hansard corpus, in the Inuktitut to English direction, reported a BLEU score of 30.35. NMT approaches use neural networks architectures that are fed with very big amounts of parallel texts. However, these resources are currently unavailable or scarce for most Indigenous languages, especially for the endangered such as Inuinnaqtun, except Inuktitut-English (Joanis et al., 2020). 3 Methodology In this section, we present some existing word segmentation method"
2020.amta-research.15,N13-1090,0,0.0220437,"g the Nunavut Hansard for Inuktitut-English (third edition). As described in Joanis et al. (2020), this corpus contains 1,293,348 sentences, 5,433 sentences and 6,139 sentences for the training, development and testing sets, respectively (Table 2). Dataset Inuktitut English #tokens 20,657,477 10,962,904 #train 1,293,348 1,293,348 #dev 5,433 5,433 #test 6,139 6,139 Table 2: Statistics of Nunavut Hansard Inuktitut-English parallel corpus 3.0 In order to pre-train the (bi-)character-based and word-based embeddings for Inuktitut, these Nunavut Hansard datasets were used with the word2vec toolkit (Mikolov et al., 2013) with a dimension of 50 and 30 for word-based and (bi-)character-based embeddings, respectively, and option CBOW (Continuous Bag-Of-Words) by default. We observe there are only 97,785 unique terms for word-based vocabulary, 102 unique terms for character-based vocabulary and 1,406 unique terms for bicharacter-based vocabulary (Table 3). To train our rich word segmenter2 , we annotated 11K sentences, 250 sentences, 250 sentences for training, development and testing, respectively. We used Uqailaut toolkit (Farley, 2012) to annotate the training data. Embedding type word-based character-based bi"
2020.amta-research.15,P02-1040,0,0.106241,"Missing"
2020.amta-research.15,P16-1162,0,0.727568,"d system that involves regular morphological variations of about 3200 head, 350 lexical, and 1500 grammatical morphemes, with heuristics for ranking the various readings. Inspired by the Uqailaut project of Farley (2012), Micher (2017) applied a segmental recurrent neural network approach (Kong et al., 2015) from the output of this morphological analyzer for Inuktitut. The development of MT systems for Indigenous languages have followed the trends in the field, with rule-based, statistical-based and neural network-based approaches. Micher (2018) applied the Byte Pair Encoding (BPE) algorithm (Sennrich et al., 2016) pre-processing both the English and Inuktitut sides of the Nunavut Hansard corpus, in the Inuktitut to English direction, reported a BLEU score of 30.35. NMT approaches use neural networks architectures that are fed with very big amounts of parallel texts. However, these resources are currently unavailable or scarce for most Indigenous languages, especially for the endangered such as Inuinnaqtun, except Inuktitut-English (Joanis et al., 2020). 3 Methodology In this section, we present some existing word segmentation methods for Inuktitut as well as our proposed one. 3.1 Uqailaut morphological"
2020.coling-main.410,2020.lrec-1.312,0,0.140665,"n in Northern Canada. We make our focus on (1) the preprocessing phase to build (2) NLP applications for Indigenous languages, such as morphological analysis, parsing, Named Entities Recognition and Machine Translation. This first step towards a multilingual NMT framework that will involve several endangered Indigenous languages of Canada, is essential, as the only parallel 4661 Proceedings of the 28th International Conference on Computational Linguistics, pages 4661–4666 Barcelona, Spain (Online), December 8-13, 2020 corpus freely available for research is the Nunavut-English Hansard corpus (Joanis et al., 2020). The main contribution of our research is to revitalize these Indigenous languages and help ancestral and other knowledge transmission vertically from the elders to the youth. The structure of the paper is described as follows: Section 2 presents the state-of-the-art on MT involving Indigenous languages. In section 3, we describe our proposed approach. Then, in section 4, we present our experiments and evaluations. Finally, in section 5, we present our conclusions and some perspectives for future research. 2 Related work Johnson and Martin (2003) proposed an unsupervised technique with the hu"
2020.coling-main.410,N03-2015,0,0.114394,"Missing"
2020.coling-main.410,N18-1005,0,0.132743,"Missing"
2020.coling-main.410,P07-2045,0,0.0078249,"t toolkit (Farley, 2012) to annotate the training data. We observe there are only 97,785 unique terms for word-based vocabulary, 102 unique terms for character-based vocabulary and 1,406 unique terms for bi-character-based vocabulary. 4.2 Training Configuration The word segmentation model is composed of 2-layer bi-directional Long Short-term Memory (LSTM), with the hidden layer of 200 neurons. We performed two experiments: with only word-based pretrained embedding (EXP1) and with all (bi)character-based and word-based pretrained embeddings (EXP2). In the preprocessing step, we used the Moses (Koehn et al., 2007) tokenizer in all experiments. In the BPE subword segmentation, we used the subword-nmt (Sennrich et al., 2016) toolkit to create a 30k BPE joint source-target vocabulary. Then to train our Transformer-based NMT models, we used the Marian-nmt toolkit (Junczys-Dowmunt et al., 2018) with the following hyper-parameters settings (Table 2). Architecture Type: Transformer Number of layers: 6-layer depth for both encoder and decoder Number of heads: 8-layer mulit-heads Hidden layers: 2,048 units in the feed-forward networks Optimization: Adam Embedding size: 512 Learning rate : 0.0003 Batch-size: 32"
2020.coling-main.410,K15-2004,0,0.0531965,"Missing"
2020.coling-main.410,2020.amta-research.15,1,0.346526,"ation of the first Inuktitut morphological analyzer based on the Finite-State Transducer method, we built a deep learning-based word segmentation tool for Inuktitut. With the emergence of deep learning and the high computation of technology, neural networkbased approaches have shown their effectiveness when applied on word segmentation and enhanced with large-scale raw texts to pretrain embeddings. The neural network-based model, with these additional linguistic factors, can be able to deal with data sparseness or language ambiguity (Kann et al., 2018). Following our previous research (Le and Sadat, 2020), we propose a two phases framework to build : (1) a bidirectional LSTM word segmentation for Inuktitut; and (2) an Inuktitut-English NMT system (Figure 1). In the first phase, the word segmentation task, considered as a sequence labeling task, is formally formulated as follows: Given an input sequence, W and C represent all the word-based (bi-)character-based pretrained embeddings. In the input representation layer, the input sequence is vectorized based on word embeddings W . This vectorized sequence is concatenated with (bi)character-based pretrained embedding C, with the state hW, Ci. Then"
2020.coling-main.410,C18-1222,0,0.115712,"respond to an increasing demand for Indigenous language educational materials and technology. Previous studies have demonstrated that the development of Indigenous language technology faces many challenges on one hand, due to a high morpheme per word rate and the rich morphophonemics and variable dialectal-dependent spellings, a complex polysynthesis in linguistic typology, and on the other hand, due to the lack of orthographic standardization and a large dialect variation. Digital text and voice data are limited. It poses many greater challenges for NLP to develop applications for all users (Littell et al., 2018; Mager et al., 2018). This research paper examines the case of Inuktitut through experiments on the crucial phase as preprocessing and NLP task, to revitalize the language which belongs to the Inuit languages family - the polysynthetic languages spoken in Northern Canada. We make our focus on (1) the preprocessing phase to build (2) NLP applications for Indigenous languages, such as morphological analysis, parsing, Named Entities Recognition and Machine Translation. This first step towards a multilingual NMT framework that will involve several endangered Indigenous languages of Canada, is ess"
2020.coling-main.410,C18-1006,0,0.112057,"ng demand for Indigenous language educational materials and technology. Previous studies have demonstrated that the development of Indigenous language technology faces many challenges on one hand, due to a high morpheme per word rate and the rich morphophonemics and variable dialectal-dependent spellings, a complex polysynthesis in linguistic typology, and on the other hand, due to the lack of orthographic standardization and a large dialect variation. Digital text and voice data are limited. It poses many greater challenges for NLP to develop applications for all users (Littell et al., 2018; Mager et al., 2018). This research paper examines the case of Inuktitut through experiments on the crucial phase as preprocessing and NLP task, to revitalize the language which belongs to the Inuit languages family - the polysynthetic languages spoken in Northern Canada. We make our focus on (1) the preprocessing phase to build (2) NLP applications for Indigenous languages, such as morphological analysis, parsing, Named Entities Recognition and Machine Translation. This first step towards a multilingual NMT framework that will involve several endangered Indigenous languages of Canada, is essential, as the only p"
2020.coling-main.410,W17-0114,0,0.036577,"Missing"
2020.coling-main.410,N13-1090,0,0.00503694,"(Lample and Conneau, 2019). 1 pretrained BERT models fromhttps://github.com/huggingface/transformers 4663 4 4.1 Experiments Data Preparation In our evaluations, we train our NMT model by using the Nunavut Hansard for Inuktitut-English (third edition) (Joanis et al., 2020). The statistics of the training corpus are described in Table 1. Dataset Inuktitut English #tokens 20,657,477 10,962,904 #train 1,293,348 1,293,348 #dev 5,433 5,433 #test 6,139 6,139 Table 1: Statistics of Nunavut Hansard for Inuktitut-English In order to pre-train the embeddings for Inuktitut, we used the word2vec toolkit (Mikolov et al., 2013) with option CBOW (Continuous Bag-Of-Words). To train our rich word segmenter, we annotated 11K sentences, 250 sentences, 250 sentences for training, development and testing, respectively. We used the Uqailaut toolkit (Farley, 2012) to annotate the training data. We observe there are only 97,785 unique terms for word-based vocabulary, 102 unique terms for character-based vocabulary and 1,406 unique terms for bi-character-based vocabulary. 4.2 Training Configuration The word segmentation model is composed of 2-layer bi-directional Long Short-term Memory (LSTM), with the hidden layer of 200 neur"
2020.coling-main.410,N12-1040,0,0.0754714,"Missing"
2020.coling-main.410,P02-1040,0,0.105928,"Missing"
2020.coling-main.410,P16-1162,0,0.040885,"rd-based vocabulary, 102 unique terms for character-based vocabulary and 1,406 unique terms for bi-character-based vocabulary. 4.2 Training Configuration The word segmentation model is composed of 2-layer bi-directional Long Short-term Memory (LSTM), with the hidden layer of 200 neurons. We performed two experiments: with only word-based pretrained embedding (EXP1) and with all (bi)character-based and word-based pretrained embeddings (EXP2). In the preprocessing step, we used the Moses (Koehn et al., 2007) tokenizer in all experiments. In the BPE subword segmentation, we used the subword-nmt (Sennrich et al., 2016) toolkit to create a 30k BPE joint source-target vocabulary. Then to train our Transformer-based NMT models, we used the Marian-nmt toolkit (Junczys-Dowmunt et al., 2018) with the following hyper-parameters settings (Table 2). Architecture Type: Transformer Number of layers: 6-layer depth for both encoder and decoder Number of heads: 8-layer mulit-heads Hidden layers: 2,048 units in the feed-forward networks Optimization: Adam Embedding size: 512 Learning rate : 0.0003 Batch-size: 32 Number of epochs: 50 iterations Early stop: cross-entropy scores Validation updates: 5,000 Table 2: Hyper-param"
2020.lincr-1.7,E17-2092,0,0.01595,"htags as a source of annotation for emotions. The annotation scheme corresponds to Ekman’s basic emotion model. They collected tweets with hashtags corresponding to Ekman’s six basics emotions: anger, disgust, fear, happy, sadness, and surprise. The dataset DailyDialogs, published by Li et al. (2017), is based on conversations and includes 13,118 sentences. The annotation used is from Ekman, with a label of &quot;no emotion&quot;. A single label by utterance via an expert annotation. This dataset contains annotations about the user’s intent and the topic of the dialog. The dataset EmoBank, published by Buechel and Hahn (2017), is based on several genres and domains. It consists of 10,548 sentences, each one annotated manually according to the emotion expressed by the author and the readers. The dataset EmoInt, published by Mohammad and BravoMarquez (2017) (Bostan and Klinger, 2018), consists of 7,097 tweets. It associates each text with different intensities of emotion. The tweets are annotated via crowdsourcing with intensities of anger, joy, sadness, and fear. As the previous list shows, there exist many emotional data set to work with. However, they all have the following limitations with regards to Plutchik’s"
2020.lincr-1.7,D17-1169,0,0.237879,"ons before modelling these tasks (Mohammad et al., 2013; Nida et al., 2019). 3.1. Previous works on emotion recognition Some works use binarized emojis as noisy labels (Read, 2005; Nakov et al., 2016; Yang et al., 2016; Nikhil and Srivastava, 2018), but emojis can be ambiguous as they can serve both as comments or to set emotional state of a text. This ambiguity was addresses by Kunneman et al. (2014) with emotional hashtags such as #nice and #lame. Nevertheless, DeepMoji has succeeded in showing that emoticons can be used to accurately categorize the emotional content of texts in many cases (Felbo et al., 2017). But DeepMoji requires more than one billion pieces of data for training (1 246 million of tweets), and it has two limitations: a) The analyzed text must contain emoticons; b) the emojis do not always reflect the emotional state behind the writing of the text, since they can also be used to complete the writing text.Other works use emotion theories such as Ekman’s six basic emotions and Plutchik’s eight basic emotions (Mohammad et al., 2013; Suttles and Ide, 2013; Felbo et al., 2017). The categorization is also done manually, and it requires requires an understanding of the emotional content"
2020.lincr-1.7,S18-1056,0,0.0234431,"the emotion is presented with its opposite, for example the binary classification in a multilabel context can indicate joy and sadness at the same time, an impossible representation by Plutchik’s theory. The authors Felbo et al. (2017) used transfer learning (Bengio, 2012), which does not require access to the original dataset, but only to the model of an already trained deep learning classifier. This allowed them to classify sarcasm (Gal and Ghahramani, 2016) and the 7 emotions of the PsychExp dataset (Wallbott and Scherer, 1986). Others works using transfer learning (Barbieri et al., 2018; Gee and Wang, 2018; Park et al., 2018) demonstrated a great performance in detecting emojis in shared tasks such as SemEval1 . 1 3.2. Datasets Overview In this section, we present the existing emotional English datasets in chronological order. The dataset ISEAR, published by (Scherer and Wallbott, 1994) uses the responses of people from different cultures to questionnaires in social media. The final dataset contains about 3,000 reports, for 7,665 sentences labeled with unique emotions. The set uses the labels “joy”, “fear”, “anger”, “sadness”, “disgust”, “shame” and “guilt”. The WordNet-Affect Lexicon (Valitutt"
2020.lincr-1.7,H05-1073,0,0.18665,"(Scherer and Wallbott, 1994) uses the responses of people from different cultures to questionnaires in social media. The final dataset contains about 3,000 reports, for 7,665 sentences labeled with unique emotions. The set uses the labels “joy”, “fear”, “anger”, “sadness”, “disgust”, “shame” and “guilt”. The WordNet-Affect Lexicon (Valitutti, 2004) is a collection of emotion related words (nouns, verbs, adjectives, and adverbs), classified as “Positive”, “Negative”, “Neutral”, or “Ambiguous”, and categorized into 28 subcategories (“Joy”, “Love”, “Fear”, etc.). The dataset Tales, published by Alm et al. (2005; Bostan and Klinger (2018) is based on literature and consists of 15,302 sentences, with its annotators only agreeing on 1,280 sentences. The goal of this resource is to help build emotion classifiers for literature. The annotation scheme includes Ekman’s six basic emotions. Labels ’angry’ and ’disgust’ are merged. The dataset AffectiveText, published by Strapparava and Mihalcea (2007; Bostan and Klinger (2018), is built from news headlines. The main objective of this resource is the classification of emotions and valence in news headlines using the basic emotions of Ekman, supplemented by en"
2020.lincr-1.7,E17-2017,0,0.0286622,"Alarm Disappointment Remorse Contempt Aggressiveness Optimism Secondary Dyads Joy + Fear Surprise + Trust Sadness + Fear Surprise + Disgust Sadness + Anger Disgust + Anticipation Anger + Joy Anticipation + Trust Results Guilt Curiosity Despair Horror Envy Cynicism Pride Fatalism Tertiary Dyads Surprise + Joy Sadness + Trust Disgust + Fear Surprise + Anger Sadness + Anticipation Disgust + Joy Anger + Trust Anticipation + Fear Results Delight Faintness Shame Outrage Pessimism Morbidity Domination Anxiety Table 1: Combinations of Plutchik’s emotions (Plutchik, 2003). 3. Related Work The authors Barbieri et al. (2017) studied the relationship between words and emoticons. They also proposed an approach to predict the most likely emoji associated with a tweet. This proposed approach was based on a Bidirectional Long Short-Term Memory (BiLSTM) architecture (BiLSTM). Zhong and Miao (2019) used a model that extends the Recurrent Convolutional Neural Network (RCNN) using finely-tuned external word representations and DeepMoji phrase representations on the emotion detection task in SemEval-2019. Other work (Tang et al., 2014) proposed a method to learn to incorporate specific words in Word Embeddings and showed a"
2020.lincr-1.7,C18-1179,0,0.178945,"bott, 1994) uses the responses of people from different cultures to questionnaires in social media. The final dataset contains about 3,000 reports, for 7,665 sentences labeled with unique emotions. The set uses the labels “joy”, “fear”, “anger”, “sadness”, “disgust”, “shame” and “guilt”. The WordNet-Affect Lexicon (Valitutti, 2004) is a collection of emotion related words (nouns, verbs, adjectives, and adverbs), classified as “Positive”, “Negative”, “Neutral”, or “Ambiguous”, and categorized into 28 subcategories (“Joy”, “Love”, “Fear”, etc.). The dataset Tales, published by Alm et al. (2005; Bostan and Klinger (2018) is based on literature and consists of 15,302 sentences, with its annotators only agreeing on 1,280 sentences. The goal of this resource is to help build emotion classifiers for literature. The annotation scheme includes Ekman’s six basic emotions. Labels ’angry’ and ’disgust’ are merged. The dataset AffectiveText, published by Strapparava and Mihalcea (2007; Bostan and Klinger (2018), is built from news headlines. The main objective of this resource is the classification of emotions and valence in news headlines using the basic emotions of Ekman, supplemented by enumerate valence between 0 t"
2020.lincr-1.7,W14-1304,0,0.0452655,"Missing"
2020.lincr-1.7,I17-1099,0,0.0970429,"is built on tweets and contains 2,557 instances published by 1,369 users. The labels is &quot;happy&quot; and &quot;sad&quot;. The tweets are annotated by the authors. The dataset TEC, published by Mohammad et al. (2013)(Bostan and Klinger, 2018), includes 21,051 tweets. The main objective of this resource is to use emotion word hashtags as a source of annotation for emotions. The annotation scheme corresponds to Ekman’s basic emotion model. They collected tweets with hashtags corresponding to Ekman’s six basics emotions: anger, disgust, fear, happy, sadness, and surprise. The dataset DailyDialogs, published by Li et al. (2017), is based on conversations and includes 13,118 sentences. The annotation used is from Ekman, with a label of &quot;no emotion&quot;. A single label by utterance via an expert annotation. This dataset contains annotations about the user’s intent and the topic of the dialog. The dataset EmoBank, published by Buechel and Hahn (2017), is based on several genres and domains. It consists of 10,548 sentences, each one annotated manually according to the emotion expressed by the author and the readers. The dataset EmoInt, published by Mohammad and BravoMarquez (2017) (Bostan and Klinger, 2018), consists of 7,0"
2020.lincr-1.7,S13-2053,0,0.0920622,"Missing"
2020.lincr-1.7,S16-1001,0,0.0227674,"sting features. In our knowledge, none of the previous works considered the case of texts with conflicting emotions, hence the need for such a model. Because of the absence of annotated data, manually or otherwise, many NLP tasks related to sentiment analysis and emotion mining use co-occurring emotional expressions for remote supervision of social media, to allow models to learn directly useful textual representations before modelling these tasks (Mohammad et al., 2013; Nida et al., 2019). 3.1. Previous works on emotion recognition Some works use binarized emojis as noisy labels (Read, 2005; Nakov et al., 2016; Yang et al., 2016; Nikhil and Srivastava, 2018), but emojis can be ambiguous as they can serve both as comments or to set emotional state of a text. This ambiguity was addresses by Kunneman et al. (2014) with emotional hashtags such as #nice and #lame. Nevertheless, DeepMoji has succeeded in showing that emoticons can be used to accurately categorize the emotional content of texts in many cases (Felbo et al., 2017). But DeepMoji requires more than one billion pieces of data for training (1 246 million of tweets), and it has two limitations: a) The analyzed text must contain emoticons; b) the"
2020.lincr-1.7,S18-1102,0,0.019605,"of the previous works considered the case of texts with conflicting emotions, hence the need for such a model. Because of the absence of annotated data, manually or otherwise, many NLP tasks related to sentiment analysis and emotion mining use co-occurring emotional expressions for remote supervision of social media, to allow models to learn directly useful textual representations before modelling these tasks (Mohammad et al., 2013; Nida et al., 2019). 3.1. Previous works on emotion recognition Some works use binarized emojis as noisy labels (Read, 2005; Nakov et al., 2016; Yang et al., 2016; Nikhil and Srivastava, 2018), but emojis can be ambiguous as they can serve both as comments or to set emotional state of a text. This ambiguity was addresses by Kunneman et al. (2014) with emotional hashtags such as #nice and #lame. Nevertheless, DeepMoji has succeeded in showing that emoticons can be used to accurately categorize the emotional content of texts in many cases (Felbo et al., 2017). But DeepMoji requires more than one billion pieces of data for training (1 246 million of tweets), and it has two limitations: a) The analyzed text must contain emoticons; b) the emojis do not always reflect the emotional state"
2020.lincr-1.7,S18-1039,0,0.0182649,"ented with its opposite, for example the binary classification in a multilabel context can indicate joy and sadness at the same time, an impossible representation by Plutchik’s theory. The authors Felbo et al. (2017) used transfer learning (Bengio, 2012), which does not require access to the original dataset, but only to the model of an already trained deep learning classifier. This allowed them to classify sarcasm (Gal and Ghahramani, 2016) and the 7 emotions of the PsychExp dataset (Wallbott and Scherer, 1986). Others works using transfer learning (Barbieri et al., 2018; Gee and Wang, 2018; Park et al., 2018) demonstrated a great performance in detecting emojis in shared tasks such as SemEval1 . 1 3.2. Datasets Overview In this section, we present the existing emotional English datasets in chronological order. The dataset ISEAR, published by (Scherer and Wallbott, 1994) uses the responses of people from different cultures to questionnaires in social media. The final dataset contains about 3,000 reports, for 7,665 sentences labeled with unique emotions. The set uses the labels “joy”, “fear”, “anger”, “sadness”, “disgust”, “shame” and “guilt”. The WordNet-Affect Lexicon (Valitutti, 2004) is a collec"
2020.lincr-1.7,W16-0404,0,0.0396642,"Missing"
2020.lincr-1.7,P05-2008,0,0.0287113,"sets of existing features. In our knowledge, none of the previous works considered the case of texts with conflicting emotions, hence the need for such a model. Because of the absence of annotated data, manually or otherwise, many NLP tasks related to sentiment analysis and emotion mining use co-occurring emotional expressions for remote supervision of social media, to allow models to learn directly useful textual representations before modelling these tasks (Mohammad et al., 2013; Nida et al., 2019). 3.1. Previous works on emotion recognition Some works use binarized emojis as noisy labels (Read, 2005; Nakov et al., 2016; Yang et al., 2016; Nikhil and Srivastava, 2018), but emojis can be ambiguous as they can serve both as comments or to set emotional state of a text. This ambiguity was addresses by Kunneman et al. (2014) with emotional hashtags such as #nice and #lame. Nevertheless, DeepMoji has succeeded in showing that emoticons can be used to accurately categorize the emotional content of texts in many cases (Felbo et al., 2017). But DeepMoji requires more than one billion pieces of data for training (1 246 million of tweets), and it has two limitations: a) The analyzed text must conta"
2020.lincr-1.7,S07-1013,0,0.109939,"tion related words (nouns, verbs, adjectives, and adverbs), classified as “Positive”, “Negative”, “Neutral”, or “Ambiguous”, and categorized into 28 subcategories (“Joy”, “Love”, “Fear”, etc.). The dataset Tales, published by Alm et al. (2005; Bostan and Klinger (2018) is based on literature and consists of 15,302 sentences, with its annotators only agreeing on 1,280 sentences. The goal of this resource is to help build emotion classifiers for literature. The annotation scheme includes Ekman’s six basic emotions. Labels ’angry’ and ’disgust’ are merged. The dataset AffectiveText, published by Strapparava and Mihalcea (2007; Bostan and Klinger (2018), is built from news headlines. The main objective of this resource is the classification of emotions and valence in news headlines using the basic emotions of Ekman, supplemented by enumerate valence between 0 to 100. The dataset Blogs, published by Aman and Szpakowicz (2007), includes 5,205 sentences. Each instance annotated with one label. The used annotation scheme corresponds to Ekman’s six fundamental emotions. (International Workshop on Semantic Evaluation) 51 The dataset EmoTxt , published by Ortu et al. (2015), includes 4000 comments posted by software devel"
2020.lincr-1.7,P14-1146,0,0.0321324,"1: Combinations of Plutchik’s emotions (Plutchik, 2003). 3. Related Work The authors Barbieri et al. (2017) studied the relationship between words and emoticons. They also proposed an approach to predict the most likely emoji associated with a tweet. This proposed approach was based on a Bidirectional Long Short-Term Memory (BiLSTM) architecture (BiLSTM). Zhong and Miao (2019) used a model that extends the Recurrent Convolutional Neural Network (RCNN) using finely-tuned external word representations and DeepMoji phrase representations on the emotion detection task in SemEval-2019. Other work (Tang et al., 2014) proposed a method to learn to incorporate specific words in Word Embeddings and showed an improvement in the performance especially when combining other sets of existing features. In our knowledge, none of the previous works considered the case of texts with conflicting emotions, hence the need for such a model. Because of the absence of annotated data, manually or otherwise, many NLP tasks related to sentiment analysis and emotion mining use co-occurring emotional expressions for remote supervision of social media, to allow models to learn directly useful textual representations before model"
2020.lincr-1.7,strapparava-valitutti-2004-wordnet,0,0.710762,"ng, 2018; Park et al., 2018) demonstrated a great performance in detecting emojis in shared tasks such as SemEval1 . 1 3.2. Datasets Overview In this section, we present the existing emotional English datasets in chronological order. The dataset ISEAR, published by (Scherer and Wallbott, 1994) uses the responses of people from different cultures to questionnaires in social media. The final dataset contains about 3,000 reports, for 7,665 sentences labeled with unique emotions. The set uses the labels “joy”, “fear”, “anger”, “sadness”, “disgust”, “shame” and “guilt”. The WordNet-Affect Lexicon (Valitutti, 2004) is a collection of emotion related words (nouns, verbs, adjectives, and adverbs), classified as “Positive”, “Negative”, “Neutral”, or “Ambiguous”, and categorized into 28 subcategories (“Joy”, “Love”, “Fear”, etc.). The dataset Tales, published by Alm et al. (2005; Bostan and Klinger (2018) is based on literature and consists of 15,302 sentences, with its annotators only agreeing on 1,280 sentences. The goal of this resource is to help build emotion classifiers for literature. The annotation scheme includes Ekman’s six basic emotions. Labels ’angry’ and ’disgust’ are merged. The dataset Affec"
2020.lincr-1.7,N16-1174,0,0.0398375,"ur knowledge, none of the previous works considered the case of texts with conflicting emotions, hence the need for such a model. Because of the absence of annotated data, manually or otherwise, many NLP tasks related to sentiment analysis and emotion mining use co-occurring emotional expressions for remote supervision of social media, to allow models to learn directly useful textual representations before modelling these tasks (Mohammad et al., 2013; Nida et al., 2019). 3.1. Previous works on emotion recognition Some works use binarized emojis as noisy labels (Read, 2005; Nakov et al., 2016; Yang et al., 2016; Nikhil and Srivastava, 2018), but emojis can be ambiguous as they can serve both as comments or to set emotional state of a text. This ambiguity was addresses by Kunneman et al. (2014) with emotional hashtags such as #nice and #lame. Nevertheless, DeepMoji has succeeded in showing that emoticons can be used to accurately categorize the emotional content of texts in many cases (Felbo et al., 2017). But DeepMoji requires more than one billion pieces of data for training (1 246 million of tweets), and it has two limitations: a) The analyzed text must contain emoticons; b) the emojis do not alwa"
2020.lincr-1.7,S19-2048,0,0.0206018,"atalism Tertiary Dyads Surprise + Joy Sadness + Trust Disgust + Fear Surprise + Anger Sadness + Anticipation Disgust + Joy Anger + Trust Anticipation + Fear Results Delight Faintness Shame Outrage Pessimism Morbidity Domination Anxiety Table 1: Combinations of Plutchik’s emotions (Plutchik, 2003). 3. Related Work The authors Barbieri et al. (2017) studied the relationship between words and emoticons. They also proposed an approach to predict the most likely emoji associated with a tweet. This proposed approach was based on a Bidirectional Long Short-Term Memory (BiLSTM) architecture (BiLSTM). Zhong and Miao (2019) used a model that extends the Recurrent Convolutional Neural Network (RCNN) using finely-tuned external word representations and DeepMoji phrase representations on the emotion detection task in SemEval-2019. Other work (Tang et al., 2014) proposed a method to learn to incorporate specific words in Word Embeddings and showed an improvement in the performance especially when combining other sets of existing features. In our knowledge, none of the previous works considered the case of texts with conflicting emotions, hence the need for such a model. Because of the absence of annotated data, manu"
2020.socialnlp-1.8,N19-1078,0,0.022729,"Missing"
2020.socialnlp-1.8,C18-1251,0,0.0172344,"al. (2019)). More specifically, we organised the four tasks from low-level to high-level, with each task being fed with a shared word embedding as well as the outputs of all the lower tasks. To construct that hierarchy of tasks, we followed some linguistic hints from the literature. Indeed, many works have shown that POS improves CK (Yang et al., 2017; Ruder12 et al., 2019); NER benefits from POS (Meftah and Semmar, 2018; Ruder, 2019) and CK (Collobert and Weston, 2008); and DP profits from POS and CK (Hashimoto et al., 2017). In simple terms, POS and CK are considered as “universal helpers” (Changpinyo et al., 2018). Thus, based on these linguistic hierarchy observations, we feed POS features to CK; then POS and CK features to both NER and DP. An illustration of our multi-task hierarchical model is given in Fig.1. More specifically, WRE is shared across all tasks, its output (namely xi = WREshared (wi )) is fed to all branches. The lower component of the POS tagging branch (FEpos ) is fed with the shared embedding and after processing, it outputs BiLSTMs features hpos . This is i then fed into the POS classifier Cpos to calculate predictions through: Figure 1: Illustrative scheme of our Hierarchical mult"
2020.socialnlp-1.8,D17-1070,0,0.0330129,"ets for the News and Tweets domains, by unifying the aforementioned task-independent datasets. 2 rates for task-specific parameters. While the second, modify the importance of each task statically or dynamically. e.g. Kiperwasser and Ballesteros (2018) proposed variable schedules that increasingly favour the principal task over batches and Jean et al. (2018) proposed adaptive schedules that vary according to the validation performance of each task during training. Multi-Task Pretraining and Fine-tuning: Multitask pretraining has been especially explored for learning universal representations (Conneau et al., 2017; Ahmad et al., 2018). Multi-task fine-tuning was recently explored to fine-tune BERT pretrained model in a multi-task fashion on multiple tasks (Liu et al., 2019). Furthermore, in term of using multi-task features for domain adaptation, Søgaard and Goldberg (2016) showed the benefit of multi-task learning for domain adaptation from News-domain to Weblogs-domain for CK task, when disposing CK’s supervision only for the source-domain, and lower-level POS supervision for the target-domain. Finally, in terms of unifying multi-task learning and fine-tuning, Kiperwasser and Ballesteros (2018) propo"
2020.socialnlp-1.8,W17-4418,0,0.0209646,"Missing"
2020.socialnlp-1.8,N19-1423,0,0.0132548,"d Multi-Task Learning. In the following, we briefly present the SOTA of each one. Then, we discuss some papers from the literature with a loosely close idea to multi-task pretraining and fine-tuning. Sequential Transfer Learning (STL) is a TL setting performed in two stages: Pretraining and Adaptation. The purpose behind using STL techniques for NLP can be divided into two main research areas, “universal representations” and “domain adaptation”. The former aims to build neural features transferable and beneficial to a wide range of NLP tasks and domains. e.g. ELMo (Peters et al., 2018), BERT (Devlin et al., 2019), etc. The second aims to harness the knowledge represented in features learned on a source domain (high-resourced in most cases) to improve learning a target domain (low-resourced in most cases) (Zennaki et al., 2016, 2019). The source and the target problems may differ on the task, the language or the domain. For instance, cross-lingual adaptation has been explored for sentiment analysis (Chen et al., 2016) and cross-domain adaptation has been applied for POS models adaptation from News to Tweets domain (Gui et al., 2017; Meftah et al., 2017, 2018). Our research falls into the second researc"
2020.socialnlp-1.8,N18-1088,0,0.0124463,"377 203,621 - 51,362 - 46,435 204,585 - 25,148 - 25,096 24,753 - 11,742 - 19,112 10,652 - 2,242 - 2,291 62,729 - 15,734 - 23,394 24,753 - 11,742 - 19,112 Table 1: Statistics of the datasets we used to train our multi-task learning models. Top: datasets of the source domain (called “EnglishAll”). Bottom: datasets of the target domain (called “TweetAll”). NER (Sang and De Meulder, 2003); CONLL2000 (Sang et al., 2000) for CK; and finally UD-EnglishEWT (Nivre et al., 2016) for DP. In the same vein, for the target-datasets, we used the Tweets domain and the following datasets: the recent TweeBank (Liu et al., 2018) for POS, annotated with the PTB universal tag-set; WNUT-17 from emerging entity detection shared task (Derczynski et al., 2017) for NER; TChunk (Ritter et al., 2011) for CK; and the data annotated with Universal dependency relations in the TweeBank dataset for DP1 . Detailed statistics of all the datasets are summarised in Table 1. To evaluate our models, we use the accuracy (acc) for POS, Exact-match F12 (Li et al., 2020) for NER and CK and labelled attachment score (LAS) (Nivre et al., 2004). 5.2 of a CNNs-based character-level representations followed by a 2-layer LSTMs. Thus, ELMo with th"
2020.socialnlp-1.8,N19-1249,0,0.0680556,"ck all the tasks following a constant ordering strategy “from lowerlevel to higher-level tasks” (Hashimoto et al., 2017): POS then CK then NER then DP. Thus, every 4 steps, the model sees all the tasks once and learns their corresponding parameters once. 4.2.2 Datasets Unification As mentioned in the previous section, we mostly face the heterogeneous multi-task learning scenario, where only one task-labels might be assigned to a dataset. In that case, the classical multi-task learning approach is not directly applicable, thus we propose to use the “Scheduling process” (Zaremoodi et al., 2018; Lu et al., 2019) (described in the following paragraph). However, since training with different datasets for each task remains difficult (Subramanian et al., 2018) ) we proposed “Dataset Unification” a much simpler and easy to learn method for that scenario. To overcome the intricacy of “tasks scheduling process”, we propose to construct a unified dataset by combining several sources of independent textual annotations. Furthermore, since we are interested in benefiting from pretraining and fine-tuning, we apply unification process on both, source and targetdomains. These datasets contain samples of a broad ra"
2020.socialnlp-1.8,P16-1101,0,0.0112188,"t al., 2018). The processing (training) order of examples from different tasks (datasets), also called Scheduling, is particularly studied in the literature. This could be implicit or explicit (Jean et al., 2018). The formal include, for instance, affecting different learning 3 3.1 Model Architecture Sequence Labelling Architecture Regarding the exact architecture of each task, POS, CK and NER tasks are Sequence Labelling (SL) tasks. Given an input sentence of n successive tokens [w1 , . . . , wn ], SL predicts the tag ci ∈ C of every wi , with C being the tag-set. We followed the literature (Ma and Hovy, 2016; Yang et al., 2018) and used a common SL architecture, including three main components: (i) a Word Representation Extractor (WRE), (ii) a Features Extractor (FE) and (iii) a Classifier (Cl). WRE computes, for each token wi , a word and a character-level biLSTMs encoderbased embeddings (respectively, wei =WE(wi ) and cei =CE(wi )), and concatenates them to get a final representation xi =(wei ,cei ). WRE’s out62 producing four distinct vectors for representing the word: (i) as a dependent seeking its head; (ii), as a head seeking all its dependants; (iii), as a dependent deciding on its relatio"
2020.socialnlp-1.8,K17-3002,0,0.0208397,"d seeking all its dependants; (iii), as a dependent deciding on its relation; and (iv), as a head deciding on the labels of its dependants. These representations are then passed to biAffine softmax classifiers. 3.3 As mentioned above, POS, CK, NER and DP are the four tasks considered in this work. As we aim to learn a multi-task model where the four tasks are learned jointly, the architecture of our model contains a common branch as well as four exits, one per task. Also, as the tasks are hierarchically related to each other, we adopted a hierarchical architecture (similar to Hashimoto et al. (2017) and Sanh et al. (2019)). More specifically, we organised the four tasks from low-level to high-level, with each task being fed with a shared word embedding as well as the outputs of all the lower tasks. To construct that hierarchy of tasks, we followed some linguistic hints from the literature. Indeed, many works have shown that POS improves CK (Yang et al., 2017; Ruder12 et al., 2019); NER benefits from POS (Meftah and Semmar, 2018; Ruder, 2019) and CK (Collobert and Weston, 2008); and DP profits from POS and CK (Hashimoto et al., 2017). In simple terms, POS and CK are considered as “univers"
2020.socialnlp-1.8,J93-2004,0,0.0723342,"selected randomly. Specifically, the base steps of “one task per mini-batch” scheduling process are as follows: 1) picking a mini-batch of samples from only one particular task and 2) updating only the parameters corresponding to the selected task, 5.1 Experiments Domains, Tasks and Datasets As mentioned above, we conducted experiments on four tasks: two low-level tasks (POS and CK) and two higher-level ones: (NER and DP). In terms of domain, data and annotations for the sourcedatasets, we used the standard English domain and chose the following datasets: The WSJ part of PennTree-Bank (PTB) (Marcus et al., 1993) for POS, annotated with the PTB tag-set; CONLL2003 for 65 Task POS: POS Tagging CK: Chunking NER: Named Entity Recognition DP: Dependency Parsing POS: POS Tagging CK: Chunking NER: Named Entity Recognition DP: Dependency Parsing Classes 36 22 4 51 17 18 6 51 Sources WSJ CONLL-2000 CONLL-2003 UD-English-EWT TweeBank TChunk WNUT TweeBank Eval. Metrics Top-1 Acc. Top-1 Exact-match F1. Top-1 Exact-match F1. Top-1 LAS. Top-1 Acc. Top-1 Exact-match F1. Top-1 Exact-match F1. Top-1 LAS. Splits (train - val - test) 912,344 - 131,768 - 129,654 211,727 - n/a - 47,377 203,621 - 51,362 - 46,435 204,585 -"
2020.socialnlp-1.8,L18-1446,1,0.851196,"common branch as well as four exits, one per task. Also, as the tasks are hierarchically related to each other, we adopted a hierarchical architecture (similar to Hashimoto et al. (2017) and Sanh et al. (2019)). More specifically, we organised the four tasks from low-level to high-level, with each task being fed with a shared word embedding as well as the outputs of all the lower tasks. To construct that hierarchy of tasks, we followed some linguistic hints from the literature. Indeed, many works have shown that POS improves CK (Yang et al., 2017; Ruder12 et al., 2019); NER benefits from POS (Meftah and Semmar, 2018; Ruder, 2019) and CK (Collobert and Weston, 2008); and DP profits from POS and CK (Hashimoto et al., 2017). In simple terms, POS and CK are considered as “universal helpers” (Changpinyo et al., 2018). Thus, based on these linguistic hierarchy observations, we feed POS features to CK; then POS and CK features to both NER and DP. An illustration of our multi-task hierarchical model is given in Fig.1. More specifically, WRE is shared across all tasks, its output (namely xi = WREshared (wi )) is fed to all branches. The lower component of the POS tagging branch (FEpos ) is fed with the shared emb"
2020.socialnlp-1.8,W18-3927,1,0.859709,"Missing"
2020.socialnlp-1.8,2020.findings-emnlp.282,0,0.0219462,"Missing"
2020.socialnlp-1.8,D17-1256,0,0.0822203,"ge of NLP tasks and domains. e.g. ELMo (Peters et al., 2018), BERT (Devlin et al., 2019), etc. The second aims to harness the knowledge represented in features learned on a source domain (high-resourced in most cases) to improve learning a target domain (low-resourced in most cases) (Zennaki et al., 2016, 2019). The source and the target problems may differ on the task, the language or the domain. For instance, cross-lingual adaptation has been explored for sentiment analysis (Chen et al., 2016) and cross-domain adaptation has been applied for POS models adaptation from News to Tweets domain (Gui et al., 2017; Meftah et al., 2017, 2018). Our research falls into the second research area, since we aim, as the last two works, to transfer the knowledge learned when training on the News-domain to improve the Tweets-domain’s training. Multi-Task Learning (MTL) consists in a joint learning of related tasks and thus leverages training signals generated by different tasks (Caruana, 1997). The advantage of using MTL over independent task learning has been shown in many NLP tasks and applications (Lin et al., 2018). The processing (training) order of examples from different tasks (datasets), also called Sche"
2020.socialnlp-1.8,N19-1416,1,0.907588,"18), consisting • BiAffine (Dozat and Manning, 2016): we report the LAS score for DP reported by Liu et al. (2018). Note that, in addition to wordlevel and character embeddings, which we use in our model to represent words, they use predicted POS labels and lemmas as input. 1 Note that TweeBank dataset is already anonymised. For TChuck and WNUT datasets, we used simple rules to anonymise usernames and URLs. 2 SeqEval package were used to calculate F1 metric. 3 https://allennlp.org/elmo • Flairs (Akbik et al., 2019): For NER, using 66 Method SOTA - BiAffine(Dozat et al., 2017) SOTA - PretRand (Meftah et al., 2019) SOTA - Flairs (Akbik et al., 2019) SOTA - MDMT (Mishra, 2019) SOTA - DA (LSTM) (Gu and Yu, 2020) SOTA - DA (BERTBASE ) (Gu and Yu, 2020) SOTA - DA (BERTLARGE ) (Gu and Yu, 2020) Best SOTA Mono-task Learning Multi-Task Learning ELMosmall ELMolarge Mono-Task Pre-Training∗ Mono-Task Pre-Training Adversarial Pre-Training MuTSPad (best) PreTraining POS (acc) DP (LAS) NER (F1) CK (F1) mNRG n/a n/a n/a n/a n/a n/a n/a n/a Adversarial n/a 94.95 n/a 92.44 n/a n/a n/a 94.95 91.58 91.98 92.51 94.02 n/a 93.33 93.47 77.7 n/a n/a n/a n/a n/a n/a 77.7 67.48 71.16 69.12 69.76 76.92 78.21 77.49 n/a n/a 49.59"
2020.socialnlp-1.8,D17-1206,0,0.14366,"d; (ii), as a head seeking all its dependants; (iii), as a dependent deciding on its relation; and (iv), as a head deciding on the labels of its dependants. These representations are then passed to biAffine softmax classifiers. 3.3 As mentioned above, POS, CK, NER and DP are the four tasks considered in this work. As we aim to learn a multi-task model where the four tasks are learned jointly, the architecture of our model contains a common branch as well as four exits, one per task. Also, as the tasks are hierarchically related to each other, we adopted a hierarchical architecture (similar to Hashimoto et al. (2017) and Sanh et al. (2019)). More specifically, we organised the four tasks from low-level to high-level, with each task being fed with a shared word embedding as well as the outputs of all the lower tasks. To construct that hierarchy of tasks, we followed some linguistic hints from the literature. Indeed, many works have shown that POS improves CK (Yang et al., 2017; Ruder12 et al., 2019); NER benefits from POS (Meftah and Semmar, 2018; Ruder, 2019) and CK (Collobert and Weston, 2008); and DP profits from POS and CK (Hashimoto et al., 2017). In simple terms, POS and CK are considered as “univers"
2020.socialnlp-1.8,L16-1262,0,0.0282557,"Missing"
2020.socialnlp-1.8,Q18-1017,0,0.123387,"ational Linguistics, pages 61–71 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 ther for the News-domain or the Tweets-domain. Though, many early works had highlighted the intricacy of multi-task training from heterogeneous datasets (Subramanian et al., 2018). Thus, we propose to build multi-task datasets for the News and Tweets domains, by unifying the aforementioned task-independent datasets. 2 rates for task-specific parameters. While the second, modify the importance of each task statically or dynamically. e.g. Kiperwasser and Ballesteros (2018) proposed variable schedules that increasingly favour the principal task over batches and Jean et al. (2018) proposed adaptive schedules that vary according to the validation performance of each task during training. Multi-Task Pretraining and Fine-tuning: Multitask pretraining has been especially explored for learning universal representations (Conneau et al., 2017; Ahmad et al., 2018). Multi-task fine-tuning was recently explored to fine-tune BERT pretrained model in a multi-task fashion on multiple tasks (Liu et al., 2019). Furthermore, in term of using multi-task features for domain adapta"
2020.socialnlp-1.8,W04-2407,0,0.0316575,"n, for the target-datasets, we used the Tweets domain and the following datasets: the recent TweeBank (Liu et al., 2018) for POS, annotated with the PTB universal tag-set; WNUT-17 from emerging entity detection shared task (Derczynski et al., 2017) for NER; TChunk (Ritter et al., 2011) for CK; and the data annotated with Universal dependency relations in the TweeBank dataset for DP1 . Detailed statistics of all the datasets are summarised in Table 1. To evaluate our models, we use the accuracy (acc) for POS, Exact-match F12 (Li et al., 2020) for NER and CK and labelled attachment score (LAS) (Nivre et al., 2004). 5.2 of a CNNs-based character-level representations followed by a 2-layer LSTMs. Thus, ELMo with the randomly initialised FE and Cl are further trained on the target-domain tasks. Specifically, we run experiments with two ELMo models: 1) ELMosmall : the small pre-trained model (13.6M parameters) on 1 billion word benchmark. 2) ELMolarge : the big pre-trained model (93.6M parameters) on 5.5 billion word benchmark. Supervised pretraining on the source-domain of the network on each task independently then fine-tuning on the same task in the Tweets domain. This method is called Mono-Task Pre-Tra"
2020.socialnlp-1.8,P18-1074,0,0.0200349,"cross-domain adaptation has been applied for POS models adaptation from News to Tweets domain (Gui et al., 2017; Meftah et al., 2017, 2018). Our research falls into the second research area, since we aim, as the last two works, to transfer the knowledge learned when training on the News-domain to improve the Tweets-domain’s training. Multi-Task Learning (MTL) consists in a joint learning of related tasks and thus leverages training signals generated by different tasks (Caruana, 1997). The advantage of using MTL over independent task learning has been shown in many NLP tasks and applications (Lin et al., 2018). The processing (training) order of examples from different tasks (datasets), also called Scheduling, is particularly studied in the literature. This could be implicit or explicit (Jean et al., 2018). The formal include, for instance, affecting different learning 3 3.1 Model Architecture Sequence Labelling Architecture Regarding the exact architecture of each task, POS, CK and NER tasks are Sequence Labelling (SL) tasks. Given an input sentence of n successive tokens [w1 , . . . , wn ], SL predicts the tag ci ∈ C of every wi , with C being the tag-set. We followed the literature (Ma and Hovy,"
2020.socialnlp-1.8,D14-1162,0,0.0821001,"but not with the same order of improvement as for NER, which we mainly attribute to the fact that contextual representations pre-trained on language modelling capture more semantic features. Particularly, we find that DP gains the least from ELMo compared to the other syntactic tasks. Implementation details The hyper-parameters (HP) we used are as follows. For The task-agnostic WRE: The dimensions of character embedding = 50, hidden states of the character-level biLSTM = 100 and word-level embeddings (updated during training) = 300 (these latter are pre-loaded from Glove pre-trained vectors (Pennington et al., 2014) and fine-tuned during training). For Sequence labelling branches: we use a single-layer biLSTM Comparing MuTSPad to baselines: MuTSPad outperforms both TL methods, Multi-Task Learning and Mono-Task Fine-Tuning, on all data-sets, by ∼+26 and ∼+10, respectively, on mNRG (median 67 Method POS DP NER CK w/o unif. w/ source unif. w/ source+target unif. 94.08 94.36 94.53 79.17 79.67 80.12 43.34 43.21 40.65 84.87 85.77 85.71 Table 3: Impact of Datasets Unification on MuTSPad. Normalised Relative Gain; a well suited metric for multi-task (Tamaazousti et al., 2019)). Compared to unsupervised pretraini"
2020.socialnlp-1.8,P19-1441,0,0.0219989,"rtance of each task statically or dynamically. e.g. Kiperwasser and Ballesteros (2018) proposed variable schedules that increasingly favour the principal task over batches and Jean et al. (2018) proposed adaptive schedules that vary according to the validation performance of each task during training. Multi-Task Pretraining and Fine-tuning: Multitask pretraining has been especially explored for learning universal representations (Conneau et al., 2017; Ahmad et al., 2018). Multi-task fine-tuning was recently explored to fine-tune BERT pretrained model in a multi-task fashion on multiple tasks (Liu et al., 2019). Furthermore, in term of using multi-task features for domain adaptation, Søgaard and Goldberg (2016) showed the benefit of multi-task learning for domain adaptation from News-domain to Weblogs-domain for CK task, when disposing CK’s supervision only for the source-domain, and lower-level POS supervision for the target-domain. Finally, in terms of unifying multi-task learning and fine-tuning, Kiperwasser and Ballesteros (2018) proposed to improve machine translation with the help of POS and DEP tasks by scheduling tasks during training, starting with multi-tasking of the principal task with a"
2020.socialnlp-1.8,N18-1202,0,0.0918159,"uential Transfer Learning and Multi-Task Learning. In the following, we briefly present the SOTA of each one. Then, we discuss some papers from the literature with a loosely close idea to multi-task pretraining and fine-tuning. Sequential Transfer Learning (STL) is a TL setting performed in two stages: Pretraining and Adaptation. The purpose behind using STL techniques for NLP can be divided into two main research areas, “universal representations” and “domain adaptation”. The former aims to build neural features transferable and beneficial to a wide range of NLP tasks and domains. e.g. ELMo (Peters et al., 2018), BERT (Devlin et al., 2019), etc. The second aims to harness the knowledge represented in features learned on a source domain (high-resourced in most cases) to improve learning a target domain (low-resourced in most cases) (Zennaki et al., 2016, 2019). The source and the target problems may differ on the task, the language or the domain. For instance, cross-lingual adaptation has been explored for sentiment analysis (Chen et al., 2016) and cross-domain adaptation has been applied for POS models adaptation from News to Tweets domain (Gui et al., 2017; Meftah et al., 2017, 2018). Our research f"
2020.socialnlp-1.8,C16-1044,1,0.836303,"er Learning (STL) is a TL setting performed in two stages: Pretraining and Adaptation. The purpose behind using STL techniques for NLP can be divided into two main research areas, “universal representations” and “domain adaptation”. The former aims to build neural features transferable and beneficial to a wide range of NLP tasks and domains. e.g. ELMo (Peters et al., 2018), BERT (Devlin et al., 2019), etc. The second aims to harness the knowledge represented in features learned on a source domain (high-resourced in most cases) to improve learning a target domain (low-resourced in most cases) (Zennaki et al., 2016, 2019). The source and the target problems may differ on the task, the language or the domain. For instance, cross-lingual adaptation has been explored for sentiment analysis (Chen et al., 2016) and cross-domain adaptation has been applied for POS models adaptation from News to Tweets domain (Gui et al., 2017; Meftah et al., 2017, 2018). Our research falls into the second research area, since we aim, as the last two works, to transfer the knowledge learned when training on the News-domain to improve the Tweets-domain’s training. Multi-Task Learning (MTL) consists in a joint learning of relate"
2020.socialnlp-1.8,K18-2016,0,0.0216028,"rchitecture. puts [x1 , . . . , xn ] are fed into the FE that outputs a context sensitive representation for each token, consisting of a single biLSTMs layer which iteratively passes through the sentence in both directions. Finally, Cl consists of a fully-connected layer (denoted Ψ) that classifies every given xi following: yˆwi = (C ◦ FE ◦ WRE)(wi ). 3.2 Hierarchical Multi-Task Architecture (1) Dependency Parsing Architecture For the DP branch, a similar procedure is applied, except that, compared to previous tasks, DP is a a harder problem and thus requires a more complex model. We followed Qi et al. (2018) and used their “neural arc-factored graph-based dependency parser”, which is based on the “Deep biAffine parser” (Dozat and Manning, 2016)). Indeed, given an input sentence of n successive tokens [w1 , . . . , wn ], the goal of DP is two folds: 1) identifying, for each wi , its head wj ∈ S. The couple of tokens wi and wj are called the dependent and the head, respectively. Then, 2) predicting the dependency syntactic relation’s class rji ∈ Rdp relating each dependent-head pair, where Rdp being the dependency-relations set. More precisely, for each token wi we predict its out-going labelled ar"
2020.socialnlp-1.8,D11-1141,0,0.00924657,"Statistics of the datasets we used to train our multi-task learning models. Top: datasets of the source domain (called “EnglishAll”). Bottom: datasets of the target domain (called “TweetAll”). NER (Sang and De Meulder, 2003); CONLL2000 (Sang et al., 2000) for CK; and finally UD-EnglishEWT (Nivre et al., 2016) for DP. In the same vein, for the target-datasets, we used the Tweets domain and the following datasets: the recent TweeBank (Liu et al., 2018) for POS, annotated with the PTB universal tag-set; WNUT-17 from emerging entity detection shared task (Derczynski et al., 2017) for NER; TChunk (Ritter et al., 2011) for CK; and the data annotated with Universal dependency relations in the TweeBank dataset for DP1 . Detailed statistics of all the datasets are summarised in Table 1. To evaluate our models, we use the accuracy (acc) for POS, Exact-match F12 (Li et al., 2020) for NER and CK and labelled attachment score (LAS) (Nivre et al., 2004). 5.2 of a CNNs-based character-level representations followed by a 2-layer LSTMs. Thus, ELMo with the randomly initialised FE and Cl are further trained on the target-domain tasks. Specifically, we run experiments with two ELMo models: 1) ELMosmall : the small pre-t"
2020.socialnlp-1.8,N19-5004,0,0.0246369,"four exits, one per task. Also, as the tasks are hierarchically related to each other, we adopted a hierarchical architecture (similar to Hashimoto et al. (2017) and Sanh et al. (2019)). More specifically, we organised the four tasks from low-level to high-level, with each task being fed with a shared word embedding as well as the outputs of all the lower tasks. To construct that hierarchy of tasks, we followed some linguistic hints from the literature. Indeed, many works have shown that POS improves CK (Yang et al., 2017; Ruder12 et al., 2019); NER benefits from POS (Meftah and Semmar, 2018; Ruder, 2019) and CK (Collobert and Weston, 2008); and DP profits from POS and CK (Hashimoto et al., 2017). In simple terms, POS and CK are considered as “universal helpers” (Changpinyo et al., 2018). Thus, based on these linguistic hierarchy observations, we feed POS features to CK; then POS and CK features to both NER and DP. An illustration of our multi-task hierarchical model is given in Fig.1. More specifically, WRE is shared across all tasks, its output (namely xi = WREshared (wi )) is fed to all branches. The lower component of the POS tagging branch (FEpos ) is fed with the shared embedding and aft"
2020.socialnlp-1.8,W03-0419,0,0.582383,"Missing"
2020.socialnlp-1.8,W00-0726,0,0.147912,"cc. Top-1 Exact-match F1. Top-1 Exact-match F1. Top-1 LAS. Top-1 Acc. Top-1 Exact-match F1. Top-1 Exact-match F1. Top-1 LAS. Splits (train - val - test) 912,344 - 131,768 - 129,654 211,727 - n/a - 47,377 203,621 - 51,362 - 46,435 204,585 - 25,148 - 25,096 24,753 - 11,742 - 19,112 10,652 - 2,242 - 2,291 62,729 - 15,734 - 23,394 24,753 - 11,742 - 19,112 Table 1: Statistics of the datasets we used to train our multi-task learning models. Top: datasets of the source domain (called “EnglishAll”). Bottom: datasets of the target domain (called “TweetAll”). NER (Sang and De Meulder, 2003); CONLL2000 (Sang et al., 2000) for CK; and finally UD-EnglishEWT (Nivre et al., 2016) for DP. In the same vein, for the target-datasets, we used the Tweets domain and the following datasets: the recent TweeBank (Liu et al., 2018) for POS, annotated with the PTB universal tag-set; WNUT-17 from emerging entity detection shared task (Derczynski et al., 2017) for NER; TChunk (Ritter et al., 2011) for CK; and the data annotated with Universal dependency relations in the TweeBank dataset for DP1 . Detailed statistics of all the datasets are summarised in Table 1. To evaluate our models, we use the accuracy (acc) for POS, Exact-m"
2020.socialnlp-1.8,P16-2038,0,0.0228586,"sed variable schedules that increasingly favour the principal task over batches and Jean et al. (2018) proposed adaptive schedules that vary according to the validation performance of each task during training. Multi-Task Pretraining and Fine-tuning: Multitask pretraining has been especially explored for learning universal representations (Conneau et al., 2017; Ahmad et al., 2018). Multi-task fine-tuning was recently explored to fine-tune BERT pretrained model in a multi-task fashion on multiple tasks (Liu et al., 2019). Furthermore, in term of using multi-task features for domain adaptation, Søgaard and Goldberg (2016) showed the benefit of multi-task learning for domain adaptation from News-domain to Weblogs-domain for CK task, when disposing CK’s supervision only for the source-domain, and lower-level POS supervision for the target-domain. Finally, in terms of unifying multi-task learning and fine-tuning, Kiperwasser and Ballesteros (2018) proposed to improve machine translation with the help of POS and DEP tasks by scheduling tasks during training, starting with multi-tasking of the principal task with auxiliary lower-level tasks (POS and DEP), and as the training graduates, the model trains only to the"
2020.socialnlp-1.8,C18-1327,0,0.0159704,"rocessing (training) order of examples from different tasks (datasets), also called Scheduling, is particularly studied in the literature. This could be implicit or explicit (Jean et al., 2018). The formal include, for instance, affecting different learning 3 3.1 Model Architecture Sequence Labelling Architecture Regarding the exact architecture of each task, POS, CK and NER tasks are Sequence Labelling (SL) tasks. Given an input sentence of n successive tokens [w1 , . . . , wn ], SL predicts the tag ci ∈ C of every wi , with C being the tag-set. We followed the literature (Ma and Hovy, 2016; Yang et al., 2018) and used a common SL architecture, including three main components: (i) a Word Representation Extractor (WRE), (ii) a Features Extractor (FE) and (iii) a Classifier (Cl). WRE computes, for each token wi , a word and a character-level biLSTMs encoderbased embeddings (respectively, wei =WE(wi ) and cei =CE(wi )), and concatenates them to get a final representation xi =(wei ,cei ). WRE’s out62 producing four distinct vectors for representing the word: (i) as a dependent seeking its head; (ii), as a head seeking all its dependants; (iii), as a dependent deciding on its relation; and (iv), as a he"
2020.socialnlp-1.8,P18-2104,0,0.06227,"ined. We successively pick all the tasks following a constant ordering strategy “from lowerlevel to higher-level tasks” (Hashimoto et al., 2017): POS then CK then NER then DP. Thus, every 4 steps, the model sees all the tasks once and learns their corresponding parameters once. 4.2.2 Datasets Unification As mentioned in the previous section, we mostly face the heterogeneous multi-task learning scenario, where only one task-labels might be assigned to a dataset. In that case, the classical multi-task learning approach is not directly applicable, thus we propose to use the “Scheduling process” (Zaremoodi et al., 2018; Lu et al., 2019) (described in the following paragraph). However, since training with different datasets for each task remains difficult (Subramanian et al., 2018) ) we proposed “Dataset Unification” a much simpler and easy to learn method for that scenario. To overcome the intricacy of “tasks scheduling process”, we propose to construct a unified dataset by combining several sources of independent textual annotations. Furthermore, since we are interested in benefiting from pretraining and fine-tuning, we apply unification process on both, source and targetdomains. These datasets contain sam"
2020.wildre-1.6,Q17-1026,0,0.0488216,"Missing"
2020.wildre-1.6,N19-4009,0,0.0464301,"Missing"
2020.wildre-1.6,W18-6319,0,0.018088,"ns:High along with Forward, Backward & Self. Parameters and training procedures are set as in Johnson et al.(2017). PyTorch Sequence-to-Sequence library, fairseq (Ott et al., 2019), was used to run the experiments. Table 1 shows that Multilingual+ consistently outperforms the others. The table also confirms that the more augmentations you add to the Multilingual NMT model (Johnson et al., 2017), the more it improves. Adding Backward, then Self and then a new language pair improved the results at each level. All the BLEU scores reported, except star (∗ ) marked, are calculated using SacreBLEU (Post, 2018) on the development set provided. 6. Comparisons We compared our results with other models submitted at the LoResMT Shared Task at the MT Summit 2019. The submission to the Shared Task followed a naming convention to distinguish between different types of corpora used, which we will follow too. The different types of corpora and their abbreviations are as follows: 7. Conclusion and Future Work We have presented a simple data augmentation technique coupled with a multilingual transformer that gives a jump of 15 points in BLEU score without any new data and 20 points in BLEU score if a rich reso"
2020.wildre-1.6,P16-1009,0,0.479381,"as the pivot language and feed the target language token to the decoder instead of the encoder. In order to improve the independence of encoder on source language they maximise the similarity between all sentence vectors and their English parallel sentence embeddings and minimize the translation cross-entropy loss. They use a discriminator and train the encoder adversarially for similarity maximisation. Artetxe et al.(2018) and Yang et al.(2018) also train the encoder adversarially to learn a shared latent space. There has been a lot of work done to improve NMT models using data augmentation. Sennrich et al (2016a) proposed automatic back-translation to augment the dataset. But, as mentioned in SwitchOut (Wang et al., 2018) faces challenges in initial models. Fadaee et al.(2017) propose 29 Figure 1: An example of different augments. Here the low resource pair of languages is English–Hindi, and the high resource pair language set is English–French a data augmentation technique where they synthesise new data by replacing a common word in the source sentence with a rare word and the corresponding word in the target sentence with its translation. And to maintain the syntactic validity of the sentence, the"
2020.wildre-1.6,P16-1162,0,0.802028,"as the pivot language and feed the target language token to the decoder instead of the encoder. In order to improve the independence of encoder on source language they maximise the similarity between all sentence vectors and their English parallel sentence embeddings and minimize the translation cross-entropy loss. They use a discriminator and train the encoder adversarially for similarity maximisation. Artetxe et al.(2018) and Yang et al.(2018) also train the encoder adversarially to learn a shared latent space. There has been a lot of work done to improve NMT models using data augmentation. Sennrich et al (2016a) proposed automatic back-translation to augment the dataset. But, as mentioned in SwitchOut (Wang et al., 2018) faces challenges in initial models. Fadaee et al.(2017) propose 29 Figure 1: An example of different augments. Here the low resource pair of languages is English–Hindi, and the high resource pair language set is English–French a data augmentation technique where they synthesise new data by replacing a common word in the source sentence with a rare word and the corresponding word in the target sentence with its translation. And to maintain the syntactic validity of the sentence, the"
2020.wildre-1.6,D18-1100,0,0.03532,"Missing"
2020.wildre-1.6,P18-1005,0,0.0411852,"Missing"
2020.wildre-1.6,1983.tc-1.13,0,0.475403,"Missing"
2020.wildre-1.6,D14-1179,0,0.0151358,"Missing"
2020.wildre-1.6,P15-1166,0,0.115174,"Missing"
2020.wildre-1.6,P17-2090,0,0.0335579,"Missing"
2020.wildre-1.6,N16-1101,0,0.0517947,"Missing"
2020.wildre-1.6,Q17-1024,0,0.0728392,"Missing"
2021.adaptnlp-1.14,W17-4418,0,0.0493384,"Missing"
2021.adaptnlp-1.14,D18-1275,0,0.0345414,"Missing"
2021.adaptnlp-1.14,D17-1256,0,0.0185638,"et al., 2018; Chen et al., 2019; Wang et al., 2019; O’Neill, 2019) that, when source and target domains are less related (e.g. languages from different families), sequential transfer learning may lead to a negative effect on the performance, instead of improving it. This phenomenon is referred to as negative transfer. Precisely, negative transfer is considered when transfer learning is harmful for the target task/dataset, i.e. the performance when using transfer learning algorithm is lower than that with a solely supervised training on in-target data (Torrey and Shavlik, 2010). Several works (Gui et al., 2017, 2018b; Meftah et al., 2018a,b; M¨arz et al., 2019) have shown that sequential transfer learning from the News resource-rich domain to the Tweets low-resource domain enhances the performance of sequence labelling of Tweets. Hence, following the above definition of negative transfer, transfer learning from News to Tweets does not beget a negative transfer. Contrariwise, in this work, we rather consider the hidden negative transfer, i.e. the percentage of predictions which were correctly tagged by random initialisation, but using transfer learning falsified. In this work, we take a step towards"
2021.adaptnlp-1.14,N18-1088,0,0.0173792,"rce model, while the second set of parameters (Ψ) of the target model is randomly initialised. Then, 3) the target model is further fine-tuned on the small target data-set. 4 Experimental Settings 4.1 Data-sets We conduct experiments on TL from English News (source-domain) to English Tweets (target-domain) on three tasks (Datasets statistics are given in Table.1): • POS tagging: we use the Wall Street Journal (WSJ) part of Penn-Tree-Bank (PTB) as a source-dataset. Regarding the target-datasets, we used three Tweets datasets: TPoS (Ritter et al., 2011), ARK (Owoputi et al., 2013) and TweeBank (Liu et al., 2018). • CK: for the source dataset, we use the CONLL2000 shared task’s English data-set (Tjong Kim Sang and Buchholz, 2000). Regarding the target dataset, we use TChunk Tweets data-set (Ritter et al., 2011) (the same corpus as TPoS). • NER: regarding the source domain, we make use of the English newswire dataset CONLL03 from the CONLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003). target domain, we conduct our experiments on WNUT2017 dataset (Derczynski et al., 2017). 4.2 Implementation Details In the standard word-level embeddings, tokens are converted to lower-case while the character-l"
2021.adaptnlp-1.14,N19-1345,0,0.0626851,"Missing"
2021.adaptnlp-1.14,L18-1446,1,0.833194,", 2019; Wang et al., 2019; O’Neill, 2019) that, when source and target domains are less related (e.g. languages from different families), sequential transfer learning may lead to a negative effect on the performance, instead of improving it. This phenomenon is referred to as negative transfer. Precisely, negative transfer is considered when transfer learning is harmful for the target task/dataset, i.e. the performance when using transfer learning algorithm is lower than that with a solely supervised training on in-target data (Torrey and Shavlik, 2010). Several works (Gui et al., 2017, 2018b; Meftah et al., 2018a,b; M¨arz et al., 2019) have shown that sequential transfer learning from the News resource-rich domain to the Tweets low-resource domain enhances the performance of sequence labelling of Tweets. Hence, following the above definition of negative transfer, transfer learning from News to Tweets does not beget a negative transfer. Contrariwise, in this work, we rather consider the hidden negative transfer, i.e. the percentage of predictions which were correctly tagged by random initialisation, but using transfer learning falsified. In this work, we take a step towards identifying and analysing t"
2021.adaptnlp-1.14,W18-3927,1,0.829422,", 2019; Wang et al., 2019; O’Neill, 2019) that, when source and target domains are less related (e.g. languages from different families), sequential transfer learning may lead to a negative effect on the performance, instead of improving it. This phenomenon is referred to as negative transfer. Precisely, negative transfer is considered when transfer learning is harmful for the target task/dataset, i.e. the performance when using transfer learning algorithm is lower than that with a solely supervised training on in-target data (Torrey and Shavlik, 2010). Several works (Gui et al., 2017, 2018b; Meftah et al., 2018a,b; M¨arz et al., 2019) have shown that sequential transfer learning from the News resource-rich domain to the Tweets low-resource domain enhances the performance of sequence labelling of Tweets. Hence, following the above definition of negative transfer, transfer learning from News to Tweets does not beget a negative transfer. Contrariwise, in this work, we rather consider the hidden negative transfer, i.e. the percentage of predictions which were correctly tagged by random initialisation, but using transfer learning falsified. In this work, we take a step towards identifying and analysing t"
2021.adaptnlp-1.14,N13-1039,0,0.064314,"Missing"
2021.adaptnlp-1.14,D14-1162,0,0.0818445,"WNUT2017 dataset (Derczynski et al., 2017). 4.2 Implementation Details In the standard word-level embeddings, tokens are converted to lower-case while the character-level component still retains access to the capitalisation information. We set the randomly initialised character embedding dimension at 50, the dimension of hidden states of the character-level biLSTM at 100 and used 300-dimensional word-level embeddings. Word-level embeddings were pre-loaded from publicly available GloVe vectors pre-trained on 42 billions words collected through web crawling and containing 1.9M different words (Pennington et al., 2014). These embeddings are also updated during training. For the FE component, we 141 Task POS: POS Tagging CK: Chunking NER: Named Entity Recognition POS: POS Tagging CK: Chunking NER: Named Entity Recognition Classes 36 22 4 17 18 6 Sources WSJ CONLL-2000 CONLL-2003 TweeBank TChunk WNUT Eval. Metrics Top-1 Acc. Top-1 Exact-match F1. Top-1 Exact-match F1. Top-1 Acc. Top-1 Exact-match F1. Top-1 Exact-match F1. Splits (train - val - test) 912,344 - 131,768 - 129,654 211,727 - n/a - 47,377 203,621 - 51,362 - 46,435 24,753 - 11,742 - 19,112 10,652 - 2,242 - 2,291 62,729 - 15,734 - 23,394 Table 1: Sta"
2021.adaptnlp-1.14,D11-1141,0,0.1434,"Missing"
2021.adaptnlp-1.14,N19-5004,0,0.0269228,"-art neural models on News (formal texts). The last few years have witnessed an escalated interest in studying Transfer Learning (TL) for neural networks to overcome the problem of the lack of annotated data. TL aims at performing a task on a target dataset using features learned from a source dataset (Pan and Yang, 2009). TL has been proven to be effective for a wide range of applications (Zamir et al., 2018; Long et al., 2015; Moon and Carbonell, 2017), especially for low-resourced domains. However, it has been shown in many works in the literature (Rosenstein et al., 2005; Ge et al., 2014; Ruder, 2019; Gui et al., 2018a; Cao et al., 2018; Chen et al., 2019; Wang et al., 2019; O’Neill, 2019) that, when source and target domains are less related (e.g. languages from different families), sequential transfer learning may lead to a negative effect on the performance, instead of improving it. This phenomenon is referred to as negative transfer. Precisely, negative transfer is considered when transfer learning is harmful for the target task/dataset, i.e. the performance when using transfer learning algorithm is lower than that with a solely supervised training on in-target data (Torrey and Shavli"
2021.adaptnlp-1.14,W00-0726,0,0.338545,"et model is further fine-tuned on the small target data-set. 4 Experimental Settings 4.1 Data-sets We conduct experiments on TL from English News (source-domain) to English Tweets (target-domain) on three tasks (Datasets statistics are given in Table.1): • POS tagging: we use the Wall Street Journal (WSJ) part of Penn-Tree-Bank (PTB) as a source-dataset. Regarding the target-datasets, we used three Tweets datasets: TPoS (Ritter et al., 2011), ARK (Owoputi et al., 2013) and TweeBank (Liu et al., 2018). • CK: for the source dataset, we use the CONLL2000 shared task’s English data-set (Tjong Kim Sang and Buchholz, 2000). Regarding the target dataset, we use TChunk Tweets data-set (Ritter et al., 2011) (the same corpus as TPoS). • NER: regarding the source domain, we make use of the English newswire dataset CONLL03 from the CONLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003). target domain, we conduct our experiments on WNUT2017 dataset (Derczynski et al., 2017). 4.2 Implementation Details In the standard word-level embeddings, tokens are converted to lower-case while the character-level component still retains access to the capitalisation information. We set the randomly initialised character embedd"
2021.adaptnlp-1.14,W03-0419,0,0.170561,"Missing"
2021.americasnlp-1.17,2020.lrec-1.879,0,0.0611976,"Missing"
2021.americasnlp-1.17,W19-4222,0,0.0237689,"gmented words, more than 50K words, with the sequence length between three letters and 30 letters. We collected manually a small corpus from several resources such as the Website of Nunavut2 government for Inuinnaqtun, open source dictionaries and grammar books (Lowe, 1985; Kudlak and Compton, 2018). The experimental corpus contains 190 word bases and 571 affixes. A small golden testing set is manually crafted containing 1,055 unique segmented words. 3 4.2 Our approach 4 4.1 Experiments Data Preparation Training Settings We used the MorphAGram toolkit (Eskander et al., Inspired by the work of Eskander et al. (2019), we 2020) to train our unsupervised morphological adapt an unsupervised morphological segmentation segmentation model. Following (Eskander et al., with the Adaptor Grammars (AG) approach for the 2019), we set up the same configuration with Inuit language family, by completing an empirical adaptation of the best learning settings: the best study on Inuinnaqtun. standard PrefixStemSuffix+SuffixMorph grammar The main process consists of defining (1) the and the best scholar-seeded grammar, that become grammar including non-terminal, terminal symhere an adaptation of the standard grammar Wordbols"
2021.americasnlp-1.17,W18-5808,0,0.0352194,"Missing"
2021.americasnlp-1.17,W18-5804,0,0.0366001,"Missing"
2021.americasnlp-1.17,W08-0704,0,0.0596666,"formative elements. A single Mager et al., 2018; Micher, 2019; Le Ngoc and word can express the meaning of a whole sentence. Sadat, 2020). Moreover, morphology is highly developed and Herein, we propose an unsupervised morpho- has extensive use of lexical and grammatical endlogical segmentation approach, which is primar- ing suffixes. All these linguistic aspects make the ily based on the grammar containing production morphological segmentation task for polysynthetic rules, non-terminal and terminal symbols, and a languages more challenging. On the other hand, lexicon using Adaptor Grammars (Johnson, 2008). the benefit of this work helps to identify more unOur current research investigates Inuinnaqtun - a known word bases by deducting from the known polysynthetic language spoken in Northern Canada, affixes, which in turn helps to enrich the Inuinin the Inuit language family. Inuinnaqtun is consid- naqtun lexicon. The global contribution consists ered as a language that will be extinct in less than of helping to revitalize and preserve low-resource two generations1 . Indigenous languages and the transmission of the Regarding the Eskimo-Aleut language family related ancestral knowledge and cultur"
2021.americasnlp-1.17,N18-1005,0,0.0437207,"Missing"
2021.americasnlp-1.17,2020.coling-main.410,1,0.797577,"Missing"
2021.americasnlp-1.17,C18-1222,0,0.0141727,"uch as isolatmuskox - hunt - go in order to - partner - have ing, inflectional or agglutinative language families. as - again - will no more - I-him However, Indigenous polysynthetic languages still (Meaning: I will no more again have him as a pose several challenges within NLP tasks and applications, such as morphological analysis or ma- partner to go hunting muskox.) chine translation, due to their complex linguistic We observe there is a general tendency to inparticularities and due to the scarcity of linguistic crease the lexical constituents with a word-base resources and reliable tools (Littell et al., 2018; by adding more formative elements. A single Mager et al., 2018; Micher, 2019; Le Ngoc and word can express the meaning of a whole sentence. Sadat, 2020). Moreover, morphology is highly developed and Herein, we propose an unsupervised morpho- has extensive use of lexical and grammatical endlogical segmentation approach, which is primar- ing suffixes. All these linguistic aspects make the ily based on the grammar containing production morphological segmentation task for polysynthetic rules, non-terminal and terminal symbols, and a languages more challenging. On the other hand, lexicon using Ad"
2021.americasnlp-1.17,C18-1006,0,0.0191893,"inflectional or agglutinative language families. as - again - will no more - I-him However, Indigenous polysynthetic languages still (Meaning: I will no more again have him as a pose several challenges within NLP tasks and applications, such as morphological analysis or ma- partner to go hunting muskox.) chine translation, due to their complex linguistic We observe there is a general tendency to inparticularities and due to the scarcity of linguistic crease the lexical constituents with a word-base resources and reliable tools (Littell et al., 2018; by adding more formative elements. A single Mager et al., 2018; Micher, 2019; Le Ngoc and word can express the meaning of a whole sentence. Sadat, 2020). Moreover, morphology is highly developed and Herein, we propose an unsupervised morpho- has extensive use of lexical and grammatical endlogical segmentation approach, which is primar- ing suffixes. All these linguistic aspects make the ily based on the grammar containing production morphological segmentation task for polysynthetic rules, non-terminal and terminal symbols, and a languages more challenging. On the other hand, lexicon using Adaptor Grammars (Johnson, 2008). the benefit of this work helps t"
2021.americasnlp-1.17,Q13-1021,0,0.053496,"Missing"
2021.jeptalnrecital-taln.29,2020.coling-main.410,1,0.769375,"Missing"
C02-1166,J93-1003,0,0.0919303,"et word, which aim at capturing the most significant collocates. The target context vectors are then translated using a general bilingual dictionary, and compared with the source context vectors. Our implementation of this strategy relies on the following steps, and follows the one given in (Rapp, 1999): - for each word w, build a context vector by considering all the words occurring in a window encompassing several sentences that is run through the corpus. Each word i in the context vector of w is then weighted with a measure of its association with w. We chose the loglikelihood ratio test, (Dunning, 1993), to measure this association - the context vectors of the target words are then translated with our general bilingual dictionary, leaving the weights unchanged (when several translations are proposed by the dictionary, we consider all of them with the same weight) - the similarity of each source word s, for each target word t, is computed on the basis of the cosine measure - the similarities are then normalized to yield a probabilistic translation lexicon, P(t|s). To illustrate the above steps, we give here the first 5 words of the context vector of the German word Leber (liver), together wit"
C02-1166,P99-1067,0,0.560093,"Headings, MeSH, provided through the metathesaurus Unified Medical Language System, UMLS2). Without anticipating too much on the linguistic preprocessing we use, it has to be noted that, unless otherwise stated, when we speak of a “word” we refer to a single (as opposed to compound), lexical word (as opposed to stop word). All our examples and experiments use the (German, English) language pair. 1 Context vectors: a basic building block Bilingual lexicon extraction from non-parallel but comparable corpora has been studied by a number of researchers, (Peters, 1995; Tanaka, 1996; Shahzad 1999; Rapp, 1999; Fung, 2000) among others. Their work relies on the assumption that if two words are mutual 1 2 http://www.icp.grenet.fr/ELRA/home.html http://www.nlm.nih.gov/mesh/meshhome.html translations, then their more frequent collocates (taken here in a very broad sense) are likely to be mutual translations as well. Based on this assumption, a standard approach consists in building context vectors, for each source and target word, which aim at capturing the most significant collocates. The target context vectors are then translated using a general bilingual dictionary, and compared with the source con"
C02-1166,C96-2098,0,0.0642267,"Missing"
L18-1698,W16-5320,1,0.937492,"OWL, they cannot be immediately connected to the Semantic Web. Moreover, the information about LFs is only textual. This means that we do not have, for example, the following information: • How complex LFs are formed from simple LFs. For example, that the LF AntiM agn is composed from the LFs Anti and M agn; • How an LF like Oper1 is related to the LFs Real1 or F unc1 through the first actant (represented by the index 1); • Information about the semantic perspective of a lexical function (presented in the next section); For this reason, we have developed a metalinguistic model called lexfom5 (Fonseca et al., 2016a), which is presented in §2.4., to represent the characteristics of LFs and we have applied this model in the transformation of the FLN into an RDF/OWL format6 . 2.2. Semantic perspective for lexical functions Jousse (2010) presents four different classifications for LFs: a semantic, a pragmatic, a combinatorial and a syntactic classification. These classifications are called “perspectives”. In this paper, we are interested in the semantic perspective (SP). The SP is comprised of ten classes: action/event, causativity, element/set, equivalence, location, opposition, participants, phase/aspect"
L18-1698,W17-1703,0,0.0445307,"Missing"
L18-1698,francopoulo-etal-2006-lexical,0,0.0501584,". For example, the class qualification is sub-divided into intensity (e.g. Magn (shave) = {close}), positive evaluation (e.g. Bon (contribution) = {valuable}), and negative evaluation (e.g. AntiBon1 Involv (car) = {smash into N}, where N represents a noun). Finally, the lexical relation between lexemes modeled by a specific LF can be classified in the same way. 2.3. of the Max Planck Institute.8 Its aim is to define grammatical categories, such as transitive and intransitive verbs, part of speech, predicate, etc. Another important metalinguistic ontology is the Lexical Markup Framework (LMF) (Francopoulo et al., 2006). LMF is an ISO project that started in 2005 and was first published in 2007. Its aim is to be a common standard in the development of dictionaries for the Semantic Web. It is designed to represent morphological, syntactic and semantic information. Some other metalinguistic ontologies were developed after LMF, leading to the publishing of a new W3C standard in 2016, called lexicon model for ontologies (lemon).9 Lemon is based in previous models, such as LMF, ISOCat, LexInfo,10 etc. Lemon’s main modules are the following: Ontologylexicon interface (ontolex), Syntax and Semantics (synsem), Decom"
N06-2013,P05-1071,1,0.411395,"Missing"
N06-2013,koen-2004-pharaoh,0,0.0322123,"Missing"
N06-2013,W04-3250,0,0.121742,"Missing"
N06-2013,N04-4015,0,0.472245,"2004); Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied 2 We conducted several additional experiments that we do not report on here for lack of space but we reserve for a separate technical report. 49 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 49–52, c New York, June 2006. 2006 Association for Computational Linguistics the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering Arabic, Lee (2004) investigated the use of automatic alignment of POS tagged English and affix-stem segmented Arabic to determine appropriate tokenizations. Her results show that morphological preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic, by studying the effect of morphological disambiguation (beyond POS tagging) on preprocessing schemes over learning curves, and by"
N06-2013,P03-1021,0,0.0968139,"Missing"
N06-2013,2001.mtsummit-papers.68,0,0.0435829,"Missing"
N06-2013,popovic-ney-2004-towards,0,0.170018,"Missing"
N06-2013,J04-2003,0,0.0866808,"ackground on Arabic linguistics to motivate the schemes discussed in Section 4. Section 5 presents the tools and data sets used, along with the results of our experiments. Section 6 contains a discussion of the results. 2 Previous Work The anecdotal intuition in the field is that reduction of word sparsity often improves translation quality. This reduction can be achieved by increasing training data or via morphologically driven preprocessing (Goldwater and McClosky, 2005). Recent publications on the effect of morphology on SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied 2 We conducted several additional experiments that we do not report on here for lack of space but we reserve for a separate technical report. 49 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 49–52, c New York, June 2006. 2006 Association for Computational Linguistics the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering Arabic, Lee ("
N06-2013,W05-0822,1,0.704448,"). D2 splits off the class of particles (l+, k+, b+ and s+) beyond D1. Finally D3 splits off what D2 does in addition to the definite article (Al+) and all pronominal clitics. MR: Morphemes. This scheme breaks up words into stem and affixival morphemes. EN: English-like. This scheme is intended to minimize differences between Arabic and English. It decliticizes similarly to D3; however, it uses lexeme and English-like POS tags instead of the regenerated word and it indicates the pro-dropped verb subject explicitly as a separate token. 5 Experiments We use the phrase-based SMT system, Portage (Sadat et al., 2005). For training, Portage uses IBM word alignment models (models 1 and 2) trained 51 bzyArp with visit AlY to trkyA. Turkey . bzyArp bzyArp b+ zyArp b+ zyArp b+ zyAr +p b+ zyArp  AlY  lY  lY  lY  lY  lY  trkyA trkyA trkyA trkyA trkyA trkyA   . . . . . . in both directions to extract phrase tables. Maximum phrase size used is 8. Trigram language models are implemented using the SRILM toolkit (Stolcke, 2002). Decoding weights are optimized using Och’s algorithm (Och, 2003) to set weights for the four components of the log-linear model: language model, phrase translation model, distortion"
N06-2013,P02-1040,0,\N,Missing
N06-2013,H05-1085,0,\N,Missing
N19-1416,R13-1026,0,0.0293853,"assess the POS tagging performances of our PretRand model, we compared it to 5 baselines: Random-200 and Random-400: randomly initialised neural model with 200 and 400 biLSTM’s units; Fine-tuning: pre-trained neural model, fine-tuned with the standard scheme; Ensemble (2 rand): averaging the predictions of two base models randomly initialised and learned independently (with different random initialisation) on Tweets datasets; and Ensemble (1 pret + 1 rand): same as the previous but with one pre-trained on WSJ and the other randomly initialised. We also compared it to the 3 best SOTA methods: Derczynski et al. (2013) (GATE) is a model based on HMMs with a set of normalisation rules, external dictionaries and lexical features. They experiment it on TPoS, with WSJ and 32K tokens from the NPS IRC corpus. They also used 1.5M additional training tokens annotated by vote-constrained bootstrapping (GATEbootstrap). Owoputi et al. (2013) proposed a model based on first-order Maximum Entropy 4109 Method #params GATE (Derczynski et al., 2013) GATE-bootstrap (Derczynski et al., 2013) ARK (Owoputi et al., 2013) TPANN (Gui et al., 2017) Random-200 Random-400 Standard fine-tuning Ensemble Model (2 rand) Ensemble Model ("
N19-1416,D17-1256,0,0.455903,"Missing"
N19-1416,N18-1088,0,0.315089,"ation, we used `2 -norm. Finally, in all experiments, training was performed using SGD with momentum and mini-batches of 8 sentences. Evidently, all the hyperparameters have been cross-validated. 3.2 Datasets For the source-dataset, we used the Wall Street Journal (WSJ) part of Penn-Tree-Bank (PTB), a large English dataset containing 1.2M+ tokens from the newswire domain annotated with the PTB tag-set. Regarding the target-datasets, we used three Tweets datasets: TPoS (Ritter et al., 2011), annotated with 40 tags ; ARK (Owoputi et al., 2013) containing 25 coarse tags; and the recent TweeBank (Liu et al., 2018) containing 17 tags (PTB universal tag-set). The number of tokens in the datasets are given in Table 1. 3.3 Comparison Methods To assess the POS tagging performances of our PretRand model, we compared it to 5 baselines: Random-200 and Random-400: randomly initialised neural model with 200 and 400 biLSTM’s units; Fine-tuning: pre-trained neural model, fine-tuned with the standard scheme; Ensemble (2 rand): averaging the predictions of two base models randomly initialised and learned independently (with different random initialisation) on Tweets datasets; and Ensemble (1 pret + 1 rand): same as"
N19-1416,L18-1446,1,0.893228,"n POS tagging of social media texts (Tweets domain) demonstrate that our method achieves state-of-the-art performances on 3 commonly used datasets. 1 Introduction POS tagging is a sequence labelling problem, that consists on assigning to each sentence’ word, its disambiguated POS tag (e.g., Pronoun, Noun) in the phrasal context in which the word is used. Such information is useful for higher-level applications, such as machine-translation (Niehues and Cho, 2017) or cross-lingual information retrieval (Semmar et al., 2006, 2008). One of the best approaches for POS tagging of social media text (Meftah et al., 2018a), is transfer-learning, which relies on a neuralnetwork learned on a source-dataset with sufficient annotated data, then further adapted to the problem of interest (target-dataset). While this approach is known to be very effective (Zennaki et al., 2019), because it takes benefit from pre-trained neurons, it has one main drawback by design. Indeed, it has been shown in computervision (Zhou et al., 2018a) that, when fine-tuning on scenes a model pre-trained on objects, it is the neuron firing on the white dog object that became highly sensitive to the white waterfall scene. Simply said, pre-t"
N19-1416,W18-3927,1,0.68001,"n POS tagging of social media texts (Tweets domain) demonstrate that our method achieves state-of-the-art performances on 3 commonly used datasets. 1 Introduction POS tagging is a sequence labelling problem, that consists on assigning to each sentence’ word, its disambiguated POS tag (e.g., Pronoun, Noun) in the phrasal context in which the word is used. Such information is useful for higher-level applications, such as machine-translation (Niehues and Cho, 2017) or cross-lingual information retrieval (Semmar et al., 2006, 2008). One of the best approaches for POS tagging of social media text (Meftah et al., 2018a), is transfer-learning, which relies on a neuralnetwork learned on a source-dataset with sufficient annotated data, then further adapted to the problem of interest (target-dataset). While this approach is known to be very effective (Zennaki et al., 2019), because it takes benefit from pre-trained neurons, it has one main drawback by design. Indeed, it has been shown in computervision (Zhou et al., 2018a) that, when fine-tuning on scenes a model pre-trained on objects, it is the neuron firing on the white dog object that became highly sensitive to the white waterfall scene. Simply said, pre-t"
N19-1416,D16-1046,0,0.057989,"by minimising a Softmax CrossEntropy (SCE) loss using the SGD algorithm. 2.2 Adding Random Branch As mentioned in the introduction, pre-trained neurons are biased by design, thus limited. This motivated our proposal to augment the pre-trained branch with additional random units (as illustrated in Fig. 1). To do so, theoretically one can add the new units in any layer of the base model. However in practice, we have to make a trade-off between performances and the number of parameters (model complexity). Thus, given that deep layers are more task-specific than shallow ones (Peters et al., 2018; Mou et al., 2016), and that word embeddings (shallow layers) contain the majority of parameters, we choose to expand only the top layers. With this choice, we desirably increase the complexity of the model only by 1.02× compared to the base one. In terms of the layers expanded, we specifically add k units to Φ resulting in an extra biLSTM layer: Φr (r for rand); and C units in Ψ resulting in an extra FC layer: Ψr . Hence, for every wi , the additional random branch predicts r = Ψ ◦ Φ (x ) class-probabilities following: yˆw r r i i (with xi = Υ(wi )). Note that, having two FC layers obviously outputs two predic"
N19-1416,W17-4708,0,0.0296247,"k with normalised, weighted and randomly initialised units that beget a better adaptation while maintaining the valuable source knowledge. Our experiments on POS tagging of social media texts (Tweets domain) demonstrate that our method achieves state-of-the-art performances on 3 commonly used datasets. 1 Introduction POS tagging is a sequence labelling problem, that consists on assigning to each sentence’ word, its disambiguated POS tag (e.g., Pronoun, Noun) in the phrasal context in which the word is used. Such information is useful for higher-level applications, such as machine-translation (Niehues and Cho, 2017) or cross-lingual information retrieval (Semmar et al., 2006, 2008). One of the best approaches for POS tagging of social media text (Meftah et al., 2018a), is transfer-learning, which relies on a neuralnetwork learned on a source-dataset with sufficient annotated data, then further adapted to the problem of interest (target-dataset). While this approach is known to be very effective (Zennaki et al., 2019), because it takes benefit from pre-trained neurons, it has one main drawback by design. Indeed, it has been shown in computervision (Zhou et al., 2018a) that, when fine-tuning on scenes a mo"
N19-1416,N13-1039,0,0.124324,"Missing"
N19-1416,D14-1162,0,0.0820529,"y SGD. Formally, the final predictions are computed folp r ). lowing: yˆwi = u Np (ˆ yw yw i ) ⊕ v Np (ˆ i 3 Experiments 3.1 Implementation Details In the word-level embeddings, tokens are lowercased while the character-level component still retains access to the capitalisation information. We set the character embedding dimension at 50, the dimension of hidden states of the character-level biLSTM at 100 and used 300-dimensional wordlevel embeddings. The latter were pre-loaded from publicly available Glove pre-trained vectors on 42 billions words from a web crawling and containing 1.9M words (Pennington et al., 2014). Note that, these embeddings are also updated during fine-tuning. For biLSTM (token-level feature extractor), we set the number of units of the pretrained branch to 200 and experimented our approach with k added random-units, with k ∈ {50, 100, 150, 200}. For the normalisation, we used `2 -norm. Finally, in all experiments, training was performed using SGD with momentum and mini-batches of 8 sentences. Evidently, all the hyperparameters have been cross-validated. 3.2 Datasets For the source-dataset, we used the Wall Street Journal (WSJ) part of Penn-Tree-Bank (PTB), a large English dataset co"
N19-1416,N18-1202,0,0.0496107,"d on the target-task by minimising a Softmax CrossEntropy (SCE) loss using the SGD algorithm. 2.2 Adding Random Branch As mentioned in the introduction, pre-trained neurons are biased by design, thus limited. This motivated our proposal to augment the pre-trained branch with additional random units (as illustrated in Fig. 1). To do so, theoretically one can add the new units in any layer of the base model. However in practice, we have to make a trade-off between performances and the number of parameters (model complexity). Thus, given that deep layers are more task-specific than shallow ones (Peters et al., 2018; Mou et al., 2016), and that word embeddings (shallow layers) contain the majority of parameters, we choose to expand only the top layers. With this choice, we desirably increase the complexity of the model only by 1.02× compared to the base one. In terms of the layers expanded, we specifically add k units to Φ resulting in an extra biLSTM layer: Φr (r for rand); and C units in Ψ resulting in an extra FC layer: Ψr . Hence, for every wi , the additional random branch predicts r = Ψ ◦ Φ (x ) class-probabilities following: yˆw r r i i (with xi = Υ(wi )). Note that, having two FC layers obviously"
N19-1416,D11-1141,0,0.185039,"Missing"
N19-1416,semmar-etal-2006-deep,1,0.34182,"beget a better adaptation while maintaining the valuable source knowledge. Our experiments on POS tagging of social media texts (Tweets domain) demonstrate that our method achieves state-of-the-art performances on 3 commonly used datasets. 1 Introduction POS tagging is a sequence labelling problem, that consists on assigning to each sentence’ word, its disambiguated POS tag (e.g., Pronoun, Noun) in the phrasal context in which the word is used. Such information is useful for higher-level applications, such as machine-translation (Niehues and Cho, 2017) or cross-lingual information retrieval (Semmar et al., 2006, 2008). One of the best approaches for POS tagging of social media text (Meftah et al., 2018a), is transfer-learning, which relies on a neuralnetwork learned on a source-dataset with sufficient annotated data, then further adapted to the problem of interest (target-dataset). While this approach is known to be very effective (Zennaki et al., 2019), because it takes benefit from pre-trained neurons, it has one main drawback by design. Indeed, it has been shown in computervision (Zhou et al., 2018a) that, when fine-tuning on scenes a model pre-trained on objects, it is the neuron firing on the w"
P03-2025,W02-0902,0,0.0270886,"anslation model yields better translations and retrieval effectiveness could be achieved across JapaneseEnglish language pair. 1 Introduction Although, corpora have been an object of study of some decades, recent years saw an increased interest in their use and construction. With this increased interest and awareness has come an expansion in the application to knowledge acquisition, such as bilingual terminology. In addition, non-aligned comparable corpora have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dejean et al., 2002; Fung, 2000; Koehn and Knight, 2002; Rapp, 1999). This paper presents a novel approach to bilingual terminology acquisition and disambiguation from scarce resources such as comparable corpora, phrasal translation through re-scoring techniques as well as evaluations on Cross-Language Information Retrieval (CLIR). CLIR consists of retrieving documents written in one language using queries written in another language. An application is completed on a large-scale test collection, NTCIR for JapaneseEnglish language pair. 2 The Proposed Translation Model in CLIR Figure 1 shows the overall design of the proposed translation model in C"
P03-2025,P99-1067,0,0.378431,"etter translations and retrieval effectiveness could be achieved across JapaneseEnglish language pair. 1 Introduction Although, corpora have been an object of study of some decades, recent years saw an increased interest in their use and construction. With this increased interest and awareness has come an expansion in the application to knowledge acquisition, such as bilingual terminology. In addition, non-aligned comparable corpora have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dejean et al., 2002; Fung, 2000; Koehn and Knight, 2002; Rapp, 1999). This paper presents a novel approach to bilingual terminology acquisition and disambiguation from scarce resources such as comparable corpora, phrasal translation through re-scoring techniques as well as evaluations on Cross-Language Information Retrieval (CLIR). CLIR consists of retrieving documents written in one language using queries written in another language. An application is completed on a large-scale test collection, NTCIR for JapaneseEnglish language pair. 2 The Proposed Translation Model in CLIR Figure 1 shows the overall design of the proposed translation model in CLIR consistin"
P03-2025,W03-1108,1,0.897796,"Proposed Model for Bilingual Terminology Acquisition and Phrasal Translation in CLIR As well, a target language morphological analysis will assign POS tags to the translation candidates. We restricted the pruning technique to nouns, verbs, adjectives and adverbs, although other POS tags could be treated in a similar way. For JapaneseEnglish pair of languages, Japanese nouns and verbs are compared to English nouns and verbs, respectively. Japanese adverbs and adjectives are compared to English adverbs and adjectives, because of the close relationship between adverbs and adjectives in Japanese (Sadat et al., 2003). Finally, the generated translation alternatives are sorted in decreasing order by similarity values and rank counts are assigned in increasing order. A fixed number of top-ranked translation alternatives are selected and misleading candidates are discarded. 2.3 Linguistic2.2 Comparable Corpora (Japanese-English) Content words (nouns, verbs, adjectives, adverbs, foreign words) Disambiguation The proposed two-stages approach on bilingual terminology acquisition and disambiguation from comparable corpora (Sadat et al., 2003) is described as follows: - Bilingual terminology acquisition from sour"
P03-2025,C02-1166,1,\N,Missing
P06-1001,P05-3026,0,0.00927356,"sions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better results. derivational morphology (such as using roots as tokens) in this paper.  Orthographic Ambiguity: The form of certain letters in Arabic script allows suboptimal orthographic variants of the same wor"
P06-1001,koen-2004-pharaoh,0,0.0605115,"Missing"
P06-1001,W04-3250,0,0.155401,"Missing"
P06-1001,N04-4015,0,0.631891,"publications on the effect of morphology on SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c 1 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1–8, c Sydney, July 2006. 2006 Association for Computational Linguistics and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering Arabic, Lee (2004) investigated the use of automatic alignment of POS tagged English and affix-stem segmented Arabic to determine appropriate tokenizations. Her results show that morphological preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been"
P06-1001,2005.iwslt-1.9,0,0.0122647,"helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better results. derivati"
P06-1001,E06-1005,0,0.00637967,"eprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better results. derivational morphology (such as using roots as tokens) in this paper.  Orthographic Ambiguity: The form of certain letters in Arabic script allows suboptimal orthographic variants of the same word to coexist in the sam"
P06-1001,J04-2003,0,0.149101,"Missing"
P06-1001,P04-1063,0,0.0161291,"that morphological preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to p"
P06-1001,P03-1021,0,0.0649375,"Missing"
P06-1001,2001.mtsummit-papers.68,0,0.13432,"sing, separating punctuation from words and splitting off “’s”. The same preprocessing was used on the English data for all experiments. Only Arabic preprocessing was varied. Decoding weight optimization was done using a set of 200 sentences from the 2003 NIST MT evaluation test set (M T 03). We report results on the 2004 NIST MT evaluation test set (M T 04) The experiment design and choices of schemes and techniques were done independently of the test set. The data sets, M T 03 and M T 04, include one Arabic source and four English reference translations. We use the evaluation metric BLEU-4 (Papineni et al., 2001) although we are aware of its caveats (CallisonBurch et al., 2006). Table 2: Scheme Statistics Scheme Tokens OOVs Perplexity ST ON D1 D2 D3 WA TB MR L1 L2 EN 36000 36000 38817 40934 52085 38635 42880 62410 36000 36000 55525 1345 1212 1016 835 575 1044 662 409 392 432 432 1164 944 582 422 137 596 338 69 401 460 103 with the number of OOVs and perplexity. The only exceptions are L1 and L2, whose low OOV rate is the result of the reductionist nature of the scheme, which does not preserve morphological information. 5 Basic Scheme Experiments We now describe the system and the data sets we used to"
P06-1001,2005.iwslt-1.5,0,0.0186921,"ical preprocessing helps, but only for the smaller corpora. As size increases, the benefits diminish. Our results are comparable to hers in terms of BLEU score and consistent in terms of conclusions. Other research on preprocessing Arabic suggests that minimal preprocessing, such as splitting off the conjunction + w+ ’and’, produces best results with very large training data (Och, 2005). System combination for MT has also been investigated by different researchers. Approaches to combination generally either select one of the hypotheses produced by the different systems combined (Nomoto, 2004; Paul et al., 2005; Lee, 2005) or combine lattices/n-best lists from the different systems with different degrees of synthesis or mixing (Frederking and Nirenburg, 1994; Bangalore et al., 2001; Jayaraman and Lavie, 2005; Matusov et al., 2006). These different approaches use various translation and language models in addition to other models such as word matching, sentence and document alignment, system translation confidence, phrase translation lexicons, etc. We extend on previous work by experimenting with a wider range of preprocessing schemes for Arabic and exploring their combination to produce better resul"
P06-1001,popovic-ney-2004-towards,0,0.294964,"Missing"
P06-1001,W05-0822,1,0.8478,"Missing"
P06-1001,E06-1032,0,0.00868398,"Missing"
P06-1001,N04-4038,0,0.0527738,"hemes. It is identical to the initial tokenization used by Lee (2004).  L1 and L2: Lexeme and POS. These reduce a word to its lexeme and a POS. L1 and L2 differ in the set of POS tags they use. L1 uses the simple POS tags advocated by Habash and RambzyArp with visit AlY to trkyA. Turkey . bzyArp bzyArp bzyArp b+ zyArp b+ zyArp bzyArp b+ zyArp b+ zyAr +p zyArp zyArp  b+ zyArp  AlY  lY  lY  lY  lY  lY  lY  lY  lY  lY   lY  trkyA trkyA trkyA trkyA trkyA trkyA trkyA trkyA trkyA trkyA   trkyA   . . . . . . . . . . . bow (2005) (15 tags); while L2 uses the reduced tag set used by Diab et al. (2004) (24 tags). The latter is modeled after the English Penn POS tag set. For example, Arabic nouns are differentiated for being singular (NN) or Plural/Dual (NNS), but adjectives are not even though, in Arabic, they inflect exactly the same way nouns do.  EN: English-like. This scheme is intended to minimize differences between Arabic and English. It decliticizes similarly to D3, but uses Lexeme and POS tags instead of the regenerated word. The POS tag set used is the reduced Arabic Treebank tag set (24 tags) (Maamouri et al., 2004; Diab et al., 2004). Additionally, the subject inflection is ind"
P06-1001,H05-1085,0,0.091081,"g, part-of-speech (POS) tagging and lemmatization. The ultimate goal of preprocessing is to improve the quality of the SMT output by addressing issues such as sparsity in training data. We refer to a specific kind of preprocessing as a “scheme” and differentiate it from the “technique” used to obtain it. In a previous publication, we presented results describing six pre2 Previous Work The anecdotal intuition in the field is that reduction of word sparsity often improves translation quality. This reduction can be achieved by increasing training data or via morphologically driven preprocessing (Goldwater and McClosky, 2005). Recent publications on the effect of morphology on SMT quality focused on morphologically rich languages such as German (Nießen and Ney, 2004); Spanish, Catalan, and Serbian (Popovi´c 1 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1–8, c Sydney, July 2006. 2006 Association for Computational Linguistics and Ney, 2004); and Czech (Goldwater and McClosky, 2005). They all studied the effects of various kinds of tokenization, lemmatization and POS tagging and show a positive effect on SMT quality. Specifically considering"
P06-1001,P05-1071,1,0.763811,"not always an easy task and often requires the use of a morphological analyzer. One common example in Arabic nouns is Broken Plurals. For example, one of the plukAtb ‘writer’ ral forms of the Arabic word is   ktbp ‘writers’. An alternative non-broken plural (concatenatively derived) is  kAtbwn ‘writers’.     4.1 We use the Buckwalter Arabic Morphological Analyzer (BAMA) (Buckwalter, 2002) to obtain possible word analyses. To select among these analyses, we use the Morphological Analysis and Disambiguation for Arabic (M ADA) tool,2 an off-theshelf resource for Arabic disambiguation (Habash and Rambow, 2005). Being a disambiguation system of morphology, not word sense, M ADA sometimes produces ties for analyses with the same inflectional features but different lexemes (resolving such ties require word-sense disambiguation). We resolve these ties in a consistent arbitrary manner: first in a sorted list of analyses. Producing a preprocessing scheme involves removing features from the word analysis and regenerating the word without the split-off features. The regeneration ensures that the generated form is appropriately normalized by addressing various morphotactics described in Section 3. The gener"
P06-1001,N06-2013,1,0.429835,"). These schemes were evaluated against three different techniques that vary in linguistic complexity; and across a learning curve of training sizes. Additionally, we reported on the effect of scheme/technique combination on genre variation between training and testing. In this paper, we shift our attention to exploring and contrasting additional preprocessing schemes for Arabic and describing and evaluating different methods for combining them. We use a single technique throughout the experiments reported here. We show an improved MT performance when combining different schemes. Similarly to Habash and Sadat (2006), the set of schemes we explore are all word-level. As such, we do not utilize any syntactic information. We define the word to be limited to written Modern Standard Arabic (MSA) strings separated by white space, punctuation and numbers. Section 2 presents previous relevant research. Section 3 presents some relevant background on Arabic linguistics to motivate the schemes discussed in Section 4. Section 5 presents the tools and data sets used, along with the results of basic scheme experiments. Section 6 presents combination techniques and their results. Statistical machine translation is quit"
P06-1001,A94-1016,0,\N,Missing
P06-1001,P02-1040,0,\N,Missing
P06-1001,2005.eamt-1.20,0,\N,Missing
R13-1076,2010.jeptalnrecital-long.30,0,0.0491681,"Missing"
R13-1076,N04-4038,0,0.123089,"Missing"
R13-1076,N10-1105,0,0.0474944,"Missing"
R13-1076,W06-3103,0,0.0397816,"Missing"
R13-1076,hasan-etal-2006-creating,0,0.0457583,"Missing"
R13-1076,P07-2045,0,0.0114952,"Missing"
R13-1076,N04-4015,0,0.0709492,"Missing"
R13-1076,J03-1002,0,0.00565899,"Missing"
R13-1076,2001.mtsummit-papers.68,0,0.0934367,"Missing"
R13-1076,N06-2013,1,0.858106,"Missing"
R13-1076,2009.mtsummit-posters.17,0,0.0509729,"Missing"
R13-1076,H05-1085,0,0.0487553,"Missing"
R13-1076,P02-1040,0,\N,Missing
W03-1108,C02-1166,1,0.899121,"ambiguation, Part-of-Speech. 1 Introduction Researches on corpus-based approaches to machine translation (MT) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri. These approaches generally rely on large text corpora, which play an important role in Natural Language Processing (NLP) and Information Retrieval (IR). Moreover, non-aligned comparable corpora have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dagan and Itai, 1994; Dejean et al., 2002; Diab and Finch, 2000; Fung, 2000; Koehn and Knight, 2002; Nakagawa, 2000; Peters and Picchi, 1995; Rapp, 1999; Shahzad and al., 1999; Tanaka and Iwasaki, 1996). Unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period. This property made comparable corpora more abundant, less expensive and more accessible through the World Wide Web. In the present paper, we are concerned by exploiting scarce resources for bilingual terminology ac"
W03-1108,J93-1003,0,0.05155,"el, represented by similarity SIMT →S . • Merge the first and second models to yield a two-stages translation model, based on bidirectional comparable corpora and represented by similarity SIMS↔T . We follow strategies of previous researches (Dejean et al., 2002; Fung, 2000; Rapp, 1999) for the first and second translation models and propose a merging strategy for the two-stages translation model (Sadat et al., 2003). First, word frequencies, context word frequencies in surrounding positions (here three-words window) are computed following a statistics-based metrics, the log-likelihood ratio (Dunning, 1993). Context vectors for each source term and each target term are constructed. Next, context vectors of the target words are translated using a preliminary bilingual dictionary. We consider all translation candidates, keeping the same context frequency value as the source term. This step requires a seed lexicon, to expand using the proposed bootstrapping approach of this paper. Similarity vectors are constructed for each pair of source term and target term using the cosine metric (Salton and McGill, 1983). Therefore, similarity vectors SIM S→T and SIMT →S for the first and second models are cons"
W03-1108,W02-0902,0,0.0542904,"on corpus-based approaches to machine translation (MT) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri. These approaches generally rely on large text corpora, which play an important role in Natural Language Processing (NLP) and Information Retrieval (IR). Moreover, non-aligned comparable corpora have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dagan and Itai, 1994; Dejean et al., 2002; Diab and Finch, 2000; Fung, 2000; Koehn and Knight, 2002; Nakagawa, 2000; Peters and Picchi, 1995; Rapp, 1999; Shahzad and al., 1999; Tanaka and Iwasaki, 1996). Unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period. This property made comparable corpora more abundant, less expensive and more accessible through the World Wide Web. In the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on Cross-Language Information"
W03-1108,P99-1067,0,0.617307,"on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri. These approaches generally rely on large text corpora, which play an important role in Natural Language Processing (NLP) and Information Retrieval (IR). Moreover, non-aligned comparable corpora have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dagan and Itai, 1994; Dejean et al., 2002; Diab and Finch, 2000; Fung, 2000; Koehn and Knight, 2002; Nakagawa, 2000; Peters and Picchi, 1995; Rapp, 1999; Shahzad and al., 1999; Tanaka and Iwasaki, 1996). Unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period. This property made comparable corpora more abundant, less expensive and more accessible through the World Wide Web. In the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on Cross-Language Information Retrieval (CLIR). CLIR consists of retrieving documen"
W03-1108,P03-2025,1,0.915812,"s conducted on NTCIR, a large-scale data collection for (Japanese, English) language pair. The remainder of the present paper is organized as follows: Section 2 presents the proposed twostages approach for bilingual terminology acquisition from comparable corpora. Section 3 describes the integration of linguistic knowledge for pruning the translation candidates. Experiments and evaluations in CLIR are discussed in Sections 4. Section 5 concludes the present paper. 2 Two-stages Comparable Corpora-based Approach Our proposed approach to bilingual terminology acquisition from comparable corpora (Sadat et al., 2003; Sadat et al., 2003) is based on the assumption of similar collocation, i.e., If two words are mutual translations, then their most frequent collocates are likely to be mutual translations as well. Moreover, we apply this assumption in both directions of the corpora, i.e., find translations of the source term in the target language corpus but also translations of the target terms in the source language corpus. The proposed two-stages approach for the acquisition, disambiguation and selection of bilingual terminology is described as follows: • Bilingual terminology acquisition from source lang"
W03-1108,C96-2098,0,\N,Missing
W03-1108,J94-4003,0,\N,Missing
W03-1108,P97-1017,0,\N,Missing
W05-0822,P00-1056,0,0.225418,"Missing"
W05-0822,2003.mtsummit-papers.15,1,0.86682,"s generated by rules; decoding to produce one or more translation hypotheses; and error-driven rescoring to choose the best final hypothesis. (A fourth postprocessing phase was not needed for the shared task.) http://www.statmt.org/wpt05/mt-shared-task/ 129 Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 129–132, c Ann Arbor, June 2005. Association for Computational Linguistics, 2005 2.1 Preprocessing Preprocessing is a necessary first step in order to convert raw texts in both source and target languages into a format suitable for both model training and decoding (Foster et al., 2003). For the supplied Europarl corpora, we relied on the existing segmentation and tokenization, except for French, which we manipulated slightly to bring into line with our existing conventions (e.g., converting l ’ an into l’ an). For the Hansard corpus used to supplement our French-English resources (described in section 3 below), we used our own alignment based on Moore’s algorithm (Moore, 2002), segmentation, and tokenization procedures. Languages with rich morphology are often problematic for statistical machine translation because the available data lacks instances of all possible forms of"
W05-0822,P02-1040,0,0.0814507,"lies on symmetrized IBM model 2 word-alignments for phrase pair induction. The distortion model is also very similar to Koehn’s, with the exception of a final cost to account for sentence endings. 130 To set weights on the components of the loglinear model, we implemented Och’s algorithm (Och, 2003). This essentially involves generating, in an iterative process, a set of nbest translation hypotheses that are representative of the entire search space for a given set of source sentences. Once this is accomplished, a variant of Powell’s algorithm is used to find weights that optimize BLEU score (Papineni et al, 2002) over these hypotheses, compared to reference translations. Unfortunately, our implementation of this algorithm converged only very slowly to a satisfactory final nbest list, so we used two different ad hoc strategies for setting weights: choosing the best values encountered during the iterations of Och’s algorithm (FrenchEnglish), and a grid search (all other languages). To perform the actual translation, we used our decoder, Canoe, which implements a dynamicprogramming beam search algorithm based on that of Pharaoh (Koehn, 2004). Canoe is input-output compatible with Pharaoh, with the except"
W05-0822,moore-2002-fast,0,0.0342615,"s, 2005 2.1 Preprocessing Preprocessing is a necessary first step in order to convert raw texts in both source and target languages into a format suitable for both model training and decoding (Foster et al., 2003). For the supplied Europarl corpora, we relied on the existing segmentation and tokenization, except for French, which we manipulated slightly to bring into line with our existing conventions (e.g., converting l ’ an into l’ an). For the Hansard corpus used to supplement our French-English resources (described in section 3 below), we used our own alignment based on Moore’s algorithm (Moore, 2002), segmentation, and tokenization procedures. Languages with rich morphology are often problematic for statistical machine translation because the available data lacks instances of all possible forms of a word to efficiently train a translation system. In a language like German, new words can be formed by compounding (writing two or more words together without a space or a hyphen in between). Segmentation is a crucial step in preprocessing languages such as German and Finnish texts. In addition to these simple operations, we also developed a rule-based component to detect numbers and dates in t"
W05-0822,P02-1038,0,0.179126,"Missing"
W05-0822,P03-1021,0,0.0391459,"ain components: one or more trigram language models, one or more phrase translation models, a distortion model, and a word-length feature. The trigram language model is implemented in the SRILM toolkit (Stolcke, 2002). The phrase-based translation model is similar to the one described in (Koehn, 2004), and relies on symmetrized IBM model 2 word-alignments for phrase pair induction. The distortion model is also very similar to Koehn’s, with the exception of a final cost to account for sentence endings. 130 To set weights on the components of the loglinear model, we implemented Och’s algorithm (Och, 2003). This essentially involves generating, in an iterative process, a set of nbest translation hypotheses that are representative of the entire search space for a given set of source sentences. Once this is accomplished, a variant of Powell’s algorithm is used to find weights that optimize BLEU score (Papineni et al, 2002) over these hypotheses, compared to reference translations. Unfortunately, our implementation of this algorithm converged only very slowly to a satisfactory final nbest list, so we used two different ad hoc strategies for setting weights: choosing the best values encountered dur"
W05-0822,koen-2004-pharaoh,0,\N,Missing
W06-3118,N06-1004,1,0.829818,"s c(s, t) where D = n1 /(n1 + 2n2 ), n1+ (∗, t) is the number of distinct phrases s with which t co-occurs, and P pk (s) = n1+ (s, ∗)/ s n1+ (s, ∗), with n1+ (s, ∗) analogous to n1+ (∗, t). Our approach to phrase-table smoothing contrasts to previous work (Zens and Ney, 2004) in which smoothed phrase probabilities are constructed from word-pair probabilities and combined in a log-linear model with an unsmoothed phrase-table. We believe the two approaches are complementary, so a combination of both would be worth exploring in future work. 2.2 Feature-Rich DT-based distortion In a recent paper (Kuhn et al, 2006), we presented a new class of probabilistic ”Segment Choice Models” (SCMs) for distortion in phrase-based systems. In some situations, SCMs will assign a better distortion score to a drastic reordering of the source sentence than to no reordering; in this, SCMs differ from the conventional penalty-based distortion, which always favours less rather than more distortion. We developed a particular kind of SCM based on decision trees (DTs) containing both questions of a positional type (e.g., questions about the distance of a given phrase from the beginning of the source sentence or from the previ"
W06-3118,W05-0822,1,0.831685,"le data set and explore the benefits of a number of recently added features. Section 2 describes the changes that have been made to Portage in the past year that affect the participation in the 2006 shared task. Section 3 outlines the methods employed for this task and extensions of it. In Section 4 the results are summarized in tabular form. Following these, there is a conclusions section that highlights what can be gleaned of value from these results. 2 Portage Because this is the second participation of Portage in such a shared task, a description of the base system can be found elsewhere (Sadat et al, 2005). Briefly, Portage is a research vehicle and development prototype system exploiting the state-of-the-art in statistical machine translation (SMT). It uses a custom Phrase-Table Smoothing Phrase-based SMT relies on conditional distributions p(s|t) and p(t|s) that are derived from the joint frequencies c(s, t) of source/target phrase pairs observed in an aligned parallel corpus. Traditionally, relative-frequency estimation is used to derive conP ditional distributions, ie p(s|t) = c(s, t)/ s c(s, t). However, relative-frequency estimation has the well-known problem of favouring rare events. For"
W06-3118,W05-0800,0,0.0869259,"Missing"
W06-3118,2006.jeptalnrecital-poster.23,1,0.726586,"n to the training resources used in WPT 2005 for the French-English task, i.e. Europarl and Hansard, we used a bilingual dictionary, Le Grand Dictionnaire Terminologique (GDT) 2 to train translation models and the English side of the UN parallel corpus (LDC2004E13) to train an English language model. Integrating terminological lexicons into a statistical machine translation engine is not a straightforward operation, since we cannot expect them to come with attached probabilities. The approach we took consists on viewing all translation candidates of each source term or phrase as equiprobable (Sadat et al, 2006). In total, the data used in this second part of our contribution to WMT 2006 is described as follows: (1) A set of 688,031 sentences in French and English extracted from the Europarl parallel corpus (2) A set of 6,056,014 sentences in French and English extracted from the Hansard parallel corpus, the official record of Canada’s parliamentary debates. (3) A set of 701,709 sentences in French and English extracted from the bilingual dictionary GDT. (4) Language models were trained on the French and English parts of the Europarl and Hansard. We used the provided Europarl corpus while omitting da"
W06-3118,N04-1033,0,0.0248659,"s phrase. The resulting estimates are: cg (s, t) , s cg (s, t) + p(t)n1 pg (s|t) = P P where p(t) = c(t)/ t c(t). The estimates for pg (t|s) are analogous. The second strategy is Kneser-Ney smoothing (Kneser and Ney, 1995), using the interpolated variant described in (Chen and Goodman., 1998):1 pk (s|t) = c(s, t) − D + D n1+ (∗, t) pk (s) P s c(s, t) where D = n1 /(n1 + 2n2 ), n1+ (∗, t) is the number of distinct phrases s with which t co-occurs, and P pk (s) = n1+ (s, ∗)/ s n1+ (s, ∗), with n1+ (s, ∗) analogous to n1+ (∗, t). Our approach to phrase-table smoothing contrasts to previous work (Zens and Ney, 2004) in which smoothed phrase probabilities are constructed from word-pair probabilities and combined in a log-linear model with an unsmoothed phrase-table. We believe the two approaches are complementary, so a combination of both would be worth exploring in future work. 2.2 Feature-Rich DT-based distortion In a recent paper (Kuhn et al, 2006), we presented a new class of probabilistic ”Segment Choice Models” (SCMs) for distortion in phrase-based systems. In some situations, SCMs will assign a better distortion score to a drastic reordering of the source sentence than to no reordering; in this, SC"
W12-1310,W06-2810,0,0.0923427,"Missing"
W12-1310,J93-2003,0,0.0664698,"Missing"
W12-1310,declerck-etal-2006-multilingual,0,0.0360272,"Missing"
W12-1310,1998.amta-tutorials.5,0,0.103051,"Missing"
W12-1310,W11-1206,0,0.0670376,"Missing"
W12-1310,W11-1205,0,0.0642362,"Missing"
W12-1310,J03-1002,0,0.00991458,"Missing"
W12-1310,2007.mtsummit-papers.26,0,0.128071,"Missing"
W12-1310,P03-2025,1,0.742512,"Missing"
W12-1310,2010.jeptalnrecital-demonstration.6,1,0.791315,"Missing"
W12-1310,C96-2141,0,0.552025,"Missing"
W14-4813,kinoshita-etal-2006-cogroo,0,0.0475011,"Missing"
W14-4813,W03-1807,0,0.055611,"Missing"
W14-4813,J96-1001,0,0.327726,"Missing"
W14-4813,J90-1003,0,\N,Missing
W14-4813,W13-1013,0,\N,Missing
W14-5706,kinoshita-etal-2006-cogroo,0,0.0751966,"Missing"
W14-5706,W03-1807,0,0.0609095,"Missing"
W14-5706,J96-1001,0,0.0607238,"reativecommons.org/licenses/by/4.0/ 53 Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 53–62, Dublin, Ireland, August 24 2014. The correct identification of MWEs is important for different NLP applications, such as machine translation, information retrieval and the semantic web, to which the principle of syntactic or semantic unit is important (Watrin and François, 2011). Methods for identifying MWEs rely on statistical measures, especially association measures, such as mutual information (Church and Hanks, 1990), log-likelihood or Dice’s coefficient (Smadja, 1996). The basic idea behind such measures can be summarized as follows: the higher the association among the words that appear together in a text, the higher the probability that they constitute a single semantic unit. There are other methods, which use linguistic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each word, the sense of the composite expression or the syntactic regularities. 2 Related Work Dias and Lopes (2005) present a method for the extraction of MWEs based only on statistics with an application"
W14-5706,J93-1007,0,0.53297,"Missing"
W14-5706,W11-0813,0,0.0127935,"y number of words. _______________ This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 53 Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 53–62, Dublin, Ireland, August 24 2014. The correct identification of MWEs is important for different NLP applications, such as machine translation, information retrieval and the semantic web, to which the principle of syntactic or semantic unit is important (Watrin and François, 2011). Methods for identifying MWEs rely on statistical measures, especially association measures, such as mutual information (Church and Hanks, 1990), log-likelihood or Dice’s coefficient (Smadja, 1996). The basic idea behind such measures can be summarized as follows: the higher the association among the words that appear together in a text, the higher the probability that they constitute a single semantic unit. There are other methods, which use linguistic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each wor"
W14-5706,J90-1003,0,\N,Missing
W14-5706,W13-1013,0,\N,Missing
W14-5813,al-sabbagh-girju-2010-mining,0,0.332951,"Missing"
W14-5813,E06-1047,0,0.332925,"Missing"
W14-5813,2012.amta-government.3,0,0.0150358,"semantic and lexical resources for Arabic Social Media within the ASMAT (Arabic Social Media Analysis Tools) project. 1 Introduction The explosive growth of social media has led to a wide range of new challenges for machine translation and language processing. The language used in social media occupies a new space between structured and unstructured media, formal and informal language, and dialect and standard usage. Yet these new platforms have given a digital voice to millions of user on the Internet, giving them the opportunity to communicate on the first truly global stage – the Internet (Colbath, 2012). Social media poses three major computational challenges, dubbed by Gartner the 3Vs of big data: volume, velocity, and variety1. Natural Language Processing (NLP) methods, in particular, face further difficulties arising from the short, noisy, and strongly contextualised nature of social media. In order to address the 3Vs of social media, new language technologies have emerged, such as the identification and definition of users&apos; language varieties and the translation to a different language, than the source. 1 http://en.wikipedia.org/wiki/Big_data This work is licenced under a Creative Common"
W14-5813,N07-5003,0,0.0799129,"Missing"
W14-5813,P13-2081,0,0.0369368,"struction of linguistic tools, such as lexical dictionaries and grammars and their exploitation in NLP applications, such as translation technologies. Basically, Arabic is considered as morphologically rich and complex language, which presents significant challenges for NLP and its applications. It is the official language in 22 countries spoken by more than 350 million people around the world2. Moreover, Arabic language exists in a state of diglossia where the standard form of the language, Modern Standard Arabic (MSA) and the regional dialects (AD) live side-by-side and are closely related (Elfardy and Diab, 2013). Arabic has more than 22 variants, refereed a as dialects; some countries share the same dialects, while many dialects may exist alongside MSA within the same Arab country. Arabic Dialects (AD) or daily language differs from MSA especially in social media communication. However, most Arabic social media texts have mixed forms and many variations especially between MSA and AD. This paper describes our efforts to create linguistic resources and translation tool for TDA to MSA. First, a bilingual TDA-MSA lexicon and a set of TDA mapping rules for the social media context are collaboratively cons"
W14-5813,N06-2013,1,0.760807,"considered a reference set of 50 phrases in TDA, translated manually into MSA. We also considered these 50 TDA phrases as the test set. Thus, we applied the proposed rule-based approach on this test set. In order to combine adequately the rule-based translation approach to the language modeling (in MSA), we considered using the United Nation Arabic corpus to train a trigram language model. This training corpus contains around 50M words after cleaning the Latin content. A preprocessing step is very crucial to any Arabic language processing. We considered tokenizing the MSA words using the D3 (Habash and Sadat, 2006a) scheme to overcome all problems of agglutination. The D3 scheme splits off clitics as follows: the class of conjunction clitics (w+ and f+), the class of particles (l+, k+, b+ and s+), the definite article (Al+) and all pronominal enclitics. These preprocessing are applied for both the hypothesis translation sentences and the training corpus, both in MSA. In addition to this preprocessing step, manual cleaning the MSA corpus of Latin contents was required. Thus, a trigram language model was implemented using the SRILM toolkit (Stolcke, 2002) on this training MSA corpus. Next, we extracted a"
W14-5813,P06-1086,0,0.325952,"Missing"
W14-5813,2013.mtsummit-papers.16,0,0.0328213,"Missing"
W14-5813,P02-1040,0,0.0892614,"his training MSA corpus. Next, we extracted all possible trigrams from the preprocessed MSA hypotheses translations and we computed the probability that these trigrams extracted appear in the MSA corpus based on the language model. A probability for each hypothesis translation is computed based on a trigram language model (LM). The hypothesis translation that has the highest probability is considered as the best translation. Evaluations of the best translation sentence from TDA to MSA against the reference sentence in MSA were completed using the BLEU metric for automatic machine translation (Papineni et al., 2002). Our experiment produced a score of 14.32 BLEU. This low score could be related to our rulebased translation approach that is word-based and to the high number of unknown words in our source test file in other language variants than TDA. Adopting a phrasal translation and solving the problem of unknown words should be more effective. Unfortunately, we could not found an available TDA-MSA test and reference files to conduct better evaluations in machine translation and social media context. 6 Conclusion and Future Work Social media has become a key communication tool for people around the worl"
W14-5813,P13-2001,0,0.0318579,"Missing"
W14-5813,W11-2602,0,0.210101,"Missing"
W14-5813,C12-3048,0,0.521296,"Missing"
W14-5813,2010.amta-papers.5,0,0.462028,"Missing"
W14-5813,N12-1006,0,0.0945391,"Missing"
W14-5813,W13-2813,0,\N,Missing
W14-5813,I13-1048,0,\N,Missing
W14-5904,N10-1027,0,0.0577781,"Missing"
W14-5904,W09-0807,0,0.265531,"Missing"
W14-5904,I11-1036,0,0.0500969,"Missing"
W14-5904,elfardy-diab-2012-simplified,0,0.0859119,"Missing"
W14-5904,P13-2081,0,0.283062,"Missing"
W14-5904,W13-1109,1,0.798704,"Missing"
W14-5904,P06-1086,0,0.0316799,"Missing"
W14-5904,habash-etal-2012-conventional,0,0.0919507,"Missing"
W14-5904,C96-2110,0,0.0407841,"Missing"
W14-5904,W11-2602,0,0.0431591,"Missing"
W14-5904,P11-2007,0,0.0408017,"Missing"
W14-5904,al-sabbagh-girju-2012-yadac,0,\N,Missing
W16-3915,F14-2015,0,0.627572,"to &quot;IPhone&quot;) and then associate negative/positive sentiment extracted from tweets. Michelson and Macskassy (2010) use Wikipedia to disambiguate, classify named entities found in tweets and identify the subjects of interest to the users and the most frequent categories related to named entities. Since hashtags are essentials in understanding the subject of a tweet, most systems of analyze of opinions try to incorporate them in their calculations. Asur and Huberman (2010) show how to improve standard techniques of supervised classification by integration of polarity from most frequent hashtags. Brun and Roux (2014a) show how to extract words from hashtags and use them to improve the detection of polarity in tweets. Their system represents each opinion according to the model proposed by Liu (2010) and compare a system that uses hashtag decomposition with a system that does not use it. Almeida et al. (2016) present a supervised learning approach dedicated to the biomedical domain for supporting the production of literature on HIV using thesaurus MeSH (Medical Subject Headings). 3 Pre-processing Our system for the classification of tweets is based on Weka1 and uses the Twitter API to extract tweets2 . We"
W16-3926,W15-4319,0,0.0615652,"Missing"
W16-3926,R13-1011,0,0.110729,"word in the sentence, the number of occurrences of the lemma of a word in the sentence and the word in lowercase format. (3) The syntactic features consist of the constituent labels and the distance of a word to root. The word’s constituent label (Constituent Label) and its depth in the constituent tree (Distance to Root) are extracted using a syntactic parser. We used Berkerley parser (Petrov and Klein, 2007). (4) The POS tags features in the task of NE recognition contain many useful information for classifying and predicting named entities. In this work, we use a POS tagger, named TwitIE (Bontcheva et al., 2013), providing the output in the same format given by the organizers. Predicted tags are used as features as follows: • POS tags: The search space windows is 4. There are a combination of patterns with the current word, the two previous words and the two next words and their corresponding POS tags: (w-2, p-2), (w-1, p-1), (w0, p0), (w+1, p+1), (w+2, p+2). (5) The polysemy count: We extract the polysemy count, which is the number of meanings of a word in a given language. The BabelNet (Navigli et al., 2012) API is used to extract this feature. (6) The longest n-gram length: We seek to get the leng"
W16-3926,N07-1051,0,0.0152211,"ere are six patterns in order to check whether the current word, the previous word and the next word contain punctuation marks and/or numbers. (2) The lexical features consist of the number of occurrences of a word in the sentence, the number of occurrences of the lemma of a word in the sentence and the word in lowercase format. (3) The syntactic features consist of the constituent labels and the distance of a word to root. The word’s constituent label (Constituent Label) and its depth in the constituent tree (Distance to Root) are extracted using a syntactic parser. We used Berkerley parser (Petrov and Klein, 2007). (4) The POS tags features in the task of NE recognition contain many useful information for classifying and predicting named entities. In this work, we use a POS tagger, named TwitIE (Bontcheva et al., 2013), providing the output in the same format given by the organizers. Predicted tags are used as features as follows: • POS tags: The search space windows is 4. There are a combination of patterns with the current word, the two previous words and the two next words and their corresponding POS tags: (w-2, p-2), (w-1, p-1), (w0, p0), (w+1, p+1), (w+2, p+2). (5) The polysemy count: We extract t"
W16-3926,2015.iwslt-papers.11,1,0.893903,"-2), (w-1, p-1), (w0, p0), (w+1, p+1), (w+2, p+2). (5) The polysemy count: We extract the polysemy count, which is the number of meanings of a word in a given language. The BabelNet (Navigli et al., 2012) API is used to extract this feature. (6) The longest n-gram length: We seek to get the length (n + 1) of the longest left sequence (wi−n) concerned by the current word (wi) and known by the language model (LM) concerned. For example, if the longest left sequence wi−2, wi−1, wi appears in the longest n-gram value for wi will be 3. This value ranges from 0 to the max order of the LM concerned (Servan et al., 2015). We used a language model from WMT-20161: n-gram #tokens 1 167 333 2 3 330 169 3 5 129 254 Table 1. Statistics of the n-gram of the language model from WMT-2016 These features were chosen because of their relevance in several NLP tasks such as POS tagging, chunk tagging and NE recognition, following the WNUT 2015 workshop2. The features for the tokens, in the patterns, were based on uni-grams, bi-grams, tri-grams and within a context window of size 3 (previous token, current token, next token). 3 3.1 Experimental setup Preparation of corpus Our model is trained with the data provided by the 2"
W16-3926,W14-5904,1,0.810477,"u and Sekine, 2007). The existing standard NER systems are usually trained on formal texts, such as the newswire. However, these linguistic tools do not work well on the new and challenging noisy tweet messages because the style of Tweet messages is short (length upto 140 characters) and unstructured. The content is highly noisy, contains many ill-formed words and covers several topics. Sometimes even human annotators do not have enough context to disambiguate the entities reliably (Baldwin et al., 2015). Our team at UQAM is interested by social media analysis research within the NLP context (Sadat et al, 2014a; Sadat et al, 2014b; Sadat, 2013). Thus, our participation at the 2nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition in Twitter, in conjunction with Coling 2016, is very fruitful. This shared task consists of two separate evaluations aiming at: (1) predicting the 10 fine-grained types of named entities, and (2) predicting the no-type of named entities. For both evaluation, our system is based on supervised machine learning and trained with a sequential labeling algorithm, using Conditional Random Fields (CRF). Our contribution here consists of the propo"
W16-3926,W14-5813,1,0.811331,"u and Sekine, 2007). The existing standard NER systems are usually trained on formal texts, such as the newswire. However, these linguistic tools do not work well on the new and challenging noisy tweet messages because the style of Tweet messages is short (length upto 140 characters) and unstructured. The content is highly noisy, contains many ill-formed words and covers several topics. Sometimes even human annotators do not have enough context to disambiguate the entities reliably (Baldwin et al., 2015). Our team at UQAM is interested by social media analysis research within the NLP context (Sadat et al, 2014a; Sadat et al, 2014b; Sadat, 2013). Thus, our participation at the 2nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition in Twitter, in conjunction with Coling 2016, is very fruitful. This shared task consists of two separate evaluations aiming at: (1) predicting the 10 fine-grained types of named entities, and (2) predicting the no-type of named entities. For both evaluation, our system is based on supervised machine learning and trained with a sequential labeling algorithm, using Conditional Random Fields (CRF). Our contribution here consists of the propo"
W16-5320,1995.mtsummit-1.1,0,0.548652,"Missing"
W18-2414,N07-1047,0,0.0421744,"news2018/ documents/news2018whitepaper.pdf http://workshop.colips.org/news2016/ 96 Bilingual pronunciation dictionary [en] [vi] PARIS Pa-ri-xơ JACQUES Giắc-cơ Aligner [en] Nice [en] Truffaut Pre-processing Alignment Extraction RNN based Machine Transliteration [en] [vi] p a r i s p a r i x ơ j a c q u e s gi ắ c c ơ [en] [vi] p # a # r # i # s # p # a # r # i # x # ơ j # a # c # q:u # e:s # gi # ắ # c # c # ơ # [vi] Nít-xờ [vi] Truy-phô Figure 1: The architecture of machine transliteration for a low-resource language pair dealing with bilingual named entities. used the m-2-m aligner3 toolkit (Jiampojamarn et al., 2007) to align the training data at the character level. We chose m = 2 (bigram-align) for all experiments; this means that a maximum of two graphemes on the source side will be aligned with a maximum of two phonemes on the target side. For the pre-trained source and target embeddings, we applied the word2vec4 toolkit (Mikolov et al., 2013) with a dimension of 64, a continuous space window size of 5 and the ’skip-gram’ option. We applied the nmt-keras5 toolkit to train our transliteration model for the English-Vietnamese language pair. In the transliteration system configuration, we used two-layer"
W18-2414,W16-2711,0,0.0233974,"systems, including Hindi, Tamil, Russian, Kannada, Chinese, Korean, Thai and Japanese. We can see that the romanization of non-Latin writing systems remains a complex computational task that depends crucially on which language is involved. Through this workshop, much progress has been made in methodologies for resolving the transliteration of proper nouns. We see the emergence of different approaches, such as grapheme-to-phoneme conversion (Finch and Sumita, 2010; Ngo et al., 2015), based on statistics like machine translation (Laurent et al., 2009; Nicolai et al., 2015) and neural networks (Finch et al., 2016; Shao and Nivre, 2016; Thu et al., 2016). Other work used attention-less sequenceto-sequence models for the transliteration task (Yao and Zweig, 2015). One study used a bidirectional Long Short-Term Memory (LSTM) models together with input delays for grapheme-tophoneme conversion (Rao et al., 2015). Another important challenge with the extraction of named entities and automatic transliteration is related to the vast variety of writing systems. All these difficulties are aggravated by the lack of bilingual pronunciation dictionaries for proper nouns, ambiguous transcriptions and orthographic v"
W18-2414,W10-2406,0,0.032362,"Workshop evaluation campaigns1 (Duan et al., 2016). These campaigns consist in transliterating from English into languages with a wide variety of writing systems, including Hindi, Tamil, Russian, Kannada, Chinese, Korean, Thai and Japanese. We can see that the romanization of non-Latin writing systems remains a complex computational task that depends crucially on which language is involved. Through this workshop, much progress has been made in methodologies for resolving the transliteration of proper nouns. We see the emergence of different approaches, such as grapheme-to-phoneme conversion (Finch and Sumita, 2010; Ngo et al., 2015), based on statistics like machine translation (Laurent et al., 2009; Nicolai et al., 2015) and neural networks (Finch et al., 2016; Shao and Nivre, 2016; Thu et al., 2016). Other work used attention-less sequenceto-sequence models for the transliteration task (Yao and Zweig, 2015). One study used a bidirectional Long Short-Term Memory (LSTM) models together with input delays for grapheme-tophoneme conversion (Rao et al., 2015). Another important challenge with the extraction of named entities and automatic transliteration is related to the vast variety of writing systems. A"
W18-2414,P06-1103,0,0.357693,"Missing"
W18-2414,W08-0509,0,0.0481359,"beddings resulted in significant advances over other methods. In this work, we built a machine transliteration method which was inspired by neural machine translation. Hence, we applied different evaluation metrics such as BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), Translation Error Rate (TER) (Snover et al., 2009), and Phoneme Error Rate (PER). To evaluate our proposed approach, we implemented five systems (Table 1): (1) Baseline system A : phrase-based statistical machine translation (pbSMT). We implemented a pbSMT system with Moses6 (Koehn et al., 2007). We used mGIZA (Gao and Vogel, 2008) to align the corpus at the character level, and SRILM (Stolcke et al., 2002) to create a character-based 5-gram language model for the target language. 5 Conclusions and perspectives In this paper, we presented a novel approach for machine transliteration in low research settings, that combines several techniques based on neural networks - encoder-decoder, attention mechanism, alignment representation for input sequences and pre-trained source and target embeddings - in machine transliteration systems. In the future work, we intend to test our proposed approach with a larger bilingual pronunc"
W18-2414,J98-4003,0,0.2051,"applies an alignment representation for input sequences and pre-trained source and target embeddings to overcome the transliteration problem for a low-resource languages pair. We participated in the NEWS 2018 shared task for the English-Vietnamese transliteration task. 1 Introduction Transliteration means the phonetic translation of the words in a source language (e.g. English) into equivalent words in a target language (e.g. Vietnamese). It entails transforming a word from one writing system (the &quot;source word&quot;) to a phonetically equivalent word in another writing system (the &quot;target word&quot;) (Knight and Graehl, 1998). This transformation requires a large set of rules defined by expert linguists to determine how the phonemes are aligned and to take into account the phonological system of the target language. Many language pairs have adopted various rules for transliteration over time, and most transliteration depends on the origin of a word (Waxmonsky and Reddy, 2012). In recent work on sequence-to-sequence neural network-based machine translation, the input vocabulary is large. Moreover, statistics for many 2 Related Work Transliteration can be considered as a subtask of machine translation, when we need"
W18-2414,N13-1090,0,0.00833814,"# s # p # a # r # i # x # ơ j # a # c # q:u # e:s # gi # ắ # c # c # ơ # [vi] Nít-xờ [vi] Truy-phô Figure 1: The architecture of machine transliteration for a low-resource language pair dealing with bilingual named entities. used the m-2-m aligner3 toolkit (Jiampojamarn et al., 2007) to align the training data at the character level. We chose m = 2 (bigram-align) for all experiments; this means that a maximum of two graphemes on the source side will be aligned with a maximum of two phonemes on the target side. For the pre-trained source and target embeddings, we applied the word2vec4 toolkit (Mikolov et al., 2013) with a dimension of 64, a continuous space window size of 5 and the ’skip-gram’ option. We applied the nmt-keras5 toolkit to train our transliteration model for the English-Vietnamese language pair. In the transliteration system configuration, we used two-layer encoder-decoder bidirectional LSTM cells (Hochreiter and Schmidhuber, 1997) for the RNN model, with a 64dimension projection layer to encode the input sequences and 128 nodes in each hidden layer. We used the ’Adam’ optimizer to learn the weights of the network with a default learning rate of 0.001. For decoding, the beam search was as"
W18-2414,E09-1091,0,0.0617283,"Missing"
W18-2414,W15-3911,0,0.0177345,"to languages with a wide variety of writing systems, including Hindi, Tamil, Russian, Kannada, Chinese, Korean, Thai and Japanese. We can see that the romanization of non-Latin writing systems remains a complex computational task that depends crucially on which language is involved. Through this workshop, much progress has been made in methodologies for resolving the transliteration of proper nouns. We see the emergence of different approaches, such as grapheme-to-phoneme conversion (Finch and Sumita, 2010; Ngo et al., 2015), based on statistics like machine translation (Laurent et al., 2009; Nicolai et al., 2015) and neural networks (Finch et al., 2016; Shao and Nivre, 2016; Thu et al., 2016). Other work used attention-less sequenceto-sequence models for the transliteration task (Yao and Zweig, 2015). One study used a bidirectional Long Short-Term Memory (LSTM) models together with input delays for grapheme-tophoneme conversion (Rao et al., 2015). Another important challenge with the extraction of named entities and automatic transliteration is related to the vast variety of writing systems. All these difficulties are aggravated by the lack of bilingual pronunciation dictionaries for proper nouns, amb"
W18-2414,N12-1039,0,0.0209299,"ce language (e.g. English) into equivalent words in a target language (e.g. Vietnamese). It entails transforming a word from one writing system (the &quot;source word&quot;) to a phonetically equivalent word in another writing system (the &quot;target word&quot;) (Knight and Graehl, 1998). This transformation requires a large set of rules defined by expert linguists to determine how the phonemes are aligned and to take into account the phonological system of the target language. Many language pairs have adopted various rules for transliteration over time, and most transliteration depends on the origin of a word (Waxmonsky and Reddy, 2012). In recent work on sequence-to-sequence neural network-based machine translation, the input vocabulary is large. Moreover, statistics for many 2 Related Work Transliteration can be considered as a subtask of machine translation, when we need to translate source graphemes into target phonemes. In other words, an alignment model needs to be constructed first, and the translation model is built 95 Proceedings of the Seventh Named Entities Workshop, pages 95–100 c Melbourne, Australia, July 20, 2018. 2018 Association for Computational Linguistics on the basis of the alignments. Transliterating a"
W18-2414,P02-1040,0,0.101646,"r rate. We observed that the output quality of the proposed approach, based on recurrent neural networks, was more fluid, coherent and had fewer errors than other systems, that use statistical-based approaches (Table 2). All the experimental results showed that using the alignment representation and the pre-trained source and target embeddings resulted in significant advances over other methods. In this work, we built a machine transliteration method which was inspired by neural machine translation. Hence, we applied different evaluation metrics such as BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), Translation Error Rate (TER) (Snover et al., 2009), and Phoneme Error Rate (PER). To evaluate our proposed approach, we implemented five systems (Table 1): (1) Baseline system A : phrase-based statistical machine translation (pbSMT). We implemented a pbSMT system with Moses6 (Koehn et al., 2007). We used mGIZA (Gao and Vogel, 2008) to align the corpus at the character level, and SRILM (Stolcke et al., 2002) to create a character-based 5-gram language model for the target language. 5 Conclusions and perspectives In this paper, we presented a novel approach for machine transliteration in low r"
W18-2414,J17-2003,0,0.0456355,"Missing"
W18-3927,W13-2408,0,0.0757231,"Missing"
W18-3927,W14-0405,0,0.136476,"Missing"
W18-3927,P16-1101,0,0.140689,"Missing"
W18-3927,L18-1446,1,0.615195,"data by significantly limiting the necessary data and instead extrapolating the relevant knowledge from another, related domain. This contribution generalizes previous results for POS tagging of user generated content This work is licensed under a Creative Commons Attribution 4.0 International License. creativecommons.org/licenses/by/4.0/. License details: http:// 235 Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects, pages 235–243 Santa Fe, New Mexico, USA, August 20, 2018. in social media for five languages: English, French, Italian, German and Spanish (Meftah et al., 2018), by applying our approach on three Twitter corpora of South-Slavic languages: Slovene, Croatian, and Serbian. Figure 1: Example of a morphologically-tagged sentence in Slovene: To ni nobena novost (”This is not a novelty” in English) . 2 The Model In this section, we introduce the model we experimented for MS tagging of South-Slavic languages. The model takes as input a tweet T , separated into a succession of n tokens wi , such as T = {w1 , w2 , ..., wn }. The objective is to predict the morpho-syntactic tag yˆi for each token wi of the tweet. 2.1 System Architecture We use a similar archite"
W18-3927,D16-1046,0,0.0845226,"Missing"
W18-3927,W18-3901,0,0.0586752,"Missing"
Y10-1060,W06-2810,0,0.0649227,"Missing"
Y10-1060,C02-1166,1,0.769935,"e up of original texts and their translations (Morin et al., 2004 ; Véronis, 2000). This allows texts to be aligned and used in applications such as computer-aided translator training and machine translation systems. This method could be expensive for any pair of languages or even not applicable for some languages, which are characterized by few amounts of Web pages on the Web. On the other hand, non-aligned comparable corpora, more abundant and accessible resources than parallel corpora, have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dejean et al., 2002; Fung, 2000; Gœuriot et al., 2009a; Gœuriot et al., 2009b; Morin et al., 2006; Nakagawa et al., 2000; Rapp, 1999; Sadat et al., 2003; Sadat et al., 2004). Comparable corpora are defined as collections of texts from pairs or multiples of languages, which can be contrasted because of their common features in the topic, the domain, the authors, the time period, etc. Comparable corpora could be collected from downloading electronic copies of newspapers and articles, on the WWW for any specified domain. Among the advantages of comparable corpora; their availability, consistency and utility for res"
Y10-1060,J93-1003,0,0.0102912,"ween terms of the source language and those in the target language. Considering the constructed comparable corpora from Wikipedia articles, we apply the following steps to extract the bilingual terminology: 1. Extraction of terms from source and target languages documents: In this step, terms with the following part of speech tags are extracted: noun, verb, adverb, adjective. 2. Construction of context vectors in both languages: For each term w, a context vector is constructed considering all terms that co-occur with the term w in a specified window size of one phrase. The mutual information (Dunning, 1993) is used as a co-occurrence tendency measure. 3. Translation of the context vector content in the source language to the target language: Context vectors of words in the source language are translated into the target language using the Wikipedia resource as translator. This step requires using the interlink information of Wikipedia for word translation. If needed, the Wikitionaire 6 is used to overcome the limitations of Wikipedia and to deal with out-of-vocabulary words. In the 6 http://fr.wiktionary.org/ 521 522 Poster Papers 4. current study, we are interested by exploiting specifically Wik"
Y10-1060,W09-3110,0,0.030391,"translations (Morin et al., 2004 ; Véronis, 2000). This allows texts to be aligned and used in applications such as computer-aided translator training and machine translation systems. This method could be expensive for any pair of languages or even not applicable for some languages, which are characterized by few amounts of Web pages on the Web. On the other hand, non-aligned comparable corpora, more abundant and accessible resources than parallel corpora, have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dejean et al., 2002; Fung, 2000; Gœuriot et al., 2009a; Gœuriot et al., 2009b; Morin et al., 2006; Nakagawa et al., 2000; Rapp, 1999; Sadat et al., 2003; Sadat et al., 2004). Comparable corpora are defined as collections of texts from pairs or multiples of languages, which can be contrasted because of their common features in the topic, the domain, the authors, the time period, etc. Comparable corpora could be collected from downloading electronic copies of newspapers and articles, on the WWW for any specified domain. Among the advantages of comparable corpora; their availability, consistency and utility for research on Natural Language Processi"
Y10-1060,2009.mtsummit-posters.26,0,0.0825908,"Missing"
Y10-1060,N09-2031,0,0.0695378,"Missing"
Y10-1060,W03-1108,1,0.8749,"ations such as computer-aided translator training and machine translation systems. This method could be expensive for any pair of languages or even not applicable for some languages, which are characterized by few amounts of Web pages on the Web. On the other hand, non-aligned comparable corpora, more abundant and accessible resources than parallel corpora, have been given a special interest in bilingual terminology acquisition and lexical resources enrichment (Dejean et al., 2002; Fung, 2000; Gœuriot et al., 2009a; Gœuriot et al., 2009b; Morin et al., 2006; Nakagawa et al., 2000; Rapp, 1999; Sadat et al., 2003; Sadat et al., 2004). Comparable corpora are defined as collections of texts from pairs or multiples of languages, which can be contrasted because of their common features in the topic, the domain, the authors, the time period, etc. Comparable corpora could be collected from downloading electronic copies of newspapers and articles, on the WWW for any specified domain. Among the advantages of comparable corpora; their availability, consistency and utility for research on Natural Language Processing (NLP). In another hand, recent publications on bilingual terminology extraction from comparable"
Y10-1060,P99-1067,0,\N,Missing
Y18-1038,P11-2031,0,0.0881236,"Missing"
Y18-1038,W16-2709,0,0.0770498,"ed to the state-of-the-art approaches, with a large increase of +7.30 BLEU and a reduction in translation error rate (TER) of −8.16 and phoneme error rate (PER) of −14.17. 1 Introduction In many domains, including machine translation, end-to-end deep learning models have become a valuable alternative to more traditional statistical approaches (Wu et al., 2016; Koehn, 2017). This is our motivation for applying a similar approach to build a machine transliteration system. In the state-of-the-art, the grapheme-to-phoneme methods were based on the use of graphemephoneme mappings (Oh et al., 2006; Duan et al., 2016). However, recurrent neural networks approaches do not require any alignment information. In this study, we propose a method to build a low-resourced machine transliteration system, using Fatiha Sadat Universite du Quebec a Montreal / 201, avenue du President-Kennedy, Montreal, Canada sadat.fatiha@uqam.ca RNN-based models and alignment information for input sequences. We are interested in solving out-ofvocabulary words for machine translation systems, such as proper nouns or technical terms, for a lowresourced language pair. The structure of the article is as follows: Section 2 presents the st"
Y18-1038,W10-2406,0,0.084457,"Missing"
Y18-1038,W16-2711,0,0.0610644,"Missing"
Y18-1038,W08-0509,0,0.0198385,"ive systems (Table 2): 4.2 Table 2: Evaluation of scoring for all systems: BLEU, TER and PER. Evaluation We use different evaluation metrics such as BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), Translation Error Rate (TER) (Snover et al., 2009), and Phoneme Error Rate (PER), that is 2 https://github.com/letter-to-phoneme/ m2m-aligner/ 3 https://code.google.com/archive/p/ word2vec/ 4 https://github.com/lvapeab/nmt-keras/ (1) Baseline system A : phrase-based statistical machine translation (pbSMT). We implemented a pbSMT system with Moses6 (Koehn et al., 2007). We used mGIZA (Gao and Vogel, 2008) to align the corpus at the character level, and SRILM (Stolcke and others, 2002) to create a character-based 5-gram language model for the target language. (2) Baseline system B : multi-joint sequence model for grapheme-to-phoneme convertion. We applied the Sequitur-G2P7 toolkit to train a transliteration model. (3) System 1 : encoder-decoder bidirectional LSTM + attention mechanism. (4) System 2 : encoder-decoder bidirectional GRU + attention mechanism + alignment representation for input sequences. (5) System 3 : encoder-decoder bidirectional GRU + attention mechanism + alignment representa"
Y18-1038,N07-1047,0,0.0532282,"dered as linear vector mappings between the source and the target. Then they become one of features in the input layer. We expect that exploiting this kind of alignment representation for RNNbased machine transliteration will enhance the system’s performance. 4 n+k p(pn |pn−k n−1 , gn−k ) (1) 4.1 Experiments Configuration n=1 where k is the context window size, and n is the position index in the alignment. A graphone alignment strategy can be automatically learnt from a pronunciation dictionary using maximum entropy derived from equation 1 (Barros and Weiss, 2006) or expectation-maximization (Jiampojamarn et al., 2007). Bisani and Ney (2008) used an alignment strategy in a multi-joint sequence model for grapheme-to-phoneme conversion. Their system performed with better accuracy in terms of phoneme error rate. To evaluate the efficiency of our proposed transliteration system in low resource settings, we used a bilingual pronunciation dictionary that has been collected from the news websites, as presented by Cao et al. (2010). The learning data comprise 4,259 pairs of bilingual French-Vietnamese named entities pairs, with a set of vocabularies that contains 31 graphemes on the French source side, and 71 phone"
Y18-1038,P07-2045,0,0.00861056,"proposed approach, we implemented five systems (Table 2): 4.2 Table 2: Evaluation of scoring for all systems: BLEU, TER and PER. Evaluation We use different evaluation metrics such as BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), Translation Error Rate (TER) (Snover et al., 2009), and Phoneme Error Rate (PER), that is 2 https://github.com/letter-to-phoneme/ m2m-aligner/ 3 https://code.google.com/archive/p/ word2vec/ 4 https://github.com/lvapeab/nmt-keras/ (1) Baseline system A : phrase-based statistical machine translation (pbSMT). We implemented a pbSMT system with Moses6 (Koehn et al., 2007). We used mGIZA (Gao and Vogel, 2008) to align the corpus at the character level, and SRILM (Stolcke and others, 2002) to create a character-based 5-gram language model for the target language. (2) Baseline system B : multi-joint sequence model for grapheme-to-phoneme convertion. We applied the Sequitur-G2P7 toolkit to train a transliteration model. (3) System 1 : encoder-decoder bidirectional LSTM + attention mechanism. (4) System 2 : encoder-decoder bidirectional GRU + attention mechanism + alignment representation for input sequences. (5) System 3 : encoder-decoder bidirectional GRU + atten"
Y18-1038,W17-4123,0,0.0187829,"rce and target embeddings to overcome the transliteration challenge for a low-resourced languages pair. The proposed method is tested with French and Vietnamese low-resourced language pair. The results showed promising improvement compared to the state-of-the-art approaches, with a large increase of +7.30 BLEU and a reduction in translation error rate (TER) of −8.16 and phoneme error rate (PER) of −14.17. 1 Introduction In many domains, including machine translation, end-to-end deep learning models have become a valuable alternative to more traditional statistical approaches (Wu et al., 2016; Koehn, 2017). This is our motivation for applying a similar approach to build a machine transliteration system. In the state-of-the-art, the grapheme-to-phoneme methods were based on the use of graphemephoneme mappings (Oh et al., 2006; Duan et al., 2016). However, recurrent neural networks approaches do not require any alignment information. In this study, we propose a method to build a low-resourced machine transliteration system, using Fatiha Sadat Universite du Quebec a Montreal / 201, avenue du President-Kennedy, Montreal, Canada sadat.fatiha@uqam.ca RNN-based models and alignment information for inp"
Y18-1038,W10-2403,0,0.0816376,"Missing"
Y18-1038,N13-1090,0,0.0205342,"Missing"
Y18-1038,W15-3911,0,0.0302346,"Missing"
Y18-1038,P02-1040,0,0.103247,"he Adam optimizer to learn the weights of the network with a default learning rate of 0.001. For decoding, the beam search was assigned the size of 6. All the RNN hyper-parameters were determined by tuning on the development set. similar to Word Error Rate. These metrics were automatically evaluated with a tool, MultEval version 0.5.15 (Clark et al., 2011). To evaluate our proposed approach, we implemented five systems (Table 2): 4.2 Table 2: Evaluation of scoring for all systems: BLEU, TER and PER. Evaluation We use different evaluation metrics such as BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), Translation Error Rate (TER) (Snover et al., 2009), and Phoneme Error Rate (PER), that is 2 https://github.com/letter-to-phoneme/ m2m-aligner/ 3 https://code.google.com/archive/p/ word2vec/ 4 https://github.com/lvapeab/nmt-keras/ (1) Baseline system A : phrase-based statistical machine translation (pbSMT). We implemented a pbSMT system with Moses6 (Koehn et al., 2007). We used mGIZA (Gao and Vogel, 2008) to align the corpus at the character level, and SRILM (Stolcke and others, 2002) to create a character-based 5-gram language model for the target language. (2) Baseline system B : multi-join"
Y18-1038,J17-2003,0,0.0603634,"Missing"
Y18-1038,W16-2710,0,0.036613,"Missing"
Y18-1038,W16-3702,0,0.0506043,"Missing"
