1991.mtsummit-papers.7,E91-1050,0,0.12652,"Missing"
1995.tc-1.11,J94-4005,1,0.89368,"Missing"
1995.tc-1.11,H90-1021,0,0.204956,". There are now a number of high-profile projects with large budgets, the most well-known being the German Verbmobil effort. At the moment, the best systems are at the level of advanced prototypes; making projections from current performance, it seems reasonable to hope that these could be developed into commercially interesting systems within a time-scale of about another five years. This paper describes a project centered around one such advanced prototype, the Spoken Language Translator (SLT) system. SLT can translate spoken English utterances from the domain of air travel planning (ATIS; (Hemphill et al., 1990)) into spoken Swedish or French, using a vocabulary of about 1200 stem entries. Table 1 shows some examples of typical sentences from this domain, together with French translations produced by the system. The Swedish version of SLT has been operational since June 1993, and has been publicly demonstrated on numerous occasions. The French version became operational fairly recently, and was publicly demonstrated for the first time at the Language Engineering Convention in London in October 1995. An initial French-to-Spanish version of the system also exists. By the middle of 1996, we expect to ha"
1995.tc-1.11,H93-1042,1,0.83877,"Missing"
1995.tc-1.11,H94-1040,1,0.83469,"Missing"
2004.tmi-1.3,C02-1095,0,0.0922259,"ss. In the other direction, academics have become more interested in grammar-based methods. The literature now contains descriptions of several research systems built using rule-based methods, which successfully use mixed-initiative strategies and complex grammars (Stent et al. 1999, Rayner et. al. 2000, Lemon et al. 2001, Rayner et. al. 2001a). Much of this work has involved the idea of compiling grammar-based language models out of descriptions written in higher-level formalisms, in particular unification grammars (Moore 1998, Kiefer & Krieger 2000, Dowding et al. 2001, Rayner et al. 2001b, Bos 2002). Given that a great deal of practical and theoretical work is going on using both statistical and rule-based methods, it is remarkable that there is almost no reported work attempting a systematic comparison of the two approaches. The only example known to us is (Knight et al. 2001), in which one of the present authors participated. In this study, two speech understanding systems were constructed for the same domain, a medium-vocabulary command and control task. Both systems ran on the Nuance 7 platform. The first had a hand-coded grammar-based language model (GLM), compiled using the standar"
2004.tmi-1.3,P01-1022,1,0.849306,"ce&apos;s SayAnythingTM module, with some success. In the other direction, academics have become more interested in grammar-based methods. The literature now contains descriptions of several research systems built using rule-based methods, which successfully use mixed-initiative strategies and complex grammars (Stent et al. 1999, Rayner et. al. 2000, Lemon et al. 2001, Rayner et. al. 2001a). Much of this work has involved the idea of compiling grammar-based language models out of descriptions written in higher-level formalisms, in particular unification grammars (Moore 1998, Kiefer & Krieger 2000, Dowding et al. 2001, Rayner et al. 2001b, Bos 2002). Given that a great deal of practical and theoretical work is going on using both statistical and rule-based methods, it is remarkable that there is almost no reported work attempting a systematic comparison of the two approaches. The only example known to us is (Knight et al. 2001), in which one of the present authors participated. In this study, two speech understanding systems were constructed for the same domain, a medium-vocabulary command and control task. Both systems ran on the Nuance 7 platform. The first had a hand-coded grammar-based language model ("
2004.tmi-1.3,2000.iwpt-1.15,0,0.00995447,"deling tools, like Nuance&apos;s SayAnythingTM module, with some success. In the other direction, academics have become more interested in grammar-based methods. The literature now contains descriptions of several research systems built using rule-based methods, which successfully use mixed-initiative strategies and complex grammars (Stent et al. 1999, Rayner et. al. 2000, Lemon et al. 2001, Rayner et. al. 2001a). Much of this work has involved the idea of compiling grammar-based language models out of descriptions written in higher-level formalisms, in particular unification grammars (Moore 1998, Kiefer & Krieger 2000, Dowding et al. 2001, Rayner et al. 2001b, Bos 2002). Given that a great deal of practical and theoretical work is going on using both statistical and rule-based methods, it is remarkable that there is almost no reported work attempting a systematic comparison of the two approaches. The only example known to us is (Knight et al. 2001), in which one of the present authors participated. In this study, two speech understanding systems were constructed for the same domain, a medium-vocabulary command and control task. Both systems ran on the Nuance 7 platform. The first had a hand-coded grammar-b"
2004.tmi-1.3,P03-2024,1,0.63371,"slated by the system, and the patient responds nonverbally, for example by nodding or shaking their head, or pointing. The key requirement of the project is a high level of accuracy: doctors are only interested in using systems they can trust. Since speech recognition can never be wholly reliable, the user interface is structured so that the initial recognition hypothesis is echoed back to the user, who has the option to abort further processing if necessary. Reliability thus means reliability on the utterances which the user considers to be correctly recognized. The current prototype system (Rayner et al. 2003) translates questions in a headache domain from English into Japanese or French, using a vocabulary of about 200 words; a production version would need to cover at least another 25 to 50 similar subdomains. The recognition component for the SLM and GLM version was built with a training corpus of 450 utterances. The initial set of training utterances were supplied to us by a physician, who then interacted with us to expand it by adding enough synonyms and alternative phrasings to make the coverage reasonably habitable. Later versions may use larger development sets, but it is unreasonable to as"
2004.tmi-1.3,E03-2010,1,0.743526,"slated by the system, and the patient responds nonverbally, for example by nodding or shaking their head, or pointing. The key requirement of the project is a high level of accuracy: doctors are only interested in using systems they can trust. Since speech recognition can never be wholly reliable, the user interface is structured so that the initial recognition hypothesis is echoed back to the user, who has the option to abort further processing if necessary. Reliability thus means reliability on the utterances which the user considers to be correctly recognized. The current prototype system (Rayner et al. 2003) translates questions in a headache domain from English into Japanese or French, using a vocabulary of about 200 words; a production version would need to cover at least another 25 to 50 similar subdomains. The recognition component for the SLM and GLM version was built with a training corpus of 450 utterances. The initial set of training utterances were supplied to us by a physician, who then interacted with us to expand it by adding enough synonyms and alternative phrasings to make the coverage reasonably habitable. Later versions may use larger development sets, but it is unreasonable to as"
2004.tmi-1.3,W00-0311,1,0.879114,"Missing"
2004.tmi-1.3,P99-1024,0,0.0383449,"language interface for a new application in a timely fashion, rule-based methods are often the only practicable alternative. Over the last few years, however, the above picture has become more blurred. Commercial platform vendors have begun to introduce statistical modeling tools, like Nuance&apos;s SayAnythingTM module, with some success. In the other direction, academics have become more interested in grammar-based methods. The literature now contains descriptions of several research systems built using rule-based methods, which successfully use mixed-initiative strategies and complex grammars (Stent et al. 1999, Rayner et. al. 2000, Lemon et al. 2001, Rayner et. al. 2001a). Much of this work has involved the idea of compiling grammar-based language models out of descriptions written in higher-level formalisms, in particular unification grammars (Moore 1998, Kiefer & Krieger 2000, Dowding et al. 2001, Rayner et al. 2001b, Bos 2002). Given that a great deal of practical and theoretical work is going on using both statistical and rule-based methods, it is remarkable that there is almost no reported work attempting a systematic comparison of the two approaches. The only example known to us is (Knight et"
2005.eamt-1.8,A97-1001,0,0.0737007,"Missing"
2005.eamt-1.8,W02-0710,1,0.794173,"Missing"
2005.eamt-1.8,P03-2024,1,0.844535,"Missing"
2005.eamt-1.8,2005.eamt-1.8,1,0.106122,"Missing"
2005.eamt-1.8,2004.tmi-1.3,1,\N,Missing
2005.jeptalnrecital-long.17,H01-1007,0,0.0462992,"Missing"
2005.jeptalnrecital-long.17,2004.tmi-1.3,1,0.912361,"Missing"
2005.jeptalnrecital-long.17,P03-2024,1,0.927157,"Missing"
2005.jeptalnrecital-long.17,E03-2010,1,0.889795,"Missing"
2005.mtsummit-papers.25,E03-2010,1,0.865288,"Missing"
2005.mtsummit-papers.25,2005.eamt-1.8,1,0.80735,"ality of pain, and the factors that increase or decrease the pain. The answers to these questions can be successfully communicated by a limited number of one or two word responses (e.g. yes/no, left/right, numbers) or even gestures (e.g. nodding or shaking the head, pointing to an area of the body). Translation can thus be unidirectional. In order to obtain an accurate translation, the system uses a grammar-based speech recogniser. For this type of application a grammar-based approach appears to give better results than a statistical-based recognition (Knight et al., 2001, Rayner et al. 2004, Bouillon et al. 2005). Diagnosis seems to be a very convergent sublanguage, where it is possible to guess the syntactic structures that a doctor will use, and thus to describe them in a grammar. The advantage of this approach is that the grammar enforces more global constraints on the recognized utterance than the simple bigrams or trigrams of a statistical language model: more complete sentences are thus well recognized, which improves the translation. The drawback is the lack of robustness: if the sentence structure is not in the grammar or if a word is not in the lexicon, the recognition completely fails. Helpi"
2005.mtsummit-papers.25,lavie-etal-2002-nespole,0,0.0623047,"Missing"
2005.mtsummit-papers.25,W02-0710,1,\N,Missing
2005.mtsummit-papers.25,2004.tmi-1.3,1,\N,Missing
2006.jeptalnrecital-long.6,P01-1022,0,0.0712505,"Missing"
2006.jeptalnrecital-long.6,J81-4003,0,0.605542,"Missing"
2006.jeptalnrecital-long.6,2005.jeptalnrecital-long.17,1,0.869615,"Missing"
2007.jeptalnrecital-poster.5,W06-3703,0,0.172189,"Missing"
2007.jeptalnrecital-poster.5,W02-0203,0,0.0701878,"Missing"
2007.jeptalnrecital-poster.5,W06-3711,0,0.0584704,"Missing"
2007.jeptalnrecital-poster.5,2005.jeptalnrecital-long.17,1,0.888808,"Missing"
2007.jeptalnrecital-poster.5,W06-3701,0,0.053261,"Missing"
2007.jeptalnrecital-poster.5,2005.mtsummit-papers.25,1,0.621309,"Missing"
2008.eamt-1.24,bouillon-etal-2008-developing,1,0.862267,"Missing"
2008.eamt-1.24,2005.eamt-1.8,1,0.901192,"Missing"
2008.eamt-1.24,2006.jeptalnrecital-long.6,1,0.8399,"Missing"
2008.eamt-1.24,2007.jeptalnrecital-poster.5,1,0.769435,"Missing"
2008.eamt-1.24,W06-3706,0,0.0315393,"Missing"
2008.eamt-1.24,W06-3703,0,0.0434588,"Missing"
2008.eamt-1.24,N04-3010,0,0.0304759,"Missing"
2008.eamt-1.24,2005.mtsummit-papers.25,1,\N,Missing
2009.mtsummit-plenaries.6,2002.eamt-1.12,0,0.0711497,"Missing"
2011.freeopmt-1.5,P03-1021,0,0.005876,"Missing"
2011.freeopmt-1.5,P00-1056,0,0.061546,"Missing"
2011.freeopmt-1.5,2010.eamt-1.39,1,0.889465,"the rule-based omponents and the orpus data used to onstru t them, and then use the same resour es, together with mainstream tools, to bootstrap statisti al proF. S´ anchez-Mart´ınez, J.A. P´ erez-Ortiz (eds.) Proceedings of the Second International Workshop on Free/Open-Source Rule-Based Machine Translation, p. 21–28 Barcelona, Spain, January 2011. http://hdl.handle.net/10609/5647 essing omponents. In (Ho key et al., 2008), we adapted and improved methods originally des ribed in (Jurafsky et al., 1995) to bootstrap a statisti al re ogniser from the original rule-based one. More re ently, in (Rayner et al., 2010) we used similar methods to bootstrap statisti al ma hine translation models. In this urrent paper, we ombine the results of the previous two sets of experiments to build a fully bootstrapped statisti al spee h translation system, whi h we then ompare with the original rule-based one, and also with a hybrid system whi h ombines rule-based and statisti al pro essing. Interestingly, although (Rayner et al., 2010) demonstrated that a bootstrapped statisti al ma hine translation system is able to add substantial robustness to the original rule-based one when both are run on text data, this robustn"
2012.amta-papers.25,P07-2045,0,0.0030871,"nnotator agreement figures we present below suggests that judges were pleased with the conditions offered and worked conscientiously. Restricting judges to a bilingual country appears to be important. We tried removing this condition, and obtained faster turnaround time but much poorerquality results, with weak inter-annotator agreement and many anomalous judgements suggesting that judges lacked fluency in one or the other language or were not taking the job seriously. 3.2 Training Data and SMT Systems The SMT baseline system was a phrase-based system trained with the standard Moses pipeline (Koehn et al., 2007), using GIZA++ (Och and Ney, 2000) for word alignment and SRILM (Stolcke, 2002) for the estimation of 5-gram Kneser-Ney smoothed (Kneser and Ney, 1995) language models. For training the translation and lexicalised reordering models we used the releases of europarl and news-commentary provided for the WMT12 shared task (Callison-Burch et al., 2012), together with a dataset from the ACCEPT project consisting mainly of technical product manuals and marketing materials. This last data set covers the same topics as the forums we wish to translate (so it may be considered as “in-domain”) but it is a"
2012.amta-papers.25,2005.mtsummit-papers.11,0,0.0214548,"ges. In this paper, we will only consider the automatic stages of the translation process in the French-toEnglish translation pair; we wish to translate French forum data for the benefit of English-speaking users. This rapidly exposes a mismatch between training and test data at the level of register. Forum posts are typically informal in tone. The vast majority of available aligned French/English training data is however formal: a typical example, which we will use in the rest of the paper as our primary resource, is the proceedings of the European parliament, the ubiquitous Europarl corpus (Koehn, 2005). Similar problems would have arisen if we had used other corpora, e.g. the UN corpus2 , Callison-Burch’s giga corpus3 or the Canadian Hansard corpus4 . French is a language where the gap between formal and informal usage is large. (For purposes of comparison, it is much larger than in English, though perhaps not as large as in Arabic). We will focus on two immediate problems, verb forms and questions. French, like most European languages (English is the major exception) has two secondperson pronouns, the formal vous and the informal tu (accusative form te, elided to t’ before a vowel). Each p"
2012.amta-papers.25,J04-2003,0,0.0997549,"Missing"
2012.amta-papers.25,P00-1056,0,0.10894,"nt below suggests that judges were pleased with the conditions offered and worked conscientiously. Restricting judges to a bilingual country appears to be important. We tried removing this condition, and obtained faster turnaround time but much poorerquality results, with weak inter-annotator agreement and many anomalous judgements suggesting that judges lacked fluency in one or the other language or were not taking the job seriously. 3.2 Training Data and SMT Systems The SMT baseline system was a phrase-based system trained with the standard Moses pipeline (Koehn et al., 2007), using GIZA++ (Och and Ney, 2000) for word alignment and SRILM (Stolcke, 2002) for the estimation of 5-gram Kneser-Ney smoothed (Kneser and Ney, 1995) language models. For training the translation and lexicalised reordering models we used the releases of europarl and news-commentary provided for the WMT12 shared task (Callison-Burch et al., 2012), together with a dataset from the ACCEPT project consisting mainly of technical product manuals and marketing materials. This last data set covers the same topics as the forums we wish to translate (so it may be considered as “in-domain”) but it is almost exclusively in the formal re"
2013.mtsummit-posters.7,2009.mtsummit-btm.7,0,0.154134,"nfluenced by the current localisation industry demands. Quicker turnaround times are required for high translation volume rates at a low cost, but quality expectations remain the same (Van Genabith, 2012). Although Translation Memories (TMs) initially appeared to be a suitable solution to challenge those requirements, Machine Translation (MT) has emerged as an efficient alternative, both for translators and translation end users (O’Brien, 2012; Plitt and Masselot, 2010). Moreover, recent studies have suggested that a combination of both systems could result in a significant productivity gain (Guerberof, 2009; He, 2011). Nevertheless, efficiency in the use of such solutions may also vary depending on several contextual factors. For instance, light has already been shed on source text characteristics (complexity, ambiguity, style) or TM content types (Tatsumi and Roturier, 2010; Yamada, 2011) as variables that can have implications on the post-editing results. The work presented in this paper is part of the Automated Community Content Editing PorTal (ACCEPT) European research project 1 , where adequacy receives greater importance than other factors precisely due to the source text nature. ACCEPT ai"
2013.mtsummit-posters.7,2011.mtsummit-tutorials.2,0,0.0974555,"current localisation industry demands. Quicker turnaround times are required for high translation volume rates at a low cost, but quality expectations remain the same (Van Genabith, 2012). Although Translation Memories (TMs) initially appeared to be a suitable solution to challenge those requirements, Machine Translation (MT) has emerged as an efficient alternative, both for translators and translation end users (O’Brien, 2012; Plitt and Masselot, 2010). Moreover, recent studies have suggested that a combination of both systems could result in a significant productivity gain (Guerberof, 2009; He, 2011). Nevertheless, efficiency in the use of such solutions may also vary depending on several contextual factors. For instance, light has already been shed on source text characteristics (complexity, ambiguity, style) or TM content types (Tatsumi and Roturier, 2010; Yamada, 2011) as variables that can have implications on the post-editing results. The work presented in this paper is part of the Automated Community Content Editing PorTal (ACCEPT) European research project 1 , where adequacy receives greater importance than other factors precisely due to the source text nature. ACCEPT aims at explo"
2013.mtsummit-posters.7,2010.amta-papers.27,0,0.0380253,"Missing"
2013.mtsummit-posters.7,2010.jec-1.6,0,0.231406,"o be a suitable solution to challenge those requirements, Machine Translation (MT) has emerged as an efficient alternative, both for translators and translation end users (O’Brien, 2012; Plitt and Masselot, 2010). Moreover, recent studies have suggested that a combination of both systems could result in a significant productivity gain (Guerberof, 2009; He, 2011). Nevertheless, efficiency in the use of such solutions may also vary depending on several contextual factors. For instance, light has already been shed on source text characteristics (complexity, ambiguity, style) or TM content types (Tatsumi and Roturier, 2010; Yamada, 2011) as variables that can have implications on the post-editing results. The work presented in this paper is part of the Automated Community Content Editing PorTal (ACCEPT) European research project 1 , where adequacy receives greater importance than other factors precisely due to the source text nature. ACCEPT aims at exploring the potential of using Statistical Machine Translation (SMT), complemented by pre-edition and post-edition modules, for translating community-generated content. Information exchange through specialized Web fora is becoming increasingly popular; however, up"
2013.mtsummit-wptp.6,2007.mtsummit-papers.1,0,0.0214519,"mmunity content by investigating minimally-intrusive preediting techniques, SMT improvement methods and post-editing strategies. Within this project, the forums used are those of Symantec, one of the partners in the project. Pre-edition is carried out through the Acrolinx IQ engine and translation is done with a phrase-based Moses system. Although several studies have explored the potential of MT of forum and user-generated content (Carrera et al, 2009; Roturier and Bensadoun, 2011; Jiang et al, 2012), few of them have looked into the role of pre- and post-editing as MT complementary modules (Aikawa et al, 2007). In previous work (Gerlach et al., 2013), we have shown that it is possible to develop preediting rules that significantly improve MT output quality, where improvement was assessed through comparative evaluation. In this paper we intend to investigate whether pre-editing rules that have a positive impact on the raw SMT outSharon O’Brien, Michel Simard and Lucia Specia (eds.) Proceedings of MT Summit XIV Workshop on Post-editing Technology and Practice, Nice, September 2, 2013, p. 45–53. c 2013 The Authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, att"
2013.mtsummit-wptp.6,bredenkamp-etal-2000-looking,0,0.652544,"valuation is a valid method to evaluate and select such rules, thus justifying the use of this evaluation method for the ACCEPT project. In the next sections (2 and 3), we briefly describe the pre-editing approach used in the ACCEPT project. In section 3 we describe the experimental setup and the methodology followed. The data obtained for each experiment is analysed in section 4. Conclusions and future work are presented in section 5. 2 Pre-edition in ACCEPT In ACCEPT, pre-edition is carried out through the Acrolinx IQ engine, which supports spelling, grammar, style and terminology checking (Bredenkamp et al, 2000). This rule-based engine follows a phenomena-oriented approach to language checking, using a combination of NLP components such as a morphological analyser and a POS tagger to obtain linguistic annotations which can be used to define complex linguistic objects. These are then used in declarative rules written in a formalism similar to regular expressions that marks phenomena that should be pre-edited. Rules can also include correction suggestions, making the pre-editing process semi-automatic, where users only have to accept suggestions provided by the system. The Symantec community will have"
2013.mtsummit-wptp.6,2012.amta-commercial.8,0,0.385718,"Missing"
2013.mtsummit-wptp.6,2013.mtsummit-posters.7,1,0.809091,"s, lack of attention and hesitation to seriously reformulate the MT output, which can at least partially be explained by the participants profiles and insights described in the next section. 4.4 Questionnaire. Insights from participants. After the post-editing task, we asked participants to complete an anonymous questionnaire to establish their profiles and gather their insights about the post-editing task. This questionnaire was based on the questionnaire used in another experiment performed at FTI, also involving translation students, texts from the same forum and the same MT system (Morado Vázquez et al., 2013), where globally feedback was very positive. From the analysis of the answers provided, we gathered the following information. All participants claimed to translate about 250 words per hour on an average 8-hour day of work, but had little experience as professional translators (only one claimed to have been working as a freelance for 2 years) and had hardly ever postedited MT-output before. As for CAT tools, one only uses them when required to do so and the other two have tried them but do not use them on a daily basis. Participants were not familiar with the topic or with Symantec products. T"
2013.mtsummit-wptp.6,2007.mtsummit-papers.46,0,0.129275,"Missing"
2013.mtsummit-wptp.6,2012.amta-papers.25,1,0.806954,"e SMT output Raw Tu as lu le tuto sur le forum? Pre-edited As-tu lu le tutoriel sur le forum? You have read the Tuto on the forum? Have you read the tutorial on the forum? Table 2. Example for rule set 2 Finally, a third set (Set 3) contains the rules for the machine that should not be visible to endusers. The rules in this set modify word order and frequent badly translated words or expressions to produce variants better suited to MT. One important rule converts the informal second person (Tu as compilé?) into its formal correspondent (Vous avez compilé?), more frequent in the training data (Rayner et al, 2012). Another rule deals with French clitics that are easily confused with definite articles, replacing them with less ambiguous structures. Examples are shown in Table 3. 47 In the rest of the paper we describe the experimental setup with the different tasks, the evaluation methodology and the results obtained. 3 3.1 Experiment Setup and Methodology Corpus The data used for this study is extracted from the French Symantec forums, where users discuss technical problems with anti-virus and other security software. In order to create a representative corpus, we selected 684 sentences from the data p"
2013.mtsummit-wptp.6,2011.mtsummit-papers.27,0,0.0304277,"technical information or to exchange problems and solutions to technical issues. Since the users contributing to the content are mainly domain specialists but not professional writers, the text quality cannot be compared with usual publishable content. In the context of a forum, where the focus is on solving problems, linguistic accuracy is often not a priority. Spelling, grammar and punctuation conventions are not always respected (cf. Figure 1). The language used is closer to spoken language, using informal syntax, colloquial vocabulary, abbreviations and technical terms (Jiang et al, 2012; Roturier and Bensadoun, 2011). Correcting or reformulating UGC is therefore not only interesting to improve readability, but also needed to improve machinetranslatability. J'ai redémarrer l'ordi (apparition de la croix rouge) mais pas besoin de restaurer le système:Toute ces mises à jour on été faite le 201303-13 Figure 1. Example from a forum post showing errors (agreement, word confusions) and word usage (abbreviations) typical for technical UGC The work presented in this paper is part of the Automated Community Content Editing PorTal (ACCEPT) research project and focusses on the relationship between pre-editing and pos"
2013.mtsummit-wptp.6,2006.amta-papers.25,0,0.0270648,"ve suggestions and can be applied by selecting an item in a list. 1 We apply one of the common definitions of outliers using the interquartile range (IQR): lower than the 1 st quartile minus 1.5*IQR or greater than the 3rd quartile plus 1.5*IQR. 50 Combined time for 138 sentences (mins) PE1 Pre-editing Postediting Total PE2 Raw Preedited PE3 Raw Preedited Raw Preedited - 16 - 16 - 16 53 29 98 56 109 54 53 46 98 81 139 78 Table 9. Combined pre- and post-editing times As another indicator of post-editing effort in terms of number of edit operations, we computed the Translation Error Rate (TER) (Snover et al., 2006) for each of the two MT outputs (raw and pre-edited) using the three corresponding postedited versions as reference. The case sensitive TER score for the translation of the raw source is 20.17, the score for the translation of the preedited source is 10.76, indicating a lower number of edits for the pre-edited version. 4.3 many places). While our data is insufficient to quantify this claim, this observation suggests that pre-editing can also have a positive impact on final post-edited translation quality. Table 11 shows the error counts by category, averaged over the three post-editors. Mistra"
2014.lilt-10.2,baur-etal-2014-using,1,0.532415,"tested in conjunction with one of their courses (Bouillon et al., 2011a); the topics covered included “greeting”, “talking about my family” and “scheduling a meeting”. A modified and abbreviated version of this course was adapted for use on mobile devices, and also tested over AMT; this work is described in detail in the next section. Most recently, we have been developing an interactive multimedia course for teaching English to beginner German-speaking school students; some examples are shown earlier in §2.5. A first evaluation with real students was carried out in late 2013 and early 2014 (Baur et al., 2014, Tsourakis et al., 2014). In the next section, we describe in detail some of the more substantial evaluations we have carried out using the French L2 courses. 4 Evaluations The central question we consider is an apparently simple one: does the system help students improve their generative language skills? Here, we summarise from this point of view the results of three concrete experiments carried out between 2011 and 2013. One-day experiment using French/Chinese system A typical early study was the one described in (Bouillon et al., 2011b), where the subjects were 10 Chinese-speaking computer"
2014.lilt-10.2,fuchs-etal-2012-scalable,1,0.800779,"g dialogue management, application integration, and large-scale grammar-based language processing on the server, rather than just returning the results of recognition to the client. Another important difference is that speech is passed to the recognition processes in the form of files, rather than using streaming audio. Although this goes against the currently prevailing wisdom, we have found that there are compensating advantages, and that the performance hit, with a little care, can be reduced to only a couple of hundred milliseconds per recognition operation. Full details are presented in (Fuchs et al., 2012). By moving almost all processing to the server, the client can be kept very simple. It only needs to be responsible for the graphical user interface, maintaining a small amount of state logic, performing recording and playback of audio, and requesting services from the remote peer. Versions of the client for standard browsers have been developed using Flash 11 in combination with ActionScript 3.0. An important aspect of the GUI is the way the recognition button is used. Due to the limitations of the target platform (lack of an endpointing mechanism), we have adopted a push-and-hold solution,"
2014.lilt-10.2,rayner-etal-2012-evaluating,1,0.886137,"driven by small corpora typically containing a few hundred examples. The scheme is explained in detail in (Rayner et al., 2006), which also includes a thorough description of the English resource grammar. Similar grammars have since been developed for French, German and Japanese. These have been further extended to cover related languages by a parameterization process. In particular, the French grammar has been extended into a shared grammar which covers French, Spanish and Catalan (Bouillon et al., 2007), and the English grammar has been similarly extended to cover both English and Swedish (Rayner et al., 2012b). The Regulus resource grammars are also parameterized to support 1 www.nuance.com CALL-SLT: A Spoken CALL System / 5 multiple types of semantic representation. In all the work reported here, the semantic formalism used is Almost Flat Functional Semantics (AFF; (Rayner et al., 2008)), a minimal formalism where clauses are represented as unordered lists of elements tagged with functional roles. For example, “Could you give me directions to the zoo?” is represented as the structure [null=[utterance_type, ynq], agent=[pronoun, you], null=[modal, could], null=[action, give], null=[voice, active]"
2014.lilt-10.2,C08-1090,1,0.818402,"ese have been further extended to cover related languages by a parameterization process. In particular, the French grammar has been extended into a shared grammar which covers French, Spanish and Catalan (Bouillon et al., 2007), and the English grammar has been similarly extended to cover both English and Swedish (Rayner et al., 2012b). The Regulus resource grammars are also parameterized to support 1 www.nuance.com CALL-SLT: A Spoken CALL System / 5 multiple types of semantic representation. In all the work reported here, the semantic formalism used is Almost Flat Functional Semantics (AFF; (Rayner et al., 2008)), a minimal formalism where clauses are represented as unordered lists of elements tagged with functional roles. For example, “Could you give me directions to the zoo?” is represented as the structure [null=[utterance_type, ynq], agent=[pronoun, you], null=[modal, could], null=[action, give], null=[voice, active], object=[abstract, directions] indobj=[pronoun, i], to_loc=[loc, zoo]] 2.3 Using interlingua to display prompts The AFF representations produced by speech recognition and parsing are translated into a language-neutral form, also expressed using AFF. The minimal list-based format mean"
2014.lilt-10.2,rayner-etal-2010-multilingual,1,0.824828,"ample is the EduSpeak 2010)), but the basic scheme is simple: the system plays the student a recorded sentence, asks them to imitate it, and then rates them on the accuracy of their imitation, giving advice if appropriate on how to improve pronunciation or prosody. It is easy to believe that this is useful, but it is also very limited in scope: the student is given no opportunity to practice spontaneous spoken generation skills. A more ambitious approach is to design an application where the student can respond flexibly to the system’s prompts. The project we describe in this paper, CALL-SLT (Rayner et al., 2010), is based on an idea originating with (Wang and Seneff, 2007); a related application, described in (Johnson and Valente, 2009), is TLTCS. The system prompts the user in some version of the L1, indicating in an abstract or indirect fashion what they are supposed to say; the student speaks in the L2, and the system provides a response based on speech recognition and language processing. We have built several prototypes on this basic pattern, exploring different language-pairs and strategies. For example, in a minimal version configured to teach French to English-speaking students, a prompt migh"
2014.lilt-10.2,P99-1024,0,0.128389,"context-free (CFG) grammars that can be compiled into language models and also used for parsing. It would be possible to write these grammars by hand, though doing so involves the usual problems, given that CFG is not a very expressive formalism; it is hard to model any non-trivial linguistic phenomena without producing an extremely large grammar that is in practice almost impossible to extend or maintain. A well-known method for addressing these issues is to specify the grammar in some higher-level formalism — most obviously, some kind of feature grammar — and compile this down to CFG form (Stent et al., 1999). This time, the problem is in another direction. Even if a substantial, linguistically motivated feature grammar can in principle be expanded out to a CFG grammar (this is of course by no means guaranteed), the resulting grammar will probably be so large that it exceeds the practical resource limits imposed by the speech recognition framework. For these reasons, grammars that can actually be used as language models need to be domain-specific; this, unfortunately, conflicts with the natural desire to make the grammars general and reusable. The Regulus system steers a middle course between thes"
2014.lilt-10.2,N07-1059,0,0.0306049,": the system plays the student a recorded sentence, asks them to imitate it, and then rates them on the accuracy of their imitation, giving advice if appropriate on how to improve pronunciation or prosody. It is easy to believe that this is useful, but it is also very limited in scope: the student is given no opportunity to practice spontaneous spoken generation skills. A more ambitious approach is to design an application where the student can respond flexibly to the system’s prompts. The project we describe in this paper, CALL-SLT (Rayner et al., 2010), is based on an idea originating with (Wang and Seneff, 2007); a related application, described in (Johnson and Valente, 2009), is TLTCS. The system prompts the user in some version of the L1, indicating in an abstract or indirect fashion what they are supposed to say; the student speaks in the L2, and the system provides a response based on speech recognition and language processing. We have built several prototypes on this basic pattern, exploring different language-pairs and strategies. For example, in a minimal version configured to teach French to English-speaking students, a prompt might be the text string: REQUEST HAMBURGER and the student will b"
2014.tc-1.24,fuchs-etal-2012-scalable,1,\N,Missing
2014.tc-1.8,bredenkamp-etal-2000-looking,0,0.0777808,"ng do not necessarily go hand in hand. The paper is organised as follows. In Section 2, we show how post-editing research is performed in ACCEPT and describe the rules developed for French. In Section 3, we describe the experimental setup and provide details about data, tasks and participants. The results are analysed in Section 4, and conclusions and future work are presented in Section 5. 2. Post-editing in ACCEPT In the ACCEPT project, post-editing rules, as well as pre-editing rules, are developed using the technology developed by one of our project partners, i.e., the Acrolinx IQ engine (Bredenkamp et al, 2000). This rule-based engine uses a combination of shallow NLP components enabling the development of declarative rules, written in a formalism similar to regular expressions, based on the syntactic tagging of the text. A sample rule is displayed in Figure 1. TRIGGER(80) == [@ne]? @auxFin^1 [@adv]* @verbInf^2 -&gt; ($aux, $inf) -&gt; {mark: $aux, $inf;} Figure 1: Title Rules can be applied through the ACCEPT portal interface (Seretan et al., 2014) or directly in any forum interface, using specific plugins that allow to check compliance with the rules (ACCEPT D5.6; Roturier et al., 2013). The ACCEPT part"
2014.tc-1.8,2013.mtsummit-wptp.6,1,0.85755,"Missing"
2014.tc-1.8,2012.amta-commercial.8,0,0.0231977,"ed by post-editors in the final output, hence the importance of considering both readability and post-editing effort in the evaluation of post-editing strategies. 1. Introducción Since the emergence of the Web 2.0 paradigm, user-generated content (UGC) represents a large share of the informative content available nowadays. Online communities share technical information and exchange solutions to technical issues through forums and blogs. However, the uneven quality of UGC can hinder both readability and machine-translatability, thus preventing sharing of knowledge between language communities (Jiang et al., 2012; Roturier and Bensadoun, 2011). 1 The ACCEPT project aims to improve the Statistical Machine Translation (SMT) of community content through minimally-intrusive pre-editing techniques, SMT improvement methods and post-editing strategies. The project targets two specific data domains: the technical forum domain, represented by posts in the Norton Community forum, and the medical domain, illustrated by Translators without Borders documents written by health professionals. 1 http://www.accept-project.eu/ 66 Translating and The Computer 36 During the first year of the project, we found that pre-ed"
2014.tc-1.8,2013.mtsummit-wptp.5,0,0.0138545,"ormalism similar to regular expressions, based on the syntactic tagging of the text. A sample rule is displayed in Figure 1. TRIGGER(80) == [@ne]? @auxFin^1 [@adv]* @verbInf^2 -&gt; ($aux, $inf) -&gt; {mark: $aux, $inf;} Figure 1: Title Rules can be applied through the ACCEPT portal interface (Seretan et al., 2014) or directly in any forum interface, using specific plugins that allow to check compliance with the rules (ACCEPT D5.6; Roturier et al., 2013). The ACCEPT partners have so far explored several approaches to post-editing: manual vs automatic, monolingual vs bilingual (ACCEPT D7.2 and D2.4; Mitchell et al., 2013). For French texts machine-translated from English, we have focused on automatic monolingual rules for various reasons. Surface errors abound in machine-translated French texts. These errors seem a good target for source-independent lightweight rules that can be developed with simple patterns and 67 Translating and The Computer 36 shallow linguistic analysis. The automatic application of rules is motivated by two potential use scenarios. In a technical forum, where users have varied linguistic knowledge and might not have particular interest in fixing linguistic issues, automatic rule applicat"
2014.tc-1.8,2013.mtsummit-wptp.14,0,0.210877,"linx IQ engine (Bredenkamp et al, 2000). This rule-based engine uses a combination of shallow NLP components enabling the development of declarative rules, written in a formalism similar to regular expressions, based on the syntactic tagging of the text. A sample rule is displayed in Figure 1. TRIGGER(80) == [@ne]? @auxFin^1 [@adv]* @verbInf^2 -&gt; ($aux, $inf) -&gt; {mark: $aux, $inf;} Figure 1: Title Rules can be applied through the ACCEPT portal interface (Seretan et al., 2014) or directly in any forum interface, using specific plugins that allow to check compliance with the rules (ACCEPT D5.6; Roturier et al., 2013). The ACCEPT partners have so far explored several approaches to post-editing: manual vs automatic, monolingual vs bilingual (ACCEPT D7.2 and D2.4; Mitchell et al., 2013). For French texts machine-translated from English, we have focused on automatic monolingual rules for various reasons. Surface errors abound in machine-translated French texts. These errors seem a good target for source-independent lightweight rules that can be developed with simple patterns and 67 Translating and The Computer 36 shallow linguistic analysis. The automatic application of rules is motivated by two potential use"
2014.tc-1.8,W14-0310,1,0.887861,"Missing"
2014.tc-1.8,2006.amta-papers.25,0,0.148908,"Missing"
2014.tc-1.8,2012.amta-wptp.9,0,0.111619,"Missing"
2014.tc-1.8,J08-4004,0,\N,Missing
2020.eamt-1.30,P01-1038,0,0.100353,"ifically, the implicit semantic context is recovered from elements of linguistic c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. 1 Ellipsis is “a case of anaphora, where the anaphor is a null proform (zero-anaphora)” (Ginzburg and Miller, 2018) and extralinguistic context” (Ginzburg and Miller, 2018). In NLP, different studies have focused on automatic ellipsis detection and resolution either with rules (patterns or grammars) (for example, the pioneer work from Hardt, 1992) or classification techniques (for example, Hardt and Rambow, 2001; Bos and Spenader, 2011; Liu et al., 2016; KenyonDean et al., 2016; McShane and Babkin, 2016; Rønning et al., 2018). However, only few studies specifically address this problem in machine translation (MT), despite the recent interest for context modelling in neural machine translation (see for example, Bawden et al., 2018). Very recently, some qualitative studies showed the negative impact of ellipsis on generalist neural systems (DeepL, Google Translate, etc.) from a translation point of view in the English-French pair (for example, Hamza, 2019). In this paper, we focus on automatic translat"
2020.eamt-1.30,P82-1020,0,0.762919,"Missing"
2020.eamt-1.30,2007.jeptalnrecital-poster.5,1,0.628962,"rovide a way to avoid duplication (Hamza et al., 2019). In the medical dialogues we are interested in, ellipsis allows doctors to question patients in a more efficient way (Where is your pain? In the back? Is the pain severe? Moderate?) (Tanguy et al., 2011). Literal translation of these elliptical utterances is rarely possible without affecting communication, in particular with structurally different languages which do not share the same type of ellipsis. For example in Japanese, adjectival ellipsis are very informal and should be 2 https://babeldr.unige.ch/ translated by complete sentences (Bouillon et al., 2007). The following examples illustrate elliptical utterances where literal translation is problematic, as it produces agreement errors, wrong prepositions or other syntactical or grammatical issues that can make the elliptical utterance difficult to understand. Source: is the pain intense? -&gt;MT: la douleur est-elle intense Source: sudden? -&gt; MT: *soudain Source: do you have pain in your stomach? -&gt; MT: le duele el est´ omago? Source: in your head? -&gt; MT: *en la cabeza? Source: is the pain severe -&gt; MT: hageshii itami desu ka? Source: moderate? -&gt; MT: *chuuteido? The aim of this paper is to compar"
2020.eamt-1.30,E17-2068,0,0.00964008,"a distance based classification method (Xing et al., 2010). We trained two different neural classifiers: CamemBERT This classifier uses the current state-of-the-art for French based on RoBERTa (Liu et al., 2019), which is used for many NLP tasks. We used the CamemBERT pre-trained model (Martin et al., 2019) and added a classification layer on top of the model to fine-tune it with our data (Sun et al., 2019). To do so, we set-up 10 epochs using the Transformer framework for python (Wolf et al., 2020). fastText The second approach uses a sequence classification baseline based on bag of tricks (Joulin et al., 2017). We used fastText on bigrams with 100 epochs and a learning rate of 0,2. The other hyper parameters were set by default5 . Indexing In this approach, the task is to find the source variations that are the closest matches for a new utterance. To do so, each sentence was represented by a vector and a similarity metric was used to compare them. We employed two approaches to embed each sentence: tf-idf The first approach uses a customised tf-idf (Salton and Buckley, 1988), where tf-idf was applied to subword occurrences (two to four characters) in variations for a given core sentence. Common pre-"
2020.eamt-1.30,W19-4330,0,0.0203079,"Missing"
2020.eamt-1.30,P19-1292,0,0.0261583,"Missing"
2020.eamt-1.30,D16-1179,0,0.034929,"Missing"
2020.eamt-1.30,P17-4012,0,0.0113691,"urt as well?) avez-vous eu un examen du foie ? (have you had a liver exam?) avez-vous eu un contrˆole m´edical du foie ? (have you had a liver checkup?) avez-vous un cancer du foie ? (do you have liver cancer?) Table 2: Two examples of ellipsis with corresponding possible core sentence Transformer The second model relies on a transformer based architecture for machine translation (Vaswani et al., 2017) with default parameters and size6 . For both architectures, early stopping was used to reduce the number of training steps by monitoring the performance on the development set. We used OpenNMT (Klein et al., 2017) to train the models. from a recent version of the BabelDr SCFG for the abdominal diagnostic domain and consist of variation-core pairs. Table 1 summarises the number of sentences, words and vocabulary for each set. 4.4 The main data set includes 23M variations, of which 321’698 are ambiguous (i.e. sentences that can be mapped to more than one core sentence). Most of these ambiguous sentences are elliptical. Table 2 shows two examples of such sentences. The variations are mapped to the 4’132 different core sentences available for the abdominal domain. These core sentences are not represented e"
2020.eamt-1.30,W16-0705,0,0.0185998,"ered from elements of linguistic c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. 1 Ellipsis is “a case of anaphora, where the anaphor is a null proform (zero-anaphora)” (Ginzburg and Miller, 2018) and extralinguistic context” (Ginzburg and Miller, 2018). In NLP, different studies have focused on automatic ellipsis detection and resolution either with rules (patterns or grammars) (for example, the pioneer work from Hardt, 1992) or classification techniques (for example, Hardt and Rambow, 2001; Bos and Spenader, 2011; Liu et al., 2016; KenyonDean et al., 2016; McShane and Babkin, 2016; Rønning et al., 2018). However, only few studies specifically address this problem in machine translation (MT), despite the recent interest for context modelling in neural machine translation (see for example, Bawden et al., 2018). Very recently, some qualitative studies showed the negative impact of ellipsis on generalist neural systems (DeepL, Google Translate, etc.) from a translation point of view in the English-French pair (for example, Hamza, 2019). In this paper, we focus on automatic translation of ellipsis in medical dialogues, in t"
2020.eamt-1.30,P92-1002,0,0.672521,"orm. The syntax thus appears to be incomplete. More specifically, the implicit semantic context is recovered from elements of linguistic c 2020 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. 1 Ellipsis is “a case of anaphora, where the anaphor is a null proform (zero-anaphora)” (Ginzburg and Miller, 2018) and extralinguistic context” (Ginzburg and Miller, 2018). In NLP, different studies have focused on automatic ellipsis detection and resolution either with rules (patterns or grammars) (for example, the pioneer work from Hardt, 1992) or classification techniques (for example, Hardt and Rambow, 2001; Bos and Spenader, 2011; Liu et al., 2016; KenyonDean et al., 2016; McShane and Babkin, 2016; Rønning et al., 2018). However, only few studies specifically address this problem in machine translation (MT), despite the recent interest for context modelling in neural machine translation (see for example, Bawden et al., 2018). Very recently, some qualitative studies showed the negative impact of ellipsis on generalist neural systems (DeepL, Google Translate, etc.) from a translation point of view in the English-French pair (for ex"
2020.eamt-1.30,D15-1166,0,0.0557517,"Missing"
2020.eamt-1.30,2016.lilt-13.1,0,0.0256421,"authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. 1 Ellipsis is “a case of anaphora, where the anaphor is a null proform (zero-anaphora)” (Ginzburg and Miller, 2018) and extralinguistic context” (Ginzburg and Miller, 2018). In NLP, different studies have focused on automatic ellipsis detection and resolution either with rules (patterns or grammars) (for example, the pioneer work from Hardt, 1992) or classification techniques (for example, Hardt and Rambow, 2001; Bos and Spenader, 2011; Liu et al., 2016; KenyonDean et al., 2016; McShane and Babkin, 2016; Rønning et al., 2018). However, only few studies specifically address this problem in machine translation (MT), despite the recent interest for context modelling in neural machine translation (see for example, Bawden et al., 2018). Very recently, some qualitative studies showed the negative impact of ellipsis on generalist neural systems (DeepL, Google Translate, etc.) from a translation point of view in the English-French pair (for example, Hamza, 2019). In this paper, we focus on automatic translation of ellipsis in medical dialogues, in the particular context of BabelDr, a speech to speec"
2020.eamt-1.30,W19-6734,1,0.507411,"describes source language variation patterns and their mapping to core sentences is used to compile a language model used by Nuance for speech recognition. This grammar based speech recognition produces high quality results for in coverage items. To handle sentences that are out of grammar coverage, BabelDr also includes a large vocabulary recogniser. Results from this recogniser must then be mapped to the closest core sentences, a task to which several approaches have been applied, including tf-idf indexing and dynamic programming (DP, Rayner et al., 2017) and, more recently, a NMT approach (Mutal et al., 2019). The latter is one of the approaches evaluated in the present study, where it has been extended to handle elliptical utterances. 2.2 Ellipsis in BabelDr In the BabelDr context, instead of producing a literal translation of the ellipsis, we aim at mapping elliptical utterances to the closest non-elliptical core sentence, for which translations are available in the system. This presents the advantage of removing all ambiguity related to ellipsis and their translation. To resolve the ellipsis, we use context information, which in a diagnostic interview is the previous translated utterance. The p"
2020.eamt-1.30,N18-2038,0,0.0322454,"Missing"
2020.eamt-1.30,W17-4811,0,0.0394809,"Missing"
2020.eamt-1.30,P19-1116,0,0.0485042,"Missing"
2020.eamt-1.30,2020.emnlp-demos.6,0,0.0110688,". 4.2 Sequence Classification In this approach, the task is to classify each variation into a core sentence using a distance based classification method (Xing et al., 2010). We trained two different neural classifiers: CamemBERT This classifier uses the current state-of-the-art for French based on RoBERTa (Liu et al., 2019), which is used for many NLP tasks. We used the CamemBERT pre-trained model (Martin et al., 2019) and added a classification layer on top of the model to fine-tune it with our data (Sun et al., 2019). To do so, we set-up 10 epochs using the Transformer framework for python (Wolf et al., 2020). fastText The second approach uses a sequence classification baseline based on bag of tricks (Joulin et al., 2017). We used fastText on bigrams with 100 epochs and a learning rate of 0,2. The other hyper parameters were set by default5 . Indexing In this approach, the task is to find the source variations that are the closest matches for a new utterance. To do so, each sentence was represented by a vector and a similarity metric was used to compare them. We employed two approaches to embed each sentence: tf-idf The first approach uses a customised tf-idf (Salton and Buckley, 1988), where tf-i"
2020.eamt-1.40,aziz-etal-2012-pet,0,0.0245493,"totyping M T 3. 3 Support tools for teaching MT/PE To our knowledge, there are only few active opensource platforms that can be used for teaching MT: Joey NMT (Kreutzer et al., 2019), MTradum`atica (Do˘gru et al., 2017) and Interactive Teaching Tool (ITT) (Khayrallah et al., 2019). However, they do not provide all the desired features, e.g. MTradum`atica and ITT do not provide neural MT (NMT) models, nor the possibility to visualize intermediate results, and Joey NMT does not have a GUI to train and test models. A valuable resource for practicing post-editing and evaluating MT systems is PET (Aziz et al., 2012), however, this tool does not offer an integrated MT module. Using several tools in an unintegrated way may present new challenges to students, such as compatibility (e.g. file formats) or confidentiality issues. It would therefore be desirable to work on the same platform with intranet restrictions. The lack of free tools that meet our desiderata has fuelled the joint development of an opensource web platform called Machine Translation Training Tool - M T 3 . This platform aims at providing a playground for translation students and non-tech savvy users, helping them get hands-on experience wi"
2020.eamt-1.40,P17-4012,0,0.0166087,"Girletti Lise Volkart Pierrette Bouillon FTI/TIM, University of Geneva Switzerland Jonathan.Mutal@unige.ch Sabrina.Girletti@unige.ch Lise.Volkart@unige.ch Pierrette.Bouillon@unige.ch on the post-editing task. Even if the idea behind these systems sounds simple (producing the most likely translation), it can be challenging to explain to non-tech savvy students how these systems produce a final output. Currently, there are many open-source tools available to train statistical and neural MT models (the most widely used are Moses (Koehn et al., 2007) for statistical MT and TensorFlow1 or OpenNMT (Klein et al., 2017) for neural MT) or commercial tools (such as KantanMT2 or Microsoft Custom Translator3 ). However, it is difficult to integrate them in the classroom because open-source tools are mostly designed for IT professionals, who do not need a graphical user interface (GUI), as opposed to translation students; as for commercial tools, the costs are far too steep for some institutions. The Faculty of Languages of the University of C´ordoba (FL-UNC) and the Faculty of Translation and Interpreting of the University of Geneva (FTIUniGe) have been collaborating since 2017 to design and prototype a tool tha"
2020.eamt-1.40,P07-2045,0,0.0125292,"no derivative works, attribution, CCBY-ND. Jonathan Mutal Sabrina Girletti Lise Volkart Pierrette Bouillon FTI/TIM, University of Geneva Switzerland Jonathan.Mutal@unige.ch Sabrina.Girletti@unige.ch Lise.Volkart@unige.ch Pierrette.Bouillon@unige.ch on the post-editing task. Even if the idea behind these systems sounds simple (producing the most likely translation), it can be challenging to explain to non-tech savvy students how these systems produce a final output. Currently, there are many open-source tools available to train statistical and neural MT models (the most widely used are Moses (Koehn et al., 2007) for statistical MT and TensorFlow1 or OpenNMT (Klein et al., 2017) for neural MT) or commercial tools (such as KantanMT2 or Microsoft Custom Translator3 ). However, it is difficult to integrate them in the classroom because open-source tools are mostly designed for IT professionals, who do not need a graphical user interface (GUI), as opposed to translation students; as for commercial tools, the costs are far too steep for some institutions. The Faculty of Languages of the University of C´ordoba (FL-UNC) and the Faculty of Translation and Interpreting of the University of Geneva (FTIUniGe) ha"
2020.eamt-1.40,2015.mtsummit-wptp.1,0,0.0202505,"and identify areas for improvements, but also to get subjective feedback from the 1 https://www.tensorflow.org/ https://kantanmt.com/ 3 https://portal.customtranslator.azure.ai/ 2 students on its usability. 2 MT in the classroom MT is one of the topics that should be introduced to translation students in preparation for their professional life, as lacking the necessary skill-set to take on post-editor roles or other technical roles, such as language engineer or MT engineer, could have a negative impact on their future employability, as many researchers and lecturers have observed (Lara, 2019; Koponen, 2015; Doherty and Kenny, 2014; Kenny and Doherty, 2014; Rico, 2017; Temiz¨oz, 2016; Mellinger, 2017; Guerberof and Moorkens, 2019). The EMT Expert Group (2017, p. 7) “recognises that the ability to interact with MT in the translation process is now an integral part of professional translation competence”. Furthermore, as part of the technological competence (p. 9), they highlight the inclusion of “basic knowledge of MT technologies and the ability to implement MT according to potential needs”. This reflects the current need of many translation and localization companies to hire specialists with a"
2020.eamt-1.40,D19-3019,0,0.0210246,"online help groups, online tutorials, instruction manuals, and occasionally a human instructor to hold their hand”. However, a major roadblock when teaching technical content such as MT to non-technical audiences (like translation students) is a lack of suitable platforms that allow users to create MT engines without having to deal with low-level programming languages, Unix consoles or command lines. This is the main motivation for prototyping M T 3. 3 Support tools for teaching MT/PE To our knowledge, there are only few active opensource platforms that can be used for teaching MT: Joey NMT (Kreutzer et al., 2019), MTradum`atica (Do˘gru et al., 2017) and Interactive Teaching Tool (ITT) (Khayrallah et al., 2019). However, they do not provide all the desired features, e.g. MTradum`atica and ITT do not provide neural MT (NMT) models, nor the possibility to visualize intermediate results, and Joey NMT does not have a GUI to train and test models. A valuable resource for practicing post-editing and evaluating MT systems is PET (Aziz et al., 2012), however, this tool does not offer an integrated MT module. Using several tools in an unintegrated way may present new challenges to students, such as compatibilit"
2020.eamt-1.40,P02-1040,0,0.110052,"modest resources, without the need for any installation, since all operating systems include a web browser by default. As for the building blocks of the server, we have based the new version on Docker6 , an opensource Platform-as-a-Service (PaaS) that allows for the isolation of each module and its dependencies from the underlying operating system. The server creates and destroys containers dynamically to execute tasks related to training statistical MT engines with Moses, neural engines with OpenNMT, and the application of standard evaluation metrics WER, TER (Snover et al., 2006) and BLEU (Papineni et al., 2002). 5.2 GUI functionalities We have kept the main functionalities of the previous versions and added major ones, namely user management (register and authentication), persistence of user’s data (models, translations and evaluations), neural engine training capability (based on OpenNMT’s encoder-decoder model), visualization of intermediate results for statistical engines (an online visualization with no need to download) and engine sharing (for more ecological use of resources by avoiding training big engines with the same data multiple times). Screenshots provided in Figures 4 to 7 show the cur"
2020.eamt-1.40,2006.amta-papers.25,0,0.0200622,"the software on a machine with modest resources, without the need for any installation, since all operating systems include a web browser by default. As for the building blocks of the server, we have based the new version on Docker6 , an opensource Platform-as-a-Service (PaaS) that allows for the isolation of each module and its dependencies from the underlying operating system. The server creates and destroys containers dynamically to execute tasks related to training statistical MT engines with Moses, neural engines with OpenNMT, and the application of standard evaluation metrics WER, TER (Snover et al., 2006) and BLEU (Papineni et al., 2002). 5.2 GUI functionalities We have kept the main functionalities of the previous versions and added major ones, namely user management (register and authentication), persistence of user’s data (models, translations and evaluations), neural engine training capability (based on OpenNMT’s encoder-decoder model), visualization of intermediate results for statistical engines (an online visualization with no need to download) and engine sharing (for more ecological use of resources by avoiding training big engines with the same data multiple times). Screenshots provid"
2021.nlp4posimpact-1.15,W19-6734,1,0.873529,"Missing"
2021.nlp4posimpact-1.15,2020.eamt-1.30,1,0.83655,"Missing"
A92-1029,1991.mtsummit-papers.7,1,0.934944,".). 209 Compounds in A v a l a n c h e B u l l e t i n s The avalanche bulletins are issued by IFENA (the Federal Institute for the Study of Snow and Avalanches) 4 a number of times a week during the winter season, the exact frequency of their appearance depending on weather conditions. Bulletins are prepared in German, and are translated into the other official Swiss languages, French and Italian, before publication. The current state of affairs, in which the source language is exclusively German, may change in future, and for this reason it has been decided to implement a reversible system (Bouillon and Boesefeldt, 1991a; Bouillon and Boesefeldt, 1991b). Avalanche bulletins describe a fixed and specifiable semantic domain, and employ a language restricted in both vocabulary and syntactic variety. They contain a large number of compounds, with differing grammatical 2See Church and Patil (1982: p. 140ff.) for discussion. 3&quot;Envizonnement Linguistique d&apos;Unification&quot; (Estival, 1990). See also Johnson and Rosner (1989) for a description of the earlier UD system on which ET.u is based. 4The project is partially supported by IFENA. properties. It is the interpretation of compounds, together with the closely related"
A92-1029,J82-3004,0,0.0311163,"ns. Bulletins are prepared in German, and are translated into the other official Swiss languages, French and Italian, before publication. The current state of affairs, in which the source language is exclusively German, may change in future, and for this reason it has been decided to implement a reversible system (Bouillon and Boesefeldt, 1991a; Bouillon and Boesefeldt, 1991b). Avalanche bulletins describe a fixed and specifiable semantic domain, and employ a language restricted in both vocabulary and syntactic variety. They contain a large number of compounds, with differing grammatical 2See Church and Patil (1982: p. 140ff.) for discussion. 3&quot;Envizonnement Linguistique d&apos;Unification&quot; (Estival, 1990). See also Johnson and Rosner (1989) for a description of the earlier UD system on which ET.u is based. 4The project is partially supported by IFENA. properties. It is the interpretation of compounds, together with the closely related issue of structural disambiguation, which most researchers have addressed (Finin, 1980; Isabelle, 1984; Sparck Jones, 1983). In an application such as avalanche bulletin translation, however, the necessity for a deep or sophisticated analysis of compound meanings is not obviou"
A92-1029,P84-1109,0,0.183006,"semantic domain, and employ a language restricted in both vocabulary and syntactic variety. They contain a large number of compounds, with differing grammatical 2See Church and Patil (1982: p. 140ff.) for discussion. 3&quot;Envizonnement Linguistique d&apos;Unification&quot; (Estival, 1990). See also Johnson and Rosner (1989) for a description of the earlier UD system on which ET.u is based. 4The project is partially supported by IFENA. properties. It is the interpretation of compounds, together with the closely related issue of structural disambiguation, which most researchers have addressed (Finin, 1980; Isabelle, 1984; Sparck Jones, 1983). In an application such as avalanche bulletin translation, however, the necessity for a deep or sophisticated analysis of compound meanings is not obvious. On the one hand, the number of compounds appearing in the sublanguage is highly restricted (approximately 400); they may therefore be listed exhaustively, and the question of disambiguation does not arise. And on the other, the interpretation of a compound is given by its established translation - the meaning of Lawinengefahr (&apos;danger of avalanches&apos;) is just the information necessary to produce the required target lang"
A92-1029,E89-1025,0,0.0256072,"ore publication. The current state of affairs, in which the source language is exclusively German, may change in future, and for this reason it has been decided to implement a reversible system (Bouillon and Boesefeldt, 1991a; Bouillon and Boesefeldt, 1991b). Avalanche bulletins describe a fixed and specifiable semantic domain, and employ a language restricted in both vocabulary and syntactic variety. They contain a large number of compounds, with differing grammatical 2See Church and Patil (1982: p. 140ff.) for discussion. 3&quot;Envizonnement Linguistique d&apos;Unification&quot; (Estival, 1990). See also Johnson and Rosner (1989) for a description of the earlier UD system on which ET.u is based. 4The project is partially supported by IFENA. properties. It is the interpretation of compounds, together with the closely related issue of structural disambiguation, which most researchers have addressed (Finin, 1980; Isabelle, 1984; Sparck Jones, 1983). In an application such as avalanche bulletin translation, however, the necessity for a deep or sophisticated analysis of compound meanings is not obvious. On the one hand, the number of compounds appearing in the sublanguage is highly restricted (approximately 400); they may"
A92-1029,E91-1050,1,0.893712,"Missing"
A92-1029,E89-1037,0,\N,Missing
atkins-etal-2002-resources,2001.mtsummit-papers.39,1,\N,Missing
atkins-etal-2002-resources,bel-etal-2000-simple,1,\N,Missing
atkins-etal-2002-resources,calzolari-etal-2002-towards,1,\N,Missing
bouillon-etal-2002-acquisition,J93-2005,0,\N,Missing
bouillon-etal-2008-developing,H05-2014,1,\N,Missing
bouillon-etal-2008-developing,2005.mtsummit-papers.25,1,\N,Missing
bouillon-etal-2008-developing,2005.eamt-1.8,1,\N,Missing
bouillon-etal-2008-developing,2005.jeptalnrecital-long.17,1,\N,Missing
bouillon-etal-2008-developing,W07-0806,1,\N,Missing
bouillon-etal-2008-developing,W06-3702,1,\N,Missing
bouillon-etal-2012-annotating,W09-3707,0,\N,Missing
bouillon-etal-2012-annotating,P07-3013,0,\N,Missing
bouillon-etal-2012-annotating,P10-1070,0,\N,Missing
bouillon-etal-2012-annotating,2005.mtsummit-papers.11,0,\N,Missing
C08-1090,2005.eamt-1.8,1,0.935429,"Missing"
C08-1090,W06-3702,1,0.850481,"model, which produces a source-langage semantic representation. This is first translated by one set of rules into an interlingual form, and then by a second set into a target language representation. A target-language grammar, compiled into generation form, turns this into one or more possible surface strings, after which a set of generation preferences picks one out. Finally, the selected string is realised in spoken form. There is also some use of corpus-based statistical methods, both to tune the language model (Rayner et al., 2006, Section 11.5) and to drive a robust embedded help system (Chatzichrisafis et al., 2006). The treatment of syntactic structure is a carefully thought-out compromise between linguistic and engineering traditions. All grammars used are extracted from general linguistically motivated resource grammars, using corpus-based methods driven by small sets of examples (Rayner et al., 2006, Chapter 9). This results in a simpler and flatter grammar specific to the domain, whose structure is similar to the ad hoc phrasal grammars typical of engineering approaches. The treatment of semantics is however less sophisticated, and basically represents a minimal approach in the engineering tradition"
C08-1090,P02-1035,0,0.0176156,"l and Frege and views predicate calculus as the paradigm representation language. On this view of things, a c 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Approaches based in the linguistic tradition were dominant about 10 to 15 years ago, when they were used in major systems like Germany’s Verbmobil (Wahlster, 2000) and SRI’s Spoken Language Translator (Rayner et al., 2000). They are still reasonably popular today, as exemplified by major systems like PARC’s XLE (Riezler et al., 2002). The competing heritage has its roots in engineering approaches to spoken language systems, which historically have been intimately connected with Machine Learning. On this view of things, a typical semantic representation is a flat list of feature-value pairs, with the features representing semantic concepts: here, “I want a pepperoni pizza” would be represented as something like [utterance_type=request, food=pizza, type=pepperoni] It is interesting to see how little contact there has been between these two traditions. Writers on formal semantics usually treat ad hoc featurevalue representat"
C08-1090,J90-1004,0,0.321346,"Missing"
C94-2112,H92-1086,0,0.0437753,"l predicates such as begin is ColMitioned by the event sort of the (lualia a.ssociate(1 with the NI ) itself. Thus, only Nl)s having associated tra.nsi+ tion events will allow coercion a,n([ control. This is not to sly, howew~r, that bcgi?z selects only for transition events. There are, of course, perfectly g r a m m a t i c a l examples of prt)cess COm l)lelnents, as shown in (8) below: (8) a. The snow began to ['all at mi(llfight. b. John 1)egan to feel ill. c. The W~/l]' bega.n to t'each ilttO Bestride. These examples illustrate the use of begin as a raising verb. We will follow Perhnutter [14], in distinguishing between two senses of the. verb begin, distiuguishal)le not I)y the selectional properties given in C o d a r d and .layex. but, rather, con+ forming to the distinction that [1.t] ula(le; namely, ~'~S eit]:ter a Raisi'ng or a (~'o?~lrol v e r b . The analysis is as folk)ws. There are in(leed two grammatical expressions of the verb &:gin, as Raising and Sul)ject-(,'outrol forms: As a control verb, the event sort specified as tim c(maplement iS a TR+ANSI3'ION. As a Raising verb, however, the event may be any sort. This tbllows the' typing assignments below: C o n t r o h (('"
C94-2112,W91-0209,0,\N,Missing
C94-2112,C88-2110,1,\N,Missing
C94-2112,E93-1021,0,\N,Missing
C96-1026,J91-4003,0,0.0157939,"ossible to give them a rich typed semantic representation which will explain both their semantic and syntactic polymorphism. 1 II A g e n t - o r l e n t e d a d j e c t i v e s : intelligent, ingdnieuz &apos;clever&apos;, habile &apos;skilful&apos;, adroit &apos;dextrous&apos;. Introduction Recently, work in computational semantics and lexical semantics has made an interesting shift. Motivated by a concern for lexical organization and global coherence in the structure of lexicon, some researchers have moved towards nlore expressive semantic descriptions, as well as more powerful methods of combining them (see for example Pustejovsky, 1991, 1995; Briscoe, 1993). This article will exploit one of these theories, The Generative Lezicon (GL: Pustejovsky, 1995), and extend it for the treatment of French mental adjectives. The following section summarizes the problematic behaviour of these adjectives. The GL approach is then described, and a GL analysis of the data. 2 The Data Mental adjectives which denote an e m o t i o n a l s t a t e or a c o m p e t e n c e ( a g e n t - o r i e n t e d , following Ernst, 1983) present interesting syntactic and semantic polymorphic behaviour, as noted in the literature (see for example Leh~er, 1"
cartoni-etal-2004-automatisation,bredenkamp-etal-2000-looking,0,\N,Missing
cartoni-etal-2004-automatisation,mitamura-etal-2002-kantoo,0,\N,Missing
cartoni-etal-2004-automatisation,A00-1031,0,\N,Missing
H05-2014,2005.eamt-1.8,1,0.774145,"me recognizer using Nuance tools. Previously, the R EGULUS grammar specialization programme has only been implemented for English. In this demo, we will show how we can apply the same methodology to Japanese. Japanese is structurally a very different language from English, so it is by no means obvious that methods which work for English will be applicable in this new context: in fact, they appear to work very well. We will demo the grammars and resulting recognizers in the context of Japanese → English and Japanese → French versions of the Open Source MedSLT medical speech translation system (Bouillon et al., 2005; MedSLT, 2005). The generic problem to be solved when building any sort of recognition grammar is that syntax alone is insufficiently constraining; many of the real constraints in a given domain and use situation tend to be semantic and pragmatic in nature. The challenge is thus to include enough non-syntactic constraints in the grammar to create a language model that can support reliable domain-specific speech recognition: we sketch our solution for Japanese. The basic structure of our current general Japanese grammar is as follows. There are four main groups of rules, covering NP, PP, VP an"
H05-2014,H01-1007,0,0.0292655,"ram language model requires substantial quantities of corpus data, which is generally not available at the start of a new project. Head-to-head comparisons of class N-gram/robust and grammar-based systems also suggest that users who are familiar with system coverage get better results from grammar-based architectures (Knight et al., 2001). As a consequence, deployed spoken dialogue systems for real-world applications frequently use grammar-based methods. This is particularly the case for speech translation systems. Although leading research systems like Verbmobil and NESPOLE! (Wahlster, 2000; Lavie et al., 2001) usually employ complex architectures combining statistical and rule-based methods, successful practical examples like Phraselator and S-MINDS (Phraselator, 2005; Sehda, 2005) are typically phrasal translators with grammar-based recognizers. Voice recognition platforms like the Nuance Toolkit provide CFG-based languages for writing grammar-based language models (GLMs), but it is challenging to develop and maintain grammars consisting of large sets of ad hoc phrase-structure rules. For this reason, there has been considerable interest in developing systems that permit language models be specifi"
H05-2014,E03-2010,1,0.69704,"lop and maintain grammars consisting of large sets of ad hoc phrase-structure rules. For this reason, there has been considerable interest in developing systems that permit language models be specified in higher-level formalisms, normally some kind of unification grammar (UG), and then compile these grammars down to the low-level platform formalisms. A prominent early example of this approach is the Gemini system (Moore, 1998). Gemini raises the level of abstraction significantly, but still assumes that the grammars will be domain-dependent. In the Open Source R EGULUS project (Regulus, 2005; Rayner et al., 2003), we have taken a further step in the direction of increased abstraction, and derive all recognizers from a single linguistically motivated UG. This derivation procedure starts with a large, application-independent UG for a language. An application-specific UG is then derived using an Explanation Based Learning (EBL) specialization technique. This corpus-based specialization process is parameterized by the training corpus and operationality criteria. The training corpus, which can be relatively small, consists of examples of utterances that should be recognized by the target application. The s"
P03-2024,C00-2097,1,0.838812,"ght, numbers) or even gestures (e.g. pointing to an area of the body). This is clearly a domain in which the constraints of the task are sufficient for a limited domain, one way spoken translation system to be a useful tool. 2 An architecture for limited-domain speech translation The basic philosophy behind the architecture of the system is to attempt an intelligent compromise between fixed-phrase translation on one hand (e.g. (IntegratedWaveTechnologies, 2002)) and linguistically motivated grammar-based processing on the other (e.g. V ERBMOBIL (Wahlster, 2000) and Spoken Language Translator (Rayner et al., 2000a)). At run-time, the system behaves essentially like a phrasal translator which allows some variation in the input language. This is close in spirit to the approach used in most normal phrase-books, which typically allow “slots” in at least some phrases (“How much does — cost?”; “How do I get to — ?”). However, in order to minimize the overhead associated with defining and maintaining large sets of phrasal patterns, these patterns are derived from a single large linguistically motivated unification grammar; thus the compile-time architecture is that of a linguistically motivated system. Phras"
P03-2024,E03-2010,1,0.673693,"le for source language speech recognition, including parsing and production of semantic representation; transfer and generation; and synthesis of target language speech. The speech processing modules (recognition and synthesis) are implemented on top of the standard Nuance Toolkit platform (Nuance, 2003). Recognition is constrained by a CFG language model written in Nuance Grammar Specification Language (GSL), which also specifies the semantic representations produced. This language model is compiled from a linguistically motivated unification grammar using the Open Source REGULUS 2 platform (Rayner et al., 2003; Regulus, 2003); the compilation process is driven by a small corpus of examples. The language processing modules (transfer and generation) are a suite of simple routines written in SICStus Prolog. The speech and language processing modules communicate with each other through a minimal file-based protocol. The semantic representations on both the source and target sides are expressed as attribute-value structures. In accordance with the generally minimalistic design philosophy of the project, semantic representations have been kept as simple as possible. The basic principle is that the repres"
P16-2027,P05-1033,0,0.0872519,"e extended across several manual activities in a straightforward way; TrPhrase $$name Source claude Gloss C L A U D E Mouthing C L a u: d e EndTrPhrase TrPhrase $$name Source marie Gloss M A R I E Mouthing L23 a R i e EndTrPhrase Figure 1: Toy speech2sign application definition. however, workarounds have been introduced for this (Ebling and Glauert, 2015). Experience with SiGML has shown that it is capable of supporting signed animation of satisfactory quality (Smith and Nolan, 2015). The core translation formalism is a version of Synchronous Context Free Grammar (SCFG; (Aho and Ullman, 1969; Chiang, 2005)) adapted to the peculiarities of sign language translation. A complete toy application definition is shown in Figure 1. The top-level Utterance rule translates French expressions of the form Je m’appelle hNAMEi (“I am called hNAMEi”) to Swiss French Sign Language (LSF-CH) expressions of a form 164 that can be glossed as MOI S_APPELER hNAMEi together with accompanying non-manual components; for example, the manual activity MOI (signed by pointing at one’s chest) is here performed together with a head nod, raised eyebrows, widened eyes, and a series of mouth movements approximating the shapes u"
rayner-etal-2006-regulus,N01-1030,1,\N,Missing
rayner-etal-2006-regulus,E03-2010,1,\N,Missing
rayner-etal-2006-regulus,C02-1095,0,\N,Missing
rayner-etal-2006-regulus,H05-2014,1,\N,Missing
rayner-etal-2006-regulus,P01-1022,1,\N,Missing
rayner-etal-2006-regulus,2005.eamt-1.8,1,\N,Missing
rayner-etal-2010-multilingual,tsourakis-etal-2008-building,1,\N,Missing
rayner-etal-2010-multilingual,2008.amta-govandcom.4,1,\N,Missing
rayner-etal-2010-multilingual,rayner-etal-2006-regulus,1,\N,Missing
rayner-etal-2010-multilingual,N07-1059,0,\N,Missing
rayner-etal-2010-multilingual,bouillon-etal-2008-developing,1,\N,Missing
rayner-etal-2010-multilingual,H05-2014,1,\N,Missing
rayner-etal-2010-multilingual,2005.eamt-1.8,1,\N,Missing
rayner-etal-2010-multilingual,W07-0806,1,\N,Missing
rayner-etal-2012-evaluating,N07-1059,0,\N,Missing
rayner-etal-2012-evaluating,rayner-etal-2010-multilingual,1,\N,Missing
ruimy-etal-2004-semi,ruimy-etal-2002-clips,1,\N,Missing
seretan-etal-2014-large,bredenkamp-etal-2000-looking,0,\N,Missing
seretan-etal-2014-large,R13-1011,0,\N,Missing
seretan-etal-2014-large,J14-1005,0,\N,Missing
seretan-etal-2014-large,C10-1043,0,\N,Missing
seretan-etal-2014-large,P11-1038,0,\N,Missing
seretan-etal-2014-large,2012.eamt-1.41,0,\N,Missing
seretan-etal-2014-large,D07-1077,0,\N,Missing
seretan-etal-2014-large,W11-0700,0,\N,Missing
seretan-etal-2014-large,W14-0310,1,\N,Missing
seretan-etal-2014-large,R11-1094,0,\N,Missing
tsourakis-etal-2008-building,N03-4015,0,\N,Missing
tsourakis-etal-2008-building,2005.mtsummit-papers.25,1,\N,Missing
tsourakis-etal-2008-building,P05-3008,1,\N,Missing
tsourakis-etal-2008-building,2005.eamt-1.8,1,\N,Missing
tsourakis-etal-2008-building,W06-3702,1,\N,Missing
tsourakis-etal-2010-examining,tsourakis-etal-2008-building,1,\N,Missing
tsourakis-etal-2010-examining,2005.eamt-1.8,1,\N,Missing
vazquez-etal-2014-applying,bredenkamp-etal-2000-looking,0,\N,Missing
W00-0722,E95-1021,0,0.101018,"absent from the lexicon. First, allomorph: the prefix part allo, and the suffix part, morph, are listed in the lexicon, with all the MS and the WS features, therefore it is recognized by the first-stage guesser. Second, allocution, it can not be split into any affix, as cution is not a morpheme, but the ending tion refers to some features (noun, singular) in the second-stage guesser. As the underlying objective of the project is to retrieve documents, the main and most complete information is provided by the first-stage guesser, and the second-stage is only interesting for MS tagging, as in (Chanod and Tapanainen, 1995). Finally (tab. 1), some of the morpho-syntactic features provided by the lemmatizer are expressed into the MS tagset 5, to be processed by the tagger (tab. 2). 3.1 Lexicon, morphological analysis and guesser The lexicon, with around 20000 entries, covers exhaustively the whole ICD-10. The morphological analyser is morpheme-based (Baud et al., 1998), it maps each inflected surface form of a word to its canonical lexical form, followed by the relevant morphological features. Words absent from the lexicon follow a two-step guessing process. First, the unknown token is analysed regarding its resp"
W00-0722,C92-3129,0,0.117955,"Missing"
W00-0722,J93-2006,0,0.159963,"Missing"
W00-0742,A97-1052,0,0.0386017,"ted on this subject, especially in the statistical learning domain (see (Grefenstette, 1994b), for e.g., or (Habert et al., 1997) and (Pichon and S~billot, 1997) for surveys of this field). Following Harris's framework (Harris et al., 1989), such research tries to extract both syntagmatic and paradigmatic information, respectively studying the words that appear in the same window-based or syntactic contexts as a considered lexical unit (first order word affinities (Grefenstette, 1994a)), or the words that generate the same contexts as the key word (second order word affinities). For example, (Briscoe and Carroll, 1997) and (Faure and N~dellec, 1999) try to automatically learn 3A semantic operation that converts an argument to the type which is expected by a function, where it would otherwise result in a type error. 201 we furnish a set of N-V pairs related by one of the qualia relations within a POS context (E+), and a set of N-V pairs that are not semantically linked ( E - ) , and the method infers general rules (clauses) that explain these E +. This particular explanatory characteristic of ILP has motivated our choice: ILP does not just provide a predictor (this N-V pair is relevant, this one is not) but"
W00-0742,J89-3006,0,0.0104612,"at is sufficiently generic to cover the majority of the positive examples (E+), and sufficiently specific to rightly correspond to the concept we want to learn and to cover no (or a few - some noise can be allowed) negative example(s) ( E - ) . For our experiment, method Trying to infer lexical semantic information from corpora is not new: lots of works have already been conducted on this subject, especially in the statistical learning domain (see (Grefenstette, 1994b), for e.g., or (Habert et al., 1997) and (Pichon and S~billot, 1997) for surveys of this field). Following Harris's framework (Harris et al., 1989), such research tries to extract both syntagmatic and paradigmatic information, respectively studying the words that appear in the same window-based or syntactic contexts as a considered lexical unit (first order word affinities (Grefenstette, 1994a)), or the words that generate the same contexts as the key word (second order word affinities). For example, (Briscoe and Carroll, 1997) and (Faure and N~dellec, 1999) try to automatically learn 3A semantic operation that converts an argument to the type which is expected by a function, where it would otherwise result in a type error. 201 we furnis"
W00-0742,C92-2082,0,0.00516475,"construction seems to be only possible if a telic relation holds between the N and V (Bassac and Bouillon, 2000) (for example: ??this book writes well vs this book reads well). Similarly, imperative constructions (e.g. open the door, follow the links) or adjectival sentences (a book difficult to write/read) may also indicate a qualia relation. These are some of the constructions that we want to identify primilarly in corpora by the learning method. 3 The machine learning verbal argument structures and selectional restrictions; (Agarwal, 1995) and (Bouaud et al., 1997) build semantic classes; (Hearst, 1992) and (Morin, 1997) focus on particular lexical relations, like hyperonymy. Some of these works are concerned with automatically obtaining more complete lexical semantic representations ((Grefenstette, 1994b; Pichon and S~billot, 1999). Among these studies, (Pustejovsky et al., 1993) presents a research whose aim is to acquire GL nominal qualia structures from a corpus; this work is however quite different from ours because it supposes that the qualia structure contents are initialized and are only refined with the help of the corpus by using the type coercion 3 mechanism. In order to automatic"
W00-0742,J93-2005,0,0.0328463,"nces (a book difficult to write/read) may also indicate a qualia relation. These are some of the constructions that we want to identify primilarly in corpora by the learning method. 3 The machine learning verbal argument structures and selectional restrictions; (Agarwal, 1995) and (Bouaud et al., 1997) build semantic classes; (Hearst, 1992) and (Morin, 1997) focus on particular lexical relations, like hyperonymy. Some of these works are concerned with automatically obtaining more complete lexical semantic representations ((Grefenstette, 1994b; Pichon and S~billot, 1999). Among these studies, (Pustejovsky et al., 1993) presents a research whose aim is to acquire GL nominal qualia structures from a corpus; this work is however quite different from ours because it supposes that the qualia structure contents are initialized and are only refined with the help of the corpus by using the type coercion 3 mechanism. In order to automatically acquire N-V pairs whose elements are linked by one of the semantic relations defined in the qualia structure in GL, we have decided to use a machine learning method. This section is devoted to the explanation of this choice and to the description of the m e t h o d that we have"
W06-3702,2005.eamt-1.8,1,0.658561,"Missing"
W06-3702,1999.mtsummit-1.8,0,0.0751905,"systems utilizing probabilistic context-free grammar tuning appear to deliver better results when training data is sparse (Rayner et al., 2005a). One drawback of grammar-based systems is that out-of-coverage utterances will be neither recognized nor translated, an objection that critics have sometimes painted as decisive. It is by no means obvious, however, that restricted coverage is such a serious problem. In text processing, work on several generations of controlled language systems has developed a range of techniques for keeping users within the bounds of system coverage (Kittredge, 2003; Mitamura, 1999). If these techniques work for text processing, it is surely not inconceivable that variants of them will be equally successful for spoken language applications. Users are usually able to adapt to a controlled language system given enough time. The critical questions are how to provide efficient support to guide them towards the system&apos;s coverage, and how much time they will then need before they have acclimatized. With regard to top-level translation functionality, the choice is between unidirectional and bidirectional systems. Bidirectional systems are certainly possible today1, but the argu"
W06-3702,E03-2010,1,0.889866,"Missing"
W06-3702,H05-2014,1,0.898237,"Missing"
W06-3702,2005.mtsummit-papers.25,1,0.809631,"s. Resource grammars are now available for several languages, including English, Japanese (Rayner et al., 2005b), French (Bouillon et al., 2006) and Spanish. MedSLT includes a help module, whose purpose is to add robustness to the system and guide the user towards the supported coverage. The help module uses a second backup recognizer, equipped with a statistical language model; it matches the results from this second recognizer against a corpus of utterances, which are within system coverage and have already been judged to give correct translations. In previous studies (Rayner et al., 2005a; Starlander et al., 2005), we showed that the grammar-based recognizer performs much better than the statistical one on in-coverage utterances, and rather worse on out-of-coverage ones. We also found that having the help module available approximately doubled the speed at which subjects learned to use the system, measured as the average difference in semantic error rate between the results for their first quarter-session and their last quarter-session. It is also possible to recover from recognition errors by selecting one of the displayed help sentences; in the cited studies, we found that this increased the number o"
W06-3707,2005.eamt-1.8,1,0.885548,"Missing"
W06-3707,2002.tmi-papers.17,0,0.0583709,"s domain for the three main input languages. Differences in the sizes of the recognition vocabularies are primarily due to differences in use of inflection. Japanese, with little inflectional morphology, has the smallest vocabulary; French, which inflects most parts of speech, has the largest. 3 The development environment Although the MedSLT system is rule-based, we would, for the usual reasons, prefer to acquire these rules from corpora using some well-defined method. There is, however, little or no material available for most medical speech translation domains, including ours. As noted in (Probst and Levin, 2002), scarcity of data generally implies use of some strategy to obtain a carefully structured training corpus. If the corpus is not organised in this way, conflicts between alternate learned rules occur, and it is hard to inWhere? “do you experience the pain in your jaw” “does the pain spread to the shoulder” When? “have you had the pain for more than a month” “do the headaches ever occur in the morning” How long? “does the pain typically last a few minutes” “does the pain ever last more than two hours” How often? “do you get headaches several times a week” “are the headaches occurring more often"
W06-3707,E03-2010,1,0.863259,"Missing"
W06-3707,2005.jeptalnrecital-long.17,1,0.922576,"k is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarThe MedSLT demonstrator has already been extensively described elsewhere (Bouillon et al., 2005; Rayner et al., 2005a), so this section will only present a brief summary. The main components are a set of speech recognisers for the source languages, a set of generators for the target languages, a translation engine, sets of rules for translating to and from interlingua, a simple discourse engine for dealing with context-dependent translation, and a top-level which manages the information flow between the other modules and the user. MedSLT also includes an intelligent help module, which adds robustness to the system and guides the user towards the supported coverage. The help module uses a backup recogniser,"
W06-3707,2005.mtsummit-papers.25,1,0.872166,"Missing"
W07-0806,2005.eamt-1.8,1,0.863353,"or: moderate? Trad: !؟23$45 ؟63$45 ؟3$45 (muhtamala, muhtamalan, muhtamal) ‘moderate_fem_attributive_adj, moderate_vocalized-predicative_adj, moderate_attributive_adj’. It is also essential for rules of translation to be applied consistently. For instance, in MedSLT, 42 Doctor: was the onset of headaches sudden? Trad: ة؟9 ,  ا;اع- 7 ( هMedSLT) (hal dhahara al sudaa fajatan?) (Q appear-past-3 the headache suddenly?) The Architecture MedSLT is a grammar-based medical speech translation system which uses the commercial Nuance speech recognition platform. It has two main features (Bouillon et al., 2005). First, all the language models (for recognition, analysis, generation) are produced from linguistically motivated, general unification grammars using the Regulus platform (Rayner, et al., 2006). First, domain specific unification grammars are created from the general grammar for the different domains of medical diagnosis through a trainable corpus-based automatic grammar specialization process. They are, next, compiled into Context Free Grammars (CFGs) in a format suitable for use with the Nuance speech recognition platform, and into a form needed for a variant of Semantic Head-driven genera"
W07-0806,W06-3702,1,0.856343,"Grammars (CFGs) in a format suitable for use with the Nuance speech recognition platform, and into a form needed for a variant of Semantic Head-driven generation (Shieber et al., 1990). Therefore, the different grammars needed by the system under this approach are easy to build and maintain. This leads us to the second feature. Because grammar-based speech recognition only produces competitive results for the sentences covered by the grammar, the user will need to learn the coverage of the system. In order to assist in this, a help system is included in the system (Starlander et al., 2005 and Chatzichrisafis et al., 2006). The help system suggests, after each user utterance, similar utterances covered by the grammar which can be taken as a model. In order to derive the help sentences, the system performs, in parallel, a statistical recognition of the input speech. It then compares the recognition result using an N-gram based metric, against a set of known correct in-coverage questions to extract the most similar ones. It is in that way that we introduce some of the robustness of the statistical systems in the controlled application. Once the sentence recognized, the translation is interlingua-based. Regulus al"
W07-0806,W06-3701,0,0.011483,"h, Japanese, Spanish and Catalan. This article focuses on the system development for Arabic. In general, translation in this context raises two specific questions: 1) how to achieve recognition quality that is good enough for translation, and 2) how to get translations to be as idiomatic as possible so they can be understood by the patient. For close languages and domains where accuracy is not very important (e.g. information requests), it may be possible to combine a statistical recognizer with a commercial translation system as it is often done in commercial tools such as SpokenTranslation (Seligman and Dillinger, 2006). However, for this specific application in a multilingual context, this solution is not applicable at all: even if perfect recognition were possible (which is far from being the case), current commercial tools for translating to Arabic do not guarantee good quality. The domain dealt with here contains, in fact, many structures specific to this type of oral dialogue that can not be handled by these systems. For example, all the doctor’s interactions with the MedSLT system consist of questions whose structures differ from one language to another, with each language having its own constraints. C"
W07-0806,2005.mtsummit-papers.25,1,0.844904,"compiled into Context Free Grammars (CFGs) in a format suitable for use with the Nuance speech recognition platform, and into a form needed for a variant of Semantic Head-driven generation (Shieber et al., 1990). Therefore, the different grammars needed by the system under this approach are easy to build and maintain. This leads us to the second feature. Because grammar-based speech recognition only produces competitive results for the sentences covered by the grammar, the user will need to learn the coverage of the system. In order to assist in this, a help system is included in the system (Starlander et al., 2005 and Chatzichrisafis et al., 2006). The help system suggests, after each user utterance, similar utterances covered by the grammar which can be taken as a model. In order to derive the help sentences, the system performs, in parallel, a statistical recognition of the input speech. It then compares the recognition result using an N-gram based metric, against a set of known correct in-coverage questions to extract the most similar ones. It is in that way that we introduce some of the robustness of the statistical systems in the controlled application. Once the sentence recognized, the translatio"
W07-1806,2006.jeptalnrecital-long.6,1,0.802795,"Missing"
W07-1806,1999.mtsummit-1.8,0,\N,Missing
W07-1806,2005.mtsummit-papers.25,1,\N,Missing
W07-1806,P05-3008,1,\N,Missing
W07-1806,2005.eamt-1.8,1,\N,Missing
W07-1806,W06-3705,0,\N,Missing
W07-1806,W06-3702,1,\N,Missing
W07-1807,2005.eamt-1.8,1,0.91887,"Missing"
W07-1807,P05-3008,1,0.710046,"Missing"
W08-1506,W07-1806,1,0.886739,"Missing"
W08-1506,bouillon-etal-2008-developing,1,0.895278,"fr Abstract 1 Introduction MedSLT is a medium-vocabulary grammar-based medical speech translation system built on top of the Regulus platform (Rayner et al., 2006). It is intended for use in doctor-patient diagnosis dialogues, and provides coverage of several subdomains and a large number of different languagepairs. Coverage is based on standard examination questions obtained from physicians, and focusses primarily on yes/no questions, though there is also support for WH-questions and elliptical utterances. Detailed descriptions of MedSLT can be found in earlier papers (Bouillon et al., 2005; Bouillon et al., 2008)1 . In the rest of this note, we will briefly sketch several versions of the system that we intend to demo at the workshop, each of which displays new features developed over the last year. Section 2 describes an any-language-toany-language multilingual version of the system; Section 3, a bidirectional English ↔ Spanish version; Section 4, a version running on a mobile PDA MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs. Vocabulary ranges from"
W08-1506,W06-3702,1,0.905634,"Missing"
W08-1506,W07-1807,1,0.893685,"Missing"
W08-1506,tsourakis-etal-2008-building,1,0.874379,"Missing"
W08-1506,2005.eamt-1.8,1,0.858642,"ukie.nakao@univ-nantes.fr Abstract 1 Introduction MedSLT is a medium-vocabulary grammar-based medical speech translation system built on top of the Regulus platform (Rayner et al., 2006). It is intended for use in doctor-patient diagnosis dialogues, and provides coverage of several subdomains and a large number of different languagepairs. Coverage is based on standard examination questions obtained from physicians, and focusses primarily on yes/no questions, though there is also support for WH-questions and elliptical utterances. Detailed descriptions of MedSLT can be found in earlier papers (Bouillon et al., 2005; Bouillon et al., 2008)1 . In the rest of this note, we will briefly sketch several versions of the system that we intend to demo at the workshop, each of which displays new features developed over the last year. Section 2 describes an any-language-toany-language multilingual version of the system; Section 3, a bidirectional English ↔ Spanish version; Section 4, a version running on a mobile PDA MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs."
W08-1511,1983.tc-1.13,0,0.250159,"Missing"
W08-1702,bouillon-etal-2008-developing,1,0.893366,"speaking or updating a visual display. Input management rules map system inputs to dialogue moves; output management rules map abstract actions to system outputs. Speech translation applications are also rulebased, using an interlingua model (Rayner et al., 2006, Chapter 6). The developer writes a second grammar for the target language, using Regulus tools to compile it into a generator; mappings from source representation to interlingua, and from interlingua to target representation, are defined by sets of translation rules. The interlingua itself is specified using a third Regulus grammar (Bouillon et al., 2008). To summarise, the core of a Regulus application consists of several different linguistically oriented rule-sets, some of which can be interpreted in either a text or a speech modality, and all of which need to interact correctly together. In the next section, we describe how this determines the nature of the Regulus development cycle. switching between modalities in regression testing. Section 6 concludes. 2 The Regulus platform The Regulus platform is a comprehensive toolkit for developing grammar-based speech-enabled systems that can be run on the commercially available Nuance recognition"
W08-1702,P93-1008,0,0.138778,"n modalities in regression testing. Section 6 concludes. 2 The Regulus platform The Regulus platform is a comprehensive toolkit for developing grammar-based speech-enabled systems that can be run on the commercially available Nuance recognition environment. The platform has been developed by an Open Source consortium, the main partners of which have been NASA Ames Research Center and Geneva University, and is freely available for download from the SourceForge website1 . In terms of ideas (though not code), Regulus is a descendent of SRI International’s CLE and Gemini platforms (Alshawi, 1992; Dowding et al., 1993); other related systems are LKB (Copestake, 2002), XLE (Crouch et al., 2008) and UNIANCE (Bos, 2002). Regulus has already been used to build several large applications. Prominent examples are Geneva University’s MedSLT medical speech translator (Bouillon et al., 2005), NASA’s Clarissa procedure browser (Rayner et al., 2005) and Ford Research’s experimental SDS in-car spoken dialogue system, which was awarded first prize at the 2007 Ford internal demo fair. Regulus is described at length in (Rayner et al., 2006), the first half of which consists of an extended tutorial introduction. The release"
W08-1702,W08-0210,0,0.0293883,"Missing"
W08-1702,C02-1095,0,0.0196162,"ehensive toolkit for developing grammar-based speech-enabled systems that can be run on the commercially available Nuance recognition environment. The platform has been developed by an Open Source consortium, the main partners of which have been NASA Ames Research Center and Geneva University, and is freely available for download from the SourceForge website1 . In terms of ideas (though not code), Regulus is a descendent of SRI International’s CLE and Gemini platforms (Alshawi, 1992; Dowding et al., 1993); other related systems are LKB (Copestake, 2002), XLE (Crouch et al., 2008) and UNIANCE (Bos, 2002). Regulus has already been used to build several large applications. Prominent examples are Geneva University’s MedSLT medical speech translator (Bouillon et al., 2005), NASA’s Clarissa procedure browser (Rayner et al., 2005) and Ford Research’s experimental SDS in-car spoken dialogue system, which was awarded first prize at the 2007 Ford internal demo fair. Regulus is described at length in (Rayner et al., 2006), the first half of which consists of an extended tutorial introduction. The release includes a command-line development environment, extensive online documentation, and several exampl"
W08-1702,W07-1807,1,0.904909,"n practice, linguist rulewriters have not been able to test their rules in the speech view without writing glue code, scripts, and other infrastructure required to tie together the various generated components. These are not necessarily things that they want to spend their time doing. The consequence can easily be that the linguists end up working exclusively in the text view, and over-refine the text versions of the rule-sets. From a project management viewpoint, this results in bad prioritisation decisions, since there are more pressing issues to address in the speech view. The Regulus GUI (Kron et al., 2007) is intended as a complete redesign of the development environment, which simultaneously attacks all of the central issues. Commands are organised in a structured set of functionality-based windows, each of which has an appropriate set of drop-down menus. Following normal GUI design practice (Dix et al., 1998, Chapters 3 and 4); (Jacko and Sears, 2003, Chapter 13), only currently meaningful commands are executable in each menu, with the others shown greyed out. Both compile-time and run-time speech-related functionality can be invoked directly from the command menus, with no need for external"
W08-1702,2005.eamt-1.8,1,0.846541,"orm has been developed by an Open Source consortium, the main partners of which have been NASA Ames Research Center and Geneva University, and is freely available for download from the SourceForge website1 . In terms of ideas (though not code), Regulus is a descendent of SRI International’s CLE and Gemini platforms (Alshawi, 1992; Dowding et al., 1993); other related systems are LKB (Copestake, 2002), XLE (Crouch et al., 2008) and UNIANCE (Bos, 2002). Regulus has already been used to build several large applications. Prominent examples are Geneva University’s MedSLT medical speech translator (Bouillon et al., 2005), NASA’s Clarissa procedure browser (Rayner et al., 2005) and Ford Research’s experimental SDS in-car spoken dialogue system, which was awarded first prize at the 2007 Ford internal demo fair. Regulus is described at length in (Rayner et al., 2006), the first half of which consists of an extended tutorial introduction. The release includes a command-line development environment, extensive online documentation, and several example applications. The core functionality offered by Regulus is compilation of typed unification grammars into parsers, generators, and Nuance-formatted CFG language model"
W08-1702,P05-3008,1,0.815415,"in partners of which have been NASA Ames Research Center and Geneva University, and is freely available for download from the SourceForge website1 . In terms of ideas (though not code), Regulus is a descendent of SRI International’s CLE and Gemini platforms (Alshawi, 1992; Dowding et al., 1993); other related systems are LKB (Copestake, 2002), XLE (Crouch et al., 2008) and UNIANCE (Bos, 2002). Regulus has already been used to build several large applications. Prominent examples are Geneva University’s MedSLT medical speech translator (Bouillon et al., 2005), NASA’s Clarissa procedure browser (Rayner et al., 2005) and Ford Research’s experimental SDS in-car spoken dialogue system, which was awarded first prize at the 2007 Ford internal demo fair. Regulus is described at length in (Rayner et al., 2006), the first half of which consists of an extended tutorial introduction. The release includes a command-line development environment, extensive online documentation, and several example applications. The core functionality offered by Regulus is compilation of typed unification grammars into parsers, generators, and Nuance-formatted CFG language models, and hence also into Nuance recognition packages. These"
W08-1702,W07-1806,1,\N,Missing
W08-1702,H93-1008,0,\N,Missing
W09-2607,2008.amta-govandcom.4,1,\N,Missing
W09-2607,E06-1008,0,\N,Missing
W09-2607,P02-1040,0,\N,Missing
W09-2607,W08-0327,0,\N,Missing
W09-2607,2006.amta-papers.24,0,\N,Missing
W09-2607,2005.eamt-1.8,1,\N,Missing
W09-2607,W08-1511,1,\N,Missing
W09-2607,P00-1056,0,\N,Missing
W09-2607,W06-3702,1,\N,Missing
W13-2816,P11-2031,0,0.01261,"in the observed translation input sentence is produced while the writer has a particular “true” word wi ∈ Ci in mind, where Ci is the set of words confusable with w ˆi . For the sake of simplicity, we assume that within a confusion set, all “true word” options are equally likely, i.e., p(w ˆi |wi = x) = 1 for x ∈ C . The writer chooses the next i |Ci | word wi+1 according to the conditional word bigram probability p(wi+1 |wi ). 3.3 Automatic evaluation (BLEU) Due to the relatively small size of the evaluation set and instability inherent in minimum error rate training (Foster and Kuhn, 2009; Clark et al., 2011), results of individual tuning and evaluation runs can be unreliable. We therefore preformed multiple tuning and evaluation runs for each system (baseline, rule-based and weighted graph). To illustrate the precision of the BLEU score on our data sets, we plot in Fig. 2 for each individual tuning run the BLEU score achieved on the tuning set (x-axis) against the performance on the evaluation set (y-axis). The variance along the x-axis for each system is due to search errors in parameter optimization. Since the search space is not convex, the tuning process can get stuck in local maxima. The app"
W13-2816,C12-2032,0,0.0222513,"translations produced by the SMT engine from plain and corrected versions. confusions. The second is an engineering method: we use a commercial pronunciation-generation tool to generate a homophone dictionary, then use this dictionary to turn the input into a weighted graph where each word is replaced by a weighted disjunction of homophones. Related, though less elaborate, work has been reported by Bertoldi et al. (2010), who address spelling errors using a character-level confusion network based on common character confusions in typed English and test them on artificially created noisy data. Formiga and Fonollosa (2012) also used character-based models to correct spelling on informally written English data. The two approaches in the present paper exploit fundamentally different knowledge sources in trying to identify and correct homophone errors. The rule-based method relies exclusively on source-side information, encoding patterns indicative of common French homophone confusions. The weighted graph method shifts the balance to the target side; the choice between potential homophone alternatives is made primarily by the target language model, though the source language weights and the translation model are a"
W13-2816,W09-0439,0,0.0299907,"ose that each word w ˆi in the observed translation input sentence is produced while the writer has a particular “true” word wi ∈ Ci in mind, where Ci is the set of words confusable with w ˆi . For the sake of simplicity, we assume that within a confusion set, all “true word” options are equally likely, i.e., p(w ˆi |wi = x) = 1 for x ∈ C . The writer chooses the next i |Ci | word wi+1 according to the conditional word bigram probability p(wi+1 |wi ). 3.3 Automatic evaluation (BLEU) Due to the relatively small size of the evaluation set and instability inherent in minimum error rate training (Foster and Kuhn, 2009; Clark et al., 2011), results of individual tuning and evaluation runs can be unreliable. We therefore preformed multiple tuning and evaluation runs for each system (baseline, rule-based and weighted graph). To illustrate the precision of the BLEU score on our data sets, we plot in Fig. 2 for each individual tuning run the BLEU score achieved on the tuning set (x-axis) against the performance on the evaluation set (y-axis). The variance along the x-axis for each system is due to search errors in parameter optimization. Since the search space is not convex, the tuning process can get stuck in"
W13-2816,2005.mtsummit-papers.11,0,0.00505547,"s trained from a small bicorpus of domain language. With automatic evaluation, the weighted graph method yields an improvement of about +0.63 BLEU points, while the rulebased method scores about the same as the baseline. On contrastive manual evaluation, both methods give highly significant improvements (p < 0.0001) and score about equally when compared against each other. 1 Introduction and motivation The data used to train Statistical Machine Translation (SMT) systems is most often taken from the proceedings of large multilingual organisations, the generic example being the Europarl corpus (Koehn, 2005); for academic evaluation exercises, the test data may well also be taken from the same source. Texts of this kind are carefully cleaned-up formal language. However, real MT systems often need to handle text from very different genres, which as usual causes problems. This paper addresses a problem common in domains containing informally written text: spelling errors based on homophone confusions. Concretely, the work reported was carried out in the context of the ACCEPT project, which deals with the increasingly important topic of translating online forum posts; the experiments we describe wer"
W13-2816,N10-1064,0,0.0214978,"ins on ne rec¸oit pas l’alerte). ... (at least we do not recoit alert). .. (at least it does not receive the alert). Figure 1: Examples of homophone errors in French forum data, contrasting English translations produced by the SMT engine from plain and corrected versions. confusions. The second is an engineering method: we use a commercial pronunciation-generation tool to generate a homophone dictionary, then use this dictionary to turn the input into a weighted graph where each word is replaced by a weighted disjunction of homophones. Related, though less elaborate, work has been reported by Bertoldi et al. (2010), who address spelling errors using a character-level confusion network based on common character confusions in typed English and test them on artificially created noisy data. Formiga and Fonollosa (2012) also used character-based models to correct spelling on informally written English data. The two approaches in the present paper exploit fundamentally different knowledge sources in trying to identify and correct homophone errors. The rule-based method relies exclusively on source-side information, encoding patterns indicative of common French homophone confusions. The weighted graph method s"
W13-2816,2012.amta-papers.25,1,0.781932,", achieves an average BLEU score of 42.47 on this set. 3.1 The rule-based approach Under the ACCEPT project, a set of lightweight pre-editing rules have been developed specifically for the Symantec Forum translation task. Some of the rules are automatic (direct reformulations); others present the user with a set of suggestions. The evaluations described in Gerlach et al. (2013) demonstrate that pre-editing with the rules has a significant positive effect on the quality of SMTbased translation. The implemented rules address four main phenomena: differences between informal and formal language (Rayner et al., 2012), differences between local French and English word-order, elThe set of Acrolinx pre-editing rules potentially relevant to resolution of homophone errors was applied to the devtest b set test corpus (Section 2.1). In order to be able to make a fair comparison with the weighted-graph method, we only used rules with a unique suggestion, which could be run automatically. Applying these rules produced 430 changed words in the test corpus, but did not change the average BLEU score significantly (42.38). Corrections made with a human in the loop, used as “oracle” input for the SMT system, by the 111"
W13-2816,bredenkamp-etal-2000-looking,0,\N,Missing
W13-2816,P07-2045,0,\N,Missing
W13-2816,P00-1056,0,\N,Missing
W14-0310,N10-1064,0,0.0264886,"translation output and signalling the paraphrases that are more likely to be useful. Related Work Transforming the source text in order to better fit the needs of machine translation is a wellinvestigated area of research. Strategies like source control, source re-ordering, or source simplification at the lexical or structural level have been largely explored; for reviews, see, for instance, Huhn (2013), Kazemi (2013), and Feng (2008), respectively. User-generated content has been investigated in the context of machine translation in recent work dealing specifically with spelling correction (Bertoldi et al., 2010; Formiga and Fonollosa, 2012); lexical normalisation by substituting ill-formed words with their correct counterpart, e.g., makn → making (Han and Baldwin, 2011); missing word – e.g., zero-pronoun – recovery and punctuation correction (Wang and Ng, 2013). Rather than focusing on specific phenomena or Web genres (i.e., tweets), we adopt a more general approach in which we address the problem of source normalisation at multiple levels – punctua11 12 70 http://try-and-see-mt.org/ http://www.matecat.com/ Acknowledgments des r`egles peu coˆuteuses, utile pour la TA statistique des forums ? In Acte"
W14-0310,P11-1038,0,0.0449889,"of machine translation is a wellinvestigated area of research. Strategies like source control, source re-ordering, or source simplification at the lexical or structural level have been largely explored; for reviews, see, for instance, Huhn (2013), Kazemi (2013), and Feng (2008), respectively. User-generated content has been investigated in the context of machine translation in recent work dealing specifically with spelling correction (Bertoldi et al., 2010; Formiga and Fonollosa, 2012); lexical normalisation by substituting ill-formed words with their correct counterpart, e.g., makn → making (Han and Baldwin, 2011); missing word – e.g., zero-pronoun – recovery and punctuation correction (Wang and Ng, 2013). Rather than focusing on specific phenomena or Web genres (i.e., tweets), we adopt a more general approach in which we address the problem of source normalisation at multiple levels – punctua11 12 70 http://try-and-see-mt.org/ http://www.matecat.com/ Acknowledgments des r`egles peu coˆuteuses, utile pour la TA statistique des forums ? In Actes de la 20e conf´erence sur le Traitement Automatique des Langues Naturelles (TALN’2013), pages 539–546, Les Sables d’Olonne, France. The research leading to thes"
W14-0310,bredenkamp-etal-2000-looking,0,0.692073,"fore posting them. The post-editing technology is being used by a community of translators, which provide pro-bono translation services to the NGOs considered in our second use case. In this paper, we describe the framework by presenting its architecture and main modules (Section 2). We discuss related work in Section 3 and conclude in Section 4. 2 In the remaining of this section, we introduce each of the framework modules.6 2.2 The pre-editing module leverages existing lingware which provides authoring support rules aimed at language professionals, by relying on shallow language processing (Bredenkamp et al., 2000). The existing English checker and the linguistic resources on which it relies have been extended and adapted to suit the type of data generated by community users. In particular, the software extension consisted of designing a number of pre-editing rules aimed at source normalisation, for the purpose of making the input text easier to handle by the SMT systems. In the case of French, the pre-editing rules have been designed from scratch. The pre-editing rules pertain to the levels of spelling, grammar, style and terminology. They are defined using the original lingware’s rule formalism and ar"
W14-0310,2012.amta-papers.24,1,0.773325,"e levels of spelling, grammar, style and terminology. They are defined using the original lingware’s rule formalism and are incorporated into a server dedicated to the project. The rule development was corpus-driven and was performed on data collected for this purpose. A stable set of pre-edition rules is available in the portal for each of the domains and source languages considered (i.e., technical forum and heathcare data in English and French). The rules are described in detail in the project deliverable D 2.2 (2013). The rules proposed have been evaluated individually and in combination (Roturier et al., 2012; Gerlach et al., 2013; Seretan et al., 2014). As a general observation, it is important to notice that, for SMT, the improvement of the input text does not go hand in hand with the improvement of translation. For example, in French the rule for correcting verbal forms to the subjunctive tense had a negative impact since the subjunctive is not frequent in the training data. Conversely, it was possible to define lexical reformulations which degraded the quality of the input text, but had a positive impact on translation quality. The combined impact of the rule application was measured in a vari"
W14-0310,2013.mtsummit-wptp.14,1,0.58515,"aluation results showed a systematic statistically significant improvement over the baseline when pre-editing is performed on the source content. More details about the evaluation methodology and results can be found in the project deliverable D 9.2.2 (2013). A data excerpt illustrating the impact of preediting on translation quality is presented in Example 1 below. The simple correction of an accented letter, du → dˆu, leads to the change of several target words, and to a much better translation of the input sentence. 2.3 Post-editing Module The post-editing module of the framework (see also Roturier et al., (2013)) is designed to fulfil the project’s objective of collecting post-editing data in order to learn correction rules and, through feedback loops, to integrate them into the SMT engines (with the goal of automating corrections whenever possible). The project relies on the participation of volunteer community members, who are subject matter experts, native speakers of the 1. a) Source (original): J’ai du m’absenter hier apr`es midi. b) Source (pre-edited): J’ai dˆu m’absenter hier apr`es midi. c) Target (original): I have the leave me yesterday afternoon. d) Target (pre-edited): I had to leave yes"
W14-0310,seretan-etal-2014-large,1,0.809377,"inology. They are defined using the original lingware’s rule formalism and are incorporated into a server dedicated to the project. The rule development was corpus-driven and was performed on data collected for this purpose. A stable set of pre-edition rules is available in the portal for each of the domains and source languages considered (i.e., technical forum and heathcare data in English and French). The rules are described in detail in the project deliverable D 2.2 (2013). The rules proposed have been evaluated individually and in combination (Roturier et al., 2012; Gerlach et al., 2013; Seretan et al., 2014). As a general observation, it is important to notice that, for SMT, the improvement of the input text does not go hand in hand with the improvement of translation. For example, in French the rule for correcting verbal forms to the subjunctive tense had a negative impact since the subjunctive is not frequent in the training data. Conversely, it was possible to define lexical reformulations which degraded the quality of the input text, but had a positive impact on translation quality. The combined impact of the rule application was measured in a variety of settings in a large-scale evaluation c"
W14-0310,N13-1050,0,0.0192066,"urce re-ordering, or source simplification at the lexical or structural level have been largely explored; for reviews, see, for instance, Huhn (2013), Kazemi (2013), and Feng (2008), respectively. User-generated content has been investigated in the context of machine translation in recent work dealing specifically with spelling correction (Bertoldi et al., 2010; Formiga and Fonollosa, 2012); lexical normalisation by substituting ill-formed words with their correct counterpart, e.g., makn → making (Han and Baldwin, 2011); missing word – e.g., zero-pronoun – recovery and punctuation correction (Wang and Ng, 2013). Rather than focusing on specific phenomena or Web genres (i.e., tweets), we adopt a more general approach in which we address the problem of source normalisation at multiple levels – punctua11 12 70 http://try-and-see-mt.org/ http://www.matecat.com/ Acknowledgments des r`egles peu coˆuteuses, utile pour la TA statistique des forums ? In Actes de la 20e conf´erence sur le Traitement Automatique des Langues Naturelles (TALN’2013), pages 539–546, Les Sables d’Olonne, France. The research leading to these results has received funding from the European Community’s Seventh Framework Programme (FP7"
W14-0310,C12-2032,0,0.0156284,"signalling the paraphrases that are more likely to be useful. Related Work Transforming the source text in order to better fit the needs of machine translation is a wellinvestigated area of research. Strategies like source control, source re-ordering, or source simplification at the lexical or structural level have been largely explored; for reviews, see, for instance, Huhn (2013), Kazemi (2013), and Feng (2008), respectively. User-generated content has been investigated in the context of machine translation in recent work dealing specifically with spelling correction (Bertoldi et al., 2010; Formiga and Fonollosa, 2012); lexical normalisation by substituting ill-formed words with their correct counterpart, e.g., makn → making (Han and Baldwin, 2011); missing word – e.g., zero-pronoun – recovery and punctuation correction (Wang and Ng, 2013). Rather than focusing on specific phenomena or Web genres (i.e., tweets), we adopt a more general approach in which we address the problem of source normalisation at multiple levels – punctua11 12 70 http://try-and-see-mt.org/ http://www.matecat.com/ Acknowledgments des r`egles peu coˆuteuses, utile pour la TA statistique des forums ? In Actes de la 20e conf´erence sur le"
W14-0310,J14-1005,0,\N,Missing
W14-0310,W11-0700,0,\N,Missing
W19-6734,S16-1081,0,0.0607361,"Missing"
W19-6734,S17-2001,0,0.0432398,"Missing"
W19-6734,W08-1510,0,0.0309718,"Missing"
W19-6734,P17-4012,0,0.0346513,"nces (target) respectively. Subset Train Dev Test #sentences 199k 12k 10k #tokens 2M 124k 103k #vocabulary 2132 1581 1478 Table 2: Number of sentences, tokens and vocabulary for source variations. Subset Train Dev Test #sentences 199k 12k 10k #tokens 1.5M 99k 82k #vocabulary 880 838 829 Table 3: Number of sentences, tokens and vocabulary for core sentences (target). The source sentences have been lower cased and tokenized; then, Byte-pair encoding (Sennrich, 2016) was trained on the training data set and applied to training, development and test data. 3.2 NMT configuration We used OpenNMT-tf (Klein et al., 2017, OpenNMT,) for training and decoding. OpenNMT is a framework mainly focused at developing encoderdecoder architectures. Proceedings of MT Summit XVII, volume 2 As we can consider our task a low resource NMT (2M tokens in training data, Zoph et al., 2016), we had two alternatives to tackle this task: 1) follow (Zoph et al., 2016) and apply transfer learning or 2) choose an appropriate neural architecture in terms of size. We find 2) a better alternative because of the lack of medical corpora suitable for this application. Transformer (Vaswani et al., 2017) is the stateof-art in most NMT tasks,"
W19-6734,D18-1325,0,0.0549231,"Missing"
W19-6734,D15-1166,0,0.205928,"Missing"
W19-6734,D13-1176,0,0.0344313,"in training data, Zoph et al., 2016), we had two alternatives to tackle this task: 1) follow (Zoph et al., 2016) and apply transfer learning or 2) choose an appropriate neural architecture in terms of size. We find 2) a better alternative because of the lack of medical corpora suitable for this application. Transformer (Vaswani et al., 2017) is the stateof-art in most NMT tasks, but it is better suited to learn in high-resource conditions (Tran et al., 2018). Therefore, we decided to compare Transformer performance with an encoder-decoder architecture based on recurrent neural networks (RNN) (Kalchbrenner and Blunsom, 2013; Bahdanau et al., 2014; Loung et al., 2015). Transformer: The model is composed of a 512 embedding size in the encoder and decoder. The architecture is described in (Vaswani et al., 2017). The parameters used were the default for this model3 . RNN: The model is composed of 512 embedding size in the encoder and decoder. Encoder and decoder are each composed of two LSTM (Hochreiter et al., 2006) with an attention mechanism on the decoder side (Bahdanau et al., 2014; Loung et al., 2015). The model was trained with a dropout rate of 0.3 and a batch size of 64 examples. Both models use early stopp"
W19-6734,P02-1040,0,0.103123,"Missing"
W19-6734,S16-1091,0,0.0351137,"Missing"
W19-6734,D16-1163,0,0.0268094,"99k 82k #vocabulary 880 838 829 Table 3: Number of sentences, tokens and vocabulary for core sentences (target). The source sentences have been lower cased and tokenized; then, Byte-pair encoding (Sennrich, 2016) was trained on the training data set and applied to training, development and test data. 3.2 NMT configuration We used OpenNMT-tf (Klein et al., 2017, OpenNMT,) for training and decoding. OpenNMT is a framework mainly focused at developing encoderdecoder architectures. Proceedings of MT Summit XVII, volume 2 As we can consider our task a low resource NMT (2M tokens in training data, Zoph et al., 2016), we had two alternatives to tackle this task: 1) follow (Zoph et al., 2016) and apply transfer learning or 2) choose an appropriate neural architecture in terms of size. We find 2) a better alternative because of the lack of medical corpora suitable for this application. Transformer (Vaswani et al., 2017) is the stateof-art in most NMT tasks, but it is better suited to learn in high-resource conditions (Tran et al., 2018). Therefore, we decided to compare Transformer performance with an encoder-decoder architecture based on recurrent neural networks (RNN) (Kalchbrenner and Blunsom, 2013; Bahd"
W19-6734,P16-1162,0,0.127681,"Missing"
W19-6734,2006.amta-papers.25,0,0.0734242,"Missing"
W19-8709,D16-1025,0,0.0332873,"Missing"
W19-8709,W11-2123,0,0.0491752,"Missing"
W19-8709,2014.eamt-1.38,0,0.0390603,"Missing"
W19-8709,E17-1083,0,0.062269,"Missing"
W19-8709,P02-1040,0,0.104336,"Missing"
W19-8709,2006.amta-papers.25,0,0.131068,"Missing"
W19-8709,stymne-ahrenberg-2012-practice,0,0.0606053,"Missing"
W19-8709,E17-1100,0,0.0371381,"Missing"
W94-0311,P89-1010,0,0.169463,"Missing"
W94-0311,E89-1018,0,0.0740175,"Missing"
W94-0311,T87-1046,0,0.0202683,"AI tradition) and a linguistic-based approach. 1 Despite these efforts, lexical choice remains a burning issue. We agree with McKeown and Swartout (1988) when they say that: ""... a truly satisfactory theoretical approach for lexical choice has yet to be developed."" However, like some leading researchers in generation, we argue that it is of paramount importance to f i r s t know the kind of information that should be coded in the lexicon, which means to pay more attention to ""the nature of words"" (McDonald, 1988) and to have a ""real knowledge of [the] lexical semantics"", as was pointed out by Marcus (1987): ""In some important sense, [the] systems have no real knowledge of lexical semantics . . . . They use fragments of linguistic structure which eventually have words as their frontiers, but have little or no explicit knowledge of what these words mean."" In this article, we will not give a review of the issue of the lexical choice; it is enough to say that the lexical semantic component for lexical representation is still 1Robin&apos;s report (1990) presents a good survey on ""Lexical Choice in NLG"". See also (Reiter, 1991) and (Nogier and Zock, 1992) for a comprehensive study of the evolution made in"
W94-0311,C88-2110,0,0.0208659,"ntry. ""I am a beer-drinker with a running problem,"" one hash lapel button re~tds. beer ARGSTR QUALIA = = [ ARGI = X: b e v e r a g e ] [ liquid-LCP ] IFORM = beer-liquid(x) | |.TELIC = drink(P,v :individual ,x) | [AGENT= produce(T,w:brewer,x) J Ms. Rifkind is a writer and editor living in New York. Mr. Ferguson is an editorial writer for Scripps Howard News Service in Washington, D.C. writer ARGSTR = x:author&apos;[ |human-LCP = [ ARGI J ] L QUALIA = |FORM = h t m a n ( x ) L TELIC = write(T,x,v:text) 5For a broader account of the semantic interpretation of nominals, including nominalizations, see Pustejovsky and Anick (1988). s W e use ""covert"" to differentiate traditional relational n o m inals (such a s / f i e n d , father, cousin), from the class of nouns . which exhibit a polysemous behaviour (such as book, door, record}. 7We mainly use the approach to typed feature structures as described in Carpenter (1992). We cannot develop here the way the information is inherited in the partial lexical entries presented. 94 7th International Generation Workshop • Kennebunkport, Maine • June 21-24, 1994 The argument structure of nouns encodes arguments which are to be taken as logical parameters providing type informati"
W94-0311,J91-4003,0,0.0287998,"a t i o n s : ( a fast car; a long book; to start a car) I d i o s y n c r a t i c L e x i c a l C o - o c c u r r e n c e s : (a heavy smoker vs. un grand fumeur (French); un grand/gros mangeur (French) vs. un gran/~gordo comelon (Spanish)) I d i o m s : (to kick the bucket; take advantage o]). Formally, this takes us from purely compositional constructions of ""free-combining words"" to the noncompositional structures in idioms. The vast space between these two extremes can still be explained in terms of compositional principles with mechanisms from GLT such as type coercion and subselection (Pustejovsky, 1991, 1993), as we shall see below. Idiosyncrasies, of course, should be listed in the lexicon, yet we believe that we can reduce the set of what are conventionally considered idiosyncrasies by differentiating ""true"" idiosyncrasies (which cannot be derived or generated) from expressions which, since they are compositional in nature, behave predictably, and which we call semantic collocations. 3 Generative Lexicon Theory The Generative Lexicon Theory (GLT) (Pustejovsky, 1991, 1994c) can be said to take advantage of both linguistic and conceptual approaches, providing a framework which arose from th"
W94-0311,J90-1003,0,\N,Missing
W94-0311,J93-1007,0,\N,Missing
