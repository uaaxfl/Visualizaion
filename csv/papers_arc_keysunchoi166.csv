2020.paclic-1.25,Enhancing Quality of Corpus Annotation: Construction of the Multi-Layer Corpus Annotation and Simplified Validation of the Corpus Annotation,2020,-1,-1,12,0,15839,youngbin noh,"Proceedings of the 34th Pacific Asia Conference on Language, Information and Computation",0,None
2020.lrec-1.27,Effective Crowdsourcing of Multiple Tasks for Comprehensive Knowledge Extraction,2020,-1,-1,8,1,16642,sangha nam,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Information extraction from unstructured texts plays a vital role in the field of natural language processing. Although there has been extensive research into each information extraction task (i.e., entity linking, coreference resolution, and relation extraction), data are not available for a continuous and coherent evaluation of all information extraction tasks in a comprehensive framework. Given that each task is performed and evaluated with a different dataset, analyzing the effect of the previous task on the next task with a single dataset throughout the information extraction process is impossible. This paper aims to propose a Korean information extraction initiative point and promote research in this field by presenting crowdsourcing data collected for four information extraction tasks from the same corpus and the training and evaluation results for each task of a state-of-the-art model. These machine learning data for Korean information extraction are the first of their kind, and there are plans to continuously increase the data volume. The test results will serve as an initiative result for each Korean information extraction task and are expected to serve as a comparison target for various studies on Korean information extraction using the data collected in this study."
2020.lrec-1.30,Crowdsourcing in the Development of a Multilingual {F}rame{N}et: A Case Study of {K}orean {F}rame{N}et,2020,-1,-1,7,1,15845,younggyun hahm,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Using current methods, the construction of multilingual resources in FrameNet is an expensive and complex task. While crowdsourcing is a viable alternative, it is difficult to include non-native English speakers in such efforts as they often have difficulty with English-based FrameNet tools. In this work, we investigated cross-lingual issues in crowdsourcing approaches for multilingual FrameNets, specifically in the context of the newly constructed Korean FrameNet. To accomplish this, we evaluated the effectiveness of various crowdsourcing settings whereby certain types of information are provided to workers, such as English definitions in FrameNet or translated definitions. We then evaluated whether the crowdsourced results accurately captured the meaning of frames both cross-culturally and cross-linguistically, and found that by allowing the crowd workers to make intuitive choices, they achieved a quality comparable to that of trained FrameNet experts (F1 {\textgreater} 0.75). The outcomes of this work are now publicly available as a new release of Korean FrameNet 1.1."
2020.coling-main.147,Unsupervised Fact Checking by Counter-Weighted Positive and Negative Evidential Paths in A Knowledge Graph,2020,-1,-1,2,1,21228,jiseong kim,Proceedings of the 28th International Conference on Computational Linguistics,0,"Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction algorithms that extract factual statements from unstructured textual data to populate the existing knowledge graphs. Traditional fact checking by experts or crowds is increasingly difficult to keep pace with the volume of newly created misinformation in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. We view this problem as a truth scoring task in a knowledge graph. We present a novel rule-based approach that finds positive and negative evidential paths in a knowledge graph for a given factual statement and calculates a truth score for the given statement by unsupervised ensemble of the found positive and negative evidential paths. For example, we can determine the factual statement {``}United States is the birth place of Barack Obama{''} as truthful if there is the positive evidential path (Barack Obama, birthPlace, Hawaii) â§ (Hawaii, country, United States) in a knowledge graph. For another example, we can determine the factual statement {``}Canada is the nationality of Barack Obama{''} as untruthful if there is the negative evidential path (Barack Obama, nationality, United States) â§ (United States, {\mbox{$\neq$}}, Canada) in a knowledge graph. For evaluating on a real-world situation, we constructed an evaluation dataset by labeling truth or untruth label on factual statements that were extracted from Wikipedia texts by using the state-of-the-art BERT-based information extraction system. Our evaluation results show that our approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two different standard datasets."
L18-1013,Semi-automatic {K}orean {F}rame{N}et Annotation over {KAIST} Treebank,2018,0,0,4,1,15845,younggyun hahm,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1165,Unsupervised {K}orean Word Sense Disambiguation using {C}ore{N}et,2018,0,0,5,0,9002,kijong han,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1230,Automatic {W}ordnet Mapping: from {C}ore{N}et to {P}rinceton {W}ord{N}et,2018,0,0,4,1,21228,jiseong kim,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1563,Incorporating Global Contexts into Sentence Embedding for Relational Extraction at the Paragraph Level with Distant Supervision,2018,0,0,2,1,16645,eunkyung kim,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-2005,A {K}orean Knowledge Extraction System for Enriching a {KB}ox,2018,0,0,6,1,16642,sangha nam,Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations,0,The increased demand for structured knowledge has created considerable interest in knowledge extraction from natural language sentences. This study presents a new Korean knowledge extraction system and web interface for enriching a KBox knowledge base that expands based on the Korean DBpedia. The aim is to create an endpoint where knowledge can be extracted and added to KBox anytime and anywhere.
C18-2011,Utilizing Graph Measure to Deduce Omitted Entities in Paragraphs,2018,0,0,4,1,16645,eunkyung kim,Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations,0,"This demo deals with the problem of capturing omitted arguments in relation extraction given a proper knowledge base for entities of interest. This paper introduces the concept of a salient entity and use this information to deduce omitted entities in the paragraph which allows improving the relation extraction quality. The main idea to compute salient entities is to construct a graph on the given information (by identifying the entities but without parsing it), rank it with standard graph measures and embed it in the context of the sentences."
2018.gwc-1.27,Distant Supervision for Relation Extraction with Multi-sense Word Embedding,2018,-1,-1,4,1,16642,sangha nam,Proceedings of the 9th Global Wordnet Conference,0,"Distant supervision can automatically generate labeled data between a large-scale corpus and a knowledge base without utilizing human efforts. Therefore, many studies have used the distant supervision approach in relation extraction tasks. However, existing studies have a disadvantage in that they do not reflect the homograph in the word embedding used as an input of the relation extraction model. Thus, it can be seen that the relation extraction model learns without grasping the meaning of the word accurately. In this paper, we propose a relation extraction model with multi-sense word embedding. We learn multi-sense word embedding using a word sense disambiguation module. In addition, we use convolutional neural network and piecewise max pooling convolutional neural network relation extraction models that efficiently grasp key features in sentences. To evaluate the performance of the proposed model, two additional methods of word embedding were learned and compared. Accordingly, our method showed the highest performance among them."
W16-4409,Filling a Knowledge Graph with a Crowd,2016,-1,-1,4,0,29663,gyuhyeon choi,Proceedings of the Open Knowledge Base and Question Answering Workshop ({OKBQA} 2016),0,
W16-4411,{SRDF}: Extracting Lexical Knowledge Graph for Preserving Sentence Meaning,2016,-1,-1,4,1,16642,sangha nam,Proceedings of the Open Knowledge Base and Question Answering Workshop ({OKBQA} 2016),0,"In this paper, we present an open information extraction system so-called SRDF that generates lexical knowledge graphs from unstructured texts. In semantic web, knowledge is expressed in the RDF triple form but the natural language text consist of multiple relations between arguments. For this reason, we combine open information extraction with the reification for the full text extraction to preserve meaning of sentence in our knowledge graph. And also our knowledge graph is designed to adapt for many existing semantic web applications. At the end of this paper, we introduce the result of the experiment and a Korean template generation module developed using SRDF."
W16-4412,{QAF}: Frame Semantics-based Question Interpretation,2016,-1,-1,3,1,15845,younggyun hahm,Proceedings of the Open Knowledge Base and Question Answering Workshop ({OKBQA} 2016),0,"Natural language questions are interpreted to a sequence of patterns to be matched with instances of patterns in a knowledge base (KB) for answering. A natural language (NL) question answering (QA) system utilizes meaningful patterns matching the syntac-tic/lexical features between the NL questions and KB. In the most of KBs, there are only binary relations in triple form to represent relation between two entities or entity and a value using the domain specific ontology. However, the binary relation representation is not enough to cover complex information in questions, and the ontology vocabulary sometimes does not cover the lexical meaning in questions. Complex meaning needs a knowledge representation to link the binary relation-type triples in KB. In this paper, we propose a frame semantics-based semantic parsing approach as KB-independent question pre-processing. We will propose requirements of question interpretation in the KBQA perspective, and a query form representation based on our proposed format QAF (Ques-tion Answering with the Frame Semantics), which is supposed to cover the requirements. In QAF, frame semantics roles as a model to represent complex information in questions and to disambiguate the lexical meaning in questions to match with the ontology vocabu-lary. Our system takes a question as an input and outputs QAF-query by the process which assigns semantic information in the question to its corresponding frame semantic structure using the semantic parsing rules."
W16-4414,Dedicated Workflow Management for {OKBQA} Framework,2016,-1,-1,3,1,21228,jiseong kim,Proceedings of the Open Knowledge Base and Question Answering Workshop ({OKBQA} 2016),0,"Nowadays, a question answering (QA) system is used in various areas such a quiz show, personal assistant, home device, and so on. The OKBQA framework supports developing a QA system in an intuitive and collaborative ways. To support collaborative development, the framework should be equipped with some functions, e.g., flexible system configuration, debugging supports, intuitive user interface, and so on while considering different developing groups of different domains. This paper presents OKBQA controller, a dedicated workflow manager for OKBQA framework, to boost collaborative development of a QA system."
L16-1055,{K}orean {T}ime{ML} and {K}orean {T}ime{B}ank,2016,5,4,5,0,29865,youngseob jeong,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Many emerging documents usually contain temporal information. Because the temporal information is useful for various applications, it became important to develop a system of extracting the temporal information from the documents. Before developing the system, it first necessary to define or design the structure of temporal information. In other words, it is necessary to design a language which defines how to annotate the temporal information. There have been some studies about the annotation languages, but most of them was applicable to only a specific target language (e.g., English). Thus, it is necessary to design an individual annotation language for each language. In this paper, we propose a revised version of Koreain Time Mark-up Language (K-TimeML), and also introduce a dataset, named Korean TimeBank, that is constructed basd on the K-TimeML. We believe that the new K-TimeML and Korean TimeBank will be used in many further researches about extraction of temporal information."
C16-2034,The Open Framework for Developing Knowledge Base And Question Answering System,2016,0,5,5,1,21228,jiseong kim,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"Developing a question answering (QA) system is a task of implementing and integrating modules of different technologies and evaluating an integrated whole system, which inevitably goes with a collaboration among experts of different domains. For supporting a easy collaboration, this demonstration presents the open framework that aims to support developing a QA system in collaborative and intuitive ways. The demonstration also shows the QA system developed by our novel framework."
C16-2037,{K}orean {F}rame{N}et Expansion Based on Projection of {J}apanese {F}rame{N}et,2016,0,0,3,0,35655,jeonguk kim,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"FrameNet project has begun from Berkeley in 1997, and is now supported in several countries reflecting characteristics of each language. The work for generating Korean FrameNet was already done by converting annotated English sentences into Korean with trained translators. However, high cost of frame-preservation and error revision was a huge burden on further expansion of FrameNet. This study makes use of linguistic similarity between Japanese and Korean to increase Korean FrameNet corpus with low cost. We also suggest adapting PubAnnotation and Korean-friendly valence patterns to FrameNet for increased accessibility."
C16-2043,{MAGES}: A Multilingual Angle-integrated Grouping-based Entity Summarization System,2016,8,0,2,1,16645,eunkyung kim,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: System Demonstrations",0,"This demo presents MAGES (multilingual angle-integrated grouping-based entity summarization), an entity summarization system for a large knowledge base such as DBpedia based on a entity-group-bound ranking in a single integrated entity space across multiple language-specific editions. MAGES offers a multilingual angle-integrated space model, which has the advantage of overcoming missing semantic tags (i.e., categories) caused by biases in different language communities, and can contribute to the creation of entity groups that are well-formed and more stable than the monolingual condition within it. MAGES can help people quickly identify the essential points of the entities when they search or browse a large volume of entity-centric data. Evaluation results on the same experimental data demonstrate that our system produces a better summary compared with other representative DBpedia entity summarization methods."
K15-1014,Entity Linking {K}orean Text: An Unsupervised Learning Approach using Semantic Relations,2015,9,0,2,0,37721,youngsik kim,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"Although entity linking is a widely researched topic, the same cannot be said for entity linking geared for languages other than English. Several limitations including syntactic features and the relative lack of resources prevent typical approaches to entity linking to be used as e ectively for other languages in general. We describe an entity linking system that leverage semantic relations between entities within an existing knowledge base to learn and perform entity linking using a minimal environment consisting of a part-of-speech tagger. We measure the performance of our system against Korean Wikipedia abstract snippets, using the Korean DBpedia knowledge base for training. Based on these results, we argue both the feasibility of our system and the possibility of extending to other domains and languages in general."
hahm-etal-2014-named,Named Entity Corpus Construction using {W}ikipedia and {DB}pedia Ontology,2014,11,9,6,1,15845,younggyun hahm,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we propose a novel method to automatically build a named entity corpus based on the DBpedia ontology. Since most of named entity recognition systems require time and effort consuming annotation tasks as training data. Work on NER has thus for been limited on certain languages like English that are resource-abundant in general. As an alternative, we suggest that the NE corpus generated by our proposed method, can be used as training data. Our approach introduces Wikipedia as a raw text and uses the DBpedia data set for named entity disambiguation. Our method is language-independent and easy to be applied to many different languages where Wikipedia and DBpedia are provided. Throughout the paper, we demonstrate that our NE corpus is of comparable quality even to the manually annotated NE corpus."
W13-5714,Towards Fully Lexicalized Dependency Parsing for {K}orean,2013,0,3,4,1,24158,jungyeul park,Proceedings of the 13th International Conference on Parsing Technologies ({IWPT} 2013),0,None
W12-5201,{K}orean {NLP}2{RDF} Resources,2012,9,2,5,1,15845,younggyun hahm,Proceedings of the 10th Workshop on {A}sian Language Resources,0,"The aim of Linked Open Data (LOD) is to improve information management and integration by enhancing accessibility to the existing various forms of open data. The goal of this paper is to make Korean resources linkable entities. By using NLP tools, which are suggested in this paper, Korean texts are converted to RDF resources and they can be connected with other RDF triples. It is worth noticing that to the best of our knowledge there is a few of publicy available Korean NLP tools. For this reason, the Korean NLP platform presented here will be available as open source. And it is shown in this paper that the result of this NLP platform can be used as Linked Data entities."
W12-3411,{K}orean Treebank Transformation for Parser Training,2012,15,12,3,1,7602,donghyun choi,Proceedings of the {ACL} 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages,0,"Korean is a morphologically rich language in which grammatical functions are marked by inflections and affixes, and they can indicate grammatical relations such as subject, object, predicate, etc. A Korean sentence could be thought as a sequence of eojeols. An eo- jeol is a word or its variant word form ag- glutinated with grammatical affixes, and eo- jeols are separated by white space as in En- glish written texts. Korean treebanks (Choi et al., 1994; Han et al., 2002; Korean Lan- guage Institute, 2012) use eojeol as their fun- damental unit of analysis, thus representing an eojeol as a prepreterminal phrase inside the constituent tree. This eojeol-based an- notating schema introduces various complex- ity to train the parser, for example an en- tity represented by a sequence of nouns will be annotated as two or more different noun phrases, depending on the number of spaces used. In this paper, we propose methods to transform eojeol-based Korean treebanks into entity-based Korean treebanks. The methods are applied to Sejong treebank, which is the largest constituent treebank in Korean, and the transformed treebank is used to train and test various probabilistic CFG parsers. The experi- mental result shows that the proposed transfor- mation methods reduce ambiguity in the train- ing corpus, increasing the overall F1 score up to about 9 %."
W10-3306,Intrinsic Property-based Taxonomic Relation Extraction from Category Structure,2010,-1,-1,4,1,7602,donghyun choi,Proceedings of the 6th Workshop on {O}ntologies and {L}exical {R}esources,0,None
W09-3426,"Word Segmentation Standard in {C}hinese, {J}apanese and {K}orean",2009,0,6,1,1,15850,keysun choi,Proceedings of the 7th Workshop on {A}sian Language Resources ({ALR}7),0,"Word segmentation is a process to divide a sentence into meaningful units called word unit [ISO/DIS 24614-1]. What is a word unit is judged by principles for its internal integrity and external use constraints. A word unit's internal structure is bound by principles of lexical integrity, unpredictability and so on in order to represent one syntactically meaningful unit. Principles for external use include language economy and frequency such that word units could be registered in a lexicon or any other storage for practical reduction of processing complexity for the further syntactic processing after word segmentation. Such principles for word segmentation are applied for Chinese, Japanese and Korean, and impacts of the standard are discussed."
W06-0506,Taxonomy Learning using Term Specificity and Similarity,2006,10,27,2,1,38088,pummo ryu,Proceedings of the 2nd Workshop on Ontology Learning and Population: Bridging the Gap between Text and Knowledge,0,"Learning taxonomy for technical terms is difficult and tedious task, especially when new terms should be included. The goal of this paper is to assign taxonomic relations among technical terms. We propose new approach to the problem that relies on term specificity and similarity measures. Term specificity and similarity are necessary conditions for taxonomy learning, because highly specific terms tend to locate in deep levels and semantically similar terms are close to each other in taxonomy. We analyzed various features used in previous researches in view of term specificity and similarity, and applied optimal features for term specificity and similarity to our method."
melz-etal-2006-compiling,Compiling large language resources using lexical similarity metrics for domain taxonomy learning,2006,24,1,3,0,50339,ronny melz,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this contribution we present a new methodology to compile large language resources for domain-specific taxonomy learning. We describe the necessary stages to deal with the rich morphology of an agglutinative language, i.e. Korean, and point out a second order machine learning algorithm to unveil term similarity from a given raw text corpus. The language resource compilation described is part of a fully automatic top-down approach to construct taxonomies, without involving the human efforts which are usually required."
I05-2012,Automatic Extraction of {E}nglish-{K}orean Translations for Constituents of Technical Terms,2005,9,2,2,1,12929,jonghoon oh,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"Technical terms are linguistic realization of a domain concept and their constituents are a component used for representing the concept. Many technical terms are usually multi-word terms and their meaning can be inferred from their constituents. Because a term constituent is usually a morphological unit rather than a conceptual unit in Korean technical terms, we need to first identify conceptual units and then to resolve the proper meaning of the conceptual units in order to properly translate technical terms. For natural language applications to properly handle technical terms, it is necessary to give information about conceptual units and their meaning including homonym, synonym and domain dependency. In this paper, we propose a term constituent alignment algorithm, which extracts such information from bilingual technical term pairs. Our algorithm regards English term constituents as a conceptual unit and then finds its Korean counterpart. Our method shows about 6.1% AER."
I05-1013,Automatic Partial Parsing Rule Acquisition Using Decision Tree Induction,2005,16,1,3,0,51049,myungseok choi,Second International Joint Conference on Natural Language Processing: Full Papers,0,"Partial parsing techniques try to recover syntactic information efficiently and reliably by sacrificing completeness and depth of analysis. One of the difficulties of partial parsing is finding a means to extract the grammar involved automatically. In this paper, we present a method for automatically extracting partial parsing rules from a tree-annotated corpus using decision tree induction. We define the partial parsing rules as those that can decide the structure of a substring in an input sentence deterministically. This decision can be considered as a classification; as such, for a substring in an input sentence, a proper structure is chosen among the structures occurred in the corpus. For the classification, we use decision tree induction, and induce partial parsing rules from the decision tree. The acquired grammar is similar to a phrase structure grammar, with contextual and lexical information, but it allows building structures of depth one or more. Our experiments showed that the proposed partial parser using the automatically extracted rules is not only accurate and efficient, but also achieves reasonable coverage for Korean."
I05-1027,Classifying {C}hinese Texts in Two Steps,2005,14,3,3,0,51055,xinghua fan,Second International Joint Conference on Natural Language Processing: Full Papers,0,"This paper proposes a two-step method for Chinese text categorization (TC). In the first step, a Naive Bayesian classifier is used to fix the fuzzy area between two categories, and, in the second step, the classifier with more subtle and powerful features is used to deal with documents in the fuzzy area, which are thought of being unreliable in the first step. The preliminary experiment validated the soundness of this method. Then, the method is extended from two-class TC to multi-class TC. In this two-step framework, we try to further improve the classifier by taking the dependences among features into consideration in the second step, resulting in a Causality Naive Bayesian Classifier."
I05-1040,An Ensemble of Grapheme and Phoneme for Machine Transliteration,2005,12,24,2,1,12929,jonghoon oh,Second International Joint Conference on Natural Language Processing: Full Papers,0,"Machine transliteration is an automatic method to generate characters or words in one alphabetical system for the corresponding characters in another alphabetical system. There has been increasing concern on machine transliteration as an assistant of machine translation and information retrieval. Three machine transliteration models, including xe2x80x9cgrapheme-based modelxe2x80x9d, xe2x80x9cphoneme-based modelxe2x80x9d, and xe2x80x9chybrid modelxe2x80x9d, have been proposed. However, there are few works trying to make use of correspondence between source grapheme and phoneme, although the correspondence plays an important role in machine transliteration. Furthermore there are few works, which dynamically handle source grapheme and phoneme. In this paper, we propose a new transliteration model based on an ensemble of grapheme and phoneme. Our model makes use of the correspondence and dynamically uses source grapheme and phoneme. Our method shows better performance than the previous works about 15~23% in English-to-Korean transliteration and about 15~43% in English-to-Japanese transliteration."
W04-1813,Determining the Specificity of Terms based on Information Theoretic Measures,2004,-1,-1,2,1,38088,pummo ryu,Proceedings of {C}ompu{T}erm 2004: 3rd International Workshop on Computational Terminology,0,None
W04-1111,A Statistical Model for Hangeul-Hanja Conversion in Terminology Domain,2004,5,1,3,1,11234,jinxia huang,Proceedings of the Third {SIGHAN} Workshop on {C}hinese Language Processing,0,"Sino-Korean words, which are historically borrowed from Chinese language, could be represented with both Hanja (Chinese characters) and Hangeul (Korean characters) writings. Previous Korean Input Method Editors (IMEs) provide only a simple dictionary-based approach for Hangeul-Hanja conversion. This paper presents a sentencebased statistical model for Hangeul-Hanja conversion, with word tokenization included as a hidden process. As a result, we reach 91.4% of character accuracy and 81.4% of word accuracy in terminology domain, when only very limited Hanja data is available."
P04-3027,Automatic clustering of collocation for detecting practical sense boundary,2004,6,1,2,0,6472,saim shin,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"This paper talks about the deciding practical sense boundary of homonymous words. The important problem in dictionaries or thesauri is the confusion of the sense boundary by each resource. This also becomes a bottleneck in the practical language processing systems. This paper proposes the method about discovering sense boundary using the collocation from the large corpora and the clustering methods. In the experiments, the proposed methods show the similar results with the sense boundary from a corpus-based dictionary and sense-tagged corpus."
bae-choi-2004-lexical,Lexical Analysis of Agglutinative Languages Using a Dictionary of Lemmas and Lexical Transducers,2004,1,0,2,0,51601,sunmee bae,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents a simple method for performing a lexical analysis of agglutinative languages like Korean, which have a heavy morphology. Especially, for nouns and adverbs with regular morphological modifications and/or high productivity, we do not need to artificially construct huge dictionaries of all inflected forms of lemmas. To construct a dictionary of lemmas and lexical transducers, first, we construct automatically a dictionary of all inflected forms from KAIST POS-Tagged Corpus. Secondly, we separate the party of lemmas and one of sequences of inflectional suffixes. Thirdly, we describe their lexical transducers (i.e., morphological rules) to recognize all inflected forms of lemmas for nouns and adverbs according to the combinatorial restrictions between lemmas and their inflectional suffixes. Finally, we evaluate the advantages of this method."
choi-etal-2004-korean,{K}orean-{C}hinese-{J}apanese Multilingual {W}ordnet with Shared Semantic Hierarchy,2004,2,3,1,1,15850,keysun choi,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"A Chinese-Japanese-Korean wordnet is introduced. It is constructed based on a shared semantic hierarchy that is originated from NTT Goidaikei (Lexical Hierarchical System). Korean wordnet was constructed through the semantic category assignment to every sense of Korean words in a dictionary. Verbs and adjectivesxe2x80x99 senses are assigned to the same semantic hierarchy as that of nouns. Each sense of verbs is investigated from corpora for their usage, and compared with Japanese translation. Chinese wordnet with the same semantic hierarchy was built up based on the comparison with Korean wordnet. Each sense of Chinese verb corresponds to Korean with its argument structure. These works have lasted since 1994. 1 Song, Youngbinxe2x80x99s current address is Ewha Womans University."
C04-1178,Semiautomatic Extension of {C}ore{N}et using a Bootstrapping Mechanism on Corpus-based Co-occurrences,2004,8,6,3,0,2565,chris biemann,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"The paper describes a language-independent approach for semiautomatic extension of lexical-semantic word nets and evaluates the method on CoreNet, the Korean version of word net. In a bootstrapping fashion, the so-called 'Pendulum Algorithm' operates on word sets obtained by co-occurrence statistics on a large un-annotated corpus and keeps error propagation low by a verification step. Results are not sufficient for automatic extension, but provide a good candidate set. Further improvements are discussed."
Y03-1001,Virtual Linked Lexical Knowledge Base for Causality Reasoning,2003,0,0,1,1,15850,keysun choi,"Proceedings of the 17th Pacific Asia Conference on Language, Information and Computation",0,"The A virtually linked knowledge base is designed to utilize a pre-constructed knowledge base in a dynamic mode when it is in actual use. An algorithm is proposed for causality reasoning based on a set of lexical knowledge bases that contain information about such items as event role, is-a hierarchy, relevant relation, antonym, and other features. These lexical knowledge bases have mainly made use of lexical features and symbols in HowNet. Several types of questions are experimented to test the effectiveness of the algorithm here proposed. In particular, questions of the form why are treated to show how causality reasoning works."
W03-1122,Question-Answering Based on Virtually Integrated Lexical Knowledge Base,2003,10,5,1,1,15850,keysun choi,Proceedings of the Sixth International Workshop on Information Retrieval with {A}sian Languages,0,"This paper proposes an algorithm for causality inference based on a set of lexical knowledge bases that contain information about such items as event role, is-a hierarchy, relevant relation, antonymy, and other features. These lexical knowledge bases have mainly made use of lexical features and symbols in HowNet. Several types of questions are experimented to test the effectiveness of the algorithm here proposed. Particularly in this paper, the question form of why is dealt with to show how causality inference works."
Y02-1028,A {K}orean Noun Semantic Hierarchy ({W}ordnet) Construction,2001,-1,-1,4,0,13330,juho lee,"Proceedings of the 16th Pacific Asia Conference on Language, Information and Computation",0,None
oh-etal-2002-word,Word Sense Disambiguation with Information Retrieval Technique,2002,16,1,4,1,12929,jonghoon oh,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
C02-1086,Implicit Ambiguity Resolution Using Incremental Clustering in {K}orean-to-{E}nglish Cross-Language Information Retrieval,2002,18,7,3,0,44657,kyungsoon lee,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper presents a method to implicitly resolve ambiguities using dynamic incremental clustering in Korean-to-English cross-language information retrieval. In the framework we propose, a query in Korean is first translated into English by looking up Korean-English dictionary, then documents are retrieved based on the vector space retrieval for the translated query terms. For the top-ranked retrieved documents, query-oriented document clusters are incrementally created and the weight of each retrieved document is re-calculated by using clusters. In experiment on TREC-6 CLIR test collection, our method achieved 28.29% performance improvement for translated queries without ambiguity resolution for queries. This corresponds to 97.27% of the monolingual performance for original queries. When we combine our method with query ambiguity resolution, our method even outperforms the monolingual retrieval."
C02-1088,Unsupervised Named Entity Classification Models and their Ensembles,2002,15,26,3,0,52722,jaeho kim,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"This paper proposes an unsupervised learning model for classifying named entities. This model uses a training set, built automatically by means of a small-scale named entity dictionary and an unlabeled corpus. This enables us to classify named entities without the cost for building a large hand-tagged training corpus or a lot of rules.Our model uses the ensemble of three different learning methods and repeats the learning with new training examples generated through the ensemble learning. The ensemble of various learning methods brings a better result than each individual learning method. The experimental result shows 73.16% in precision and 72.98% in recall for Korean news articles."
C02-1097,Word Sense Disambiguation using Static and Dynamic Sense Vectors,2002,13,12,2,1,12929,jonghoon oh,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"It is popular in WSD to use contextual information in training sense tagged data. Co-occurring words within a limited window-sized context support one sense among the semantically ambiguous ones of the word. This paper reports on word sense disambiguation of English words using static and dynamic sense vectors. First, context vectors are constructed using contextual words in the training sense tagged data. Then, the words in the context vector are weighted with local density. Using the whole training sense tagged data, each sense of a target word is represented as a static sense vector in word space, which is the centroid of the context vectors. Then contextual noise is removed using a automatic selective sampling. A automatic selective sampling method use information retrieval technique, so as to enhance the discriminative power. In each test case, a automatic selective sampling method retrieves N relevant training samples to reduce noise. Using them, we construct another sense vectors for each sense of the target word. They are called dynamic sense vectors because they are changed according to a target word and its context. Finally, a word sense of a target word is determined using static and dynamic sense vectors. The English SENSEVAL test suit is used for this experimentation and our method produces relatively good results."
C02-1099,An {E}nglish-{K}orean Transliteration Model Using Pronunciation and Contextual Rules,2002,8,77,2,1,12929,jonghoon oh,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"There is increasing concern about English-Korean (E-K) transliteration recently. In the previous works, direct converting methods from English alphabets to Korean alphabets were a main research topic. In this paper, we present an E-K transliteration model using pronunciation and contextual rules. Unlike the previous works, our method uses phonetic information such as phoneme and its context. We also use word formation information such as English words of Greek origin, With them, our method shows significant performance increase about 31% in word accuracy."
2001.mtsummit-papers.35,A test suite for evaluation of {E}nglish-to-{K}orean machine translation systems,2001,1,6,5,0,54060,sungryong koh,Proceedings of Machine Translation Summit VIII,0,"This paper describes KORTERM{'}s test suite and their practicability. The test-sets have been being constructed on the basis of fine-grained classification of linguistic phenomena to evaluate the technical status of English-to-Korean MT systems systematically. They consist of about 5000 test-sets and are growing. Each test-set contains an English sentence, a model Korean translation, a linguistic phenomenon category, and a yes/no question about the linguistic phenomenon. Two commercial systems were evaluated with a yes/no test of prepared questions. Total accuracy rates of the two systems were different (50{\%} vs. 66{\%}). In addition, a comprehension test was carried out. We found that one system was more comprehensible than the other system. These results seem to show that our test suite is practicable."
Y00-1013,Using Bilingual Semantic Information in {C}hinese-{K}orean Word Alignment,2000,12,2,2,1,11234,jinxia huang,"Proceedings of the 14th Pacific Asia Conference on Language, Information and Computation",0,None
P00-1005,Phrase-Pattern-based {K}orean to {E}nglish Machine Translation using Two Level Translation Pattern Selection,2000,5,5,2,0,6516,jungjae kim,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"Pattern-Based Machine Translation is one of the machine translation methods which performs syntactic analysis and structure transfer at the same time using bilingual patterns. PBMT is used to expand the length of patterns up to sentence-length in order to reduce ambiguities in translation, but it brought out the problem of rapidly increased patterns. We propose a model which shortens the length of patterns to phrase-length and reduces ambiguities in translation by using two level translation pattern selection method. In the first level, the proper translation patterns are selected by using a hybrid method of exact example matching and semantic constraint by thesaurus. In the second level, the most natural translation pattern for the verb phrase is selected among the selected translation pattern categories by using statistic information of the target language. By using this proposed model, we could shorten the length of patterns without raising the ambiguities in translation."
P00-1050,{C}hinese-{K}orean Word Alignment Based on Linguistic Comparison,2000,17,13,2,1,11234,jinxia huang,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"Word alignment problem between parallel corpora is based on the similar characteristics of two aligned words in two languages. We investigate linguistic-knowledge-based word similarity measures while other previous works heavily rely on statistical information, and their limits will be discussed. Linguistic knowledge is acquired from linguistic comparison of all layers between two languages, for Chinese and Korean in this paper."
P00-1063,Term Recognition Using Technical Dictionary Hierarchy,2000,8,6,3,1,12929,jonghoon oh,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"In recent years, statistical approaches on ATR (Automatic Term Recognition) have achieved good results. However, there are scopes to improve the performance in extracting terms still further. For example, domain dictionaries can improve the performance in ATR. This paper focuses on a method for extracting terms using a dictionary hierarchy. Our method produces relatively good results for this task."
P00-1072,Dimension-Reduced Estimation of Word Co-occurrence Probability,2000,8,1,2,0,54357,kilyoun kim,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,We investigate a novel approach to solve the problem of sparse data through dimension reduction. Linear algebraic technique called LSA/SVD is used to find co-relationships of sparse words. Three variant estimation methods are suggested and they are evaluated for estimating unseen noun-verb co-occurrence probability. The model shows possibility to be alternative probability smoothing method.
kang-choi-2000-automatic,Automatic Transliteration and Back-transliteration by Decision Tree Learning,2000,12,65,2,0,54517,byungju kang,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"Automatic transliteration and back-transliteration across languages with drastically different alphabets and phonemes inventories such as English/Korean, English/Japanese, English/Arabic, English/Chinese, etc, have practical importance in machine translation, crosslingual information retrieval, and automatic bilingual dictionary compilation, etc. In this paper, a bi-directional and to some extent language independent methodology for English/Korean transliteration and back-transliteration is described. Our method is composed of character alignment and decision tree learning. We induce transliteration rules for each English alphabet and back-transliteration rules for each Korean alphabet. For the training of decision trees we need a large labeled examples of transliteration and backtransliteration. However this kind of resources are generally not available. Our character alignment algorithm is capable of highly accurately aligning English word and Korean transliteration in a desired way."
chae-choi-2000-design,Design and Construction of Knowledge base for Verb using {MRD} and Tagged Corpus,2000,1,0,2,0,54333,youngsoog chae,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"This paper represents the procedure of building syntactic knowledge base. This study is to construct basic sentence pattern automatically by using the POS-tagged corpus in balanced KAIST corpus, and electronic dictionary for Korean, and to construct syntactic knowledge base with specific information added to the lexicographer's analysis. The summary of work process will be as follows: 1) Extraction of characteristic verb targeting the high frequency verb from KAIST corpus 2) Constructing sentence pattern from each verb case frame structure extracted from MRD 3) Making out the noun categories of sentence pattern through KCP examples 4) Semantic classification of selected verb suitable for classified sentence pattern 5) Description of hyper concept to individual noun categories 6) Putting the translated words in Japanese to each noun and verb 1 * This paper has been supported by AITrc and The Korean Ministry of Science and Technology."
chae-choi-2000-introduction,Introduction of {KIBS} ({K}orean Information Base System) Project,2000,1,4,2,0,54333,youngsoog chae,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,This project has been carried out on the basis of resources and tools for Korean NLP. The main research is the construction of raw corpus of 64 million tokens and Part-of-Speech tagged corpus of about 11 million tokens. And we develop some analytic tools to construct and some supporting tools to navigate them. This paper represents the present state of the work carried out by the KIBS project. We introduce a KAIST tag set of POS and syntax for standard corpus and annotation principles. And we explain several error types represented in tagged corpus. 1 This paper has been supported by AITrc and The Korean Ministry of Science and Technology.
choi-chae-2000-terminology,Terminology in {K}orea: {KORTERM},2000,2,1,1,1,15850,keysun choi,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"Korterm (Korea Terminology Research Center for Language and Knowledge Engineering) had been set up in the late August of 1998 under the auspices of Ministry of Culture and Tourism in Korea. Its major mission is to construct terminology resources and their unification, harmonization and standardization. This mission is naturally linked to the general language engineering and knowledge engineering tasks including specific-domain corpus, ontology, wordnet, electronic dictionary construction as well as language engineering products like information extraction and machine translation. This organization is located under the KAIST (Korea Advanced Institute of Science and Technology) that is one of national university specifically under the Ministry of Science and Technology. KORTERM is only one representative for terminology standardization and research with relation to Infoterm.."
W99-0635,Corpus-Based Approach for Nominal Compound Analysis for {K}orean Based on Linguistic and Statistical Information,1999,9,3,2,0,51071,juntae yoon,1999 Joint {SIGDAT} Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,0,None
1999.tmi-1.23,Pipelined multi-engine Machine Translation: accomplishment of {MATES}/{CK} system,1999,5,0,2,0,3694,min zhang,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1999.mtsummit-1.54,A pipelined multi-engine approach to {C}hinese-to-{K}orean machine translation: {MATES}/{CK},1999,4,0,2,0,3694,min zhang,Proceedings of Machine Translation Summit VII,0,"This paper presents MATES/CK, a Chinese-to-Korean machine translation system. We introduce the design philosophy, component modules, implementation and some other aspects of MATES/CK system in this paper."
P98-2167,Machine Aided Error-Correction Environment for {K}orean Morphological Analysis and Partof-Speech Tagging,1998,2,2,4,0,55280,junsik park,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,Statistical methods require very large corpus with high quality. But building large and faultless annotated corpus is a very difficult job. This paper proposes an efficient method to construct part-of-speech tagged corpus. A rule-based error correction method is proposed to find and correct errors semi-automatically by user-defined rules. We also make use of user's correction log to reflect feedback. Experiments were carried out to show the efficiency of error correction process of this workbench. The result shows that about 63.2 % of tagging errors can be corrected.
P98-1039,Hybrid Approaches to Improvement of Translation Quality in Web-based {E}nglish-{K}orean Machine Translation,1998,5,9,7,0,15823,sungkwon choi,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,The previous English-Korean MT system that was the transfer-based MT system and applied to only written text enumerated a following brief list of the problems that had not seemed to be easy to solve in the near future: 1) processing of non-continuous idiomatic expressions 2) reduction of too many ambiguities in English syntactic analysis 3) robust processing for failed or illformed sentences 4) selecting correct word correspondence between several alternatives 5) generation of Korean sentence style. The problems can be considered as factors that have influence on the translation quality of machine translation system. This paper describes the symbolic and statistical hybrid approaches to solutions of problems of the previous English-to-Korean machine translation system in terms of the improvement of translation quality. The solutions are now successfully applied to the web-based English-Korean machine translation system FromTo/EK which has been developed from 1997.
P98-1119,Automatic Acquisition of Language Model based on Head-Dependent Relation between Words,1998,9,2,2,1,55365,seungmi lee,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"Language modeling is to associate a sequence of words with a priori probability, which is a key part of many natural language applications such as speech recognition and statistical machine translation. In this paper, we present a language modeling based on a kind of simple dependency grammar. The grammar consists of head-dependent relations between words and can be learned automatically from a raw corpus using the reestimation algorithm which is also introduced in this paper. Our experiments show that the proposed model performs better than n-gram models at 11% to 11.5% reductions in test corpus entropy."
C98-2162,Machine Aided Error-Correction Environment for {K}orean Morphological Analysis and Part-of-Speech Tagging,1998,2,2,4,0,55280,junsik park,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,Statistical methods require very large corpus with high quality. But building large and faultless annotated corpus is a very difficult job. This paper proposes an efficient method to construct part-of-speech tagged corpus. A rule-based error correction method is proposed to find and correct errors semi-automatically by user-defined rules. We also make use of user's correction log to reflect feedback. Experiments were carried out to show the efficiency of error correction process of this workbench. The result shows that about 63.2 % of tagging errors can be corrected.
C98-1039,Hybrid Approaches to Improvement of Translation Quality in Web-based {E}nglish-{K}orean Machine Translation,1998,5,9,4,0,15823,sungkwon choi,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,The previous English-Korean MT system that was the transfer-based MT system and applied to only written text enumerated a following brief list of the problems that had not seemed to be easy to solve in the near future: 1) processing of non-continuous idiomatic expressions 2) reduction of too many ambiguities in English syntactic analysis 3) robust processing for failed or illformed sentences 4) selecting correct word correspondence between several alternatives 5) generation of Korean sentence style. The problems can be considered as factors that have influence on the translation quality of machine translation system. This paper describes the symbolic and statistical hybrid approaches to solutions of problems of the previous English-to-Korean machine translation system in terms of the improvement of translation quality. The solutions are now successfully applied to the web-based English-Korean machine translation system FromTo/EK which has been developed from 1997.
C98-1115,Automatic Acquisition of Language Model based on Head-Dependent Relation between Words,1998,9,2,2,1,55365,seungmi lee,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"Language modeling is to associate a sequence of words with a priori probability, which is a key part of many natural language applications such as speech recognition and statistical machine translation. In this paper, we present a language modeling based on a kind of simple dependency grammar. The grammar consists of head-dependent relations between words and can be learned automatically from a raw corpus using the reestimation algorithm which is also introduced in this paper. Our experiments show that the proposed model performs better than n-gram models at 11% to 11.5% reductions in test corpus entropy."
W97-0107,Reestimation and Best-First Parsing Algorithm for Probabilistic Dependency Grammars,1997,9,14,2,1,55365,seungmi lee,Fifth Workshop on Very Large Corpora,0,None
W97-0125,A Local Grammar-based Approach to Recognizing of Proper Names in {K}orean Texts,1997,11,10,2,0,50114,jeesun nam,Fifth Workshop on Very Large Corpora,0,"We present an LO-based approach to recognizing of Proper Names in Korean texts. Local grammars (LGs) are constructed by examining specific syntactic contexts of lexical elements, given that the general syntactic rules, independent from lexical items, cannot provide accurate analyses. The LGs will be represented under the form of Finite State Automata (FSA) in our system. So far as we do not have a dictionary which would provide all proper names, we need auxiliary tools to analyze them. We will examine contexts where strings containing proper names occur. Our approach consists in building an electronic lexicon of PNs in a way more satisfactory than other existing methods, such as their recognition in texts by means of statistical approaches or by rule-based methods."
O97-2003,Corpus-Based {C}hinese Text Summarization System,1997,0,1,2,0,13359,junjie li,{ROCLING} 1997 Poster Papers,0,None
Y96-1014,A Logical Structure for the Construction of Machine Readable Dictionaries,1996,6,0,4,0,55815,byungjin choi,"Proceedings of the 11th Pacific Asia Conference on Language, Information and Computation",0,"During the last 10 years, there have been many efforts in some areas of Natural Language Processing to encode the normal text or documents into machine readable form. If we encode written data using a canonical form which can be recognized by a computer, we can extract needed information and process and utilize it for another purposes. From this point of view, we present an account of the encoding of a printed dictionary. The construction of a lexicon is very time-consuming and expensive work and the application of the lexicon is restricted. In this paper, we describe a logical structure for Korean printed dictionaries as a general lexical representation based on SDML, which can be transformed into another representation for different application requirements."
J96-3007,A Chart Re-estimation Algorithm for a Probabilistic Recursive Transition Network,1996,6,1,2,0.5,55947,young han,Computational Linguistics,0,"A Probabilistic Recursive Transition Network is an elevated version of a Recursive Transition Network used to model and process context-free languages in stochastic parameters. We present a re-estimation algorithm for training probabilistic parameters, and show how efficiently it can be implemented using charts. The complexity of the Outside algorithm we present is O(N4G3) where N is the input size and G is the number of states. This complexity can be significantly overcome when the redundant computations are avoided. Experiments on the Penn tree corpus show that re-estimation can be done more efficiently with charts."
C96-2185,{K}orean Language Engineering: Current Status of the Information Platform,1996,6,2,2,0,55986,seongyong kim,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"Language engineering implements functions of a language and information via computers. The need for language engineering platforms has been generally recognized and several researches are being undertaken around the world. Our goal is to establish Korean information platform of linguistic resources and tools for Korean language and information communities. The platform will support, researchers and engineers with well-developed and standardized resources and application tools thereby avoiding duplicate activities from scratch and amplifying overall effort on the domain. This paper reports the components and the current status of the project, and the importance of the effort."
C96-1040,Bilingual Knowledge Acquisition from {K}orean-{E}nglish Parallel Corpus Using Alignment,1996,0,5,3,0,56027,jung shin,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"This paper snggests a method to align Korean-English parallel corpus. '1?he structural dissimilarity between Korean and Indo-European languages requires more flexible measures to evaluate the alignment candidates between the bilingual units than is used to handle the pairs of Indo-European languages. The flexible measure is intended to capture the dependency between bilingual items that can occur in different units according to different ordering rules. The proposed method to accomplish KoreanEnglish aligmnent takes phrases as an alignment unit that is a departure from the existing methods taking words as the unit. Phrasal alignment avoids the problem of alignment units and appease the problem of ordering mismatch. The parameters are estimated using the EM algorithm. The proposed alignment algorithm is based on dynamic programming. In the experimenl, s carried out on 253,000 English words and its Korean translations the proposed method achived 68.7% in accuracy at phrase level and 89.2% in accuracy with the bilingual dictionary induced from the alignment. 'File result of the alignment may lead to richer bilingual data than can be derived from only wordlevel aligments."
C96-1041,{M}arkov random field based {E}nglish Part-Of-Speech tagging system,1996,23,11,3,0,56028,sungyoung jung,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"Probabilistic models have been widely used for natural language processing. Part-of-speech tagging, which assingns the most likely tag to each word in a given sentence, is one of the problems which can be solved by statistical approach. Many researchers have tried to solve the problem by hidden Markov model (HMM), which is well known as one of the statistical models. But it has many difficulties: integrating heterogeneous information, coping with data sparseness problem, and adapting to new environments. In this paper, we propose a Markov radom field (MRF) model based approach to the tagging problem. The MRF provides the base frame to combine various statistical information with maximum entropy (ME) method. As Gibbs distribution can be used to describe a posteriori probability of tagging, we use it in maximum a posteriori (MAP) estimation of optimizing process. Besides, several tagging models are developed to show the effect of adding information. Experimental results show that the performance of the tagger gets improved as we add more statistical information, and that MRF-based tagging model is better than HMM based tagging in data sparseness problem."
E95-1008,Collocation Map for Overcoming Data Sparseness,1995,8,3,3,0,56191,moonjoo kim,Seventh Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Statistical language models are useful because they can provide probabilistic information upon uncertain decision making. The most common statistic is n-grams measuring word cooccurrences in texts. The method suffers from data shortage problem, however. In this paper, we suggest Bayesian networks be used in approximating the statistics of insufficient occurrences and of those that do not occur in the sample texts with graceful degradation. Collocation map is a sigmoid belief network that can be constructed from bigrams. We compared the conditional probabilities and mutual information computed from bigrams and Collocation map. The results show that the variance of the values from Collocation map is smaller than that from frequency measure for the infrequent pairs by 48%. The predictive power of Collocation map for arbitrary associations not observed from sample texts is also demonstrated."
1995.mtsummit-1.45,Machine Translation for the office automation,1995,-1,-1,1,1,15850,keysun choi,Proceedings of Machine Translation Summit V,0,None
C94-2138,A Reestimation Algorithm for Probabilistic ttecursive Transition Network,1994,9,0,2,0,55947,young han,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,Probabilistic Recursive Transition Network (PRTN) is an elevated version of RTN to model and process languages in stochastic parameters. The representation is a direct derivation from the RTN and keeps much the spirit of Hidden Markov Model at the same time. We present a resetination algorithm for PRTN that is a variation of Inside-Outside algorithm that computes the values of the probabilistic parameters from sample sentences (parsed or unparsed).
C94-1020,An {E}nglish-to-{K}orean Machine Translator: {MATES/EK},1994,2,10,1,1,15850,keysun choi,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This note introduces an English-to-Korean Machine Translation System MATES/EK, which has been developed as a research prototype and is still under upgrading in KAIST (Korea Advanced Institute of Science and Technology). MATES/EK is a transfer-based system and it has several subsystems that can be used to support other MT-developments. They are grammar developing environment systems, dictionary developing tools, a set of augmented context free grammars for English syntactic analysis, and so on."
C94-1087,A Two-Level Morphological Analysis of {K}orean,1994,8,16,3,0,56507,deokbong kim,{COLING} 1994 Volume 1: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"The two-level morphology model has received a great deal of attention and has been implemented for languages like Finnish, English, Japanese, Russian, French, and so on. However, this model has been claimed to be inappropriate for Korean morphological analysis, because the complex conjugation (inflection) and agglutination in word formation, and the syllable-based representation of words may lead to a huge number of two-level morphological rules. In this paper, we show that the two-level model can be successfully applied to Korean and its rule size is limited to only 52. An extension of two-level morphology is described for Korean language."
W93-0103,Lexical Concept Acquisition from Collocation Map,1993,11,6,3,0,55947,young han,Acquisition of Lexical Knowledge from Text,0,None
