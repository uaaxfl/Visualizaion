N18-2079,Incremental Decoding and Training Methods for Simultaneous Translation in Neural Machine Translation,2018,0,11,4,1,3158,fahim dalvi,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"We address the problem of simultaneous translation by modifying the Neural MT decoder to operate with dynamically built encoder and attention. We propose a tunable agent which decides the best segmentation strategy for a user-defined BLEU loss and Average Proportion (AP) constraint. Our agent outperforms previously proposed Wait-if-diff and Wait-if-worse agents (Cho and Esipova, 2016) on BLEU with a lower latency. Secondly we proposed data-driven changes to Neural MT training to better match the incremental decoding framework."
L18-1336,The {WAW} Corpus: The First Corpus of Interpreted Speeches and their Translations for {E}nglish and {A}rabic,2018,0,0,4,0.464477,482,ahmed abdelali,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
temnikova-etal-2017-interpreting,Interpreting Strategies Annotation in the {WAW} Corpus,2017,8,0,4,0.468269,23303,irina temnikova,Proceedings of the Workshop Human-Informed Translation and Interpreting Technology,0,"With the aim to teach our automatic speech-to-text translation system human interpreting strategies, our first step is to identify which interpreting strategies are most often used in the language pair of our interest (English-Arabic). In this article we run an automatic analysis of a corpus of parallel speeches and their human interpretations, and provide the results of manually annotating the human interpreting strategies in a sample of the corpus. We give a glimpse of the corpus, whose value surpasses the fact that it contains a high number of scientific speeches with their interpretations from English into Arabic, as it also provides rich information about the interpreters. We also discuss the difficulties, which we encountered on our way, as well as our solutions to them: our methodology for manual re-segmentation and alignment of parallel segments, the choice of annotation tool, and the annotation procedure. Our annotation findings explain the previously extracted specific statistical features of the interpreted corpus (compared with a translation one) as well as the quality of interpretation provided by different interpreters."
nakov-vogel-2017-robust,Robust Tuning Datasets for Statistical Machine Translation,2017,29,0,2,0,1636,preslav nakov,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"We explore the idea of automatically crafting a tuning dataset for Statistical Machine Translation (SMT) that makes the hyper-parameters of the SMT system more robust with respect to some specific deficiencies of the parameter tuning algorithms. This is an under-explored research direction, which can allow better parameter tuning. In this paper, we achieve this goal by selecting a subset of the available sentence pairs, which are more suitable for specific combinations of optimizers, objective functions, and evaluation measures. We demonstrate the potential of the idea with the pairwise ranking optimization (PRO) optimizer, which is known to yield too short translations. We show that the learning problem can be alleviated by tuning on a subset of the development set, selected based on sentence length. In particular, using the longest 50{\%} of the tuning sentences, we achieve two-fold tuning speedup, and improvements in BLEU score that rival those of alternatives, which fix BLEU+1{'}s smoothing instead."
P17-2095,Challenging Language-Dependent Segmentation for {A}rabic: An Application to Machine Translation and Part-of-Speech Tagging,2017,27,6,6,0.67126,3156,hassan sajjad,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Word segmentation plays a pivotal role in improving any Arabic NLP application. Therefore, a lot of research has been spent in improving its accuracy. Off-the-shelf tools, however, are: i) complicated to use and ii) domain/dialect dependent. We explore three language-independent alternatives to morphological segmentation using: i) data-driven sub-word units, ii) characters as a unit of learning, and iii) word embeddings learned using a character CNN (Convolution Neural Network). On the tasks of Machine Translation and POS tagging, we found these methods to achieve close to, and occasionally surpass state-of-the-art performance. In our analysis, we show that a neural machine translation system is sensitive to the ratio of source and target tokens, and a ratio close to 1 or greater, gives optimal performance."
I17-1015,Understanding and Improving Morphological Learning in the Neural Machine Translation Decoder,2017,0,22,5,1,3158,fahim dalvi,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"End-to-end training makes the neural machine translation (NMT) architecture simpler, yet elegant compared to traditional statistical machine translation (SMT). However, little is known about linguistic patterns of morphology, syntax and semantics learned during the training of NMT systems, and more importantly, which parts of the architecture are responsible for learning each of these phenomenon. In this paper we i) analyze how much morphology an NMT decoder learns, and ii) investigate whether injecting target morphology in the decoder helps it to produce better translations. To this end we present three methods: i) simultaneous translation, ii) joint-data learning, and iii) multi-task learning. Our results show that explicit morphological information helps the decoder learn target language morphology and improves the translation quality by 0.2{--}0.6 BLEU points."
E17-3016,{QCRI} Live Speech Translation System,2017,11,1,9,1,3158,fahim dalvi,Proceedings of the Software Demonstrations of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper presents QCRI{'}s Arabic-to-English live speech translation system. It features modern web technologies to capture live audio, and broadcasts Arabic transcriptions and English translations simultaneously. Our Kaldi-based ASR system uses the Time Delay Neural Network (TDNN) architecture, while our Machine Translation (MT) system uses both phrase-based and neural frameworks. Although our neural MT system is slower than the phrase-based system, it produces significantly better translations and is memory efficient. The demo is available at \url{https://st.qcri.org/demos/livetranslation}."
E17-3029,The {SUMMA} Platform Prototype,2017,8,1,43,0,28433,renars liepins,Proceedings of the Software Demonstrations of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We present the first prototype of the SUMMA Platform: an integrated platform for multilingual media monitoring. The platform contains a rich suite of low-level and high-level natural language processing technologies: automatic speech recognition of broadcast media, machine translation, automated tagging and classification of named entities, semantic parsing to detect relationships between entities, and automatic construction / augmentation of factual knowledge bases. Implemented on the Docker platform, it can easily be deployed, customised, and scaled to large volumes of incoming media streams."
N16-1125,Eyes Don{'}t Lie: Predicting Machine Translation Quality Using Eye Movement,2016,17,3,7,0.789854,3156,hassan sajjad,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,None
L16-1578,Applying the Cognitive Machine Translation Evaluation Approach to {A}rabic,2016,27,1,3,0.468269,23303,irina temnikova,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The goal of the cognitive machine translation (MT) evaluation approach is to build classifiers which assign post-editing effort scores to new texts. The approach helps estimate fair compensation for post-editors in the translation industry by evaluating the cognitive difficulty of post-editing MT output. The approach counts the number of errors classified in different categories on the basis of how much cognitive effort they require in order to be corrected. In this paper, we present the results of applying an existing cognitive evaluation approach to Modern Standard Arabic (MSA). We provide a comparison of the number of errors and categories of errors in three MSA texts of different MT quality (without any language-specific adaptation), as well as a comparison between MSA texts and texts from three Indo-European languages (Russian, Spanish, and Bulgarian), taken from a previous experiment. The results show how the error distributions change passing from the MSA texts of worse MT quality to MSA texts of better MT quality, as well as a similarity in distinguishing the texts of better MT quality for all four languages."
2016.amta-users.9,An Empirical Study: Post-editing Effort for {E}nglish to {A}rabic Hybrid Machine Translation,2016,-1,-1,3,0.789854,3156,hassan sajjad,Conferences of the Association for Machine Translation in the Americas: MT Users' Track,0,None
W15-3059,How do Humans Evaluate Machine Translation,2015,16,5,5,1,7331,francisco guzman,Proceedings of the Tenth Workshop on Statistical Machine Translation,0,"In this paper, we take a closer look at the MT evaluation process from a glass-box perspective using eye-tracking. We analyze two aspects of the evaluation task xe2x80x90 the background of evaluators (monolingual or bilingual) and the sources of information available, and we evaluate them using time and consistency as criteria. Our findings show that monolinguals are slower but more consistent than bilinguals, especially when only target language information is available. When exposed to various sources of information, evaluators in general take more time and in the case of monolinguals, there is a drop in consistency. Our findings suggest that to have consistent and cost effective MT evaluations, it is better to use monolinguals with only target language information."
K15-1007,"Analyzing Optimization for Statistical Machine Translation: {MERT} Learns Verbosity, {PRO} Learns Length",2015,34,5,3,1,7331,francisco guzman,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"We study the impact of source length and verbosity of the tuning dataset on the performance of parameter optimizers such as MERT and PRO for statistical machine translation. In particular, we test whether the verbosity of the resulting translations can be modified by varying the length or the verbosity of the tuning sentences. We find that MERT learns the tuning set verbosity very well, while PRO is sensitive to both the verbosity and the length of the source sentences in the tuning set; yet, overall PRO learns best from highverbosity tuning datasets. Given these dependencies, and potentially some other such as amount of reordering, number of unknown words, syntactic complexity, and evaluation measure, to mention just a few, we argue for the need of controlled evaluation scenarios, so that the selection of tuning set and optimization strategy does not overshadow scientific advances in modeling or decoding. In the mean time, until we develop such controlled scenarios, we recommend using PRO with a large verbosity tuning set, which, in our experiments, yields highest BLEU across datasets and language pairs."
D15-1147,How to Avoid Unwanted Pregnancies: Domain Adaptation using Neural Network Models,2015,57,14,6,0,3407,shafiq joty,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"We present novel models for domain adaptation based on the neural network joint model (NNJM). Our models maximize the cross entropy by regularizing the loss function with respect to in-domain model. Domain adaptation is carried out by assigning higher weight to out-domain sequences that are similar to the in-domain data. In our alternative model we take a more restrictive approach by additionally penalizing sequences similar to the outdomain data. Our models achieve better perplexities than the baseline NNJM models and give improvements of up to 0.5 and 0.6 BLEU points in Arabic-to-English and English-to-German language pairs, on a standard task of translating TED talks."
2015.mtsummit-papers.10,Using joint models or domain adaptation in statistical machine translation,2015,-1,-1,5,0.360812,3159,nadir durrani,Proceedings of Machine Translation Summit XV: Papers,0,None
W14-3628,Unsupervised Word Segmentation Improves Dialectal {A}rabic to {E}nglish Machine Translation,2014,35,5,6,0,37814,kamla almannai,Proceedings of the {EMNLP} 2014 Workshop on {A}rabic Natural Language Processing ({ANLP}),0,"We demonstrate the feasibility of using unsupervised morphological segmentation for dialects of Arabic, which are poor in linguistics resources. Our experiments using a Qatari Arabic to English machine translation system show that unsupervised segmentation helps to improve the translation quality as compared to using no segmentation or to using ATB segmentation, which was especially designed for Modern Standard Arabic (MSA). We use MSA and other dialects to improve Qatari Arabic to English machine translation, and we show that a uniform segmentation scheme across them yields an improvement of 1.5 BLEU points over using no segmentation."
abdelali-etal-2014-amara,The {AMARA} Corpus: Building Parallel Language Resources for the Educational Domain,2014,24,26,4,0.99775,482,ahmed abdelali,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper presents the AMARA corpus of on-line educational content: a new parallel corpus of educational video subtitles, multilingually aligned for 20 languages, i.e. 20 monolingual corpora and 190 parallel corpora. This corpus includes both resource-rich languages such as English and Arabic, and resource-poor languages such as Hindi and Thai. In this paper, we describe the gathering, validation, and preprocessing of a large collection of parallel, community-generated subtitles. Furthermore, we describe the methodology used to prepare the data for Machine Translation tasks. Additionally, we provide a document-level, jointly aligned development and test sets for 14 language pairs, designed for tuning and testing Machine Translation systems. We provide baseline results for these tasks, and highlight some of the challenges we face when building machine translation systems for educational content."
2014.iwslt-papers.1,Advances in dialectal {A}rabic speech recognition: a study using {T}witter to improve {E}gyptian {ASR},2014,-1,-1,3,0,12956,ahmed ali,Proceedings of the 11th International Workshop on Spoken Language Translation: Papers,0,"This paper reports results in building an Egyptian Arabic speech recognition system as an example for under-resourced languages. We investigated different approaches to build the system using 10 hours for training the acoustic model, and results for both grapheme system and phoneme system using MADA. The phoneme-based system shows better results than the grapheme-based system. In this paper, we explore the use of tweets written in dialectal Arabic. Using 880K Egyptian tweets reduced the Out Of Vocabulary (OOV) rate from 15.1{\%} to 3.2{\%} and the WER from 59.6{\%} to 44.7{\%}, a relative gain 25{\%} in WER."
W13-2246,{MT} Quality Estimation: The {CMU} System for {WMT}{`}13,2013,-1,-1,2,0,40956,silja hildebrand,Proceedings of the Eighth Workshop on Statistical Machine Translation,0,None
R13-1066,Parameter Optimization for Statistical Machine Translation: It Pays to Learn from Hard Examples,2013,24,5,4,0.155073,1636,preslav nakov,Proceedings of the International Conference Recent Advances in Natural Language Processing {RANLP} 2013,0,"Research on statistical machine translation has focused on particular translation directions, typically with English as the target language, e.g., from Arabic to English. When we reverse the translation direction, the multiple reference translations turn into multiple possible inputs, which offers both challenges and opportunities. We propose and evaluate several strategies for making use of these multiple inputs: (a) select one of the datasets, (b) select the best input for each sentence, and (c) synthesize an input for each sentence by fusing the available inputs. Surprisingly, we find out that it is best to tune on the hardest available input, not on the one that yields the highest BLEU score. This finding has implications on how to pick good translators and how to select useful data for parameter optimization in SMT."
P13-2003,A Tale about {PRO} and Monsters,2013,20,13,3,0.155073,1636,preslav nakov,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"While experimenting with tuning on long sentences, we made an unexpected discovery: that PRO falls victim to monsters xe2x80x90 overly long negative examples with very low BLEU1 scores, which are unsuitable for learning and can cause testing BLEU to drop by several points absolute. We propose several effective ways to address the problem, using length- and BLEU1based cut-offs, outlier filters, stochastic sampling, and random acceptance. The best of these fixes not only slay and protect against monsters, but also yield higher stability for PRO as well as improved testtime BLEU scores. Thus, we recommend them to anybody using PRO, monsterbeliever or not."
P13-1156,Integrating Phrase-based Reordering Features into a Chart-based Decoder for Machine Translation,2013,14,13,2,1,41511,thuylinh nguyen,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Hiero translation models have two limitations compared to phrase-based models: 1) Limited hypothesis space; 2) No lexicalized reordering model. We propose an extension of Hiero called PhrasalHiero to address Hieroxe2x80x99s second problem. Phrasal-Hiero still has the same hypothesis space as the original Hiero but incorporates a phrase-based distance cost feature and lexicalized reodering features into the chart decoder. The work consists of two parts: 1) for each Hiero translation derivation, find its corresponding discontinuous phrase-based path. 2) Extend the chart decoder to incorporate features from the phrase-based path. We achieve significant improvement over both Hiero and phrase-based baselines for ArabicEnglish, Chinese-English and GermanEnglish translation."
2013.iwslt-papers.2,The {AMARA} corpus: building resources for translating the web{'}s educational content,2013,24,10,3,1,7331,francisco guzman,Proceedings of the 10th International Workshop on Spoken Language Translation: Papers,0,"In this paper, we introduce a new parallel corpus of subtitles of educational videos: the AMARA corpus for online educational content. We crawl a multilingual collection community generated subtitles, and present the results of processing the Arabic{--}English portion of the data, which yields a parallel corpus of about 2.6M Arabic and 3.9M English words. We explore different approaches to align the segments, and extrinsically evaluate the resulting parallel corpus on the standard TED-talks tst-2010. We observe that the data can be successfully used for this task, and also observe an absolute improvement of 1.6 BLEU when it is used in combination with TED data. Finally, we analyze some of the specific challenges when translating the educational content."
2013.iwslt-evaluation.8,{QCRI} at {IWSLT} 2013: experiments in {A}rabic-{E}nglish and {E}nglish-{A}rabic spoken language translation,2013,27,15,7,0.762691,3156,hassan sajjad,Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We describe the Arabic-English and English-Arabic statistical machine translation systems developed by the Qatar Computing Research Institute for the IWSLT{'}2013 evaluation campaign on spoken language translation. We used one phrase-based and two hierarchical decoders, exploring various settings thereof. We further experimented with three domain adaptation methods, and with various Arabic word segmentation schemes. Combining the output of several systems yielded a gain of up to 3.4 BLEU points over the baseline. Here we also describe a specialized normalization scheme for evaluating Arabic output, which was adopted for the IWSLT{'}2013 evaluation campaign."
W12-3136,{QCRI} at {WMT}12: Experiments in {S}panish-{E}nglish and {G}erman-{E}nglish Machine Translation of News Text,2012,11,5,4,1,7331,francisco guzman,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"We describe the systems developed by the team of the Qatar Computing Research Institute for the WMT12 Shared Translation Task. We used a phrase-based statistical machine translation model with several non-standard settings, most notably tuning data selection and phrase table combination. The evaluation results show that we rank second in BLEU and TER for Spanish-English, and in the top tier for German-English."
C12-3042,Nonparametric Model for {I}nupiaq Word Segmentation,2012,8,0,2,0.952381,43669,thuy nguyen,Proceedings of {COLING} 2012: Demonstration Papers,0,None
C12-1063,Understanding the Performance of Statistical {MT} Systems: A Linear Regression Framework,2012,23,1,2,1,7331,francisco guzman,Proceedings of {COLING} 2012,0,"We present a framework for the analysis of Machine Translation performance. We use multivariate linear models to determine the impact of a wide range of features on translation performance. Our assumption is that variables that most contribute to predict translation performance are the key to understand the differences between good and bad translations. During training, we learn the regression parameters that better predict translation quality using a wide range of input features based on the translation model and the first-best translation hypotheses. We use a linear regression with regularization. Our results indicate that with regularized linear regression, we can achieve higher levels of correlation between our predicted values and the actual values of the quality metrics. Our analysis shows that the performance for in-domain data is largely dependent on the characteristics of the translation model. On the other hand, out-of domain data can benefit from better reordering strategies."
C12-1121,Optimizing for Sentence-Level {BLEU}+1 Yields Short Translations,2012,22,43,3,0.155073,1636,preslav nakov,Proceedings of {COLING} 2012,0,"We study a problem with pairwise ranking optimization (PRO): that it tends to yield too short translations. We find that this is partially due to the inadequate smoothing in PROxe2x80x99s BLEU1, which boosts the precision component of BLEU but leaves the brevity penalty unchanged, thus destroying the balance between the two, compared to BLEU. It is also partially due to PRO optimizing for a sentence-level score without a global view on the overall length, which introducing a bias towards short translations; we show that letting PRO optimize a corpus-level BLEU yields a perfect length. Finally, we find some residual bias due to the interaction of PRO with BLEU1: such a bias does not exist for a version of MIRA with sentence-level BLEU1. We propose several ways to fix the length problem of PRO, including smoothing the brevity penalty, scaling the effective reference length, grounding the precision component, and unclipping the brevity penalty, which yield sizable improvements in test BLEU on two Arabic-English datasets: IWSLT (0.65) and NIST (0.37)."
W11-2124,Wider Context by Using Bilingual Language Models in Machine Translation,2011,18,60,3,0.432099,5714,jan niehues,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"In past Evaluations for Machine Translation of European Languages, it could be shown that the translation performance of SMT systems can be increased by integrating a bilingual language model into a phrase-based SMT system. In the bilingual language model, target words with their aligned source words build the tokens of an n-gram based language model. We analyzed the effect of bilingual language models and show where they could help to better model the translation process. We could show improvements of translation quality on German-to-English and Arabic-to-English. In addition, for the Arabic-to-English task, training an extra bilingual language model on the POS tags instead of the surface word forms led to further improvements."
W11-2146,{CMU} {H}aitian {C}reole-{E}nglish Translation System for {WMT} 2011,2011,15,6,5,1,37937,sanjika hewavitharana,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the statistical machine translation system submitted to the WMT11 Featured Translation Task, which involves translating Haitian Creole SMS messages into English. In our experiments we try to address the issue of noise in the training data, as well as the lack of parallel training data. Spelling normalization is applied to reduce out-of-vocabulary words in the corpus. Using Semantic Role Labeling rules we expand the available training corpus. Additionally we investigate extracting parallel sentences from comparable data to enhance the available parallel data."
W11-2164,Crisis {MT}: Developing A Cookbook for {MT} in Crisis Situations,2011,23,26,3,0,36762,william lewis,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"In this paper, we propose that MT is an important technology in crisis events, something that can and should be an integral part of a rapid-response infrastructure. By integrating MT services directly into a messaging infrastructure (whatever the type of messages being serviced, e.g., text messages, Twitter feeds, blog postings, etc.), MT can be used to provide first pass translations into a majority language, which can be more effectively triaged and then routed to the appropriate aid agencies. If done right, MT can dramatically increase the speed by which relief can be provided. To ensure that MT is a standard tool in the arsenal of tools needed in crisis events, we propose a preliminary Crisis Cookbook, the contents of which could be translated into the relevant language(s) by volunteers immediately after a crisis event occurs. The resulting data could then be made available to relief groups on the ground, as well as to providers of MT services. We also note that there are significant contributions that our community can make to relief efforts through continued work on our research, especially that research which makes MT more viable for under-resourced languages."
W11-1209,Extracting Parallel Phrases from Comparable Data,2011,18,27,2,1,37937,sanjika hewavitharana,Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web,0,"Mining parallel data from comparable corpora is a promising approach for overcoming the data sparseness in statistical machine translation and other NLP applications. Even if two comparable documents have few or no parallel sentence pairs, there is still potential for parallelism in the sub-sentential level. The ability to detect these phrases creates a valuable resource, especially for low-resource languages. In this paper we explore three phrase alignment approaches to detect parallel phrase pairs embedded in comparable sentences: the standard phrase extraction algorithm, which relies on the Viterbi path; a phrase extraction approach that does not rely on the Viterbi path, but uses only lexical features; and a binary classifier that detects parallel phrase pairs when presented with a large collection of phrase pair candidates. We evaluate the effectiveness of these approaches in detecting alignments for phrase pairs that have a known alignment in comparable sentence pairs. The results show that the Non-Viterbi alignment approach outperforms the other two approaches on F1 measure."
W11-1210,Active Learning with Multiple Annotations for Comparable Data Classification Task,2011,18,5,3,1,44215,vamshi ambati,Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web,0,Supervised learning algorithms for identifying comparable sentence pairs from a dominantly non-parallel corpora require resources for computing feature functions as well as training the classifier. In this paper we propose active learning techniques for addressing the problem of building comparable data for low-resource languages. In particular we propose strategies to elicit two kinds of annotations from comparable sentence pairs: class label assignment and parallel segment extraction. We also propose an active learning strategy for these two annotations that performs significantly better than when sampling for either of the annotations independently.
W11-1012,Utilizing Target-Side Semantic Role Labels to Assist Hierarchical Phrase-based Machine Translation,2011,21,9,2,1,40070,qin gao,"Proceedings of Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"In this paper we present a novel approach of utilizing Semantic Role Labeling (SRL) information to improve Hierarchical Phrase-based Machine Translation. We propose an algorithm to extract SRL-aware Synchronous Context-Free Grammar (SCFG) rules. Conventional Hiero-style SCFG rules will also be extracted in the same framework. Special conversion rules are applied to ensure that when SRL-aware SCFG rules are used in derivation, the decoder only generates hypotheses with complete semantic structures. We perform machine translation experiments using 9 different Chinese-English test-sets. Our approach achieved an average BLEU score improvement of 0.49 as well as 1.21 point reduction in TER."
P11-2051,Corpus Expansion for Statistical Machine Translation with Semantic Role Label Substitution Rules,2011,8,20,2,1,40070,qin gao,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"We present an approach of expanding parallel corpora for machine translation. By utilizing Semantic role labeling (SRL) on one side of the language pair, we extract SRL substitution rules from existing parallel corpus. The rules are then used for generating new sentence pairs. An SVM classifier is built to filter the generated sentence pairs. The filtered corpus is used for training phrase-based translation models, which can be used directly in translation tasks or combined with baseline models. Experimental results on Chinese-English machine translation tasks show an average improvement of 0.45 BLEU and 1.22 TER points across 5 different NIST test sets."
P11-2066,Dealing with Spurious Ambiguity in Learning {ITG}-based Word Alignment,2011,13,2,2,0,4607,shujian huang,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"Word alignment has an exponentially large search space, which often makes exact inference infeasible. Recent studies have shown that inversion transduction grammars are reasonable constraints for word alignment, and that the constrained space could be efficiently searched using synchronous parsing algorithms. However, spurious ambiguity may occur in synchronous parsing and cause problems in both search efficiency and accuracy. In this paper, we conduct a detailed study of the causes of spurious ambiguity and how it effects parsing and discriminative learning. We also propose a variant of the grammar which eliminates those ambiguities. Our grammar shows advantages over previous grammars in both synthetic and real-world experiments."
P11-1001,A Word-Class Approach to Labeling {PSCFG} Rules for Machine Translation,2011,26,17,2,1,44639,andreas zollmann,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"In this work we propose methods to label probabilistic synchronous context-free grammar (PSCFG) rules using only word tags, generated by either part-of-speech analysis or unsupervised word class induction. The proposals range from simple tag-combination schemes to a phrase clustering model that can incorporate an arbitrary number of features.n n Our models improve translation quality over the single generic label approach of Chiang (2005) and perform on par with the syntactically motivated approach from Zollmann and Venugopal (2006) on the NIST large Chinese-to-English translation task. These results persist when using automatically learned word tags, suggesting broad applicability of our technique across diverse language pairs for which syntactic resources are not available."
I11-1053,{T}ri{S}: A Statistical Sentence Simplifier with Log-linear Models and Margin-based Discriminative Training,2011,36,9,3,1,9067,nguyen bach,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We propose a statistical sentence simplification system with log-linear models. In contrast to state-of-the-art methods that drive sentence simplification process by hand-written linguistic rules, our method used a margin-based discriminative learning algorithm operates on a feature set. The feature set is defined on statistics of surface form as well as syntactic and dependency structures of the sentences. A stack decoding algorithm is used which allows us to efficiently generate and search simplification hypotheses. Experimental results show that the simplified text produced by the proposed system reduces 1.7 Flesch-Kincaid grade level when compared with the original text. We will show that a comparison of a state-ofthe-art rule-based system (Heilman and Smith, 2010) to the proposed system demonstrates an improvement of 0.2, 0.6, and 4.5 points in ROUGE-2, ROUGE-4, andAveF 10 , respectively."
2011.mtsummit-papers.12,Multi-Strategy Approaches to Active Learning for Statistical Machine Translation,2011,17,3,2,1,44215,vamshi ambati,Proceedings of Machine Translation Summit XIII: Papers,0,"This paper investigates active learning to improve statistical machine translation (SMT) for low-resource language pairs, i.e., when there is very little pre-existing parallel text. Since generating additional parallel text to train SMT may be costly, active sampling selects the sentences from a monolingual corpus which if translated would have maximal positive impact in training SMT models. We investigate different strategies such as density and diversity preferences as well as multistrategy methods such as modified version of DUAL and our new ensemble approach GraDUAL. These result in significant BLEU-score improvements over strong baselines when parallel training data is scarce."
2011.iwslt-evaluation.23,Extending a probabilistic phrase alignment approach for {SMT},2011,16,2,3,0,44097,mridul gupta,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"Phrase alignment is a crucial step in phrase-based statistical machine translation. We explore a way of improving phrase alignment by adding syntactic information in the form of chunks as soft constraints guided by an in-depth and detailed analysis on a hand-aligned data set. We extend a probabilistic phrase alignment model that extracts phrase pairs by optimizing phrase pair boundaries over the sentence pair [1]. The boundaries of the target phrase are chosen such that the overall sentence alignment probability is optimal. Viterbi alignment information is also added in the extended model with a view of improving phrase alignment. We extract phrase pairs using a relatively larger number of features which are discriminatively trained using a large-margin online learning algorithm, i.e., Margin Infused Relaxed Algorithm (MIRA) and integrate it in our approach. Initial experiments show improvements in both phrase alignment and translation quality for Arabic-English on a moderate-size translation task."
W10-4127,A Multi-layer {C}hinese Word Segmentation System Optimized for Out-of-domain Tasks,2010,12,7,2,1,40070,qin gao,{CIPS}-{SIGHAN} Joint Conference on {C}hinese Language Processing,0,None
W10-3814,New Parameterizations and Features for {PSCFG}-Based Machine Translation,2010,26,2,2,1,44639,andreas zollmann,Proceedings of the 4th Workshop on Syntax and Structure in Statistical Translation,0,"We propose several improvements to the hierarchical phrase-based MT model of Chiang (2005) and its syntax-based extension by Zollmann and Venugopal (2006). We add a source-span variance model that, for each rule utilized in a probabilistic synchronous context-free grammar (PSCFG) derivation, gives a confidence estimate in the rule based on the number of source words spanned by the rule and its substituted child rules, with the distributions of these source span sizes estimated during training time. We further propose different methods of combining hierarchical and syntax-based PSCFG models, by merging the grammars as well as by interpolating the translation models. Finally, we compare syntax-augmented MT, which extracts rules based on targetside syntax, to a corresponding variant based on source-side syntax, and experiment with a model extension that jointly takes source and target syntax into account."
W10-1701,A Semi-Supervised Word Alignment Algorithm with Partial Manual Alignments,2010,22,22,3,1,40070,qin gao,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"We present a word alignment framework that can incorporate partial manual alignments. The core of the approach is a novel semi-supervised algorithm extending the widely used IBM Models with a constrained EM algorithm. The partial manual alignments can be obtained by human labelling or automatically by high-precision-low-recall heuristics. We demonstrate the usages of both methods by selecting alignment links from manually aligned corpus and apply links generated from bilingual dictionary on unlabelled data. For the first method, we conduct controlled experiments on Chinese-English and Arabic-English translation tasks to compare the quality of word alignment, and to measure effects of two different methods in selecting alignment links from manually aligned corpus. For the second method, we experimented with moderate-scale Chinese-English translation task. The experiment results show an average improvement of 0.33 BLEU point across 8 test sets."
W10-1745,{CMU} System Combination via Hypothesis Selection for {WMT}{'}10,2010,7,6,2,1,28512,almut hildebrand,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"This paper describes the CMU entry for the system combination shared task at WMT'10. Our combination method is hypothesis selection, which uses information from n-best lists from the input MT systems, where available. The sentence level features used are independent from the MT systems involved. Compared to the baseline we added source-to-target word alignment based features and trained system weights to our feature set. We combined MT systems for French - English and German - English using provided data only."
W10-0704,Semi-supervised Word Alignment with {M}echanical {T}urk,2010,7,2,2,1,40070,qin gao,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,None
W10-0710,Can Crowds Build parallel corpora for Machine Translation Systems?,2010,6,49,2,1,44215,vamshi ambati,Proceedings of the {NAACL} {HLT} 2010 Workshop on Creating Speech and Language Data with {A}mazon{'}s Mechanical Turk,0,"Corpus based approaches to machine translation (MT) rely on the availability of parallel corpora. In this paper we explore the effectiveness of Mechanical Turk for creating parallel corpora. We explore the task of sentence translation, both into and out of a language. We also perform preliminary experiments for the task of phrase translation, where ambiguous phrases are provided to the turker for translation in isolation and in the context of the sentence it originated from."
W10-0102,Active Semi-Supervised Learning for Improving Word Alignment,2010,27,3,2,1,44215,vamshi ambati,Proceedings of the {NAACL} {HLT} 2010 Workshop on Active Learning for Natural Language Processing,0,Word alignment models form an important part of building statistical machine translation systems. Semi-supervised word alignment aims to improve the accuracy of automatic word alignment by incorporating full or partial alignments acquired from humans. Such dedicated elicitation effort is often expensive and depends on availability of bilingual speakers for the language-pair. In this paper we study active learning query strategies to carefully identify highly uncertain or most informative alignment links that are proposed under an unsupervised word alignment model. Manual correction of such informative links can then be applied to create a labeled dataset used by a semi-supervised word alignment model. Our experiments show that using active learning leads to maximal reduction of alignment error rates with reduced human effort.
P10-2027,Fixed Length Word Suffix for Factored Statistical Machine Translation,2010,7,4,2,0,21884,narges razavian,Proceedings of the {ACL} 2010 Conference Short Papers,0,"Factored Statistical Machine Translation extends the Phrase Based SMT model by allowing each word to be a vector of factors. Experiments have shown effectiveness of many factors, including the Part of Speech tags in improving the grammaticality of the output. However, high quality part of speech taggers are not available in open domain for many languages. In this paper we used fixed length word suffix as a new factor in the Factored SMT, and were able to achieve significant improvements in three set of experiments: large NIST Arabic to English system, medium WMT Spanish to English system, and small TRANSTAC English to Iraqi system."
P10-2067,Active Learning-Based Elicitation for Semi-Supervised Word Alignment,2010,23,3,2,1,44215,vamshi ambati,Proceedings of the {ACL} 2010 Conference Short Papers,0,"Semi-supervised word alignment aims to improve the accuracy of automatic word alignment by incorporating full or partial manual alignments. Motivated by standard active learning query sampling frameworks like uncertainty-, margin- and query-by-committee sampling we propose multiple query strategies for the alignment link selection task. Our experiments show that by active selection of uncertain and informative links, we reduce the overall manual effort involved in elicitation of alignment link data for training a semi-supervised word aligner."
ambati-etal-2010-active,Active Learning and Crowd-Sourcing for Machine Translation,2010,17,126,2,1,44215,vamshi ambati,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Large scale parallel data generation for new language pairs requires intensive human effort and availability of experts. It becomes immensely difficult and costly to provide Statistical Machine Translation (SMT) systems for most languages due to the paucity of expert translators to provide parallel data. Even if experts are present, it appears infeasible due to the impending costs. In this paper we propose Active Crowd Translation (ACT), a new paradigm where active learning and crowd-sourcing come together to enable automatic translation for low-resource language pairs. Active learning aims at reducing cost of label acquisition by prioritizing the most informative data for annotation, while crowd-sourcing reduces cost by using the power of the crowds to make do for the lack of expensive language experts. We experiment and compare our active learning strategies with strong baselines and see significant improvements in translation quality. Similarly, our experiments with crowd-sourcing on Mechanical Turk have shown that it is possible to create parallel corpora using non-experts and with sufficient quality assurance, a translation system that is trained using this corpus approaches expert quality."
C10-1040,{EMDC}: A Semi-supervised Approach for Word Alignment,2010,18,1,3,1,40070,qin gao,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,This paper proposes a novel semi-supervised word alignment technique called EMDC that integrates discriminative and generative methods. A discriminative aligner is used to find high precision partial alignments that serve as constraints for a generative aligner which implements a constrained version of the EM algorithm. Experiments on small-size Chinese and Arabic tasks show consistent improvements on AER. We also experimented with moderate-size Chinese machine translation tasks and got an average of 0.5 point improvement on BLEU scores across five standard NIST test sets and four other test sets.
C10-1092,Nonparametric Word Segmentation for Machine Translation,2010,24,32,2,1,41511,thuylinh nguyen,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"We present an unsupervised word segmentation model for machine translation. The model uses existing monolingual segmentation techniques and models the joint distribution over source sentence segmentations and alignments to the target sentence. During inference, the monolingual segmentation model and the bilingual word alignment model are coupled so that the alignments to the target sentence guide the segmentation of the source sentence. The experiments show improvements on Arabic-English and Chinese-English translation tasks."
W09-0406,{CMU} System Combination for {WMT}{`}09,2009,-1,-1,2,1,28512,almut hildebrand,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,None
N09-2001,Cohesive Constraints in A Beam Search Phrase-based Decoder,2009,30,12,2,1,9067,nguyen bach,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"Cohesive constraints allow the phrase-based decoder to employ arbitrary, non-syntactic phrases, and encourage it to translate those phrases in an order that respects the source dependency tree structure. We present extensions of the cohesive constraints, such as exhaustive interruption count and rich interruption check. We show that the cohesion-enhanced decoder significantly outperforms the standard phrase-based decoder on Englishxe2x86x92Spanish. Improvements between 0.5 and 1.2 BLEU point are obtained on Englishxe2x86x92Iraqi system."
N09-2038,Incremental Adaptation of Speech-to-Speech Translation,2009,9,11,5,1,9067,nguyen bach,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"In building practical two-way speech-to-speech translation systems the end user will always wish to use the system in an environment different from the original training data. As with all speech systems, it is important to allow the system to adapt to the actual usage situations. This paper investigates how a speech-to-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two. The platform is the CMU Iraqi-English portable two-way speech-to-speech system as developed under the DARPA TransTac program. We show how machine translation, speech recognition and overall system performance can be improved on day 2 after adapting from day 1 in both a supervised and unsupervised way."
N09-1027,Preference Grammars: Softening Syntactic Constraints to Improve Statistical Machine Translation,2009,20,46,4,1,44842,ashish venugopal,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We propose a novel probabilistic synchoronous context-free grammar formalism for statistical machine translation, in which syntactic nonterminal labels are represented as soft preferences rather than as hard matching constraints. This formalism allows us to efficiently score unlabeled synchronous derivations without forgoing traditional syntactic constraints. Using this score as a feature in a log-linear model, we are able to approximate the selection of the most likely unlabeled derivation. This helps reduce fragmentation of probability across differently labeled derivations of the same translation. It also allows the importance of syntactic preferences to be learned alongside other features (e.g., the language model) and for particular labeling procedures. We show improvements in translation quality on small and medium sized Chinese-to-English translation tasks."
2009.mtsummit-papers.1,Source-side Dependency Tree Reordering Models with Subtree Movements and Constraints,2009,-1,-1,3,1,9067,nguyen bach,Proceedings of Machine Translation Summit XII: Papers,0,None
2009.mtsummit-papers.5,Reassessment of the Role of Phrase Extraction in {PBSMT},2009,8,10,3,1,7331,francisco guzman,Proceedings of Machine Translation Summit XII: Papers,0,"In this paper we study in detail the relation between word alignment and phrase extraction. First, we analyze different word alignments according to several characteristics and compare them to hand-aligned data. Secondly, we analyzed the phrase-pairs generated by these alignments. We observed that the number of unaligned words has a large impact on the characteristics of the phrase table. A manual evaluation of phrase pair quality showed that the increase in the number of unaligned words results in a lower quality. Finally, we present translation results from using the number of unaligned words as features from which we obtain up to 2BP of improvement."
W08-2118,Context-based {A}rabic Morphological Analysis for Machine Translation,2008,16,10,2,1,41511,thuylinh nguyen,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"In this paper, we present a novel morphology preprocessing technique for Arabic-English translation. We exploit the Arabic morphology-English alignment to learn a model removing nonaligned Arabic morphemes. The model is an instance of the Conditional Random Field (Lafferty et al., 2001) model; it deletes a morpheme based on the morpheme's context. We achieved around two BLEU points improvement over the original Arabic translation for both a travel-domain system trained on 20K sentence pairs and a news domain system trained on 177K sentence pairs, and showed a potential improvement for a large-scale SMT system trained on 5 million sentence pairs."
W08-0509,Parallel Implementations of Word Alignment Tool,2008,7,257,2,1,40070,qin gao,"Software Engineering, Testing, and Quality Assurance for Natural Language Processing",0,"Training word alignment models on large corpora is a very time-consuming processes. This paper describes two parallel implementations of GIZA that accelerate this word alignment process. One of the implementations runs on computer clusters, the other runs on multi-processor system using multi-threading technology. Results show a near-linear speed-up according to the number of CPUs used, and alignment quality is preserved."
W08-0303,Discriminative Word Alignment via Alignment Matrix Modeling,2008,22,46,2,0.666667,5714,jan niehues,Proceedings of the Third Workshop on Statistical Machine Translation,0,"In this paper a new discriminative word alignment method is presented. This approach models directly the alignment matrix by a conditional random field (CRF) and so no restrictions to the alignments have to be made. Furthermore, it is easy to add features and so all available information can be used. Since the structure of the CRFs can get complex, the inference can only be done approximately and the standard algorithms had to be adapted. In addition, different methods to train the model have been developed. Using this approach the alignment quality could be improved by up to 23 percent for 3 different language pairs compared to a combination of both IBM4-alignments. Furthermore the word alignment was used to generate new phrase tables. These could improve the translation quality significantly."
W08-0321,Improving Word Alignment with Language Model Based Confidence Scores,2008,11,6,3,1,9067,nguyen bach,Proceedings of the Third Workshop on Statistical Machine Translation,0,"This paper describes the statistical machine translation systems submitted to the ACL-WMT 2008 shared translation task. Systems were submitted for two translation directions: Englishxe2x86x92Spanish and Spanishxe2x86x92English. Using sentence pair confidence scores estimated with source and target language models, improvements are observed on the News-Commentary test sets. Genre-dependent sentence pair confidence score and integration of sentence pair confidence score into phrase table are also investigated."
P08-2020,Recent Improvements in the {CMU} Large Scale {C}hinese-{E}nglish {SMT} System,2008,9,5,7,1,28512,almut hildebrand,"Proceedings of ACL-08: HLT, Short Papers",0,"In this paper we describe recent improvements to components and methods used in our statistical machine translation system for Chinese-English used in the January 2008 GALE evaluation. Main improvements are results of consistent data processing, larger statistical models and a POS-based word reordering approach."
eck-etal-2008-communicating,Communicating Unknown Words in Machine Translation,2008,15,12,2,1,40353,matthias eck,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"A new approach to handle unknown words in machine translation is presented. The basic idea is to find definitions for the unknown words on the source language side and translate those definitions instead. Only monolingual resources are required, which generally offer a broader coverage than bilingual resources and are available for a large number of languages. In order to use this in a machine translation system definitions are extracted automatically from online dictionaries and encyclopedias. The translated definition is then inserted and clearly marked in the original hypothesis. This is shown to lead to significant improvements in (subjective) translation quality."
2008.iwslt-evaluation.2,The {CMU} syntax-augmented machine translation system: {SAMT} on Hadoop with n-best alignments.,2008,23,7,3,1,44639,andreas zollmann,Proceedings of the 5th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We present the CMU Syntax Augmented Machine Translation System that was used in the IWSLT-08 evaluation campaign. We participated in the Full-BTEC data track for Chinese-English translation, focusing on transcript translation. For this year{'}s evaluation, we ported the Syntax Augmented MT toolkit [1] to the Hadoop MapReduce [2] parallel processing architecture, allowing us to efficiently run experiments evaluating a novel {``}wider pipelines{''} approach to integrate evidence from N -best alignments into our translation models. We describe each step of the MapReduce pipeline as it is implemented in the open-source SAMT toolkit, and show improvements in translation quality by using N-best alignments in both hierarchical and syntax augmented translation systems."
2008.amta-srw.3,Combination of Machine Translation Systems via Hypothesis Selection from Combined N-Best Lists,2008,15,50,2,1,28512,almut hildebrand,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Student Research Workshop,0,"Different approaches in machine translation achieve similar translation quality with a variety of translations in the output. Recently it has been shown, that it is possible to leverage the individual strengths of various systems and improve the overall translation quality by combining translation outputs. In this paper we present a method of hypothesis selection which is relatively simple compared to system combination methods which construct a synthesis of the input hypotheses. Our method uses information from n-best lists from several MT systems and features on the sentence level which are independent from the MT systems involved to improve the translation quality."
2008.amta-srw.5,Diacritization as a Machine Translation and as a Sequence Labeling Problem,2008,18,12,3,0,39405,tim schlippe,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Student Research Workshop,0,"In this paper we describe and compare two techniques for the automatic diacritization of Arabic text: First, we treat diacritization as a monotone machine translation problem, proposing and evaluating several translation and language models, including word and character-based models separately and combined as well as a model which uses statistical machine translation (SMT) to post-edit a rule-based diacritization system. Then we explore a more traditional view of diacritization as a sequence labeling problem, and propose a solution using conditional random fields (Lafferty et al., 2001). All these techniques are compared through word error rate and diacritization error rate both in terms of full diacritization and ignoring vowel endings. The empirical experiments showed that the machine translation approaches perform better than the sequence labeling approaches concerning the error rates."
2008.amta-papers.18,Wider Pipelines: N-Best Alignments and Parses in {MT} Training,2008,24,28,4,1,44842,ashish venugopal,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"State-of-the-art statistical machine translation systems use hypotheses from several maximum a posteriori inference steps, including word alignments and parse trees, to identify translational structure and estimate the parameters of translation models. While this approach leads to a modular pipeline of independently developed components, errors made in these {``}single-best{''} hypotheses can propagate to downstream estimation steps that treat these inputs as clean, trustworthy training data. In this work we integrate N-best alignments and parses by using a probability distribution over these alternatives to generate posterior fractional counts for use in downstream estimation. Using these fractional counts in a DOP-inspired syntax-based translation system, we show significant improvements in translation quality over a single-best trained baseline."
W07-0727,The {ISL} Phrase-Based {MT} System for the 2007 {ACL} Workshop on Statistical Machine Translation,2007,13,10,5,0,14461,matthias paulik,Proceedings of the Second Workshop on Statistical Machine Translation,0,"In this paper we describe the Interactive Systems Laboratories (ISL) phrase-based machine translation system used in the shared task Machine Translation for European Languages of the ACL 2007 Workshop on Statistical Machine Translation. We present results for a system combination of the ISL syntax-augmented MT system and the ISL phrase-based system by combining and rescoring the n-best lists of the two systems. We also investigate the combination of two of our phrase-based systems translating from different source languages, namely Spanish and German, into their common target language, English."
W07-0731,The Syntax Augmented {MT} ({SAMT}) System at the Shared Task for the 2007 {ACL} Workshop on Statistical Machine Translation,2007,12,6,4,1,44639,andreas zollmann,Proceedings of the Second Workshop on Statistical Machine Translation,0,"We describe the CMU-UKA Syntax Augmented Machine Translation system 'SAMT' used for the shared task Machine Translation for European Languages at the ACL 2007 Workshop on Statistical Machine Translation. Following an overview of syntax augmented machine translation, we describe parameters for components in our open-source SAMT toolkit that were used to generate translation results for the Spanish to English in-domain track of the shared task and discuss relative performance against our phrase-based submission."
W07-0410,A Walk on the Other Side: Using {SMT} Components in a Transfer-Based Translation System,2007,0,0,2,0,48477,ariadna llitjos,"Proceedings of {SSST}, {NAACL}-{HLT} 2007 / {AMTA} Workshop on Syntax and Structure in Statistical Translation",0,None
N07-2006,Translation Model Pruning via Usage Statistics for Statistical Machine Translation,2007,10,13,2,1,40353,matthias eck,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,We describe a new pruning approach to remove phrase pairs from translation models of statistical machine translation systems. The approach applies the original translation system to a large amount of text and calculates usage statistics for the phrase pairs. Using these statistics the relevance of each phrase pair can be estimated. The approach is tested against a strong baseline based on previous work and shows significant improvements.
N07-1046,A Log-Linear Block Transliteration Model based on Bi-Stream {HMM}s,2007,20,23,4,0.882353,44678,bing zhao,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"We propose a novel HMM-based framework to accurately transliterate unseen named entities. The framework leverages features in letteralignment and letter n-gram pairs learned from available bilingual dictionaries. Letter-classes, such as vowels/non-vowels, are integrated to further improve transliteration accuracy. The proposed transliteration system is applied to out-of-vocabulary named-entities in statistical machine translation (SMT), and a significant improvement over traditional transliteration approach is obtained. Furthermore, by incorporating an automatic spell-checker based on statistics collected from web search engines, transliteration accuracy is further improved. The proposed system is implemented within our SMT system and applied to a real translation scenario from Arabic to English."
N07-1063,An Efficient Two-Pass Approach to Synchronous-{CFG} Driven Statistical {MT},2007,15,53,3,1,44842,ashish venugopal,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"We present an efficient, novel two-pass approach to mitigate the computational impact resulting from online intersection of an n-gram language model (LM) and a probabilistic synchronous context-free grammar (PSCFG) for statistical machine translation. In first pass CYK-style decoding, we consider first-best chart item approximations, generating a hypergraph of sentence spanning target language derivations. In the second stage, we instantiate specific alternative derivations from this hypergraph, using the LM to drive this search process, recovering from search errors made in the first pass. Model search errors in our approach are comparable to those made by the state-of-the-art xe2x80x9cCube Pruningxe2x80x9d approach in (Chiang, 2007) under comparable pruning conditions evaluated on both hierarchical and syntax-based grammars."
2007.tmi-papers.21,Word reordering in statistical machine translation with a {POS}-based distortion model,2007,-1,-1,2,1,45526,kay rottmann,Proceedings of the 11th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,None
2007.mtsummit-papers.12,Enhancing image-based {A}rabic document translation using noisy channel correction model,2007,-1,-1,3,0,6406,yi chang,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.22,Estimating phrase pair relevance for translation model pruning,2007,-1,-1,2,1,40353,matthias eck,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.33,Experiments with a noun-phrase driven statistical machine translation system,2007,-1,-1,3,1,37937,sanjika hewavitharana,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.38,Iterative refinement of lexicon and phrasal alignment,2007,-1,-1,2,0,46632,jae kim,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.mtsummit-papers.72,{P}an{D}o{RA}: a large-scale two-way statistical machine translation system for hand-held devices,2007,-1,-1,2,1,7842,ying zhang,Proceedings of Machine Translation Summit XI: Papers,0,None
2007.iwslt-1.4,The {CMU} {T}rans{T}ac 2007 eyes-free two-way speech-to-speech translation system,2007,17,22,9,1,9067,nguyen bach,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"The paper describes our portable two-way speech-to-speech translation system using a completely eyes-free/hands-free user interface. This system translates between the language pair English and Iraqi Arabic as well as between English and Farsi, and was built within the framework of the DARPA TransTac program. The Farsi language support was developed within a 90-day period, testing our ability to rapidly support new languages. The paper gives an overview of the system{'}s components along with the individual component objective measures and a discussion of issues relevant for the overall usage of the system. We found that usability, flexibility, and robustness serve as severe constraints on system architecture and design."
2007.iwslt-1.9,The {CMU}-{UKA} statistical machine translation systems for {IWSLT} 2007,2007,19,1,6,1,23757,ian lane,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"This paper describes the CMU-UKA statistical machine translation systems submitted to the IWSLT 2007 evaluation campaign. Systems were submitted for three language-pairs: JapaneseEnglish, ChineseEnglish and ArabicEnglish. All systems were based on a common phrase-based SMT (statistical machine translation) framework but for each language-pair a specific research problem was tackled. For JapaneseEnglish we focused on two problems: first, punctuation recovery, and second, how to incorporate topic-knowledge into the translation framework. Our ChineseEnglish submission focused on syntax-augmented SMT and for the ArabicEnglish task we focused on incorporating morphological-decomposition into the SMT framework. This research strategy enabled us to evaluate a wide variety of approaches which proved effective for the language pairs they were evaluated on."
W06-1626,Distributed Language Modeling for $N$-best List Re-ranking,2006,18,79,3,1,7842,ying zhang,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we describe a novel distributed language model for N-best list re-ranking. The model is based on the client/server paradigm where each server hosts a portion of the data and provides information to the client. This model allows for using an arbitrarily large corpus in a very efficient way. It also provides a natural platform for relevance weighting and selection. We applied this model on a 2.97 billion-word corpus and re-ranked the N-best list from Hiero, a state-of-the-art phrase-based system. Using BLEU as a metric, the re-ranked translation achieves a relative improvement of 4.8%, significantly better than the model-best translation."
N06-2051,Bridging the Inflection Morphology Gap for {A}rabic Statistical Machine Translation,2006,12,35,3,1,44639,andreas zollmann,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Short Papers",0,"Statistical machine translation (SMT) is based on the ability to effectively learn word and phrase relationships from parallel corpora, a process which is considerably more difficult when the extent of morphological expression differs significantly across the source and target languages. We present techniques that select appropriate word segmentations in the morphologically rich source language based on contextual relationships in the target language. Our results take advantage of existing word level morphological analysis components to improve translation quality above state-of-the-art on a limited-data Arabic to English speech translation task."
2006.iwslt-evaluation.19,The {UKA}/{CMU} statistical machine translation system for {IWSLT} 2006,2006,-1,-1,8,1,40353,matthias eck,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,None
2006.iwslt-evaluation.20,The {CMU}-{UKA} syntax augmented machine translation system for {IWSLT}-06,2006,12,12,3,1,44639,andreas zollmann,Proceedings of the Third International Workshop on Spoken Language Translation: Evaluation Campaign,0,"We present the CMU-UKA Syntax Augmented Machine Translation System that was used in the IWSLT-06 evaluation campaign. We participated in the C-Star data track using only the Full BTEC corpus, for Chinese-English translation, focusing on transcript translation. We applied techniques that produce true-cased, punctuated translations from non-punctuated Chinese transcripts, generating translations which score higher against the Official metric than against the lower-cased, punctuation removed metric. Our results demonstrate the impact of syntax and hierarchy based models for speech transcript translation."
2006.eamt-1.12,A Flexible Online Server for Machine Translation Evaluation,2006,6,3,2,1,40353,matthias eck,Proceedings of the 11th Annual conference of the European Association for Machine Translation,0,"We present an Online Server for Machine Translation Evaluation that offers improvements over the standard usage of the typical scoring scripts. Users are able to interactively define their own test sets, experiments and pre-processing steps. Several scores are automatically calculated for submitted translations and the hypotheses and scores are organized and archived for later review. The server offers a nice web based user interface."
W05-0825,A Generalized Alignment-Free Phrase Extraction,2005,4,23,2,0.897436,44678,bing zhao,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"In this paper, we present a phrase extraction algorithm using a translation lexicon, a fertility model, and a simple distortion model. Except these models, we do not need explicit word alignments for phrase extraction. For each phrase pair (a block), a bilingual lexicon based score is computed to estimate the translation quality between the source and target phrase pairs; a fertility score is computed to estimate how good the lengths are matched between phrase pairs; a center distortion score is computed to estimate the relative position divergence between the phrase pairs. We presented the results and our experience in the shared tasks on French-English."
W05-0829,Competitive Grouping in Integrated Phrase Segmentation and Alignment Model,2005,8,8,2,1,7842,ying zhang,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,This article describes the competitive grouping algorithm at the core of our Integrated Segmentation and Alignment (ISA) model. ISA extracts phrase pairs from a bilingual corpus without requiring the pre-calculated word alignment as many other phrase alignment models do. Experiments conducted within the WPT-05 shared task on statistical machine translation demonstrate the simplicity and effectiveness of this approach.
I05-2048,Statistical Machine Translation Part {I}: Hands-On Introduction,2005,0,0,1,1,29364,stephan vogel,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,None
H05-1061,Mining Key Phrase Translations from Web Corpora,2005,9,65,3,1,3692,fei huang,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"Key phrases are usually among the most information-bearing linguistic structures. Translating them correctly will improve many natural language processing applications. We propose a new framework to mine key phrase translations from web corpora. We submit a source phrase to a search engine as a query, then expand queries by adding the translations of topic-relevant hint words from the returned snippets. We retrieve mixed-language web pages based on the expanded queries. Finally, we extract the key phrase translation from the second-round returned web page snippets with phonetic, semantic and frequency-distance features. We achieve 46% phrase translation accuracy when using top 10 returned snippets, and 80% accuracy with 165 snippets. Both results are significantly better than several existing methods."
2005.mtsummit-papers.30,Low Cost Portability for Statistical Machine Translation based on N-gram Coverage,2005,14,29,2,1,40353,matthias eck,Proceedings of Machine Translation Summit X: Papers,0,"Statistical machine translation relies heavily on the available training data. However, in some cases, it is necessary to limit the amount of training data that can be created for or actually used by the systems. To solve that problem, we introduce a weighting scheme that tries to select more informative sentences first. This selection is based on the previously unseen n-grams the sentences contain, and it allows us to sort the sentences according to their estimated importance. After sorting, we can construct smaller training corpora, and we are able to demonstrate that systems trained on much less training data show a very competitive performance compared to baseline systems using all available training data."
2005.mtsummit-papers.33,{PESA}: Phrase Pair Extraction as Sentence Splitting,2005,-1,-1,1,1,29364,stephan vogel,Proceedings of Machine Translation Summit X: Papers,0,"Most statistical machine translation systems use phrase-to-phrase translations to capture local context information, leading to better lexical choice and more reliable local reordering. The quality of the phrase alignment is crucial to the quality of the resulting translations. Here, we propose a new phrase alignment method, not based on the Viterbi path of word alignment models. Phrase alignment is viewed as a sentence splitting task. For a given spitting of the source sentence (source phrase, left segment, right segment) find a splitting for the target sentence, which optimizes the overall sentence alignment probability. Experiments on different translation tasks show that this phrase alignment method leads to highly competitive translation results."
2005.iwslt-1.6,The {CMU} Statistical Machine Translation System for {IWSLT}2005,2005,23,22,7,1,37937,sanjika hewavitharana,Proceedings of the Second International Workshop on Spoken Language Translation,0,"In this paper we describe the CMU statistical machine translation system used in the IWSLT 2005 evaluation campaign. This system is based on phrase-to-phrase translations extracted from a bilingual corpus. We experimented with two different phrase extraction methods; PESA on-the-fly phrase extraction and alignment free extraction method. The translation model, language model and other features were combined in a log-linear model during decoding. We present our experiments on model adaptation for new data in a different domain, as well as combining different translation hypotheses to obtain better translations. We participated in the supplied data track for manual transcriptions in the translation directions: ArabicEnglish, Chinese-English, Japanese-English and KoreanEnglish. For Chinese-English direction we also worked on ASR output of the supplied data, and with additional data in unrestricted and C-STAR tracks."
2005.iwslt-1.7,Low Cost Portability for Statistical Machine Translation based on N-gram Frequency and {TF}-{IDF},2005,15,30,2,1,40353,matthias eck,Proceedings of the Second International Workshop on Spoken Language Translation,0,Statistical machine translation relies heavily on the available training data. In some cases it is necessary to limit the amount of training data that can be created for or actually used by the systems. We introduce weighting schemes which allow us to sort sentences based on the frequency of unseen n-grams. A second approach uses TF-IDF to rank the sentences. After sorting we can select smaller training corpora and we are able to show that systems trained on much less training data achieve a very competitive performance compared to baseline systems using all available training data.
2005.eamt-1.18,Augmenting a statistical translation system with a translation memory,2005,10,8,2,1,37937,sanjika hewavitharana,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"In this paper, we present a translation memory (TM) based system to augment a statistical translation (SMT) system. It is used for translating sentences which have close matches in the training corpus. Given a test sentence, we first extract sentence pairs from the training corpus, whose source side is similar to the test sentence. Then, the TM system modifies the translation of the sentences by a sequence of substitution, deletion and inser- tion operations, to obtain the desired result. Statistical phrase alignment model of the SMT system is used for this purpose. The system was evaluated using a corpus of Chinese- English conversational data. For close matching sentences, the translations produced by the translation memory approach were compared with the translations of the statistical decoder."
2005.eamt-1.19,Adaptation of the translation model for statistical machine translation based on information retrieval,2005,11,146,3,1,28512,almut hildebrand,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,In this paper we present experiments concerning translation model adaptation for statistical machine translation. We develop a method to adapt translation models using in- formation retrieval. The approach selects sentences similar to the test set to form an adapted training corpus. The method allows a better use of additionally available out-of-domain training data or finds in-domain data in a mixed corpus. The adapted translation models significantly improve the translation performance compared to competitive baseline sys- tems.
2005.eamt-1.36,Considerations in maximum mutual information and minimum classification error training for statistical machine translation,2005,-1,-1,2,0,51293,ashish vengupol,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,None
2005.eamt-1.39,An efficient phrase-to-phrase alignment model for arbitrarily long phrase and large corpora,2005,11,56,2,1,7842,ying zhang,Proceedings of the 10th EAMT Conference: Practical applications of machine translation,0,"Most statistical machine translation (SMT) systems use phrase-to-phrase transla- tions to capture local context information, leading to better lexical choices and more reli- able word reordering. Long phrases capture more contexts than short phrases and result in better translation qualities. On the other hand, the increasing amount of bilingual data poses serious problems for storing all possible phrases. In this paper, we describe a novel phrase- to-phrase alignment model which allows for arbitrarily long phrases and works for very large bilingual corpora. This model is very efficient in both time and space and the resulting translations are better than the state-of-the-art systems."
W04-3227,Phrase Pair Rescoring with Term Weighting for Statistical Machine Translation,2004,19,12,2,1,44678,bing zhao,Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,0,We propose to score phrase translation pairs for statistical machine translation using term weight based models. These models employ tf.idf to encode the weights of content and non-content words in phrase translation pairs. The translation probability is then modeled by similarity functions defined in a vector space. Two similarity functions are compared. Using these models in a statistical machine translation task shows significant improvements.
N04-1036,Improving Named Entity Translation Combining Phonetic and Semantic Similarities,2004,0,36,2,1,3692,fei huang,Proceedings of the Human Language Technology Conference of the North {A}merican Chapter of the Association for Computational Linguistics: {HLT}-{NAACL} 2004,0,None
eck-etal-2004-language,Language Model Adaptation for Statistical Machine Translation Based on Information Retrieval,2004,10,66,2,1,40353,matthias eck,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,Language modeling is an important part for both speech recognition and machine translation systems. Adaptation has been successfully applied to language models for speech recognition. In this paper we present experiments concerning language model adaptation for statistical machine translation. We develop a method to adapt language models using information retrieval methods. The adapted language models drastically reduce perplexity over a general language model and we can show that it is possible to improve the translation quality of a statistical machine translation using those adapted language models instead of a general language model.
vogel-monson-2004-augmenting,Augmenting Manual Dictionaries for Statistical Machine Translation Systems,2004,5,9,1,1,29364,stephan vogel,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We show that the usefulness of manually created dictionaries can be enhanced for a statistical machine translation system when new translations are automatically added which are simple morphological transformations (plural forms, different verb inflections) of the original. Further improvement is possible when assigning probabilities to the lexicon entries. We describe a method to do this on the basis of an automatically trained statistical lexicon. Experimental results are given for Chinese to English translation tasks and show a significant improvement in translation quality."
zhang-etal-2004-interpreting,Interpreting {BLEU}/{NIST} Scores: How Much Improvement do We Need to Have a Better System?,2004,4,134,2,1,7842,ying zhang,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Automatic evaluation metrics for Machine Translation (MT) systems, such as BLEU and the related NIST metric, are becoming increasingly important in MT. Yet, their behaviors are not fully understood. In this paper, we analyze some flaws in the BLEU/NIST metrics. With a better understanding of these problems, we can better interpret the reported BLEU/NIST scores. In addition, this paper reports a novel method of calculating the confidence intervals for BLEU/NIST scores using bootstrapping. With this method, we can determine whether two MT systems are significantly different from each other."
C04-1059,Language Model Adaptation for Statistical Machine Translation via Structured Query Models,2004,13,95,3,1,44678,bing zhao,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,We explore unsupervised language model adaptation techniques for Statistical Machine Translation. The hypotheses from the machine translation output are converted into queries at different levels of representation power and used to extract similar sentences from very large monolingual text collection. Specific language models are then build from the retrieved data and interpolated with a general background model. Experiments show significant improvements when translating with these adapted language models.
C04-1114,Improving Statistical Machine Translation in the Medical Domain using the Unified Medical Language system,2004,11,22,2,1,40353,matthias eck,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,Texts from the medical domain are an important task for natural language processing. This paper investigates the usefulness of a large medical database (the Unified Medical Language System) for the translation of dialogues between doctors and patients using a statistical machine translation system. We are able to show that the extraction of a large dictionary and the usage of semantic type information to generalize the training data significantly improves the translation performance.
2004.tmi-1.9,Measuring confidence intervals for the machine translation evaluation metrics,2004,-1,-1,2,1,7842,ying zhang,Proceedings of the 10th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
2004.iwslt-papers.6,Toward named entity extraction and translation in spoken language translation,2004,0,1,2,1,3692,fei huang,Proceedings of the First International Workshop on Spoken Language Translation: Papers,0,None
2004.iwslt-evaluation.11,The {ISL} statistical translation system for spoken language translation,2004,7,26,1,1,29364,stephan vogel,Proceedings of the First International Workshop on Spoken Language Translation: Evaluation Campaign,0,"In this paper we describe the components of our statistical machine translation system used for the spoken language translation evaluation campaign. This system is based on phrase-to-phrase translations extracted from a bilingual corpus. A new phrase alignment approaches will be introduced, which finds the target phrase by optimizing the overall word-to-word alignment for the sentence pair under the constraint that words within the source phrase are only aligned to words within the target phrase. The system will be used for Chinese-to-English translations under the small, additional and unlimited data conditions, and for the small Japanese-to-English translation track."
2004.eamt-1.14,A trainable transfer-based {MT} approach for languages with limited resources,2004,11,24,4,0,13539,alon lavie,Proceedings of the 9th EAMT Workshop: Broadening horizons of machine translation and its applications,0,"We describe a Machine Translation (MT) approach that is specifically designed to enable rapid development of MT for languages with limited amounts of online resources. Our approach assumes the availability of a small number of bi-lingual speakers of the two languages, but these need not be linguistic experts. The bi-lingual speakers create a comparatively small corpus of word aligned phrases and sentences (on the order of magnitude of a few thousand sentence pairs) using a specially designed elicitation tool. From this data, the learning module of our system automatically infers hierarchical syntactic transfer rules, which encode how syntactic constituent structures in the source language transfer to the target language. The collection of transfer rules is then used in our run-time system to translate previously unseen source language text into the target language. We describe the general principles underlying our approach, and present results from an experiment, where we developed a basic Hindi-to-English MT system over the course of two months, using extremely limited resources."
W03-1502,Automatic Extraction of Named Entity Translingual Equivalence Based on Multi-Feature Cost Minimization,2003,10,73,2,1,3692,fei huang,Proceedings of the {ACL} 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,0,"Translingual equivalence refers to the relationship between expressions of the same meaning from different languages. Identifying translingual equivalence of named entities (NE) can significantly contribute to multilingual natural language processing, such as crosslingual information retrieval, crosslingual information extraction and statistical machine translation. In this paper we present an integrated approach to extract NE translingual equivalence from a parallel Chinese-English corpus.Starting from a bilingual corpus where NEs are automatically tagged for each language, NE pairs are aligned in order to minimize the overall multi-feature alignment cost. An NE transliteration model is presented and iteratively trained using named entity pairs extracted from a bilingual dictionary. The transliteration cost, combined with the named entity tagging cost and word-based translation cost, constitute the multi-feature alignment cost. These features are derived from several information sources using unsupervised and partly supervised methods. A greedy search algorithm is applied to minimize the alignment cost. Experiments show that the proposed approach extracts NE translingual equivalence with 81% F-score and improves the translation score from 7.68 to 7.74."
W03-0303,Word Alignment Based on Bilingual Bracketing,2003,5,16,2,1,44678,bing zhao,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,"In this paper, an improved word alignment based on bilingual bracketing is described. The explored approaches include using Model-1 conditional probability, a boosting strategy for lexicon probabilities based on importance sampling, applying Parts of Speech to discriminate English words and incorporating information of English base noun phrase. The results of the shared task on French-English, Romanian-English and Chinese-English word alignments are presented and discussed."
P03-1041,Effective Phrase Translation Extraction from Alignment Models,2003,12,66,2,1,44842,ashish venugopal,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"Phrase level translation models are effective in improving translation quality by addressing the problem of local re-ordering across language boundaries. Methods that attempt to fundamentally modify the traditional IBM translation model to incorporate phrases typically do so at a prohibitive computational cost. We present a technique that begins with improved IBM models to create phrase level knowledge sources that effectively represent local as well as global phrasal context. Our method is robust to noisy alignments at both the sentence and corpus level, delivering high quality phrase level translation pairs that contribute to significant improvements in translation quality (as measured by the BLEU metric) over word based lexica as well as a competing alignment based method."
E03-1050,Using Noisy Biligual Data for Statistical Machine Translation,2003,6,13,1,1,29364,stephan vogel,10th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,SMT systems rely on sufficient amount of parallel corpora to train the translation model. This paper investigates possibilities to use word-to-word and phrase-to-phrase translations extracted not only from clean parallel corpora but also from noisy comparable corpora. Translation results for a Chinese to English translation task are given.
2003.mtsummit-semit.2,{SMT} {--} {TIDES} {--} and all that,2003,-1,-1,1,1,29364,stephan vogel,Workshop on Machine Translation for Semitic languages: issues and approaches,0,None
2003.mtsummit-semit.3,The {CMU} {A}rabic-to-{E}nglish statistical {MT} system,2003,-1,-1,2,0,49102,alicia tribble,Workshop on Machine Translation for Semitic languages: issues and approaches,0,None
2003.mtsummit-papers.53,The {CMU} statistical machine translation system,2003,13,114,1,1,29364,stephan vogel,Proceedings of Machine Translation Summit IX: Papers,0,In this paper we describe the components of our statistical machine translation system. This system combines phrase-to-phrase translations extracted from a bilingual corpus using different alignment approaches. Special methods to extract and align named entities are used. We show how a manual lexicon can be incorporated into the statistical system in an optimized way. Experiments on Chinese-to-English and Arabic-to-English translation tasks are presented.
P00-1004,Translation with Cascaded Finite State Transducers,2000,10,14,1,1,29364,stephan vogel,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"In this paper we discuss the use of cascaded finite state transducers for machine translation. A number of small, dedicated transducers is applied to convert sentence pairs from a bilingual corpus into generalized translation patterns. These patterns, together with the transducers are then used as a hierarchical translation memory for fully automatic translation. Results on the German--English VERBMOBIL corpus are given."
P97-1037,A {DP}-based Search Using Monotone Alignments in Statistical Translation,1997,10,112,2,0,38270,christoph tillmann,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"In this paper, we describe a Dynamic Programming (DP) based search algorithm for statistical translation and present experimental results. The statistical translation uses two sources of information: a translation model and a language model. The language model used is a standard bigram model. For the translation model, the alignment probabilities are made dependent on the differences in the alignment positions rather than on the absolute positions. Thus, the approach amounts to a first-order Hidden Markov model (HMM) as they are used successfully in speech recognition for the time alignment problem. Under the assumption that the alignment is monotone with respect to the word order in both languages, an efficient search strategy for translation can be formulated. The details of the search algorithm are described. Experiments on the EuTrans corpus produced a word error rate of 5.1%."
C96-2141,{HMM}-Based Word Alignment in Statistical Translation,1996,6,748,1,1,29364,stephan vogel,{COLING} 1996 Volume 2: The 16th International Conference on Computational Linguistics,0,"In this paper, we describe a new model for word alignment in statistical translation and present experimental results. The idea of the model is to make the alignment probabilities dependent on the differences in the alignment positions rather than on the absolute positions. To achieve this goal, the approach uses a first-order Hidden Markov model (HMM) for the word alignment problem as they are used successfully in speech recognition for the time alignment problem. The difference to the time alignment HMM is that there is no monotony constraint for the possible word orderings. We describe the details of the model and test the model on several bilingual corpora."
