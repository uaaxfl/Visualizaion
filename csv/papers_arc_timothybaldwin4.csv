2021.sigdial-1.16,A Simple yet Effective Method for Sentence Ordering,2021,-1,-1,2,1,1467,aili shen,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"Sentence ordering is the task of arranging a given bag of sentences so as to maximise the coherence of the overall text. In this work, we propose a simple yet effective training method that improves the capacity of models to capture overall text coherence based on training over pairs of sentences/segments. Experimental results show the superiority of our proposed method in in- and cross-domain settings. The utility of our method is also verified over a multi-document summarisation task."
2021.nllp-1.23,Semi-automatic Triage of Requests for Free Legal Assistance,2021,-1,-1,5,1,3096,meladel mistica,Proceedings of the Natural Legal Language Processing Workshop 2021,0,"Free legal assistance is critically under-resourced, and many of those who seek legal help have their needs unmet. A major bottleneck in the provision of free legal assistance to those most in need is the determination of the precise nature of the legal problem. This paper describes a collaboration with a major provider of free legal assistance, and the deployment of natural language processing models to assign area-of-law categories to real-world requests for legal assistance. In particular, we focus on an investigation of models to generate efficiencies in the triage process, but also the risks associated with naive use of model predictions, including fairness across different user demographics."
2021.nllp-1.24,Automatic Resolution of Domain Name Disputes,2021,-1,-1,5,0,3100,wayan vihikan,Proceedings of the Natural Legal Language Processing Workshop 2021,0,"We introduce the new task of domain name dispute resolution (DNDR), that predicts the outcome of a process for resolving disputes about legal entitlement to a domain name. TheICANN UDRP establishes a mandatory arbitration process for a dispute between a trade-mark owner and a domain name registrant pertaining to a generic Top-Level Domain (gTLD) name (one ending in .COM, .ORG, .NET, etc). The nature of the problem leads to a very skewed data set, which stems from being able to register a domain name with extreme ease, very little expense, and no need to prove an entitlement to it. In this paper, we describe thetask and associated data set. We also present benchmarking results based on a range of mod-els, which show that simple baselines are in general difficult to beat due to the skewed data distribution, but in the specific case of the respondent having submitted a response, a fine-tuned BERT model offers considerable improvements over a majority-class model"
2021.naacl-main.175,Automatic Classification of Neutralization Techniques in the Narrative of Climate Change Scepticism,2021,-1,-1,3,1,3800,shraey bhatia,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Neutralisation techniques, e.g. denial of responsibility and denial of victim, are used in the narrative of climate change scepticism to justify lack of action or to promote an alternative view. We first draw on social science to introduce the problem to the community of nlp, present the granularity of the coding schema and then collect manual annotations of neutralised techniques in text relating to climate change, and experiment with supervised and semi- supervised BERT-based models."
2021.naacl-main.301,Discourse Probing of Pretrained Language Models,2021,-1,-1,3,1,4140,fajri koto,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Existing work on probing of pretrained language models (LMs) has predominantly focused on sentence-level syntactic tasks. In this paper, we introduce document-level discourse probing to evaluate the ability of pretrained LMs to capture document-level relations. We experiment with 7 pretrained LMs, 4 languages, and 7 discourse probing tasks, and find BART to be overall the best model at capturing discourse {---} but only in its encoder, with BERT performing surprisingly well as the baseline model. Across the different models, there are substantial differences in which layers best capture discourse information, and large disparities between models."
2021.mrl-1.2,Learning Contextualised Cross-lingual Word Embeddings and Alignments for Extremely Low-Resource Languages Using Parallel Corpora,2021,-1,-1,4,0,5200,takashi wada,Proceedings of the 1st Workshop on Multilingual Representation Learning,0,"We propose a new approach for learning contextualised cross-lingual word embeddings based on a small parallel corpus (e.g. a few hundred sentence pairs). Our method obtains word embeddings via an LSTM encoder-decoder model that simultaneously translates and reconstructs an input sentence. Through sharing model parameters among different languages, our model jointly trains the word embeddings in a common cross-lingual space. We also propose to combine word and subword embeddings to make use of orthographic similarities across different languages. We base our experiments on real-world data from endangered languages, namely Yongning Na, Shipibo-Konibo, and Griko. Our experiments on bilingual lexicon induction and word alignment tasks show that our model outperforms existing methods by a large margin for most language pairs. These results demonstrate that, contrary to common belief, an encoder-decoder translation model is beneficial for learning cross-lingual representations even in extremely low-resource conditions. Furthermore, our model also works well on high-resource conditions, achieving state-of-the-art performance on a German-English word-alignment task."
2021.findings-emnlp.249,{KFCN}et: Knowledge Filtering and Contrastive Learning for Generative Commonsense Reasoning,2021,-1,-1,5,1,7034,haonan li,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Pre-trained language models have led to substantial gains over a broad range of natural language processing (NLP) tasks, but have been shown to have limitations for natural language generation tasks with high-quality requirements on the output, such as commonsense generation and ad keyword generation. In this work, we present a novel Knowledge Filtering and Contrastive learning Network (KFCNet) which references external knowledge and achieves better generation performance. Specifically, we propose a BERT-based filter model to remove low-quality candidates, and apply contrastive learning separately to each of the encoder and decoder, within a general encoder{--}decoder architecture. The encoder contrastive module helps to capture global target semantics during encoding, and the decoder contrastive module enhances the utility of retrieved prototypes while learning general features. Extensive experiments on the CommonGen benchmark show that our model outperforms the previous state of the art by a large margin: +6.6 points (42.5 vs. 35.9) for BLEU-4, +3.7 points (33.3 vs. 29.6) for SPICE, and +1.3 points (18.3 vs. 17.0) for CIDEr. We further verify the effectiveness of the proposed contrastive module on ad keyword generation, and show that our model has potential commercial value."
2021.findings-emnlp.414,"{`}Just What do You Think You{'}re Doing, Dave?{'} A Checklist for Responsible Data Use in {NLP}",2021,-1,-1,2,0,5900,anna rogers,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"A key part of the NLP ethics movement is responsible use of data, but exactly what that means or how it can be best achieved remain unclear. This position paper discusses the core legal and ethical principles for collection and sharing of textual data, and the tensions between them. We propose a potential checklist for responsible data (re-)use that could both standardise the peer review of conference submissions, as well as enable a more in-depth view of published research across the community. Our proposal aims to contribute to the development of a consistent standard for data (re-)use, embraced across NLP conferences."
2021.findings-acl.41,Decoupling Adversarial Training for Fair {NLP},2021,-1,-1,2,0,7590,xudong han,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.findings-acl.71,Evaluating the Efficacy of Summarization Evaluation across Languages,2021,-1,-1,3,1,4140,fajri koto,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.155,Fairness-aware Class Imbalanced Learning,2021,-1,-1,3,1,8947,shivashankar subramanian,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Class imbalance is a common challenge in many NLP tasks, and has clear connections to bias, in that bias in training data often leads to higher accuracy for majority groups at the expense of minority groups. However there has traditionally been a disconnect between research on class-imbalanced learning and mitigating bias, and only recently have the two been looked at through a common lens. In this work we evaluate long-tail learning methods for tweet sentiment and occupation classification, and extend a margin-loss based approach with methods to enforce fairness. We empirically show through controlled experiments that the proposed approaches help mitigate both class imbalance and demographic biases."
2021.emnlp-main.193,Evaluating Debiasing Techniques for Intersectional Biases,2021,-1,-1,3,1,8947,shivashankar subramanian,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Bias is pervasive for NLP models, motivating the development of automatic debiasing techniques. Evaluation of NLP debiasing methods has largely been limited to binary attributes in isolation, e.g., debiasing with respect to binary gender or race, however many corpora involve multiple such attributes, possibly with higher cardinality. In this paper we argue that a truly fair model must consider {`}gerrymandering{'} groups which comprise not only single attributes, but also intersectional groups. We evaluate a form of bias-constrained model which is new to NLP, as well an extension of the iterative nullspace projection technique which can handle multiple identities."
2021.emnlp-main.833,{I}ndo{BERT}weet: A Pretrained Language Model for {I}ndonesian {T}witter with Effective Domain-Specific Vocabulary Initialization,2021,-1,-1,3,1,4140,fajri koto,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"We present IndoBERTweet, the first large-scale pretrained model for Indonesian Twitter that is trained by extending a monolingually-trained Indonesian BERT model with additive domain-specific vocabulary. We focus in particular on efficient model adaptation under vocabulary mismatch, and benchmark different ways of initializing the BERT embedding layer for new word types. We find that initializing with the average BERT subword embedding makes pretraining five times faster, and is more effective than proposed methods for vocabulary adaptation in terms of extrinsic evaluation over seven Twitter-based datasets."
2021.eacl-main.4,On the (In)Effectiveness of Images for Text Classification,2021,-1,-1,6,0,10519,chunpeng ma,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Images are core components of multi-modal learning in natural language processing (NLP), and results have varied substantially as to whether images improve NLP tasks or not. One confounding effect has been that previous NLP research has generally focused on sophisticated tasks (in varying settings), generally applied to English only. We focus on text classification, in the context of assigning named entity classes to a given Wikipedia page, where images generally complement the text and the Wikipedia page can be in one of a number of different languages. Our experiments across a range of languages show that images complement NLP models (including BERT) trained without external pre-training, but when combined with BERT models pre-trained on large-scale external data, images contribute nothing."
2021.eacl-main.60,Top-down Discourse Parsing via Sequence Labelling,2021,-1,-1,3,1,4140,fajri koto,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"We introduce a top-down approach to discourse parsing that is conceptually simpler than its predecessors (Kobayashi et al., 2020; Zhang et al., 2020). By framing the task as a sequence labelling problem where the goal is to iteratively segment a document into individual discourse units, we are able to eliminate the decoder and reduce the search space for splitting points. We explore both traditional recurrent models and modern pre-trained transformer models for the task, and additionally introduce a novel dynamic oracle for top-down parsing. Based on the Full metric, our proposed LSTM model sets a new state-of-the-art for RST parsing."
2021.eacl-main.116,{C}h{EMU}-Ref: A Corpus for Modeling Anaphora Resolution in the Chemical Domain,2021,-1,-1,5,0,10678,biaoyan fang,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Chemical patents contain rich coreference and bridging links, which are the target of this research. Specially, we introduce a novel annotation scheme, based on which we create the ChEMU-Ref dataset from reaction description snippets in English-language chemical patents. We propose a neural approach to anaphora resolution, which we show to achieve strong results, especially when jointly trained over coreference and bridging links."
2021.eacl-main.239,Diverse Adversaries for Mitigating Bias in Training,2021,-1,-1,2,0,7590,xudong han,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"Adversarial learning can learn fairer and less biased models of language processing than standard training. However, current adversarial techniques only partially mitigate the problem of model bias, added to which their training procedures are often unstable. In this paper, we propose a novel approach to adversarial learning based on the use of multiple diverse discriminators, whereby discriminators are encouraged to learn orthogonal hidden representations from one another. Experimental results show that our method substantially improves over standard adversarial removal methods, in terms of reducing bias and stability of training."
2020.nlpcovid19-2.12,Improved Topic Representations of Medical Documents to Assist {COVID}-19 Literature Exploration,2020,-1,-1,3,0,16247,yulia otmakhova,Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020,0,"Efficient discovery and exploration of biomedical literature has grown in importance in the context of the COVID-19 pandemic, and topic-based methods such as latent Dirichlet allocation (LDA) are a useful tool for this purpose. In this study we compare traditional topic models based on word tokens with topic models based on medical concepts, and propose several ways to improve topic coherence and specificity."
2020.coling-main.66,{I}ndo{LEM} and {I}ndo{BERT}: A Benchmark Dataset and Pre-trained Language Model for {I}ndonesian {NLP},2020,-1,-1,4,1,4140,fajri koto,Proceedings of the 28th International Conference on Computational Linguistics,0,"Although the Indonesian language is spoken by almost 200 million people and the 10th most spoken language in the world, it is under-represented in NLP research. Previous work on Indonesian has been hampered by a lack of annotated datasets, a sparsity of language resources, and a lack of resource standardization. In this work, we release the IndoLEM dataset comprising seven tasks for the Indonesian language, spanning morpho-syntax, semantics, and discourse. We additionally release IndoBERT, a new pre-trained language model for Indonesian, and evaluate it over IndoLEM, in addition to benchmarking it against existing resources. Our experiments show that IndoBERT achieves state-of-the-art performance over most of the tasks in IndoLEM."
2020.coling-main.330,Target Word Masking for Location Metonymy Resolution,2020,-1,-1,4,1,7034,haonan li,Proceedings of the 28th International Conference on Computational Linguistics,0,"Existing metonymy resolution approaches rely on features extracted from external resources like dictionaries and hand-crafted lexical resources. In this paper, we propose an end-to-end word-level classification approach based only on BERT, without dependencies on taggers, parsers, curated dictionaries of place names, or other external resources. We show that our approach achieves the state-of-the-art on 5 datasets, surpassing conventional BERT models and benchmarks by a large margin. We also show that our approach generalises well to unseen data."
2020.coling-main.523,{W}iki{UMLS}: Aligning {UMLS} to {W}ikipedia via Cross-lingual Neural Ranking,2020,26,0,2,1,8948,afshin rahimi,Proceedings of the 28th International Conference on Computational Linguistics,0,"We present our work on aligning the Unified Medical Language System (UMLS) to Wikipedia, to facilitate manual alignment of the two resources. We propose a cross-lingual neural reranking model to match a UMLS concept with a Wikipedia page, which achieves a recall@1of 72{\%}, a substantial improvement of 20{\%} over word- and char-level BM25, enabling manual alignment with minimal effort. We release our resources, including ranked Wikipedia pages for 700k UMLSconcepts, and WikiUMLS, a dataset for training and evaluation of alignment models between UMLS and Wikipedia collected from Wikidata. This will provide easier access to Wikipedia for health professionals, patients, and NLP systems, including in multilingual settings."
2020.clinicalnlp-1.25,Learning from Unlabelled Data for Clinical Semantic Textual Similarity,2020,-1,-1,3,0,5944,yuxia wang,Proceedings of the 3rd Clinical Natural Language Processing Workshop,0,"Domain pretraining followed by task fine-tuning has become the standard paradigm for NLP tasks, but requires in-domain labelled data for task fine-tuning. To overcome this, we propose to utilise domain unlabelled data by assigning pseudo labels from a general model. We evaluate the approach on two clinical STS datasets, and achieve r= 0.80 on N2C2-STS. Further investigation reveals that if the data distribution of unlabelled sentence pairs is closer to the test data, we can obtain better performance. By leveraging a large general-purpose STS dataset and small-scale in-domain training data, we obtain further improvements to r= 0.90, a new SOTA."
2020.bionlp-1.11,Evaluating the Utility of Model Configurations and Data Augmentation on Clinical Semantic Textual Similarity,2020,-1,-1,4,0,5944,yuxia wang,Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing,0,"In this paper, we apply pre-trained language models to the Semantic Textual Similarity (STS) task, with a specific focus on the clinical domain. In low-resource setting of clinical STS, these large models tend to be impractical and prone to overfitting. Building on BERT, we study the impact of a number of model design choices, namely different fine-tuning and pooling strategies. We observe that the impact of domain-specific fine-tuning on clinical STS is much less than that in the general domain, likely due to the concept richness of the domain. Based on this, we propose two data augmentation techniques. Experimental results on N2C2-STS 1 demonstrate substantial improvements, validating the utility of the proposed methods."
2020.bionlp-1.17,Domain Adaptation and Instance Selection for Disease Syndrome Classification over Veterinary Clinical Notes,2020,-1,-1,2,0,22261,brian hur,Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing,0,"Identifying the reasons for antibiotic administration in veterinary records is a critical component of understanding antimicrobial usage patterns. This informs antimicrobial stewardship programs designed to fight antimicrobial resistance, a major health crisis affecting both humans and animals in which veterinarians have an important role to play. We propose a document classification approach to determine the reason for administration of a given drug, with particular focus on domain adaptation from one drug to another, and instance selection to minimize annotation effort."
2020.alta-1.12,Information Extraction from Legal Documents: A Study in the Context of Common Law Court Judgements,2020,-1,-1,8,1,3096,meladel mistica,Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association,0,"{`}Common Law{'} judicial systems follow the doctrine of precedent, which means the legal principles articulated in court judgements are binding in subsequent cases in lower courts. For this reason, lawyers must search prior judgements for the legal principles that are relevant to their case. The difficulty for those within the legal profession is that the information that they are looking for may be contained within a few paragraphs or sentences, but those few paragraphs may be buried within a hundred-page document. In this study, we create a schema based on the relevant information that legal professionals seek within judgements and perform text classification based on it, with the aim of not only assisting lawyers in researching cases, but eventually enabling large-scale analysis of legal judgements to find trends in court outcomes over time."
2020.alta-1.14,Popularity Prediction of Online Petitions using a Multimodal {D}eep{R}egression Model,2020,-1,-1,3,0,22447,kotaro kitayama,Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association,0,"Online petitions offer a mechanism for peopleto initiate a request for change and gather sup-port from others to demonstrate support for thecause. In this work, we model the task of peti-tion popularity using both text and image rep-resentations across four different languages,and including petition metadata. We evaluateour proposed approach using a dataset of 75kpetitions from Avaaz.org, and find strong com-plementarity between text and images."
2020.acl-main.261,"Give Me Convenience and Give Her Death: Who Should Decide What Uses of {NLP} are Appropriate, and on What Basis?",2020,-1,-1,3,0,7452,kobi leins,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"As part of growing NLP capabilities, coupled with an awareness of the ethical dimensions of research, questions have been raised about whether particular datasets and tasks should be deemed off-limits for NLP research. We examine this question with respect to a paper on automatic legal sentencing from EMNLP 2019 which was a source of some debate, in asking whether the paper should have been allowed to be published, who should have been charged with making such a decision, and on what basis. We focus in particular on the role of data statements in ethically assessing research, but also discuss the topic of dual use, and examine the outcomes of similar debates in other scientific disciplines."
2020.acl-main.448,Tangled up in {BLEU}: Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics,2020,-1,-1,2,1,13911,nitika mathur,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Automatic metrics are fundamental for the development and evaluation of machine translation systems. Judging whether, and to what extent, automatic metrics concur with the gold standard of human evaluation is not a straightforward problem. We show that current methods for judging metrics are highly sensitive to the translations used for assessment, particularly the presence of outliers, which often leads to falsely confident conclusions about a metric{'}s efficacy. Finally, we turn to pairwise system ranking, developing a method for thresholding performance improvement under an automatic metric against human judgements, which allows quantification of type I versus type II errors incurred, i.e., insignificant human differences in system quality that are accepted, and significant human differences that are rejected. Together, these findings suggest improvements to the protocols for metric evaluation and system performance evaluation in machine translation."
2020.aacl-main.60,Liputan6: A Large-scale {I}ndonesian Dataset for Text Summarization,2020,-1,-1,3,1,4140,fajri koto,Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing,0,"In this paper, we introduce a large-scale Indonesian summarization dataset. We harvest articles from Liputan6.com, an online news portal, and obtain 215,827 document{--}summary pairs. We leverage pre-trained language models to develop benchmark extractive and abstractive summarization methods over the dataset with multilingual and monolingual BERT-based models. We include a thorough error analysis by examining machine-generated summaries that have low ROUGE scores, and expose both issues with ROUGE itself, as well as with extractive and abstractive summarization models."
W19-2004,How Well Do Embedding Models Capture Non-compositionality? A View from Multiword Expressions,2019,0,0,2,0,24742,navnita nandakumar,Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for {NLP},0,"In this paper, we apply various embedding methods on multiword expressions to study how well they capture the nuances of non-compositional data. Our results from a pool of word-, character-, and document-level embbedings suggest that Word2vec performs the best, followed by FastText and Infersent. Moreover, we find that recently-proposed contextualised embedding models such as Bert and ELMo are not adept at handling non-compositionality in multiword expressions."
U19-1007,Feature-guided Neural Model Training for Supervised Document Representation Learning,2019,0,0,4,1,1467,aili shen,Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association,0,
U19-1010,Improved Document Modelling with a Neural Discourse Parser,2019,20,0,3,1,4140,fajri koto,Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association,0,"Despite the success of attention-based neural models for natural language generation and classification tasks, they are unable to capture the discourse structure of larger documents. We hypothesize that explicit discourse representations have utility for NLP tasks over longer documents or document sequences, which sequence-to-sequence models are unable to capture. For abstractive summarization, for instance, conventional neural models simply match source documents and the summary in a latent space without explicit representation of text structure or relations. In this paper, we propose to use neural discourse representations obtained from a rhetorical structure theory (RST) parser to enhance document representations. Specifically, document representations are generated for discourse spans, known as the elementary discourse units (EDUs). We empirically investigate the benefit of the proposed approach on two different tasks: abstractive summarization and popularity prediction of online petitions. We find that the proposed approach leads to substantial improvements in all cases."
U19-1011,Does an {LSTM} forget more than a {CNN}? An empirical study of catastrophic forgetting in {NLP},2019,0,1,3,0,5375,gaurav arora,Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association,0,"Catastrophic forgetting {---} whereby a model trained on one task is fine-tuned on a second, and in doing so, suffers a {``}catastrophic{''} drop in performance over the first task {---} is a hurdle in the development of better transfer learning techniques. Despite impressive progress in reducing catastrophic forgetting, we have limited understanding of how different architectures and hyper-parameters affect forgetting in a network. With this study, we aim to understand factors which cause forgetting during sequential training. Our primary finding is that CNNs forget less than LSTMs. We show that max-pooling is the underlying operation which helps CNNs alleviate forgetting compared to LSTMs. We also found that curriculum learning, placing a hard task towards the end of task sequence, reduces forgetting. We analysed the effect of fine-tuning contextual embeddings on catastrophic forgetting and found that using embeddings as feature extractor is preferable to fine-tuning in continual learning setup."
U19-1014,Detecting Chemical Reactions in Patents,2019,0,1,7,0.952381,10520,hiyori yoshikawa,Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association,0,"Extracting chemical reactions from patents is a crucial task for chemists working on chemical exploration. In this paper we introduce the novel task of detecting the textual spans that describe or refer to chemical reactions within patents. We formulate this task as a paragraph-level sequence tagging problem, where the system is required to return a sequence of paragraphs which contain a description of a reaction. To address this new task, we construct an annotated dataset from an existing proprietary database of chemical reactions manually extracted from patents. We introduce several baseline methods for the task and evaluate them over our dataset. Through error analysis, we discuss what makes the task complex and challenging, and suggest possible directions for future research."
S19-2231,{U}ni{M}elb at {S}em{E}val-2019 Task 12: Multi-model combination for toponym resolution,2019,0,2,3,1,7034,haonan li,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"This paper describes our submission to SemEval-2019 Task 12 on toponym resolution over scientific articles. We train separate NER models for toponym detection over text extracted from tables vs. text from the body of the paper, and train another auxiliary model to eliminate misdetected toponyms. For toponym disambiguation, we use an SVM classifier with hand-engineered features. The best setting achieved a strict micro-F1 score of 80.92{\%} and overlap micro-F1 score of 86.88{\%} in the toponym detection subtask, ranking 2nd out of 8 teams on F1 score. For toponym disambiguation and end-to-end resolution, we officially ranked 2nd and 3rd, respectively."
S19-1030,Target Based Speech Act Classification in Political Campaign Text,2019,0,1,3,1,8947,shivashankar subramanian,Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019),0,"We study pragmatics in political campaign text, through analysis of speech acts and the target of each utterance. We propose a new annotation schema incorporating domain-specific speech acts, such as commissive-action, and present a novel annotated corpus of media releases and speech transcripts from the 2016 Australian election cycle. We show how speech acts and target referents can be modeled as sequential classification, and evaluate several techniques, exploiting contextualized word representations, semi-supervised learning, task dependencies and speaker meta-data."
P19-1186,Semi-supervised Stochastic Multi-Domain Learning using Variational Inference,2019,36,0,2,1,9817,yitong li,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Supervised models of NLP rely on large collections of text which closely resemble the intended testing setting. Unfortunately matching text is often not available in sufficient quantity, and moreover, within any domain of text, data is often highly heterogenous. In this paper we propose a method to distill the important domain signal as part of a multi-domain learning system, using a latent variable model in which parts of a neural model are stochastically gated based on the inferred domain. We compare the use of discrete versus continuous latent variables, operating in a domain-supervised or a domain semi-supervised setting, where the domain is known only for a subset of training inputs. We show that our model leads to substantial performance improvements over competitive benchmark domain adaptation methods, including methods using adversarial learning."
P19-1269,Putting Evaluation in Context: Contextual Embeddings Improve Machine Translation Evaluation,2019,0,7,2,1,13911,nitika mathur,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Accurate, automatic evaluation of machine translation is critical for system tuning, and evaluating progress in the field. We proposed a simple unsupervised metric, and additional supervised metrics which rely on contextual word embeddings to encode the translation and reference sentences. We find that these models rival or surpass all existing metrics in the WMT 2017 sentence-level and system-level tracks, and our trained model has a substantially higher correlation with human judgements than all existing metrics on the WMT 2017 to-English sentence level dataset."
N19-1203,Contextualization of Morphological Inflection,2019,11,0,4,0.729167,1282,ekaterina vylomova,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Critical to natural language generation is the production of correctly inflected text. In this paper, we isolate the task of predicting a fully inflected sentence from its partially lemmatized version. Unlike traditional morphological inflection or surface realization, our task input does not provide {``}gold{''} tags that specify what morphological features to realize on each lemmatized word; rather, such features must be inferred from sentential context. We develop a neural hybrid graphical model that explicitly reconstructs morphological features before predicting the inflected forms, and compare this to a system that directly predicts the inflected forms without relying on any morphological annotation. We experiment on several typologically diverse languages from the Universal Dependencies treebanks, showing the utility of incorporating linguistically-motivated latent variables into NLP models."
D19-6124,Reevaluating Argument Component Extraction in Low Resource Settings,2019,0,0,2,0,19853,anirudh joshi,Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),0,"Argument component extraction is a challenging and complex high-level semantic extraction task. As such, it is both expensive to annotate (meaning training data is limited and low-resource by nature), and hard for current-generation deep learning methods to model. In this paper, we reevaluate the performance of state-of-the-art approaches in both single- and multi-task learning settings using combinations of character-level, GloVe, ELMo, and BERT encodings using standard BiLSTM-CRF encoders. We use evaluation metrics that are more consistent with evaluation practice in named entity recognition to understand how well current baselines address this challenge and compare their performance to lower-level semantic tasks such as CoNLL named entity recognition. We find that performance utilizing various pre-trained representations and training methodologies often leaves a lot to be desired as it currently stands, and suggest future pathways for improvement."
D19-5525,Modelling Uncertainty in Collaborative Document Quality Assessment,2019,0,0,5,1,1467,aili shen,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"In the context of document quality assessment, previous work has mainly focused on predicting the quality of a document relative to a putative gold standard, without paying attention to the subjectivity of this task. To imitate people{'}s disagreement over inherently subjective tasks such as rating the quality of a Wikipedia article, a document quality assessment system should provide not only a prediction of the article quality but also the uncertainty over its predictions. This motivates us to measure the uncertainty in document quality predictions, in addition to making the label prediction. Experimental results show that both Gaussian processes (GPs) and random forests (RFs) can yield competitive results in predicting the quality of Wikipedia articles, while providing an estimate of uncertainty when there is inconsistency in the quality labels from the Wikipedia contributors. We additionally evaluate our methods in the context of a semi-automated document quality class assignment decision-making process, where there is asymmetric risk associated with overestimates and underestimates of document quality. Our experiments suggest that GPs provide more reliable estimates in this context."
D19-1182,Deep Ordinal Regression for Pledge Specificity Prediction,2019,0,0,3,1,8947,shivashankar subramanian,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Many pledges are made in the course of an election campaign, forming important corpora for political analysis of campaign strategy and governmental accountability. At present, there are no publicly available annotated datasets of pledges, and most political analyses rely on manual annotations. In this paper we collate a novel dataset of manifestos from eleven Australian federal election cycles, with over 12,000 sentences annotated with specificity (e.g., rhetorical vs detailed pledge) on a fine-grained scale. We propose deep ordinal regression approaches for specificity prediction, under both supervised and semi-supervised settings, and provide empirical results demonstrating the effectiveness of the proposed techniques over several baseline approaches. We analyze the utility of pledge specificity modeling across a spectrum of policy issues in performing ideology prediction, and further provide qualitative analysis in terms of capturing party-specific issue salience across election cycles."
W18-6102,{T}witter Geolocation using Knowledge-Based Methods,2018,0,2,4,0,13718,taro miyazaki,Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text,0,"Automatic geolocation of microblog posts from their text content is particularly difficult because many location-indicative terms are rare terms, notably entity names such as locations, people or local organisations. Their low frequency means that key terms observed in testing are often unseen in training, such that standard classifiers are unable to learn weights for them. We propose a method for reasoning over such terms using a knowledge base, through exploiting their relations with other entities. Our technique uses a graph embedding over the knowledge base, which we couple with a text representation to learn a geolocation classifier, trained end-to-end. We show that our method improves over purely text-based methods, which we ascribe to more robust treatment of low-count and out-of-vocabulary entities."
W18-6119,"Preferred Answer Selection in {S}tack {O}verflow: Better Text Representations ... and Metadata, Metadata, Metadata",2018,0,1,5,0,27821,steven xu,Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text,0,"Community question answering (cQA) forums provide a rich source of data for facilitating non-factoid question answering over many technical domains. Given this, there is considerable interest in answer retrieval from these kinds of forums. However this is a difficult task as the structure of these forums is very rich, and both metadata and text features are important for successful retrieval. While there has recently been a lot of work on solving this problem using deep learning models applied to question/answer text, this work has not looked at how to make use of the rich metadata available in cQA forums. We propose an attention-based model which achieves state-of-the-art results for text-based answer selection alone, and by making use of complementary meta-data, achieves a substantially higher result over two reference datasets novel to this work."
W18-3908,"Language and the Shifting Sands of Domain, Space and Time (Invited Talk)",2018,0,0,1,1,1468,timothy baldwin,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,"In this talk, I will first present recent work on domain debiasing in the context of language identification, then discuss a new line of work on language variety analysis in the form of dialect map generation. Finally, I will reflect on the interplay between time and space on language variation, and speculate on how these can be captured in a single model."
U18-1009,A Comparative Study of Embedding Models in Predicting the Compositionality of Multiword Expressions,2018,0,0,3,0,24742,navnita nandakumar,Proceedings of the Australasian Language Technology Association Workshop 2018,0,"In this paper, we perform a comparative evaluation of off-the-shelf embedding models over the task of compositionality prediction of multiword expressions(``MWEs''). Our experimental results suggest that character- and document-level models capture knowledge of MWE compositionality and are effective in modelling varying levels of compositionality, with the advantage over word-level models that they do not require token-level identification of MWEs in the training corpus."
U18-1010,Towards Efficient Machine Translation Evaluation by Modelling Annotators,2018,0,0,2,1,13911,nitika mathur,Proceedings of the Australasian Language Technology Association Workshop 2018,0,"Accurate evaluation of translation has long been a difficult, yet important problem. Current evaluations use direct assessment (DA), based on crowd sourcing judgements from a large pool of workers, along with quality control checks, and a robust method for combining redundant judgements. In this paper we show that the quality control mechanism is overly conservative, which increases the time and expense of the evaluation. We propose a model that does not rely on a pre-processing step to filter workers and takes into account varying annotator reliabilities. Our model effectively weights each worker's scores based on the inferred precision of the worker, and is much more reliable than the mean of either the raw scores or the standardised scores. We also show that DA does not deliver on the promise of longitudinal evaluation, and propose redesigning the structure of the annotation tasks that can solve this problem."
P18-2005,Towards Robust and Privacy-preserving Text Representations,2018,14,15,2,1,9817,yitong li,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Written text often provides sufficient clues to identify the author, their gender, age, and other important attributes. Consequently, the authorship of training and evaluation corpora can have unforeseen impacts, including differing model performance for different user groups, as well as privacy implications. In this paper, we propose an approach to explicitly obscure important author characteristics at training time, such that representations learned are invariant to these attributes. Evaluating on two tasks, we show that this leads to increased privacy in the learned representations, as well as more robust models to varying evaluation conditions, including out-of-domain corpora."
P18-2030,Content-based Popularity Prediction of Online Petitions Using a Deep Regression Model,2018,18,1,2,1,8947,shivashankar subramanian,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Online petitions are a cost-effective way for citizens to collectively engage with policy-makers in a democracy. Predicting the popularity of a petition {---} commonly measured by its signature count {---} based on its textual content has utility for policymakers as well as those posting the petition. In this work, we model this task using CNN regression with an auxiliary ordinal regression objective. We demonstrate the effectiveness of our proposed approach using UK and US government petition datasets."
P18-2045,Narrative Modeling with Memory Chains and Semantic Supervision,2018,16,0,3,0.291546,3138,fei liu,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Story comprehension requires a deep semantic understanding of the narrative, making it a challenging task. Inspired by previous studies on ROC Story Cloze Test, we propose a novel method, tracking various semantic aspects with external neural memory chains while encouraging each to focus on a particular semantic aspect. Evaluated on the task of story ending prediction, our model demonstrates superior performance to a collection of competitive baselines, setting a new state of the art."
P18-1181,"Deep-speare: A joint neural model of poetic language, meter and rhyme",2018,0,6,3,1,3097,jey lau,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this paper, we propose a joint architecture that captures language, rhyme and meter for sonnet modelling. We assess the quality of generated poems using crowd and expert judgements. The stress and rhyme models perform very well, as generated poems are largely indistinguishable from human-written poems. Expert evaluation, however, reveals that a vanilla language model captures meter implicitly, and that machine-generated poems still underperform in terms of readability and emotion. Our research shows the importance expert evaluation for poetry generation, and that future research should look beyond rhyme/meter and focus on poetic language."
P18-1187,Semi-supervised User Geolocation via Graph Convolutional Networks,2018,31,14,3,1,8948,afshin rahimi,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Social media user geolocation is vital to many applications such as event detection. In this paper, we propose GCN, a multiview geolocation model based on Graph Convolutional Networks, that uses both text and network context. We compare GCN to the state-of-the-art, and to two baselines we propose, and show that our model achieves or is competitive with the state-of-the-art over three benchmark geolocation datasets when sufficient supervision is available. We also evaluate GCN under a minimal supervision scenario, and show it outperforms baselines. We find that highway network gates are essential for controlling the amount of useful neighbourhood expansion in GCN."
N18-2045,Recurrent Entity Networks with Delayed Memory Update for Targeted Aspect-Based Sentiment Analysis,2018,14,10,3,0.291546,3138,fei liu,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"While neural networks have been shown to achieve impressive results for sentence-level sentiment analysis, targeted aspect-based sentiment analysis (TABSA) {---} extraction of fine-grained opinion polarity w.r.t. a pre-defined set of aspects {---} remains a difficult task. Motivated by recent advances in memory-augmented models for machine reading, we propose a novel architecture, utilising external {``}memory chains{''} with a delayed memory update mechanism to track entities. On a TABSA task, the proposed model demonstrates substantial improvements over state-of-the-art approaches, including those using external knowledge bases."
N18-2076,What{'}s in a Domain? Learning Domain-Robust Text Representations using Adversarial Training,2018,11,2,2,1,9817,yitong li,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"Most real world language problems require learning from heterogenous corpora, raising the problem of learning robust models which generalise well to both similar (\textit{in domain}) and dissimilar (\textit{out of domain}) instances to those seen in training. This requires learning an underlying task, while not learning irrelevant signals and biases specific to individual domains. We propose a novel method to optimise both in- and out-of-domain accuracy based on joint learning of a structured neural model with domain-specific and domain-general components, coupled with adversarial training for domain. Evaluating on multi-domain language identification and multi-domain sentiment analysis, we show substantial improvements over standard domain adaptation techniques, and domain-adversarial training."
N18-1178,Hierarchical Structured Model for Fine-to-Coarse Manifesto Text Analysis,2018,23,0,3,1,8947,shivashankar subramanian,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Election manifestos document the intentions, motives, and views of political parties. They are often used for analysing a party{'}s fine-grained position on a particular issue, as well as for coarse-grained positioning of a party on the left{--}right spectrum. In this paper we propose a two-stage model for automatically performing both levels of analysis over manifestos. In the first step we employ a hierarchical multi-task structured deep model to predict fine- and coarse-grained positions, and in the second step we perform post-hoc calibration of coarse-grained positions using probabilistic soft logic. We empirically show that the proposed model outperforms state-of-art approaches at both granularities using manifestos from twelve countries, written in ten different languages."
D18-1098,Topic Intrusion for Automatic Topic Model Evaluation,2018,0,1,3,1,3800,shraey bhatia,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Topic coherence is increasingly being used to evaluate topic models and filter topics for end-user applications. Topic coherence measures how well topic words relate to each other, but offers little insight on the utility of the topics in describing the documents. In this paper, we explore the topic intrusion task {---} the task of guessing an outlier topic given a document and a few topics {---} and propose a method to automate it. We improve upon the state-of-the-art substantially, demonstrating its viability as an alternative method for topic model evaluation."
C18-1085,Encoding Sentiment Information into Word Vectors for Sentiment Analysis,2018,0,7,3,0,30782,zhe ye,Proceedings of the 27th International Conference on Computational Linguistics,0,"General-purpose pre-trained word embeddings have become a mainstay of natural language processing, and more recently, methods have been proposed to encode external knowledge into word embeddings to benefit specific downstream tasks. The goal of this paper is to encode sentiment knowledge into pre-trained word vectors to improve the performance of sentiment analysis. Our proposed method is based on a convolutional neural network (CNN) and an external sentiment lexicon. Experiments on four popular sentiment analysis datasets show that this method improves the accuracy of sentiment analysis compared to a number of benchmark methods."
2018.gwc-1.19,The Company They Keep: Extracting {J}apanese Neologisms Using Language Patterns,2018,9,0,2,1,31040,james breen,Proceedings of the 9th Global Wordnet Conference,0,"We describe an investigation into the identification and extraction of unrecorded potential lexical items in Japanese text by detecting text passages containing selected language patterns typically associated with such items. We identified a set of suitable patterns, then tested them with two large collections of text drawn from the WWW and Twitter. Samples of the extracted items were evaluated, and it was demonstrated that the approach has considerable potential for identifying terms for later lexicographic analysis."
W17-5404,{BIBI} System Description: Building with {CNN}s and Breaking with Deep Reinforcement Learning,2017,14,1,3,1,9817,yitong li,Proceedings of the First Workshop on Building Linguistically Generalizable {NLP} Systems,0,"This paper describes our submission to the sentiment analysis sub-task of {``}Build It, Break It: The Language Edition (BIBI){''}, on both the builder and breaker sides. As a builder, we use convolutional neural nets, trained on both phrase and sentence data. As a breaker, we use Q-learning to learn minimal change pairs, and apply a token substitution method automatically. We analyse the results to gauge the robustness of NLP systems."
W17-4122,Sub-character Neural Language Modelling in {J}apanese,2017,0,4,3,0,1949,viet nguyen,Proceedings of the First Workshop on Subword and Character Level Models in {NLP},0,"In East Asian languages such as Japanese and Chinese, the semantics of a character are (somewhat) reflected in its sub-character elements. This paper examines the effect of using sub-characters for language modeling in Japanese. This is achieved by decomposing characters according to a range of character decomposition datasets, and training a neural language model over variously decomposed character representations. Our results indicate that language modelling can be improved through the inclusion of sub-characters, though this result depends on a good choice of decomposition dataset and the appropriate granularity of decomposition."
W17-1726,Semi-Automated Resolution of Inconsistency for a Harmonized Multiword Expression and Dependency Parse Annotation,2017,23,1,3,0,32038,king chan,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"This paper presents a methodology for identifying and resolving various kinds of inconsistency in the context of merging dependency and multiword expression (MWE) annotations, to generate a dependency treebank with comprehensive MWE annotations. Candidates for correction are identified using a variety of heuristics, including an entirely novel one which identifies violations of MWE constituency in the dependency tree, and resolved by arbitration with minimal human intervention. Using this technique, we identified and corrected several hundred errors across both parse and MWE annotations, representing changes to a significant percentage (well over 10{\%}) of the MWE instances in the joint corpus."
W17-1002,Decoupling Encoder and Decoder Networks for Abstractive Document Summarization,2017,7,3,3,0,4212,ying xu,Proceedings of the {M}ulti{L}ing 2017 Workshop on Summarization and Summary Evaluation Across Source Types and Genres,0,"Abstractive document summarization seeks to automatically generate a summary for a document, based on some abstract {``}understanding{''} of the original document. State-of-the-art techniques traditionally use attentive encoder{--}decoder architectures. However, due to the large number of parameters in these models, they require large training datasets and long training times. In this paper, we propose decoupling the encoder and decoder networks, and training them separately. We encode documents using an unsupervised document encoder, and then feed the document vector to a recurrent neural network decoder. With this decoupled architecture, we decrease the number of parameters in the decoder substantially, and shorten its training time. Experiments show that the decoupled model achieves comparable performance with state-of-the-art models for in-domain documents, but less well for out-of-domain documents."
U17-1002,Improving End-to-End Memory Networks with Unified Weight Tying,2017,0,1,3,0.295119,3138,fei liu,Proceedings of the Australasian Language Technology Association Workshop 2017,0,None
U17-1003,Joint Sentence-Document Model for Manifesto Text Analysis,2017,0,0,3,1,8947,shivashankar subramanian,Proceedings of the Australasian Language Technology Association Workshop 2017,0,None
U17-1005,A Hybrid Model for Quality Assessment of {W}ikipedia Articles,2017,29,5,3,1,1467,aili shen,Proceedings of the Australasian Language Technology Association Workshop 2017,0,None
U17-1008,Automatic Negation and Speculation Detection in Veterinary Clinical Text,2017,0,6,2,0,32219,katherine cheng,Proceedings of the Australasian Language Technology Association Workshop 2017,0,None
S17-2003,{S}em{E}val-2017 Task 3: Community Question Answering,2017,0,65,6,0,1636,preslav nakov,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"We describe SemEval{--}2017 Task 3 on Community Question Answering. This year, we reran the four subtasks from SemEval-2016: (A) Question{--}Comment Similarity, (B) Question{--}Question Similarity, (C) Question{--}External Comment Similarity, and (D) Rerank the correct answers for a new question in Arabic, providing all the data from 2015 and 2016 for training, and fresh data for testing. Additionally, we added a new subtask E in order to enable experimentation with Multi-domain Question Duplicate Detection in a larger-scale scenario, using StackExchange subforums. A total of 23 teams participated in the task, and submitted a total of 85 runs (36 primary and 49 contrastive) for subtasks A{--}D. Unfortunately, no teams participated in subtask E. A variety of approaches and features were used by the participating systems to address the different subtasks. The best systems achieved an official score (MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D, respectively. These scores are better than the baselines, especially for subtasks A{--}C."
Q17-1032,Unsupervised Acquisition of Comprehensive Multiword Lexicons using Competition in an n-gram Lattice,2017,11,0,3,0.420677,28552,julian brooke,Transactions of the Association for Computational Linguistics,0,"We present a new model for acquiring comprehensive multiword lexicons from large corpora based on competition among n-gram candidates. In contrast to the standard approach of simple ranking by association measure, in our model n-grams are arranged in a lattice structure based on subsumption and overlap relationships, with nodes inhibiting other nodes in their vicinity when they are selected as a lexical item. We show how the configuration of such a lattice can be optimized tractably, and demonstrate using annotations of sampled n-grams that our method consistently outperforms alternatives by at least 0.05 F-score across several corpora and languages."
P17-2033,A Neural Model for User Geolocation and Lexical Dialectology,2017,32,10,3,1,8948,afshin rahimi,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We propose a simple yet effective text-based user geolocation model based on a neural network with one hidden layer, which achieves state of the art performance over three Twitter benchmark geolocation datasets, in addition to producing word and phrase embeddings in the hidden layer that we show to be useful for detecting dialectal terms. As part of our analysis of dialectal terms, we release DAREDS, a dataset for evaluating dialect term detection methods."
P17-1033,Topically Driven Neural Language Model,2017,31,8,2,1,3097,jey lau,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Language models are typically applied at the sentence level, without access to the broader document context. We present a neural language model that incorporates document context in the form of a topic model-like architecture, thus providing a succinct representation of the broader document context outside of the current sentence. Experiments over a range of datasets demonstrate that our model outperforms a pure sentence-based model in terms of language model perplexity, and leads to topics that are potentially more coherent than those produced by a standard LDA topic model. Our model also has the ability to generate related sentences for a topic, providing another way to interpret topics."
K17-1022,An Automatic Approach for Document-level Topic Model Evaluation,2017,15,6,3,1,3800,shraey bhatia,Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017),0,"Topic models jointly learn topics and document-level topic distribution. Extrinsic evaluation of topic models tends to focus exclusively on topic-level evaluation, e.g. by assessing the coherence of topics. We demonstrate that there can be large discrepancies between topic- and document-level model quality, and that basing model evaluation on topic-level analysis can be highly misleading. We propose a method for automatically predicting topic model quality based on analysis of document-level topic allocations, and provide empirical evidence for its robustness."
I17-1056,Capturing Long-range Contextual Dependencies with Memory-enhanced Conditional Random Fields,2017,20,2,2,0.295119,3138,fei liu,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),0,"Despite successful applications across a broad range of NLP tasks, conditional random fields ({``}CRFs{''}), in particular the linear-chain variant, are only able to model local features. While this has important benefits in terms of inference tractability, it limits the ability of the model to capture long-range dependencies between items. Attempts to extend CRFs to capture long-range dependencies have largely come at the cost of computational complexity and approximate inference. In this work, we propose an extension to CRFs by integrating external memory, taking inspiration from memory networks, thereby allowing CRFs to incorporate information far beyond neighbouring steps. Experiments across two tasks show substantial improvements over strong CRF and LSTM baselines."
E17-2004,Robust Training under Linguistic Adversity,2017,31,17,3,1,9817,yitong li,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"Deep neural networks have achieved remarkable results across many language processing tasks, however they have been shown to be susceptible to overfitting and highly sensitive to noise, including adversarial attacks. In this work, we propose a linguistically-motivated approach for training robust models based on exposing the model to corrupted text examples at training time. We consider several flavours of linguistically plausible corruption, include lexical semantic and syntactic methods. Empirically, we evaluate our method with a convolutional neural model across a range of sentiment analysis datasets. Compared with a baseline and the dropout method, our method achieves better overall performance."
E17-2019,Context-Aware Prediction of Derivational Word-forms,2017,10,1,3,0.925926,1282,ekaterina vylomova,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"Derivational morphology is a fundamental and complex characteristic of language. In this paper we propose a new task of predicting the derivational form of a given base-form lemma that is appropriate for a given context. We present an encoder-decoder style neural network to produce a derived form character-by-character, based on its corresponding character-level representation of the base form and the context. We demonstrate that our model is able to generate valid context-sensitive derivations from known base forms, but is less accurate under lexicon agnostic setting."
E17-2057,Improving Evaluation of Document-level Machine Translation Quality Estimation,2017,11,3,3,0.820531,9403,yvette graham,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"Meaningful conclusions about the relative performance of NLP systems are only possible if the gold standard employed in a given evaluation is both valid and reliable. In this paper, we explore the validity of human annotations currently employed in the evaluation of document-level quality estimation for machine translation (MT). We demonstrate the degree to which MT system rankings are dependent on weights employed in the construction of the gold standard, before proposing direct human assessment as a valid alternative. Experiments show direct assessment (DA) scores for documents to be highly reliable, achieving a correlation of above 0.9 in a self-replication experiment, in addition to a substantial estimated cost reduction through quality controlled crowd-sourcing. The original gold standard based on post-edits incurs a 10{--}20 times greater cost than DA."
E17-2111,Multimodal Topic Labelling,2017,19,3,4,0,33012,ionut sorodoc,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"Topics generated by topic models are typically presented as a list of topic terms. Automatic topic labelling is the task of generating a succinct label that summarises the theme or subject of a topic, with the intention of reducing the cognitive load of end-users when interpreting these topics. Traditionally, topic label systems focus on a single label modality, e.g. textual labels. In this work we propose a multimodal approach to topic labelling using a simple feedforward neural network. Given a topic and a candidate image or textual label, our method automatically generates a rating for the label, relative to the topic. Experiments show that this multimodal approach outperforms single-modality topic labelling systems."
D17-1016,Continuous Representation of Location for Geolocation and Lexical Dialectology using Mixture Density Networks,2017,25,2,2,1,8948,afshin rahimi,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We propose a method for embedding two-dimensional locations in a continuous vector space using a neural network-based model incorporating mixtures of Gaussian distributions, presenting two model variants for text-based geolocation and lexical dialectology. Evaluated over Twitter data, the proposed model outperforms conventional regression-based geolocation and provides a better estimate of uncertainty. We also show the effectiveness of the representation for predicting words from location in lexical dialectology, and evaluate it using the DARE dataset."
D17-1262,Further Investigation into Reference Bias in Monolingual Evaluation of Machine Translation,2017,6,3,3,0,13912,qingsong ma,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Monolingual evaluation of Machine Translation (MT) aims to simplify human assessment by requiring assessors to compare the meaning of the MT output with a reference translation, opening up the task to a much larger pool of genuinely qualified evaluators. Monolingual evaluation runs the risk, however, of bias in favour of MT systems that happen to produce translations superficially similar to the reference and, consistent with this intuition, previous investigations have concluded monolingual assessment to be strongly biased in this respect. On re-examination of past analyses, we identify a series of potential analytical errors that force some important questions to be raised about the reliability of past conclusions, however. We subsequently carry out further investigation into reference bias via direct human assessment of MT adequacy via quality controlled crowd-sourcing. Contrary to both intuition and past conclusions, results for show no significant evidence of reference bias in monolingual evaluation of MT."
D17-1306,Sequence Effects in Crowdsourced Annotations,2017,14,2,2,1,13911,nitika mathur,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Manual data annotation is a vital component of NLP research. When designing annotation tasks, properties of the annotation interface can unintentionally lead to artefacts in the resulting dataset, biasing the evaluation. In this paper, we explore sequence effects where annotations of an item are affected by the preceding items. Having assigned one label to an instance, the annotator may be less (or more) likely to assign the same label to the next. During rating tasks, seeing a low quality item may affect the score given to the next item either positively or negatively. We see clear evidence of both types of effects using auto-correlation studies over three different crowdsourced datasets. We then recommend a simple way to minimise sequence effects."
W16-3928,{T}witter Geolocation Prediction Shared Task of the 2016 Workshop on Noisy User-generated Text,2016,6,20,4,0.921865,33670,bo han,Proceedings of the 2nd Workshop on Noisy User-generated Text ({WNUT}),0,"This paper presents the shared task for English Twitter geolocation prediction in WNUT 2016. We discuss details of task settings, data preparations and participant systems. The derived dataset and performance figures from each system provide baselines for future research in this realm."
W16-3802,Multiword Expressions at the Grammar-Lexicon Interface,2016,-1,-1,1,1,1468,timothy baldwin,Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces ({G}ram{L}ex),0,"In this talk, I will outline a range of challenges presented by multiword expressions in terms of (lexicalist) precision grammar engineering, and different strategies for accommodating those challenges, in an attempt to strike the right balance in terms of generalisation and over- and under-generation."
W16-1609,An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation,2016,20,93,2,1,3097,jey lau,Proceedings of the 1st Workshop on Representation Learning for {NLP},0,"Recently, Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al., 2013a) to learn document-level embeddings. Despite promising results in the original paper, others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models."
S16-1027,{UNIMELB} at {S}em{E}val-2016 Tasks 4{A} and 4{B}: An Ensemble of Neural Networks and a {W}ord2{V}ec Based Model for Sentiment Classification,2016,11,9,3,0,27821,steven xu,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper describes our sentiment classification system for microblog-sized documents, and documents where a topic is present. The system consists of a softvoting ensemble of a word2vec language model adapted to classification, a convolutional neural network (CNN), and a longshort term memory network (LSTM). Our main contribution consists of a way to introduce topic information into this model, by concatenating a topic embedding, consisting of the averaged word embedding for that topic, to each word embedding vector in our neural networks. When we apply our models to SemEval 2016 Task 4 subtasks A and B, we demonstrate that the ensemble performed better than any single classifier, and our method of including topic information achieves a substantial performance gain. According to results on the official test sets, our model ranked 3rd for xefxbfxbdxefxbfxbd PN in the message-only"
S16-1131,{U}ni{M}elb at {S}em{E}val-2016 Task 3: Identifying Similar Questions by combining a {CNN} with String Similarity Measures,2016,20,6,1,1,1468,timothy baldwin,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper describes the results of the participation of The University of Melbourne in the community question-answering (CQA) task of SemEval 2016 (Task 3-B). We obtained a MAP score of 70.2% on the test set, by combining three classifiers: a NaiveBayes classifier and a support vector machine (SVM) each trained over lexical similarity features, and a convolutional neural network (CNN). The CNN uses word embeddings and machine translation evaluation scores as features."
S16-1145,{V}ector{W}eavers at {S}em{E}val-2016 Task 10: From Incremental Meaning to Semantic Unit (phrase by phrase),2016,11,1,4,0,1286,andreas scherbakov,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper describes an experimental approach to Detection of Minimal Semantic Units and their Meaning (DiMSUM), explored within the framework of SemEvalxe2x80x9916 Task 10. The approach is primarily based on a combination of word embeddings and parserbased features, and employs unidirectional incremental computation of compositional embeddings for multiword expressions."
S16-1150,{M}elbourne at {S}em{E}val 2016 Task 11: Classifying Type-level Word Complexity using Random Forests with Corpus and Word List Features,2016,15,3,3,0.420677,28552,julian brooke,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"SemEval 2016 task 11 involved determining whether words in a sentence were complex orn simple for a cohort of people with English as a second language. Training data consistedn of 200 annotated sentences, representing the combined judgements of 20 human annota-n tors, such that if any annotator of the group labelled a word as complex, then it was con-n sidered to be complex. Testing was based on single annotator judgements. Our system usedn a random forest classifier with a variety of features, the most important of which were termn frequency statistics garnered from four large corpora, and style lexicons built on two largen corpora. Minor features in the final system include the presence or absence of words inn various readability word lists; many other features we tried were not successful. Our rank-n ing amongst submitted systems did not reflect the strength of our system, due to submitting an far from optimal weighting between complex and simple, but we show that when a more ap-n propriate weighting is used, our system ranks amongst the best submitted systems."
P16-4022,pigeo: A Python Geotagging Tool,2016,24,16,3,1,8948,afshin rahimi,Proceedings of {ACL}-2016 System Demonstrations,0,"We present pigeo, a Python geolocation prediction tool that predicts a location for a given text input or Twitter user. We discuss the design, implementation and application of pigeo, and empirically evaluate it. pigeo is able to geolocate informal text and is a very useful tool for users who require a free and easy-to-use, yet accurate geolocation service based on pre-trained models. Additionally, users can train their own models easily using pigeo's API."
P16-2056,Bootstrapped Text-level Named Entity Recognition for Literature,2016,16,9,3,0.420677,28552,julian brooke,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,None
P16-1143,{L}ex{S}em{T}m: A Semantic Dataset Based on All-words Unsupervised Sense Distribution Learning,2016,35,14,2,1,27822,andrew bennett,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
P16-1158,"Take and Took, Gaggle and Goose, Book and Read: Evaluating the Utility of Vector Differences for Lexical Relation Learning",2016,22,56,4,0.925926,1282,ekaterina vylomova,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
N16-1057,The Sensitivity of Topic Coherence Evaluation to Topic Cardinality,2016,9,19,2,1,3097,jey lau,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"xc2xa92016 Association for Computational Linguistics. When evaluating the quality of topics generated by a topic model, the convention is to score topic coherence - either manually or automatically - using the top-N topic words. This hyper-parameter N, or the cardinality of the topic, is often overlooked and selected arbitrarily. In this paper, we investigate the impact of this cardinality hyper-parameter on topic coherence evaluation. For two automatic topic coherence methodologies, we observe that the correlation with human ratings decreases systematically as the cardinality increases. More interestingly, we find that performance can be improved if the system scores and human ratings are aggregated over several topic cardinalities before computing the correlation. In contrast to the standard practice of using a fixed value of N (e.g. N = 5 or N = 10), our results suggest that calculating topic coherence over several different cardinalities and averaging results in a substantially more stable and robust evaluation. We release the code and the datasets used in this research, for reproducibility.1"
L16-1042,Evaluating a Topic Modelling Approach to Measuring Corpus Similarity,2016,18,3,3,1,34768,richard fothergill,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Web corpora are often constructed automatically, and their contents are therefore often not well understood. One technique for assessing the composition of such a web corpus is to empirically measure its similarity to a reference corpus whose composition is known. In this paper we evaluate a number of measures of corpus similarity, including a method based on topic modelling which has not been previously evaluated for this task. To evaluate these methods we use known-similarity corpora that have been previously used for this purpose, as well as a number of newly-constructed known-similarity corpora targeting differences in genre, topic, time, and region. Our findings indicate that, overall, the topic modelling approach did not improve on a chi-square method that had previously been found to work well for measuring corpus similarity."
D16-1087,Named Entity Recognition for Novel Types by Transfer Learning,2016,15,7,5,1,7403,lizhen qu,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
D16-1207,Learning Robust Representations of Text,2016,21,6,3,1,9817,yitong li,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
C16-1046,Determining the Multiword Expression Inventory of a Surprise Language,2016,29,2,3,1,24743,bahar salehi,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Much previous research on multiword expressions (MWEs) has focused on the token- and type-level tasks of MWE identification and extraction, respectively. Such studies typically target known prevalent MWE types in a given language. This paper describes the first attempt to learn the MWE inventory of a {``}surprise{''} language for which we have no explicit prior knowledge of MWE patterns, certainly no annotated MWE data, and not even a parallel corpus. Our proposed model is trained on a treebank with MWE relations of a source language, and can be applied to the monolingual corpus of the surprise language to identify its MWE construction types."
C16-1091,Automatic Labelling of Topics with Neural Embeddings,2016,20,4,3,1,3800,shraey bhatia,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Topics generated by topic models are typically represented as list of terms. To reduce the cognitive overhead of interpreting these topics for end-users, we propose labelling a topic with a succinct phrase that summarises its theme or idea. Using Wikipedia document titles as label candidates, we compute neural embeddings for documents and words to select the most relevant labels for topics. Comparing to a state-of-the-art topic labelling system, our methodology is simpler, more efficient and finds better topic labels."
C16-1294,Is all that Glitters in Machine Translation Quality Estimation really Gold?,2016,4,3,2,0.919301,9403,yvette graham,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Human-targeted metrics provide a compromise between human evaluation of machine translation, where high inter-annotator agreement is difficult to achieve, and fully automatic metrics, such as BLEU or TER, that lack the validity of human assessment. Human-targeted translation edit rate (HTER) is by far the most widely employed human-targeted metric in machine translation, commonly employed, for example, as a gold standard in evaluation of quality estimation. Original experiments justifying the design of HTER, as opposed to other possible formulations, were limited to a small sample of translations and a single language pair, however, and this motivates our re-evaluation of a range of human-targeted metrics on a substantially larger scale. Results show significantly stronger correlation with human judgment for HBLEU over HTER for two of the nine language pairs we include and no significant difference between correlations achieved by HTER and HBLEU for the remaining language pairs. Finally, we evaluate a range of quality estimation systems employing HTER and direct assessment (DA) of translation adequacy as gold labels, resulting in a divergence in system rankings, and propose employment of DA for future quality estimation evaluations."
W15-4319,Shared Tasks of the 2015 Workshop on Noisy User-generated Text: {T}witter Lexical Normalization and Named Entity Recognition,2015,34,66,1,1,1468,timothy baldwin,Proceedings of the Workshop on Noisy User-generated Text,0,"This paper presents the results of the two shared tasks associated with W-NUT 2015: (1) a text normalization task with 10 participants; and (2) a named entity tagging task with 8 participants. We outline the task, annotation process and dataset statistics, and provide a high-level overview of the participating systems for each shared task."
W15-0909,The Impact of Multiword Expression Compositionality on Machine Translation Evaluation,2015,26,6,4,1,24743,bahar salehi,Proceedings of the 11th Workshop on Multiword Expressions,0,"In this paper, we present the first attempt to integrate predicted compositionality scores of multiword expressions into automatic machine translation evaluation, in integrating compositionality scores for English noun compounds into the TESLA machine translation evaluation metric. The attempt is marginally successful, and we speculate on whether a larger-scale attempt is likely to have greater impact."
U15-1010,Domain Adaption of Named Entity Recognition to Support Credit Risk Assessment,2015,9,4,3,0,37175,julio alvarado,Proceedings of the Australasian Language Technology Association Workshop 2015,0,None
U15-1015,Understanding engagement with insurgents through retweet rhetoric,2015,-1,-1,5,0,28420,joel nothman,Proceedings of the Australasian Language Technology Association Workshop 2015,0,None
S15-2092,{R}ose{M}erry: A Baseline Message-level Sentiment Classification System,2015,11,3,3,0.789474,1908,huizhi liang,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"In this paper, we propose a baseline messagelevel sentiment classification method, as developed for SemEval-2015 Task 10, Subtask B. This system leverages both hand-crafted features and message-level embedding features, and uses an SVM classifier for messagelevel sentiment classification. In pre-training the embedding features, we use one million randomly-selected tweets. We present results over SemEval-2015 Task 10, Subtask B, as well as the Stanford Sentiment Treebank. Our experiments show the effectiveness of our method over both datasets."
S15-1012,Collective Document Classification with Implicit Inter-document Semantic Relationships,2015,35,1,3,0,37312,clint burford,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"This paper addresses the question of how document classifiers can exploit implicit information about document similarity to improve document classifier accuracy. We infer document similarity using simple n-gram overlap, and demonstrate that this improves overall document classification performance over two datasets. As part of this, we find that collective classification based on simple iterative classifiers outperforms the more complex and computationally-intensive dual classifier approach."
P15-2104,{T}witter User Geolocation Using a Unified Text and Network Prediction Model,2015,27,18,3,1,8948,afshin rahimi,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We propose a label propagation approach to geolocation prediction based on Modified Adsorption, with two enhancements: (1) the removal of celebrity nodes to increase location homophily and boost tractability; and (2) the incorporation of text-based geolocation priors for test users. Experiments over three Twitter benchmark datasets achieve state-of-theart results, and demonstrate the effectiveness of the enhancements."
N15-1099,A Word Embedding Approach to Predicting the Compositionality of Multiword Expressions,2015,25,52,3,1,24743,bahar salehi,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"This paper presents the first attempt to use word embeddings to predict the compositionality of multiword expressions. We consider both single- and multi-prototype word embeddings. Experimental results show that, in combination with a back-off method based on string similarity, word embeddings outperform a method using count-based distributional similarity. Our best results are competitive with, or superior to, state-of-the-art methods over three standard compositionality datasets, which include two types of multiword expressions and two languages."
N15-1124,Accurate Evaluation of Segment-level Machine Translation Metrics,2015,15,43,2,1,9403,yvette graham,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Evaluation of segment-level machine translation metrics is currently hampered by: (1) low inter-annotator agreement levels in human assessments; (2) lack of an effective mechanism for evaluation of translations of equal quality; and (3) lack of methods of significance testing improvements over a baseline. In this paper, we provide solutions to each of these challenges and outline a new human evaluation methodology aimed specifically at assessment of segment-level metrics. We replicate the human evaluation component of WMT-13 and reveal that the current state-of-the-art performance of segment-level metrics is better than previously believed. Three segment-level metrics xe2x80x94 METEOR, NLEPOR and SENTBLEUMOSES xe2x80x94 are found to correlate with human assessment at a level not significantly outperformed by any other metric in both the individual language pair assessment for Spanish-toEnglish and the aggregated set of 9 language pairs."
N15-1153,Exploiting Text and Network Context for Geolocation of Social Media Users,2015,15,20,4,1,8948,afshin rahimi,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Research on automatically geolocating social media users has conventionally been based on the text content of posts from a given user or the social network of the user, with very little crossover between the two, and no bench-marking of the two approaches over compara- ble datasets. We bring the two threads of research together in first proposing a text-based method based on adaptive grids, followed by a hybrid network- and text-based method. Evaluating over three Twitter datasets, we show that the empirical difference between text- and network-based methods is not great, and that hybridisation of the two is superior to the component methods, especially in contexts where the user graph is not well connected. We achieve state-of-the-art results on all three datasets."
K15-1009,"Big Data Small Data, In Domain Out-of Domain, Known Word Unknown Word: The Impact of Word Representations on Sequence Labelling Tasks",2015,37,19,6,1,7403,lizhen qu,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"Word embeddings -- distributed word representations that can be learned from unlabelled data -- have been shown to have high utility in many natural language processing applications. In this paper, we perform an extrinsic evaluation of five popular word embedding methods in the context of four sequence labelling tasks: POS-tagging, syntactic chunking, NER and MWE identification. A particular focus of the paper is analysing the effects of task-based updating of word representations. We show that when using word embeddings as features, as few as several hundred training instances are sufficient to achieve competitive results, and that word embeddings lead to improvements over OOV words and out of domain. Perhaps more surprisingly, our results indicate there is little difference between the different word embedding methods, and that simple Brown clusters are often competitive with word embeddings across all tasks we consider."
W14-5315,Exploring Methods and Resources for Discriminating Similar Languages,2014,31,5,6,1,38273,marco lui,"Proceedings of the First Workshop on Applying {NLP} Tools to Similar Languages, Varieties and Dialects",0,"The Discriminating between Similar Languages (DSL) shared task at VarDial challenged participants to build an automatic language identification system to discriminate between 13 languages in 6 groups of highly-similar languages (or national varieties of the same language). In this paper, we describe the submissions made by team UniMelb-NLP, which took part in both the closed and open categories. We present the text representations and modeling techniques used, including cross-lingual POS tagging as well as fine-grained tags extracted from a deep grammar of English, and discuss additional data we collected for the open submissions, utilizing custombuilt web corpora based on top-level domains as well as existing corpora."
W14-3333,Randomized Significance Tests in Machine Translation,2014,20,11,3,1,9403,yvette graham,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"Randomized methods of significance testing enable estimation of the probability that an increase in score has occurred simply by chance. In this paper, we examine the accuracy of three randomized methods of significance testing in the context of machine translation: paired bootstrap resampling, bootstrap resampling and approximate randomization. We carry out a large-scale human evaluation of shared task systems for two language pairs to provide a gold standard for tests. Results show very little difference in accuracy across the three methods of significance testing. Notably, accuracy of all test/metric combinations for evaluation of English-to-Spanish are so low that there is not enough evidence to conclude they are any better than a random coin toss."
W14-1303,Accurate Language Identification of {T}witter Messages,2014,29,32,2,1,38273,marco lui,Proceedings of the 5th Workshop on Language Analysis for Social Media ({LASM}),0,"We present an evaluation of xe2x80x9coff-theshelfxe2x80x9d language identification systems as applied to microblog messages from Twitter. A key challenge is the lack of an adequate corpus of messages annotated for language that reflects the linguistic diversity present on Twitter. We overcome this through a xe2x80x9cmostly-automatedxe2x80x9d approach to gathering language-labeled Twitter messages for evaluating language identification. We present the method to construct this dataset, as well as empirical results over existing datasets and off-theshelf language identifiers. We also test techniques that have been proposed in the literature to boost language identification performance over Twitter messages. We find that simple voting over three specific systems consistently outperforms any specific system, and achieves state-of-the-art accuracy on the task."
Q14-1003,Automatic Detection and Language Identification of Multilingual Documents,2014,37,57,3,1,38273,marco lui,Transactions of the Association for Computational Linguistics,0,"Language identification is the task of automatically detecting the language(s) present in a document based on the content of the document. In this work, we address the problem of detecting documents that contain text from more than one language (multilingual documents). We introduce a method that is able to detect that a document is multilingual, identify the languages present, and estimate their relative proportions. We demonstrate the effectiveness of our method over synthetic data, as well as real-world multilingual documents collected from the web."
P14-2016,Automatic Detection of Multilingual Dictionaries on the Web,2014,20,0,2,0,29652,gintare grigonyte,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"This paper presents an approach to query construction to detect multilingual dictionaries for predetermined language combinations on the web, based on the identification of terms which are likely to occur in bilingual dictionaries but not in general web documents. We use eight target languages for our case study, and train our method on pre-identified multilingual dictionaries and the Wikipedia dump for each of our languages."
P14-1025,"Learning Word Sense Distributions, Detecting Unattested Senses and Identifying Novel Senses Using Topic Models",2014,55,27,5,1,3097,jey lau,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Unsupervised word sense disambiguation (WSD) methods are an attractive approach to all-words WSD due to their non-reliance on expensive annotated data. Unsupervised estimates of sense frequency have been shown to be very useful for WSD due to the skewed nature of word sense distributions. This paper presents a fully unsupervised topic modelling-based approach to sense frequency estimation, which is highly portable to different corpora and sense inventories, in being applicable to any part of speech, and not requiring a hierarchical sense inventory, parsing or parallel text. We demonstrate the effectiveness of the method over the tasks of predominant sense learning and sense distribution acquisition, and also the novel tasks of detecting senses which arenxe2x80x99t attested in the corpus, and identifying novel senses in the corpus which arenxe2x80x99t captured in the sense inventory."
E14-4042,One Sense per Tweeter ... and Other Lexical Semantic Tales of {T}witter,2014,20,9,3,0.606061,9729,spandana gella,"Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics, volume 2: Short Papers",0,"In recent years, microblogs such as Twitter have emerged as a new communication channel. Twitter in particular has become the target of a myriad of content-based applications including trend analysis and event detection, but there has been little fundamental work on the analysis of word usage patterns in this text type. In this paper xe2x80x94 inspired by the one-sense-perdiscourse heuristic of Gale et al. (1992) xe2x80x94 we investigate user-level sense distributions, and detect strong support for xe2x80x9cone sense per tweeterxe2x80x9d. As part of this, we construct a novel sense-tagged lexical sample dataset based on Twitter and a web corpus."
E14-1047,Is Machine Translation Getting Better over Time?,2014,15,21,2,1,9403,yvette graham,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Recent human evaluation of machine translation has focused on relative preference judgments of translation quality, making it difficult to track longitudinal improvements over time. We carry out a large-scale crowd-sourcing experiment to estimate the degree to which state-of-theart performance in machine translation has increased over the past five years. To facilitate longitudinal evaluation, we move away from relative preference judgments and instead ask human judges to provide direct estimates of the quality of individual translations in isolation from alternate outputs. For seven European language pairs, our evaluation estimates an average 10-point improvement to state-of-theart machine translation between 2007 and 2012, with Czech-to-English translation standing out as the language pair achieving most substantial gains. Our method of human evaluation offers an economically feasible and robust means of performing ongoing longitudinal evaluation of machine translation."
E14-1050,Using Distributional Similarity of Multi-way Translations to Predict Multiword Expression Compositionality,2014,25,24,3,1,24743,bahar salehi,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We predict the compositionality of multiword expressions using distributional similarity between each component word and the overall expression, based on translations into multiple languages. We evaluate the method over English noun compounds, English verb particle constructions and German noun compounds. We show that the estimation of compositionality is improved when using translations into multiple languages, as compared to simply using distributional similarity in the source language. We further find that string similarity complements distributional similarity. 1 Compositionality of MWEs Multiword expressions (hereafter MWEs) are combinations of words which are lexically, syntactically, semantically or statistically idiosyncratic (Sag et al., 2002; Baldwin and Kim, 2009). Much research has been carried out on the extraction and identification of MWEs1 in English (Schone and Jurafsky, 2001; Pecina, 2008; Fazly et al., 2009) and other languages (Dias, 2003; Evert and Krenn, 2005; Salehi et al., 2012). However, considerably less work has addressed the task of predicting the meaning of MWEs, especially in non-English languages. As a step in this direction, the focus of this study is on predicting the compositionality of MWEs. An MWE is fully compositional if its meaning is predictable from its component words, and it is non-compositional (or idiomatic) if not. For example, stand up xe2x80x9crise to onexe2x80x99s feetxe2x80x9d is composiIn this paper, we follow Baldwin and Kim (2009) in considering MWE xe2x80x9cidentificationxe2x80x9d to be a token-level disambiguation task, and MWE xe2x80x9cextractionxe2x80x9d to be a type-level lexicon induction task. tional, because its meaning is clear from the meaning of the components stand and up. However, the meaning of strike up xe2x80x9cto start playingxe2x80x9d is largely unpredictable from the component words strike and up. In this study, following McCarthy et al. (2003) and Reddy et al. (2011), we consider compositionality to be graded, and aim to predict the degree of compositionality. For example, in the dataset of Reddy et al. (2011), climate change is judged to be 99% compositional, while silver screen is 48% compositional and ivory tower is 9% compositional. Formally, we model compositionality prediction as a regression task. An explicit handling of MWEs has been shown to be useful in NLP applications (Ramisch, 2012). As an example, Carpuat and Diab (2010) proposed two strategies for integrating MWEs into statistical machine translation. They show that even a large scale bilingual corpus cannot capture all the necessary information to translate MWEs, and that in adding the facility to model the compositionality of MWEs into their system, they could improve translation quality. Acosta et al. (2011) showed that treating non-compositional MWEs as a single unit in information retrieval improves retrieval effectiveness. For example, while searching for documents related to ivory tower, we are almost certainly not interested in documents relating to elephant tusks. Our approach is to use a large-scale multi-way translation lexicon to source translations of MWEs and their component words, and then model the relative similarity between each of the component words and the MWE, using distributional similarity based on monolingual corpora for the source language and each of the target languages. Our hypothesis is that using distributional similarity in more than one language will improve the prediction of compositionality. Importantly, in order to make the method as language-independent and"
E14-1056,Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality,2014,26,182,3,1,3097,jey lau,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Topic models based on latent Dirichlet allocation and related methods are used in a range of user-focused tasks including document navigation and trend analysis, but evaluation of the intrinsic quality of the topic model and topics remains an open research area. In this work, we explore the two tasks of automatic evaluation of single topics and automatic evaluation of whole topic models, and provide recommendations on the best strategy for performing the two tasks, in addition to providing an open-source toolkit for topic and topic model evaluation."
D14-1020,Testing for Significance of Increased Correlation with Human Judgment,2014,15,22,2,1,9403,yvette graham,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"Automatic metrics are widely used in machine translation as a substitute for human assessment. With the introduction of any new metric comes the question of just how well that metric mimics human assessment of translation quality. This is often measured by correlation with human judgment. Significance tests are generally not used to establish whether improvements over existing methods such as BLEU are statistically significant or have occurred simply by chance, however. In this paper, we introduce a significance test for comparing correlations of two metrics, along with an open-source implementation of the test. When applied to a range of metrics across seven language pairs, tests show that for a high proportion of metrics, there is insufficient evidence to conclude significant improvement over BLEU."
D14-1189,Detecting Non-compositional {MWE} Components using {W}iktionary,2014,14,7,3,1,24743,bahar salehi,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary. The approach makes use of the definitions, synonyms and translations in Wiktionary, and is applicable to any type of MWE in any language, assuming the MWE is contained in Wiktionary. Our experiments show that the proposed approach achieves higher F-score than state-of-the-art methods."
C14-1154,Novel Word-sense Identification,2014,31,12,4,0.525568,1013,paul cook,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"Automatic lexical acquisition has been an active area of research in computational linguistics for over two decades, but the automatic identification of new word-senses has received attention only very recently. Previous work on this topic has been limited by the availability of appropriate evaluation resources. In this paper we present the largest corpus-based dataset of diachronic sense differences to date, which we believe will encourage further work in this area. We then describe several extensions to a state-of-the-art topic modelling approach for identifying new word-senses. This adapted method shows superior performance on our dataset of two different corpus pairs to that of the original method for both: (a) types having taken on a novel sense over time; and (b) the token instances of such novel senses."
W13-2305,Continuous Measurement Scales in Human Evaluation of Machine Translation,2013,14,34,2,1,9403,yvette graham,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"We explore the use of continuous rating scales for human evaluation in the context of machine translation evaluation, comparing two assessor-intrinsic qualitycontrol techniques that do not rely on agreement with expert judgments. Experiments employing Amazonxe2x80x99s Mechanical Turk service show that quality-control techniques made possible by the use of the continuous scale show dramatic improvements to intra-annotator agreement of up to 0.101 in the kappa coefficient, with inter-annotator agreement increasing by up to0.144 when additional standardization of scores is applied."
U13-1004,Crowd-Sourcing of Human Judgments of Machine Translation Fluency,2013,15,0,2,1,9403,yvette graham,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"Human evaluation of machine translation quality is a key element in the development of machine translation systems, as automatic metrics are validated through correlation with human judgment. However, achievement of consistent human judgments of machine translation is not easy, with decreasing levels of consistency reported in annual evaluation campaigns. In this paper we describe experiences gained during the collection of human judgments of the fluency of machine translation output using Amazonxe2x80x99s Mechanical Turk service. We gathered a large collection of crowd-sourced human judgments for the machine translation systems that participated in the WMT 2012 shared translation task, collected across a range of eight different assessment configurations to gain insight into possible causes of xe2x80x93 and remedies for xe2x80x93 inconsistency in human judgments. Overall, approximately half of the workers carry out the human evaluation to a high standard, but effectiveness varies considerably across different target languages, with dramatically higher numbers of good quality judgments for Spanish and French, and the reverse observed for German."
U13-1018,Automatic Climate Classification of Environmental Science Literature,2013,-1,-1,4,0,41185,jared willett,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,None
S13-2024,{U}melb: Cross-lingual Textual Entailment with Word Alignment and String Similarity Features,2013,14,2,3,1,9403,yvette graham,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes The University of Melbourne NLP group submission to the Crosslingual Textual Entailment shared task, our first tentative attempt at the task. The approach involves using parallel corpora and automatic word alignment to align text fragment pairs, and statistics based on unaligned words as features to classify items as forward and backward before a compositional combination into the final four classes, as well as experiments with additional string similarity features."
S13-2039,unimelb: Topic Modelling-based Word Sense Induction for Web Snippet Clustering,2013,10,14,3,1,3097,jey lau,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes our system for Task 11 of SemEval-2013. In the task, participants are provided with a set of ambiguous search queries and the snippets returned by a search engine, and are asked to associate senses with the snippets. The snippets are then clustered using the sense assignments and systems are evaluated based on the quality of the snippet clusters. Our system adopts a preexisting Word Sense Induction (WSI) methodology based on Hierarchical Dirichlet Process (HDP), a non-parametric topic model. Our system is trained over extracts from the full text of English Wikipedia, and is shown to perform well in the shared task."
S13-2051,unimelb: Topic Modelling-based Word Sense Induction,2013,7,16,3,1,3097,jey lau,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper describes our system for shared task 13 xe2x80x9cWord Sense Induction for Graded and Non-Graded Sensesxe2x80x9d of SemEval-2013. The task is on word sense induction (WSI), and builds on earlier SemEval WSI tasks in exploring the possibility of multiple senses being compatible to varying degrees with a single contextual instance: participants are asked to grade senses rather than selecting a single sense like most word sense disambiguation (WSD) settings. The evaluation measures are designed to assess how well a system perceives the different senses in a contextual instance. We adopt a previously-proposed WSI methodology for the task, which is based on a Hierarchical Dirichlet Process (HDP), a nonparametric topic model. Our system requires no parameter tuning, uses the English ukWaC as an external resource, and achieves encouraging results over the shared task."
S13-1030,{U}ni{M}elb{\\_}{NLP}-{CORE}: Integrating predictions from multiple domains and feature sets for estimating semantic textual similarity,2013,26,3,6,0.606061,9729,spandana gella,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",0,"In this paper we present our systems for calculating the degree of semantic similarity between two texts that we submitted to the Semantic Textual Similarity task at SemEval2013. Our systems predict similarity using a regression over features based on the following sources of information: string similarity, topic distributions of the texts based on latent Dirichlet allocation, and similarity between the documents returned by an information retrieval engine when the target texts are used as queries. We also explore methods for integrating predictions using different training datasets and feature sets. Our best system was ranked 17th out of 89 participating systems. In our post-task analysis, we identify simple changes to our system that further improve our results."
P13-4002,A Stacking-based Approach to {T}witter User Geolocation Prediction,2013,26,38,3,1,33670,bo han,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We implement a city-level geolocation prediction system for Twitter users. The system infers a userxe2x80x99s location based on both tweet text and user-declared metadata using a stacking approach. We demonstrate that the stacking method substantially outperforms benchmark methods, achieving 49% accuracy on a benchmark dataset. We further evaluate our method on a recent crawl of Twitter data to investigate the impact of temporal factors on model generalisation. Our results suggest that user-declared location metadata is more sensitive to temporal change than the text of Twitter messages. We also describe two ways of accessing/demoing our system."
I13-1041,"How Noisy Social Media Text, How Diffrnt Social Media Sources?",2013,33,111,1,1,1468,timothy baldwin,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"While various claims have been made about text in social media text being noisy, there has never been a systematic study to investigate just how linguistically noisy or otherwise it is over a range of social media sources. We explore this question empirically over popular social media text types, in the form of YouTube comments, Twitter posts, web user forum posts, blog posts and Wikipedia, which we compare to a reference corpus of edited English text. We first extract out various descriptive statistics from each data type (including the distribution of languages, average sentence length and proportion of out-ofvocabulary words), and then investigate the proportion of grammatical sentences in each, based on a linguistically-motivated parser. We also investigate the relative similarity between different data types."
I13-1080,Unsupervised Word Class Induction for Under-resourced Languages: A Case Study on {I}ndonesian,2013,21,1,3,1,3096,meladel mistica,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"In this study we investigate how we can learn both: (a) syntactic classes that capture the range of predicate argument structures (PASs) of a word and the syntactic alternations it participates in, but ignore large semantic differences in the component words; and (b) syntactico-semantic classes that capture PAS and alternation properties, but are also semantically coherent (a la Levin classes). We focus on Indonesian as our case study, a language that is spoken by more than 165 million speakers, but is nonetheless relatively under-resourced in terms of NLP. In particular, we focus on the syntactic variation that arises with the affixing of the Indonesian suffix -kan, which varies according to the kind of stem it attaches to."
Y12-1005,Social Media: Friend or Foe of Natural Language Processing?,2012,6,8,1,1,1468,timothy baldwin,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"In this talk, I will outline some of the myriad of challenges and opportunities that social media offer for natural language processing. I will present analysis of how pre-processing can be used to make social media data more amenable to natural language processing, and review a selection of tasks which attempt to harness the considerable potential of different social media services. There is no question that social media are fantastically popular and varied in form xe2x80x94 ranging from user forums, to microblogs such as Twitter, to social networking sites such as Facebook xe2x80x94 and that much of the content they host is in the form of natural language. This would suggest a myriad of opportunities for natural language processing (NLP), and yet much of the applied research on social media which uses language data is based on superficial analysis, often in the form of simple keyword search. This begs the question: Are NLP methods not suited to social media analysis? Conversely, is social media data too challenging for modern-day NLP? Alternatively, are simple term search-based methods sufficient for social media analysis, i.e. is NLP overkill for social media? In exploring these questions, I attempt to answer the overarching question of whether social media data is the friend or foe of NLP. I approach the question first from the perspective of what challenges social media language poses for NLP. The most immediate answer is the infamously free-form nature of language in social media, encompassing spelling inconsistencies, the free-form adoption of new terms, and regular violations of English grammar norms. Unsurprisingly, when NLP tools are applied directly to social media data, the results tend to be miserable when compared to data sets such as the Wall Street Journal component of the Penn Treebank. However, there have been recent successes in adapting parsers and POS taggers to social media data (Foster et al., 2011; Gimpel et al., 2011). Additionally, lexical normalisation and other preprocessing strategies have been shown to enhance the performance of NLP tools over social media data (Lui and Baldwin, 2012; Han et al., to appear). Furthermore, social media posts tend to be short and the content highly varied, meaning it is difficult to adapt a tool to the domain, or harness textual context to disambiguate the content. There is also the engineering challenge of real-time processing of the text stream, as much of NLP research is carried out offline with only secondary concern for throughput. As such, we might conclude that social media data is a foe of NLP, in that it challenges traditional assumptions made in NLP research on the nature of the target text and the requirements for real-time responsiveness. However, if we look beyond the immediate text content of social media, we quickly realise that there are various non-textual data sources that can be used to enhance the robustness and accuracy of NLP models, in a way which is not possible with static text corpora. For example, simple information on the author of a post can be used to develop authoradapted models based on the previous posts of the same individual (at least for users who post sufficiently large volumes of data). Links in the post can be used to disambiguate the textual content of the post, whether in the form of URLs and the content contained in the target document(s), hashtags and the content of other similarly-tagged posts, thread-"
Y12-1021,Extracting Keywords from Multi-party Live Chats,2012,21,8,2,0.96549,38922,su kim,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"Live chats have become a popular form of communication, connecting people all over the globe. We believe that one of the simplest approaches for providing topic information to users joining a chat is keywords. In this paper, we present a method to automatically extract contextually relevant keywords for multi-party live chats. In our work, we identify keywords that are associated with specific dialogue acts as well as the occurrences of keywords across the entire conversation. In this way, we are able to identify distinguishing features of the chat based on structural information derived from live chats and predicted dialogue acts. In evaluation, we find that using structural information and predicted dialogue acts performs well, and that conventional methods do not work well over live chats."
Y12-1050,Classifying Dialogue Acts in Multi-party Live Chats,2012,19,18,3,0.96549,38922,su kim,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"We consider the task of classifying chat contributions by dialogue act in a multi-party setting. This extends the problem significantly over the 1-1 chat scenario due to the semiasynchronous and xe2x80x9centangledxe2x80x9d nature of the contributions by chat participants. We experiment with a number of machine learning approaches, using different categories of features: lexical, contextual, structural, keyword and dialogue interaction information. For evaluation, we developed gold-standard data using online forums from the USA Library of Congress. We found that, for multi-party dialogues, features based on 1-gram and keywords produced best performance, while features exploiting structure and interaction did not perform as well as previously reported results over 1-to-1 chats."
Y12-1052,Deep Lexical Acquisition of Type Properties in Low-resource Languages: A Case Study in {W}ambaya,2012,21,0,3,1,41188,jeremy nicholson,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"We present a case study on applying common methods for the prediction of lexical properties to a low-resource language, namely Wambaya. Leveraging a small corpus leads to a typical high-precision, low-recall system; using the Web as a corpus has no utility for this language, but a machine learning approach seems to utilise the available resources most effectively. This motivates a semi-supervised approach to lexicon extension."
U12-1006,Unsupervised Estimation of Word Usage Similarity,2012,-1,-1,2,1,38273,marco lui,Proceedings of the Australasian Language Technology Association Workshop 2012,0,None
U12-1009,Segmentation and Translation of {J}apanese Multi-word Loanwords,2012,12,1,2,1,31040,james breen,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"The Japanese language has absorbed large numbers of loanwords from many languages, in particular English. As well as using single loanwords, compound nouns, multiword expressions (MWEs), etc. constructed from loanwords can be found in use in very large quantities. In this paper we describe a system which has been developed to segment Japanese loanword MWEs and construct likely English translations. The system, which leverages the availability of large bilingual dictionaries of loanwords and English n-gram corpora, achieves high levels of accuracy in discriminating between single loanwords and MWEs, and in segmenting MWEs. It also generates useful translations of MWEs, and has the potential to being a major aid to lexicographers in this area."
U12-1010,Measurement of Progress in Machine Translation,2012,23,7,2,1,9403,yvette graham,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"Machine translation (MT) systems can only be improved if their performance can be reliably measured and compared. However, measurement of the quality of MT output is not straightforward, and, as we discuss in this paper, relies on correlation with inconsistent human judgments. Even when the question is captured via xe2x80x9cis translation A better than translation Bxe2x80x9d pairwise comparisons, empirical evidence shows that inter-annotator consistency in such experiments is not particularly high; for intra-judge consistency xe2x80x93 computed by showing the same judge the same pair of candidate translations twice xe2x80x93 only low levels of agreement are achieved. In this paper we review current and past methodologies for human evaluation of translation quality, and explore the ramifications of current practices for automatic MT evaluation. Our goal is to document how the methodologies used for collecting human judgments of machine translation quality have evolved; as a result, we raise key questions in connection with the low levels of judgment agreement and the lack of mechanisms for longitudinal evaluation."
U12-1016,Classification of Study Region in Environmental Science Abstracts,2012,-1,-1,2,0,41185,jared willett,Proceedings of the Australasian Language Technology Association Workshop 2012,0,None
S12-1017,Combining resources for {MWE}-token classification,2012,8,4,2,1,34768,richard fothergill,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"We study the task of automatically disambiguating word combinations such as jump the gun which are ambiguous between a literal and MWE interpretation, focusing on the utility of type-level features from an MWE lexicon for the disambiguation task. To this end we combine gold-standard idiomaticity of tokens in the OpenMWE corpus with MWE-type-level information drawn from the recently-published JDMWE lexicon. We find that constituent modifiability in an MWE-type is more predictive of the idiomaticity of its tokens than other constituent characteristics such as semantic class or part of speech."
S12-1031,The Effects of Semantic Annotations on Precision Parse Ranking,2012,24,10,4,1,32906,andrew mackinlay,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"We investigate the effects of adding semantic annotations including word sense hypernyms to the source text for use as an extra source of information in HPSG parse ranking for the English Resource Grammar. The semantic annotations are coarse semantic categories or entries from a distributional thesaurus, assigned either heuristically or by a pre-trained tagger. We test this using two test corpora in different domains with various sources of training data. The best reduces error rate in dependency F-score by 1% on average, while some methods produce substantial decreases in performance."
P12-3005,langid.py: An Off-the-shelf Language Identification Tool,2012,15,250,2,1,38273,marco lui,Proceedings of the {ACL} 2012 System Demonstrations,0,"We present langid.py, an off-the-shelf language identification tool. We discuss the design and implementation of langid.py, and provide an empirical comparison on 5 long-document datasets, and 2 datasets from the microblog domain. We find that langid.py maintains consistently high accuracy across all domains, making it ideal for end-users that require language identification without wanting to invest in preparation of in-domain training data."
N12-1040,Evaluating a Morphological Analyser of {I}nuktitut,2012,11,0,3,1,41188,jeremy nicholson,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We evaluate the performance of an morphological analyser for Inuktitut across a medium-sized corpus, where it produces a useful analysis for two out of every three types. We then compare its segmentation to that of simpler approaches to morphology, and use these as a pre-processing step to a word alignment task. Our observations show that the richer approaches provide little as compared to simply finding the head, which is more in line with the particularities of the task."
E12-2014,A Support Platform for Event Detection using Social Intelligence,2012,5,15,1,1,1468,timothy baldwin,Proceedings of the Demonstrations at the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"This paper describes a system designed to support event detection over Twitter. The system operates by querying the data stream with a user-specified set of keywords, filtering out non-English messages, and probabilistically geolocating each message. The user can dynamically set a probability threshold over the geolocation predictions, and also the time interval to present data for."
E12-1060,Word Sense Induction for Novel Sense Detection,2012,24,97,5,1,3097,jey lau,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We apply topic modelling to automatically induce word senses of a target word, and demonstrate that our word sense induction method can be used to automatically detect words with emergent novel senses, as well as token occurrences of those senses. We start by exploring the utility of standard topic models for word sense induction (WSI), with a pre-determined number of topics (=senses). We next demonstrate that a non-parametric formulation that learns an appropriate number of senses per word actually performs better at the WSI task. We go on to establish state-of-the-art results over two WSI datasets, and apply the proposed model to a novel sense detection task."
D12-1039,Automatically Constructing a Normalisation Dictionary for Microblogs,2012,34,135,3,1,33670,bo han,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"Microblog normalisation methods often utilise complex models and struggle to differentiate between correctly-spelled unknown words and lexical variants of known words. In this paper, we propose a method for constructing a dictionary of lexical variants of known words that facilitates lexical normalisation via simple string substitution (e.g. tomorrow for tmrw). We use context information to generate possible variant and normalisation pairs and then rank these by string similarity. Highly-ranked pairs are selected to populate the dictionary. We show that a dictionary-based approach achieves state-of-the-art performance for both F-score and word error rate on a standard dataset. Compared with other methods, this approach offers a fast, lightweight and easy-to-use solution, and is thus suitable for high-volume microblog pre-processing."
C12-1064,Geolocation Prediction in Social Media Data by Finding Location Indicative Words,2012,42,92,3,1,33670,bo han,Proceedings of {COLING} 2012,0,"Geolocation prediction is vital to geospatial applications like localised search and local event detection. Predominately, social media geolocation models are based on full text data, including common words with no geospatial dimension (e.g. today) and noisy strings (tmrw), potentially hampering prediction and leading to slower/more memory-intensive models. In this paper, we focus on finding location indicative words (LIWs) via feature selection, and establishing whether the reduced feature set boosts geolocation accuracy. Our results show that an information gain ratiobased approach surpasses other methods at LIW selection, outperforming state-of-the-art geolocation prediction methods by 10.6% in accuracy and reducing the mean and median of prediction error distance by 45km and 209km, respectively, on a public dataset. We further formulate notions of prediction confidence, and demonstrate that performance is even higher in cases where our model is more confident, striking a trade-off between accuracy and coverage. Finally, the identified LIWs reveal regional language differences, which could be potentially useful for lexicographers."
C12-1093,On-line Trend Analysis with Topic Models: {\\#}twitter Trends Detection Topic Model Online,2012,19,101,3,1,3097,jey lau,Proceedings of {COLING} 2012,0,"We present a novel topic modelling-based methodology to track emerging events in microblogs such as Twitter. Our topic model has an in-built update mechanism based on time slices and implements a dynamic vocabulary. We first show that the method is robust in detecting events using a range of datasets with injected novel events, and then demonstrate its application in identifying trending topics in Twitter."
C12-1127,{B}ayesian Text Segmentation for Index Term Identification and Keyphrase Extraction,2012,16,30,4,1,40087,david newman,Proceedings of {COLING} 2012,0,"Automatically extracting terminology and index terms from scientific literature is useful for a variety of digital library, indexing and search applications. This task is non-trivial, compli- cated by domain-specific terminology and a steady introduction of new terminology. Correctly identifying nested terminology further adds to the challenge. We present a Dirichlet Process (DP) model of word segmentation where multiword segments are either retrieved from a cache or newly generated. We show how this DP-Segmentation model can be used to successfully extract nested terminology, outperforming previous methods for solving this problem."
C12-1167,The Utility of Discourse Structure in Identifying Resolved Threads in Technical User Forums,2012,24,7,3,1,41187,li wang,Proceedings of {COLING} 2012,0,"Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. Automatically identifying whether the problem in a thread has been solved or not can help direct users to threads where the original problem has been solved, hence enhancing their prospects of solving their particular problem. In this paper, we investigate the task of Solvedness classification by exploiting the discourse structure of forum threads. Experimental results show that simple features derived from thread discourse structure can greatly boost the accuracy of Solvedness classification, which has been shown to be very difficult in previous research."
Y11-1031,Word classes in {I}ndonesian: A linguistic reality or a convenient fallacy in natural language processing?,2011,21,1,2,1,3096,meladel mistica,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"This paper looks at Indonesian (Bahasa Indonesia), and the claim that there is no noun-verb distinction within the language as it is spoken in regions such as Riau and Jakarta. We test this claim for the language as it is written by a variety of Indonesian speakers using empirical methods traditionally used in part-of-speech induction. In this study we use only morphological patterns that we generate from a pre-existing morphological analyser. We find that once the distribution of the data points in our experiments match the distribution of the text from which we gather our data, we obtain significant results that show a distinction between the class of nouns and the class of verbs in Indonesian. Furthermore it shows promise that the labelling of word classes may be achieved only with morphological features, which could be applied to out-of-vocabulary items."
Y11-1039,In Situ Text Summarisation for Museum Visitors,2011,20,1,1,1,1468,timothy baldwin,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"This paper presents an experiment on in situ summarisation in a museum context. We implement a range of standard summarisation algorithms, and use them to generate summaries for individual exhibit areas in a museum, intended for in situ delivery to a museum visitor on a mobile device. Personalisation is relative to a visitorxe2x80x99s preference for summary length, the visitorxe2x80x99s relative interest in a given exhibit topic, as well as (optionally) the summary history. We find that the best-performing summarisation strategy is the Centroid algorithm, and that content diversification and customisation of summary length have a significant impact on user ratings of summary quality."
W11-0801,{MWE}s and Topic Modelling: Enhancing Machine Learning with Linguistics,2011,0,4,1,1,1468,timothy baldwin,Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,0,"Topic modelling is a popular approach to joint clustering of documents and terms, e.g. via Latent Dirichlet Allocation. The standard document representation in topic modelling is a bag of unigrams, ignoring both macro-level document structure and micro-level constituent structure. In this talk, I will discuss recent work on consolidating the micro-level document representation with multiword expressions, and present experimental results which demonstrate that linguistically-richer document representations enhance topic modelling."
U11-1011,Predicting Thread Linking Structure by Lexical Chaining,2011,30,4,3,1,41187,li wang,Proceedings of the Australasian Language Technology Association Workshop 2011,0,"Web user forums are valuable means for users to resolve specific information needs, both interactively for participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. Thread linking structure has the potential to help tasks such as information retrieval (IR) and threading visualisation of forums, thereby improving information access. Unfortunately, thread linking structure is not always available in forums. This paper proposes an unsupervised approach to predict forum thread linking structure using lexical chaining, a technique which identifies lists of related word tokens within a given discourse. Three lexical chaining algorithms, including one that only uses statistical associations between words, are experimented with. Preliminary experiments lead to results which surpass an informed baseline."
P11-2046,Relation Guided Bootstrapping of Semantic Lexicons,2011,14,8,4,0,44608,tara mcintosh,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,0,"State-of-the-art bootstrapping systems rely on expert-crafted semantic constraints such as negative categories to reduce semantic drift. Unfortunately, their use introduces a substantial amount of supervised knowledge. We present the Relation Guided Bootstrapping (RGB) algorithm, which simultaneously extracts lexicons and open relationships to guide lexicon growth and reduce semantic drift. This removes the necessity for manually crafting category and relationship constraints, and manually generating negative categories."
P11-1038,Lexical Normalisation of Short Text Messages: Makn Sens a {\\#}twitter,2011,26,335,2,1,33670,bo han,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"Twitter provides access to large volumes of data in real time, but is notoriously noisy, hampering its utility for NLP. In this paper, we target out-of-vocabulary words in short text messages and propose a method for identifying and normalising ill-formed words. Our method uses a classifier to detect ill-formed words, and generates correction candidates based on morphophonemic similarity. Both word similarity and context are then exploited to select the most probable correction candidate for the word. The proposed method doesn't require any annotations, and achieves state-of-the-art performance over an SMS corpus and a novel dataset based on Twitter."
P11-1151,Collective Classification of Congressional Floor-Debate Transcripts,2011,25,38,3,0,44692,clinton burfoot,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"This paper explores approaches to sentiment classification of U. S. Congressional floor-debate transcripts. Collective classification techniques are used to take advantage of the informal citation structure present in the debates. We use a range of methods based on local and global formulations and introduce novel approaches for incorporating the outputs of machine learners into collective classification algorithms. Our experimental evaluation shows that the mean-field algorithm obtains the best results for the task, significantly outperforming the benchmark technique."
P11-1154,Automatic Labelling of Topic Models,2011,27,136,4,1,3097,jey lau,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We propose a method for automatically labelling topics learned via LDA topic models. We generate our label candidate set from the top-ranking topic terms, titles of Wikipedia articles containing the top-ranking topic terms, and sub-phrases extracted from the Wikipedia article titles. We rank the label candidates using a combination of association measures and lexical features, optionally fed into a supervised ranking model. Our method is shown to perform strongly over four independent sets of topics, significantly better than a benchmark method."
I11-1028,{T}reeblazing: Using External Treebanks to Filter Parse Forests for Parse Selection and Treebanking,2011,27,5,5,1,32906,andrew mackinlay,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We describe xe2x80x9ctreeblazingxe2x80x9d, a method of using annotations from the GENIA treebank to constrain a parse forest from an HPSG parser. Combining this with self-training, we show significant dependency score improvements in a task of adaptation to the biomedical domain, reducing error rate by 9% compared to out-of-domain gold data and 6% compared to self-training. We also demonstrate improvements in treebanking efficiency, requiring 25% fewer decisions, and 17% less annotation time."
I11-1062,Cross-domain Feature Selection for Language Identification,2011,30,65,2,1,38273,marco lui,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"We show that transductive (cross-domain) learning is an important consideration in building a general-purpose language identification system, and develop a feature selection method that generalizes across domains. Our results demonstrate that our method provides improvements in transductive transfer learning for language identification. We provide an implementation of the method and show that our system is faster than popular standalone language identification systems, while maintaining competitive accuracy."
I11-1102,Fleshing it out: A Supervised Approach to {MWE}-token and {MWE}-type Classification,2011,13,5,2,1,34768,richard fothergill,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Although some multiword expressions (MWEs) like How do you do? have exclusively idiomatic meaning, other MWEtypes like the phrase kick the bucket may be idiomatic or literal depending on context. The recently developed OpenMWE corpus provides the largest freely available collection of annotated MWE-tokens suitable for supervised classification, but so far its potential has only been superficially investigated and only for classification of MWE-types in the corpus. Instead, we train and evaluate classifiers for crosstype classification and introduce novel features specialised to this task. Our best crosstype classifiers performed as well on non-trained MWE-types as a majority class baseline which has knowledge of the MWE-type."
D11-1002,Predicting Thread Discourse Structure over Technical Web Forums,2011,55,37,5,1,41187,li wang,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with in situ classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads."
W10-2923,Tagging and Linking Web Forum Posts,2010,39,63,3,1,38922,su kim,Proceedings of the Fourteenth Conference on Computational Natural Language Learning,0,"We propose a method for annotating post-to-post discourse structure in online user forum data, in the hopes of improving troubleshooting-oriented information access. We introduce the tasks of: (1) post classification, based on a novel dialogue act tag set; and (2) link classification. We also introduce three feature sets (structural features, post context features and semantic features) and experiment with three discriminative learners (maximum entropy, SVM-HMM and CRF). We achieve above-baseline results for both dialogue act and link classification, with interesting divergences in which feature sets perform well over the two sub-tasks, and go on to perform preliminary investigation of the interaction between post tagging and linking."
W10-0508,Intelligent Linux Information Access by Data Mining: the {ILIAD} Project,2010,7,8,1,1,1468,timothy baldwin,Proceedings of the {NAACL} {HLT} 2010 Workshop on Computational Linguistics in a World of Social Media,0,"We propose an alternative to conventional information retrieval over Linux forum data, based on thread-, post- and user-level analysis, interfaced with an information retrieval engine via reranking."
U10-1003,Multilingual Language Identification: {ALTW} 2010 Shared Task Data,2010,3,6,1,1,1468,timothy baldwin,Proceedings of the Australasian Language Technology Association Workshop 2010,0,"While there has traditionally been strong interest in the task of monolingual language identification, research on multilingual language identification is underrepresented in the literature, partly due to a lack of standardised datasets. This paper describes an artificially-generated dataset for multilingual language identification, as used in the 2010 Australasian Language Technology Workshop shared task."
U10-1006,Thread-level Analysis over Technical User Forum Data,2010,13,8,3,1,41187,li wang,Proceedings of the Australasian Language Technology Association Workshop 2010,0,"This research focuses on improving information access over troubleshootingoriented technical user forums via threadlevel analysis. We describe a modular task formulation and novel dataset, and go on to describe a series of preliminary classification experiments over the data. We find that a class composition strategy achieves the best results, surpassing multiclass classification approaches."
U10-1009,"Classifying User Forum Participants: Separating the Gurus from the Hacks, and Other Tales of the {I}nternet",2010,26,12,2,1,38273,marco lui,Proceedings of the Australasian Language Technology Association Workshop 2010,0,"This paper introduces a novel user classification task in the context of web user forums. We present a definition of four basic user characteristics and an annotated dataset. We outline a series of approaches for predicting user characteristics, utilising aggregated post features and user/thread network analysis in a supervised learning context. Using the proposed feature sets, we achieve results above both a naive baseline and a bag-ofwords approach, for all four of our basic user characteristics. In all cases, our bestperforming classifier is statistically indistinct from an upper bound based on the inter-annotator agreement for the task."
S10-1004,{S}em{E}val-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles,2010,19,199,4,1,38922,su kim,Proceedings of the 5th International Workshop on Semantic Evaluation,0,This paper describes Task 5 of the Workshop on Semantic Evaluation 2010 (SemEval-2010). Systems are to automatically assign keyphrases or keywords to given scientific articles. The participating systems were evaluated by matching their extracted keyphrases against manually assigned ones. We present the overall ranking of the submitted systems and discuss our findings to suggest future directions for this task.
N10-1002,Chart Mining-based Lexical Acquisition with Precision Grammars,2010,34,4,2,0.151201,3425,yi zhang,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"In this paper, we present an innovative chart mining technique for improving parse coverage based on partial parse outputs from precision grammars. The general approach of mining features from partial analyses is applicable to a range of lexical acquisition tasks, and is particularly suited to domain-specific lexical tuning and lexical acquisition using low-coverage grammars. As an illustration of the functionality of our proposed technique, we develop a lexical acquisition model for English verb particle constructions which operates over unlexicalised features mined from a partial parsing chart. The proposed technique is shown to outperform a state-of-the-art parser over the target task, despite being based on relatively simplistic features."
N10-1012,Automatic Evaluation of Topic Coherence,2010,35,398,4,1,40087,david newman,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper introduces the novel task of topic coherence evaluation, whereby a set of words, as generated by a topic model, is rated for coherence or interpretability. We apply a range of topic scoring models to the evaluation task, drawing on WordNet, Wikipedia and the Google search engine, and existing research on lexical similarity/relatedness. In comparison with human scores for a set of learned topics over two distinct datasets, we show a simple co-occurrence measure based on pointwise mutual information over Wikipedia data is able to achieve results for the task at or nearing the level of inter-annotator correlation, and that other Wikipedia-based lexical relatedness methods also achieve strong results. Google produces strong, if less consistent, results, while our results over WordNet are patchy at best."
N10-1027,Language Identification: The Long and the Short of the Matter,2010,21,86,1,1,1468,timothy baldwin,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Language identification is the task of identifying the language a given document is written in. This paper describes a detailed examination of what models perform best under different conditions, based on experiments across three separate datasets and a range of tokenisation strategies. We demonstrate that the task becomes increasingly difficult as we increase the number of languages, reduce the amount of training data and reduce the length of documents. We also show that it is possible to perform language identification without having to perform explicit character encoding detection."
D10-1068,Unsupervised Parse Selection for {HPSG},2010,36,8,2,1,39167,rebecca dridan,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"Parser disambiguation with precision grammars generally takes place via statistical ranking of the parse yield of the grammar using a supervised parse selection model. In the standard process, the parse selection model is trained over a hand-disambiguated treebank, meaning that without a significant investment of effort to produce the treebank, parse selection is not possible. Furthermore, as treebanking is generally streamlined with parse selection models, creating the initial treebank without a model requires more resources than subsequent treebanks. In this work, we show that, by taking advantage of the constrained nature of these HPSG grammars, we can learn a discriminative parse selection model from raw text in a purely unsupervised fashion. This allows us to bootstrap the treebanking process and provide better parsers faster, and with less resources."
D10-1084,Classifying Dialogue Acts in One-on-One Live Chats,2010,33,49,3,1,38922,su kim,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service. In particular, we investigate the effectiveness of various features and machine learners for this task. While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance. We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data."
C10-3010,{P}an{L}ex and {LEXTRACT}: Translating all Words of all Languages of the World,2010,5,23,1,1,1468,timothy baldwin,Coling 2010: Demonstrations,0,"PanLex is a lemmatic translation resource which combines a large number of translation dictionaries and other translingual lexical resources. It currently covers 1353 language varieties and 12M expressions, but aims to cover all languages and up to 350M expressions. This paper describes the resource and current applications of it, as well as lextract, a new effort to expand the coverage of PanLex via semi-automatic dictionary scraping."
C10-2069,Best Topic Word Selection for Topic Labelling,2010,17,62,4,1,3097,jey lau,Coling 2010: Posters,0,"This paper presents the novel task of best topic word selection, that is the selection of the topic word that is the best label for a given topic, as a means of enhancing the interpretation and visualisation of topic models. We propose a number of features intended to capture the best topic word, and show that, in combination as inputs to a reranking model, we are able to consistently achieve results above the baseline of simply selecting the highest-ranked topic word. This is the case both when training in-domain over other labelled topics for that topic model, and cross-domain, using only labellings from independent topic models learned over document collections from different domains and genres."
C10-1065,Evaluating N-gram based Evaluation Metrics for Automatic Keyphrase Extraction,2010,23,31,2,1,38922,su kim,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"This paper describes a feasibility study of n-gram-based evaluation metrics for automatic keyphrase extraction. To account for near-misses currently ignored by standard evaluation metrics, we adapt various evaluation metrics developed for machine translation and summarization, and also the R-precision evaluation metric from keyphrase evaluation. In evaluation, the R-precision metric is found to achieve the highest correlation with human annotations. We also provide evidence that the degree of semantic similarity varies with the location of the partially-matching component words."
W09-1410,Biomedical Event Annotation with {CRF}s and Precision Grammars,2009,6,17,3,1,32906,andrew mackinlay,Proceedings of the {B}io{NLP} 2009 Workshop Companion Volume for Shared Task,0,"This work describes a system for the tasks of identifying events in biomedical text and marking those that are speculative or negated. The architecture of the system relies on both Machine Learning (ML) approaches and hand-coded precision grammars. We submitted the output of our approach to the event extraction shared task at BioNLP 2009, where our methods suffered from low recall, although we were one of the few teams to provide answers for task 3."
U09-1006,Corpus-based Extraction of {J}apanese Compound Verbs,2009,8,4,2,1,31040,james breen,Proceedings of the Australasian Language Technology Association Workshop 2009,0,"We describe two methods for Japanese compound verb (JCV) extraction, based on synthesis and pattern matching over the Google Japanese n-gram corpus. We devise a number of filters to boost the precision of the corpus-based method, and evaluate the two methods based on a sample of JCVs occurring in varying frequency bands. We also investigate the distribution of JCV token frequency, and the type frequency of their components."
U09-1007,"Double Double, Morphology and Trouble: Looking into Reduplication in {I}ndonesian",2009,-1,-1,3,1,3096,meladel mistica,Proceedings of the Australasian Language Technology Association Workshop 2009,0,None
U09-1013,Extracting Domain-Specific Words - A Statistical Approach,2009,0,5,2,1,38922,su kim,Proceedings of the Australasian Language Technology Association Workshop 2009,0,None
P09-2041,Automatic Satire Detection: Are You Having a Laugh?,2009,8,75,2,0,47176,clint burfoot,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"We introduce the novel task of determining whether a newswire article is true or satirical. We experiment with SVMs, feature scaling, and a number of lexical and semantic feature types, and achieve promising results over the task."
N09-2018,Web and Corpus Methods for {M}alay Count Classifier Prediction,2009,9,2,2,1,41188,jeremy nicholson,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"We examine the capacity of Web and corpus frequency methods to predict preferred count classifiers for nouns in Malay. The observed F-score for the Web model of 0.671 considerably outperformed corpus-based frequency and machine learning models. We expect that this is a fruitful extension for Web-as-corpus approaches to lexicons in languages other than English, but further research is required in other South-East and East Asian languages."
N09-2065,Recognising the Predicate-argument Structure of {T}agalog,2009,9,1,2,1,3096,meladel mistica,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"This paper describes research on parsing Tagalog text for predicate-argument structure (PAS). We first outline the linguistic phenomenon and corpus annotation process, then detail a series of PAS parsing experiments."
J09-4003,{O}bituaries: Hozumi {T}anaka,2009,-1,-1,1,1,1468,timothy baldwin,Computational Linguistics,0,None
J09-2001,Prepositions in Applications: A Survey and Introduction to the Special Issue,2009,194,42,1,1,1468,timothy baldwin,Computational Linguistics,0,"Prepositions1xe2x80x94as well as prepositional phrases (PPs) and markers of various sortsxe2x80x94 have a mixed history in computational linguistics (CL), as well as related fields such as artificial intelligence, information retrieval (IR), and computational psycholinguistics: On the one hand they have been championed as being vital to precise language understanding (e.g., in information extraction), and on the other they have been ignored on the grounds of being syntactically promiscuous and semantically vacuous, and relegated to the ignominious rank of xe2x80x9cstop wordxe2x80x9d (e.g., in text classification and IR). Although NLP in general has benefitted from advances in those areas where prepositions have received attention, there are still many issues to be addressed. For example, in machine translation, generating a preposition (or xe2x80x9ccase markerxe2x80x9d in languages such as Japanese) incorrectly in the target language can lead to critical semantic divergences over the source language string. Equivalently in information retrieval and information extraction, it would seem desirable to be able to predict that book on NLP and book about NLPmean largely the same thing, but paranoid about drugs and paranoid on drugs suggest very different things. Prepositions are often among the most frequent words in a language. For example, based on the British National Corpus (BNC; Burnard 2000), four out of the top-ten most-frequent words in English are prepositions (of, to, in, and for). In terms of both parsing and generation, therefore, accurate models of preposition usage are essential to avoid repeatedly making errors. Despite their frequency, however, they are notoriously difficult to master, even for humans (Chodorow, Tetreault, and Han 2007). For example, Lindstromberg (2001) estimates that less than 10% of upper-level English as a Second"
U08-1011,Automatic Event Reference Identification,2008,16,13,2,0,47848,olivia march,Proceedings of the Australasian Language Technology Association Workshop 2008,0,"Event reference identification is often treated as a sentence level classification task. However, several different event references can occur within a single sentence. We present a set of experiments involving real world event reference identification at the word level in newspaper and newswire documents, addressing the issue of effective text representation for classification of events using support vector machines. Our final system achieved an F-score of 0.764, significantly exceeding that of our baseline system. Additionally we achieved a marginally higher performance than a more complex comparable system."
U08-1015,Learning Count Classifier Preferences of {M}alay Nouns,2008,12,1,2,1,41188,jeremy nicholson,Proceedings of the Australasian Language Technology Association Workshop 2008,0,"We develop a data set of Malay lexemes labelled with count classifiers, that are attested in raw or lemmatised corpora. A maximum entropy classifier based on simple, languageinspecific features generated from context tokens achieves about 50% F-score, or about 65% precision when a suite of binary classifiers is built to aid multi-class prediction of headword nouns. Surprisingly, numeric features are not observed to aid classification. This system represents a useful step for semisupervised lexicography across a range of languages."
P08-1037,Improving Parsing and {PP} Attachment Performance with Sense Information,2008,27,67,2,0,8824,eneko agirre,Proceedings of ACL-08: HLT,1,"To date, parsers have made limited use of semantic information, but there is evidence to suggest that semantic features can enhance parse disambiguation. This paper shows that semantic classes help to obtain significant improvement in both parsing and PP attachment tasks. We devise a gold-standard sense- and parse tree-annotated dataset based on the intersection of the Penn Treebank and SemCor, and experiment with different approaches to both semantic representation and disambiguation. For the Bikel parser, we achieved a maximal error reduction rate over the baseline parser of 6.9% and 20.5%, for parsing and PP-attachment respectively, using an unsupervised WSD strategy. This demonstrates that word sense information can indeed enhance the performance of syntactic disambiguation."
nicholson-etal-2008-evaluating,Evaluating and Extending the Coverage of {HPSG} Grammars: A Case Study for {G}erman,2008,12,3,4,1,41188,jeremy nicholson,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this work, we examine and attempt to extend the coverage of a German HPSG grammar. We use the grammar to parse a corpus of newspaper text and evaluate the proportion of sentences which have a correct attested parse, and analyse the cause of errors in terms of lexical or constructional gaps which prevent parsing. Then, using a maximum entropy model, we evaluate prediction of lexical types in the HPSG type hierarchy for unseen lexemes. By automatically adding entries to the lexicon, we observe that we can increase coverage without substantially decreasing precision."
I08-2108,{MRD}-based Word Sense Disambiguation: Further Extending {L}esk,2008,12,14,1,1,1468,timothy baldwin,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"This paper reconsiders the task of MRDbased word sense disambiguation, in extending the basic Lesk algorithm to investigate the impact onWSD performance of different tokenisation schemes, scoring mechanisms, methods of gloss extension and filtering methods. In experimentation over the Lexeed Sensebank and the Japanese Senseval2 dictionary task, we demonstrate that character bigrams with sense-sensitive gloss extension over hyponyms and hypernyms enhances WSD performance."
I08-1074,Benchmarking Noun Compound Interpretation,2008,22,6,2,1,38922,su kim,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{I},0,"In this paper we provide benchmark results for two classes of methods used in interpreting noun compounds (NCs): semantic similarity-based methods and their hybrids. We evaluate the methods using 7-way and binary class data from the nominal pair interpretation task of SEMEVAL-2007.1 We summarize and analyse our results, with the intention of providing a framework for benchmarking future research in this area."
C08-1073,Applying Discourse Analysis and Data Mining Methods to Spoken {OSCE} Assessments,2008,17,3,2,1,3096,meladel mistica,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"This paper looks at the transcribed data of patient-doctor consultations in an examination setting. The doctors are internationally qualified and enrolled in a bridging course as preparation for their Australian Medical Council examination. In this study, we attempt to ascertain if there are measurable linguistic features of the consultations, and to investigate whether there is any relevant information about the communicative styles of the qualifying doctors that may predict satisfactory or non-satisfactory examination outcomes. We have taken a discourse analysis approach in this study, where the core unit of analysis is a 'turn'. We approach this problem as a binary classification task and employ data mining methods to see whether the application of which to richly annotated dialogues can produce a system with an adequate predictive capacity."
C08-1131,Measuring and Predicting Orthographic Associations: Modelling the Similarity of {J}apanese Kanji,2008,12,5,2,1,44609,lars yencken,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"As human beings, our mental processes for recognising linguistic symbols generate perceptual neighbourhoods around such symbols where confusion errors occur. Such neighbourhoods also provide us with conscious mental associations between symbols. This paper formalises orthographic models for similarity of Japanese kanji, and provides a proof-of-concept dictionary extension leveraging the mental associations provided by orthographic proximity."
Y07-1001,Scalable Deep Linguistic Processing: Mind the Lexical Gap,2007,53,3,1,1,1468,timothy baldwin,"Proceedings of the 21st Pacific Asia Conference on Language, Information and Computation",0,"Coverage has been a constant thorn in the side of deployed deep linguistic processing applications, largely because of the difficulty in constructing, maintaining and domaintuning the complex lexicons that they rely on. This paper reviews various strands of research on deep lexical acquisition (DLA), i.e. the (semi-)automatic creation of linguistically-rich language resources, particularly from the viewpoint of DLA for precision grammars."
W07-2205,The Impact of Deep Linguistic Processing on Parsing Technology,2007,2,7,1,1,1468,timothy baldwin,Proceedings of the Tenth International Conference on Parsing Technologies,0,"As the organizers of the ACL 2007 Deep Linguistic Processing workshop (Baldwin et al., 2007), we were asked to discuss our perspectives on the role of current trends in deep linguistic processing for parsing technology. We are particularly interested in the ways in which efficient, broad coverage parsing systems for linguistically expressive grammars can be built and integrated into applications which require richer syntactic structures than shallow approaches can provide. This often requires hybrid technologies which use shallow or statistical methods for pre- or post-processing, to extend coverage, or to disambiguate the output."
W07-1602,Landmark Classification for Route Directions,2007,16,11,2,0,48953,aidan furlan,Proceedings of the Fourth {ACL}-{SIGSEM} Workshop on Prepositions,0,"In order for automated navigation systems to operate effectively, the route instructions they produce must be clear, concise and easily understood by users. In order to incorporate a landmark within a coherent sentence, it is necessary to first understand how that landmark is conceptualised by travellers --- whether it is perceived as point-like, line-like or area-like. This paper investigates the viability of automatically classifying the conceptualisation of landmarks relative to a given city context. We use web data to learn the default conceptualisation of those landmarks, crucially analysing preposition and verb collocations in the classification."
W07-1220,The Corpus and the Lexicon: Standardising Deep Lexical Acquisition Evaluation,2007,20,3,2,0.350877,3425,yi zhang,{ACL} 2007 Workshop on Deep Linguistic Processing,0,"This paper is concerned with the standardisation of evaluation metrics for lexical acquisition over precision grammars, which are attuned to actual parser performance. Specifically, we investigate the impact that lexicons at varying levels of lexical item precision and recall have on the performance of pre-existing broad-coverage precision grammars in parsing, i.e., on their coverage and accuracy. The grammars used for the experiments reported here are the LinGO English Resource Grammar (ERG; Flickinger (2000)) and JaCY (Siegel and Bender, 2002), precision grammars of English and Japanese, respectively. Our results show convincingly that traditional F-score-based evaluation of lexical acquisition does not correlate with actual parsing performance. What we argue for, therefore, is a recall-heavy interpretation of F-score in designing and optimising automated lexical acquisition algorithms."
W07-0907,Dynamic Path Prediction and Recommendation in a Museum Environment,2007,13,15,2,1,41273,karl grieser,Proceedings of the Workshop on Language Technology for Cultural Heritage Data ({L}a{T}e{CH} 2007).,0,"This research is concerned with making recommendations to museum visitors based on their history within the physical environment, and textual information associated with each item in their history. We investigate a method of providing such recommendations to users through a combination of language modelling techniques, geospatial modelling of the physical space, and observation of sequences of locations visited by other users in the past. This study compares and analyses different methods of path prediction including an adapted naive Bayes method, document similarity, visitor feedback and measures of lexical similarity."
U07-1009,Extending Sense Collocations in Interpreting Noun Compounds,2007,21,5,3,1,38922,su kim,Proceedings of the Australasian Language Technology Workshop 2007,0,"This paper investigates the task of noun compound interpretation, building on the sense collocation approach proposed by Moldovan et al. (2004). Our primary task is to evaluate the impact of similar words on the sense collocation method, and decrease the sensitivity of the classifiers by expanding the range of sense collocations via different semantic relations. Our method combines hypernyms, hyponyms and sister words of the component nouns, based on WORDNET. The data used in our experiments was taken from the nominal pair interpretation task of SEMEVAL-2007 (4th International Workshop on Semantic Evaluation 2007). In our evaluation, we test 7-way and 2-way class data, and show that the inclusion of hypernyms improves the performance of the sense collocation method, while the inclusion of hyponym and sister word information leads to a deterioration in performance."
U07-1018,Dictionary Alignment for Context-sensitive Word Glossing,2007,12,1,2,0,49092,willy yap,Proceedings of the Australasian Language Technology Workshop 2007,0,"This paper proposes a method for automatically sense-to-sense aligning dictionaries in different languages (focusing on Japanese and English), based on structural data in the respective dictionaries. The basis of the proposed method is sentence similarity of the sense definition sentences, using a bilingual Japanese-to-English dictionary as a pivot during the alignment process. We experiment with various embellishments to the basic method, including term weighting, stemming/lemmatisation, and ontology expansion."
S07-1049,{MELB}-{KB}: Nominal Classification as Noun Compound Interpretation,2007,9,6,2,1,38922,su kim,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper, we outline our approach to interpreting semantic relations in nominal pairs in SemEval-2007 task #4: Classification of Semantic Relations between Nominals. We build on two baseline approaches to interpreting noun compounds: sense collocation, and constituent similarity. These are consolidated into an overall system in combination with co-training, to expand the training data. Our two systems attained an average F-score over the test data of 58.7% and 57.8%, respectively."
S07-1050,{MELB}-{MKB}: Lexical Substitution system based on Relatives in Context,2007,5,11,3,1,13902,david martinez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper we describe the MELB-MKB system, as entered in the SemEval-2007 lexical substitution task. The core of our system was the Relatives in Context unsupervised approach, which ranked the candidate substitutes by web-lookup of the word sequences built combining the target context and each substitute. Our system ranked third in the final evaluation, performing close to the top-ranked system."
S07-1051,{MELB}-{YB}: Preposition Sense Disambiguation Using Rich Semantic Features,2007,11,32,2,1,43951,patrick ye,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,This paper describes a maxent-based preposition sense disambiguation system entry to the preposition sense disambiguation task of the SemEval 2007. This system uses a wide variety of semantic and syntactic features to perform the disambiguation task and achieves a precision of 69.3% over the test data.
S07-1076,{UBC}-{UMB}: Combining unsupervised and supervised systems for all-words {WSD},2007,5,0,2,1,13902,david martinez,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper describes the joint submission of two systems to the all-words WSD sub-task of SemEval-2007 task 17. The main goal of this work was to build a competitive unsupervised system by combining heterogeneous algorithms. As a secondary goal, we explored the integration of unsupervised predictions into a supervised system by different means."
D07-1050,Word Sense Disambiguation Incorporating Lexical and Structural Semantic Information,2007,21,14,3,0.665167,29830,takaaki tanaka,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"We present results that show that incorporating lexical and structural semantic information is effective for word sense disambiguation. We evaluated the method by using precise information from a large treebank and an ontology automatically created from dictionary sentences. Exploiting rich semantic and structural information improves precision 2xe2x80x903%. The most gains are seen with verbs, with an improvement of 5.7% over a model using only bag of words and n-gram features."
W06-2110,Automatic Identification of {E}nglish Verb Particle Constructions using Linguistic Features,2006,20,10,2,1,38922,su kim,Proceedings of the Third {ACL}-{SIGSEM} Workshop on Prepositions,0,"This paper presents a method for identifying token instances of verb particle constructions (VPCs) automatically, based on the output of the RASP parser. The proposed method pools together instances of VPCs and verb-PPs from the parser output and uses the sentential context of each such instance to differentiate VPCs from verb-PPs. We show our technique to perform at an F-score of 97.4% at identifying VPCs in Wall Street Journal and Brown Corpus data taken from the Penn Tree-bank."
W06-1620,Multilingual Deep Lexical Acquisition for {HPSG}s via Supertagging,2006,24,20,2,0,3270,phil blunsom,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"We propose a conditional random field-based method for supertagging, and apply it to the task of learning new lexical items for HPSG-based precision grammars of English and Japanese. Using a pseudo-likelihood approximation we are able to scale our model to hundreds of supertags and tens-of-thousands of training sentences. We show that it is possible to achieve start-of-the-art results for both languages using maximally language-independent lexical features. Further, we explore the performance of the models at the type- and token-level, demonstrating their superior performance when compared to a unigram-based baseline and a transformation-based learning approach."
W06-1201,"Compositionality and Multiword Expressions: Six of One, Half a Dozen of the Other?",2006,15,13,1,1,1468,timothy baldwin,Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,0,"In this talk, I will investigate the relationship between compositionality and multiword expressions, as part of which I will outline different approaches for formalising the notion of compositionality. I will then briefly review computational methods that have been proposed for modelling compositionality, and applications thereof. Finally, I will discuss possible future directions for modelling compositionality, and present some preliminary results."
W06-1208,Interpretation of Compound Nominalisations using Corpus and Web Statistics,2006,26,11,2,1,41188,jeremy nicholson,Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,0,"We present two novel paraphrase tests for automatically predicting the inherent semantic relation of a given compound nominalisation as one of subject, direct object, or prepositional object. We compare these to the usual verb-argument paraphrase test using corpus statistics, and frequencies obtained by scraping the Google search engine interface. We also implemented a more robust statistical measure than maximum likelihood estimation --- the confidence interval. A significant reduction in data sparseness was achieved, but this alone is insufficient to provide a substantial performance improvement."
U06-1011,Die Morphologie (f): Targeted Lexical Acquisition for Languages other than {E}nglish,2006,21,4,2,1,41188,jeremy nicholson,Proceedings of the Australasian Language Technology Workshop 2006,0,"We examine standard deep lexical acquisition features in automatically predicting the gender of noun types and tokens by bootstrapping from a small annotated corpus. Using a knowledge-poor approach to simulate prediction in unseen languages, we observe results comparable to morphological analysers trained specifically on our target languages of German and French. These results describe further scope in analysing other properties in languages displaying a more challenging morphosyntax, in order to create language resources in a language-independent manner."
U06-1020,Verb Sense Disambiguation Using Selectional Preferences Extracted with a State-of-the-art Semantic Role Labeler,2006,11,18,2,1,43951,patrick ye,Proceedings of the Australasian Language Technology Workshop 2006,0,"This paper investigates whether multisemantic-role (MSR) based selectional preferences can be used to improve the performance of supervised verb sense disambiguation. Unlike conventional selectional preferences which are extracted from parse trees based on hand-crafted rules, and only include the direct subject or the direct object of the verbs, the MSR based selectional preferences to be presented in this paper are extracted from the output of a state-of-the-art semantic role labeler and incorporate a much richer set of semantic roles. The performance of the MSR based selectional preferences is evaluated on two distinct datasets: the verbs from the lexical sample task of SENSEVAL-2, and the verbs from a movie script corpus. We show that the MSR based features can indeed improve the performance of verb sense disambiguation."
U06-1022,Analysis and Prediction of User Behaviour in a Museum Environment,2006,-1,-1,2,1,41273,karl grieser,Proceedings of the Australasian Language Technology Workshop 2006,0,None
P06-2064,Interpreting Semantic Relations in Noun Compounds via Verb Semantics,2006,20,64,2,1,38922,su kim,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"We propose a novel method for automatically interpreting compound nouns based on a predefined set of semantic relations. First we map verb tokens in sentential contexts to a fixed set of seed verbs using WordNet::Similarity and Moby's Thesaurus. We then match the sentences with semantic relations based on the semantics of the seed verbs and grammatical roles of the head noun and modifier. Based on the semantics of the matched sentences, we then build a classifier using TiMBL. The performance of our final system at interpreting NCs is 52.6%."
hughes-etal-2006-reconsidering,Reconsidering Language Identification for Written Language Resources,2006,17,61,2,0,49832,baden hughes,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The task of identifying the language in which a given document (ranging from a sentence to thousands of pages) is written has been relatively well studied over several decades. Automated approachesto written language identification are used widely throughout research and industrial contexts, over both oral and written source materials. Despite this widespread acceptance, a review of previous research in written language identification reveals a number of questions which remain openand ripe for further investigation."
baldwin-awab-2006-open,Open Source Corpus Analysis Tools for {M}alay,2006,6,20,1,1,1468,timothy baldwin,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Tokenisers, lemmatisers and POS taggers are vital to the linguistic and digital furtherment of any language. In this paper, we present an open source toolkit for Malay incorporating a word and sentence tokeniser, a lemmatiser and a partial POS tagger, based on heavy reuse of pre-existing language resources. We outline the software architecture of each component, and present an evaluation of each over a 26K word sample of Malay text."
W05-1008,Bootstrapping Deep Lexical Resources: Resources for Courses,2005,15,36,1,1,1468,timothy baldwin,Proceedings of the {ACL}-{SIGLEX} Workshop on Deep Lexical Acquisition,0,"We propose a range of deep lexical acquisition methods which make use of morphological, syntactic and ontological language resources to model word similarity and bootstrap from a seed lexicon. The different methods are deployed in learning lexical items for a precision grammar, and shown to each have strengths and weaknesses over different word classes. A particular focus of this paper is the relative accessibility of different language resource types, and predicted bang for the buck associated with each in deep lexical acquisition applications."
U05-1008,{POS} Tagging with a More Informative Tagset,2005,16,5,2,1,32906,andrew mackinlay,Proceedings of the Australasian Language Technology Workshop 2005,0,"We investigate the impact of introducing finer distinctions into the tagset on the accuracy of partof-speech tagging. This is a tangential approach to most recent research in the field, which has focussed on applying dierent algorithms using a very similar set of features. We outline the basic approach to tagset refinement and describe preliminary findings."
U05-1021,Efficient Grapheme-phoneme Alignment for {J}apanese,2005,0,1,2,1,44609,lars yencken,Proceedings of the Australasian Language Technology Workshop 2005,0,None
U05-1022,Statistical Interpretation of Compound Nominalisations,2005,17,7,2,1,41188,jeremy nicholson,Proceedings of the Australasian Language Technology Workshop 2005,0,"This paper presents a method for detecting compound nominalisations from open data, and providing a semantic intepretation. It uses a statistical model based on confidence intervals over frequencies extracted from a large, balanced corpus. Using three paraphrases of the given compound nominalisation, and interpretation preferences of its components, the algorithm achieves about 70% accuracy in classifying the semantic relationship as one of subject, and object, and 57% between subject, direct object, and prepositional object."
I05-1068,Semantic Role Labelling of Prepositional Phrases,2005,14,3,2,1,43951,patrick ye,Second International Joint Conference on Natural Language Processing: Full Papers,0,"We propose a method for labelling prepositional phrases according to two different semantic role classifications, as contained in the Penn treebank and the CoNLL 2004 Semantic Role Labelling data set. Our results illustrate the difficulties in determining preposition semantics, but also demonstrate the potential for PP semantic role labelling to improve the performance of a holistic semantic role labelling system."
I05-1082,Automatic Interpretation of Noun Compounds Using {W}ord{N}et Similarity,2005,22,77,2,1,38922,su kim,Second International Joint Conference on Natural Language Processing: Full Papers,0,"The paper introduces a method for interpreting novel noun compounds with semantic relations. The method is built around word similarity with pre-tagged noun compounds, based on WordNet::Similarity. Over 1,088 training instances and 1,081 test instances from the Wall Street Journal in the Penn Treebank, the proposed method was able to correctly classify 53.3% of the test noun compounds. We also investigated the relative contribution of the modifier and the head noun in noun compounds of different semantic types."
Y04-1012,Automatic Discovery of Telic and Agentive Roles from Corpus Data,2004,12,17,2,0,300,ichiro yamada,"Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation",0,"We present two methods for automatically discovering the telic and agentive roles of nouns from corpus data. These relations form part of the qualia structure assumed in generative lexicon theory, where the telic role represents a typical purpose of the entity and the agentive role represents the origin of the entity. The first discovery method uses hand-generated templates for each role type, and the second employs a supervised machine-learning technique. To evaluate the effectiveness of the two methods, we took a sample of 30 nouns, selected 50 verbs for each, and then generated a ranked list of verbs for a given noun. Using a variant of Spearmanxe2x80x99s rank correlation, we demonstrate the ability of the methods to identify qualia structure."
W04-0907,Making sense of {J}apanese relative clause constructions,2004,14,3,1,1,1468,timothy baldwin,Proceedings of the 2nd Workshop on Text Meaning and Interpretation,0,"We apply the C4.5 decision tree learner in interpreting Japanese relative clause constructions, based around shallow syntactic and semantic processing. In parameterising data for use with C4.5, we propose and test various means of reducing intra-clausal interpretational ambiguity, and cross indexing the overall analysis of cosubordinated relative clause constructions. We additionally investigate the disambiguating effect of the different parameter types used, and establish upper bounds for the task."
W04-0404,Translation by Machine of Complex Nominals: Getting it Right,2004,17,45,1,1,1468,timothy baldwin,Proceedings of the Workshop on Multiword Expressions: Integrating Processing,0,"We present a method for compositionally translating noun-noun (NN) compounds, using a word-level bilingual dictionary and syntactic templates for candidate generation, and corpus and dictionary statistics for selection. We propose a support vector learning-based method employing target language corpus and bilingual dictionary data, and evaluate it over a English xe2x86x94 Japanese machine translation task. We show the proposed method to be superior to previous methods and also robust over low-frequency NN compounds."
bilac-etal-2004-evaluating,Evaluating the {FOKS} Error Model,2004,8,2,2,0.833333,47895,slaven bilac,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Learners of Japanese face great difficulty when trying to lookup words containing kanji in a dictionary, due to the requirement of knowing the correct reading of the target word. We propose a system that imitates the cognitive process learners go through in generating readings for novel kanji strings, and provide direct access to the dictionary entries based on the generated readings. In doing so we remove the correct reading requirement. The system described here is implemented in a web-based environment and freely available for general use. In this paper we provide an analysis of query and error data collected by our server."
baldwin-etal-2004-road,Road-testing the {E}nglish {R}esource {G}rammar Over the {B}ritish {N}ational {C}orpus,2004,8,56,1,1,1468,timothy baldwin,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper addresses two questions: (1) when a large deep processing resource developed for relatively closed domains is run over open text, what coverage does it have, and (2) what are the most effective and time-efficient ways of consolidating gaps in the coverage of such as resource?"
villavicencio-etal-2004-multilingual,A Multilingual Database of Idioms,2004,7,11,2,0.45977,7141,aline villavicencio,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents a possible architecture for a multilingual database of idioms. We discuss the challenges that idioms present to the creation of such a database and propose a possible encoding that maximises the amount of information that can be stored for different languages. Such a resource provides important information for linguistic, computational linguistic and psycholinguistic use, and allows for the comparison of different phenomena in different languages. This can provide the basis for a better understanding of regularities in idioms across languages."
W03-1803,Noun-Noun Compound Machine Translation A Feasibility Study on Shallow Processing,2003,16,49,2,0.665167,29830,takaaki tanaka,"Proceedings of the {ACL} 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment",0,"The translation of compound nouns is a major issue in machine translation due to their frequency of occurrence and high productivity. Various shallow methods have been proposed to translate compound nouns, notable amongst which are memory-based machine translation and word-to-word compositional machine translation. This paper describes the results of a feasibility study on the ability of these methods to translate Japanese and English noun-noun compounds."
W03-1809,A Statistical Approach to the Semantics of Verb-Particles,2003,23,96,2,0,21000,colin bannard,"Proceedings of the {ACL} 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment",0,"This paper describes a distributional approach to the semantics of verb-particle constructions (e.g. put up, make off). We report first on a framework for implementing and evaluating such models. We then go on to report on the implementation of some techniques for using statistical models acquired from corpus data to infer the meaning of verb-particle constructions."
W03-1812,An Empirical Model of Multiword Expression Decomposability,2003,26,181,1,1,1468,timothy baldwin,"Proceedings of the {ACL} 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment",0,"This paper presents a construction-inspecific model of multiword expression decomposability based on latent semantic analysis. We use latent semantic analysis to determine the similarity between a multiword expression and its constituent words, and claim that higher similarities indicate greater decomposability. We test the model over English noun-noun compounds and verb-particles, and evaluate its correlation with similarities and hyponymy values in WordNet. Based on mean hyponymy over partitions of data ranked on similarity, we furnish evidence for the calculated similarities being correlated with the semantic relational content of WordNet."
W03-1010,A Plethora of Methods for Learning {E}nglish Countability,2003,14,20,1,1,1468,timothy baldwin,Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,0,"This paper compares a range of methods for classifying words based on linguistic diagnostics, focusing on the task of learning countabilities for English nouns. We propose two basic approaches to feature representation: distribution-based representation, which simply looks at the distribution of features in the corpus data, and agreement-based representation which analyses the level of token-wise agreement between multiple preprocessor systems. We additionally compare a single multiclass classifier architecture with a suite of binary classifiers, and combine analyses from multiple preprocessors. Finally, we present and evaluate a feature selection method."
U03-1007,The Ins and Outs of {D}utch noun countability classification,2003,15,1,1,1,1468,timothy baldwin,Proceedings of the Australasian Language Technology Workshop 2003,0,This paper presents a range of methods for classifying Dutch noun countability based on either Dutch or English data. The classification is founded on translational equivalences and the corpus analysis of linguistic features which correlate with particular countability classes. We show that crosslingual classification on the basis of word-to-word or featureto-feature mappings between English and Dutch performs at least as well as in-language classification based on gold-standard Dutch countability data.
P03-1059,Learning the Countability of {E}nglish Nouns from Corpus Data,2003,16,46,1,1,1468,timothy baldwin,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"This paper describes a method for learning the countability preferences of English nouns from raw text corpora. The method maps the corpus-attested lexico-syntactic properties of each noun onto a feature vector, and uses a suite of memory-based classifiers to predict membership in 4 countability classes. We were able to assign countability to English nouns with a precision of 94.6%."
2003.mtsummit-papers.50,Translation selection for {J}apanese-{E}nglish noun-noun compounds,2003,14,13,2,0.665167,29830,takaaki tanaka,Proceedings of Machine Translation Summit IX: Papers,0,"We present a method for compositionally translating Japanese NN compounds into English, using a word-level transfer dictionary and target language monolingual corpus. The method interpolates over fully-specified and partial translation data, based on corpus evidence. In evaluation, we demonstrate that interpolation over the two data types is superior to using either one, and show that our method performs at an F-score of 0.68 over translation-aligned inputs and 0.66 over a random sample of 500 NN compounds."
W02-2001,Extracting the Unextractable: A Case Study on Verb-particles,2002,21,66,1,1,1468,timothy baldwin,{COLING}-02: The 6th Conference on Natural Language Learning 2002 ({C}o{NLL}-2002),0,"This paper proposes a series of techniques for extracting English verb--particle constructions from raw text corpora. We initially propose three basic methods, based on tagger output, chunker output and a chunk grammar, respectively, with the chunk grammar method optionally combining with an attachment resolution module to determine the syntactic structure of verb--preposition pairs in ambiguous constructs. We then combine the three methods together into a single classifier, and add in a number of extra lexical and frequentistic features, producing a final F-score of 0.865 over the WSJ."
copestake-etal-2002-multiword,Multiword expressions: linguistic precision and reusability,2002,4,52,5,0,6790,ann copestake,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper discusses the approach to multiword expressions being adopted in the LinGO English Resource Grammar (http://lingo.stanford.edu), a broad-scale bidirectional grammar of English in the HPSG framework. We discuss how the lexicon of multiword expressions is encoded in a database and describe the implications for building a reusable lexical resource."
baldwin-etal-2002-enhanced,Enhanced {J}apanese Electronic Dictionary Look-up,2002,7,2,1,1,1468,timothy baldwin,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper describes the process of data preparation and reading generation for an ongoing project aimed at improving the accessibility of unknown words for learners of foreign languages, focusing initially on Japanese. Rather then requiring absolute knowledge of the readings of words in the foreign language, we allow look-up of dictionary entries by readings which learners can predictably be expected to associate with them. We automatically extract an exhaustive set of phonemic readings for each grapheme segment and learn basic morpho-phonological rules governing compound word formation, associating a probability with each. Then we apply the naive Bayes model to generate a set of readings and give each a likeliness score based on previously extracted evidence and corpus frequencies."
C02-1140,Bringing the Dictionary to the User: The {FOKS} System,2002,9,9,2,0.833333,47895,slaven bilac,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"The dictionary look-up of unknown words is particularly difficult in Japanese due to the complicated writing system. We propose a system which allows learners of Japanese to look up words according to their expected, but not necessarily correct, reading. This is an improvement over previous systems which provide no handling of incorrect readings. In preprocessing, we calculate the possible readings each kanji character can take and different types of phonological and conjugational changes that can occur, and associate a probability with each. Using these probabilities and corpus-based frequencies we calculate a plausibility measure for each generated reading given a dictionary entry, based on the naive Bayes model. In response to a reading input, we calculate the plausibility of each dictionary entry corresponding to the reading and display a list of candidates for the user to choose from. We have implemented our system in a web-based environment and are currently evaluating its usefulness to learners of Japanese."
2002.tmi-tutorials.3,Translation memories,2002,2,2,1,1,1468,timothy baldwin,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Tutorials,0,"This paper begins with the following question: What is the relation between memory and translation? If a computer, which can be given a very large amount of memory, stored millions and millions of documents and their human translations would that computer then be able to translate just like a human? The paper then explores a limitation to automatic translation based on memory. This limitation is explained in terms of the Black Box Myth of translation. However, despite this limitation, the usefulness of computers is explored as productivity tools for human translators. Then the study asks what properties might be needed in a computer, besides memory, in order to allow it to translate like a human and how to tell whether a computer has acquired human translation skills. A variation of the Turing Test is proposed as a diagnostic, along with various intermediate translation-based tests for theories of meaning. The paper ends with some philosophical speculation about the possible role of free will in language,..."
2002.tmi-papers.2,Alternation-based lexicon reconstruction,2002,10,2,1,1,1468,timothy baldwin,Proceedings of the 9th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages: Papers,0,"This research is aimed at developing a hierarchical alternation-based lexical architecture for machine translation. The proposed architecture makes extensive use of information sharing in describing valency frames through derivational links from base frames, rather than as independent entities. This has advantages in descriptive exe2x80x90ciency, robustness and maintainability. The lexicon being developed is built up automatically from the Japanese component of an existing Japanese-English machine translation lexicon. The reconstruction process consists of analysing consistencies in selectional restrictions between valency frames, and postulating alternations where selectional restrictions are preserved on matching case slots; this was found to perform at 60.9% accuracy. All alternation candidates are incorporated into the flnal-version lexicon as derivational links, and expanded out at run time."
S01-1013,The {J}apanese Translation Task: Lexical and Structural Perspectives,2001,4,1,1,1,1468,timothy baldwin,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"This paper describes two distinct attempts at the SENSEVAL-2 Japanese translation task. The first implementation is based on lexical similarity and builds on the results of Baldwin (2001b; 2001a), whereas the second is based on structural similarity via the medium of parse trees and includes a basic model of conceptual similarity. Despite its simplistic nature, the lexical method was found to perform the better of the two, at 49.1% accuracy, as compared to 41.2% for the structural method and 36.8% for the baseline."
P01-1004,"Low-cost, High-performance Translation Retrieval: Dumber is Better",2001,12,13,1,1,1468,timothy baldwin,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"In this paper, we compare the relative effects of segment order, segmentation and segment contiguity on the retrieval performance of a translation memory system. We take a selection of both bag-of-words and segment order-sensitive string comparison methods, and run each over both character and word-segmented data, in combination with a range of local segment contiguity models (in the form of N-grams). Over two distinct datasets, we find that indexing according to simple character bigrams produces a retrieval accuracy superior to any of the tested word N-gram models. Further, in their optimum configuration, bag-of-words methods are shown to be equivalent to segment order-sensitive methods in terms of retrieval accuracy, but much faster. We also provide evidence that our findings are scalable."
Y00-1002,"Verb Alternations and {J}apanese : How, What and Where",2000,9,3,1,1,1468,timothy baldwin,"Proceedings of the 14th Pacific Asia Conference on Language, Information and Computation",0,"We set out to empirically identify the range and frequency of basic verb alternation types in Japanese, through analysis of the Goi-Taikei Japanese pattern-based valency dictionary. This is achieved through comparison of the selectional preference annotation on corresponding case slots, based on the assumption that selectional preferences are preserved under alternation. Three separate extraction methods are considered, founded around: (1) simple match of selectional restrictions; (2) selectional restriction matching, with recourse to penalised backing-off; and (3) semantic density, again with recourse to backing-off."
C00-1006,The Effects of Word Order and Segmentation on Translation Retrieval Performance,2000,12,20,1,1,1468,timothy baldwin,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"This research looks at the effects of word order and segmentation on translation retrieval performance for an experimental Japanese-English translation memory system. We implement a number of both bag-of-words and word order-sensitive similarity metrics, and test each over character-based and word-based indexing. The translation retrieval performance of each system configuration is evaluated empirically through the notion of word edit distance between translation candidate outputs and the model translation. Our results indicate that character-based indexing is consistently superior to word-based indexing, suggesting that segmentation is an unnecessary luxury in the given domain. Word order-sensitive approaches are demonstrated to generally outperform bag-of-words methods, with source language segment-level edit distance proving the most effective similarity metric."
W99-0902,The applications of unsupervised learning to {J}apanese grapheme-phoneme alignment,1999,10,8,1,1,1468,timothy baldwin,Unsupervised Learning in Natural Language Processing,0,"In this paper, we adapt the TF-IDF model to the Japanese grapheme-phoneme alignment task, by way of a simple statistical model and an incremental learning method. In the incremental learning method, grapheme-phoneme alignment paradigms are disambiguated one at a t ime according to the relative plausibility of the highest scoring alignment schema, and the statistical model is re-trained accordingly. On limited evaluation, the learning method achieved an accuracy of 93.28%, representing a slight improvement over a baseline rule-based method."
1999.tmi-1.20,Argument status in {J}apanese verb sense disambiguation,1999,-1,-1,1,1,1468,timothy baldwin,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1999.tmi-1.21,A valency dictionary architecture for Machine Translation,1999,14,12,1,1,1468,timothy baldwin,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
