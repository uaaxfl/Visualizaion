2021.emnlp-main.92,Label Verbalization and Entailment for Effective Zero and Few-Shot Relation Extraction,2021,-1,-1,3,0,6128,oscar sainz,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Relation extraction systems require large amounts of labeled examples which are costly to annotate. In this work we reformulate relation extraction as an entailment task, with simple, hand-made, verbalizations of relations produced in less than 15 min per relation. The system relies on a pretrained textual entailment engine which is run as-is (no training examples, zero-shot) or further fine-tuned on labeled examples (few-shot or fully trained). In our experiments on TACRED we attain 63{\%} F1 zero-shot, 69{\%} with 16 examples per relation (17{\%} points better than the best supervised system on the same conditions), and only 4 points short to the state-of-the-art (which uses 20 times more training data). We also show that the performance can be improved significantly with larger entailment models, up to 12 points in zero-shot, allowing to report the best results to date on TACRED when fully trained. The analysis shows that our few-shot systems are specially effective when discriminating between relations, and that the performance difference in low data regimes comes mainly from identifying no-relation cases."
2021.acl-long.506,Beyond Offline Mapping: Learning Cross-lingual Word Embeddings through Context Anchoring,2021,-1,-1,4,0,13428,aitor ormazabal,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Recent research on cross-lingual word embeddings has been dominated by unsupervised mapping approaches that align monolingual embeddings. Such methods critically rely on those embeddings having a similar structure, but it was recently shown that the separate training in different languages causes departures from this assumption. In this paper, we propose an alternative approach that does not have this limitation, while requiring a weak seed dictionary (e.g., a list of identical words) as the only form of supervision. Rather than aligning two fixed embedding spaces, our method works by fixing the target language embeddings, and learning a new set of embeddings for the source language that are aligned with them. To that end, we use an extension of skip-gram that leverages translated context words as anchor points, and incorporates self-learning and iterative restarts to reduce the dependency on the initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task."
2020.wmt-1.96,Ixamed{'}s submission description for {WMT}20 Biomedical shared task: benefits and limitations of using terminologies for domain adaptation,2020,-1,-1,3,1,13932,xabier soto,Proceedings of the Fifth Conference on Machine Translation,0,"In this paper we describe the systems developed at Ixa for our participation in WMT20 Biomedical shared task in three language pairs, en-eu, en-es and es-en. When defining our approach, we have put the focus on making an efficient use of corpora recently compiled for training Machine Translation (MT) systems to translate Covid-19 related text, as well as reusing previously compiled corpora and developed systems for biomedical or clinical domain. Regarding the techniques used, we base on the findings from our previous works for translating clinical texts into Basque, making use of clinical terminology for adapting the MT systems to the clinical domain. However, after manually inspecting some of the outputs generated by our systems, for most of the submissions we end up using the system trained only with the basic corpus, since the systems including the clinical terminologies generated outputs shorter in length than the corresponding references. Thus, we present simple baselines for translating abstracts between English and Spanish (en/es); while for translating abstracts and terms from English into Basque (en-eu), we concatenate the best en-es system for each kind of text with our es-eu system. We present automatic evaluation results in terms of BLEU scores, and analyse the effect of including clinical terminology on the average sentence length of the generated outputs. Following the recent recommendations for a responsible use of GPUs for NLP research, we include an estimation of the generated CO2 emissions, based on the power consumed for training the MT systems."
2020.emnlp-main.618,Translation Artifacts in Cross-lingual Transfer Learning,2020,41,2,2,1,10622,mikel artetxe,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Both human and machine translation play a central role in cross-lingual transfer learning: many multilingual datasets have been created through professional translation services, and using machine translation to translate either the test set or the training set is a widely used transfer technique. In this paper, we show that such translation process can introduce subtle artifacts that have a notable impact in existing cross-lingual models. For instance, in natural language inference, translating the premise and the hypothesis independently can reduce the lexical overlap between them, which current models are highly sensitive to. We show that some previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively."
2020.acl-srw.34,Unsupervised Multilingual Sentence Embeddings for Parallel Corpus Mining,2020,-1,-1,3,0,13979,ivana kvapilikova,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,0,"Existing models of multilingual sentence embeddings require large parallel data resources which are not available for low-resource languages. We propose a novel unsupervised method to derive multilingual sentence embeddings relying only on monolingual data. We first produce a synthetic parallel corpus using unsupervised machine translation, and use it to fine-tune a pretrained cross-lingual masked language model (XLM) to derive the multilingual sentence representations. The quality of the representations is evaluated on two parallel corpus mining tasks with improvements of up to 22 F1 points over vanilla XLM. In addition, we observe that a single synthetic bilingual corpus is able to improve results for other language pairs."
2020.acl-main.658,A Call for More Rigor in Unsupervised Cross-lingual Learning,2020,76,0,4,1,10622,mikel artetxe,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"We review motivations, definition, approaches, and methodology for unsupervised cross-lingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world{'}s languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models."
W19-7102,Leveraging {SNOMED} {CT} terms and relations for machine translation of clinical texts from {B}asque to {S}panish,2019,-1,-1,4,1,13932,xabier soto,Proceedings of the Second Workshop on Multilingualism at the Intersection of Knowledge Bases and Machine Translation,0,None
P19-1019,An Effective Approach to Unsupervised Machine Translation,2019,30,3,2,1,10622,mikel artetxe,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"While machine translation has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both Neural Machine Translation (NMT) and Statistical Machine Translation (SMT) systems using monolingual corpora only. In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. Moreover, we use our improved SMT system to initialize a dual NMT model, which is further fine-tuned through on-the-fly back-translation. Together, we obtain large improvements over the previous state-of-the-art in unsupervised machine translation. For instance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points more than the previous best unsupervised system, and 0.5 points more than the (supervised) shared task winner back in 2014."
P19-1492,Analyzing the Limitations of Cross-lingual Word Embedding Mappings,2019,0,10,3,0,13428,aitor ormazabal,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Recent research in cross-lingual word embeddings has almost exclusively focused on offline methods, which independently train word embeddings in different languages and map them to a shared space through linear transformations. While several authors have questioned the underlying isomorphism assumption, which states that word embeddings in different languages have approximately the same structure, it is not clear whether this is an inherent limitation of mapping approaches or a more general issue when learning cross-lingual embeddings. So as to answer this question, we experiment with parallel corpora, which allows us to compare offline mapping to an extension of skip-gram that jointly learns both embedding spaces. We observe that, under these ideal conditions, joint learning yields to more isomorphic embeddings, is less sensitive to hubness, and obtains stronger results in bilingual lexicon induction. We thus conclude that current mapping methods do have strong limitations, calling for further research to jointly learn cross-lingual embeddings with a weaker cross-lingual signal."
P19-1494,Bilingual Lexicon Induction through Unsupervised Machine Translation,2019,0,5,2,1,10622,mikel artetxe,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"A recent research line has obtained strong results on bilingual lexicon induction by aligning independently trained word embeddings in two languages and using the resulting cross-lingual embeddings to induce word translation pairs through nearest neighbor or related retrieval methods. In this paper, we propose an alternative approach to this problem that builds on the recent work on unsupervised machine translation. This way, instead of directly inducing a bilingual lexicon from cross-lingual embeddings, we use them to build a phrase-table, combine it with a language model, and use the resulting machine translation system to generate a synthetic parallel corpus, from which we extract the bilingual lexicon using statistical word alignment techniques. As such, our method can work with any word embedding and cross-lingual mapping technique, and it does not require any additional resource besides the monolingual corpus used to train the embeddings. When evaluated on the exact same cross-lingual embeddings, our proposed method obtains an average improvement of 6 accuracy points over nearest neighbor and 4 points over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset."
P18-1073,A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings,2018,12,4,2,1,10622,mikel artetxe,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Recent work has managed to learn cross-lingual word embeddings without parallel data by mapping monolingual embeddings to a shared space through adversarial training. However, their evaluation has focused on favorable conditions, using comparable corpora or closely-related languages, and we show that they often fail in more realistic scenarios. This work proposes an alternative approach based on a fully unsupervised initialization that explicitly exploits the structural similarity of the embeddings, and a robust self-learning algorithm that iteratively improves this solution. Our method succeeds in all tested scenarios and obtains the best published results in standard datasets, even surpassing previous supervised systems. Our implementation is released as an open source project at \url{https://github.com/artetxem/vecmap}."
L18-1397,{K}onbitzul: an {MWE}-specific database for {S}panish-{B}asque,2018,0,0,4,1,16505,uxoa inurrieta,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1557,Building Named Entity Recognition Taggers via Parallel Corpora,2018,0,2,5,0,7239,rodrigo agerri,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
K18-1028,Uncovering Divergent Linguistic Information in Word Embeddings with Lessons for Intrinsic and Extrinsic Evaluation,2018,25,2,2,1,10622,mikel artetxe,Proceedings of the 22nd Conference on Computational Natural Language Learning,0,"Following the recent success of word embeddings, it has been argued that there is no such thing as an ideal representation for words, as different models tend to capture divergent and often mutually incompatible aspects like semantics/syntax and similarity/relatedness. In this paper, we show that each embedding model captures more information than directly apparent. A linear transformation that adjusts the similarity order of the model without any external resource can tailor it to achieve better results in those aspects, providing a new perspective on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones."
D18-1399,Unsupervised Statistical Machine Translation,2018,0,50,2,1,10622,mikel artetxe,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"While modern machine translation has relied on large parallel corpora, a recent line of work has managed to train Neural Machine Translation (NMT) systems from monolingual corpora only (Artetxe et al., 2018c; Lample et al., 2018). Despite the potential of this approach for low-resource settings, existing systems are far behind their supervised counterparts, limiting their practical interest. In this paper, we propose an alternative approach based on phrase-based Statistical Machine Translation (SMT) that significantly closes the gap with supervised systems. Our method profits from the modular architecture of SMT: we first induce a phrase table from monolingual corpora through cross-lingual embedding mappings, combine it with an n-gram language model, and fine-tune hyperparameters through an unsupervised MERT variant. In addition, iterative backtranslation improves results further, yielding, for instance, 14.08 and 26.22 BLEU points in WMT 2014 English-German and English-French, respectively, an improvement of more than 7-10 BLEU points over previous unsupervised systems, and closing the gap with supervised SMT (Moses trained on Europarl) down to 2-5 BLEU points. Our implementation is available at \url{https://github.com/artetxem/monoses}."
W17-1720,Rule-Based Translation of {S}panish Verb-Noun Combinations into {B}asque,2017,-1,-1,4,1,16505,uxoa inurrieta,Proceedings of the 13th Workshop on Multiword Expressions ({MWE} 2017),0,"This paper presents a method to improve the translation of Verb-Noun Combinations (VNCs) in a rule-based Machine Translation (MT) system for Spanish-Basque. Linguistic information about a set of VNCs is gathered from the public database Konbitzul, and it is integrated into the MT system, leading to an improvement in BLEU, NIST and TER scores, as well as the results being evidently better according to human evaluators."
P17-1042,Learning bilingual word embeddings with (almost) no bilingual data,2017,18,136,2,1,10622,mikel artetxe,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Most methods to learn bilingual word embeddings rely on large parallel corpora, which is difficult to obtain for most language pairs. This has motivated an active research line to relax this requirement, with methods that use document-aligned corpora or bilingual dictionaries of a few thousand words instead. In this work, we further reduce the need of bilingual resources using a very simple self-learning approach that can be combined with any dictionary-based mapping technique. Our method exploits the structural similarity of embedding spaces, and works with as little bilingual evidence as a 25 word dictionary or even an automatically generated list of numerals, obtaining results comparable to those of systems that use richer resources."
W16-6405,Adding syntactic structure to bilingual terminology for improved domain adaptation,2016,3,1,2,1,10622,mikel artetxe,Proceedings of the 2nd Deep Machine Translation Workshop,0,None
W16-2332,{SMT} and Hybrid systems of the {QTL}eap project in the {WMT}16 {IT}-task,2016,26,3,2,0,17856,rosa gaudio,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"This paper presents the description of 12 systems submitted to the WMT16 IT-task, covering six different languages, namely Basque, Bulgarian, Dutch, Czech, Portuguese and Spanish. All these systems were developed under the scope of the QTLeap project, presenting a common strategy. For each language two different systems were submitted, namely a phrasebased MT system built using Moses, and a system exploiting deep language engineering approaches, that in all the languages but Bulgarian was implemented using TectoMT. For 4 of the 6 languages, the TectoMT-based system performs better than the Moses-based one."
W16-2338,{IXA} Biomedical Translation System at {WMT}16 Biomedical Translation Task,2016,10,2,2,1,13905,olatz perezdevinaspre,"Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers",0,"In this paper we present the system developed at the IXA NLP Group of the University of the Basque Country for the Biomedical Translation Task in the First Conference on Machine Translation (WMT16). For the adaptation of a statistical machine translation system to the biomedical domain, we developed three approaches based on a baseline system for English-Spanish and Spanish-English language pairs. The lack of terminology and the variation of the prominent sense of the words are the issues we have addressed on these approaches. The best of our systems reached the average of all the systems submitted in the challenge in most of the eval-"
L16-1351,Domain Adaptation in {MT} Using Titles in {W}ikipedia as a Parallel Corpus: Resources and Evaluation,2016,0,0,1,1,8822,gorka labaka,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents how an state-of-the-art SMT system is enriched by using an extra in-domain parallel corpora extracted from Wikipedia. We collect corpora from parallel titles and from parallel fragments in comparable articles from Wikipedia. We carried out an evaluation with a double objective: evaluating the quality of the extracted data and evaluating the improvement due to the domain-adaptation. We think this can be very useful for languages with limited amount of parallel corpora, where in-domain data is crucial to improve the performance of MT sytems. The experiments on the Spanish-English language pair improve a baseline trained with the Europarl corpus in more than 2 points of BLEU when translating in the Computer Science domain."
D16-1250,Learning principled bilingual mappings of word embeddings while preserving monolingual invariance,2016,10,116,2,1,10622,mikel artetxe,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,0,None
C16-1082,Using Linguistic Data for {E}nglish and {S}panish Verb-Noun Combination Identification,2016,18,1,3,1,16505,uxoa inurrieta,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We present a linguistic analysis of a set of English and Spanish verb+noun combinations (VNCs), and a method to use this information to improve VNC identification. Firstly, a sample of frequent VNCs are analysed in-depth and tagged along lexico-semantic and morphosyntactic dimensions, obtaining satisfactory inter-annotator agreement scores. Then, a VNC identification experiment is undertaken, where the analysed linguistic data is combined with chunking information and syntactic dependencies. A comparison between the results of the experiment and the results obtained by a basic detection method shows that VNC identification can be greatly improved by using linguistic information, as a large number of additional occurrences are detected with high precision."
W15-5707,Deep-syntax {T}ecto{MT} for {E}nglish-{S}panish {MT},2015,-1,-1,1,1,8822,gorka labaka,Proceedings of the 1st Deep Machine Translation Workshop,0,None
W15-4901,Exploiting portability to build an {RBMT} prototype for a new source language,2015,10,2,2,1,20841,nora aranberri,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,None
W15-4902,Building hybrid machine translation systems by using an {EBMT} preprocessor to create partial translations,2015,17,0,2,1,10622,mikel artetxe,Proceedings of the 18th Annual Conference of the {E}uropean Association for Machine Translation,0,"This paper presents a hybrid machine translation framework based on a preprocessor that translates fragments of the input text by using example-based machine translation techniques. The preprocessor resembles a translation memory with named-entity and chunk generalization, and generates a high quality partial translation that is then completed by the main translation engine, which can be either rule-based (RBMT) or statistical (SMT). Results are reported for both RBMT and SMT hybridization as well as the preprocessor on its own, showing the effectiveness of our approach."
W15-1007,Analyzing {E}nglish-{S}panish Named-Entity enhanced Machine Translation,2015,6,1,4,1,10622,mikel artetxe,"Proceedings of the Ninth Workshop on Syntax, Semantics and Structure in Statistical Translation",0,"Translation of named-entities (NEs) is an issue in SMT. In this paper we analyze the errors when translating NEs with a SMT system from English to Spanish. We train on Europarl and test on News Commentary, focusing on entities correctly recognized by an automatic NE recognition system. The automatic systems translate around 85% NEs correctly, leaving a small margin for improving performance. In addition, we implement a purpose-build NE translator and integrate it in the SMT system, yielding a small but significant improvement in BLEU score. Our analysis shows that, contrary to similar systems translating from Chinese to English, there was no improvement in NE translation, prompting further work."
2015.eamt-1.2,Exploiting portability to build an {RBMT} prototype for a new source language,2015,10,2,2,1,20841,nora aranberri,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,None
2015.eamt-1.3,Building hybrid machine translation systems by using an {EBMT} preprocessor to create partialtranslations,2015,17,0,2,1,10622,mikel artetxe,Proceedings of the 18th Annual Conference of the European Association for Machine Translation,0,"This paper presents a hybrid machine translation framework based on a preprocessor that translates fragments of the input text by using example-based machine translation techniques. The preprocessor resembles a translation memory with named-entity and chunk generalization, and generates a high quality partial translation that is then completed by the main translation engine, which can be either rule-based (RBMT) or statistical (SMT). Results are reported for both RBMT and SMT hybridization as well as the preprocessor on its own, showing the effectiveness of our approach."
2014.amta-wptp.2,Comparison of post-editing productivity between professional translators and lay users,2014,-1,-1,2,1,20841,nora aranberri,Proceedings of the 11th Conference of the Association for Machine Translation in the Americas,0,"This work compares the post-editing productivity of professional translators and lay users. We integrate an English to Basque MT system within Bologna Translation Service, an end-to-end translation management platform, and perform a producitivity experiment in a real working environment. Six translators and six lay users translate or post-edit two texts from English into Basque. Results suggest that overall, post-editing increases translation throughput for both translators and users, although the latter seem to benefit more from the MT output. We observe that translators and users perceive MT differently. Additionally, a preliminary analysis seems to suggest that familiarity with the domain, source text complexity and MT quality might affect potential productivity gain."
W12-6212,Developing an Open-Source {FST} Grammar for Verb Chain Transfer in a {S}panish-{B}asque {MT} System,2012,6,1,3,0,42031,aingeru mayor,Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing,0,"This paper presents the current status of development of a finite state transducer grammar for the verbal-chain transfer module in Matxin, a Rule Based Machine Translation system between Spanish and Basque. Due to the distance between Spanish and Basque, the verbal-chain transfer is a very complex module in the overall system. The grammar is compiled with foma, an open-source finitestate toolkit, and yields a translation execution time of 2000 verb chains/second."
2012.freeopmt-1.7,Deep evaluation of hybrid architectures: use of different metrics in {MERT} weight optimization,2012,-1,-1,2,0.689655,5030,cristina espanabonet,Proceedings of the Third International Workshop on Free/Open-Source Rule-Based Machine Translation,0,None
2011.mtsummit-papers.63,Hybrid Machine Translation Guided by a Rule{--}Based System,2011,11,17,2,0.689655,5030,cristina espanabonet,Proceedings of Machine Translation Summit XIII: Papers,0,"This paper presents a machine translation architecture which hybridizes Matxin, a rulebased system, with regular phrase-based Statistical Machine Translation. In short, the hybrid translation process is guided by the rulebased engine and, before transference, a set of partial candidate translations provided by SMT subsystems is used to enrich the treebased representation. The final hybrid translation is created by choosing the most probable combination among the available fragments with a statistical decoder in a monotonic way.n We have applied the hybrid model to a pairn of distant languages, Spanish and Basque, andn according to our evaluation (both automaticn and manual) the hybrid approach significantlyn outperforms the best SMT system on out-of-domain data."
alegria-etal-2010-morphological,A Morphological Processor Based on {F}oma for {B}iscayan (a {B}asque dialect),2010,10,0,4,1,28091,inaki alegria,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We present a new morphological processor for Biscayan, a dialect of Basque, developed on the description of the morphology of standard Basque. The database for the standard morphology has been extended for dialects and an open-source tool for morphological description named foma is used for building the processor. Biscayan is a dialect of the Basque language spoken mainly in Biscay, a province on the western of the Basque Country. The description of the lexicon and the morphotactics (or word grammar) for the standard Basque was carried out using a relational database and the database has been extended in order to include dialectal variants linked to the standard entries. XuxenB, a spelling checker/corrector for this dialect, is the first application of this work. Additionally to the basic analyzer used for spelling, a new transducer is included. It is an enhanced analyzer for linking standard form with the corresponding standard ones. It is used in correction for generation of proposals when in the input text appear standard forms which we want to replace with dialectal forms."
C10-1005,Plagiarism Detection across Distant Language Pairs,2010,27,45,4,0,15265,alberto barroncedeno,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"Plagiarism, the unacknowledged reuse of text, does not end at language boundaries. Cross-language plagiarism occurs if a text is translated from a fragment written in a different language and no proper citation is provided. Regardless of the change of language, the contents and, in particular, the ideas remain the same. Whereas different methods for the detection of monolingual plagiarism have been developed, less attention has been paid to the cross-language case.n n In this paper we compare two recently proposed cross-language plagiarism detection methods (CL-CNG, based on character n-grams and CL-ASA, based on statistical translation), to a novel approach to this problem, based on machine translation and monolingual similarity analysis (TMA). We explore the effectiveness of the three approaches for less related languages. CL-CNG shows not be appropriate for this kind of language pairs, whereas TMA performs better than the previously proposed models."
2009.mtsummit-posters.4,Reordering on {S}panish-{B}asque {SMT},2009,-1,-1,2,0,47470,arantza ilaraza,Proceedings of Machine Translation Summit XII: Posters,0,None
2009.eamt-1.9,Use of Rich Linguistic Information to Translate Prepositions and Grammar Cases to {B}asque,2009,18,5,3,0,8824,eneko agirre,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"This paper presents three successful techniques to translate prepositions heading verbal complements by means of rich linguistic information, in the context of a rule-based Machine Translation system for an agglutinative language with scarce resources. This information comes in the form of lexicalized syntactic dependency triples, verb subcategorization and manually coded selection rules based on lexical, syntactic and semantic information. The first two resources have been automatically extracted from monolingual corpora. The results obtained using a new evaluation methodology show that all proposed techniques improve precision over the baselines, including a translation dictionary compiled from an aligned corpus, and a state-of-the-art statistical Machine Translation system. The results also show that linguistic information in all three techniques are complementary, and that a combination of them obtains the best F-score results overall."
2009.eamt-1.11,Relevance of Different Segmentation Options on {S}panish-{B}asque {SMT},2009,15,1,2,0.325407,24640,arantza ilarraza,Proceedings of the 13th Annual conference of the European Association for Machine Translation,0,"Segmentation is widely used in adapting Statistical Machine Translation to highly inflected languages as Basque. The way this segmentation is carried out impacts on the quality of the translation. In order to look for the most adequate segmentation for a Spanish-Basque system, we have tried different segmentation options and analyzed their effects on the translation quality. Although all segmentation options used in this work are based on the same morphological analysis, translation quality varies significantly depending on the segmentation criteria used. Most of the segmentation options outperform the baseline according to all metrics, except the one which splits words according the morpheme boundaries. From here we can conclude the importance of the development of the segmentation criteria in SMT."
2008.amta-papers.1,{S}panish-to-{B}asque {M}ulti{E}ngine Machine Translation for a Restricted Domain,2008,-1,-1,5,1,28091,inaki alegria,Proceedings of the 8th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We present our initial strategy for Spanish-to-Basque MultiEngine Machine Translation, a language pair with very different structure and word order and with no huge parallel corpus available. This hybrid proposal is based on the combination of three different MT paradigms: Example-Based MT, Statistical MT and Rule- Based MT. We have evaluated the system, reporting automatic evaluation metrics for a corpus in a test domain. The first results obtained are encouraging."
2007.mtsummit-papers.40,Comparing rule-based and data-driven approaches to {S}panish-to-{B}asque machine translation,2007,23,19,1,1,8822,gorka labaka,Proceedings of Machine Translation Summit XI: Papers,0,"In this paper, we compare the rule-based and data-drivenn approaches in the context of Spanish-to-Basque Machine Translation. The rule-based system we consider has been developed specifically for Spanish-to-Basque machine translation, and is tuned to this language pair. On the contrary, the data-driven system we use is generic, and has not been specifically designed to deal with Basque. Spanish-to-Basque Machine Translation is a challenge for data-drivenn approaches for at least two reasons. First, there is lack ofn bilingual data on which a data-driven MT system can be trained. Second, Basque is a morphologically-rich agglutinative language and translating to Basque requires a huge generation of morphological information, a difficult task for a generic system not specifically tuned to Basque. We present the results of a series of experiments, obtained on two different corpora, one being xe2x80x9cin-domainxe2x80x9d and then other one xe2x80x9cout-of-domainxe2x80x9d with respect to the data-drivenn system. We show that n-gram based automatic evaluation and edit-distance-based human evaluation yield two different sets of results. According to BLEU, the data-driven system outperforms the rule-based system on the in-domain data, while according to the human evaluation, the rule-basedn approach achieves higher scores for both corpora."
2005.mtsummit-osmtw.2,An Open Architecture for Transfer-based Machine Translation between {S}panish and {B}asque,2005,7,10,3,0,28091,inaki alegria,Workshop on open-source machine translation,0,"We present the current status of development of an open architecture for the translation from Spanish into Basque. The machine translation architecture uses an open source analyser for Spanish and new modules mainly based on finite-state transducers. The project is integrated in the OpenTrad initiative, a larger government funded project shared among different universities and small companies, which will also include MT engines for translation among the main languages in Spain. The main objective is the construction of an open, reusable and interoperable framework. This paper describes the design of the engine, the formats it uses for the communication among the modules, the modules reused from other project named Matxin and the new modules we are building."
