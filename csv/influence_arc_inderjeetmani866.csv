1991.mtsummit-papers.4,W91-0109,1,0.813531,"Missing"
1991.mtsummit-papers.4,W90-0107,1,0.89702,"Missing"
1991.mtsummit-papers.4,W91-0114,1,0.719369,"Missing"
1991.mtsummit-papers.4,E89-1032,0,0.125206,"Missing"
1991.mtsummit-papers.4,P90-1017,0,0.0819618,"Missing"
1991.mtsummit-papers.4,J85-4002,0,0.110244,"Missing"
1991.mtsummit-papers.4,P91-1025,0,0.129776,"Missing"
1991.mtsummit-papers.4,A88-1003,1,0.89245,"Missing"
1991.mtsummit-papers.4,A88-1026,1,0.76461,"Missing"
1991.mtsummit-papers.4,C90-2052,0,\N,Missing
1991.mtsummit-papers.4,A88-1034,0,\N,Missing
breck-etal-2000-evaluate,P99-1042,1,\N,Missing
E99-1011,J97-1002,0,0.100238,"Missing"
H01-1031,A97-1006,0,0.0151107,"pect to when the time period starts and ends; the early 60’s is fuzzy as to which part of the 1960’s is included. Our format for representing time values includes parameters such as FA (for Fall), EARLY (for early, etc.), PRESENT_REF (for today, current, etc.), among others. For example, we have <TIMEX2 VAL=“1990-SU”>Summer of 1990</TIMEX2>. Fuzziness in modifiers is also represented, e.g., <TIMEX2 VAL=“1990” MOD=“BEFORE”>more than a Others have used temporal annotation schemes for the much more constrained domain of meeting scheduling, e.g., [Wiebe et al. 1998], [Alexandersson et al. 1997], [Busemann et al. 1997]; our scheme has been applied to such domains as well. In particular, we have begun annotation of the ‘Enthusiast’ corpus of meeting scheduling dialogs used at CMU and by [Wiebe et al. 1998]. Only minor revisions to the guidelines’ rules for tag extent have so far been required for these dialogs. This annotation scheme is also being leveraged in the Automatic Content Extraction (ACE) program of the U.S. Department of Defense, whose focus is on extraction of time-dependent relations between pairs of ‘entities’ (persons, organizations, etc.). Finally, initial feedback from Machine Translation s"
H01-1031,setzer-gaizauskas-2000-annotating,0,\N,Missing
H01-1031,A97-1007,0,\N,Missing
H01-1031,P00-1010,1,\N,Missing
H01-1038,P00-1010,1,0.854482,"Missing"
H01-1038,W00-0503,1,\N,Missing
H05-1046,W95-0101,0,0.159817,"Missing"
H05-1046,W03-0103,0,0.0607092,"Missing"
H05-1046,P95-1026,0,0.231477,"Missing"
H05-1046,W03-0107,0,\N,Missing
H05-1046,W03-0106,0,\N,Missing
J09-4002,C02-1140,0,0.0651193,"Missing"
J09-4002,C02-1059,0,0.0606955,"Missing"
J09-4002,1997.iwpt-1.16,0,0.101538,"y of Manchester, UK Hozumi Tanaka—or Tanaka-sensei as he was fondly known to his colleagues and students in Japanese—passed away at the age of 67 in the early morning of 27 July 2009. He is survived by his wife Reiko and two sons. Tanaka-sensei’s primary contributions to natural language processing (NLP) are in parsing and semantic analysis. In parsing, he extended the GLR parsing algorithm to incorporate probabilities, multiple connection tables, and simultaneously carry out morphological and syntactic analysis for non-segmenting languages such as Japanese (Tanaka, Tokunaga, and Aizawa 1993; Inui et al. 1997; Shirai et al. 2000). His research on semantic analysis covered a broad spectrum, encompassing word sense disambiguation (Fujii et al. 1998), spoken language understanding for virtual agent systems (Shinyama, Tokunaga, and Tanaka 2000), lexical semantic approaches to query expansion in information retrieval (Mandala, Tokunaga, and Tanaka 2000), and metaphor processing (Iwayama, Tokunaga, and Tanaka 1990). He also carried out research on machine translation (Tanaka, Isahara, and Yasuhara 1983; Tanaka 1999b; Baldwin and Tanaka 2000), computer-assisted language learning (Bilac, Baldwin, and Tana"
J09-4002,1999.mtsummit-1.1,0,0.0366081,"is for non-segmenting languages such as Japanese (Tanaka, Tokunaga, and Aizawa 1993; Inui et al. 1997; Shirai et al. 2000). His research on semantic analysis covered a broad spectrum, encompassing word sense disambiguation (Fujii et al. 1998), spoken language understanding for virtual agent systems (Shinyama, Tokunaga, and Tanaka 2000), lexical semantic approaches to query expansion in information retrieval (Mandala, Tokunaga, and Tanaka 2000), and metaphor processing (Iwayama, Tokunaga, and Tanaka 1990). He also carried out research on machine translation (Tanaka, Isahara, and Yasuhara 1983; Tanaka 1999b; Baldwin and Tanaka 2000), computer-assisted language learning (Bilac, Baldwin, and Tanaka 2002), speech recognition (Itou, Hayamizu, and Tanaka 1992; Li, Tanaka, and Tokunaga 1995), dialogue systems (Akiba and Tanaka 1994; Funakoshi, Tokunaga, and Tanaka 2002), and automatic music generation (Suzuki, Tokunaga, and Tanaka 1999). He was the author or editor of a number of popular introductory texts on NLP in Japanese (Tanaka 1989, 1999a). Tanaka-sensei was the technical lead on the Japanese government-funded CICC Machine Translation Project (1987–1995) between East and South-East Asian langua"
J09-4002,1993.iwpt-1.10,0,0.393005,"Missing"
J11-1014,P09-1010,0,0.0204518,"implementing. 2. Problems with Reviewing 2.1 The Lack of Qualiﬁed Reviewers In an earlier Last Words piece, Ken Church (Church 2006) pointed out how the ACL conference reviewing process can be derailed by the lack of positive endorsement by reviewers who are not well qualiﬁed to review a given paper. He went on to suggest that papers rejected by NAACL are “often strong contenders for the best-paper award at ACL.” An instance of this phenomenon was observed in 2009, when a paper rejected from NAACL 2009 with an average acceptance score of 2.3 out of 5 was given a best paper award at ACL 2009 (Branavan et al. 2009).1 It is especially hard to ﬁnd qualiﬁed reviewers these days partly because computational linguistics has become increasingly specialized. Papers in ﬁelds like parsing and machine translation involve very technical modiﬁcations to a few current models. Reviewers for such areas need to be ‘insiders’, well-versed in the latest developments in the sub-area. This need is likely to become more pronounced as the specialization trend continues. Reviewers are currently selected based on informal social networks. Unfortunately, most researchers do not have an extensive set of names of reviewers at han"
J96-2007,P90-1017,0,0.0208832,"the stimulus perceived (e.g., hear a bark). It will be interesting to see what sorts of cross-linguistic generalizations will emerge from such distinctions and the corpora in use (which, by the way, aren't identified, except for a footnote reference to an 18-million-word corpus used by Oxford University Press). Their project expects to eventually link the different monolingual lexicons in this vocabulary domain. With regard to structuring these multilingual lexicons, Heid discusses the potential relevance of classifications of lexical differences in terms of divergences and mismatches (e.g., Dorr 1990, Barnett, Mani, and Rich 1994); the corpora to which these lexicons are to be linked could provide useful data for testing these and other classifications. Overall, despite the fine introduction and several interesting papers, the book offers an uneven mix. While a high-level project report or system overview may work well in the ambiance of a workshop setting, it becomes less attractive in the pages of a book. I think the book will be of interest primarily to readers seeking an overview of some of the issues of lexicon data management and reuse that various groups in Europe are addressing th"
mani-etal-2008-spatialml,H05-1046,1,\N,Missing
mani-etal-2008-spatialml,P07-1033,0,\N,Missing
N03-2019,W01-1313,0,0.561711,"Missing"
N03-2019,P00-1010,1,0.657087,"Missing"
P00-1010,A97-1007,0,0.0617476,"Missing"
P00-1010,A97-1006,0,0.0556389,"Missing"
P00-1010,J88-2003,0,0.55515,"Missing"
P00-1010,J88-2005,0,0.625901,"Missing"
P00-1010,setzer-gaizauskas-2000-annotating,0,0.158075,"Missing"
P00-1010,J88-2006,0,\N,Missing
P00-1010,W97-0320,0,\N,Missing
P01-1059,M95-1012,0,0.00890777,"tives, 2 groups: chairman, impeachment prosecutor. Victor Polay is the Tupac Amaru rebels&apos; top leader, founder and the organization&apos;s commander-and-chief. He was arrested again in 1992 and is serving a life sentence. His associates include Alberto Fujimori, Tupac Amaru Revolutionary, and Nestor Cerpa. 73 docs, 38,000 words, 24 Polay sentences, 10 extracted appositives, 3 groups: leader, founder and commander-in-chief. 2 Producing biographical descriptions 2.1 Preprocessing Each document in the collection to be summarized is processed by a sentence tokenizer, the Alembic part-of-speech tagger (Aberdeen et al. 1995), the Nametag named entity tagger (Krupka 1995) restricted to people names, and the CASS parser (Abney 1996). The tagged sentences are further analyzed by a cascade of finite state machines leveraging patterns with lexical and syntactic information, to identify constructions such as pre- and postmodifying appositive phrases, e.g., “Presidential candidate George Bush”, “Bush, the presidential candidate”, and relative clauses, e.g., “Senator ..., who is running for re-election this Fall,”. These appositive phrases and relative clauses capture descriptive information which can correspond variousl"
P01-1059,J90-1003,0,0.0687559,"Missing"
P01-1059,M95-1018,0,0.0239604,"r Polay is the Tupac Amaru rebels&apos; top leader, founder and the organization&apos;s commander-and-chief. He was arrested again in 1992 and is serving a life sentence. His associates include Alberto Fujimori, Tupac Amaru Revolutionary, and Nestor Cerpa. 73 docs, 38,000 words, 24 Polay sentences, 10 extracted appositives, 3 groups: leader, founder and commander-in-chief. 2 Producing biographical descriptions 2.1 Preprocessing Each document in the collection to be summarized is processed by a sentence tokenizer, the Alembic part-of-speech tagger (Aberdeen et al. 1995), the Nametag named entity tagger (Krupka 1995) restricted to people names, and the CASS parser (Abney 1996). The tagged sentences are further analyzed by a cascade of finite state machines leveraging patterns with lexical and syntactic information, to identify constructions such as pre- and postmodifying appositive phrases, e.g., “Presidential candidate George Bush”, “Bush, the presidential candidate”, and relative clauses, e.g., “Senator ..., who is running for re-election this Fall,”. These appositive phrases and relative clauses capture descriptive information which can correspond variously to a person’s age, occupation, or some role a"
P01-1059,P99-1005,0,0.0109801,"t vectors correctly classified). Tool Barry’s Rules MC4 Decision Tree C4.5Rules Ripper Naive Bayes Majority Class (coherent) Accuracy .69 .69 .67 .62 .62 .60 Table 2. Accuracy of Different Description Learners on Clinton corpus The best learning methods are comparable with rules created by hand by one of the authors (Barry’s rules). In the learners, the bestverb feature is used heavily in tests for the negative class, whereas in Barry’s Rules it occurs in tests for the positive class. 6 Related Work Our work on measuring subject-verb associations has a different focus from the previous work. (Lee and Pereira 1999), for example, examined verb-object pairs. Their focus was on a method that would improve techniques for gathering statistics where there are a multitude of sparse examples. We are focusing on the use of the verbs for the specific purpose of finding associations that we have previously observed to be strong, with a view towards selecting a clause or sentence, rather than just to measure similarity. We also try to strengthen the numbers by dealing with ‘gapped’ constructions. While there has been plenty of work on extracting named entities and relations between them, e.g., (MUC-7 1998), the mai"
P01-1059,J98-3005,0,0.0401471,"thod that would improve techniques for gathering statistics where there are a multitude of sparse examples. We are focusing on the use of the verbs for the specific purpose of finding associations that we have previously observed to be strong, with a view towards selecting a clause or sentence, rather than just to measure similarity. We also try to strengthen the numbers by dealing with ‘gapped’ constructions. While there has been plenty of work on extracting named entities and relations between them, e.g., (MUC-7 1998), the main previous body of work on biographical summarization is that of (Radev and McKeown 1998). The fundamental differences in our work are as follows: (1) We extract not only appositive phrases, but also clauses at large based on corpus statistics; (2) We make heavy use of coreference, whereas they don’t use coreference at all; (3) We focus on generating succinct descriptions by removing redundancy and merging, whereas they categorize descriptions using WordNet, without a focus on succinctness. 7 Conclusion This research has described and evaluated techniques for producing a novel kind of summary called biographical summaries. The techniques use syntactic analysis and semantic type-ch"
P01-1059,W00-0401,0,0.0125996,"ople in the Reuters corpus (negative log scores). 4 4.1 Evaluation Overview Methods for evaluating text summarization can be broadly classified into two categories (Sparck-Jones and Galliers 1996). The first, an extrinsic evaluation, tests the summarization based on how it affects the completion of some other task, such as comprehension, e.g., (Morris et al. 1992), or relevance assessment (Brandow et al. 1995) (Jing et al. 1998) (Tombros and Sanderson 1998) (Mani et al. 1998). An intrinsic evaluation, on the other hand, can involve assessing the coherence of the summary (Brandow et al. 1995) (Saggion and Lapalme 2000). Another intrinsic approach involves assessing the informativeness of the summary, based on to what extent key information from the source is preserved in the system summary at different levels of compression (Paice and Jones 1993), (Brandow et al. 1995). Informativeness can also be assessed in terms of how much information in an ideal (or ‘reference’) summary is preserved in the system summary, where the summaries being compared are at similar levels of compression (Edmundson 1969). We have carried out a number of intrinsic evaluations of the accuracy of components involved in the summarizat"
P05-3021,W97-0810,0,0.041464,"Missing"
P05-3021,W01-1315,0,0.0329764,"(Sang and D´ej´ean, 2001); they are currently being implemented as sequences of finite-state transducers along the lines of (A¨ıtMokhtar and Chanod, 1997). Evaluation results are not yet available. 6 SputLink SputLink is a temporal closure component that takes known temporal relations in a text and derives new 83 implied relations from them, in effect making explicit what was implicit. A temporal closure component helps to find those global links that are not necessarily derived by other means. SputLink is based on James Allen’s interval algebra (1983) and was inspired by (Setzer, 2001) and (Katz and Arosio, 2001) who both added a closure component to an annotation environment. Allen reduces all events and time expressions to intervals and identifies 13 basic relations between the intervals. The temporal information in a document is represented as a graph where events and time expressions form the nodes and temporal relations label the edges. The SputLink algorithm, like Allen’s, is basically a constraint propagation algorithm that uses a transitivity table to model the compositional behavior of all pairs of relations. For example, if A precedes B and B precedes C, then we can compose the two relations"
P05-3021,N03-2019,1,0.852311,"each event. For example, a past tense non-stative verb followed by a past perfect non-stative verb, with grammatical aspect maintained, suggests that the second event precedes the first. GUTenLINK uses default rules for ordering events; its handling of successive past tense nonstative verbs in case (iii) will not correctly order sequences like Max fell. John pushed him. GUTenLINK is intended as one component in a larger machine-learning based framework for ordering events. Another component which will be developed will leverage document-level inference, as in the machine learning approach of (Mani et al., 2003), which required annotation of a reference time (Reichenbach, 1947; Kamp and Reyle, 1993) for the event in each finite clause. 1 TimeBank is a 200-document news corpus manually annotated with TimeML tags. It contains about 8000 events, 2100 time expressions, 5700 TLINKs and 2600 SLINKs. See (Day et al., 2003) and www.timeml.org for more details. An early version of GUTenLINK was scored at .75 precision on 10 documents. More formal Precision and Recall scoring is underway, but it compares favorably with an earlier approach developed at Georgetown. That approach converted eventevent TLINKs from"
P05-3021,W01-0708,0,0.0278935,"Missing"
P05-3021,P00-1010,1,\N,Missing
P06-1095,P92-1030,0,0.0591899,"of rules derived from human intuitions. 1 Introduction The growing interest in practical NLP applications such as question-answering and text summarization places increasing demands on the processing of temporal information. In multidocument summarization of news articles, it can be useful to know the relative order of events so as to merge and present information from multiple news sources correctly. In questionanswering, one would like to be able to ask when an event occurs, or what events occurred prior to a particular event. A wealth of prior research by (Passoneau 1988), (Webber 1988), (Hwang and Schubert 1992), (Kamp and Reyle 1993), (Lascarides and Asher 1993), (Hitzeman et al. 1995), (Kehler 2000) and others, has explored the different knowledge sources used in inferring the temporal ordering of events, including temporal adverbials, tense, aspect, rhetorical relations, pragmatic conventions, and background knowledge. For example, the narrative convention of events being described in the order in which they occur is followed in (1), but overridden by means of a discourse relation, Explanation in (2). (1) Max stood up. John greeted him. (2) Max fell. John pushed him. In addition to discourse relat"
P06-1095,N04-1020,0,0.0106106,"Missing"
P06-1095,P04-1074,0,0.124056,"Missing"
P06-1095,N03-2019,1,0.411076,"Missing"
P06-1095,P00-1010,1,0.81515,"Missing"
P06-1095,J88-2005,0,0.0930769,"Missing"
P06-1095,H05-1088,1,0.378139,"Missing"
P06-1095,setzer-gaizauskas-2000-annotating,0,0.0424773,"54 33.33 25.00 84.29 66.37 60.86 82.54 94.20 38.60 88.23 97.26 68.29 83.87 90.90 47.72 89.30 96.09 Event-Time 88.25 (62.3) Prec Rec F 0 0 0 76.47 79.31 73.68 86.07 90.16 74.28 77.97 56.00 80.78 93.56 75.36 78.62 63.63 83.34 91.83 Table 2. Machine learning results using unclosed and closed data 3.2 Expanding Training Data using Temporal Reasoning To expand our training set, we use a temporal closure component SputLink (Verhagen 2004), that takes known temporal relations in a text and derives new implied relations from them, in effect making explicit what was implicit. SputLink was inspired by (Setzer and Gaizauskas 2000) and is based on Allen’s interval algebra, taking into account the limitations on that algebra that were pointed out by (Vilain et al. 1990). It is basically a constraint propagation algorithm that uses a transitivity table to model the compositional behavior of all pairs of relations in a document. SputLink’s transitivity table is represented by 745 axioms. An example axiom: If relation(A, B) = BEFORE && relation(B, C) = INCLUDES then infer relation(A, C) = BEFORE Once the TLINKs in each document in the corpus are closed using SputLink, the same vector generation procedure and feature represe"
P06-1095,E06-1049,0,\N,Missing
P06-1095,J88-2006,0,\N,Missing
P06-1095,E95-1035,0,\N,Missing
P06-1095,W04-3205,0,\N,Missing
P06-1095,W01-1309,0,\N,Missing
P99-1072,M95-1018,0,0.0147199,"Missing"
P99-1072,W97-0713,0,0.220371,"Missing"
P99-1072,E99-1011,1,0.777178,"Missing"
verhagen-etal-2006-annotation,A97-1051,0,\N,Missing
verhagen-etal-2006-annotation,P05-3021,1,\N,Missing
W00-0410,P99-1072,1,0.88805,"Missing"
W00-0410,P98-2151,0,0.0676292,"Missing"
W00-0410,P98-2173,0,0.0740712,"Missing"
W00-0410,E99-1011,1,\N,Missing
W00-0410,C98-2168,0,\N,Missing
W00-0410,C98-2146,0,\N,Missing
W01-1312,A97-1007,0,0.0112722,"than from cultural and world knowledge. <TIMEX2 VAL=""2001-W12""&gt;la semana pasada</TIMEX2&gt; <TIMEX2 VAL=""2001-W12""&gt;last week</TIMEX2&gt; 6 Related Work Our scheme differs from the recent scheme of (Setzer and Gaizauskas 2000) in terms of our indepth focus on representations for the values of specific classes of time expressions, and in the application of our scheme to a variety of different genres, including print news, broadcast news, and meeting scheduling dialogs. Others have used temporal annotation schemes for the much more constrained domain of meeting scheduling, e.g., (Wiebe et al. 1998), (Alexandersson et al. 1997), (Busemann et al. 1997). Our scheme has been applied to such domains as well, our annotation of the Enthusiast corpus being an example. 7 Conclusion In the future, we hope to extend our English annotation guidelines into a set of multilingual annotation guidelines, which would include language-specific supplements specifying examples, tokenization rules, and rules for determining tag extents. To support development of such guidelines, we expect to develop large keyword-in-context concordances, and would like to use the time-tagger system as a tool in that effort. Our approach would be (1) to"
W01-1312,A97-1006,0,0.0133071,"knowledge. <TIMEX2 VAL=""2001-W12""&gt;la semana pasada</TIMEX2&gt; <TIMEX2 VAL=""2001-W12""&gt;last week</TIMEX2&gt; 6 Related Work Our scheme differs from the recent scheme of (Setzer and Gaizauskas 2000) in terms of our indepth focus on representations for the values of specific classes of time expressions, and in the application of our scheme to a variety of different genres, including print news, broadcast news, and meeting scheduling dialogs. Others have used temporal annotation schemes for the much more constrained domain of meeting scheduling, e.g., (Wiebe et al. 1998), (Alexandersson et al. 1997), (Busemann et al. 1997). Our scheme has been applied to such domains as well, our annotation of the Enthusiast corpus being an example. 7 Conclusion In the future, we hope to extend our English annotation guidelines into a set of multilingual annotation guidelines, which would include language-specific supplements specifying examples, tokenization rules, and rules for determining tag extents. To support development of such guidelines, we expect to develop large keyword-in-context concordances, and would like to use the time-tagger system as a tool in that effort. Our approach would be (1) to run the tagger over the"
W01-1312,H93-1040,0,0.0413232,"Missing"
W01-1312,P00-1010,1,0.816717,"detail in (Ferro et al. 2000), has several novel features, including the following: It goes well beyond the one used in the Message Understanding Conference (MUC7 1998), not only in terms of the range of expressions that are flagged, but, also, more importantly, in terms of representing and normalizing the time values that are communicated by the expressions. In addition to handling fully-specified time expressions (e.g., September 3rd, 1997), it also handles context-dependent expressions. This is significant because of the ubiquity of contextdependent time expressions; a recent corpus study (Mani and Wilson 2000) revealed that more than two-thirds of time expressions in print and broadcast news were context-dependent ones. The context can be local (within the same sentence), e.g., In 1995, the months of June and July were devilishly hot, or global (outside the sentence), e.g., The hostages were beheaded that afternoon. A subclass of these contextdependent expressions are ‘indexical’ expressions, which require knowing when the speaker is speaking to determine the intended time value, e.g., now, today, yesterday, tomorrow, next Tuesday, two weeks ago, etc. This work has been funded by DARPA’s Translingu"
W01-1312,setzer-gaizauskas-2000-annotating,0,\N,Missing
W04-0208,W01-1605,0,0.0899404,"Missing"
W04-0208,J95-2003,0,0.133007,"can see that even for interpreting such relatively simple discourses, a system might require a variety of sources of linguistic knowledge, including knowledge of tense, aspect, temporal adverbials, discourse relations, as well as background knowledge. Of course, other inferences are clearly possible, e.g., that the running stopped after the twisting, but when viewed as defaults, these latter inferences seem to be more easily violated. The need for commonsense inferences has motivated computational approaches that are domainspecific, using hand-coded knowledge (e.g., Asher and Lascarides 2003, Hitzeman et al. 1995). A number of theories have postulated the existence of various discourse relations that relate elements in the text to produce a global model of discourse, e.g., (Mann and Thompson 1988), (Hobbs 1985), (Hovy 1990) and others. In RST (Mann and Thompson 1988), (Marcu 2000), these relations are ultimately between semantic elements corresponding to discourse units that can be simple sentences or clauses as well as entire discourses. In SDRT (Asher and Lascarides 2003), these relations are between representations of propositional content, called Discourse Representation Structures (Kamp and Reyle,"
W04-0208,W90-0117,0,0.033397,"l as background knowledge. Of course, other inferences are clearly possible, e.g., that the running stopped after the twisting, but when viewed as defaults, these latter inferences seem to be more easily violated. The need for commonsense inferences has motivated computational approaches that are domainspecific, using hand-coded knowledge (e.g., Asher and Lascarides 2003, Hitzeman et al. 1995). A number of theories have postulated the existence of various discourse relations that relate elements in the text to produce a global model of discourse, e.g., (Mann and Thompson 1988), (Hobbs 1985), (Hovy 1990) and others. In RST (Mann and Thompson 1988), (Marcu 2000), these relations are ultimately between semantic elements corresponding to discourse units that can be simple sentences or clauses as well as entire discourses. In SDRT (Asher and Lascarides 2003), these relations are between representations of propositional content, called Discourse Representation Structures (Kamp and Reyle, 1993). Despite a considerable amount of very productive research, annotating such discourse relations has proved problematic. This is due to the fact that discourse markers may be absent (i.e., implicit) or ambigu"
W04-0208,kingsbury-palmer-2002-treebank,0,0.0616809,"elations in TDMs involve temporal inclusion and temporal ordering, the mentioned events can naturally be mapped to other discourse representations used in computational linguistics. A TDM tree can be converted to a first-order temporal logic representation (where temporal ordering and inclusion operators are added) by expanding the properties of the nodes. These properties include any additional predications made explicitly about the event, e.g., information from thematic arguments and adjuncts. In other words, a full predicate argument representation, e.g., as might be found in the PropBank (Kingsbury and Palmer 2002), can be associated with each node. TDMs can also be mapped to Discourse Representation Structures (DRS) (which in turn can be mapped to a logical form). Since TDMs represent events as pairs of time points (which can be viewed as intervals), and DRT represents events as primitives, we can reintroduce time intervals based on the standard DRT approach (e ⊆ t for events, e O t for states, except for present tense states, where t ⊆ e). Consider an example from the Discourse Representation Theory (DRT) literature (from Kamp and Reyle 1993): (3) a. A man entered the White Hart. b. He was wearing a b"
W04-0208,N03-2019,1,0.824933,"se, time expressions are flagged, and their values normalized, so that Thursday in He left on Thursday would get a resolved ISO time value depending on context (TIMEX2 2004). Finally, temporal relations between events and time expressions (e.g., that the leaving occurs during Thursday) are recorded by means of temporal links (TLINKs) that express Allen-style interval relations (Allen 1984). Several automatic tools have been developed in conjunction with TimeML, including event taggers (Pustejovsky et al. 2003), time expression taggers (Mani and Wilson 2000), and an exploratory link extractor (Mani et al. 2003). Temporal reasoning algorithms have also been developed, that apply transitivity axioms to expand the links using temporal closure algorithms (Setzer and Gaizauskas 2001), (Pustejovsky et al. 2003). However, TimeML is inadequate as a temporal model of discourse: it constructs no global representation of the narrative structure, instead annotating a complex graph that links primitive events and times. 4 Related Frameworks Since the relations in TDMs involve temporal inclusion and temporal ordering, the mentioned events can naturally be mapped to other discourse representations used in computat"
W04-0208,W99-0307,0,0.0257067,"rresponding to discourse units that can be simple sentences or clauses as well as entire discourses. In SDRT (Asher and Lascarides 2003), these relations are between representations of propositional content, called Discourse Representation Structures (Kamp and Reyle, 1993). Despite a considerable amount of very productive research, annotating such discourse relations has proved problematic. This is due to the fact that discourse markers may be absent (i.e., implicit) or ambiguous; but more importantly, because in many cases the precise nature of these discourse relations is unclear. Although (Marcu et al. 1999) (Carlson et al. 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion. While we appreciate the importance of representing rhetorical relations in order to carry out temporal inferences about event ordering, we believe that there are substantial advantages in isolating the temporal aspects and modeling them separately as TDMs. This greatly simplifies the representation, which we discuss next. 2 Temporal Discourse Models A TDM is a tree-struc"
W04-0208,W01-1311,0,0.0679626,"ime points. So, E0 is an abstract node representing a top-level story, and E1 is an abstract node representing an embedded story. Note that the mentioned events are ordered left to right in text order for notational convenience, but no temporal ordering is directly represented in the tree. Since the nodes in this representation are at a semantic level, the tree structure is not necessarily isomorphic to a representation at the text level, although T1 happens to be isomorphic. Ee Ec Ed C2 = {Ea < Ee, Eb < Ec} Note that the partial ordering C can be extended using T and temporal closure axioms (Setzer and Gaizauskas 2001), (Verhagen 2004), so that in the case of <T2, C2>, we can infer, for example, that Eb < Ed, Ed < Ee, and so forth. In representing states, we take a conservative approach to the problems of ramification and change (McCarthy and Hayes 1969). This is the classic problem of recognizing when states (the effects of actions) change as a result of actions. Any tensed stative predicate will be represented as a node in the tree (progressives are here treated as stative). Consider an example like John walked home. He was feeling great. Here we represent the state of feeling great as being minimally a p"
W04-0208,P00-1010,1,\N,Missing
W04-0208,J03-4002,0,\N,Missing
W04-0208,J88-2006,0,\N,Missing
W04-0208,E95-1035,0,\N,Missing
W04-1806,P99-1016,0,0.127089,"CBS has run is the ProMed corpus where, considering each paragraph a distinct context, there were 117,690 contexts in the 11,198 documents. Here is an example from ProMed of a transitive relation that spans three tiers: ‘mosquito’ is a hypernym of ‘mosquito pool’, and ‘mosquito’ is also a hypernym of ‘standing water’. 50 CompuTerm 2004 - 3rd International Workshop on Computational Terminology 2.3.4 Explicit Patterns Relations This knowledge source infers specific relations between terms based on characteristic cue-phrases which relate them. For example, the cue-phrase “such as” (Hearst 1992) (Caraballo 1999) suggest a kind-of relation, e.g., ‘a ligand such as triethylphosphine’ tells us that ‘triethylphosphene’ is a kind of ‘ligand’. Likewise, in the TREC domain, ‘air toxics such as benzene’ can suggest that ‘benzene’ is a kind of ‘air toxic’. However, since such cue-phrase patterns tend to be sparse in occurrence, we do not use them in the evaluations described below. 2.3.5 Domain-Specific Knowledge Sources Although our approach is domain-independent, it is possible to factor in domain knowledge sources for a given domain. For example, in biology, ‘ase’ is usually a suffix indicating an enzyme."
W04-1806,J93-1003,0,0.0867052,"ccurs significantly more in a domain corpus than in a more diffuse background corpus, then the term is clearly domain relevant. As an illustration, in Table 1 we compare the number of documents containing the term ‘income tax’ (or ‘income taxes’) in a long (2.18 Mb) IRS publication, Publication 17, from an IRS web site (IRS 2001) compared to a larger (27.63 Mb subset of the) Reuters 21578 news corpus 7 . One would expect that ‘income tax’ is much more a characteristic of the IRS publication, and this is borne out by the document frequencies in the table. We use the log likelihood ratio (LLR) (Dunning 1993) given by -2log2(Ho(p;k1,n1,k2,n2)/Ha(p1,p2;n1,k1,n2,k2)) LLR measures the extent to which a hypothesized model of the distribution of cell counts, Ha, differs from the null hypothesis, Ho (namely, that the percentage of documents containing this term is the same in both corpora). We used a binomial model for Ho and Ha8. 2.3 Relationship Discovery The main innovation in our approach is to fuse together information from multiple knowledge 7 In Publication 17, each “chapter” is a document. Table 1, p=294/19238=.015, p1=285/285=1.0, p2=9/19043=4.72, k1=285, n1=285, k2=9, n2=19043. 8From 49 source"
W04-1806,N03-1011,0,0.0590099,"Missing"
W04-1806,C92-2082,0,0.0255617,"against which CBS has run is the ProMed corpus where, considering each paragraph a distinct context, there were 117,690 contexts in the 11,198 documents. Here is an example from ProMed of a transitive relation that spans three tiers: ‘mosquito’ is a hypernym of ‘mosquito pool’, and ‘mosquito’ is also a hypernym of ‘standing water’. 50 CompuTerm 2004 - 3rd International Workshop on Computational Terminology 2.3.4 Explicit Patterns Relations This knowledge source infers specific relations between terms based on characteristic cue-phrases which relate them. For example, the cue-phrase “such as” (Hearst 1992) (Caraballo 1999) suggest a kind-of relation, e.g., ‘a ligand such as triethylphosphine’ tells us that ‘triethylphosphene’ is a kind of ‘ligand’. Likewise, in the TREC domain, ‘air toxics such as benzene’ can suggest that ‘benzene’ is a kind of ‘air toxic’. However, since such cue-phrase patterns tend to be sparse in occurrence, we do not use them in the evaluations described below. 2.3.5 Domain-Specific Knowledge Sources Although our approach is domain-independent, it is possible to factor in domain knowledge sources for a given domain. For example, in biology, ‘ase’ is usually a suffix indic"
W04-1806,W99-0510,0,0.0145543,"18 False Negatives), and 10 decisions involving WordNet (with 12 True Positives). This shows that there is solid agreement between the human subjects and the system on the kind-of relations. However, these 154 decisions involved only four newspaper articles, so clearly more data would be helpful. 3.3 Automatic Evaluation While evaluation by humans is valuable, it is expensive to carry out, and this expense must be incurred each time one wants to do an evaluation. Automatic comparison of a machine-generated ontology against reference ontologies constructed by humans, e.g., (Zhang et al. 1996) (Sekine et al. 1999) (Daude et al. 2001), is therefore desirable, provided suitable reference ontologies are available. In this evaluation, the human-generated taxonomy for ProMed described in Section 3.2.1 was used as a reference ontology, with its unlabeled parent-child relation treated as a kind-of link. However, the human ‘ontology’ was created without looking at a corpus, and was developed for use with a different set of goals in mind. Although this involves comparing ‘apples’ and ‘oranges’, a comparison is nevertheless illustrative, and can in 9 The chi-square for Subphrase Relations is 61.68, and the chi-s"
W06-0904,P06-1095,1,0.694629,"etric temporal constraints for events. The work is carried out in the context of the TimeML framework for marking up events and their temporal relations. This pilot study examines the feasibility of acquisition of metric temporal constraints from corpora. 1 (1) Max stood up. John greeted him. (2) Max fell. John pushed him. While there has been a spurt of recent research addressing the event ordering problem, e.g., (Mani and Wilson 2000) (Filatova and Hovy 2001) (Schilder and Habel 2001) (Li et al. 2001) (Mani et al. 2003) (Li et al. 2004) (Lapata and Lascarides 2004) (Boguraev and Ando 2005) (Mani et al. 2006), that research relies on qualitative temporal relations. Qualitative relations (e.g., event A BEFORE event B, or event A DURING time T) are certainly of interest in developing timelines of events in news and other genres. However, metric constraints can also be potentially useful in this ordering problem. For example, in (3), it can be crucial to know whether the bomb landed a few minutes to hours or several years BEFORE the hospitalization. While humans have strong intuitions about this from commonsense knowledge, machines don’t. Introduction The growing interest in practical NLP application"
W06-0904,J88-2005,0,0.205297,"Missing"
W06-0904,P06-1050,0,0.0396327,"Missing"
W06-0904,H05-1088,0,0.0263669,"Missing"
W06-0904,P92-1030,0,0.017844,"rom commonsense knowledge, machines don’t. Introduction The growing interest in practical NLP applications such as question-answering and text summarization places increasing demands on the processing of temporal information. In multidocument summarization of news articles, it can be useful to know the relative order of events so as to merge and present information from multiple news sources correctly. In questionanswering, one would like to be able to ask when an event occurs, or what events occurred prior to a particular event. A wealth of prior research by (Passoneau 1988), (Webber 1988), (Hwang and Schubert 1992), (Kamp and Reyle 1993), (Lascarides and Asher 1993), (Hitzeman et al. 1995), (Kehler 2000) and others, has explored the different knowledge sources used in inferring the temporal ordering of events, including temporal adverbials, tense, aspect, rhetorical relations, pragmatic conventions, and background knowledge. For example, the narrative convention of events being described in the order in which they (3) An elderly Catholic man was hospitalized from cuts after a Protestant gasoline bomb landed in his back yard. Fortunately, there are numerous instances such as (4), where metric constraints"
W06-0904,setzer-gaizauskas-2000-annotating,0,0.0225459,"t z=&lt;z1, z2> be the time of Tuesday, where z1 = 19980108T00, and z2 = 19980108T23:59. Since we are given the qualitative relation y IS_INCLUDED z, the metric constraints (z1-y1) &lt; 0 and (y2-z2) &lt; 0 can be asserted. 3.3 Translation We now turn to the general problem of checking consistency. The set of TLINKs for a document constitutes a graph, where the nodes are events or times, and the edges are TLINKs. Given such a TimeML-derived graph for a document, a temporal closure algorithm (Verhagen 2005) carries out a transitive closure of the graph. The transitive closure algorithm was inspired by (Setzer and Gaizauskas 2000) and is based on Allen’s interval algebra, taking into account the limitations on that algebra that were pointed out by (Vilain et al. 1990). It is basically a constraint propagation algorithm that uses a transitivity table to model the compositional behavior of all pairs of relations in a document. The algorithm’s transitivity table is represented by 745 axioms. An example axiom is shown in (8): Introduction The first step is to translate a TimeML representation with qualitative relations into one where metric constraints are added. This translation needs to produce a consistent metric repres"
W06-0904,P05-3021,1,0.816933,"nnotated OTC. From these, we restricted ourselves to those where the times involved were of type TIMEX3 DURATION. We augmented the TimeBank data with information from the raw (un-annotated) British National Corpus. We tried a variety of search patterns to try and elicit durations, finally converging on the single pattern “lasted”. There were 1325 hits for this query in the BNC. (The public web interface to the BNC only shows 50 random results at a time, so we had to iterate.) The retrieved hits (sentences and fragments of sentences) were then processed with components from the TARSQI toolkit (Verhagen et al. 2005) to provide automatic TimeML annotations. The TLINKs between events and times that were Number of Events The resulting dataset had 255 distinct events with the number of durations for the events as shown in the frequency distribution in Table 1. The granularities found in news corpora such as OTC and mixed corpora such as BNC are domi26 Interestingly, 67 events in the data correspond to ‘achievement’ verbs, whose main characteristic is that they can have a near-instantaneous duration (though of course they can be iterated or extended to have other durations). We obtained a list of achievement"
W06-0904,N04-1020,0,0.0124714,"t. This paper describes the first steps in acquiring metric temporal constraints for events. The work is carried out in the context of the TimeML framework for marking up events and their temporal relations. This pilot study examines the feasibility of acquisition of metric temporal constraints from corpora. 1 (1) Max stood up. John greeted him. (2) Max fell. John pushed him. While there has been a spurt of recent research addressing the event ordering problem, e.g., (Mani and Wilson 2000) (Filatova and Hovy 2001) (Schilder and Habel 2001) (Li et al. 2001) (Mani et al. 2003) (Li et al. 2004) (Lapata and Lascarides 2004) (Boguraev and Ando 2005) (Mani et al. 2006), that research relies on qualitative temporal relations. Qualitative relations (e.g., event A BEFORE event B, or event A DURING time T) are certainly of interest in developing timelines of events in news and other genres. However, metric constraints can also be potentially useful in this ordering problem. For example, in (3), it can be crucial to know whether the bomb landed a few minutes to hours or several years BEFORE the hospitalization. While humans have strong intuitions about this from commonsense knowledge, machines don’t. Introduction The g"
W06-0904,P04-1074,0,0.0135518,"w long events last. This paper describes the first steps in acquiring metric temporal constraints for events. The work is carried out in the context of the TimeML framework for marking up events and their temporal relations. This pilot study examines the feasibility of acquisition of metric temporal constraints from corpora. 1 (1) Max stood up. John greeted him. (2) Max fell. John pushed him. While there has been a spurt of recent research addressing the event ordering problem, e.g., (Mani and Wilson 2000) (Filatova and Hovy 2001) (Schilder and Habel 2001) (Li et al. 2001) (Mani et al. 2003) (Li et al. 2004) (Lapata and Lascarides 2004) (Boguraev and Ando 2005) (Mani et al. 2006), that research relies on qualitative temporal relations. Qualitative relations (e.g., event A BEFORE event B, or event A DURING time T) are certainly of interest in developing timelines of events in news and other genres. However, metric constraints can also be potentially useful in this ordering problem. For example, in (3), it can be crucial to know whether the bomb landed a few minutes to hours or several years BEFORE the hospitalization. While humans have strong intuitions about this from commonsense knowledge, machi"
W06-0904,P00-1010,1,0.792137,"tative relations can be usefully supplemented with information about metric constraints, specifically as to how long events last. This paper describes the first steps in acquiring metric temporal constraints for events. The work is carried out in the context of the TimeML framework for marking up events and their temporal relations. This pilot study examines the feasibility of acquisition of metric temporal constraints from corpora. 1 (1) Max stood up. John greeted him. (2) Max fell. John pushed him. While there has been a spurt of recent research addressing the event ordering problem, e.g., (Mani and Wilson 2000) (Filatova and Hovy 2001) (Schilder and Habel 2001) (Li et al. 2001) (Mani et al. 2003) (Li et al. 2004) (Lapata and Lascarides 2004) (Boguraev and Ando 2005) (Mani et al. 2006), that research relies on qualitative temporal relations. Qualitative relations (e.g., event A BEFORE event B, or event A DURING time T) are certainly of interest in developing timelines of events in news and other genres. However, metric constraints can also be potentially useful in this ordering problem. For example, in (3), it can be crucial to know whether the bomb landed a few minutes to hours or several years BEFO"
W06-0904,N03-2019,1,0.849907,"ecifically as to how long events last. This paper describes the first steps in acquiring metric temporal constraints for events. The work is carried out in the context of the TimeML framework for marking up events and their temporal relations. This pilot study examines the feasibility of acquisition of metric temporal constraints from corpora. 1 (1) Max stood up. John greeted him. (2) Max fell. John pushed him. While there has been a spurt of recent research addressing the event ordering problem, e.g., (Mani and Wilson 2000) (Filatova and Hovy 2001) (Schilder and Habel 2001) (Li et al. 2001) (Mani et al. 2003) (Li et al. 2004) (Lapata and Lascarides 2004) (Boguraev and Ando 2005) (Mani et al. 2006), that research relies on qualitative temporal relations. Qualitative relations (e.g., event A BEFORE event B, or event A DURING time T) are certainly of interest in developing timelines of events in news and other genres. However, metric constraints can also be potentially useful in this ordering problem. For example, in (3), it can be crucial to know whether the bomb landed a few minutes to hours or several years BEFORE the hospitalization. While humans have strong intuitions about this from commonsense"
W06-0904,J88-2006,0,\N,Missing
W06-0904,P97-1020,0,\N,Missing
W06-0904,E95-1035,0,\N,Missing
W06-0904,W04-3205,0,\N,Missing
W06-0904,W01-1309,0,\N,Missing
W08-1402,A00-2038,0,0.0397798,"les below the threshold are also eliminated. Other criteria, including a MALINE score, could be used, but the MLEV scores seemed adequate for these preliminary experiments. Raising the threshold reduces the number of negative examples. It is highly desirable to balance the number of positive and negative examples in training, to avoid the learning being Monolingual Approach Instead of relying on rules that require extensive knowledge of differences between a language pair2, the monolingual approach first builds phonemic representations for each name, and then aligns them. Earlier research by (Kondrak 2000) used dynamic programming to align strings of phonemes, representing the phonemes as vectors of phonological features, which are associated with scores to produce similarity values. His program ALINE includes a “skip” function in the alignment operations that can be exploited for handling epenthetic segments, and in addition to 1:1 alignments, it also handles 1:2 and 2:1 alignments. In this research, we made extensive modifications to ALINE to add the phonological features for languages like Chinese and Arabic and to normalize the similarity scores, producing a system called MALINE. In Table 1"
W08-1402,P97-1017,0,0.0738807,"Missing"
W08-1402,P04-1021,0,0.0413517,"Missing"
W08-1402,W06-1630,0,0.0892374,"variant forms, including dialectical variants, (e.g., Bourguiba can map to Abu Ruqayba), orthographic conventions (e.g., Anglophone Wasim can map to Francophone Ouassime), and differences in name segmentation (Abd Al Rahman can map to Abdurrahman). Given the high degree of variation and noise in the data, approaches based on machine learning are needed. The considerable differences in possible spellings of a name also call for approaches which can compare names based on pronunciation. Recent work has developed pronunciation-based models for name comparison, e.g., (Sproat, Tao and Zhai 2006) (Tao et al. 2006). This paper explores trainable pronunciation-based models further. Introduction The problem of matching pairs of names which may have different spellings or segmentation arises in a variety of common settings, including integration or linking database records, mapping from text to structured data (e.g., phonebooks, gazetteers, and biological databases), and text to text comparison (for information retrieval, clustering, summarization, coreference, etc.). For named entity recognition, a name from a gazetteer or dictionary may be matched against text input; even within monolingual applications,"
W08-1402,N04-1036,0,\N,Missing
W08-1402,C00-1056,0,\N,Missing
W08-1402,W03-1508,0,\N,Missing
W08-1402,W02-0505,0,\N,Missing
W08-1402,W09-3533,1,\N,Missing
W08-1402,P06-1010,0,\N,Missing
W08-1402,W09-3501,0,\N,Missing
W08-1402,P98-2220,0,\N,Missing
W08-1402,C98-2215,0,\N,Missing
W08-1402,J98-4003,0,\N,Missing
W08-1402,N06-1060,1,\N,Missing
W08-1402,D07-1025,0,\N,Missing
W08-1402,W09-3504,0,\N,Missing
W90-0107,E89-1032,0,0.0809935,"Missing"
W90-0107,P87-1019,0,0.0677102,"Missing"
W90-0107,P81-1035,0,0.104224,"Missing"
W90-0107,P88-1012,0,0.0448216,"Missing"
W90-0107,C88-1054,0,0.0675298,"Missing"
W90-0107,A88-1006,0,0.0685862,"Missing"
W90-0107,P87-1028,0,0.0655989,"Missing"
W90-0107,C88-2128,0,0.0422177,"Missing"
W90-0107,P89-1002,0,0.0403732,"Missing"
W90-0107,P87-1025,0,0.0369736,"Missing"
W90-0107,P86-1015,0,0.0614772,"Missing"
W90-0107,J88-4003,0,0.0275977,"Missing"
W90-0107,T87-1042,0,\N,Missing
W91-0109,1991.mtsummit-papers.4,1,0.80617,"Missing"
W91-0109,P91-1025,0,0.170235,"Missing"
W91-0109,W91-0114,1,0.61953,"Missing"
W91-0109,E89-1032,0,0.134929,"Missing"
W91-0109,J90-1004,0,0.0806206,"Missing"
W91-0109,P90-1017,0,0.168635,"Missing"
W91-0109,1988.tmi-1.12,0,0.0828879,"Missing"
W91-0109,C90-2052,0,0.17733,"Missing"
W91-0109,1989.mtsummit-1.33,0,0.0285207,"Missing"
W91-0114,P90-1013,0,0.0633033,"Missing"
W91-0114,A88-1003,0,0.165323,"Missing"
W91-0114,P89-1002,0,0.0244469,"Missing"
W91-0114,E89-1032,0,0.241721,"Missing"
W91-0114,J87-1005,0,0.0460852,"Missing"
W91-0114,A88-1021,0,0.0330177,"Missing"
W91-0114,J81-1002,0,0.0406878,"Missing"
W93-0105,P90-1031,0,0.0690412,"Missing"
W93-0105,C69-7001,0,0.130264,"Missing"
W93-0105,J86-2003,0,0.0305432,"Missing"
W93-0105,H93-1062,0,0.108868,"Missing"
