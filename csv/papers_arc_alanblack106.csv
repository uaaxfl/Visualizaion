2021.naacl-main.297,Case Study: Deontological Ethics in {NLP},2021,-1,-1,4,1,4128,shrimai prabhumoye,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Recent work in natural language processing (NLP) has focused on ethical challenges such as understanding and mitigating bias in data and algorithms; identifying objectionable content like hate speech, stereotypes and offensive language; and building frameworks for better system design and data handling practices. However, there has been little discussion about the ethical foundations that underlie these efforts. In this work, we study one ethical theory, namely deontological ethics, from the perspective of NLP. In particular, we focus on the generalization principle and the respect for autonomy through informed consent. We provide four case studies to demonstrate how these principles can be used with NLP systems. We also recommend directions to avoid the ethical issues in these systems."
2021.naacl-main.338,Focused Attention Improves Document-Grounded Generation,2021,-1,-1,4,1,4128,shrimai prabhumoye,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Document grounded generation is the task of using the information provided in a document to improve text generation. This work focuses on two different document grounded generation tasks: Wikipedia Update Generation task and Dialogue response generation. Our work introduces two novel adaptations of large scale pre-trained encoder-decoder models focusing on building context driven representation of the document and enabling specific attention to the information in the document. Additionally, we provide a stronger BART baseline for these tasks. Our proposed techniques outperform existing methods on both automated (at least 48{\%} increase in BLEU-4 points) and human evaluation for closeness to reference and relevance to the document. Furthermore, we perform comprehensive manual inspection of the generated output and categorize errors to provide insights into future directions in modeling these tasks."
2021.findings-emnlp.373,Switch Point biased Self-Training: Re-purposing Pretrained Models for Code-Switching,2021,-1,-1,3,0,7339,parul chopra,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Code-switching (CS), a ubiquitous phenomenon due to the ease of communication it offers in multilingual communities still remains an understudied problem in language processing. The primary reasons behind this are: (1) minimal efforts in leveraging large pretrained multilingual models, and (2) the lack of annotated data. The distinguishing case of low performance of multilingual models in CS is the intra-sentence mixing of languages leading to switch points. We first benchmark two sequence labeling tasks {--} POS and NER on 4 different language pairs with a suite of pretrained models to identify the problems and select the best performing char-BERT model among them (addressing (1)). We then propose a self training method to repurpose the existing pretrained models using a switch-point bias by leveraging unannotated data (addressing (2)). We finally demonstrate that our approach performs well on both tasks by reducing the gap between the switch point performance while retaining the overall performance on two distinct language pairs in both the tasks. We plan to release our models and the code for all our experiments."
2021.findings-acl.375,Grounding {`}Grounding{'} in {NLP},2021,-1,-1,3,1,6250,khyathi chandu,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.eacl-main.259,{N}oise{QA}: Challenge Set Evaluation for User-Centric Question Answering,2021,-1,-1,6,0.833333,10888,abhilasha ravichander,Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,0,"When Question-Answering (QA) systems are deployed in the real world, users query them through a variety of interfaces, such as speaking to voice assistants, typing questions into a search engine, or even translating questions to languages supported by the QA system. While there has been significant community attention devoted to identifying correct answers in passages assuming a perfectly formed question, we show that components in the pipeline that precede an answering engine can introduce varied and considerable sources of error, and performance can degrade substantially based on these upstream noise sources even for powerful pre-trained QA models. We conclude that there is substantial room for progress before QA systems can be effectively deployed, highlight the need for QA evaluation to expand to consider real-world use, and hope that our findings will spur greater community interest in the issues that arise when our systems actually need to be of utility to humans."
2021.dravidianlangtech-1.9,Task-Specific Pre-Training and Cross Lingual Transfer for Sentiment Analysis in {D}ravidian Code-Switched Languages,2021,-1,-1,3,0,11148,akshat gupta,Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages,0,"Sentiment analysis in Code-Mixed languages has garnered a lot of attention in recent years. It is an important task for social media monitoring and has many applications, as a large chunk of social media data is Code-Mixed. In this paper, we work on the problem of sentiment analysis for Dravidian Code-Switched languages - Tamil-Engish and Malayalam-English, using three different BERT based models. We leverage task-specific pre-training and cross-lingual transfer to improve on previously reported results, with significant improvement for the Tamil-Engish dataset. We also present a multilingual sentiment classification model that has competitive performance on both Tamil-English and Malayalam-English datasets."
2021.calcs-1.13,Unsupervised Self-Training for Sentiment Analysis of Code-Switched Data,2021,-1,-1,4,0,11148,akshat gupta,Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching,0,"Sentiment analysis is an important task in understanding social media content like customer reviews, Twitter and Facebook feeds etc. In multilingual communities around the world, a large amount of social media text is characterized by the presence of Code-Switching. Thus, it has become important to build models that can handle code-switched data. However, annotated code-switched data is scarce and there is a need for unsupervised models and algorithms. We propose a general framework called Unsupervised Self-Training and show its applications for the specific use case of sentiment analysis of code-switched data. We use the power of pre-trained BERT models for initialization and fine-tune them in an unsupervised manner, only using pseudo labels produced by zero-shot transfer. We test our algorithm on multiple code-switched languages and provide a detailed analysis of the learning dynamics of the algorithm with the aim of answering the question - {`}Does our unsupervised model understand the Code-Switched languages or does it just learn its representations?{'}. Our unsupervised models compete well with their supervised counterparts, with their performance reaching within 1-7{\%} (weighted F1 scores) when compared to supervised models trained for a two class problem."
2021.calcs-1.14,{C}odemixed{NLP}: An Extensible and Open {NLP} Toolkit for Code-Mixing,2021,-1,-1,4,0,1301,sai jayanthi,Proceedings of the Fifth Workshop on Computational Approaches to Linguistic Code-Switching,0,"The NLP community has witnessed steep progress in a variety of tasks across the realms of monolingual and multilingual language processing recently. These successes, in conjunction with the proliferating mixed language interactions on social media, have boosted interest in modeling code-mixed texts. In this work, we present CodemixedNLP, an open-source library with the goals of bringing together the advances in code-mixed NLP and opening it up to a wider machine learning community. The library consists of tools to develop and benchmark versatile model architectures that are tailored for mixed texts, methods to expand training sets, techniques to quantify mixing styles, and fine-tuned state-of-the-art models for 7 tasks in Hinglish. We believe this work has the potential to foster a distributed yet collaborative and sustainable ecosystem in an otherwise dispersed space of code-mixing research. The toolkit is designed to be simple, easily extensible, and resourceful to both researchers as well as practitioners. Demo: {\textless}http://k-ikkees.pc.cs.cmu.edu:5000{\textgreater} and Library: {\textless}https://github.com/murali1996/CodemixedNLP{\textgreater}"
2021.acl-long.319,Breaking Down Walls of Text: How Can {NLP} Benefit Consumer Privacy?,2021,-1,-1,2,0.833333,10888,abhilasha ravichander,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"Privacy plays a crucial role in preserving democratic ideals and personal autonomy. The dominant legal approach to privacy in many jurisdictions is the {``}Notice and Choice{''} paradigm, where privacy policies are the primary instrument used to convey information to users. However, privacy policies are long and complex documents that are difficult for users to read and comprehend. We discuss how language technologies can play an important role in addressing this information gap, reporting on initial progress towards helping three specific categories of stakeholders take advantage of digital privacy policies: consumers, enterprises, and regulators. Our goal is to provide a roadmap for the development and use of language technologies to empower users to reclaim control over their privacy, limit privacy harms, and rally research efforts from the community towards addressing an issue with large social impact. We highlight many remaining opportunities to develop language technologies that are more precise or nuanced in the way in which they use the text of privacy policies."
2020.wnut-1.22,Detecting Entailment in Code-Mixed {H}indi-{E}nglish Conversations,2020,-1,-1,3,0,13690,sharanya chakravarthy,Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020),0,"The presence of large-scale corpora for Natural Language Inference (NLI) has spurred deep learning research in this area, though much of this research has focused solely on monolingual data. Code-mixing is the intertwined usage of multiple languages, and is commonly seen in informal conversations among polyglots. Given the rising importance of dialogue agents, it is imperative that they understand code-mixing, but the scarcity of code-mixed Natural Language Understanding (NLU) datasets has precluded research in this area. The dataset by Khanuja et. al. for detecting conversational entailment in code-mixed Hindi-English text is the first of its kind. We investigate the effectiveness of language modeling, data augmentation, translation, and architectural approaches to address the code-mixed, conversational, and low-resource aspects of this dataset. We obtain an 8.09{\%} increase in test set accuracy over the current state of the art."
2020.semeval-1.230,{LTI}at{CMU} at {S}em{E}val-2020 Task 11: Incorporating Multi-Level Features for Multi-Granular Propaganda Span Identification,2020,-1,-1,4,0,2579,sopan khosla,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"In this paper we describe our submission for the task of Propaganda Span Identification in news articles. We introduce a BERT-BiLSTM based span-level propaganda classification model that identifies which token spans within the sentence are indicative of propaganda. The {''}multi-granular{''} model incorporates linguistic knowledge at various levels of text granularity, including word, sentence and document level syntactic, semantic and pragmatic affect features, which significantly improve model performance, compared to its language-agnostic variant. To facilitate better representation learning, we also collect a corpus of 10k news articles, and use it for fine-tuning the model. The final model is a majority-voting ensemble which learns different propaganda class boundaries by leveraging different subsets of incorporated knowledge."
2020.scil-1.32,What Code-Switching Strategies are Effective in Dialog Systems?,2020,0,0,4,0,11447,emily ahn,Proceedings of the Society for Computation in Linguistics 2020,0,None
2020.lrec-1.350,A Resource for Computational Experiments on {M}apudungun,2020,-1,-1,7,0,17377,mingjun duan,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We present a resource for computational experiments on Mapudungun, a polysynthetic indigenous language spoken in Chile with upwards of 200 thousand speakers. We provide 142 hours of culturally significant conversations in the domain of medical treatment. The conversations are fully transcribed and translated into Spanish. The transcriptions also include annotations for code-switching and non-standard pronunciations. We also provide baseline results on three core NLP tasks: speech recognition, speech synthesis, and machine translation between Spanish and Mapudungun. We further explore other applications for which the corpus will be suitable, including the study of code-switching, historical orthography change, linguistic structure, and sociological and anthropological studies."
2020.lrec-1.656,{A}llo{V}era: A Multilingual Allophone Database,2020,23,0,7,0,9801,david mortensen,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We introduce a new resource, AlloVera, which provides mappings from 218 allophones to phonemes for 14 languages. Phonemes are contrastive phonological units, and allophones are their various concrete realizations, which are predictable from phonological context. While phonemic representations are language specific, phonetic representations (stated in terms of (allo)phones) are much closer to a universal (language-independent) transcription. AlloVera allows the training of speech recognition models that output phonetic transcriptions in the International Phonetic Alphabet (IPA), regardless of the input language. We show that a {``}universal{''} allophone model, Allosaurus, built with AlloVera, outperforms {``}universal{''} phonemic models and language-specific models on a speech-transcription task. We explore the implications of this technology (and related technologies) for the documentation of endangered and minority languages. We further explore other applications for which AlloVera will be suitable as it grows, including phonological typology."
2020.emnlp-main.93,Reading Between the Lines: Exploring Infilling in Visual Narratives,2020,-1,-1,3,1,6250,khyathi chandu,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Generating long form narratives such as stories and procedures from multiple modalities has been a long standing dream for artificial intelligence. In this regard, there is often crucial subtext that is derived from the surrounding contexts. The general seq2seq training methods render the models shorthanded while attempting to bridge the gap between these neighbouring contexts. In this paper, we tackle this problem by using infilling techniques involving prediction of missing steps in a narrative while generating textual descriptions from a sequence of images. We also present a new large scale visual procedure telling (ViPT) dataset with a total of 46,200 procedures and around 340k pairwise images and textual descriptions that is rich in such contextual dependencies. Generating steps using infilling technique demonstrates the effectiveness in visual procedures with more coherent texts. We conclusively show a METEOR score of 27.51 on procedures which is higher than the state-of-the-art on visual storytelling. We also demonstrate the effects of interposing new text with missing images during inference. The code and the dataset will be publicly available at https://visual-narratives.github.io/Visual-Narratives/."
2020.conll-1.46,Understanding Linguistic Accommodation in Code-Switched Human-Machine Dialogues,2020,-1,-1,4,0,20995,tanmay parekh,Proceedings of the 24th Conference on Computational Natural Language Learning,0,"Code-switching is a ubiquitous phenomenon in multilingual communities. Natural language technologies that wish to communicate like humans must therefore adaptively incorporate code-switching techniques when they are deployed in multilingual settings. To this end, we propose a Hindi-English human-machine dialogue system that elicits code-switching conversations in a controlled setting. It uses different code-switching agent strategies to understand how users respond and accommodate to the agent{'}s language choice. Through this system, we collect and release a new dataset CommonDost, comprising of 439 human-machine multilingual conversations. We adapt pre-defined metrics to discover linguistic accommodation from users to agents. Finally, we compare these dialogues with Spanish-English dialogues collected in a similar setting, and analyze the impact of linguistic and socio-cultural factors on code-switching patterns across the two language pairs."
2020.coling-main.1,Exploring Controllable Text Generation Techniques,2020,66,0,2,1,4128,shrimai prabhumoye,Proceedings of the 28th International Conference on Computational Linguistics,0,"Neural controllable text generation is an important area gaining attention due to its plethora of applications. Although there is a large body of prior work in controllable text generation, there is no unifying theme. In this work, we provide a new schema of the pipeline of the generation process by classifying it into five modules. The control of attributes in the generation process requires modification of these modules. We present an overview of different techniques used to perform the modulation of these modules. We also provide an analysis on the advantages and disadvantages of these techniques. We further pave ways to develop new architectures based on the combination of the modules described in this paper."
2020.bea-1.15,Should You Fine-Tune {BERT} for Automated Essay Scoring?,2020,-1,-1,2,1,16871,elijah mayfield,Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"Most natural language processing research now recommends large Transformer-based models with fine-tuning for supervised classification tasks; older strategies like bag-of-words features and linear models have fallen out of favor. Here we investigate whether, in automated essay scoring (AES) research, deep neural models are an appropriate technological choice. We find that fine-tuning BERT produces similar performance to classical models at significant additional cost. We argue that while state-of-the-art strategies do match existing best results, they come with opportunity costs in computational resources. We conclude with a review of promising areas for research on student essays where the unique characteristics of Transformers may provide benefits over classical methods to justify the costs."
2020.acl-main.169,Politeness Transfer: A Tag and Generate Approach,2020,40,1,8,0,3436,aman madaan,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https://github.com/tag-and-generate."
2020.acl-main.217,Phone Features Improve Speech Translation,2020,-1,-1,2,0.586749,1275,elizabeth salesky,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"End-to-end models for speech translation (ST) more tightly couple speech recognition (ASR) and machine translation (MT) than a traditional cascade of separate ASR and MT models, with simpler model architectures and the potential for reduced error propagation. Their performance is often assumed to be superior, though in many conditions this is not yet the case. We compare cascaded and end-to-end models across high, medium, and low-resource conditions, and show that cascades remain stronger baselines. Further, we introduce two methods to incorporate phone features into ST models. We show that these features improve both architectures, closing the gap between end-to-end models and cascades, and outperforming previous academic work {--} by up to 9 BLEU on our low-resource setting."
2020.acl-main.248,Topological Sort for Sentence Ordering,2020,20,0,3,1,4128,shrimai prabhumoye,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Sentence ordering is the task of arranging the sentences of a given text in the correct order. Recent work using deep neural networks for this task has framed it as a sequence prediction problem. In this paper, we propose a new framing of this task as a constraint solving problem and introduce a new technique to solve it. Additionally, we propose a human evaluation for this task. The results on both automatic and human metrics across four different datasets show that this new technique is better at capturing coherence in documents."
2020.acl-main.415,A Corpus for Large-Scale Phonetic Typology,2020,-1,-1,6,0.586749,1275,elizabeth salesky,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"A major hurdle in data-driven research on typology is having sufficient data in many languages to draw meaningful conclusions. We present VoxClamantis v1.0, the first large-scale corpus for phonetic typology, with aligned segments and estimated phoneme-level labels in 690 readings spanning 635 languages, along with acoustic-phonetic measures of vowels and sibilants. Access to such data can greatly facilitate investigation of phonetic typology at a large scale and across many languages. However, it is non-trivial and computationally intensive to obtain such alignments for hundreds of languages, many of which have few to no resources presently available. We describe the methodology to create our corpus, discuss caveats with current methods and their impact on the utility of this data, and illustrate possible research directions through a series of case studies on the 48 highest-quality readings. Our corpus and scripts are publicly available for non-commercial use at https://voxclamantisproject.github.io."
2020.acl-main.651,{C}lar{Q}: A large-scale and diverse dataset for Clarification Question Generation,2020,-1,-1,2,0,14422,vaibhav kumar,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Question answering and conversational systems are often baffled and need help clarifying certain ambiguities. However, limitations of existing datasets hinder the development of large-scale models capable of generating and utilising clarification questions. In order to overcome these limitations, we devise a novel bootstrapping framework (based on self-supervision) that assists in the creation of a diverse, large-scale dataset of clarification questions based on post-comment tuples extracted from stackexchange. The framework utilises a neural network based architecture for classifying clarification questions. It is a two-step method where the first aims to increase the precision of the classifier and second aims to increase its recall. We quantitatively demonstrate the utility of the newly created dataset by applying it to the downstream task of question-answering. The final dataset, ClarQ, consists of {\textasciitilde}2M examples distributed across 173 domains of stackexchange. We release this dataset in order to foster research into the field of clarification question generation with the larger goal of enhancing dialog and question answering systems."
W19-5943,A Dynamic Strategy Coach for Effective Negotiation,2019,25,0,3,0,23783,yiheng zhou,Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue,0,"Negotiation is a complex activity involving strategic reasoning, persuasion, and psychology. An average person is often far from an expert in negotiation. Our goal is to assist humans to become better negotiators through a machine-in-the-loop approach that combines machine{'}s advantage at data-driven decision-making and human{'}s language generation ability. We consider a bargaining scenario where a seller and a buyer negotiate the price of an item for sale through a text-based dialogue. Our negotiation coach monitors messages between them and recommends strategies in real time to the seller to get a better deal (e.g., {``}reject the proposal and propose a price{''}, {``}talk about your personal experience with the product{''}). The best strategy largely depends on the context (e.g., the current price, the buyer{'}s attitude). Therefore, we first identify a set of negotiation strategies, then learn to predict the best strategy in a given dialogue context from a set of human-human bargaining dialogues. Evaluation on human-human dialogues shows that our coach increases the profits of the seller by almost 60{\%}."
W19-4446,Equity Beyond Bias in Language Technologies for Education,2019,-1,-1,7,1,16871,elijah mayfield,Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications,0,"There is a long record of research on equity in schools. As machine learning researchers begin to study fairness and bias in earnest, language technologies in education have an unusually strong theoretical and applied foundation to build on. Here, we introduce concepts from culturally relevant pedagogy and other frameworks for teaching and learning, identifying future work on equity in NLP. We present case studies in a range of topics like intelligent tutoring systems, computer-assisted language learning, automated essay scoring, and sentiment analysis in classrooms, and provide an actionable agenda for research."
W19-3823,Measuring Bias in Contextualized Word Representations,2019,25,4,4,0,22746,keita kurita,Proceedings of the First Workshop on Gender Bias in Natural Language Processing,0,"Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases."
W19-3637,Principled Frameworks for Evaluating Ethics in {NLP} Systems,2019,13,0,3,1,4128,shrimai prabhumoye,Proceedings of the 2019 Workshop on Widening NLP,0,"We critique recent work on ethics in natural language processing. Those discussions have focused on data collection, experimental design, and interventions in modeling. But we argue that we ought to first understand the frameworks of ethics that are being used to evaluate the fairness and justice of algorithmic systems. Here, we begin that discussion by outlining deontological and consequentialist ethics, and make predictions on the research agenda prioritized by each."
W19-3402,{``}My Way of Telling a Story{''}: Persona based Grounded Story Generation,2019,39,2,4,1,6250,khyathi chandu,Proceedings of the Second Workshop on Storytelling,0,"Visual storytelling is the task of generating stories based on a sequence of images. Inspired by the recent works in neural generation focusing on controlling the form of text, this paper explores the idea of generating these stories in different personas. However, one of the main challenges of performing this task is the lack of a dataset of visual stories in different personas. Having said that, there are independent datasets for both visual storytelling and annotated sentences for various persona. In this paper we describe an approach to overcome this by getting labelled persona data from a different task and leveraging those annotations to perform persona based story generation. We inspect various ways of incorporating personality in both the encoder and the decoder representations to steer the generation in the target direction. To this end, we propose five models which are incremental extensions to the baseline model to perform the task at hand. In our experiments we use five different personas to guide the generation process. We find that the models based on our hypotheses perform better at capturing words while generating stories in the target persona."
W19-3413,{W}riter{F}orcing: Generating more interesting story endings,2019,27,0,4,0,3963,prakhar gupta,Proceedings of the Second Workshop on Storytelling,0,"We study the problem of generating interesting endings for stories. Neural generative models have shown promising results for various text generation problems. Sequence to Sequence (Seq2Seq) models are typically trained to generate a single output sequence for a given input sequence. However, in the context of a story, multiple endings are possible. Seq2Seq models tend to ignore the context and generate generic and dull responses. Very few works have studied generating diverse and interesting story endings for the same story context. In this paper, we propose models which generate more diverse and interesting outputs by 1) training models to focus attention on important keyphrases of the story, and 2) promoting generating nongeneric words. We show that the combination of the two leads to more interesting endings."
W19-2108,"Stance Classification, Outcome Prediction, and Impact Assessment: {NLP} Tasks for Studying Group Decision-Making",2019,-1,-1,2,1,16871,elijah mayfield,Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science,0,"In group decision-making, the nuanced process of conflict and resolution that leads to consensus formation is closely tied to the quality of decisions made. Behavioral scientists rarely have rich access to process variables, though, as unstructured discussion transcripts are difficult to analyze. Here, we define ways for NLP researchers to contribute to the study of groups and teams. We introduce three tasks alongside a large new corpus of over 400,000 group debates on Wikipedia. We describe the tasks and their importance, then provide baselines showing that BERT contextualized word embeddings consistently outperform other language representations."
P19-1005,Boosting Dialog Response Generation,2019,0,4,2,1,12664,wenchao du,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Neural models have become one of the most important approaches to dialog response generation. However, they still tend to generate the most common and generic responses in the corpus all the time. To address this problem, we designed an iterative training process and ensemble method based on boosting. We combined our method with different training and decoding paradigms as the base model, including mutual-information-based decoding and reward-augmented maximum likelihood learning. Empirical results show that our approach can significantly improve the diversity and relevance of the responses generated by all base models, backed by objective measurements and human evaluation."
P19-1179,Exploring Phoneme-Level Speech Representations for End-to-End Speech Translation,2019,27,1,3,0.586749,1275,elizabeth salesky,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Previous work on end-to-end translation from speech has primarily used frame-level features as speech representations, which creates longer, sparser sequences than text. We show that a naive method to create compressed phoneme-like speech representations is far more effective and efficient for translation than traditional frame-level speech features. Specifically, we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for translation. We see improvements of up to 5 BLEU on both our high and low resource language pairs, with a reduction in training time of 60{\%}. Our improvements hold across multiple data sizes and two language pairs."
P19-1606,Storyboarding of Recipes: Grounded Contextual Generation,2019,0,1,3,1,6250,khyathi chandu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61{\%} found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes. We also discuss analysis of the output highlighting key important NLP issues for prospective directions."
N19-1062,Black is to Criminal as Caucasian is to Police: Detecting and Removing Multiclass Bias in Word Embeddings,2019,25,10,3,1,26090,thomas manzini,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Online texts - across genres, registers, domains, and styles - are riddled with human stereotypes, expressed in overt or subtle ways. Word embeddings, trained on these texts, perpetuate and amplify these stereotypes, and propagate biases to machine learning models that use word embeddings as features. In this work, we propose a method to debias word embeddings in multiclass settings such as race and religion, extending the work of (Bolukbasi et al., 2016) from the binary setting, such as binary gender. Next, we propose a novel methodology for the evaluation of multiclass debiasing. We demonstrate that our multiclass debiasing is robust and maintains the efficacy in standard NLP tasks."
N19-1377,Top-Down Structurally-Constrained Neural Response Generation with Lexicalized Probabilistic Context-Free Grammar,2019,0,0,2,1,12664,wenchao du,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We consider neural language generation under a novel problem setting: generating the words of a sentence according to the order of their first appearance in its lexicalized PCFG parse tree, in a depth-first, left-to-right manner. Unlike previous tree-based language generation methods, our approach is both (i) top-down and (ii) explicitly generating syntactic structure at the same time. In addition, our method combines neural model with symbolic approach: word choice at each step is constrained by its predicted syntactic function. We applied our model to the task of dialog response generation, and found it significantly improves over sequence-to-sequence baseline, in terms of diversity and relevance. We also investigated the effect of lexicalization on language generation, and found that lexicalization schemes that give priority to content words have certain advantages over those focusing on dependency relations."
D19-6302,Learning to Order Graph Elements with Application to Multilingual Surface Realization,2019,0,0,2,1,12664,wenchao du,Proceedings of the 2nd Workshop on Multilingual Surface Realisation (MSR 2019),0,"Recent advances in deep learning have shown promises in solving complex combinatorial optimization problems, such as sorting variable-sized sequences. In this work, we take a step further and tackle the problem of ordering the elements of sequences that come with graph structures. Our solution adopts an encoder-decoder framework, in which the encoder is a graph neural network that learns the representation for each element, and the decoder predicts the ordering of each local neighborhood of the graph in turn. We apply our framework to multilingual surface realization, which is the task of ordering and completing sentences with their dependency parses given but without the ordering of words. Experiments show that our approach is much better for this task than prior works that do not consider graph structures. We participated in 2019 Surface Realization Shared Task (SR{'}19), and we ranked second out of 14 teams while outperforming those teams below by a large margin."
D19-6121,"Multimodal, Multilingual Grapheme-to-Phoneme Conversion for Low-Resource Languages",2019,0,0,5,0,23986,james route,Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),0,"Grapheme-to-phoneme conversion (g2p) is the task of predicting the pronunciation of words from their orthographic representation. His- torically, g2p systems were transition- or rule- based, making generalization beyond a mono- lingual (high resource) domain impractical. Recently, neural architectures have enabled multilingual systems to generalize widely; however, all systems to date have been trained only on spelling-pronunciation pairs. We hy- pothesize that the sequences of IPA characters used to represent pronunciation do not capture its full nuance, especially when cleaned to fa- cilitate machine learning. We leverage audio data as an auxiliary modality in a multi-task training process to learn a more optimal inter- mediate representation of source graphemes; this is the first multimodal model proposed for multilingual g2p. Our approach is highly ef- fective: on our in-domain test set, our mul- timodal model reduces phoneme error rate to 2.46{\%}, a more than 65{\%} decrease compared to our implementation of a unimodal spelling- pronunciation model{---}which itself achieves state-of-the-art results on the Wiktionary test set. The advantages of the multimodal model generalize to wholly unseen languages, reduc- ing phoneme error rate on our out-of-domain test set to 6.39{\%} from the unimodal 8.21{\%}, a more than 20{\%} relative decrease. Further- more, our training and test sets are composed primarily of low-resource languages, demon- strating that our multimodal approach remains useful when training data are constrained."
D19-5502,"Formality Style Transfer for Noisy, User-generated Conversations: Extracting Labeled, Parallel Data from Unlabeled Corpora",2019,0,0,2,0,26474,isak etinger,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"Typical datasets used for style transfer in NLP contain aligned pairs of two opposite extremes of a style. As each existing dataset is sourced from a specific domain and context, most use cases will have a sizable mismatch from the vocabulary and sentence structures of any dataset available. This reduces the performance of the style transfer, and is particularly significant for noisy, user-generated text. To solve this problem, we show a technique to derive a dataset of aligned pairs (style-agnostic vs stylistic sentences) from an unlabeled corpus by using an auxiliary dataset, allowing for in-domain training. We test the technique with the Yahoo Formality Dataset and 6 novel datasets we produced, which consist of scripts from 5 popular TV-shows (Friends, Futurama, Seinfeld, Southpark, Stargate SG-1) and the Slate Star Codex online forum. We gather 1080 human evaluations, which show that our method produces a sizable change in formality while maintaining fluency and context; and that it considerably outperforms OpenNMT{'}s Seq2Seq model directly trained on the Yahoo Formality Dataset. Additionally, we publish the full pipeline code and our novel datasets."
D19-5527,What A Sunny Day â: Toward Emoji-Sensitive Irony Detection,2019,0,0,4,0,9720,shirley hayati,Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),0,"Irony detection is an important task with applications in identification of online abuse and harassment. With the ubiquitous use of non-verbal cues such as emojis in social media, in this work we aim to study the role of these structures in irony detection. Since the existing irony detection datasets have {\textless}10{\%} ironic tweets with emoji, classifiers trained on them are insensitive to emojis. We propose an automated pipeline for creating a more balanced dataset."
D19-1500,Question Answering for Privacy Policies: Combining Computational and Legal Perspectives,2019,0,0,2,0.833333,10888,abhilasha ravichander,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Privacy policies are long and complex documents that are difficult for users to read and understand. Yet, they have legal effects on how user data can be collected, managed and used. Ideally, we would like to empower users to inform themselves about the issues that matter to them, and enable them to selectively explore these issues. We present PrivacyQA, a corpus consisting of 1750 questions about the privacy policies of mobile applications, and over 3500 expert annotations of relevant answers. We observe that a strong neural baseline underperforms human performance by almost 0.3 F1 on PrivacyQA, suggesting considerable room for improvement for future systems. Further, we use this dataset to categorically identify challenges to question answerability, with domain-general implications for any question answering system. The PrivacyQA corpus offers a challenging corpus for question answering, with genuine real world utility."
W18-5708,Data Augmentation for Neural Online Chats Response Selection,2018,18,1,2,1,12664,wenchao du,Proceedings of the 2018 {EMNLP} Workshop {SCAI}: The 2nd International Workshop on Search-Oriented Conversational {AI},0,"Data augmentation seeks to manipulate the available data for training to improve the generalization ability of models. We investigate two data augmentation proxies, permutation and flipping, for neural dialog response selection task on various models over multiple datasets, including both Chinese and English languages. Different from standard data augmentation techniques, our method combines the original and synthesized data for prediction. Empirical results show that our approach can gain 1 to 3 recall-at-1 points over baseline models in both full-scale and small-scale settings."
W18-5028,{D}ial{C}rowd: A toolkit for easy dialog system assessment,2018,0,2,3,0,3380,kyusong lee,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"When creating a dialog system, developers need to test each version to ensure that it is performing correctly. Recently the trend has been to test on large datasets or to ask many users to try out a system. Crowdsourcing has solved the issue of finding users, but it presents new challenges such as how to use a crowdsourcing platform and what type of test is appropriate. DialCrowd has been designed to make system assessment easier and to ensure the quality of the result. This paper describes DialCrowd, what specific needs it fulfills and how it works. It then relates a test of DialCrowd by a group of dialog system developer."
W18-5030,An Empirical Study of Self-Disclosure in Spoken Dialogue Systems,2018,0,7,2,0.833333,10888,abhilasha ravichander,Proceedings of the 19th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"Self-disclosure is a key social strategy employed in conversation to build relations and increase conversational depth. It has been heavily studied in psychology and linguistic literature, particularly for its ability to induce self-disclosure from the recipient, a phenomena known as reciprocity. However, we know little about how self-disclosure manifests in conversation with automated dialog systems, especially as any self-disclosure on the part of a dialog system is patently disingenuous. In this work, we run a large-scale quantitative analysis on the effect of self-disclosure by analyzing interactions between real-world users and a spoken dialog system in the context of social conversation. We find that indicators of reciprocity occur even in human-machine dialog, with far-reaching implications for chatbots in a variety of domains including education, negotiation and social dialog."
W18-3204,Code-Mixed Question Answering Challenge: Crowd-sourcing Data and Techniques,2018,0,5,8,1,6250,khyathi chandu,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"Code-Mixing (CM) is the phenomenon of alternating between two or more languages which is prevalent in bi- and multi-lingual communities. Most NLP applications today are still designed with the assumption of a single interaction language and are most likely to break given a CM utterance with multiple languages mixed at a morphological, phrase or sentence level. For example, popular commercial search engines do not yet fully understand the intents expressed in CM queries. As a first step towards fostering research which supports CM in NLP applications, we systematically crowd-sourced and curated an evaluation dataset for factoid question answering in three CM languages - Hinglish (Hindi+English), Tenglish (Telugu+English) and Tamlish (Tamil+English) which belong to two language families (Indo-Aryan and Dravidian). We share the details of our data collection process, techniques which were used to avoid inducing lexical bias amongst the crowd workers and other CM specific linguistic properties of the dataset. Our final dataset, which is available freely for research purposes, has 1,694 Hinglish, 2,848 Tamlish and 1,391 Tenglish factoid questions and their answers. We discuss the techniques used by the participants for the first edition of this ongoing challenge."
W18-3209,Automatic Detection of Code-switching Style from Acoustics,2018,0,2,3,0,28340,saikrishna rallabandi,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"Multilingual speakers switch between languages in an non-trivial fashion displaying inter sentential, intra sentential, and congruent lexicalization based transitions. While monolingual ASR systems may be capable of recognizing a few words from a foreign language, they are usually not robust enough to handle these varied styles of code-switching. There is also a lack of large code-switched speech corpora capturing all these styles making it difficult to build code-switched speech recognition systems. We hypothesize that it may be useful for an ASR system to be able to first detect the switching style of a particular utterance from acoustics, and then use specialized language models or other adaptation techniques for decoding the speech. In this paper, we look at the first problem of detecting code-switching style from acoustics. We classify code-switched Spanish-English and Hindi-English corpora using two metrics and show that features extracted from acoustics alone can distinguish between different kinds of code-switching in these language pairs."
W18-3211,Language Informed Modeling of Code-Switched Text,2018,0,7,4,1,6250,khyathi chandu,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"Code-switching (CS), the practice of alternating between two or more languages in conversations, is pervasive in most multi-lingual communities. CS texts have a complex interplay between languages and occur in informal contexts that make them harder to collect and construct NLP tools for. We approach this problem through Language Modeling (LM) on a new Hindi-English mixed corpus containing 59,189 unique sentences collected from blogging websites. We implement and discuss different Language Models derived from a multi-layered LSTM architecture. We hypothesize that encoding language information strengthens a language model by helping to learn code-switching points. We show that our highest performing model achieves a test perplexity of 19.52 on the CS corpus that we collected and processed. On this data we demonstrate that our performance is an improvement over AWD-LSTM LM (a recent state of the art on monolingual English)."
W18-3217,Tackling Code-Switched {NER}: Participation of {CMU},2018,0,3,3,0,28351,parvathy geetha,Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching,0,"Named Entity Recognition plays a major role in several downstream applications in NLP. Though this task has been heavily studied in formal monolingual texts and also noisy texts like Twitter data, it is still an emerging task in code-switched (CS) content on social media. This paper describes our participation in the shared task of NER on code-switched data for Spanglish (Spanish + English) and Arabish (Arabic + English). In this paper we describe models that intuitively developed from the data for the shared task Named Entity Recognition on Code-switched Data. Owing to the sparse and non-linear relationships between words in Twitter data, we explored neural architectures that are capable of non-linearities fairly well. In specific, we trained character level models and word level models based on Bidirectional LSTMs (Bi-LSTMs) to perform sequential tagging. We train multiple models to identify nominal mentions and subsequently use this information to predict the labels of named entity in a sequence. Our best model is a character level model along with word level pre-trained multilingual embeddings that gave an F-score of 56.72 in Spanglish and a word level model that gave an F-score of 65.02 in Arabish on the test data."
P18-1080,Style Transfer Through Back-Translation,2018,42,40,4,1,4128,shrimai prabhumoye,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Style transfer is the task of rephrasing the text to contain specific stylistic properties without changing the intent or affect within the context. This paper introduces a new method for automatic style transfer. We first learn a latent representation of the input sentence which is grounded in a language translation model in order to better preserve the meaning of the sentence while reducing stylistic properties. Then adversarial generation techniques are used to make the output match the desired style. We evaluate this technique on three different style transformations: sentiment, gender and political slant. Compared to two state-of-the-art style transfer modeling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency."
D18-1076,A Dataset for Document Grounded Conversations,2018,0,23,3,0,30465,kangyan zhou,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"This paper introduces a document grounded dataset for conversations. We define {``}Document Grounded Conversations{''} as conversations that are about the contents of a specified document. In this dataset the specified documents were Wikipedia articles about popular movies. The dataset contains 4112 conversations with an average of 21.43 turns per conversation. This positions this dataset to not only provide a relevant chat history while generating responses but also provide a source of information that the models could use. We describe two neural architectures that provide benchmark performance on the task of generating the next response. We also evaluate our models for engagement and fluency, and find that the information from the document helps in generating more engaging and fluent responses."
W17-2908,Linguistic Markers of Influence in Informal Interactions,2017,9,0,6,1,4128,shrimai prabhumoye,Proceedings of the Second Workshop on {NLP} and Computational Social Science,0,"There has been a long standing interest in understanding {`}Social Influence{'} both in Social Sciences and in Computational Linguistics. In this paper, we present a novel approach to study and measure interpersonal influence in daily interactions. Motivated by the basic principles of influence, we attempt to identify indicative linguistic features of the posts in an online knitting community. We present the scheme used to operationalize and label the posts as influential or non-influential. Experiments with the identified features show an improvement in the classification accuracy of influence by 3.15{\%}. Our results illustrate the important correlation between the structure of the language and its potential to influence others."
W16-3608,A {W}izard-of-{O}z Study on A Non-Task-Oriented Dialog Systems That Reacts to User Engagement,2016,7,22,3,1,1417,zhou yu,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
W16-3618,Initiations and Interruptions in a Spoken Dialog System,2016,8,1,3,0,21752,leah nicolichhenkin,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
W16-3647,Automatic Recognition of Conversational Strategies in the Service of a Socially-Aware Dialog System,2016,35,12,3,0,32618,ran zhao,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
W16-3649,Strategy and Policy Learning for Non-Task-Oriented Conversational Systems,2016,14,32,3,1,1417,zhou yu,Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,None
N16-1161,Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning,2016,36,25,7,0.194849,3965,yulia tsvetkov,Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted. We apply these to the problem of modeling phone sequences---a domain in which universal symbol inventories and cross-linguistically shared feature representations are a natural fit. Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations, and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually."
L16-1546,Speech Synthesis of Code-Mixed Text,2016,15,8,2,0.833333,6024,sunayana sitaram,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Most Text to Speech (TTS) systems today assume that the input text is in a single language and is written in the same language that the text needs to be synthesized in. However, in bilingual and multilingual communities, code mixing or code switching occurs in speech, in which speakers switch between languages in the same utterance. Due to the popularity of social media, we now see code-mixing even in text in these multilingual communities. TTS systems capable of synthesizing such text need to be able to handle text that is written in multiple languages and scripts. Code-mixed text poses many challenges to TTS systems, such as language identification, spelling normalization and pronunciation modeling. In this work, we describe a preliminary framework for synthesizing code-mixed text. We carry out experiments on synthesizing code-mixed Hindi and English text. We find that there is a significant user preference for TTS systems that can correctly identify and pronounce words in different languages."
J16-2005,Mining Parallel Corpora from {S}ina {W}eibo and {T}witter,2016,43,2,4,0.964561,13846,wang ling,Computational Linguistics,0,"Microblogs such as Twitter, Facebook, and Sina Weibo China's equivalent of Twitter are a remarkable linguistic resource. In contrast to content from edited genres such as newswire, microblogs contain discussions of virtually every topic by numerous individuals in different languages and dialects and in different styles. In this work, we show that some microblog users post self-translated messages targeting audiences who speak different languages, either by writing the same message in multiple languages or by retweeting translations of their original posts in a second language. We introduce a method for finding and extracting this naturally occurring parallel data. Identifying the parallel content requires solving an alignment problem, and we give an optimally efficient dynamic programming algorithm for this. Using our method, we extract nearly 3M Chinese-English parallel segments from Sina Weibo using a targeted crawl of Weibo users who post in multiple languages. Additionally, from a random sample of Twitter, we obtain substantial amounts of parallel data in multiple language pairs. Evaluation is performed by assessing the accuracy of our extraction approach relative to a manual annotation as well as in terms of utility as training data for a Chinese-English machine translation system. Relative to traditional parallel data resources, the automatically extracted parallel data yield substantial translation quality improvements in translating microblog text and modest improvements in translating edited news content."
2016.gwc-1.60,This Table is Different: A {W}ord{N}et-Based Approach to Identifying References to Document Entities,2016,-1,-1,2,0,13158,shomir wilson,Proceedings of the 8th Global WordNet Conference (GWC),0,"Writing intended to inform frequently contains references to document entities (DEs), a mixed class that includes orthographically structured items (e.g., illustrations, sections, lists) and discourse entities (arguments, suggestions, points). Such references are vital to the interpretation of documents, but they often eschew identifiers such as {``}Figure 1{''} for inexplicit phrases like {``}in this figure{''} or {``}from these premises{''}. We examine inexplicit references to DEs, termed DE references, and recast the problem of their automatic detection into the determination of relevant word senses. We then show the feasibility of machine learning for the detection of DE-relevant word senses, using a corpus of human-labeled synsets from WordNet. We test cross-domain performance by gathering lemmas and synsets from three corpora: website privacy policies, Wikipedia articles, and Wikibooks textbooks. Identifying DE references will enable language technologies to use the information encoded by them, permitting the automatic generation of finely-tuned descriptions of DEs and the presentation of richly-structured information to readers."
W15-4606,An Incremental Turn-Taking Model with Active System Barge-in for Spoken Dialog Systems,2015,15,6,2,0.283019,3378,tiancheng zhao,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper deals with an incremental turntaking model that provides a novel solution for end-of-turn detection. It includes a flexible framework that enables active system barge-in. In order to accomplish this, a systematic procedure of teaching a dialog system to produce meaningful system barge-in is presented. This procedure improves system robustness and success rate. It includes constructing cost models and learning optimal policy using reinforcement learning. Results show that our model reduces false cut-in rate by 37.1% and response delay by 32.5% compared to the baseline system. Also the learned system barge-in strategy yields a 27.7% increase in average reward from user responses."
W15-4630,The Real Challenge 2014: Progress and Prospects,2015,3,0,2,0,1592,maxine eskenazi,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"The REAL Challenge took place for the first time in 2014, with a long term goal of creating streams of real data that the research community can use, by fostering the creation of systems that are capable of attracting real users. A novel approach is to have high school and undergraduate students devise the types of applications that would attract many real users and that need spoken interaction. The projects are presented to researchers from the spoken dialog research community and the researchers and students work together to refine and develop the ideas. Eleven projects were presented at the first workshop. Many of them have found mentors to help in the next stages of the projects. The students have also brought out issues in the use of speech for real applications. Those issues involve privacy and significant personalization of the applications. While long-term impact of the challenge remains to be seen, the challenge has already been a success at its immediate aims of bringing new ideas and new researchers into the community, and serves as a model for related outreach efforts."
P15-2105,Automatic Keyword Extraction on {T}witter,2015,39,24,5,1,26032,luis marujo,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"In this paper, we build a corpus of tweets from Twitter annotated with keywords using crowdsourcing methods. We identify key differences between this domain and the work performed on other domains, such as news, which makes existing approaches for automatic keyword extraction not generalize well on Twitter datasets. These datasets include the small amount of content in each tweet, the frequent usage of lexical variants and the high variance of the cardinality of keywords present in each tweet. We propose methods for addressing these issues, which leads to solid improvements on this dataset for this task."
N15-1142,Two/Too Simple Adaptations of {W}ord2{V}ec for Syntax Problems,2015,23,194,3,1,13846,wang ling,Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present two simple modifications to the models in the popular Word2Vec tool, in order to generate embeddings more suited to tasks involving syntax. The main issue with the original models is the fact that they are insensitive to word order. While order independence is useful for inducing semantic representations, this leads to suboptimal results when they are used to solve syntax-based problems. We show improvements in part-ofspeech tagging and dependency parsing using our proposed models."
D15-1161,Not All Contexts Are Created Equal: Better Word Representations with Variable Attention,2015,24,93,6,1,13846,wang ling,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"We introduce an extension to the bag-ofwords model for learning words representations that take into account both syntactic and semantic properties within language. This is done by employing an attention model that finds within the contextual words, the words that are relevant for each prediction. The general intuition of our model is that some words are only relevant for predicting local context (e.g. function words), while other words are more suited for determining global context, such as the topic of the document. Experiments performed on both semantically and syntactically oriented tasks show gains using our model over the existing bag of words model. Furthermore, compared to other more sophisticated models, our model scales better as we increase the size of the context of the model."
D15-1176,Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation,2015,34,265,3,1,13846,wang ling,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"We introduce a model for constructing vector representations of words by composing characters using bidirectional LSTMs. Relative to traditional word representation models that have independent vectors for each word type, our model requires only a single vector per character type and a fixed set of parameters for the compositional model. Despite the compactness of this model and, more importantly, the arbitrary nature of the formxe2x80x90function relationship in language, our xe2x80x9ccomposedxe2x80x9d word representations yield state-of-the-art results in language modeling and part-of-speech tagging. Benefits over traditional baselines are particularly pronounced in morphologically rich languages (e.g., Turkish)."
W14-3356,Crowdsourcing High-Quality Parallel Data Extraction from {T}witter,2014,23,10,4,1,13846,wang ling,Proceedings of the Ninth Workshop on Statistical Machine Translation,0,"High-quality parallel data is crucial for a range of multilingual applications, from tuning and evaluating machine translation systems to cross-lingual annotation projection. Unfortunately, automatically obtained parallel data (which is available in relative abundance) tends to be quite noisy. To obtain high-quality parallel data, we introduce a crowdsourcing paradigm in which workers with only basic bilingual proficiency identify translations from an automatically extracted corpus of parallel microblog messages. For less than $350, we obtained over 5000 parallel segments in five language pairs. Evaluated against expert annotations, the quality of the crowdsourced corpus is significantly better than existing automatic methods: it obtains an performance comparable to expert annotations when used in MERT tuning of a microblog MT system; and training a parallel sentence classifier with it leads also to improved results. The crowdsourced corpora will be made available in http://www.cs.cmu.edu/ ~lingwang/microtopia/."
W13-4007,Automatic Prediction of Friendship via Multi-model Dyadic Features,2013,43,18,4,1,1417,zhou yu,Proceedings of the {SIGDIAL} 2013 Conference,0,"In this paper we focus on modeling friendships between humans as a way of working towards technology that can initiate and sustain a lifelong relationship with users. We do this by predicting friendship status in a dyad using a set of automatically harvested verbal and nonverbal features from videos of the interaction of students in a peer tutoring study. We propose a new computational model used to model friendship status in our data, based on a group sparse model (GSM) with L2,1 norm which is designed to accommodate the sparse and noisy properties of the multi-channel features. Our GSM model achieved the best overall performance compared to a non-sparse linear model (NLM) and a regular sparse linear model (SLM), as well as outperforming human raters. Dyadic features, such as number and length of conversational turns and mutual gaze, in addition to low level features such as F0 and gaze at task, were found to be good predictors of friendship status."
W13-4065,The Dialog State Tracking Challenge,2013,14,190,4,0,4765,jason williams,Proceedings of the {SIGDIAL} 2013 Conference,0,"In a spoken dialog system, dialog state tracking deduces information about the userxe2x80x99s goal as the dialog progresses, synthesizing evidence such as dialog acts over multiple turns with external data sources. Recent approaches have been shown to overcome ASR and SLU errors in some applications. However, there are currently no common testbeds or evaluation measures for this task, hampering progress. The dialog state tracking challenge seeks to address this by providing a heterogeneous corpus of 15K human-computer dialogs in a standard format, along with a suite of 11 evaluation metrics. The challenge received a total of 27 entries from 9 research groups. The results show that the suite of performance metrics cluster into 4 natural groups. Moreover, the dialog systems that benefit most from dialog state tracking are those with less discriminative speech recognition confidence scores. Finally, generalization is a key problem: in 2 of the 4 test sets, fewer than half of the entries out-performed simple baselines. 1 Overview and motivation Spoken dialog systems interact with users via natural language to help them achieve a goal. As the interaction progresses, the dialog manager maintains a representation of the state of the dialog in a process called dialog state tracking (DST). For example, in a bus schedule information system, the dialog state might indicate the userxe2x80x99s desired bus route, origin, and destination. Dialog state tracking is difficult because automatic speech xe2x88x97Most of the work for the challenge was performed when the second and third authors were with Honda Research Institute, Mountain View, CA, USA recognition (ASR) and spoken language understanding (SLU) errors are common, and can cause the system to misunderstand the userxe2x80x99s needs. At the same time, state tracking is crucial because the system relies on the estimated dialog state to choose actions xe2x80x93 for example, which bus schedule information to present to the user. Most commercial systems use hand-crafted heuristics for state tracking, selecting the SLU result with the highest confidence score, and discarding alternatives. In contrast, statistical approaches compute scores for many hypotheses for the dialog state (Figure 1). By exploiting correlations between turns and information from external data sources xe2x80x93 such as maps, bus timetables, or models of past dialogs xe2x80x93 statistical approaches can overcome some SLU errors. Numerous techniques for dialog state tracking have been proposed, including heuristic scores (Higashinaka et al., 2003), Bayesian networks (Paek and Horvitz, 2000; Williams and Young, 2007), kernel density estimators (Ma et al., 2012), and discriminative models (Bohus and Rudnicky, 2006). Techniques have been fielded which scale to realistically sized dialog problems and operate in real time (Young et al., 2010; Thomson and Young, 2010; Williams, 2010; Mehta et al., 2010). In end-to-end dialog systems, dialog state tracking has been shown to improve overall system performance (Young et al., 2010; Thomson and Young, 2010). Despite this progress, direct comparisons between methods have not been possible because past studies use different domains and system components, for speech recognition, spoken language understanding, dialog control, etc. Moreover, there is little agreement on how to evaluate dialog state tracking. Together these issues limit progress in this research area. The Dialog State Tracking Challenge (DSTC) provides a first common testbed and evaluation"
P13-1018,Microblogs as Parallel Corpora,2013,23,45,4,1,13846,wang ling,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In the ever-expanding sea of microblog data, there is a surprising amount of naturally occurring parallel text: some users create post multilingual messages targeting international audiences while others xe2x80x9cretweetxe2x80x9d translations. We present an efficient method for detecting these messages and extracting parallel segments from them. We have been able to extract over 1M Chinese-English parallel segments from Sina Weibo (the Chinese counterpart of Twitter) using only their public APIs. As a supplement to existing parallel training data, our automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news commentary. The resources in described in this paper are available at http://www.cs.cmu.edu/ lingwang/utopia."
D13-1008,Paraphrasing 4 Microblog Normalization,2013,34,37,3,1,13846,wang ling,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"Compared to the edited genres that have played a central role in NLP research, microblog texts use a more informal register with nonstandard lexical items, abbreviations, and free orthographic variation. When confronted with such input, conventional text analysis tools often perform poorly. Normalization xe2x80x94 replacing orthographically or lexically idiosyncratic forms with more standard variants xe2x80x94 can improve performance. We propose a method for learning normalization rules from machine translations of a parallel corpus of microblog messages. To validate the utility of our approach, we evaluate extrinsically, showing that normalizing English tweets and then translating improves translation quality (compared to translating unnormalized text) using three standard web translation services as well as a phrase-based translation system trained on parallel microblog data."
W12-1810,Future Directions in Spoken Dialog Systems: A Community of Possibilities,2012,4,0,1,1,4130,alan black,{NAACL}-{HLT} Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data ({SDCTD} 2012),0,"A spoken dialog system consists of a number of non-trivially interacting components. In order to allow new students, researchers and developers to meaningfully and relatively rapidly enter the field it is critical that, despite their complexity, the resources be accessible and easy to use. Everyone should be able to start building new technologies without spending a significant amount of time re-inventing the wheel. There are four levels of support that we believe new entrants should have. 1) A flexible open source system that runs on many different operating systems, is well documented and supports both simple and complex dialog systems. 2) Logs and speech files from a large number of dialogs that enable analysis and training of new systems and techniques. 3) An actual set of real users that speak to the system on a regular basis. 4) The ability to run studies on complete real user platforms."
W12-1603,"{``}Love ya, jerkface{''}: Using Sparse Log-Linear Models to Build Positive and Impolite Relationships with Teens",2012,45,14,4,0,3991,william wang,Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"One challenge of implementing spoken dialogue systems for long-term interaction is how to adapt the dialogue as user and system become more familiar. We believe this challenge includes evoking and signaling aspects of long-term relationships such as rapport. For tutoring systems, this may additionally require knowing how relationships are signaled among non-adult users. We therefore investigate conversational strategies used by teenagers in peer tutoring dialogues, and how these strategies function differently among friends or strangers. In particular, we use annotated and automatically extracted linguistic devices to predict impoliteness and positivity in the next turn. To take into account the sparse nature of these features in real data we use models including Lasso, ridge estimator, and elastic net. We evaluate the predictive power of our models under various settings, and compare our sparse models with standard non-sparse solutions. Our experiments demonstrate that our models are more accurate than non-sparse models quantitatively, and that teens use unexpected kinds of language to do relationship work such as signaling rapport, but friends and strangers, tutors and tutees, carry out this work in quite different ways from one another."
georgila-etal-2012-practical,Practical Evaluation of Human and Synthesized Speech for Virtual Human Dialogue Systems,2012,14,10,2,0,16796,kallirroi georgila,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"The current practice in virtual human dialogue systems is to use professional human recordings or limited-domain speech synthesis. Both approaches lead to good performance but at a high cost. To determine the best trade-off between performance and cost, we perform a systematic evaluation of human and synthesized voices with regard to naturalness, conversational aspect, and likability. We vary the type (in-domain vs. out-of-domain), length, and content of utterances, and take into account the age and native language of raters as well as their familiarity with speech synthesis. We present detailed results from two studies, a pilot one and one run on Amazon's Mechanical Turk. Our results suggest that a professional human voice can supersede both an amateur human voice and synthesized voices. Also, a high-quality general-purpose voice or a good limited-domain voice can perform better than amateur human recordings. We do not find any significant differences between the performance of a high-quality general-purpose voice and a limited-domain voice, both trained with speech recorded by actors. As expected, the high-quality general-purpose voice is rated higher than the limited-domain voice for out-of-domain sentences and lower for in-domain sentences. There is also a trend for long or negative-content utterances to receive lower ratings."
D12-1088,Entropy-based Pruning for Phrase-based Machine Translation,2012,16,14,4,1,13846,wang ling,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"Phrase-based machine translation models have shown to yield better translations than Word-based models, since phrase pairs encode the contextual information that is needed for a more accurate translation. However, many phrase pairs do not encode any relevant context, which means that the translation event encoded in that phrase pair is led by smaller translation events that are independent from each other, and can be found on smaller phrase pairs, with little or no loss in translation accuracy. In this work, we propose a relative entropy model for translation models, that measures how likely a phrase pair encodes a translation event that is derivable using smaller translation events with similar probabilities. This model is then applied to phrase table pruning. Tests show that considerable amounts of phrase pairs can be excluded, without much impact on the translation quality. In fact, we show that better translations can be obtained using our pruned models, due to the compression of the search space during decoding."
C12-2070,Improving Relative-Entropy Pruning using Statistical Significance,2012,20,1,5,1,13846,wang ling,Proceedings of {COLING} 2012: Posters,0,"Relative Entropy-based pruning has been shown to be efficient for pruning language models for more than a decade ago. Recently, this method has been applied to Phrase-based Machine Translation, and results suggest that this method is comparable the state-of-art pruning method based on significance tests. In this work, we show that these 2 methods are effective in pruning different types of phrase pairs. On one hand, relative entropy pruning searches for phrase pairs that can be composed using smaller constituents with a small or no loss in probability. On the other hand, significance pruning removes phrase pairs that are likely to be spurious. Then, we show that these methods can be combined in order to produce better results, over both metrics when used individually."
C12-2089,Text-To-Speech for Languages without an Orthography,2012,8,3,2,0,43707,sukhada palkar,Proceedings of {COLING} 2012: Posters,0,"Speech synthesis models are typically built from a corpus of speech that has accurate transcriptions. However, many of the languages of the world do not have a standardized writing system. This paper is an initial attempt at building synthetic voices for such languages. It may seem useless to develop a text-to-speech system when there is no text available. But we will discuss some well defined use cases where we need these models. We will present our method to build synthetic voices from only speech data. We will present experimental results and oracle studies that show that we can automatically devise an artificial writing system for these languages, and build synthetic voices that are understandable and usable. TITLE AND ABSTRACT IN MARATHI xe0xa4x85xeex8cx97xe0xa4xb0xe0xa4xaaxeex85x83xe0xa4xa4xe0xa5x80 xe0xa4xa8xe0xa4xb8xe0xa4xb2xeex88xa8xe0xa4xbe xe0xa4xadxe0xa4xbexe0xa4xb7xe0xa4xbexe0xa4xb8xe0xa4xbexe0xa4xa0xe0xa5x80 xe0xa4xb5xe0xa4xbexe0xa4xa3xe0xa5x80 xe0xa4xb8xeex89xbfxe0xa4xb7xe0xa4xa3 xefx8dx88xe0xa4xb5xe0xa4xbfxe0xa4xa8xe0xa4xaexefx8cx9fxefx8dxb0xe0xa4xa4 xe0xa4xb5xe0xa4xbexefx90x8bxe0xa4xbexefx8cxbexe0xa4xafxe0xa4xbe xe0xa4x95xe0xa4xbexe0xa4xb7xe0xa4xbexe0xa4xaaxe0xa4xbexe0xa4xb8xe0xa4xa8 xe0xa4xb5xe0xa4xbexe0xa4xa3xe0xa5x80 xe0xa4xb8xefx8dx9bxe0xa4xb2xe0xa4xb7xe0xa4xa3xe0xa4xbexe0xa4x9axe0xa5x80 xe0xa4xb8xe0xa4x97xe0xa4xa3xe0xa4x95xefx8cxaaxe0xa4xaf xefx8dxb4xe0xa4xbfxe0xa4xa4xefx95x94xe0xa4xaa xe0xa4xacxe0xa4xa8xefx8cx91xe0xa4xb5xefx8dx84xe0xa4xafxe0xa4xbexe0xa4xb8xe0xa4xbexe0xa4xa0xefx8cxa5 xefx8dx86xe0xa4xafxe0xa4xbe xe0xa4x95xe0xa4xbexe0xa4xb7xe0xa4xbexe0xa4x9axe0xa5x80 xe0xa4x85xe0xa4x9axe0xa4x95 xefx8cx94xe0xa4xb2xefx8cx9fxe0xa4x96xe0xa4xa4 xefx8dxb4xe0xa4xbfxe0xa4xa4xefx8cx94xe0xa4xb2xe0xa4xaaxe0xa5x80 xe0xa4x89xe0xa4xaaxe0xa4xb2xefx8dx8dxe0xa4xa7 xe0xa4x85xe0xa4xb8xe0xa4xbexe0xa4xb5xe0xa5x80 xe0xa4xb2xe0xa4xbexe0xa4x97xe0xa4xa4. xe0xa4x9cxe0xa4x97xe0xa4xbexe0xa4xa4xe0xa5x80xe0xa4xb2 xe0xa4x85xe0xa4xa8xe0xa4x95 xe0xa4xadxe0xa4xbexe0xa4xb7xe0xa4xbe xe0xa4xaexe0xa4xbexefx8dxae xe0xa4xaexe0xa4xbexe0xa4xa8xe0xa4xbexefx8cx91xe0xa4x95xe0xa4xa4 xe0xa4x85xefx8cxb7xe0xa4xb0xe0xa4xaaxefx91xa9xe0xa4xa4xe0xa5x80 xe0xa4xb5xe0xa4xbexe0xa4xaaxe0xa4xb0xe0xa4xa4 xe0xa4xa8xe0xa4xbexe0xa4xb9xe0xa5x80xe0xa4xa4. xefx8dxb4xefx8dx9bxe0xa4xa4xefx9dx93xe0xa4xa4 xe0xa4x95xe0xa4xbexe0xa4xae xe0xa4xb9 xe0xa4x85xe0xa4xb6xe0xa4xbe xe0xa4xadxe0xa4xbexe0xa4xb7xe0xa4xbexe0xa4xb8xe0xa4xbexe0xa4xa0xefx8cxa5 xe0xa4xb8xefx8dx9bxe0xa4xb2xefx8cx91xe0xa4xb7xe0xa4xa4 xe0xa4x85xe0xa4xbexe0xa4xb5xe0xa4xbexe0xa4x9c xe0xa4xacxe0xa4xa8xefx8cx91xe0xa4xb5xefx8dx84xe0xa4xafxe0xa4xbexe0xa4x9axe0xa4xbe xe0xa4x8fxe0xa4x95 xe0xa4xaaxefx8cx90xe0xa4xb9xe0xa4xb2xe0xa4xbe xefx8dxb4xe0xa4xafxe0xa4xbexe0xa4xb8 xe0xa4x85xe0xa4xbexe0xa4xb9. xe0xa4xaexe0xa4xb3xe0xa4xbexe0xa4xa4 xe0xa4x85xefx8cxb7xe0xa4xb0xe0xa4xaaxefx91xa9xe0xa4xa4xe0xa5x80xe0xa4x9a xe0xa4xa8xe0xa4xb8xe0xa4xa4xe0xa4xbexe0xa4xa8xe0xa4xbe xefx8dx86xe0xa4xafxe0xa4xbe xe0xa4xadxe0xa4xbexe0xa4xb7xefx8cxbexe0xa4xafxe0xa4xbe xefx8cx94xe0xa4xb2xefx8cx9fxe0xa4x96xe0xa4xa4 xe0xa4xaaxe0xa4xbexe0xa4xa0 xefx96x84xe0xa4xbexe0xa4x9a xe0xa4xb5xe0xa4xbexe0xa4xa3xe0xa5x80 xe0xa4xb8xefx8dx9bxe0xa4xb2xe0xa4xb7xe0xa4xa3 xe0xa4x95xe0xa4xb0xefx8dx84xe0xa4xafxe0xa4xbexe0xa4x9a xe0xa4xa4xefx8dxae xe0xa4xb9 xefx8dx96xe0xa4xafxe0xa4xa5xefx8cx86 xe0xa4xb5xe0xa4xbexe0xa4x9f xe0xa4xb6xe0xa4x95xe0xa4xa4. xe0xa4xaaxe0xa4xa3 xefx8dxb4xefx8dx9bxe0xa4xa4xefx9dx93xe0xa4xa4 xe0xa4xb2xe0xa4x96xe0xa4xbexe0xa4xa4 xe0xa4x85xe0xa4xbexefx8dx90xe0xa4xb9xe0xa5x80 xe0xa4xafxe0xa4xbe xe0xa4xb8xefx8dx9bxe0xa4xb2xe0xa4xb7xe0xa4xa3 xefx8dxb4xe0xa4xa3xe0xa4xbexe0xa4xb2xefx8cxa6xe0xa4x9a xe0xa4x95xe0xa4xbexe0xa4xb9xe0xa5x80 xefx8dxb4xe0xa4xaexe0xa4x96 xe0xa4x89xe0xa4xaaxe0xa4xafxe0xa4xbexe0xa4x97 xe0xa4xb8xefx9dx93xe0xa4x9axe0xa4xb5xe0xa5x80xe0xa4xa4 xe0xa4x85xe0xa4xbexe0xa4xb9xe0xa4xbexe0xa4xa4. xe0xa4x95xe0xa4xb5xe0xa4xb3 xefx8dx88xe0xa4xb5xe0xa4xbfxe0xa4xa8xe0xa4xaexefx8cx9fxefx8dxb0xe0xa4xa4 xe0xa4xb5xe0xa4xbexefx90x8bxe0xa4xbexe0xa4x9axe0xa4xbe xe0xa4x95xe0xa4xbexe0xa4xb7 xe0xa4xb5xe0xa4xbexe0xa4xaaxefx95x95xe0xa4xa8 xe0xa4xb8xefx8dx9bxe0xa4xb2xefx8cx91xe0xa4xb7xe0xa4xa4 xe0xa4x85xe0xa4xbexe0xa4xb5xe0xa4xbexe0xa4x9c xe0xa4xacxe0xa4xa8xefx8cx91xe0xa4xb5xefx8dx84xe0xa4xafxe0xa4xbexe0xa4x9axe0xa5x80 xe0xa4x85xe0xa4xbexe0xa4xaexe0xa4x9axe0xa5x80 xe0xa4xaaxefx91xa9xe0xa4xa4 xe0xa4xafxe0xa4xbe xe0xa4xb2xe0xa4x96xe0xa4xbexe0xa4xa4 xe0xa4x85xe0xa4xbexe0xa4xaaxe0xa4xa3 xe0xa4xaaxe0xa4xbexefx95xa5. xe0xa4x85xe0xa4xbexefx8dx90xe0xa4xb9xe0xa5x80 xe0xa4x95xe0xa4xb2xe0xa4xb2 xefx8dxb4xe0xa4xafxe0xa4xbexe0xa4x97 xe0xa4xb5 xefx8cx91xe0xa4xb5xefx93xa1xe0xa4xb7xe0xa4xa3 xe0xa4x85xe0xa4xb8 xe0xa4xa6xe0xa4xb6xefx8cx86xefx8cx91xe0xa4xb5xe0xa4xa4xe0xa4xbexe0xa4xa4 xe0xa4x95xefx8cxaa xe0xa4x85xe0xa4xbexe0xa4xaaxe0xa4xa3 xe0xa4x8fxe0xa4x96xe0xa4xbexe0xa4xa6xefx8cxa1 xe0xa4x85xefx8cxb7xe0xa4xb0xe0xa4xaaxefx91xa9xe0xa4xa4xe0xa5x80 xe0xa4x85xe0xa4xbexe0xa4xaaxe0xa4xbexe0xa4x85xe0xa4xbexe0xa4xaa xe0xa4xb6xe0xa4xbexe0xa4xa7 xe0xa4xb6xe0xa4x95xe0xa4xa4xe0xa4xbe, xefx8cx9dxe0xa4x9cxe0xa4x9axe0xa4xbe xe0xa4xb5xe0xa4xbexe0xa4xaaxe0xa4xb0 xe0xa4x95xefx95x95xe0xa4xa8 xe0xa4x95xe0xa4xb2xe0xa4xb2 xe0xa4xb5xe0xa4xbexe0xa4xa3xe0xa5x80 xe0xa4xb8xefx8dx9bxe0xa4xb2xe0xa4xb7xe0xa4xa3 xe0xa4xb8xefx9dx93xe0xa4x97xe0xa4xae xe0xa4xb5 xe0xa4xb5xe0xa4xbexe0xa4xaaxe0xa4xb0xefx8dx84xe0xa4xafxe0xa4xbexe0xa4x9cxe0xa4xbexe0xa4x97 xe0xa4x85xe0xa4xb8xe0xa4xa4."
W11-2002,Spoken Dialog Challenge 2010: Comparison of Live and Control Test Results,2011,8,49,1,1,4130,alan black,Proceedings of the {SIGDIAL} 2011 Conference,0,"The Spoken Dialog Challenge 2010 was an exercise to investigate how different spoken dialog systems perform on the same task. The existing Let's Go Pittsburgh Bus Information System was used as a task and four teams provided systems that were first tested in controlled conditions with speech researchers as users. The three most stable systems were then deployed to real callers. This paper presents the results of the live tests, and compares them with the control test results. Results show considerable variation both between systems and between the control and live tests. Interestingly, relatively high task completion for controlled tests did not always predict relatively high task completion for live tests. Moreover, even though the systems were quite different in their designs, we saw very similar correlations between word error rate and task completion for all the systems. The dialog data collected is available to the research community."
I11-1006,Discriminative Phrase-based Lexicalized Reordering Models using Weighted Reordering Graphs,2011,13,3,5,1,13846,wang ling,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Lexicalized reordering models play a central role in phrase-based statistical machine translation systems. Starting from the distance-based reordering model, improvements have been made by considering adjacent words in word-based models, adjacent phrases pairs in phrasebased models, and finally, all phrases pairs in a sentence pair in the reordering graphs. However, reordering graphs treat all phrase pairs equally and fail to weight the relationships between phrase pairs. In this work, we propose an extension to the reordering models, named weighted reordering models, that allows discriminative behavior to be defined in the estimation of the reordering model orientations. We apply our extension using the weighted alignment matrices to weight phrase pairs, based on the consistency of their alignments, and define a distance metric to weight relationships between phrase pairs, based on their distance in the sentence. Experiments on the IWSLT 2010 evaluation dataset for for the Chinese-English language pair yields an improvement of 0.38 (2%) and 0.94 (3.7%) BLEU points over the state-of-the-art workxe2x80x99s results using weighted alignment matrices."
2011.iwslt-papers.3,Named entity translation using anchor texts,2011,11,10,5,1,13846,wang ling,Proceedings of the 8th International Workshop on Spoken Language Translation: Papers,0,"This work describes a process to extract Named Entity (NE) translations from the text available in web links (anchor texts). It translates a NE by retrieving a list of web documents in the target language, extracting the anchor texts from the links to those documents and finding the best translation from the anchor texts, using a combination of features, some of which, are specific to anchor texts. Experiments performed on a manually built corpora, suggest that over 70{\%} of the NEs, ranging from unpopular to popular entities, can be translated correctly using sorely anchor texts. Tests on a Machine Translation task indicate that the system can be used to improve the quality of the translations of state-of-the-art statistical machine translation systems."
W10-4318,Towards Improving the Naturalness of Social Conversations with Dialogue Systems,2010,9,8,3,0,1549,matthew marge,Proceedings of the {SIGDIAL} 2010 Conference,0,"We describe an approach to improving the naturalness of a social dialogue system, Talkie, by adding disfluencies and other content-independent enhancements to synthesized conversations. We investigated whether listeners perceive conversations with these improvements as natural (i.e., human-like) as human-human conversations. We also assessed their ability to correctly identify these conversations as between humans or computers. We find that these enhancements can improve the perceived naturalness of conversations for observers overhearing the dialogues."
W09-3950,The Spoken Dialogue Challenge,2009,5,13,1,1,4130,alan black,Proceedings of the {SIGDIAL} 2009 Conference,0,"In the field of speech and language processing the introduction of Challenges has helped focus the focus a field, allowing detailed comparisons of systems and techniques, bringing new members into the field, and facilitating advancements in core research. Although the idea of a spoken dialogue challenge has been discussed for some time, this is the first attempt to bring these discussions together and take concrete action."
N09-2038,Incremental Adaptation of Speech-to-Speech Translation,2009,9,11,9,0.555556,9067,nguyen bach,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"In building practical two-way speech-to-speech translation systems the end user will always wish to use the system in an environment different from the original training data. As with all speech systems, it is important to allow the system to adapt to the actual usage situations. This paper investigates how a speech-to-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two. The platform is the CMU Iraqi-English portable two-way speech-to-speech system as developed under the DARPA TransTac program. We show how machine translation, speech recognition and overall system performance can be improved on day 2 after adapting from day 1 in both a supervised and unsupervised way."
W08-1509,Speech Translation for Triage of Emergency Phonecalls in Minority Languages,2008,9,0,2,0,14460,udhyakumar nallasamy,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,"We describe Ayudame, a system designed to recognize and translate Spanish emergency calls for better dispatching. We analyze the research challenges in adapting speech translation technology to 9-1-1 domain. We report our initial research in 9-1-1 translation system design, ASR experiments, and utterance classification for translation."
P08-5002,Building Practical Spoken Dialog Systems,2008,0,1,3,0.436516,30422,antoine raux,Tutorial Abstracts of ACL-08: HLT,0,"This tutorial will give a practical description of the free software Carnegie Mellon Olympus 2 Spoken Dialog Architecture. Building real working dialog systems that are robust enough for the general public to use is difficult. Most frequently, the functionality of the conversations is severely limited - down to simple question-answer pairs. While off-the-shelf toolkits help the development of such simple systems, they do not support more advanced, natural dialogs nor do they offer the transparency and flexibility required by computational linguistic researchers. However, Olympus 2 offers a complete dialog system with automatic speech recognition (Sphinx) and synthesis (SAPI, Festival) and has been used, along with previous versions of Olympus, for teaching and research at Carnegie Mellon and elsewhere for some 5 years. Overall, a dozen dialog systems have been built using various versions of Olympus, handling tasks ranging from providing bus schedule information to guidance through maintenance procedures for complex machinery, to personal calendar management. In addition to simplifying the development of dialog systems, Olympus provides a transparent platform for teaching and conducting research on all aspects of dialog systems, including speech recognition and synthesis, natural language understanding and generation, and dialog and interaction management.n n The tutorial will give a brief introduction to spoken dialog systems before going into detail about how to create your own dialog system within Olympus 2, using the Let's Go bus information system as an example. Further, we will provide guidelines on how to use an actual deployed spoken dialog system such as Let's Go to validate research results in the real world. As a possible testbed for such research, we will describe Let's Go Lab, which provides access to both the Let's Go system and its genuine user population for research experiments."
nallasamy-etal-2008-nineoneone,{N}ine{O}ne{O}ne: Recognizing and Classifying Speech for Handling Minority Language Emergency Calls,2008,11,3,2,0,14460,udhyakumar nallasamy,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper, we describe NineOneOne (9-1-1), a system designed to recognize and translate Spanish emergency calls for better dispatching. We analyze the research challenges in adapting speech translation technology to 9-1-1 domain. We report our initial research towards building the system and the results of our initial experiments."
2007.iwslt-1.4,The {CMU} {T}rans{T}ac 2007 eyes-free two-way speech-to-speech translation system,2007,17,22,11,0.555556,9067,nguyen bach,Proceedings of the Fourth International Workshop on Spoken Language Translation,0,"The paper describes our portable two-way speech-to-speech translation system using a completely eyes-free/hands-free user interface. This system translates between the language pair English and Iraqi Arabic as well as between English and Farsi, and was built within the framework of the DARPA TransTac program. The Farsi language support was developed within a 90-day period, testing our ability to rapidly support new languages. The paper gives an overview of the system{'}s components along with the individual component objective measures and a discussion of issues relevant for the overall usage of the system. We found that usability, flexibility, and robustness serve as severe constraints on system architecture and design."
N06-1030,Learning Pronunciation Dictionaries: Language Complexity and Word Selection Strategies,2006,7,23,2,0,41825,john kominek,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,The speed with which pronunciation dictionaries can be bootstrapped depends on the efficiency of learning algorithms and on the ordering of words presented to the user. This paper presents an active-learning word selection strategy that is mindful of human limitations. Learning rates approach that of an oracle system that knows the final LTS rule set.
N04-3010,A {T}hai Speech Translation System for Medical Dialogs,2004,4,16,3,0,14741,tanja schultz,Demonstration Papers at {HLT}-{NAACL} 2004,0,"In this paper we present our activities towards a Thai Speech-to-Speech translation system. We investigated in the design and implementation of a prototype system. For this purpose we carried out research on bootstrapping a Thai speech recognition system, developing a translation component, and building an initial Thai synthesis system using our existing tools."
N03-4015,{S}peechalator: Two-Way Speech-to-Speech Translation in Your Hand,2003,2,20,3,0,5073,alex waibel,Companion Volume of the Proceedings of {HLT}-{NAACL} 2003 - Demonstrations,0,"This demonstration involves two-way automatic speech-to-speech translation on a consumer off-the-shelf PDA. This work was done as part of the DARPA-funded Babylon project, investigating better speech-to-speech translation systems for communication in the field. The development of the Speechalator software-based translation system required addressing a number of hard issues, including a new language for the team (Egyptian Arabic), close integration on a small device, computational efficiency on a limited platform, and scalable coverage for the domain."
W02-0711,Speech Translation on a Tight Budget without Enough Data,2002,11,3,2,0,39652,robert frederking,Proceedings of the {ACL}-02 Workshop on Speech-to-Speech Translation: Algorithms and Systems,0,"The Tongues speech-to-speech translation system was developed for the US Army chaplains, with fairly stringent constraints on time, budget, and available data. The resulting prototype was required to undergo a quite realistic field test. We describe the development and architecture of the system, the field test, and our analysis of its results. The system performed quite well, especially given its development constraints."
font-llitjos-black-2002-evaluation,Evaluation and collection of proper name pronunciations online,2002,5,10,2,0,48477,ariadna llitjos,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,None
frederking-etal-2002-field,Field Testing the Tongues Speech-to-Speech Machine Translation System,2002,5,12,2,0,39652,robert frederking,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The Tongues portable, rapid-development, speech-to-speech machine translation system was developed specifically to allow a realistic field-test of a deployable prototype. In this paper we will describe the system, its field-testing using regular US Army officers and naive Croatians, and the evaluation of these tests. The evaluation includes analysis of answers to a questionnaire, analysis of system transcript logs, and the authorsxe2x80x99 qualitative observations. The overall result of the test was that while the system did successfully aid translation, it requires further development before it would be ready for regular field use. 1. The Tongues System The Tongues system was funded by the US Army to support the mission of the US Army chaplains, who are increasingly called upon to deal with local populations, usually without the benefit of human translators. It is thus intended to be used by a trained US Army chaplain with a completely naive and untrained non-English speaker. The architecture and user interface of the Tongues system were based in large measure on the Diplomat system (Frederking et al., 2000). The speech recognition system used was the open-source Sphinx II (Huang et al., 1992); the translation system was a EBMT/MEMT (ExampleBased MT/Multi-Engine MT) system (Brown, 1996; Frederking and Nirenburg, 1994; Brown and Frederking, 1995) very similar to that in Diplomat; and the synthesis system was the open-source Festival (Black et al., 1998). While the initial system was specifically to demonstrate translation in both directions between English and Croatian, the design was also required to allow rapid development for new languages. To ensure rapid development, the entire project was only allowed to take one calendar year, including contractual arrangements, hiring language experts, etc. The total development effort was similarly restricted: six senior research personnel (the authors of this paper) provided an estimated total of about two (2) fulltime person-years of effort. In addition to the senior staff, there were also part-time Croatian informants, chaplains, and some student programmers. We should note that some of the translation data used to train the system was collected for the Diplomat project (Frederking et al., 2000). In addition to rapid development, the system was not permitted to be restricted to a narrowly-limited domain, but had to be wide-coverage. (Both of these properties were important for the chaplainsxe2x80x99 envisioned activities.) Since we were to build a broad-coverage system in a short period of time on a small budget, data-driven approaches were the only reasonable choice. In order to provide in-domain conversational data, we arranged at the start of the project to record a number of chaplains in role-playing conversations of the type they expected the device to encounter. Fortunately, the chaplains were familiar with role-playing exercises, and all had relevant field experiences to re-enact. Both sides of the conversations were spoken in English. These were digitally recorded with head-mounted microphones at 16KHz in stereo (one speaker on each channel), as this was closest to the intended audio channel characteristics of the eventual system. In all, we recorded 46 conversations, ranging from a few minutes to 20 minutes length. This provided a total of 4.25 hours of actual speech. The recorded conversations were hand-transcribed at the word level, and translated into Croatian by native Croatian speakers. The English recordings were used for training the English speech recognition models. The transcripts and their translations were added to the EBMT systemxe2x80x99s example base of parallel sentences. A subset of the Croatian translations were read by native Croatian speakers to create data for the Croatian speech recognizer, as described elsewhere (Black et al., 2002). This simple approach appears to be surprisingly adequate. Simply stringing together a recognizer, translator, and synthesizer does not make a very useful speech-to-speech translation system. A good interface is necessary to make the parts work together in such a way that a user can actually derive benefit from it. Using our experience from the earlier Diplomat system, we designed the Tongues interface to be asymmetric, with the Croatian side being as simple as possible, and any necessary complexity handled on the English side, since the chaplain would be trained and practiced in using the system. Even the English side was not terribly complex (see Figure 1). We included a back-translation capability, to allow a user with no knowledge of the target language to better assess the quality of the translation. (We could not use the approach of generating paraphrases from meaning representations, since the system does not use any meaning representations.) We also included several user-requested features, such as built-in pre-recorded instructions and explanations for the Croatian (since the Croatian speaker is completely naive regarding the device and the chaplainxe2x80x99s intentions), emergency key phrases (such as xe2x80x9cDonxe2x80x99t move!xe2x80x9d), and enhancements such as being able to modify the translation lexicon in the field, so that the system could be tuned to more specific tasks. The final system ran on a Windows-based Toshiba Libretto, running at 200MHz with 192MB of memory. At the time of the project (2000) this was the best combination of speed and size that was readily available. The system was equipped with a custom touchscreen, so that the Croatian-speaker would not need to type or use a mouse at all. Aware that the system might be used in situations where the non-English participant would be unfamiliar with computer technology, we included a microphone/speaker handset that looks like a conventional telephone handset. This has the advantage of provided a close-talking microphone, thus making speech recognition easier, while coming in a form factor that will be familiar to most people. We have provided a more detailed description of the development of the Tongues system elsewhere (Black et al., 2002). Our design provides abundant opportunities for user error correction, in an effort to enable cooperative users to communicate well enough to accomplish significant tasks that they could not accomplish without the system (or a bilingual human interpreter), despite the error-prone nature of current speech recognition, broad-coverage rapiddevelopment machine translation, and speech synthesis. Determining whether we have met such a goal requires task-based evaluation; while error rates of components are useful information, the real system-level issue is whether communication is achieved, and at what level of effort. Figure 1: Tongues User Interface."
C94-2158,{CHATR}: a generic speech synthesis system,1994,4,76,1,1,4130,alan black,{COLING} 1994 Volume 2: The 15th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper describes a generic speech synthesis system called CHATR which is being developed at ATR. CHATR is designed in a modular way so that module parameters and even which modules are actually used may be set and selected at runtime. Although some interdependencies exist between modules, CHATR offers a useful research tool in which functionally equivalent modules may be easily compared. It also acts as a simple system for those less interested in the internals of speech synthesis but just wish their computer to talk."
C92-4175,Embedding {DRT} in a Situation Theoretic Framework,1992,5,1,1,1,4130,alan black,{COLING} 1992 Volume 4: The 14th {I}nternational {C}onference on {C}omputational {L}inguistics,0,"This paper proposes the use of situation theory as a basic semantic formalism for defining general semantic theories. ASTL, a computational situation theoretic language, is described which goes some way to offering such a system. After a general description of Discourse Representation Theory an encoding of DRT in ASTL is given. Advantages and disadvantages of this method are then discussed."
E91-1018,Analysis of Unknown Words through Morphological Decomposition,1991,4,14,1,1,4130,alan black,Fifth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,This paper describes a method of analysing words through morphological decomposition when the lexicon is incomplete. The method is used within a text-to-speech system to help generate pronunciations of unknown words. The method is achieved within a general morphological analyser system using Koskenniemi two-level rules.
W89-0229,Finite State Machines from Feature Grammars,1989,0,22,1,1,4130,alan black,Proceedings of the First International Workshop on Parsing Technologies,0,"This paper describes the conversion of a set of feature grammar rules into a deterministic finite state machine that accepts the same language (or at least a well-defined related language). First the reasoning behind why this is an interesting thing to do within the Edinburgh speech recogniser project, is discussed. Then details about the compilation algorithm are given. Finally, there is some discussion of the advantages and disadvantages of this method of implementing feature based grammar formalisms."
J87-3008,A Computational Framework for Lexical Description,1987,9,23,3,0,47097,graeme ritchie,Computational Linguistics,0,"To achieve generality, natural language parsers require dictionaries which handle lexical information in a linguistically motivated but computationally viable manner. Various rule formalisms are presented which process orthographic effects, word structure, and lexicai redundancy in a manner which allows the statement of linguistic generalisations with a clear computational interpretation. A compact description of a medium-sized subset of the English lexicon can be stated using these formalisms. The proposed mechanisms have been implemented and tested, but require to be refined further if they are to be regarded as an interesting linguistic theory."
E87-1003,Formalisms for Morphographemic Description,1987,7,16,1,1,4130,alan black,Third Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"Recently there has been some interest in rule formalisms for describing morphologically significant regularities in orthography of words, largely influenced by the work of Koskenniemi. Various implementations of these rules are possible, but there are some weaknesses in the formalism as it stands. An alternative specification formalism is possible which solves some of the problems. This new formalism can be viewed as a variant of the pure Koskenniemi model with certain constraints relaxed. The new formalism has particular advantages for multiple character changes. An interpreter has been implemented for the formalism and a significant subset of English morphographemics has been described, but it has yet to be used for describing other languages."
