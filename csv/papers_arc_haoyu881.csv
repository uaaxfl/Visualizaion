2021.findings-emnlp.248,Lexicon-Based Graph Convolutional Network for {C}hinese Word Segmentation,2021,-1,-1,2,0,7029,kaiyu huang,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Precise information of word boundary can alleviate the problem of lexical ambiguity to improve the performance of natural language processing (NLP) tasks. Thus, Chinese word segmentation (CWS) is a fundamental task in NLP. Due to the development of pre-trained language models (PLM), pre-trained knowledge can help neural methods solve the main problems of the CWS in significant measure. Existing methods have already achieved high performance on several benchmarks (e.g., Bakeoff-2005). However, recent outstanding studies are limited by the small-scale annotated corpus. To further improve the performance of CWS methods based on fine-tuning the PLMs, we propose a novel neural framework, LBGCN, which incorporates a lexicon-based graph convolutional network into the Transformer encoder. Experimental results on five benchmarks and four cross-domain datasets show the lexicon-based graph convolutional network successfully captures the information of candidate words and helps to improve performance on the benchmarks (Bakeoff-2005 and CTB6) and the cross-domain datasets (SIGHAN-2010). Further experiments and analyses demonstrate that our proposed framework effectively models the lexicon to enhance the ability of basic neural frameworks and strengthens the robustness in the cross-domain scenario."
I13-1109,Semi-supervised Classification of {T}witter Messages for Organization Name Disambiguation,2013,19,2,5,1,35774,shu zhang,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"In this paper, we probe the problem of organization name disambiguation on twitter messages. This task is challenging due to the fact of lacking sufficient information in a tweet message. Instead of conventional methods based on mining external information from web sources to enrich information about organization, we propose to mine the relationship among tweets in data set to utilize context information for disambiguation. With a small scale of labeled tweets, we propose LP-based and TSVM-based semi-supervised methods to classify tweets. We aim to mine both related and non-related information for a given organization. The experiments on WePS-3 show that proposed methods are effective."
Y12-1010,Extracting and Visualizing Semantic Relationships from {C}hinese Biomedical Text,2012,21,9,4,0,33264,qingliang miao,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"In this paper, we study how to automatically extract and visualize food (or nutrition) and disease relationships from Chinese publications of Nutritional Genomics. Different from previous approaches that mostly apply handcrafted rules or co-occurrence patterns, we propose an approach using probabilistic models and domain knowledge. In particular, we first utilize encyclopedia to construct a domain knowledge base, and then develop a sentence simplification model to simplify complicated sentences we meet. Afterwards, we treat relation extraction issue as a sequence labeling task and adopt Conditional Random Fields (CRFs) models to extract food and disease relationships. Finally, these relationships are visualized. Experimental results on real-world datasets show that the proposed approach is effective."
Y12-1012,Improving {C}hinese-to-{J}apanese Patent Translation Using {E}nglish as Pivot Language,2012,27,1,3,0,41957,xianhua li,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"This paper implements and compares three different strategies to use English as pivot language for Chinese-Japanese patent translation: corpus enrichment, sentence pivot translation and phrase pivot translation. Our results show that both corpus enrichment and phrase pivot translation strategy outperform the baseline system, while the sentence pivot translation strategy failed to improve the system. We apply the strategies on large data set and figure out approaches to improve efficiency. Finally, we perform Minimum Bayes Risk system combination on the different results of direct translation system and pivot translation systems, which significantly outperforms the direct translation system by 4.25 BLEU scores."
Y12-1025,An Adaptive Method for Organization Name Disambiguation with Feature Reinforcing,2012,15,4,5,1,35774,shu zhang,"Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation",0,"Twitter is an online social networking, which has become an important source of information for marketing strategies and online reputation management. In this paper, we probe the problem of organization name disambiguation on twitter messages. This task is challenging due to the fact of lacking sufficient information both from organization and the tweets. We mine organization information from web sources to train a general classifier. Further, we mine tweets information. We train an adaptive classifier for a given organization name with more features derived from twitter messages labeled by the general classifier. The experiments on WePS-3 show mining web sources to enrich organization are effective. The adaptive classifier trained for a given organization is promising."
Y11-1010,Automatic Wrapper Generation and Maintenance,2011,29,3,4,1,36299,yingju xia,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"This paper investigates automatic wrapper generation and maintenance for Forums, Blogs and News web sites. Web pages are increasingly dynamically generated using a common template populated with data from databases. This paper proposes a novel method that uses tree alignment and transfer learning method to generate the wrapper from this kind of web pages. The tree alignment algorithm is adopted to find the best matching structure of the input web pages. A kind of linear regression method is employed to get the weight of different tag-matching. A transfer learning method is adopted to find the most likely content block. A wrapper built on the most probable content block and the repeating patterns extracts data from web pages. The wrapper maintenance arises because web source may experiment changes that invalidate the current wrappers. This paper presents a wrapper maintenance method using a log likelihood ratio test for detecting the change points on the similarity series which gotten from the wrapper and input web pages. The wrapper generation method is applied to generate a wrapper once the web source change is detected. Experimental results show that the method achieves high accuracy and has steady performance"
Y11-1023,Maximum Entropy Based Lexical Reordering Model for Hierarchical Phrase-based Machine Translation,2011,18,0,3,0,33266,zhongguang zheng,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"The hierarchical phrase-based (HPB) model on the basis of a synchronous context-free grammar (SCFG) is prominent in solving global reorderings. However, the HPB model is inadequate to supervise the reordering process so that sometimes positions of different lexicons are switched due to the incorrect SCFG rules. In this paper, we consider the order of two lexicons as a classification problem and propose a novel lexical reordering model based on a maximum entropy classifier. Our model employs the word alignment and translation during the decoding process. Experimental results on the Chinese-to-English task showed that our method outperformed the baseline system in BLEU score significantly. Moreover, the translation results further proved the effectiveness of our approach."
Y11-1066,Supervised and Semi-supervised Methods based Organization Name Disambiguity,2011,11,1,2,1,35774,shu zhang,"Proceedings of the 25th Pacific Asia Conference on Language, Information and Computation",0,"Twitter is a widespread social media, which rapidly gained worldwide popularity. Pursuing on the problem of finding related tweets to a given organization, we propose supervised and semi-supervised based methods. This is a challenging task due to the potential organization name ambiguity. The tweets and organization contain little information. The organizations in training data are different with those in test data, which leads that we could not train a classifier to a certain organization. Therefore, we induce external resources to enrich the information of organization. Supervised and semi- supervised methods are adopted in two stages to classify the tweets. This is a try to utilize both training and test data for this specific task. Our experimental results on WePS-3 are primary and encouraging, they prove the proposed techniques are effective in performing the task."
2011.mtsummit-wpt.4,Feedback Selecting of Manually Acquired Rules Using Automatic Evaluation,2011,-1,-1,5,0,41957,xianhua li,Proceedings of the 4th Workshop on Patent Translation,0,None
2011.mtsummit-papers.44,Lexical-based Reordering Model for Hierarchical Phrase-based Machine Translation,2011,18,0,3,0,33266,zhongguang zheng,Proceedings of Machine Translation Summit XIII: Papers,0,"The hierarchical phrase-based (HPB) model on the basis of a synchronous context-free grammar (SCFG) is prominent in solving global reorderings. However, the HPB model is inadequate to supervise the reordering process so that sometimes positions of different lexicons are switched due to the incorrect SCFG rules. In this paper, we consider the order of two lexicons as a classification problem and propose a novel lexical reordering model based on a maximum entropy classifier. Our model employs the word alignment and translation during the decoding process. Experimental results on the Chinese-to-English task showed that our method outperformed the baseline system in BLEU score significantly. Moreover, the translation results further proved the effectiveness of our approach."
Y10-1036,Fault-Tolerant Learning for Term Extraction,2010,21,2,2,1,43936,yuhang yang,"Proceedings of the 24th Pacific Asia Conference on Language, Information and Computation",0,This paper presents the Fault-Tolerant Learning approach for term extraction. The approach extract s terms using automatically generated seeds instead of prior domain knowledge or annotated corpora. Thus it is applicable to any domain specific corpus and it is especially useful for resource-limited domains. Two classifiers are separately trained for prediction and verification to ensure the performance of the proposed approach. Evaluations conducted on two different domains for Chinese term extraction show significant improvements over existing techniques and also verify the efficiency and relative domain independent nature of the approach.
zhang-etal-2010-extracting,Extracting Product Features and Sentiments from {C}hinese Customer Reviews,2010,9,5,5,1,35774,shu zhang,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"With the growing interest in opinion mining from web data, more works are focused on mining in English and Chinese reviews. Probing into the problem of product opinion mining, this paper describes the details of our language resources, and imports them into the task of extracting product feature and sentiment task. Different from the traditional unsupervised methods, a supervised method is utilized to identify product features, combining the domain knowledge and lexical information. Nearest vicinity match and syntactic tree based methods are proposed to identify the opinions regarding the product features. Multi-level analysis module is proposed to determine the sentiment orientation of the opinions. With the experiments on the electronic reviews of COAE 2008, the validities of the product features identified by CRFs and the two opinion words identified methods are testified and compared. The results show the resource is well utilized in this task and our proposed method is valid."
D10-1054,Maximum Entropy Based Phrase Reordering for Hierarchical Phrase-Based Translation,2010,17,16,3,1,6457,zhongjun he,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"Hierarchical phrase-based (HPB) translation provides a powerful mechanism to capture both short and long distance phrase reorderings. However, the phrase reorderings lack of contextual information in conventional HPB systems. This paper proposes a context-dependent phrase reordering approach that uses the maximum entropy (MaxEnt) model to help the HPB decoder select appropriate reordering patterns. We classify translation rules into several reordering patterns, and build a MaxEnt model for each pattern based on various contextual features. We integrate the MaxEnt models into the HPB model. Experimental results show that our approach achieves significant improvements over a standard HPB system on large-scale translation tasks. On Chinese-to-English translation, the absolute improvements in BLEU (case-insensitive) range from 1.2 to 2.1."
C10-2044,Learning Phrase Boundaries for Hierarchical Phrase-based Translation,2010,18,5,3,1,6457,zhongjun he,Coling 2010: Posters,0,"Hierarchical phrase-based models provide a powerful mechanism to capture non-local phrase reorderings for statistical machine translation (SMT). However, many phrase reorderings are arbitrary because the models are weak on determining phrase boundaries for pattern-matching. This paper presents a novel approach to learn phrase boundaries directly from word-aligned corpus without using any syntactical information. We use phrase boundaries, which indicate the beginning/ending of phrase reordering, as soft constraints for decoding. Experimental results and analysis show that the approach yields significant improvements over the baseline on large-scale Chinese-to-English translation."
C10-1074,Structure-Aware Review Mining and Summarization,2010,24,180,7,0,20931,fangtao li,Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),0,"In this paper, we focus on object feature based review summarization. Different from most of previous work with linguistic rules or statistical methods, we formulate the review mining task as a joint structure tagging problem. We propose a new machine learning framework based on Conditional Random Fields (CRFs). It can employ rich features to jointly extract positive opinions, negative opinions and object features for review sentences. The linguistic structure can be naturally integrated into model representation. Besides linear-chain structure, we also investigate conjunction structure and syntactic tree structure in this framework. Through extensive experiments on movie review and product review data sets, we show that structure-aware models outperform many state-of-the-art approaches to review mining."
2010.amta-papers.25,Extending the Hierarchical Phrase Based Model with Maximum Entropy Based {BTG},2010,-1,-1,3,1,6457,zhongjun he,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"In the hierarchical phrase based (HPB) translation model, in addition to hierarchical phrase pairs extracted from bi-text, glue rules are used to perform serial combination of phrases. However, this basic method for combining phrases is not sufficient for phrase reordering. In this paper, we extend the HPB model with maximum entropy based bracketing transduction grammar (BTG), which provides content-dependent combination of neighboring phrases in two ways: serial or inverse. Experimental results show that the extended HPB system achieves absolute improvements of 0.9â¼1.8 BLEU points over the baseline for large-scale translation tasks."
Y09-2017,A Bootstrapping Method for Finer-Grained Opinion Mining Using Graph Model,2009,11,3,4,1,35774,shu zhang,"Proceedings of the 23rd Pacific Asia Conference on Language, Information and Computation, Volume 2",0,"Pursuing on the analysis of product reviews, a bootstrapping method is proposed to find the product features and opinion words in iterative steps. Different from conventional methods, a graph model is built to link and measure the relationship between the pairs of product features and opinion words. A rule-based method is presented to get the initial seeds of product features and opinion words automatically. Our experimental results on electronic product reviews are encouraging, which prove the proposed method and techniques are effective in performing this task of feature level opinion mining."
P09-2031,Reducing {SMT} Rule Table with Monolingual Key Phrase,2009,6,5,4,1,6457,zhongjun he,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"This paper presents an effective approach to discard most entries of the rule table for statistical machine translation. The rule table is filtered by monolingual key phrases, which are extracted from source text using a technique based on term extraction. Experiments show that 78% of the rule table is reduced without worsening translation performance. In most cases, our approach results in measurable improvements in BLEU score."
P09-2054,{C}hinese Term Extraction Using Different Types of Relevance,2009,13,8,5,1,43936,yuhang yang,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"This paper presents a new term extraction approach using relevance between term candidates calculated by a link analysis based method. Different types of relevance are used separately or jointly for term verification. The proposed approach requires no prior domain knowledge and no adaptation for new domains. Consequently, the method can be used in any domain corpus and it is especially useful for resource-limited domains. Evaluations conducted on two different domains for Chinese term extraction show significant improvements over existing techniques and also verify the efficiency and relative domain independent nature of the approach."
I08-2081,Dimensionality Reduction with Multilingual Resource,2008,20,0,2,1,36299,yingju xia,Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-{II},0,"Query and document representation is a key problem for information retrieval and filtering. The vector space model (VSM) has been widely used in this domain. But the VSM suffers from high dimensionality. The vectors built from documents always have high dimensionality and contain too much noise. In this paper, we present a novel method that reduces the dimensionality using multilingual resource. We introduce a new metric called TC to measure the term consistency constraints. We deduce a TC matrix from the multilingual corpus and then use this matrix together with the termby-document matrix to do the Latent Semantic Indexing (LSI). By adopting different TC threshold, we can truncate the TC matrix into small size and thus lower the computational cost of LSI. The experimental results show that this dimensionality reduction method improves the retrieval performance significantly."
P06-2026,{C}hinese-{E}nglish Term Translation Mining Based on Semantic Prediction,2006,10,19,2,0,49914,gaolin fang,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Using abundant Web resources to mine Chinese term translations can be applied in many fields such as reading/writing assistant, machine translation and cross-language information retrieval. In mining English translations of Chinese terms, how to obtain effective Web pages and evaluate translation candidates are two challenging issues. In this paper, the approach based on semantic prediction is first proposed to obtain effective Web pages. The proposed method predicts possible English meanings according to each constituent unit of Chinese term, and expands these English items using semantically relevant knowledge for searching. The refined related terms are extracted from top retrieved documents through feedback learning to construct a new query expansion for acquiring more effective Web pages. For obtaining a correct translation list, a translation evaluation method in the weighted sum of multi-features is presented to rank these candidates estimated from effective Web pages. Experimental results demonstrate that the proposed method has good performance in Chinese-English term translation acquisition, and achieves 82.9% accuracy."
P06-2106,Infrastructure for Standardization of {A}sian Language Resources,2006,10,18,9,0,301,takenobu tokunaga,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"As an area of great linguistic and cultural diversity, Asian language resources have received much less attention than their western counterparts. Creating a common standard for Asian language resources that is compatible with an international standard has at least three strong advantages: to increase the competitive edge of Asian countries, to bring Asian countries to closer to their western counterparts, and to bring more cohesion among Asian countries. To achieve this goal, we have launched a two year project to create a common standard for Asian language resources. The project is comprised of four research items, (1) building a description framework of lexical entries, (2) building sample lexicons, (3) building an upper-layer ontology and (4) evaluating the proposed framework through an application. This paper outlines the project in terms of its aim and approach."
O05-5010,ãäººæ°æ¥å ±ãèªæåº«å½åå¯¦ä½åé¡çç ç©¶ (The {C}hinese Named Entity Categorization Based on the People{'}s Daily Corpus) [In {C}hinese],2005,6,0,2,1,36299,yingju xia,"International Journal of Computational Linguistics {\\&} {C}hinese Language Processing, Volume 10, Number 4, {D}ecember 2005: Special Issue on Selected Papers from {CLSW}-5",0,Named entity recognition is a very important part of information retrieval and information extraction. Classification is also very important. This paper investigates the sub-classification of named entities from the point of view of information retrieval and information extraction. This paper also presents multi-classification and gives detailed information about each sub-class. We have manually annotated people's daily corpus (1998) and conducted a serial of experiments using the statistical model of named entity recognition. The
I05-3006,Product Named Entity Recognition Based on Hierarchical Hidden {M}arkov Model,2005,12,12,5,0,26515,feifan liu,Proceedings of the Fourth {SIGHAN} Workshop on {C}hinese Language Processing,0,"A hierarchical hidden Markov model (HHMM) based approach of product named entity recognition (NER) from Chinese free text is presented in this paper. Characteristics and challenges in product NER is also investigated and analyzed deliberately compared with general NER. Within a unified statistical framework, the approach we proposed is able to make probabilistically reasonable decisions to a global optimization by leveraging diverse range of linguistic features and knowledge sources. Experimental results show that our approach performs quite well in two different domains."
I05-2003,A Hybrid {C}hinese Language Model based on a Combination of Ontology with Statistical Method,2005,15,1,4,1,36315,dequan zheng,Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts,0,"In this paper, we present a hybrid Chinese language model based on a combination of ontology with statistical method. In this study, we determined the structure of such a Chinese language model. This structure is firstly comprised of an ontology description framework for Chinese words and a representation of Chinese lingual ontology knowledge. Subsequently, a Chinese lingual ontology knowledge bank is automatically acquired by determining, for each word, its cooccurrence with semantic, pragmatics, and syntactic information from the training corpus and the usage of Chinese words will be gotten from lingual ontology knowledge bank for a actual document. To evaluate the performance of this language model, we completed two groups of experiments on texts reordering for Chinese information retrieval and texts similarity computing. Compared with previous works, the proposed method improved the precision of nature language processing."
I05-1048,A Lexicon-Constrained Character Model for {C}hinese Morphological Analysis,2005,17,0,2,1,9063,yao meng,Second International Joint Conference on Natural Language Processing: Full Papers,0,"This paper proposes a lexicon-constrained character model that combines both word and character features to solve complicated issues in Chinese morphological analysis. A Chinese character-based model constrained by a lexicon is built to acquire word building rules. Each character in a Chinese sentence is assigned a tag by the proposed model. The word segmentation and part-of-speech tagging results are then generated based on the character tags. The proposed method solves such problems as unknown word identification, data sparseness, and estimation bias in an integrated, unified framework. Preliminary experiments indicate that the proposed method outperforms the best SIGHAN word segmentation systems in the open track on 3 out of the 4 test corpora. Additionally, our method can be conveniently integrated with any other Chinese morphological systems as a post-processing module leading to significant improvement in performance."
I05-1087,Web-Based Terminology Translation Mining,2005,12,3,2,0,49914,gaolin fang,Second International Joint Conference on Natural Language Processing: Full Papers,0,"Mining terminology translation from a large amount of Web data can be applied in many fields such as reading/writing assistant, machine translation and cross-language information retrieval. How to find more comprehensive results from the Web and obtain the boundary of candidate translations, and how to remove irrelevant noises and rank the remained candidates are the challenging issues. In this paper, after reviewing and analyzing all possible methods of acquiring translations, a feasible statistics-based method is proposed to mine terminology translation from the Web. In the proposed method, on the basis of an analysis of different forms of term translation distributions, character-based string frequency estimation is presented to construct term translation candidates for exploring more translations and their boundaries, and then sort-based subset deletion and mutual information methods are respectively proposed to deal with subset redundancy information and prefix/suffix redundancy information formed in the process of estimation. Extensive experiments on two test sets of 401 and 3511 English terms validate that our system has better performance."
H05-1027,Minimum Sample Risk Methods for Language Modeling,2005,19,34,2,0,3502,jianfeng gao,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper proposes a new discriminative training method, called minimum sample risk (MSR), of estimating parameters of language models for text input. While most existing discriminative training methods use a loss function that can be optimized easily but approaches only approximately to the objective of minimum error rate, MSR minimizes the training error directly using a heuristic training procedure. Evaluations on the task of Japanese text input show that MSR can handle a large number of features and training samples; it significantly outperforms a regular trigram model trained using maximum likelihood estimation, and it also outperforms the two widely applied discriminative methods, the boosting and the perceptron algorithms, by a small but statistically significant margin."
H05-1054,{C}hinese Named Entity Recognition with Multiple Features,2005,0,0,4,0,4600,youzheng wu,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,None
C04-1104,Subcategorization Acquisition and Evaluation for {C}hinese Verbs,2004,10,10,4,0,32292,xiwu han,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"This paper describes the technology and an experiment of subcategorization acquisition for Chinese verbs. The SCF hypotheses are generated by means of linguistic heuristic information and filtered via statistical methods. Evaluation on the acquisition of 20 multi-pattern verbs shows that our experiment achieved the similar precision and recall with former researches. Besides, simple application of the acquired lexicon to a PCFG parser indicates great potentialities of subcategorization information in the fields of NLP."
W02-1613,Automatic Information Transfer between {E}nglish and {C}hinese,2002,1,0,2,0,12358,jianmin yao,{COLING}-02: Machine Translation in Asia,0,"The translation choice and transfer modules in an English Chinese machine translation system are introduced. The translation choice is realized on basis of a grammar tree and takes the context as a word bag, with the lexicon and POS tag information as context features. The Bayes minimal error probability is taken as the evaluation function of the candidate translation. The rule-based transfer and generation module takes the parsing tree as the input and operates on the information of POS tag, semantics or even the lexicon."
C02-1057,An Automatic Evaluation Method for Localization Oriented Lexicalised {EBMT} System,2002,11,4,4,0,12358,jianmin yao,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"To help developing a localization oriented EBMT system, an automatic machine translation evaluation method is implemented which adopts edit distance, cosine correlation and Dice coefficient as criteria. Experiment shows that the evaluation method distinguishes well between good translations and bad ones. To prove that the method is consistent with human evaluation, 6 MT systems are scored and compared. Theoretical analysis is made to validate the experimental results. Correlation coefficient and significance tests at 0.01 level are made to ensure the reliability of the results. Linear regression equations are calculated to map the automatic scoring results to human scorings."
W00-1211,Statistics Based Hybrid Approach to {C}hinese Base Phrase Identification,2000,3,20,5,0,1945,tiejun zhao,Second {C}hinese Language Processing Workshop,0,"This paper extends the base noun phrase (BNP) identification into a research on Chinese base phrase identification. After briefly introducing some basic concepts on Chinese base phrase, this paper presents a statistics based hybrid model for identifying 7 types of Chinese base phrases in view. Experiments show the efficiency of the proposed method in simplifying sentence structure. Significance of the research lies in it provides a solid foundation for the Chinese parser."
