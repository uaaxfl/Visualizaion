2021.starsem-1.8,"Teach the Rules, Provide the Facts: Targeted Relational-knowledge Enhancement for Textual Inference",2021,-1,-1,3,1,952,ohad rozen,Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics,0,"We present InferBert, a method to enhance transformer-based inference models with relevant relational knowledge. Our approach facilitates learning generic inference patterns requiring relational knowledge (e.g. inferences related to hypernymy) during training, while injecting on-demand the relevant relational facts (e.g. pangolin is an animal) at test time. We apply InferBERT to the NLI task over a diverse set of inference types (hypernymy, location, color, and country of origin), for which we collected challenge datasets. In this setting, InferBert succeeds to learn general inference patterns, from a relatively small number of training instances, while not hurting performance on the original NLI data and substantially outperforming prior knowledge enhancement models on the challenge data. It further applies its inferences successfully at test time to previously unobserved entities. InferBert is computationally more efficient than most prior methods, in terms of number of parameters, memory consumption and training time."
2021.mwe-1.1,A Long Hard Look at {MWE}s in the Age of Language Models,2021,-1,-1,1,1,954,vered shwartz,Proceedings of the 17th Workshop on Multiword Expressions (MWE 2021),0,"In recent years, language models (LMs) have become almost synonymous with NLP. Pre-trained to {``}read{''} a large text corpus, such models are useful as both a representation layer as well as a source of world knowledge. But how well do they represent MWEs? This talk will discuss various problems in representing MWEs, and the extent to which LMs address them: {\mbox{$\bullet$}} Do LMs capture the implicit relationship between constituents in compositional MWEs (from baby oil through parsley cake to cheeseburger stabbing)? {\mbox{$\bullet$}} Do LMs recognize when words are used nonliterally in non-compositional MWEs (e.g. do they know whether there are fleas in the flea market)? {\mbox{$\bullet$}} Do LMs know idioms, and can they infer the meaning of new idioms from the context as humans often do?"
2021.findings-emnlp.326,Uncovering Implicit Gender Bias in Narratives through Commonsense Inference,2021,-1,-1,3,0,7216,tenghao huang,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"Pre-trained language models learn socially harmful biases from their training corpora, and may repeat these biases when used for generation. We study gender biases associated with the protagonist in model-generated stories. Such biases may be expressed either explicitly ({``}women can{'}t park{''}) or implicitly (e.g. an unsolicited male character guides her into a parking space). We focus on implicit biases, and use a commonsense reasoning engine to uncover them. Specifically, we infer and analyze the protagonist{'}s motivations, attributes, mental states, and implications on others. Our findings regarding implicit biases are in line with prior work that studied explicit biases, for example showing that female characters{'} portrayal is centered around appearance, while male figures{'} focus on intellect."
2021.emnlp-main.564,Surface Form Competition: Why the Highest Probability Answer Isn{'}t Always Right,2021,-1,-1,3,0,4388,ari holtzman,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Large language models have shown promising results in zero-shot settings. For example, they can perform multiple choice tasks simply by conditioning on a question and selecting the answer with the highest probability. However, ranking by string probability can be problematic due to surface form competition{---}wherein different surface forms compete for probability mass, even if they represent the same underlying concept in a given context, e.g. {``}computer{''} and {``}PC.{''} Since probability mass is finite, this lowers the probability of the correct answer, due to competition from other strings that are valid answers (but not one of the multiple choice options). We introduce Domain Conditional Pointwise Mutual Information, an alternative scoring function that directly compensates for surface form competition by simply reweighing each option according to its a priori likelihood within the context of a specific task. It achieves consistent gains in zero-shot performance over both calibrated and uncalibrated scoring functions on all GPT-2 and GPT-3 models on a variety of multiple choice datasets."
2020.findings-emnlp.418,Thinking Like a Skeptic: Defeasible Inference in Natural Language,2020,-1,-1,2,0,8348,rachel rudinger,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Defeasible inference is a mode of reasoning in which an inference (X is a bird, therefore X flies) may be weakened or overturned in light of new evidence (X is a penguin). Though long recognized in classical AI and philosophy, defeasible inference has not been extensively studied in the context of contemporary data-driven research on natural language inference and commonsense reasoning. We introduce Defeasible NLI (abbreviated $\delta$-NLI), a dataset for defeasible inference in natural language. Defeasible NLI contains extensions to three existing inference datasets covering diverse modes of reasoning: common sense, natural language inference, and social norms. From Defeasible NLI, we develop both a classification and generation task for defeasible inference, and demonstrate that the generation task is much more challenging. Despite lagging human performance, however, generative models trained on this data are capable of writing sentences that weaken or strengthen a specified inference up to 68{\%} of the time."
2020.findings-emnlp.440,Paraphrasing vs Coreferring: Two Sides of the Same Coin,2020,25,0,3,0,19976,yehudit meged,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"We study the potential synergy between two different NLP tasks, both confronting predicate lexical variability: identifying predicate paraphrases, and event coreference resolution. First, we used annotations from an event coreference dataset as distant supervision to re-score heuristically-extracted predicate paraphrases. The new scoring gained more than 18 points in average precision upon their ranking by the original scoring method. Then, we used the same re-ranking features as additional inputs to a state-of-the-art event coreference resolution model, which yielded modest but consistent improvements to the model{'}s performance. The results suggest a promising direction to leverage data and models for each of the tasks to the benefit of the other."
2020.emnlp-main.48,Social Chemistry 101: Learning to Reason about Social and Moral Norms,2020,-1,-1,3,0,8745,maxwell forbes,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Social norms{---}the unspoken commonsense rules about acceptable social behavior{---}are crucial in understanding the underlying causes and intents of people{'}s actions in narratives. For example, underlying an action such as {``}wanting to call cops on my neighbor{''} are social norms that inform our conduct, such as {``}It is expected that you report crimes.{''} We present SOCIAL CHEMISTRY, a new conceptual formalism to study people{'}s everyday social norms and moral judgments over a rich spectrum of real life situations described in natural language. We introduce SOCIAL-CHEM-101, a large-scale corpus that catalogs 292k rules-of-thumb such as {``}It is rude to run a blender at 5am{''} as the basic conceptual units. Each rule-of-thumb is further broken down with 12 different dimensions of people{'}s judgments, including social judgments of good and bad, moral foundations, expected cultural pressure, and assumed legality, which together amount to over 4.5 million annotations of categorical labels and free-text descriptions. Comprehensive empirical results based on state-of-the-art neural models demonstrate that computational modeling of social norms is a promising research direction. Our model framework, Neural Norm Transformer, learns and generalizes SOCIAL-CHEM-101 to successfully reason about previously unseen situations, generating relevant (and potentially novel) attribute-aware social rules-of-thumb."
2020.emnlp-main.58,Back to the Future: Unsupervised Backprop-based Decoding for Counterfactual and Abductive Commonsense Reasoning,2020,-1,-1,2,0,4389,lianhui qin,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Abductive and counterfactual reasoning, core abilities of everyday human cognition, require reasoning about what might have happened at time t, while conditioning on multiple contexts from the relative past and future. However, simultaneous incorporation of past and future contexts using generative language models (LMs) can be challenging, as they are trained either to condition only on the past context or to perform narrowly scoped text-infilling. In this paper, we propose DeLorean, a new unsupervised decoding algorithm that can flexibly incorporate both the past and future contexts using only off-the-shelf, left-to-right language models and no supervision. The key intuition of our algorithm is incorporating the future through back-propagation, during which, we only update the internal representation of the output while fixing the model parameters. By alternating between forward and backward propagation, DeLorean can decode the output representation that reflects both the left and right contexts. We demonstrate that our approach is general and applicable to two nonmonotonic reasoning tasks: abductive text generation and counterfactual story revision, where DeLorean outperforms a range of unsupervised and some supervised methods, based on automatic and human evaluation."
2020.emnlp-main.373,Unsupervised Commonsense Question Answering with Self-Talk,2020,57,2,1,1,954,vered shwartz,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Natural language understanding involves reading between the lines with implicit background knowledge. Current systems either rely on pre-trained language models as the sole implicit source of world knowledge, or resort to external knowledge bases (KBs) to incorporate additional relevant knowledge. We propose an unsupervised framework based on self-talk as a novel alternative to multiple-choice commonsense tasks. Inspired by inquiry-based discovery learning (Bruner, 1961), our approach inquires language models with a number of information seeking questions such as {``}what is the definition of...{''} to discover additional background knowledge. Empirical results demonstrate that the self-talk procedure substantially improves the performance of zero-shot language model baselines on four out of six commonsense benchmarks, and competes with models that obtain knowledge from external KBs. While our approach improves performance on several benchmarks, the self-talk induced knowledge even when leading to correct answers is not always seen as helpful by human judges, raising interesting questions about the inner-workings of pre-trained language models for commonsense reasoning."
2020.emnlp-main.556,{``}You are grounded!{''}: Latent Name Artifacts in Pre-trained Language Models,2020,34,0,1,1,954,vered shwartz,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),0,"Pre-trained language models (LMs) may perpetuate biases originating in their training corpus to downstream models. We focus on artifacts associated with the representation of given names (e.g., Donald), which, depending on the corpus, may be associated with specific entities, as indicated by next token prediction (e.g., Trump). While helpful in some contexts, grounding happens also in under-specified or inappropriate contexts. For example, endings generated for {`}Donald is a{'} substantially differ from those of other names, and often have more-than-average negative sentiment. We demonstrate the potential effect on downstream tasks with reading comprehension probes where name perturbation changes the model answers. As a silver lining, our experiments suggest that additional pre-training on different corpora may mitigate this bias."
2020.coling-main.605,Do Neural Language Models Overcome Reporting Bias?,2020,-1,-1,1,1,954,vered shwartz,Proceedings of the 28th International Conference on Computational Linguistics,0,"Mining commonsense knowledge from corpora suffers from reporting bias, over-representing the rare at the expense of the trivial (Gordon and Van Durme, 2013). We study to what extent pre-trained language models overcome this issue. We find that while their generalization capacity allows them to better estimate the plausibility of frequent but unspoken of actions, outcomes, and properties, they also tend to overestimate that of the very rare, amplifying the bias that already exists in their training corpus."
2020.acl-tutorials.7,Commonsense Reasoning for Natural Language Processing,2020,-1,-1,2,0,3837,maarten sap,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts,0,"Commonsense knowledge, such as knowing that {``}bumping into people annoys them{''} or {``}rain makes the road slippery{''}, helps humans navigate everyday situations seamlessly. Yet, endowing machines with such human-like commonsense reasoning capabilities has remained an elusive goal of artificial intelligence research for decades. In recent years, commonsense knowledge and reasoning have received renewed attention from the natural language processing (NLP) community, yielding exploratory studies in automated commonsense understanding. We organize this tutorial to provide researchers with the critical foundations and recent advances in commonsense representation and reasoning, in the hopes of casting a brighter light on this promising area of future research. In our tutorial, we will (1) outline the various types of commonsense (e.g., physical, social), and (2) discuss techniques to gather and represent commonsense knowledge, while highlighting the challenges specific to this type of knowledge (e.g., reporting bias). We will then (3) discuss the types of commonsense knowledge captured by modern NLP systems (e.g., large pretrained language models), and (4) present ways to measure systems{'} commonsense reasoning abilities. We will finish with (5) a discussion of various ways in which commonsense reasoning can be used to improve performance on NLP tasks, exemplified by an (6) interactive session on integrating commonsense into a downstream task."
W19-5111,A Systematic Comparison of {E}nglish Noun Compound Representations,2019,31,0,1,1,954,vered shwartz,Proceedings of the Joint Workshop on Multiword Expressions and WordNet (MWE-WN 2019),0,"Building meaningful representations of noun compounds is not trivial since many of them scarcely appear in the corpus. To that end, composition functions approximate the distributional representation of a noun compound by combining its constituent distributional vectors. In the more general case, phrase embeddings have been trained by minimizing the distance between the vectors representing paraphrases. We compare various types of noun compound representations, including distributional, compositional, and paraphrase-based representations, through a series of tasks and analyses, and with an extensive number of underlying word embeddings. We find that indeed, in most cases, composition functions produce higher quality representations than distributional ones, and they improve with computational power. No single function performs best in all scenarios, suggesting that a joint training objective may produce improved representations."
Q19-1027,Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition,2019,63,0,1,1,954,vered shwartz,Transactions of the Association for Computational Linguistics,0,"Building meaningful phrase representations is challenging because phrase meanings are not simply the sum of their constituent meanings. Lexical composition can shift the meanings of the constituent words and introduce implicit information. We tested a broad range of textual representations for their capacity to address these issues. We found that, as expected, contextualized word representations perform better than static word embeddings, more so on detecting meaning shift than in recovering implicit information, in which their performance is still far from that of humans. Our evaluation suite, consisting of six tasks related to lexical composition effects, can serve future research aiming to improve representations."
P19-1409,Revisiting Joint Modeling of Cross-document Entity and Event Coreference Resolution,2019,27,0,2,0,25797,shany barhom,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Recognizing coreferring events and entities across multiple texts is crucial for many NLP applications. Despite the task{'}s importance, research focus was given mostly to within-document entity coreference, with rather little attention to the other variants. We propose a neural architecture for cross-document coreference resolution. Inspired by Lee et al. (2012), we jointly model entity and event coreference. We represent an event (entity) mention using its lexical span, surrounding context, and relation to entity (event) mentions via predicate-arguments structures. Our model outperforms the previous state-of-the-art event coreference model on ECB+, while providing the first entity coreference results on this corpus. Our analysis confirms that all our representation elements, including the mention span itself, its context, and the relation to other mentions contribute to the model{'}s success."
N19-1233,Evaluating Text {GAN}s as Language Models,2019,0,5,3,0,10547,guy tevet,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"Generative Adversarial Networks (GANs) are a promising approach for text generation that, unlike traditional language models (LM), does not suffer from the problem of {``}exposure bias{''}. However, A major hurdle for understanding the potential of GANs for text generation is the lack of a clear evaluation metric. In this work, we propose to approximate the distribution of text generated by a GAN, which permits evaluating them with traditional probability-based LM metrics. We apply our approximation procedure on several GAN-based models and show that they currently perform substantially worse than state-of-the-art LMs. Our evaluation procedure promotes better understanding of the relation between GANs and LMs, and can accelerate progress in GAN-based text generation."
K19-1019,Diversify Your Datasets: Analyzing Generalization via Controlled Variance in Adversarial Datasets,2019,25,0,2,1,952,ohad rozen,Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL),0,"Phenomenon-specific {``}adversarial{''} datasets have been recently designed to perform targeted stress-tests for particular inference types. Recent work (Liu et al., 2019a) proposed that such datasets can be utilized for training NLI and other types of models, often allowing to learn the phenomenon in focus and improve on the challenge dataset, indicating a {``}blind spot{''} in the original training data. Yet, although a model can improve in such a training process, it might still be vulnerable to other challenge datasets targeting the same phenomenon but drawn from a different distribution, such as having a different syntactic complexity level. In this work, we extend this method to drive conclusions about a model{'}s ability to learn and generalize a target phenomenon rather than to {``}learn{''} a dataset, by controlling additional aspects in the adversarial datasets. We demonstrate our approach on two inference phenomena {--} dative alternation and numerical reasoning, elaborating, and in some cases contradicting, the results of Liu et al.. Our methodology enables building better challenge datasets for creating more robust models, and may yield better model understanding and subsequent overarching improvements."
S18-2020,Integrating Multiplicative Features into Supervised Distributional Methods for Lexical Entailment,2018,18,1,2,0,9626,tu vu,Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics,0,"Supervised distributional methods are applied successfully in lexical entailment, but recent work questioned whether these methods actually learn a relation between two words. Specifically, Levy et al. (2015) claimed that linear classifiers learn only separate properties of each word. We suggest a cheap and easy way to boost the performance of these methods by integrating multiplicative features into commonly used representations. We provide an extensive evaluation with different classifiers and evaluation setups, and suggest a suitable evaluation setup for the task, eliminating biases existing in previous ones."
S18-1115,{S}em{E}val-2018 Task 9: Hypernym Discovery,2018,0,12,7,0,5213,jose camachocollados,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes the SemEval 2018 Shared Task on Hypernym Discovery. We put forward this task as a complementary benchmark for modeling hypernymy, a problem which has traditionally been cast as a binary classification task, taking a pair of candidate words as input. Instead, our reformulated task is defined as follows: given an input term, retrieve (or discover) its suitable hypernyms from a target corpus. We proposed five different subtasks covering three languages (English, Spanish, and Italian), and two specific domains of knowledge in English (Medical and Music). Participants were allowed to compete in any or all of the subtasks. Overall, a total of 11 teams participated, with a total of 39 different systems submitted through all subtasks. Data, results and further information about the task can be found at \url{https://competitions.codalab.org/competitions/17119}."
P18-2103,Breaking {NLI} Systems with Sentences that Require Simple Lexical Inferences,2018,0,66,2,0,9899,max glockner,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We create a new NLI test set that shows the deficiency of state-of-the-art models in inferences that require lexical and world knowledge. The new examples are simpler than the SNLI test set, containing sentences that differ by at most one word from sentences in the training set. Yet, the performance on the new test set is substantially worse across systems trained on SNLI, demonstrating that these systems are limited in their generalization ability, failing to capture many simple inferences."
P18-1111,Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations,2018,29,1,1,1,954,vered shwartz,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Revealing the implicit semantic relation between the constituents of a noun-compound is important for many NLP applications. It has been addressed in the literature either as a classification task to a set of pre-defined relations or by producing free text paraphrases explicating the relations. Most existing paraphrasing methods lack the ability to generalize, and have a hard time interpreting infrequent or new noun-compounds. We propose a neural model that generalizes better by representing paraphrases in a continuous space, generalizing for both unseen noun-compounds and rare paraphrases. Our model helps improving performance on both the noun-compound paraphrasing and classification tasks."
N18-2035,"Olive Oil is Made \\textit{of} Olives, Baby Oil is Made \\textit{for} Babies: Interpreting Noun Compounds Using Paraphrases in a Neural Model",2018,15,1,1,1,954,vered shwartz,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",0,"Automatic interpretation of the relation between the constituents of a noun compound, e.g. olive oil (source) and baby oil (purpose) is an important task for many NLP applications. Recent approaches are typically based on either noun-compound representations or paraphrases. While the former has initially shown promising results, recent work suggests that the success stems from memorizing single prototypical words for each relation. We explore a neural paraphrasing approach that demonstrates superior performance when such memorization is not possible."
W17-6927,Neural Disambiguation of Causal Lexical Markers Based on Context,2017,14,2,2,0,27775,eugenio martinezcamara,{IWCS} 2017 {---} 12th International Conference on Computational Semantics {---} Short papers,0,"We propose a neural network architecture for the task of causality classification. We claim that the encoding of the meaning of a sentence is required for the disambiguation of its causal meaning. Our results show that our claim holds, and we outperform the state-of-the-art."
W17-0902,A Consolidated Open Knowledge Representation for Multiple Texts,2017,53,4,2,0,32101,rachel wities,"Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics",0,"We propose to move from Open Information Extraction (OIE) ahead to Open Knowledge Representation (OKR), aiming to represent information conveyed jointly in a set of texts in an open text-based manner. We do so by consolidating OIE extractions using entity and predicate coreference, while modeling information containment between coreferring elements via lexical entailment. We suggest that generating OKR structures can be a useful step in the NLP pipeline, to give semantic applications an easy handle on consolidated information across multiple texts."
S17-1002,Learning Antonyms with Paraphrases and a Morphology-Aware Neural Network,2017,15,3,4,0,32400,sneha rajana,Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*{SEM} 2017),0,"Recognizing and distinguishing antonyms from other types of semantic relations is an essential part of language understanding systems. In this paper, we present a novel method for deriving antonym pairs using paraphrase pairs containing negation markers. We further propose a neural network model, AntNET, that integrates morphological features indicative of antonymy into a path-based relation detection algorithm. We demonstrate that our model outperforms state-of-the-art models in distinguishing antonyms from other semantic relations and is capable of efficiently handling multi-word expressions."
S17-1019,Acquiring Predicate Paraphrases from News Tweets,2017,11,3,1,1,954,vered shwartz,Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*{SEM} 2017),0,"We present a simple method for ever-growing extraction of predicate paraphrases from news headlines in Twitter. Analysis of the output of ten weeks of collection shows that the accuracy of paraphrases with different support levels is estimated between 60-86{\%}. We also demonstrate that our resource is to a large extent complementary to existing resources, providing many novel paraphrases. Our resource is publicly available, continuously expanding based on daily news."
E17-1007,Hypernyms under Siege: Linguistically-motivated Artillery for Hypernymy Detection,2017,18,39,1,1,954,vered shwartz,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"The fundamental role of hypernymy in NLP has motivated the development of many methods for the automatic identification of this relation, most of which rely on word distribution. We investigate an extensive number of such unsupervised measures, using several distributional semantic models that differ by context type and feature weighting. We analyze the performance of the different methods based on their linguistic motivation. Comparison to the state-of-the-art supervised methods shows that while supervised methods generally outperform the unsupervised ones, the former are sensitive to the distribution of training instances, hurting their reliability. Being based on general linguistic hypotheses and independent from training data, unsupervised measures are more robust, and therefore are still useful artillery for hypernymy detection."
W16-5304,Path-based vs. Distributional Information in Recognizing Lexical Semantic Relations,2016,23,7,1,1,954,vered shwartz,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"Recognizing various semantic relations between terms is beneficial for many NLP tasks. While path-based and distributional information sources are considered complementary for this task, the superior results the latter showed recently suggested that the former{'}s contribution might have become obsolete. We follow the recent success of an integrated neural method for hypernymy detection (Shwartz et al., 2016) and extend it to recognize multiple relations. The empirical results show that this method is effective in the multiclass setting as well. We further show that the path-based information source always contributes to the classification, and analyze the cases in which it mostly complements the distributional information."
W16-5310,{C}og{AL}ex-{V} Shared Task: {L}ex{NET} - Integrated Path-based and Distributional Method for the Identification of Semantic Relations,2016,24,3,1,1,954,vered shwartz,Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon ({C}og{AL}ex - V),0,"We present a submission to the CogALex 2016 shared task on the corpus-based identification of semantic relations, using LexNET (Shwartz and Dagan, 2016), an integrated path-based and distributional method for semantic relation classification. The reported results in the shared task bring this submission to the third place on subtask 1 (word relatedness), and the first place on subtask 2 (semantic relation classification), demonstrating the utility of integrating the complementary path-based and distributional information sources in recognizing concrete semantic relations. Combined with a common similarity measure, LexNET performs fairly good on the word relatedness task (subtask 1). The relatively low performance of LexNET and all other systems on subtask 2, however, confirms the difficulty of the semantic relation classification task, and stresses the need to develop additional methods for this task."
S16-2013,Adding Context to Semantic Data-Driven Paraphrasing,2016,23,2,1,1,954,vered shwartz,Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics,0,"Recognizing lexical inferences between pairs of terms is a common task in NLP applications, which should typically be performed within a given context. Such context-sensitive inferences have to consider both term meaning in context as well as the fine-grained relation holding between the terms. Hence, to develop suitable lexical inference methods, we need datasets that are annotated with fine-grained semantic relations in-context. Since existing datasets either provide outof-context annotations or refer to coarsegrained relations, we propose a methodology for adding context-sensitive annotations. We demonstrate our methodology by applying it to phrase pairs from PPDB 2.0, creating a novel dataset of finegrained lexical inferences in-context and showing its utility in developing contextsensitive methods."
P16-1226,Improving Hypernymy Detection with an Integrated Path-based and Distributional Method,2016,33,4,1,1,954,vered shwartz,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Detecting hypernymy relations is a key task in NLP, which is addressed in the literature using two complementary approaches. Distributional methods, whose supervised variants are the current best performers, and path-based methods, which received less research attention. We suggest an improved path-based algorithm, in which the dependency paths are encoded using a recurrent neural network, that achieves results comparable to distributional methods. We then extend the approach to integrate both path-based and distributional signals, significantly improving upon the state-of-the-art on this task."
S15-1022,Multi-Level Alignments As An Extensible Representation Basis for Textual Entailment Algorithms,2015,20,9,3,0,37318,taegil noh,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"A major problem in research on Textual Entailment (TE) is the high implementation effort for TE systems. Recently, interoperable standards for annotation and preprocessing have been proposed. In contrast, the algorithmic level remains unstandardized, which makes component re-use in this area very difficult in practice. In this paper, we introduce multi-level alignments as a central, powerful representation for TE algorithms that encourages modular, reusable, multilingual algorithm development. We demonstrate that a pilot open-source implementation of multi-level alignment with minimal features competes with state-of-theart open-source TE engines in three languages."
K15-1018,Learning to Exploit Structured Resources for Lexical Inference,2015,31,10,1,1,954,vered shwartz,Proceedings of the Nineteenth Conference on Computational Natural Language Learning,0,"Massive knowledge resources, such as Wikidata, can provide valuable information for lexical inference, especially for proper-names. Prior resource-based approaches typically select the subset of each resourcexe2x80x99s relations which are relevant for a particular given task. The selection process is done manually, limiting these approaches to smaller resources such as WordNet, which lacks coverage of propernames and recent terminology. This paper presents a supervised framework for automatically selecting an optimized subset of resource relations for a given target inference task. Our approach enables the use of large-scale knowledge resources, thus providing a rich source of high-precision inferences over proper-names. 1"
