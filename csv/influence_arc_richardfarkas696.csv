C12-1052,C10-1011,1,0.873148,"order graph-based parser corresponds to a dependency edge. McDonald et al. (2005a) first used second order factors which incorporates siblings of the head and dependent. The second order algorithm of Carreras (2007) uses three second order factors: the sibling, the leftmost and rightmost grandchildren. The edge labeling is an integral part of the algorithm, which requires an additional loop over the labels. This algorithm has a complexity of O(n4 L). 851 Koo and Collins (2010) presented a parser that can evaluate factors of three edges. In this paper, we utilize the state-of-the-art parser of Bohnet (2010), a graph-based parser which employs online training with a perceptron which employs the MIRA update (Crammer and Singer, 2003). The parser contains a feature function for the first order factor, one for the sibling factor, and one for the grandchildren. We integrated in each of the functions features representing information on the phrase structure. 3.1 Features Defined on Phrase Structure Parses We explore new feature templates to include features from the phrase structures. These templates are defined on the phrase structures themselves which is an important difference compared to previous"
C12-1052,D07-1101,0,0.203635,"approach in the dependency parsing environment is still considerable in the presence of other extensions. • We give explanations why the proposed stacking approach works. 850 2 Related Work A number of studies have addressed feature-rich dependency and phrase structure parsing, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The two main approaches to dependency parsing are transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2003; Titov and Henderson, 2007), and graph-based dependency parsing (Eisner, 1996; McDonald et al., 2005a; Carreras, 2007; Rush et al., 2010). The most successful supervised phrase structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consist of two stages. At the first stage they apply a PCFG to extract possible parses, then at the second stage select the best parse from the set of possible parses (i.e. rerank this set) employing a large feature set (Collins, 2000; Charniak and Johnson, 2005). There is little related work on combining the two approaches. Some generative parsing approaches have exploited th"
C12-1052,W08-2102,0,0.417452,"ploit the difference of the representations of dependency and phrase structure parses and the divergence in the parsing techniques. We use features derived from the 1-best automatic phrase structure parse to augment the feature set of the dependency parser and vice versa. This way of combining parsers proved to be effective and provides a substantial accuracy gain for both parsing approaches. Our ultimate objective is to advance one parser by a second one. This motivation is different from previous approaches for combining phrase-structure and dependency parsers (cf. (Klein and Manning, 2003; Carreras et al., 2008; Rush et al., 2010)) which aimed to achieve a joint optimum of the two approaches. Our proposal has three advantages over previous work. (i) Our approach is simple to implement by defining new feature templates, yet very effective. (ii) It does not require a joint representation of different parse structures. (iii) The participating dependency and phrase-structure parsers can be easily replaced, and each can be developed and optimized independently. In our experiments both parsers utilize the same (training) data set – having two different representations – without having access to external i"
C12-1052,A00-2018,0,0.123613,"ish development set where the discriminative parsers with and without these features gave different output. We identified two categories of improvement. The first one is the “attachment” of adverbs and adjectives, especially in the case of collocational modifiers like more like and many more. The second phenomenon where the dependency parse-based features could eliminate a considerable amount of errors – much more than was introduced – is PP attachment. The explanation for both of these contributions might be the “lossless” lexicalization of the dependency parsers. Although the PCFG parser of Charniak (2000) is lexicalized8 and the re-ranking stage is deeply lexicalized, using only 50 candidate parses and a frequency-based feature pruning implies some extent of information loss while dependency parsers can exploit very rare lexical cues. 7.3 What is the difference between stacking directly and stacking after conversion? We also manually compared the parses of the two stacking approaches, i.e. the one where the features are defined directly on phrase structures versus the other where the features are defined on a dependency tree which were automatically converted from the phrase structures (see Se"
C12-1052,P05-1022,0,0.217984,"hest reported accuracy score on dependency parsing of the Penn Treebank. The phrase structure parser obtains 91.72 F-score with the features derived from the dependency trees, and this is also competitive with the best reported PARSEVAL scores for the Penn Treebank. KEYWORDS: parsing, stacking, dependency parsing, phrase structure parsing. Proceedings of COLING 2012: Technical Papers, pages 849–866, COLING 2012, Mumbai, December 2012. 849 1 Introduction Both phrase structure and dependency parsers have developed considerably in the last decade, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The development has taken rather different directions as phrase structure parsers and dependency parsers employ different techniques to parse sentences. Phrase structure parsers usually apply probabilistic context free grammars and focus on the relationships among phrases. Dependency parsers use edge factored models for parsing that primarily model the interaction between the a head word and a dependent word. Second order graph-based parsers consider in addition for the decision on a dependency edge the interaction with siblings and grandchildren. Phrase structure and dependenc"
C12-1052,J03-4003,0,0.063618,"age they apply a PCFG to extract possible parses, then at the second stage select the best parse from the set of possible parses (i.e. rerank this set) employing a large feature set (Collins, 2000; Charniak and Johnson, 2005). There is little related work on combining the two approaches. Some generative parsing approaches have exploited the differences between phrase structure and dependency parsers. For instance, Klein and Manning (2003) introduced an approach where the objective function is the product of the probabilities of a generative phrase structure and a dependency parser. Model 1 of Collins (2003) is based on the dependencies between pairs of head words. On the other hand, the related work on this topic for discriminative parsing is sparse, and we are only aware of the following works. Carreras et al. (2008) and Rush et al. (2010) introduced frameworks for joint learning of phrase and dependency structures, and showed improvements on both tasks for English. These frameworks require special formulation of – one or both – parsing approaches while our approach allows the usage of arbitrary dependency parsers and any feature-based phrase structure parser. Our motivation differs from these"
C12-1052,C96-1058,0,0.0793168,"nd vice versa. The added value of the approach in the dependency parsing environment is still considerable in the presence of other extensions. • We give explanations why the proposed stacking approach works. 850 2 Related Work A number of studies have addressed feature-rich dependency and phrase structure parsing, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The two main approaches to dependency parsing are transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2003; Titov and Henderson, 2007), and graph-based dependency parsing (Eisner, 1996; McDonald et al., 2005a; Carreras, 2007; Rush et al., 2010). The most successful supervised phrase structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consist of two stages. At the first stage they apply a PCFG to extract possible parses, then at the second stage select the best parse from the set of possible parses (i.e. rerank this set) employing a large feature set (Collins, 2000; Charniak and Johnson, 2005). There is little related work on combining the two approaches. Some generat"
C12-1052,W11-2924,1,0.883475,"of phrase and dependency structures, and showed improvements on both tasks for English. These frameworks require special formulation of – one or both – parsing approaches while our approach allows the usage of arbitrary dependency parsers and any feature-based phrase structure parser. Our motivation differs from these solutions as we focus on advancing one approach rather than achieving a joint optimum. Our approach can be regarded as a special stacking procedure (Nivre and McDonald, 2008), specifically, the stacking of a phrase structure parser with a dependency parser. In our previous work (Farkas et al., 2011), we reported results with a stacking approach for phrase structure parsing evaluated on a German corpus. We focus herein on the reverse direction as well, i.e. we define features for dependency parsers, we report performance outstanding scores on English for both directions, compare to the state-of-the-art results and carried out a detailed analysis of the stacking’s contributions. Wang and Zong (2010) introduced a procedure that exploits dependency parses to improve a phrase structure parser. They used automatic dependency parses for pruning the chart of a phrase structure parser and reporte"
C12-1052,W09-1205,0,0.0237672,"09 This work (G+P+T+C) English (UAS) Devel. Test 92.5 93.5 93.04 93.26 92.14 94.04 91.85 92.96 93.16 93.8 94.14 GHPT’09 B’10 German (LAS) Devel. Test 87.28 88.06 88.54 89.69 88.50 89.90 Table 4: Comparison to previous work. We report UAS only for the English Penn Treebank since usually unlabeled scores were published and labeled attachments scores only for the German Tiger Treebank since in the CoNLL shared task 2009 only labeled attachment scores were reported. For German the two top scoring parsers of the CoNLL 2009 shared task on Syntactic and Semantic Dependency parsing were the parser of Gesmundo et al. (2009), who had the best overall scores and the parser of Bohnet (2010), which performed best on English and German. However we note that directly comparing these results to our ones is not fully fair since the POS tagging accuracy of the data sets were lower than 95.5 at the CoNLL 2009 shared task. Table 5 sketches the phrase-structure parsing results in the context of previously published results. We retrained the current version of the Charniak and Johnson (2005) parser5 (C&J) for English. We also cite the scores reported by Rush et al. (2010) who also exploited phrase structure and dependency pa"
C12-1052,W09-1201,0,0.0305944,"Missing"
C12-1052,P08-1067,0,0.546645,"on dependency parsing of the Penn Treebank. The phrase structure parser obtains 91.72 F-score with the features derived from the dependency trees, and this is also competitive with the best reported PARSEVAL scores for the Penn Treebank. KEYWORDS: parsing, stacking, dependency parsing, phrase structure parsing. Proceedings of COLING 2012: Technical Papers, pages 849–866, COLING 2012, Mumbai, December 2012. 849 1 Introduction Both phrase structure and dependency parsers have developed considerably in the last decade, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The development has taken rather different directions as phrase structure parsers and dependency parsers employ different techniques to parse sentences. Phrase structure parsers usually apply probabilistic context free grammars and focus on the relationships among phrases. Dependency parsers use edge factored models for parsing that primarily model the interaction between the a head word and a dependent word. Second order graph-based parsers consider in addition for the decision on a dependency edge the interaction with siblings and grandchildren. Phrase structure and dependency parsers have"
C12-1052,P08-1068,0,0.0440803,"of 0.89 and 0.54 employing them as an extension of the graph-based and the stacked dependency parser G+T. The added value of the features from the transition-based dependency parses on top of the extended feature set (i.e. the difference between G+P and G+P+T) is minor – and there is a decrease at 2 out of the 8 settings. These results indicate that the features gathered from the phrase structure parse contain almost all of the information which can be gathered from the transition-based dependency parse. The two last rows show scores when we use in addition cluster-based features similarly to Koo et al. (2008). The cluster-based feature provided an improvement of 0.17 on top of the results of the graph-based parser (G+C features). The last row (G+P+T+C features) shows the scores for the features from all sources where we finally obtain 94.14 UAS. Similarly to the results for English, we can also report large improvements for the German Tiger Treebank. With the G+T features, we gain 0.24 UAS and 0.71 with the “G+P features” compared with the “baseline G”. When we utilized each feature set, the parser achieved 91.88 UAS and 89.90 LAS (0.81 improvements in UAS), which is the highest reported accuracy"
C12-1052,P10-1001,0,0.0986425,"apted to a transition-based parser. Graph-based dependency parsers decompose the dependency structure into factors. Each factor of the first order graph-based parser corresponds to a dependency edge. McDonald et al. (2005a) first used second order factors which incorporates siblings of the head and dependent. The second order algorithm of Carreras (2007) uses three second order factors: the sibling, the leftmost and rightmost grandchildren. The edge labeling is an integral part of the algorithm, which requires an additional loop over the labels. This algorithm has a complexity of O(n4 L). 851 Koo and Collins (2010) presented a parser that can evaluate factors of three edges. In this paper, we utilize the state-of-the-art parser of Bohnet (2010), a graph-based parser which employs online training with a perceptron which employs the MIRA update (Crammer and Singer, 2003). The parser contains a feature function for the first order factor, one for the sibling factor, and one for the grandchildren. We integrated in each of the functions features representing information on the phrase structure. 3.1 Features Defined on Phrase Structure Parses We explore new feature templates to include features from the phras"
C12-1052,D10-1004,0,0.102696,"Missing"
C12-1052,P05-1012,0,0.798663,"95 UAS, which is the highest reported accuracy score on dependency parsing of the Penn Treebank. The phrase structure parser obtains 91.72 F-score with the features derived from the dependency trees, and this is also competitive with the best reported PARSEVAL scores for the Penn Treebank. KEYWORDS: parsing, stacking, dependency parsing, phrase structure parsing. Proceedings of COLING 2012: Technical Papers, pages 849–866, COLING 2012, Mumbai, December 2012. 849 1 Introduction Both phrase structure and dependency parsers have developed considerably in the last decade, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The development has taken rather different directions as phrase structure parsers and dependency parsers employ different techniques to parse sentences. Phrase structure parsers usually apply probabilistic context free grammars and focus on the relationships among phrases. Dependency parsers use edge factored models for parsing that primarily model the interaction between the a head word and a dependent word. Second order graph-based parsers consider in addition for the decision on a dependency edge the interaction with siblings and grandchildren. P"
C12-1052,H05-1066,0,0.847248,"95 UAS, which is the highest reported accuracy score on dependency parsing of the Penn Treebank. The phrase structure parser obtains 91.72 F-score with the features derived from the dependency trees, and this is also competitive with the best reported PARSEVAL scores for the Penn Treebank. KEYWORDS: parsing, stacking, dependency parsing, phrase structure parsing. Proceedings of COLING 2012: Technical Papers, pages 849–866, COLING 2012, Mumbai, December 2012. 849 1 Introduction Both phrase structure and dependency parsers have developed considerably in the last decade, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The development has taken rather different directions as phrase structure parsers and dependency parsers employ different techniques to parse sentences. Phrase structure parsers usually apply probabilistic context free grammars and focus on the relationships among phrases. Dependency parsers use edge factored models for parsing that primarily model the interaction between the a head word and a dependent word. Second order graph-based parsers consider in addition for the decision on a dependency edge the interaction with siblings and grandchildren. P"
C12-1052,P07-1122,0,0.0168907,"introduces 3 attachment errors (for Therese, for the comma and for Quebec). Besides noun phrases the parses of institutionalized phrases like with or without and rather than to were also considerable improved. These improvements can be probably attributed to the phrase-based thinking of the second parser. Phrase structure-based features improved considerably the accuracy of coordinations. It is a known issue that the representation of coordination in the dependency structure has an impact on the accuracy. The Penn2Malt converter builds dependency structures where the conjunction is the head. Nilsson et al. (2007) showed that this representation of coordinations yields a lower parsing accuracy – across four languages – than a representation where the conjunction and the members of the coordination form one chain. Our features defined on the phrase structure trees can be regarded as a third type of representation of coordination. Although these features help in the current setting we expect a smaller contribution if a different dependency representation (like the chain type) is targeted. The counting of the errors – or error fixes – related to coordination is not straightforward because besides the wron"
C12-1052,W03-3017,0,0.115821,"Treebank for stacking a phrase structure parser on and a dependency parser and vice versa. The added value of the approach in the dependency parsing environment is still considerable in the presence of other extensions. • We give explanations why the proposed stacking approach works. 850 2 Related Work A number of studies have addressed feature-rich dependency and phrase structure parsing, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The two main approaches to dependency parsing are transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2003; Titov and Henderson, 2007), and graph-based dependency parsing (Eisner, 1996; McDonald et al., 2005a; Carreras, 2007; Rush et al., 2010). The most successful supervised phrase structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consist of two stages. At the first stage they apply a PCFG to extract possible parses, then at the second stage select the best parse from the set of possible parses (i.e. rerank this set) employing a large feature set (Collins, 2000; Charniak and Johnson, 200"
C12-1052,W04-2407,0,0.177788,"parser and reach 93.95 UAS, which is the highest reported accuracy score on dependency parsing of the Penn Treebank. The phrase structure parser obtains 91.72 F-score with the features derived from the dependency trees, and this is also competitive with the best reported PARSEVAL scores for the Penn Treebank. KEYWORDS: parsing, stacking, dependency parsing, phrase structure parsing. Proceedings of COLING 2012: Technical Papers, pages 849–866, COLING 2012, Mumbai, December 2012. 849 1 Introduction Both phrase structure and dependency parsers have developed considerably in the last decade, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The development has taken rather different directions as phrase structure parsers and dependency parsers employ different techniques to parse sentences. Phrase structure parsers usually apply probabilistic context free grammars and focus on the relationships among phrases. Dependency parsers use edge factored models for parsing that primarily model the interaction between the a head word and a dependent word. Second order graph-based parsers consider in addition for the decision on a dependency edge the interaction with siblin"
C12-1052,P08-1108,0,0.407715,"cture parsers usually apply probabilistic context free grammars and focus on the relationships among phrases. Dependency parsers use edge factored models for parsing that primarily model the interaction between the a head word and a dependent word. Second order graph-based parsers consider in addition for the decision on a dependency edge the interaction with siblings and grandchildren. Phrase structure and dependency parsers have both shown to be efficient and to provide accurate parsing results. Different parsing approaches have different strengths on distinct linguistic constructions, cf. (Nivre and McDonald, 2008). In this paper, we exploit the difference of the representations of dependency and phrase structure parses and the divergence in the parsing techniques. We use features derived from the 1-best automatic phrase structure parse to augment the feature set of the dependency parser and vice versa. This way of combining parsers proved to be effective and provides a substantial accuracy gain for both parsing approaches. Our ultimate objective is to advance one parser by a second one. This motivation is different from previous approaches for combining phrase-structure and dependency parsers (cf. (Kle"
C12-1052,P06-1055,0,0.076953,"al scores are competitive with the best reported supervised PARSEVAL score in the Penn Treebank by (Huang, 2008) who also extended the feature set of Charniak and Johnson (2005) and applied forest-based reranking. C&J Rush’10 Huang’08 English Devel. Test 90.60 91.36 – 90.7 – 91.69 This work (bl+dep) 90.92 Berkeley PyNLP 91.72 German Devel. Test 76.60 (65.25) 76.05 (64.00) 76.76 (66.29) 76.27 (65.21) 80.90 (70.39) 79.45 (68.73) Table 5: Comparison to previous work. Our method significantly outperforms state-of-the-art systems. For German, we trained the current version of the Berkeley parser6 (Petrov et al., 2006) and PyNLP7 parsers (Versley and Rehbein, 2009). Note that the results of the generative Berkeley parser is competitive with the PyNLP parser which utilizes reranking, while the first-stage parser, which we employ here – using a fine-tuned German-specific tree annotation schema – outperforms both of them. The discriminative approach with the baseline feature set we employed gave an improvement of 2 percentage points over the first-stage parser and the features gathered from dependency parsers could add an additional 1 point to this. 5 6 7 http://www.cog.brown.edu/ mj/Software.htm http://code.g"
C12-1052,D10-1001,0,0.403278,"the representations of dependency and phrase structure parses and the divergence in the parsing techniques. We use features derived from the 1-best automatic phrase structure parse to augment the feature set of the dependency parser and vice versa. This way of combining parsers proved to be effective and provides a substantial accuracy gain for both parsing approaches. Our ultimate objective is to advance one parser by a second one. This motivation is different from previous approaches for combining phrase-structure and dependency parsers (cf. (Klein and Manning, 2003; Carreras et al., 2008; Rush et al., 2010)) which aimed to achieve a joint optimum of the two approaches. Our proposal has three advantages over previous work. (i) Our approach is simple to implement by defining new feature templates, yet very effective. (ii) It does not require a joint representation of different parse structures. (iii) The participating dependency and phrase-structure parsers can be easily replaced, and each can be developed and optimized independently. In our experiments both parsers utilize the same (training) data set – having two different representations – without having access to external information. Thus, ou"
C12-1052,C04-1024,0,0.0394137,"h-based parser of the dependency parsers of Bohnet (2011)1 . The second-order parser employs online training with a perceptron (Crammer and Singer, 2003) and it is based on a Hash Kernel. We employed this parser since it is quick to train, provides useful labeled dependency trees and achieves state-of-the-art accuracies. We used the transition-based parser that is included in the same package for our experiments as well. For the phrase structure parsing experiments, we also employed state-of-the-art parsers. We used the first-stage parser of Charniak and Johnson (2005) for English and Bitpar (Schmid, 2004) for German. The latter employs a grammar engineered for German (Farkas et al., 2011). At the second stage, we used the 50 and 100-best parses to rerank and filtered out rare features (which occurred in less than 5 sentences). We employed the ranking MaxEnt implementation of the MALLET package (McCallum, 2002) and optimized the L2 regularizer coefficient on the development set. 5.3 Baseline Feature Sets For conducting baseline dependency parsing experiments, we employed the feature set of Bohnet (2010). For the stacking of graph-based and transition-based dependency parsers, we used the featur"
C12-1052,P08-1076,0,0.0598484,"Missing"
C12-1052,D09-1058,0,0.078152,"Missing"
C12-1052,W07-2218,0,0.020652,"stacking a phrase structure parser on and a dependency parser and vice versa. The added value of the approach in the dependency parsing environment is still considerable in the presence of other extensions. • We give explanations why the proposed stacking approach works. 850 2 Related Work A number of studies have addressed feature-rich dependency and phrase structure parsing, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The two main approaches to dependency parsing are transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2003; Titov and Henderson, 2007), and graph-based dependency parsing (Eisner, 1996; McDonald et al., 2005a; Carreras, 2007; Rush et al., 2010). The most successful supervised phrase structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consist of two stages. At the first stage they apply a PCFG to extract possible parses, then at the second stage select the best parse from the set of possible parses (i.e. rerank this set) employing a large feature set (Collins, 2000; Charniak and Johnson, 2005). There is little related"
C12-1052,D08-1017,0,0.0200495,"50 and 100-best parses to rerank and filtered out rare features (which occurred in less than 5 sentences). We employed the ranking MaxEnt implementation of the MALLET package (McCallum, 2002) and optimized the L2 regularizer coefficient on the development set. 5.3 Baseline Feature Sets For conducting baseline dependency parsing experiments, we employed the feature set of Bohnet (2010). For the stacking of graph-based and transition-based dependency parsers, we used the feature template definitions from Nivre and McDonald (2008) which was extended by grandchildren factors (similarly to Torres Martins et al. (2008)). For phrase structure reranking we utilized the features of Charniak and Johnson (2005) and for German we reimplemented the feature templates of Versley and Rehbein (2009) as baseline feature sets. The latter is the state-of-the-art feature set for German, which consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (like the clustering of unknown words according to their context of occurrences and PP attachment statistics gathered from the automatic POS tagged DE-WaC corpus, a 1.7G words sampl"
C12-1052,N03-1033,0,0.0207322,"task (Kübler, 2008) for phrase structure parsing. For dependency parsing, we used the dependency corpora of the CoNLL-2009 shared task, cf. (Hajiˇc et al., 2009) (which consists of automatically converted trees from a part of the Tiger Treebank). The phrase structure parsers traditionally conduct POS tagging during parsing (the different POS alternatives are on the chart). For obtaining POS tags for the dependency parsing experiments, we jackknifed the training data 10 fold, i.e. we trained the POS tagger on nine folds and tagged the tenth fold. On the English training set, the POS tagger of Toutanova et al. (2003) achieves an accuracy of 97.1, on the development set, 97.2 and the test set, 97.3. For German, we used a SVM-based tagger and we obtained on the training set an accuracy of 97.2, on the development set, 97.5 and on the test set, 97.4. We followed the same jackknifing procedure in the stacking experiments in order to obtain the parses from which the features are extracted. We generated the dependency and constituent parses of the training corpus by training the respective parser on nine folds and parsing the tenth fold. During parsing the test set and development set we utilized the parses fro"
C12-1052,W09-3820,0,0.222646,"e–all), VP-PP, VP-PP-LOC (from invite–to). We also investigated the role of case and grammatical functions of the phrase structure parser in German and extended the POSRel and ConstRel feature sets by adding this information to the labels. Note that the value of outArc is 1 iff the word span in question has a dominating dependency subtree in the automatic parse. Wang and Zong (2010) prune hyperedges with outArc= 6 1 thus this feature can be regarded as a generalization of their approach. These features are similar in nature to the lexical head-based features of Charniak and Johnson (2005) and Versley and Rehbein (2009) but their role is different. Those dependency-like features try to describe the local hyperedges using the internal state of the parsing approach while we exploit here a globally (i.e. sentence-level) optimized dependency parse tree which represents external knowledge to the parser. 5 5.1 Experimental Setting Data Sets We used the Penn Treebank (section 23 served as test set and section 22 and 24 were used as development set in the phrase-structure and dependency experiments, respectively) with the Penn2Malt converter, and the head-finding rules of Yamada and Matsumoto (2003) for our experime"
C12-1052,C10-2148,0,0.217194,"Our approach can be regarded as a special stacking procedure (Nivre and McDonald, 2008), specifically, the stacking of a phrase structure parser with a dependency parser. In our previous work (Farkas et al., 2011), we reported results with a stacking approach for phrase structure parsing evaluated on a German corpus. We focus herein on the reverse direction as well, i.e. we define features for dependency parsers, we report performance outstanding scores on English for both directions, compare to the state-of-the-art results and carried out a detailed analysis of the stacking’s contributions. Wang and Zong (2010) introduced a procedure that exploits dependency parses to improve a phrase structure parser. They used automatic dependency parses for pruning the chart of a phrase structure parser and reported a significant improvement. One of our feature templates for the phrase structure parser can be regarded as a generalization of this approach. 3 Dependency Parser Exploiting Phrase Structure Parses In this study we focus on graph-based parsers, however, our features from the phrase structures can also be adapted to a transition-based parser. Graph-based dependency parsers decompose the dependency struc"
C12-1052,I11-1140,0,0.0629179,"forest (chart) (Huang, 2008). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set). These methods employ a large feature set (usually a few millions features) (Collins, 2000; Charniak and Johnson, 2005). The n-best list approaches can straightforwardly employ local and non-local features as well because they decide at the sentence-level (Charniak and Johnson, 2005) while involving non-local features is more complicated in the forest-based approaches and studies show only a minor empirical advantage of the latter approach (Huang, 2008; Wang and Zong, 2011). In this study, we experiment with n-best list reranking using a Maximum Entropy machine learning model and our goal is to investigate the extension of the standard feature set of these models by features extracted from the automatic dependency parse of the sentence in question. 4.1 Features Defined on Dependency Parses The objective of the features defined for phrase structure parsing is to characterize the divergence/similarity of constituents with the corresponding part of the automatic (1-best) dependency parse of the sentence in question. We defined three feature templates for representi"
C12-1052,W03-3023,0,0.727028,"bank and on the German Tiger Treebank for stacking a phrase structure parser on and a dependency parser and vice versa. The added value of the approach in the dependency parsing environment is still considerable in the presence of other extensions. • We give explanations why the proposed stacking approach works. 850 2 Related Work A number of studies have addressed feature-rich dependency and phrase structure parsing, cf. (Nivre et al., 2004; McDonald et al., 2005b; Charniak and Johnson, 2005; Huang, 2008). The two main approaches to dependency parsing are transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre, 2003; Titov and Henderson, 2007), and graph-based dependency parsing (Eisner, 1996; McDonald et al., 2005a; Carreras, 2007; Rush et al., 2010). The most successful supervised phrase structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consist of two stages. At the first stage they apply a PCFG to extract possible parses, then at the second stage select the best parse from the set of possible parses (i.e. rerank this set) employing a large feature set (Collins, 2000; Charniak and"
C12-1052,W08-1008,0,\N,Missing
C12-2105,P04-1082,0,0.203759,"rve the parallelism. The German example on the bottom shows a coordination of two sentences that share the finite and the passive auxiliary with each other, both represented as a phonetically empty head in the structure. By introducing empty nodes into the annotation, the parallelism in the underlying syntactic structure of the two conjuncts is preserved. We would like to stress that the problem of empty heads in dependency syntax is rather different from the problem of introducing trace elements previously addressed by work on the English Penn Treebank (Johnson, 2002; Dienes and Dubey, 2003; Campbell, 2004). The PTB encodes a lot of different elements that do not show on the surface, but most of these would be leaf nodes in dependency representation.1 1 There is a small number of cases, where the PTB annotates a missing verb (marked as *?*, see Section 4.6 in Bies et al. (1995)). We found 581 instances of those in the whole corpus, 293 of which were dominated by a VP node. Only those empty elements correspond to empty heads in a dependency representation since they would normally have dependents on their own. But in contrast to dependency formalisms, it is not a problem to annotate a head-less p"
C12-2105,W11-0417,0,0.208415,"ian. We conclude with an error analysis and a discussion of the results. 2 Related Work We are aware of two previous papers where the issue of empty heads has been addressed in the context of dependency parsing: One is Dukes and Habash (2011) who present a parser for the Quranic Arabic Dependency Treebank, which also contains empty heads. Unfortunately, they do not evaluate or discuss the role of empty heads. Their solution of the problem – introducing a new transition into a transition-based parser – is similar to one of our proposed procedures (the in-parsing approach). The other work is by Chaitanya et al. (2011), who use hand-crafted rules to recover empty nodes from the output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first pars"
C12-2105,P03-1055,0,0.710356,"ead can be used to preserve the parallelism. The German example on the bottom shows a coordination of two sentences that share the finite and the passive auxiliary with each other, both represented as a phonetically empty head in the structure. By introducing empty nodes into the annotation, the parallelism in the underlying syntactic structure of the two conjuncts is preserved. We would like to stress that the problem of empty heads in dependency syntax is rather different from the problem of introducing trace elements previously addressed by work on the English Penn Treebank (Johnson, 2002; Dienes and Dubey, 2003; Campbell, 2004). The PTB encodes a lot of different elements that do not show on the surface, but most of these would be leaf nodes in dependency representation.1 1 There is a small number of cases, where the PTB annotates a missing verb (marked as *?*, see Section 4.6 in Bies et al. (1995)). We found 581 instances of those in the whole corpus, 293 of which were dominated by a VP node. Only those empty elements correspond to empty heads in a dependency representation since they would normally have dependents on their own. But in contrast to dependency formalisms, it is not a problem to annot"
C12-2105,W11-2912,0,0.42051,"oach where the presence of empty heads is determined by a classifier run prior to parsing. The paper is structured as follows: we first review some related work and continue with the presentation of the three different methods. We then define the metric that we use to measure the quality of the empty head prediction and use it to evaluate parsing experiments on German and Hungarian. We conclude with an error analysis and a discussion of the results. 2 Related Work We are aware of two previous papers where the issue of empty heads has been addressed in the context of dependency parsing: One is Dukes and Habash (2011) who present a parser for the Quranic Arabic Dependency Treebank, which also contains empty heads. Unfortunately, they do not evaluate or discuss the role of empty heads. Their solution of the problem – introducing a new transition into a transition-based parser – is similar to one of our proposed procedures (the in-parsing approach). The other work is by Chaitanya et al. (2011), who use hand-crafted rules to recover empty nodes from the output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, pro"
C12-2105,N10-1115,0,0.0348517,"recover empty nodes from the output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In"
C12-2105,P02-1018,0,0.449938,"ces, an empty head can be used to preserve the parallelism. The German example on the bottom shows a coordination of two sentences that share the finite and the passive auxiliary with each other, both represented as a phonetically empty head in the structure. By introducing empty nodes into the annotation, the parallelism in the underlying syntactic structure of the two conjuncts is preserved. We would like to stress that the problem of empty heads in dependency syntax is rather different from the problem of introducing trace elements previously addressed by work on the English Penn Treebank (Johnson, 2002; Dienes and Dubey, 2003; Campbell, 2004). The PTB encodes a lot of different elements that do not show on the surface, but most of these would be leaf nodes in dependency representation.1 1 There is a small number of cases, where the PTB annotates a missing verb (marked as *?*, see Section 4.6 in Bies et al. (1995)). We found 581 instances of those in the whole corpus, 293 of which were dominated by a VP node. Only those empty elements correspond to empty heads in a dependency representation since they would normally have dependents on their own. But in contrast to dependency formalisms, it i"
C12-2105,P06-2066,0,0.0283657,"resort to a swap operation as is done in Tratz and Hovy (2011). It also increases theoretical decoding complexity to O(n2 ). However, there are non-projective structures that cannot be produced by this approach.2 To allow the derivation of these structures, we reintroduce the swap operation from the parser in Tratz and Hovy (2011), but during training, the parser is only allowed to apply the swap operation in case of an ill-nested structure, which leads to a very small number of swaps. 2 These structures do not fulfill the well-nestedness condition that is described in Bodirsky et al. (2005); Kuhlmann and Nivre (2006) and appear for example in German centerfield scrambling structures. 1083 The feature set of the parser uses the word forms, lemmata, POS tags, and already predicted dependency labels for the head and its prospective dependent, as well as combinations thereof for up to three surrounding tokens in the sentence. The same features and combinations are extracted for up to three surrounding partially built structures. We also add features for the left-most and right-most dependent of a token, the labels of the dependents, distance features, and valency features as proposed by Zhang and Nivre (2011)"
C12-2105,P05-1012,0,0.0104219,"guage-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so that it works like the LTAG dependency parser described in Shen and Joshi (2008), which allows an edge to attach to an inside node of an already built structure. This difference makes it possible to directly produce a large portion of non-p"
C12-2105,W04-2407,0,0.0203665,"eads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so that it works like the LTAG dependency parser described in Shen and Joshi (2008), which allows an edge to attach to an inside node of an already built structure. This difference makes it possible to directly produce a large portion of non-projective structures (e. g. sentence extraposition or WH-extraction) without having to resort to a swap operation as is done in Tratz and Ho"
C12-2105,W01-0708,0,0.0254884,"before to-infinitive constructions) whereas our empty heads can occur more freely due to the free word order of German and Hungarian. We therefore pursue here a clause-based empty head preinsertion procedure since we think that the decision about inserting an empty head (which is basically the identification of the absence of the verb) can be made on the clause-level. For this, we implemented a clause boundary identification module and a classifier that predicts whether an empty word form should be inserted into a particular clause. Clause boundary identification is a difficult problem (cf. (Sang and Déjean, 2001)) as clauses usually form a hierarchy – and this hierarchy is important for predicting the insertion of empty heads. Our clause boundary detector achieves f-scores of 92.6 and 86.8 on the German and Hungarian development datasets respectively. These results are in line with the state-of-the-art results on the English Penn Treebank (Carreras et al., 2005; Ram and Lalitha Devi, 2008). If we evaluate only the in-sentence clauses, we get f-scores of 85.4 and 78.2 for German and Hungarian respectively. In order to decide whether to insert an empty head, we implemented a classifier that decides for"
C12-2105,seeker-kuhn-2012-making,1,0.832743,"e of the verb in the verb-second word order of German). For Hungarian, the manual annotation of the position of the empty word forms is quite irregular and we insert them at the beginning of the clause. Finally, we train the best-first parser on the original training dataset containing the gold standard empty heads and use it to parse the sentences that contain the automatically inserted empty heads from the preinserter. 4 Experiments In order to test the parsing methods, we performed two experiments each: we trained the parser on the German TiGer corpus using the dependency representation by Seeker and Kuhn (2012) , and on the Szeged Dependency Treebank of Hungarian (Vincze et al., 2010), both of which data sets explicitly represent empty heads in the dependency trees. Table 1 shows the data sizes and the splits we used for the experiment. The German data was preprocessed (lemma, POS, morphology) with the mate-tools,4 the Hungarian data comes with automatic annotation.5 data set German Hungarian # sentences 50,474 81,960 training # sents # empty 36,000 2,618 61,034 14,850 development # sents # empty 2,000 117 11,688 2,536 # sents 10,472 9,238 test # empty 722 2,106 Table 1: Data sets 4.1 Evaluation Met"
C12-2105,D08-1052,0,0.0558341,"best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so that it works like the LTAG dependency parser described in Shen and Joshi (2008), which allows an edge to attach to an inside node of an already built structure. This difference makes it possible to directly produce a large portion of non-projective structures (e. g. sentence extraposition or WH-extraction) without having to resort to a swap operation as is done in Tratz and Hovy (2011). It also increases theoretical decoding complexity to O(n2 ). However, there are non-projective structures that cannot be produced by this approach.2 To allow the derivation of these structures, we reintroduce the swap operation from the parser in Tratz and Hovy (2011), but during training"
C12-2105,P07-1096,0,0.0170372,"eve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-first parser in Goldberg and Elhadad (2010), the decoding algorithm is modified so th"
C12-2105,D11-1116,0,0.134076,"e output of a rule-based dependency parser for the Hindi Dependency Treebank. They achieve good results on some phenomena and a bit lower results on others, proving that it is indeed possible to treat this problem in syntactic processing. However, given that their data base is very small, and they used a rule-based, language-specific approach, the question remains if we can use statistical learning to address this problem. 3 Approaches for Parsing with Empty Heads The parser that we use for our experiment is basically a best-first parser like the ones described in (Goldberg and Elhadad, 2010; Tratz and Hovy, 2011), which is trained with the Guided Learning technique proposed in Shen et al. (2007) embedded in a MIRA framework (Crammer et al., 2003). The best-first parsing approach has the advantage that it is easy to modify in order to allow for the introduction of empty heads, while for graph-based parsers (McDonald et al., 2005) it is not even clear how to do it. The approach is also more suitable here than the standard transition-based approach (Nivre et al., 2004), since it can build context on both sides of the current attachment site while it achieves competitive results. In contrast to the best-f"
C12-2105,vincze-etal-2010-hungarian,0,0.105132,"nual annotation of the position of the empty word forms is quite irregular and we insert them at the beginning of the clause. Finally, we train the best-first parser on the original training dataset containing the gold standard empty heads and use it to parse the sentences that contain the automatically inserted empty heads from the preinserter. 4 Experiments In order to test the parsing methods, we performed two experiments each: we trained the parser on the German TiGer corpus using the dependency representation by Seeker and Kuhn (2012) , and on the Szeged Dependency Treebank of Hungarian (Vincze et al., 2010), both of which data sets explicitly represent empty heads in the dependency trees. Table 1 shows the data sizes and the splits we used for the experiment. The German data was preprocessed (lemma, POS, morphology) with the mate-tools,4 the Hungarian data comes with automatic annotation.5 data set German Hungarian # sentences 50,474 81,960 training # sents # empty 36,000 2,618 61,034 14,850 development # sents # empty 2,000 117 11,688 2,536 # sents 10,472 9,238 test # empty 722 2,106 Table 1: Data sets 4.1 Evaluation Method Since the number of edges in the gold standard does not always equal th"
C12-2105,P11-2033,0,0.0210148,"lmann and Nivre (2006) and appear for example in German centerfield scrambling structures. 1083 The feature set of the parser uses the word forms, lemmata, POS tags, and already predicted dependency labels for the head and its prospective dependent, as well as combinations thereof for up to three surrounding tokens in the sentence. The same features and combinations are extracted for up to three surrounding partially built structures. We also add features for the left-most and right-most dependent of a token, the labels of the dependents, distance features, and valency features as proposed by Zhang and Nivre (2011) but adapted to the best-first decoder. For internal feature representation and combination the parser implements the hash kernel method by Bohnet (2010). 3.1 Empty Head Introduction during Parsing For the first method, we change the parser so that it can decide for an empty head during the parsing itself. To the three moves that the standard parser can perform – attach_left(label), attach_right(label), and swap – we add a fourth move (see Figure 2), that allows the parser to introduce an empty head for a particular dependent (together with a dependency label). This is similar in spirit to the"
C14-1132,C10-1011,0,0.0650955,"Missing"
C14-1132,C12-1052,1,0.930312,"r on the gold standard constituency data and converting the output into dependency format. convDep: training the Bohnet parser without dependency labels on the silver standard data. conjunctions or adverbs – that require manual checking even if automatic conversion from constituency to dependency is applied. 5 Pre- or Post Conversion? It is well known that for English, converting a constituency parser’s output to dependency format (post conversion) can achieve competitive ULA scores to a dependency parser’s output trained on automatically converted trees (pre conversion) (Petrov et al., 2010; Farkas and Bohnet, 2012). One of the possible reasons for this may be that English is a configurational language, hence constituency parsers are expected to perform better here. In this paper, we investigate whether this is true for Hungarian, which is the prototype of morphologically rich languages with free word order. We employed the product-of-grammars procedure (Petrov, 2010) of the Berkeleyparser (Petrov et al., 2006), where grammars are trained on the same dataset but with different initialization setups, which leads to different grammars. We trained 8 grammars and used tree-level inference. The output of the"
C14-1132,E12-1007,1,0.924075,"n. The differences between them originate from the characteristics of constituent and dependency syntax. 3 Converting Constituency Trees to Dependency Trees In this section, we present our methods to convert constituency trees to dependency trees and we also discuss the most typical sources of errors during conversion. 3.1 Conversion rules In order to convert constituency trees to dependency trees, we used a rule based system. Sentences with virtual dependency nodes were omitted, as they are not annotated in the constituent treebank and their treatment in dependency trees is also problematic (Farkas et al., 2012; Seeker et al., 2012). As a result, we worked with 7,372 sentences and 162,960 tokens. First, we determined the head of each clause (CP) and the relations between CPs in complex sentences. In most cases the head of the CP is a finite verb, if the CP contains no finite verb, the head is the either an infinitive verb or a participle, if none of these are present in the CP, the head can be a nominal expression. The relations between the CP heads make up the base of the dependency structure using ROOT relation for the sentence’s main verb, COORD for coordination and ATT for subordination, as well"
C14-1132,P06-1055,0,0.0599368,"output to dependency format (post conversion) can achieve competitive ULA scores to a dependency parser’s output trained on automatically converted trees (pre conversion) (Petrov et al., 2010; Farkas and Bohnet, 2012). One of the possible reasons for this may be that English is a configurational language, hence constituency parsers are expected to perform better here. In this paper, we investigate whether this is true for Hungarian, which is the prototype of morphologically rich languages with free word order. We employed the product-of-grammars procedure (Petrov, 2010) of the Berkeleyparser (Petrov et al., 2006), where grammars are trained on the same dataset but with different initialization setups, which leads to different grammars. We trained 8 grammars and used tree-level inference. The output of the parser was then automatically converted to dependency format, based on the rules described in Section 3 (BerkeleyConv). Second, we used the silver standard dependency treebank for training the Bohnet parser (convDep). Since our constituency parser did not produce grammatical functions for the nodes, we trained the Bohnet parser on unlabeled dependency trees in order to ensure a fair comparison here ("
C14-1132,D10-1069,0,0.154876,"the quality of a rule-based automatic conversion from constituency to dependency trees, to compare the two sets of manual annotations and also the output of constituency and dependency parsers trained on converted and gold standard dependency trees. We investigate the effect of automatic conversions related to the two parsing paradigms as well. It is well known that for English, the automatic conversion of a constituency parser’s output to dependency format can achieve competitive unlabeled attachment scores (ULA) to a dependency parser’s output trained on automatically converted trees1 (cf. Petrov et al. (2010)). One of the possible explanations for this is that English is a configurational language, hence constituency parsers have advantages over dependency parsers here. We check whether this hypothesis holds for Hungarian too, which is the prototype of free word order languages. In this paper, we compare three pairs of dependency analyses in order to evaluate the usefulness of converted trees. First, we examine the errors of the conversion itself by comparing the converted dependency trees with the manually annotated gold standard ones. Second, we argue for the importance of training parsers on go"
C14-1132,C12-2105,1,0.858462,"tween them originate from the characteristics of constituent and dependency syntax. 3 Converting Constituency Trees to Dependency Trees In this section, we present our methods to convert constituency trees to dependency trees and we also discuss the most typical sources of errors during conversion. 3.1 Conversion rules In order to convert constituency trees to dependency trees, we used a rule based system. Sentences with virtual dependency nodes were omitted, as they are not annotated in the constituent treebank and their treatment in dependency trees is also problematic (Farkas et al., 2012; Seeker et al., 2012). As a result, we worked with 7,372 sentences and 162,960 tokens. First, we determined the head of each clause (CP) and the relations between CPs in complex sentences. In most cases the head of the CP is a finite verb, if the CP contains no finite verb, the head is the either an infinitive verb or a participle, if none of these are present in the CP, the head can be a nominal expression. The relations between the CP heads make up the base of the dependency structure using ROOT relation for the sentence’s main verb, COORD for coordination and ATT for subordination, as well as CONJ in the case o"
C14-1132,N10-1003,0,\N,Missing
C14-1132,W13-4917,1,\N,Missing
C14-1132,vincze-etal-2010-hungarian,1,\N,Missing
D11-1070,W07-1011,0,0.193543,"rs (e.g. auxiliaries like might and can); they may refer to a subject which differs from the target entity of the task (e.g. clinical notes usually contain information about the family history of the patient); or the semantic content of the shifter may change the role of the target span of a text (e.g. a sportsman can play for or against a particular team). We call these phenomena content shifters and the task of identifying them content shift detection (CSD). Existing CSD approaches focus on a particular class of language phenomena (especially negation or hedging) and use hand-crafted rules (Chapman et al., 2007) or a supervised learning approach that exploits corpora manually annotated at the token-level for a particular type of content shifter (Morante et al., 2009). Moreover higher level applications (like document labeling and information extraction) use a separate CSD module which is developed independently from the target task. We argue that the nature of content shifters is domain and task dependent, so training corpora (at the token-level) are required for content shifters which are important for a particular task but the construction of such training corpora is expensive. Here, we propose an"
D11-1070,W10-3001,1,0.76909,"Missing"
D11-1070,P09-2044,0,0.0137174,"on for negation, certainty and factuality in the biological (Medlock and Briscoe, 2007; Vincze et al., 2008), newswire (Strassel et al., 2008; Sauri and Pustejovsky, 2009) and encyclopedical (Farkas et al., 2010) domains. Exploiting these corpora, machine learning models were also developed. Solving the sentencelevel task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or nonspeculative. Szarvas (2008) extended their methodology to use n-gram features and a semi-supervised selection of the keyword features. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags and syntactic patterns. For in-sentence negation and speculation detection, Morante et al. (2009) developed scope – i.e. content shifted text spans – detectors for negation and speculation following a supervised sequence label¨ ur and Radev (2009) develing approach, while Ozg¨ oped a rule-based system that exploits syntactic patterns. The goal of the CoNLL 2010 Shared Task (Farkas et al., 2010) was to develop linguistic scope detectors as well. The participants usually followed"
D11-1070,W09-1418,0,0.0195502,"actic patterns. The goal of the CoNLL 2010 Shared Task (Farkas et al., 2010) was to develop linguistic scope detectors as well. The participants usually followed a supervised sequence labeling approach or used a rule-based system that exploits syntactic patterns. The approach of classifying identified events into whether they fall under negation or speculation was followed by Sauri and Pustejovsky (2009) and the participants of the BioNLP’09 Shared Task (Kim et al., 2009). Here the systems investigated the syntax path between the event trigger and a cue word (which came from a small lexicon) (Kilicoglu and Bergler, 2009; Aramaki et al., 2009). Our approach differs from the previous works fundamentally. We deal with the two tasks (information-oriented document classification and 761 content shift detection) together and introduce a colearning approach for them. Our approach handles content shifters in a data-driven and generalized way i.e. it is not specialized for a certain class of language phenomena. Instead it tries to recognize task-specific syntactic and semantic patterns which are responsible for semantic changes or irrelevance. In addition, we have no access to a goldstandard sentence-level or in-sent"
D11-1070,W09-1401,0,0.0162353,"culation following a supervised sequence label¨ ur and Radev (2009) develing approach, while Ozg¨ oped a rule-based system that exploits syntactic patterns. The goal of the CoNLL 2010 Shared Task (Farkas et al., 2010) was to develop linguistic scope detectors as well. The participants usually followed a supervised sequence labeling approach or used a rule-based system that exploits syntactic patterns. The approach of classifying identified events into whether they fall under negation or speculation was followed by Sauri and Pustejovsky (2009) and the participants of the BioNLP’09 Shared Task (Kim et al., 2009). Here the systems investigated the syntax path between the event trigger and a cue word (which came from a small lexicon) (Kilicoglu and Bergler, 2009; Aramaki et al., 2009). Our approach differs from the previous works fundamentally. We deal with the two tasks (information-oriented document classification and 761 content shift detection) together and introduce a colearning approach for them. Our approach handles content shifters in a data-driven and generalized way i.e. it is not specialized for a certain class of language phenomena. Instead it tries to recognize task-specific syntactic and"
D11-1070,P03-1054,0,0.00535801,"Missing"
D11-1070,W04-3103,0,0.0853017,"s, places or organisations. Some items of information are available about these entities in the form of categories and infoboxes assigned to articles. Automatic document labeling methods can be trained based on these assignments (Sch¨onhofen, 2006), but these labels do not refer to the main theme of the article but to a certain type of information. Existing content shift detection approaches focus on a particular class of language phenomena, especially on negation and hedge recognitions. Available tools work mainly on clinical and biological domains. The first systems were fully hand-crafted (Light et al., 2004; Friedman et al., 1994; Chapman et al., 2007) without any empirical evaluation on a dedicated corpus. Recently, there have been several corpora published with manual sentence-, event- or token-level annotation for negation, certainty and factuality in the biological (Medlock and Briscoe, 2007; Vincze et al., 2008), newswire (Strassel et al., 2008; Sauri and Pustejovsky, 2009) and encyclopedical (Farkas et al., 2010) domains. Exploiting these corpora, machine learning models were also developed. Solving the sentencelevel task, Medlock and Briscoe (2007) used single words as input features in o"
D11-1070,P07-1125,0,0.0161636,"main theme of the article but to a certain type of information. Existing content shift detection approaches focus on a particular class of language phenomena, especially on negation and hedge recognitions. Available tools work mainly on clinical and biological domains. The first systems were fully hand-crafted (Light et al., 2004; Friedman et al., 1994; Chapman et al., 2007) without any empirical evaluation on a dedicated corpus. Recently, there have been several corpora published with manual sentence-, event- or token-level annotation for negation, certainty and factuality in the biological (Medlock and Briscoe, 2007; Vincze et al., 2008), newswire (Strassel et al., 2008; Sauri and Pustejovsky, 2009) and encyclopedical (Farkas et al., 2010) domains. Exploiting these corpora, machine learning models were also developed. Solving the sentencelevel task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or nonspeculative. Szarvas (2008) extended their methodology to use n-gram features and a semi-supervised selection of the keyword features. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences"
D11-1070,W09-1203,0,0.0677704,"Missing"
D11-1070,W07-1013,0,0.212568,"extraction task as the task is to assign class labels to documents, and the training dataset contains labels just at this level. These special tasks lie somewhere between information extraction and document classification and require special approaches to solve them. We will call them Information-oriented document labeling throughout this paper. There are several application areas where information-oriented document labels are naturally present in an enormous amount like clinical records, Wikipedia categories and usergenerated tags of news. Previous evaluation campaigns (Uzuner et al., 2008; Pestian et al., 2007; Uzuner, 2009) demonstrated that information-oriented document labeling can be effectively performed by looking up indicator phrases which can be gathered by hand, by corpus statistics or in a hybrid way. However these campaigns also highlighted that the analysis of the local context of the indicator phrases is crucial. For instance, in the smoking habit detection task there are a few indicator words (e.g. smokes, cigarette) and the local context of their occurrences in texts should Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 759–770, c Edinbu"
D11-1070,strassel-etal-2008-linguistic,0,0.0228612,"ion. Existing content shift detection approaches focus on a particular class of language phenomena, especially on negation and hedge recognitions. Available tools work mainly on clinical and biological domains. The first systems were fully hand-crafted (Light et al., 2004; Friedman et al., 1994; Chapman et al., 2007) without any empirical evaluation on a dedicated corpus. Recently, there have been several corpora published with manual sentence-, event- or token-level annotation for negation, certainty and factuality in the biological (Medlock and Briscoe, 2007; Vincze et al., 2008), newswire (Strassel et al., 2008; Sauri and Pustejovsky, 2009) and encyclopedical (Farkas et al., 2010) domains. Exploiting these corpora, machine learning models were also developed. Solving the sentencelevel task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or nonspeculative. Szarvas (2008) extended their methodology to use n-gram features and a semi-supervised selection of the keyword features. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags"
D11-1070,P08-1033,0,0.138264,"edicated corpus. Recently, there have been several corpora published with manual sentence-, event- or token-level annotation for negation, certainty and factuality in the biological (Medlock and Briscoe, 2007; Vincze et al., 2008), newswire (Strassel et al., 2008; Sauri and Pustejovsky, 2009) and encyclopedical (Farkas et al., 2010) domains. Exploiting these corpora, machine learning models were also developed. Solving the sentencelevel task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or nonspeculative. Szarvas (2008) extended their methodology to use n-gram features and a semi-supervised selection of the keyword features. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags and syntactic patterns. For in-sentence negation and speculation detection, Morante et al. (2009) developed scope – i.e. content shifted text spans – detectors for negation and speculation following a supervised sequence label¨ ur and Radev (2009) develing approach, while Ozg¨ oped a rule-based system that exploits syntactic patterns. The goal of th"
D11-1070,W08-0606,1,0.876943,"Missing"
D11-1070,W09-1324,0,\N,Missing
D11-1070,D09-1145,0,\N,Missing
D12-1095,P05-1022,0,0.640872,"anking for phrase structure parsing. The proposed framework can be regarded as an extension of this approach. It has several advantages compared with the perceptron-based forest reranker. In this paper we focus on the most important one – and briefly discuss two others in Section 5 – which is enabling the use of any kind of learning to rank approaches. While the perceptron is fast to train, other machine learning approaches usually outperform it. Most of the existing learning to rank approaches are built on linear models and evaluate the candidates independently of each other (such as MaxEnt (Charniak and Johnson, 2005), SVMRank (Joachims, 2002), SoftRank (Guiver and Snelson, 2008)). Thus the choice 1039 of the learning method does not influence parsing time. We believe that the real bottleneck of parsing applications is parsing time and not training time. On the other hand, they can learn a better model (at the cost of higher training time) than the Perceptron. In theory, we can imagine learning to rank approaches which can not be reduced to the individual scoring of candidates at prediction time, for instance a decision tree-based pairwise ranker. Although such methods would also fit into the general subtr"
D12-1095,P04-1015,0,0.0931214,"the parsing algorithm reduces to perceptron-based forest parsing. If the “selection strategy” utilizes the base system ranking and training starts with a filtering step which keeps only candidate sets from the root node of the forest we get the offline version of the training procedure of the perceptron-based forest reranker of Huang (2008). As our approach is based on local ranking (local update in the online learning literature), it is highly related to early update which looks for the first local decision point where the oracle parse falls out from the beam. Early update was introduced by Collins and Roark (2004) for incremental parsing and adopted to forest reranking by Wang and Zong (2011). Besides phrase structure parsing, the forest reranking approach was successfully applied for dependency parsing as well. Hayashi et al. (2011) introduced a procedure where the interpolation of a generative and a forest-based discriminative parser is exploited. From the algorithmic point of view, our approach is probably most closely related to Searn (Daum´e et al., 2009) and Magerman (1995) as we also employ a particular machine learned model for a sequence of local decisions. The topological order of the parse f"
D12-1095,W11-2924,1,0.848015,"is different from the ’perceptron with global training’ as we conduct updates at every local decision point and we do offline training (’subtree ranking by AvgPer’). • The subtree ranker method using Maximum Entropy training (’subtree ranking by MaxEnt’). 1042 We (re)implemented these methods and used the same forests and the same feature sets for the comparative experiments. 4.4 Implementation Details We used the first-stage PCFG parser of Charniak and Johnson (2005) for English and BitPar (Schmid, 2004) for German. BitPar employs a grammar engineered for German (for details please refer to Farkas et al. (2011)). These two parsers are state-of-the-art PCFG parsers for English and German, respectively. For German the base parser and the reranker operate on the conflation of constituent labels and grammatical functions. For English, we used the forest extraction and pruning code of Huang (2008). The pruning removes hyperedges where the difference between the cost of the best derivation using this hyperedge and the cost of the globally best derivation is above some threshold. For German, we used the pruned parse forest of Bitpar (Schmid, 2004). After computing the posterior probability of each hyperedg"
D12-1095,P07-1050,0,0.0193862,"arameter optimization. Another chief advantage of the framework is that arbitrary learning to rank methods can be applied. We evaluated our reranking approach on German and English phrase structure parsing tasks and compared it to various state-of-the-art reranking approaches such as the perceptron-based forest reranker. The subtree ranking approach with a Maximum Entropy model significantly outperformed the other approaches. 1 Introduction Reranking has become a popular technique for solving various structured prediction tasks, such as phrase-structure (Collins, 2000) and dependency parsing (Hall, 2007), semantic role labeling (Toutanova et al., 2008) and machine translation (Shen et al., 2004). The idea is to (re)rank candidates extracted by a base system exploiting a rich feature set and operating at a global (usually sentence) level. Reranking achieved significant gains over the base system in many tasks because it has access to information/features which are not computable in the base system. Reranking also outperforms discriminative approaches which try to handle the entire candidate universe (cf. Turian et al. (2006)) because the base system effectively and efficiently filters out many"
D12-1095,D11-1137,0,0.0951197,"for reranking is the n-best list ranking procedure, where the base system extracts its top n global-level candidates with associated goodness scores that define an initial ranking. Then the task is to rerank these candidates by using a rich feature set. The bottleneck of this approach is the small number of candidates considered. Compared to n-best lists, packed parse forests encode more candidates in a compact way. Forest reranking methods have been proposed, which can exploit the richer set of candidates and they have been successfully applied for phrase-structure (Huang, 2008), dependency (Hayashi et al., 2011) parsing and machine translation (Li and Khudanpur, 2009) as well. Huang (2008) introduced the perceptron-based forest reranking approach. The core of the algorithm is a beam-search based decoder operating on the packed forest in a bottom-up manner. It follows the assumption that the feature values of the whole structure are the sum of the feature values of the local elements and they are designed to the usage of the perceptron update. Under these assumptions a 1-best Viterbi or beam-search decoder can be efficiently employed at parsing and training time. During training, it decodes the 1-best"
D12-1095,P08-1067,0,0.147466,"le. The standard approach for reranking is the n-best list ranking procedure, where the base system extracts its top n global-level candidates with associated goodness scores that define an initial ranking. Then the task is to rerank these candidates by using a rich feature set. The bottleneck of this approach is the small number of candidates considered. Compared to n-best lists, packed parse forests encode more candidates in a compact way. Forest reranking methods have been proposed, which can exploit the richer set of candidates and they have been successfully applied for phrase-structure (Huang, 2008), dependency (Hayashi et al., 2011) parsing and machine translation (Li and Khudanpur, 2009) as well. Huang (2008) introduced the perceptron-based forest reranking approach. The core of the algorithm is a beam-search based decoder operating on the packed forest in a bottom-up manner. It follows the assumption that the feature values of the whole structure are the sum of the feature values of the local elements and they are designed to the usage of the perceptron update. Under these assumptions a 1-best Viterbi or beam-search decoder can be efficiently employed at parsing and training time. Dur"
D12-1095,2008.amta-papers.12,0,0.0433754,"WSJ test 90.32 89.97 WB 83.83 83.34 Table 4: The results of the two selection strategies. Using the oracle trees proved to be better on each of the datasets. Extracting candidate lists from each of the local decision points might seem to be redundant. To gain some insight into this question, we investigated the effect of training instance filtering strategies on the Tiger treebank. We removed the training instances from the training sample T where the F-score of the oracle (sub)tree against the gold standard tree is less than a certain threshold (this data selection procedure was inspired by Li and Khudanpur (2008)). The idea behind this data selection is to eliminate bad training examples which might push the learner into the wrong direction. Figure 1 depicts the results on the Tiger treebank as a function of this data selection threshold. With this data selection strategy we could further gain 0.22 F-score percentage points achieving 79.58 (68.87) and we can conclude that omitting candidate sets far from the gold-standard tree helps training. Figure 1 also shows that too strict filtering hurts the performance. The result with threshold=90 is worse than the result without filtering. We should note that"
D12-1095,P95-1037,0,0.109089,"s for the first local decision point where the oracle parse falls out from the beam. Early update was introduced by Collins and Roark (2004) for incremental parsing and adopted to forest reranking by Wang and Zong (2011). Besides phrase structure parsing, the forest reranking approach was successfully applied for dependency parsing as well. Hayashi et al. (2011) introduced a procedure where the interpolation of a generative and a forest-based discriminative parser is exploited. From the algorithmic point of view, our approach is probably most closely related to Searn (Daum´e et al., 2009) and Magerman (1995) as we also employ a particular machine learned model for a sequence of local decisions. The topological order of the parse forest nodes can form the “sequence of choices” of Searn. The biggest differences between our approach and Searn are that we propose an approach employing beam search and the “policy” is a ranker in our framework instead of a multiclass classifier as there are no “actions” here, instead we have to choose from candidate sets in the forest reranking framework. In a wider sense, our approach can be regarded – like Searn – as an Inverse Reinforcement Learning approach where “"
D12-1095,C04-1024,1,0.772101,"of 0.3 on the German dataset. • The subtree ranker method using the Averaged Perceptron reranker. This is different from the ’perceptron with global training’ as we conduct updates at every local decision point and we do offline training (’subtree ranking by AvgPer’). • The subtree ranker method using Maximum Entropy training (’subtree ranking by MaxEnt’). 1042 We (re)implemented these methods and used the same forests and the same feature sets for the comparative experiments. 4.4 Implementation Details We used the first-stage PCFG parser of Charniak and Johnson (2005) for English and BitPar (Schmid, 2004) for German. BitPar employs a grammar engineered for German (for details please refer to Farkas et al. (2011)). These two parsers are state-of-the-art PCFG parsers for English and German, respectively. For German the base parser and the reranker operate on the conflation of constituent labels and grammatical functions. For English, we used the forest extraction and pruning code of Huang (2008). The pruning removes hyperedges where the difference between the cost of the best derivation using this hyperedge and the cost of the globally best derivation is above some threshold. For German, we used"
D12-1095,N04-1023,0,0.090629,"Missing"
D12-1095,J08-2002,0,0.0704792,"Missing"
D12-1095,W09-3820,0,0.465226,"† (67.97†) 79.36 (68.72) WSJ dev 90.58 90.81† 90.89 90.65† 91.14 WSJ test 89.60 90.01 90.11 89.97 90.32 WB 82.87 83.03† 83.55 83.04† 83.83 Table 2: The results achieved by various forest rerankers. The difference between the scores marked by † and the ’perceptron with global training’ were not statistically significant with p < 0.005 according to the the McNemar test. All other results are statistically different from this baseline. 2008) and selectively re-implemented feature templates from (Collins, 2000) and Charniak and Johnson (2005). For German we re-implemented the feature templates of Versley and Rehbein (2009) which is the state-of-the-art feature set for German. It consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (such as the clustering of unknown words according to their context of occurrence and PP attachment statistics gathered from the automatically POS tagged DE-WaC corpus, a 1.7G words sample of the German-language WWW). We filtered out rare features which occurred in less than 10 forests (we used the same non-tuned threshold for the English and German training sets as well). We also re-i"
D12-1095,I11-1140,0,0.240881,"strategy” utilizes the base system ranking and training starts with a filtering step which keeps only candidate sets from the root node of the forest we get the offline version of the training procedure of the perceptron-based forest reranker of Huang (2008). As our approach is based on local ranking (local update in the online learning literature), it is highly related to early update which looks for the first local decision point where the oracle parse falls out from the beam. Early update was introduced by Collins and Roark (2004) for incremental parsing and adopted to forest reranking by Wang and Zong (2011). Besides phrase structure parsing, the forest reranking approach was successfully applied for dependency parsing as well. Hayashi et al. (2011) introduced a procedure where the interpolation of a generative and a forest-based discriminative parser is exploited. From the algorithmic point of view, our approach is probably most closely related to Searn (Daum´e et al., 2009) and Magerman (1995) as we also employ a particular machine learned model for a sequence of local decisions. The topological order of the parse forest nodes can form the “sequence of choices” of Searn. The biggest differences"
D14-1103,N09-2054,0,0.0728471,"iversity of Munich, Germany § Department of Informatics, University of Szeged, Hungary ‡ Heidelberg Institute for Theoretical Studies, Heidelberg, Germany muellets@cis.lmu.de 2 Abstract Petrov et al. (2006) introduce generative splitmerge training for PCFGs and provide a fully automatic method for training state-of-the-art phrase structure parsers. They argue that the resulting latent annotations are linguistically meaningful. Sun et al. (2008) induce latent sub-states into CRFs and show that noun phrase (NP) recognition can be improved, especially if no part-of-speech features are available. Huang et al. (2009) apply split-merge training to create HMMs with latent annotations (HMM-LA) for Chinese POS tagging. They report that the method outperforms standard generative bigram and trigram tagging, but do not compare to discriminative methods. Eidelman et al. (2010) show that a bidirectional variant of latent HMMs with incorporation of prosodic information can yield state-of-the-art results in POS tagging of conversational speech. In this paper we propose a method to increase dependency parser performance without using additional labeled or unlabeled data by refining the layer of predicted part-of-spee"
D14-1103,N07-1051,0,0.0556405,"ile Hidden Markov Models with latent annotations (HMMLA) (Huang et al., 2009), stay somewhat behind the performance of state-of-the-art discriminative taggers (Eidelman et al., 2010). In this paper we address the question of whether the resulting latent POS tags are linguistically meaningful and useful for upstream tasks such as syntactic parsing. We find that this is indeed the case, leading to a procedure that significantly increases the performance of dependency parsers. The procedure is attractive because the refinement of predicted part-of-speech sequences using a coarse-tofine strategy (Petrov and Klein, 2007) is fast and efficient. More precisely, we show that incorporating the induced POS into a state-of-the-art dependency parser (Bohnet, 2010) gives increases in Labeled Attachment Score (LAS): from 90.34 to 90.57 for English and from 87.92 to 88.24 (resp. 88.35 to 88.51) for German without using (resp. with using) morphological features. 3 Split-Merge Training for HMMs Split-merge training for HMMs (Huang et al., 2009) iteratively splits every tag into two subtags. Word emission and tag transition probabilities of subtags are then initialized close to the values of the parent tags but with some"
D14-1103,P06-1055,0,0.172311,"tion of prosodic information can yield state-of-the-art results in POS tagging of conversational speech. In this paper we propose a method to increase dependency parser performance without using additional labeled or unlabeled data by refining the layer of predicted part-of-speech (POS) tags. We perform experiments on English and German and show significant improvements for both languages. The refinement is based on generative split-merge training for Hidden Markov models (HMMs). 1 Related Work Introduction Probabilistic Context-free Grammars with latent annotations (PCFG-LA) have been shown (Petrov et al., 2006) to yield phrase structure parsers with state-of-the-art accuracy. While Hidden Markov Models with latent annotations (HMMLA) (Huang et al., 2009), stay somewhat behind the performance of state-of-the-art discriminative taggers (Eidelman et al., 2010). In this paper we address the question of whether the resulting latent POS tags are linguistically meaningful and useful for upstream tasks such as syntactic parsing. We find that this is indeed the case, leading to a procedure that significantly increases the performance of dependency parsers. The procedure is attractive because the refinement o"
D14-1103,C00-2137,0,\N,Missing
D14-1103,C08-1106,0,\N,Missing
D14-1103,W09-1201,0,\N,Missing
D14-1103,petrov-etal-2012-universal,0,\N,Missing
D14-1103,D10-1080,0,\N,Missing
E12-1007,E03-1012,0,0.43377,"Missing"
E12-1007,C10-1011,0,0.333815,"ide the issue of the internal structure of NPs, most sentence-level syntactic information in Hungarian is conveyed ´ Kiss, by morphology, not by configuration (E. 2002). A large part of the methodology for syntactic parsing has been developed for English. However, parsing non-configurational and less configurational languages requires different techniques. In this study, we present results on Hungarian dependency parsing and we investigate this general issue in the case of English and Hungarian. We employed three state-of-the-art data-driven parsers (Nivre et al., 2004; McDonald et al., 2005; Bohnet, 2010), which achieved (un)labeled attachment scores on Hungarian not so different from the corresponding English scores (and even higher on certain domains/subcorpora). Our investigations show that the feature representation used by the data-driven parsers is so rich that they can – without any modification – effectively learn a reasonable model for non-configurational languages as well. We also conducted a systematic and comparative error analysis of the system’s outputs for Hungarian and English. This analysis highlights the challenges of parsing Hungarian and suggests that the further improvemen"
E12-1007,W06-2920,0,0.200297,"Missing"
E12-1007,D07-1101,0,0.0214338,"on-based system, which uses an arc-eager system along with support vector machines to learn the scoring function for transitions and which uses greedy, deterministic onebest search at parsing time. As one of the graphbased parsers, we employed the MST parser (McDonald et al., 2005) with a second-order feature decoder. It uses an approximate exhaustive search for unlabeled parsing, then a separate arc label classifier is applied to label each arc. The Mate parser (Bohnet, 2010) is an efficient second order dependency parser that models the interaction between siblings as well as grandchildren (Carreras, 2007). Its decoder works on labeled edges, i.e. it uses a single-step approach for obtaining labeled dependency trees. Mate uses a rich and 4 The JAVA implementation of the morphological analyser and the slightly modified POS tagger along with trained models are available at http://www.inf.u-szeged. hu/rgai/magyarlanc. 58 corpus newspaper short business fiction law computer composition #sent. 9189 8616 9279 8347 8653 22248 length 21.6 23.6 12.6 27.3 21.9 13.7 CPOS 97.2 98.0 96.9 98.3 96.4 96.7 DPOS 96.5 97.7 95.8 98.1 95.8 95.6 ULA 88.0 (90.0) 93.8 (94.8) 87.7 (89.4) 90.6 (90.7) 91.3 (92.8) 92.7 (9"
E12-1007,C96-1058,0,0.0840122,"ds inside of constituents to be consecutive and it naturally represent discontinuous constructions, which are frequent in languages where grammatical relations are often signaled by morphology instead of word order (McDonald and Nivre, 2011). The two main efficient approaches for dependency parsing are the graph-based and the transition-based parsers. The graph-based models look for the highest scoring directed spanning tree in the complete graph whose nodes are the words of the sentence in question. They solve the machine learning problem of finding the optimal scoring function of subgraphs (Eisner, 1996; McDonald et al., 2005). The transition-based approaches parse a sentence in a single left-to-right pass over the words. The next transition in these systems is predicted by a classifier that is based on history-related features (Kudo and Matsumoto, 2002; Nivre et al., 2004). Although the available treebanks for Hungarian are relatively big (82K sentences) and fully manually annotated, the studies on parsing Hungarian are rather limited. The Szeged (Constituency) Treebank (Csendes et al., 2005) con56 sists of six domains – namely, short business news, newspaper, law, literature, compositions"
E12-1007,D07-1097,0,0.0321724,"are efficiently identified by our morphological analyser. The most frequent morphological features which cannot be disambiguated at the word level are related to suffixes with multiple functions or the word itself cannot be unambiguously segmented into morphemes. Although the number of such ambiguous cases is low, they form important features for the parser, thus we will focus on the more accurate handling of these cases in future work. Comparison to CoNLL-2007 results: The best performing participant of the CoNLL-2007 Shared Task (Nivre et al., 2007) achieved an ULA of 83.6 and LAS of 80.3 (Hall et al., 2007) on the Hungarian corpus. The difference between the top performing English and Hungarian systems were 8.14 ULA and 9.3 LAS. The results reported in 2007 were significantly lower and the gap between English and Hungarian is higher than our current values. To locate the sources of difference we carried out other experiments with Mate on the CoNLL-2007 dataset using the gold-standard POS tags (the shared task used gold-standard POS tags for evaluation). First we trained and evaluated Mate on the original CoNLL-2007 datasets, where it achieved ULA 84.3 and LAS 80.0. Then we used the sentences of"
E12-1007,W02-2016,0,0.0111191,"The two main efficient approaches for dependency parsing are the graph-based and the transition-based parsers. The graph-based models look for the highest scoring directed spanning tree in the complete graph whose nodes are the words of the sentence in question. They solve the machine learning problem of finding the optimal scoring function of subgraphs (Eisner, 1996; McDonald et al., 2005). The transition-based approaches parse a sentence in a single left-to-right pass over the words. The next transition in these systems is predicted by a classifier that is based on history-related features (Kudo and Matsumoto, 2002; Nivre et al., 2004). Although the available treebanks for Hungarian are relatively big (82K sentences) and fully manually annotated, the studies on parsing Hungarian are rather limited. The Szeged (Constituency) Treebank (Csendes et al., 2005) con56 sists of six domains – namely, short business news, newspaper, law, literature, compositions and informatics – and it is manually annotated for the possible alternatives of words’ morphological analyses, the disambiguated analysis and constituency trees. We are aware of only two articles on phrase-structure parsers which were trained and evaluate"
E12-1007,J11-1007,0,0.0114111,"). This train of thought indicates that the cross-lingual comparison of final parser scores should be conducted very carefully. 3 Related work We decided to focus on dependency parsing in this study as it is a superior framework for nonconfigurational languages. It has gained interest in natural language processing recently because the representation itself does not require the words inside of constituents to be consecutive and it naturally represent discontinuous constructions, which are frequent in languages where grammatical relations are often signaled by morphology instead of word order (McDonald and Nivre, 2011). The two main efficient approaches for dependency parsing are the graph-based and the transition-based parsers. The graph-based models look for the highest scoring directed spanning tree in the complete graph whose nodes are the words of the sentence in question. They solve the machine learning problem of finding the optimal scoring function of subgraphs (Eisner, 1996; McDonald et al., 2005). The transition-based approaches parse a sentence in a single left-to-right pass over the words. The next transition in these systems is predicted by a classifier that is based on history-related features"
E12-1007,H05-1066,0,0.74539,"tence level. Leaving aside the issue of the internal structure of NPs, most sentence-level syntactic information in Hungarian is conveyed ´ Kiss, by morphology, not by configuration (E. 2002). A large part of the methodology for syntactic parsing has been developed for English. However, parsing non-configurational and less configurational languages requires different techniques. In this study, we present results on Hungarian dependency parsing and we investigate this general issue in the case of English and Hungarian. We employed three state-of-the-art data-driven parsers (Nivre et al., 2004; McDonald et al., 2005; Bohnet, 2010), which achieved (un)labeled attachment scores on Hungarian not so different from the corresponding English scores (and even higher on certain domains/subcorpora). Our investigations show that the feature representation used by the data-driven parsers is so rich that they can – without any modification – effectively learn a reasonable model for non-configurational languages as well. We also conducted a systematic and comparative error analysis of the system’s outputs for Hungarian and English. This analysis highlights the challenges of parsing Hungarian and suggests that the fur"
E12-1007,P05-1013,0,0.021246,"he internal structures of Named Entities and we imagine a pipeline where a Named Entity Recogniser precedes the parsing step. Empty copula: In the verbless clauses (predicative nouns or adjectives) the Szeged Dependency Treebank introduces virtual nodes (16,000 items in the corpus). This solution means that a similar tree structure is ascribed to the same sentence in the present third person singular and all the other tenses / persons. A further argument for the use of a virtual node is that the virtual node is always present at the syntactic level 2 Using the transitive closure definition of Nivre and Nilsson (2005). 57 corpus Hungarian English dev test dev test Malt ULA LAS 88.3 (89.9) 85.7 (87.9) 88.7 (90.2) 86.1 (88.2) 87.8 (89.1) 84.5 (86.1) 88.8 (89.9) 86.2 (87.6) MST ULA LAS 86.9 (88.5) 80.9 (82.9) 87.5 (89.0) 81.6 (83.5) 89.4 (91.2) 86.1 (87.7) 90.7 (91.8) 87.7 (89.2) Mate ULA LAS 89.7 (91.1) 86.8 (89.0) 90.1 (91.5) 87.2 (89.4) 91.6 (92.7) 88.5 (90.0) 92.6 (93.4) 90.3 (91.5) Table 1: Results achieved by the three parsers on the (full) Hungarian (Szeged Dependency Treebank) and English (CoNLL-2009) datasets. The scores in brackets are achieved with gold-standard POS tagging. since it is overt in al"
E12-1007,W04-2407,0,0.0175033,"Missing"
E12-1007,2004.eamt-1.17,0,0.0785525,"Missing"
E12-1007,N03-1033,0,0.00635951,"egedTreebank. Tools: We employed a finite state automatabased morphological analyser constructed from the morphdb.hu lexical resource (Tr´on et al., 2006) and we used the MSD-style morphological code system of the Szeged TreeBank (Alexin et al., 2003). The output of the morphological analyser is a set of possible lemma–morphological analysis pairs. This set of possible morphological analyses for a word form is then used as possible alternatives – instead of open and closed tag sets – in a standard sequential POS tagger. Here, we applied the Conditional Random Fields-based Stanford POS tagger (Toutanova et al., 2003) and carried out 5-fold-cross POS training/tagging inside the subcorpora.4 For the English experiments we used the predicted POS tags provided for the CoNLL-2009 shared task (Hajiˇc et al., 2009). As the dependency parser we employed three state-of-the-art data-driven parsers, a transitionbased parser (Malt) and two graph-based parsers (MST and Mate parsers). The Malt parser (Nivre et al., 2004) is a transition-based system, which uses an arc-eager system along with support vector machines to learn the scoring function for transitions and which uses greedy, deterministic onebest search at pars"
E12-1007,tron-etal-2006-morphdb,0,0.468383,"Missing"
E12-1007,vincze-etal-2010-hungarian,1,0.867873,"Missing"
E12-1007,W09-1201,0,\N,Missing
E12-1007,D07-1096,0,\N,Missing
E14-1015,H91-1060,0,0.436281,"nducted experiments on the treebanks of the 2013 shared task on ‘Statistical Parsing of Morphologically Rich Languages’ (Seddah et al., 2013). We used the train/dev/test splits of the shared task’s Basque (Aduriz et al., 2003), French (Abeill´e et al., 2003), Hebrew (Sima’an et al., 2001), German (Brants et al., 2002) and Hungarian (Csendes et al., 2005) treebanks. Table 1 shows the basic statistics of these treebanks, for a more detailed description about their annotation schemata, domain, preprocessing etc. please see Seddah et al. (2013). As evaluation metrics we employ the PARSEVAL score (Abney et al., 1991) along with the exact match accuracy (i.e. the ratio of perfect parse trees). We use the evalb implementation of the shared task1 . 4 Enhanced Lexical Models Before introducing our proposal and experiments with preterminal set optimisation, we have to offer a solution for the out-of-vocabulary (OOV) problem, which – because of the inflectional nature – is a crucial problem in morphologically rich lan1 Available at http://pauillac.inria.fr/ seddah/evalb_spmrl2013.tar.gz. An important ˜ change in this version compared to the original evalb is the penalization of unparsed sentences. 2 137 ( Ptb ("
E14-1015,J13-1005,1,0.899934,"Missing"
E14-1015,J13-1007,0,0.444914,"FG parser using latent annotations at nonterminals. Its basic idea is to iteratively split each non-terminal into subsymbols thus capturing the different subusage of them instead of manually designed annotations. The constituent parsing of morphologically rich languages is a much less investigated field. There exist constituent treebanks for several languages along with a very limited number of parsing reports on them. For instance, Petrov (2009) trained BerkeleyParser on Arabic, Bulgarian, French, German and Italian and he reported good accuracies, but there has been previous work on Hebrew (Goldberg and Elhadad, 2013), Korean (Choi et al., 1994) and Spanish (Le Roux et al., 2012) etc. The recently organized ‘Statistical Parsing of Morphologically Rich Languages’ (Seddah et al., 2013) addressed the dependency and constituency parsing of nine morphologically rich languages and provides useful benchmark datasets for these languages. Our chief contribution in this paper is a procedure to merge preterminal labels. The related work for this line of research includes the studies on manual refinement of preterminal sets such as Marton et al. (2010) and Le Roux et al. (2012). The most closely related approach to ou"
E14-1015,P08-1085,0,0.0218217,"om an external lexicon. We calculate the emission probabilities P (w|t) from the tagging probabilities P (t|w) by applying the Bayesian rule. The key question here is how to construct the external lexicon. For a baseline, Goldberg and Elhadad (2013) suggest using the uniform distribution over all possible morphological analyses coming from a morphological analyser (’uniform’). Goldberg and Elhadad (2013) also report considerable improvements over the ‘uniform’ baseline by relative frequencies counted on a large corpus which was automatically annotated in the unsupervised POS tagging paradigm (Goldberg et al., 2008). Here we show that even a supervised morphological tagger without a morphological analyzer can achieve the same level of improvement. We employ MarMot2 (Mueller et al., 2013) for predicting full morphological analysis (i.e. POS tags and morphological features jointly). MarMot is a Conditional Random Field tagger which incrementally creates forwardbackward lattices of increasing order to prune the P (t|w) = Experimental Setup We conducted experiments on the treebanks of the 2013 shared task on ‘Statistical Parsing of Morphologically Rich Languages’ (Seddah et al., 2013). We used the train/dev/"
E14-1015,C10-1011,0,0.0679298,"logy of the language at the lexical and constituent levels, while the last two templates might capture (dis)agreement at the morphological level. The motivation for using these features is that because of the free(er) word order of morphologically rich languages, morphological (dis)agreement can be a good indicator of attachment. Table 5 shows the added value of these feature templates over mainPOS (’extended’), which is again statistically significant in exact match. Exploiting the morphological agreement in syntactic parsing has been investigated in previous studies, e.g. the Bohnet parser (Bohnet, 2010) employs morphological feature value pairs similar to our feature templates and Seeker and Kuhn (2013) introduces an integer linear programming framework including constraints for morphological agreement. However, these works focus on dependency parsing and to the best of our knowledge, this is the first study on experimenting with atomic morphological features and their agreement in a constituency parsing. which are much smaller than full on German and Hebrew and it could not find any useful merge at Basque. The output of the merger procedure consists of one sixth of preterminals compared wit"
E14-1015,P08-1067,0,0.0264066,"The most closely related approach to our proposal is Dehdari et al. (2011), who defines metaheuristics to incrementally insert or remove morphological features. Their approach uses parser – training and parsing – as a black box evaluation of a preterminal set. In contrast, our proposal operates as a submodule of the BerkeleyParser, hence does not require the re-training of the parser for every possible preterminal set candidate, thus it is way more faster. The most successful supervised constituent parsers contain a second feature-rich discriminative parsing step (Charniak and Johnson, 2005; Huang, 2008; Chen and Kit, 2012) as well. At the first stage they apply a PCFG to extract posIn this study, we propose answers to the two main challenges of constituent parsing of morphologically rich languages, which are finding the optimal preterminal set and handling the huge number of wordforms. The size of the preterminal set in the standard context free grammar environment is crucial. If we use only the main POS tags as preterminals, we lose a lot of information encoded in the morphological description of the tokens. On the other hand, using the full morphological description as preterminal yields"
E14-1015,W12-3408,0,0.207286,"Missing"
E14-1015,P05-1022,0,0.557251,", April 26-30 2014. 2014 Association for Computational Linguistics et al., 2006) enriched with these three techniques achieved state-of-the-art results on each language. Fraser et al. (2013) that “... there is no clear evidence for preferring dependency parsing over constituency parsing in analyzing languages with rich morphology and instead argue that research in both frameworks is important.” 2 Related Work Constituent parsing of English is a well researched area. The field has been dominated by data-driven, i.e. treebank-based statistical approaches in the last two decades (Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). We extend here BerkeleyParser (Petrov et al., 2006), which is a PCFG parser using latent annotations at nonterminals. Its basic idea is to iteratively split each non-terminal into subsymbols thus capturing the different subusage of them instead of manually designed annotations. The constituent parsing of morphologically rich languages is a much less investigated field. There exist constituent treebanks for several languages along with a very limited number of parsing reports on them. For instance, Petrov (2009) trained BerkeleyParser on Arabic, Bulgarian, French, German"
E14-1015,J93-2004,0,0.0457132,"Missing"
E14-1015,A00-2018,0,0.121521,"thenburg, Sweden, April 26-30 2014. 2014 Association for Computational Linguistics et al., 2006) enriched with these three techniques achieved state-of-the-art results on each language. Fraser et al. (2013) that “... there is no clear evidence for preferring dependency parsing over constituency parsing in analyzing languages with rich morphology and instead argue that research in both frameworks is important.” 2 Related Work Constituent parsing of English is a well researched area. The field has been dominated by data-driven, i.e. treebank-based statistical approaches in the last two decades (Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). We extend here BerkeleyParser (Petrov et al., 2006), which is a PCFG parser using latent annotations at nonterminals. Its basic idea is to iteratively split each non-terminal into subsymbols thus capturing the different subusage of them instead of manually designed annotations. The constituent parsing of morphologically rich languages is a much less investigated field. There exist constituent treebanks for several languages along with a very limited number of parsing reports on them. For instance, Petrov (2009) trained BerkeleyParser on Arabi"
E14-1015,W10-1402,0,0.0310648,"ood accuracies, but there has been previous work on Hebrew (Goldberg and Elhadad, 2013), Korean (Choi et al., 1994) and Spanish (Le Roux et al., 2012) etc. The recently organized ‘Statistical Parsing of Morphologically Rich Languages’ (Seddah et al., 2013) addressed the dependency and constituency parsing of nine morphologically rich languages and provides useful benchmark datasets for these languages. Our chief contribution in this paper is a procedure to merge preterminal labels. The related work for this line of research includes the studies on manual refinement of preterminal sets such as Marton et al. (2010) and Le Roux et al. (2012). The most closely related approach to our proposal is Dehdari et al. (2011), who defines metaheuristics to incrementally insert or remove morphological features. Their approach uses parser – training and parsing – as a black box evaluation of a preterminal set. In contrast, our proposal operates as a submodule of the BerkeleyParser, hence does not require the re-training of the parser for every possible preterminal set candidate, thus it is way more faster. The most successful supervised constituent parsers contain a second feature-rich discriminative parsing step (C"
E14-1015,P12-2001,0,0.0142071,"sely related approach to our proposal is Dehdari et al. (2011), who defines metaheuristics to incrementally insert or remove morphological features. Their approach uses parser – training and parsing – as a black box evaluation of a preterminal set. In contrast, our proposal operates as a submodule of the BerkeleyParser, hence does not require the re-training of the parser for every possible preterminal set candidate, thus it is way more faster. The most successful supervised constituent parsers contain a second feature-rich discriminative parsing step (Charniak and Johnson, 2005; Huang, 2008; Chen and Kit, 2012) as well. At the first stage they apply a PCFG to extract posIn this study, we propose answers to the two main challenges of constituent parsing of morphologically rich languages, which are finding the optimal preterminal set and handling the huge number of wordforms. The size of the preterminal set in the standard context free grammar environment is crucial. If we use only the main POS tags as preterminals, we lose a lot of information encoded in the morphological description of the tokens. On the other hand, using the full morphological description as preterminal yields a set of over a thous"
E14-1015,D13-1032,0,0.122298,"Missing"
E14-1015,P06-1055,0,0.662329,"ociation for Computational Linguistics et al., 2006) enriched with these three techniques achieved state-of-the-art results on each language. Fraser et al. (2013) that “... there is no clear evidence for preferring dependency parsing over constituency parsing in analyzing languages with rich morphology and instead argue that research in both frameworks is important.” 2 Related Work Constituent parsing of English is a well researched area. The field has been dominated by data-driven, i.e. treebank-based statistical approaches in the last two decades (Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). We extend here BerkeleyParser (Petrov et al., 2006), which is a PCFG parser using latent annotations at nonterminals. Its basic idea is to iteratively split each non-terminal into subsymbols thus capturing the different subusage of them instead of manually designed annotations. The constituent parsing of morphologically rich languages is a much less investigated field. There exist constituent treebanks for several languages along with a very limited number of parsing reports on them. For instance, Petrov (2009) trained BerkeleyParser on Arabic, Bulgarian, French, German and Italian and he re"
E14-1015,W13-4917,1,0.910743,"Missing"
E14-1015,J13-1004,0,0.0501594,"t capture (dis)agreement at the morphological level. The motivation for using these features is that because of the free(er) word order of morphologically rich languages, morphological (dis)agreement can be a good indicator of attachment. Table 5 shows the added value of these feature templates over mainPOS (’extended’), which is again statistically significant in exact match. Exploiting the morphological agreement in syntactic parsing has been investigated in previous studies, e.g. the Bohnet parser (Bohnet, 2010) employs morphological feature value pairs similar to our feature templates and Seeker and Kuhn (2013) introduces an integer linear programming framework including constraints for morphological agreement. However, these works focus on dependency parsing and to the best of our knowledge, this is the first study on experimenting with atomic morphological features and their agreement in a constituency parsing. which are much smaller than full on German and Hebrew and it could not find any useful merge at Basque. The output of the merger procedure consists of one sixth of preterminals compared with full. Manually investigating the clusters, we can see that it basically merged every morphological f"
E14-1015,W10-1401,0,0.0138139,"example, a big constituent treebank has been available for Hungarian for almost 10 years (Csendes et al., 2005) and to the best of our knowledge our work is the first one reporting results on this treebank. One reason for the moderate level of interest in constituent parsing of morphologically rich languages is the widely held belief that dependency structures are better suited for representing syntactic analyses for morphologically rich languages than constituent representations because they allow non-projective structures (i.e. discontinuous constituents). From a theoretical point of view, Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. For a detailed discussion, please see Fraser et al. (2013). From an empirical point of view, the organizers of the recent shared task on ‘Statistical Parsing of Morphologically Rich Languages’ (Seddah et al., 2013) provided datasets only for languages having treebanks in both dependency and constituency format and their cross-framework evaluation – employing the unlabeled TedEval (Tsarfaty et al., 2012) as evaluation procedure – reve"
E14-1015,E12-1006,0,0.0140783,"m a theoretical point of view, Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. For a detailed discussion, please see Fraser et al. (2013). From an empirical point of view, the organizers of the recent shared task on ‘Statistical Parsing of Morphologically Rich Languages’ (Seddah et al., 2013) provided datasets only for languages having treebanks in both dependency and constituency format and their cross-framework evaluation – employing the unlabeled TedEval (Tsarfaty et al., 2012) as evaluation procedure – revealed that at 4 out of 9 morphologically rich languages, the results of constituent parsers were higher than the scores achieved by the best dependency parsing system. Based on these theoretical issues and empirical results, we support the conclusion of We introduce three techniques for improving constituent parsing for morphologically rich languages. We propose a novel approach to automatically find an optimal preterminal set by clustering morphological feature values and we conduct experiments with enhanced lexical models and feature engineering for rerankers. T"
E14-1015,J13-1003,0,0.0227972,"Missing"
E14-1015,varadi-2002-hungarian,0,0.0940969,"Missing"
E14-1015,W09-3820,0,0.115409,"atures in n-best Reranking n-best rerankers (Collins, 2000; Charniak and Johnson, 2005) are used as second stage after a PCFG parser and they usually achieve considerable improvement over the first stage parser. They extract a large feature set to describe the n best output of a PCFG parser and they select the best parse from this set (i.e. rerank the parses). Here, we define feature templates exploiting morphological information and investigate their added value for the standard feature sets (engineered for English). We reimplemented the feature templates from Charniak and Johnson (2005) and Versley and Rehbein (2009) excluding the features based on external corpora and use them as our baseline feature set. We used n = 50 in our experiment and followed a 5-fold-cross-parsing (a.k.a. jackknifing) approach for generating unseen parse candidates for the training sentences (Charniak and Johnson, 2005). The reranker is trained for the maximum entropy objective function of Charniak and Johnson (2005), i.e. the sum of posterior probabilities of the oracles. We used a slightly modified version of the Mallet toolkit for reranking (McCallum, 2002) and L2 regularizer with its default value for coefficient. The featur"
E14-1015,R13-1099,1,0.872029,"ar.gz. An important ˜ change in this version compared to the original evalb is the penalization of unparsed sentences. 2 137 ( Ptb (t|w), c(w)Ptb (t|w)+Pex (t|w) , 1+c(w) if c(w) ≥ K otherwise https://code.google.com/p/cistern/ sizable space of possible morphological analyses. We used MarMoT with the default parameters. This purely data-driven tagger achieves a tagging accuracy of 97.6 evaluated at full morphological analyses on the development set of the Hungarian treebank, which is competitive with the state-of-the-art Hungarian taggers which employ language-specific rules (e.g. magyarlanc (Zsibrita et al., 2013)). The chief advantage of using MarMot instead of an unsupervised tagger is that the former does not require any morphological lexicon/analyser (which can lists the possible tags for a given word). This morphological lexicon/analyser is language-dependent, usually handcrafted and it has to be compatible with the treebank in question. In contrast, a supervised morphological tagger can build a reasonable tagging model on the training part of the treebanks – especially for morphologically rich languages, where the tag ambiguity is generally low – thus each of these problems is avoided. Table 2 sh"
E14-1015,W11-3802,0,\N,Missing
E17-1034,C10-1011,0,0.0394206,"tions. We empirical evaluations which we introduce in this were particularly interested in the utility of the section. two representations for dependency parsing. We trained two models of the MarMot morphological 5.1 On the Accuracy of Automatic tagger (Mueller et al., 2013) using the two morConverters phological representation in 10-fold cross-tagging Most of the UD treebanks are the result of autoon our manually corrected 1800 sentences. Then matic conversion from a dependency treebank of we trained and evaluated the Bohnet dependency originally different principles. The accuracy of parser (Bohnet, 2010) on the train/test split of the these automatic converters is unknown, i.e. we do UD repository v3.0 utilizing the two different prenot know how much information was lost or how dicted morphological descriptions. We used the much noise was introduced by the converters. To default parameters for both the MarMot and the empirically investigate this in the case of HungarBohnet parser. ian UD, we compared the converted and the manuTable 1 presents unlabeled (UAS) and labeled ally corrected, i.e. gold standard, trees of the 1800 (LAS) attachment scores achieved by the parser sentences. on the test"
E17-1034,W04-1903,0,0.0503916,". Recently, a further extension on the UD relations has been proposed: enhanced English dependencies are described in Schuster and Manning (2016). Our UD principles introduced in this paper follow the central UD guidelines (Nivre, 2015) and we did our best to align with the existing guidelines for other morphologically rich languages as well. On the other hand, there are several Hungarian-specific phenomena that required changes and extensions of the original UD principles. The only available manually annotated treehttp://universaldependencies.org/ 357 bank for Hungarian is the Szeged Corpus (Csendes et al., 2004) and Szeged Dependency Treebank (Vincze et al., 2010). It contains approximately 82,000 sentences and 1.5 million tokens, all manually annotated for POS-tagging and constituency and dependency syntax. We developed an automatic tool that converts the morphological descriptions of the Szeged Corpus to universal morphology tags and the dependency trees of the Szeged Treebank to universal dependencies. 3 the possessor on the possessed noun but use determiners for this purpose (cf. my car but az autóm (the car-1SGPOSS)). Moreover, the number of the possessed can be marked on the noun in elliptical"
E17-1034,L16-1248,0,0.0132852,"ed datasets available for 40 languages, including English, German, French, Hungarian and Irish, among others1 . In these datasets, the very same tagsets are applied at the morphological and 1 Up to now, several papers have been published on the general principles behind UD (Nivre, 2015; Nivre et al., 2016) or on specific treebanks. For instance, there are UD treebanks available for agglutinative languages such as Finnish (Haverinen et al., 2014; Pyysalo et al., 2015), Estonian (Muischnek et al., 2016) and Japanese (Tanaka et al., 2016), for Slavic languages (Zeman, 2015) and spoken Slovenian (Dobrovoljc and Nivre, 2016) and for Nordic languages such as Norwegian (Øvrelid and Hohle, 2016), Danish (Johannsen et al., 2014) and Swedish (Nivre, 2014), together with several other languages (Persian (Seraji et al., 2016) and Basque (Aranzabe et al., 2014), just to name a few). Recently, a further extension on the UD relations has been proposed: enhanced English dependencies are described in Schuster and Manning (2016). Our UD principles introduced in this paper follow the central UD guidelines (Nivre, 2015) and we did our best to align with the existing guidelines for other morphologically rich languages as well. O"
E17-1034,J13-1005,1,0.880652,"farkas}@inf.u-szeged.hu Abstract plementation of multilingual morphological and syntactic parsers from a computational linguistic point of view. Furthermore, it can enhance studies on linguistic typology and contrastive linguistics. From the viewpoint of syntactic parsing, the languages of the world are usually categorized according to their level of morphological richness (which is negatively correlated with configurationality). At one end, there is English, a strongly configurational language while there is Hungarian at the other end of the spectrum with rich morphology and free word order (Fraser et al., 2013). In this paper, we present how UD principles were adapted to Hungarian, with special emphasis on Hungarian-specific phenomena. Hungarian is one of the prototypical morphologically rich languages thus our UD principles can provide important best practices for the universalization of other morphologically rich languages. The UD guidelines for Hungarian were motivated by both linguistic considerations and data-driven observations. We developed a converter from the existing Szeged Dependency Treebank (Vincze et al., 2010) to UD and manually corrected 1,800 sentences from the newspaper domain. The"
E17-1034,D07-1013,0,0.0285171,"l and syntactic annotations have been constantly developed in the international NLP community. For instance, the MSD morphological coding system was developed for a set of Eastern European languages (Erjavec, 2012), within the MULTEXTEAST project. Interset functions as an interlingua for several morphological coding systems, which can convert different tagsets to the same morphological representation (Zeman, 2008). There have also been some attempts to define a common set of parts-of-speech: Rambow et al. (2006) defined a multilingual tagset for part-of-speech (POS) tagging and parsing, while McDonald and Nivre (2007) identified eight POS tags based on data from the CoNLL-2007 Shared Task (Nivre et al., 2007). Petrov et al. (2012) offered a tagset of 12 POS tags and applied this tagset to 22 languages. Now, Universal Dependencies (UD) is the latest standardized tagset that we are aware of. UD is an international project that aims at developing a unified annotation scheme for dependency syntax and morphology in a language-independent framework (Nivre, 2015). Hungarian was among the first 10 languages of the project, participating also in the first official release in January 2015. In the latest release (Ver"
E17-1034,D13-1032,0,0.0217888,"iences gained during We carried out experiments for investigating the manual correction could reinforce the linguiswhether is there any difference between using the tic conversion rules and the manually corrected original MSD (Vincze et al., 2014) and the new gold standard corpus provides the opportunity for universal morphological (UM) descriptions. We empirical evaluations which we introduce in this were particularly interested in the utility of the section. two representations for dependency parsing. We trained two models of the MarMot morphological 5.1 On the Accuracy of Automatic tagger (Mueller et al., 2013) using the two morConverters phological representation in 10-fold cross-tagging Most of the UD treebanks are the result of autoon our manually corrected 1800 sentences. Then matic conversion from a dependency treebank of we trained and evaluated the Bohnet dependency originally different principles. The accuracy of parser (Bohnet, 2010) on the train/test split of the these automatic converters is unknown, i.e. we do UD repository v3.0 utilizing the two different prenot know how much information was lost or how dicted morphological descriptions. We used the much noise was introduced by the conv"
E17-1034,W13-4917,1,0.920355,"Missing"
E17-1034,L16-1247,0,0.0834687,"also in the first official release in January 2015. In the latest release (Version 1.3, May 2016), there are annotated datasets available for 40 languages, including English, German, French, Hungarian and Irish, among others1 . In these datasets, the very same tagsets are applied at the morphological and 1 Up to now, several papers have been published on the general principles behind UD (Nivre, 2015; Nivre et al., 2016) or on specific treebanks. For instance, there are UD treebanks available for agglutinative languages such as Finnish (Haverinen et al., 2014; Pyysalo et al., 2015), Estonian (Muischnek et al., 2016) and Japanese (Tanaka et al., 2016), for Slavic languages (Zeman, 2015) and spoken Slovenian (Dobrovoljc and Nivre, 2016) and for Nordic languages such as Norwegian (Øvrelid and Hohle, 2016), Danish (Johannsen et al., 2014) and Swedish (Nivre, 2014), together with several other languages (Persian (Seraji et al., 2016) and Basque (Aranzabe et al., 2014), just to name a few). Recently, a further extension on the UD relations has been proposed: enhanced English dependencies are described in Schuster and Manning (2016). Our UD principles introduced in this paper follow the central UD guidelines (N"
E17-1034,W14-6111,0,0.0406033,"ion and the added value of language-specific, i.e. non-universal, annotations. Our results reveal that converting to universal dependencies is not necessarily trivial, moreover, using languagespecific morphological features may have an impact on overall performance. 1 Introduction Morphological tagging and syntactic parsing are key components in most natural language processing (NLP) applications. Linguistic resources and parsers for morphological and syntactic analysis have been developed for several languages, see e.g. the shared tasks on morphologically rich languages (Seddah et al., 2013; Seddah et al., 2014). However, the comparison of results achieved for different languages is not straightforward as most languages and databases apply a unique tagset, moreover, they were annotated following different guidelines. In order to overcome these issues, the project Universal Dependencies and Morphology (UD) has recently been initiated within the NLP community (Nivre, 2015). The main goal of the UD project is to develop a “universal”, i.e. a language-independent morphological and syntactic representation which can contribute to the im356 Proceedings of the 15th Conference of the European Chapter of the"
E17-1034,L16-1261,0,0.0248178,"January 2015. In the latest release (Version 1.3, May 2016), there are annotated datasets available for 40 languages, including English, German, French, Hungarian and Irish, among others1 . In these datasets, the very same tagsets are applied at the morphological and 1 Up to now, several papers have been published on the general principles behind UD (Nivre, 2015; Nivre et al., 2016) or on specific treebanks. For instance, there are UD treebanks available for agglutinative languages such as Finnish (Haverinen et al., 2014; Pyysalo et al., 2015), Estonian (Muischnek et al., 2016) and Japanese (Tanaka et al., 2016), for Slavic languages (Zeman, 2015) and spoken Slovenian (Dobrovoljc and Nivre, 2016) and for Nordic languages such as Norwegian (Øvrelid and Hohle, 2016), Danish (Johannsen et al., 2014) and Swedish (Nivre, 2014), together with several other languages (Persian (Seraji et al., 2016) and Basque (Aranzabe et al., 2014), just to name a few). Recently, a further extension on the UD relations has been proposed: enhanced English dependencies are described in Schuster and Manning (2016). Our UD principles introduced in this paper follow the central UD guidelines (Nivre, 2015) and we did our best to"
E17-1034,L16-1250,0,0.0191574,"h, Hungarian and Irish, among others1 . In these datasets, the very same tagsets are applied at the morphological and 1 Up to now, several papers have been published on the general principles behind UD (Nivre, 2015; Nivre et al., 2016) or on specific treebanks. For instance, there are UD treebanks available for agglutinative languages such as Finnish (Haverinen et al., 2014; Pyysalo et al., 2015), Estonian (Muischnek et al., 2016) and Japanese (Tanaka et al., 2016), for Slavic languages (Zeman, 2015) and spoken Slovenian (Dobrovoljc and Nivre, 2016) and for Nordic languages such as Norwegian (Øvrelid and Hohle, 2016), Danish (Johannsen et al., 2014) and Swedish (Nivre, 2014), together with several other languages (Persian (Seraji et al., 2016) and Basque (Aranzabe et al., 2014), just to name a few). Recently, a further extension on the UD relations has been proposed: enhanced English dependencies are described in Schuster and Manning (2016). Our UD principles introduced in this paper follow the central UD guidelines (Nivre, 2015) and we did our best to align with the existing guidelines for other morphologically rich languages as well. On the other hand, there are several Hungarian-specific phenomena that"
E17-1034,petrov-etal-2012-universal,0,0.0372414,"phological coding system was developed for a set of Eastern European languages (Erjavec, 2012), within the MULTEXTEAST project. Interset functions as an interlingua for several morphological coding systems, which can convert different tagsets to the same morphological representation (Zeman, 2008). There have also been some attempts to define a common set of parts-of-speech: Rambow et al. (2006) defined a multilingual tagset for part-of-speech (POS) tagging and parsing, while McDonald and Nivre (2007) identified eight POS tags based on data from the CoNLL-2007 Shared Task (Nivre et al., 2007). Petrov et al. (2012) offered a tagset of 12 POS tags and applied this tagset to 22 languages. Now, Universal Dependencies (UD) is the latest standardized tagset that we are aware of. UD is an international project that aims at developing a unified annotation scheme for dependency syntax and morphology in a language-independent framework (Nivre, 2015). Hungarian was among the first 10 languages of the project, participating also in the first official release in January 2015. In the latest release (Version 1.3, May 2016), there are annotated datasets available for 40 languages, including English, German, French, Hu"
E17-1034,W15-1821,0,0.0517461,"ges of the project, participating also in the first official release in January 2015. In the latest release (Version 1.3, May 2016), there are annotated datasets available for 40 languages, including English, German, French, Hungarian and Irish, among others1 . In these datasets, the very same tagsets are applied at the morphological and 1 Up to now, several papers have been published on the general principles behind UD (Nivre, 2015; Nivre et al., 2016) or on specific treebanks. For instance, there are UD treebanks available for agglutinative languages such as Finnish (Haverinen et al., 2014; Pyysalo et al., 2015), Estonian (Muischnek et al., 2016) and Japanese (Tanaka et al., 2016), for Slavic languages (Zeman, 2015) and spoken Slovenian (Dobrovoljc and Nivre, 2016) and for Nordic languages such as Norwegian (Øvrelid and Hohle, 2016), Danish (Johannsen et al., 2014) and Swedish (Nivre, 2014), together with several other languages (Persian (Seraji et al., 2016) and Basque (Aranzabe et al., 2014), just to name a few). Recently, a further extension on the UD relations has been proposed: enhanced English dependencies are described in Schuster and Manning (2016). Our UD principles introduced in this paper"
E17-1034,zeman-2008-reusable,0,0.0370556,"ssing the added value of language-specific information at the morphological and syntactic layers along with the interaction of these two. 2 Related Work Standardized tagsets for both morphological and syntactic annotations have been constantly developed in the international NLP community. For instance, the MSD morphological coding system was developed for a set of Eastern European languages (Erjavec, 2012), within the MULTEXTEAST project. Interset functions as an interlingua for several morphological coding systems, which can convert different tagsets to the same morphological representation (Zeman, 2008). There have also been some attempts to define a common set of parts-of-speech: Rambow et al. (2006) defined a multilingual tagset for part-of-speech (POS) tagging and parsing, while McDonald and Nivre (2007) identified eight POS tags based on data from the CoNLL-2007 Shared Task (Nivre et al., 2007). Petrov et al. (2012) offered a tagset of 12 POS tags and applied this tagset to 22 languages. Now, Universal Dependencies (UD) is the latest standardized tagset that we are aware of. UD is an international project that aims at developing a unified annotation scheme for dependency syntax and morph"
E17-1034,rambow-etal-2006-parallel,0,0.0128733,"yers along with the interaction of these two. 2 Related Work Standardized tagsets for both morphological and syntactic annotations have been constantly developed in the international NLP community. For instance, the MSD morphological coding system was developed for a set of Eastern European languages (Erjavec, 2012), within the MULTEXTEAST project. Interset functions as an interlingua for several morphological coding systems, which can convert different tagsets to the same morphological representation (Zeman, 2008). There have also been some attempts to define a common set of parts-of-speech: Rambow et al. (2006) defined a multilingual tagset for part-of-speech (POS) tagging and parsing, while McDonald and Nivre (2007) identified eight POS tags based on data from the CoNLL-2007 Shared Task (Nivre et al., 2007). Petrov et al. (2012) offered a tagset of 12 POS tags and applied this tagset to 22 languages. Now, Universal Dependencies (UD) is the latest standardized tagset that we are aware of. UD is an international project that aims at developing a unified annotation scheme for dependency syntax and morphology in a language-independent framework (Nivre, 2015). Hungarian was among the first 10 languages"
E17-1034,L16-1376,0,0.0409195,"Missing"
I13-1038,W07-1101,0,0.0243724,"ind a noun that is a conversive of a verb (i.e. it can be used as a verb without any morphological change), while in vague action verbs such as to make an agreement there is a noun derived from a verb (i.e. there is morphological change). 330 verbs do, get, give, have, make, take were marked. Statistical data on the three corpora are listed in Table 1. Some of the earlier studies aimed at identifying or extracting only a restricted set of LVCs. Most of them focus on verb-object pairs when identifying LVCs (Stevenson et al., 2004; Tan et al., 2006; Fazly and Stevenson, 2007; Cook et al., 2007; Bannard, 2007; Tu and Roth, 2011), thus they concentrate on structures like give a decision or take control. With languages other than English, authors often select verb + prepositional object pairs (instead of verb-object pairs) and categorise them as LVCs or not. See, e.g. Van de Cruys and Moir´on (2007) for Dutch LVC detection or Krenn (2008) for German LVC detection. In other cases, only true LVCs were considered (Stevenson et al., 2004; Tu and Roth, 2011). In some other studies (Cook et al., 2007; Diab and Bhutada, 2009) the authors just distinguished between the literal and idiomatic uses of verb + n"
I13-1038,R11-1089,1,0.869779,"Missing"
I13-1038,C10-1011,0,0.0873412,"Missing"
I13-1038,calzolari-etal-2002-towards,0,0.020926,"e investigate the performance of different candidate extraction methods on two English full-coverage LVC annotated corpora, where we found that less severe candidate extraction methods should be applied. Then we follow a machine learning approach that makes use of an extended and rich feature set to select LVCs among extracted candidates. 1 Introduction A multiword expression (MWE) is a lexical unit that consists of more than one orthographical word, i.e. a lexical unit that contains spaces and displays lexical, syntactic, semantic, pragmatic and/or statistical idiosyncrasy (Sag et al., 2002; Calzolari et al., 2002). Light verb constructions (LVCs) (e.g. to take a decision, to take sg into consideration) form a subtype of MWEs, namely, they consist of a nominal and a verbal component where the verb functions as the syntactic head (the whole construction fulfills the role of a verb in the clause), but the semantic head is the noun (i.e. the noun is used in one of its original senses). The verbal component (also called a light verb) usually loses its original sense to some extent.1 The meaning of LVCs can only partially be computed on the basis of the meanings of their parts and the way they are related to"
I13-1038,W07-1106,0,0.0196449,"ve a laugh we can find a noun that is a conversive of a verb (i.e. it can be used as a verb without any morphological change), while in vague action verbs such as to make an agreement there is a noun derived from a verb (i.e. there is morphological change). 330 verbs do, get, give, have, make, take were marked. Statistical data on the three corpora are listed in Table 1. Some of the earlier studies aimed at identifying or extracting only a restricted set of LVCs. Most of them focus on verb-object pairs when identifying LVCs (Stevenson et al., 2004; Tan et al., 2006; Fazly and Stevenson, 2007; Cook et al., 2007; Bannard, 2007; Tu and Roth, 2011), thus they concentrate on structures like give a decision or take control. With languages other than English, authors often select verb + prepositional object pairs (instead of verb-object pairs) and categorise them as LVCs or not. See, e.g. Van de Cruys and Moir´on (2007) for Dutch LVC detection or Krenn (2008) for German LVC detection. In other cases, only true LVCs were considered (Stevenson et al., 2004; Tu and Roth, 2011). In some other studies (Cook et al., 2007; Diab and Bhutada, 2009) the authors just distinguished between the literal and idiomatic u"
I13-1038,W10-2108,0,0.0300711,"Missing"
I13-1038,W09-2903,0,0.0738282,"out contextual information – are then classified as LVCs or not (Stevenson et al., 2004; Tan et al., 2006; Fazly and Stevenson, 2007; Van de Cruys and Moir´on, 2007; Gurrutxaga and Alegria, 2011). As a gold standard, lists collected from dictionaries or other annotated corpora are used: if the extracted candidate is classified as an LVC and can be found on the list, it is a true positive, regardless of the fact whether it was a genuine LVC in its context. In the second approach, the goal is to detect individual LVC token instances in a running text, taking contextual information into account (Diab and Bhutada, 2009; Tu and Roth, 2011; Nagy T. et al., 2011). While the first approach assumes that a specific candidate in all of its occurrences constitutes an LVC or not (i.e. there are no ambiguous cases), the second one may account for the fact that there are contexts where a given candidate functions as an LVC whereas in other contexts it does not, recall the example of give a ring in Section 1. The authors of Stevenson et al. (2004), Fazly and Stevenson (2007), Van de Cruys and Moir´on 2 In theoretical linguistics, two types of LVCs are distinguished (Kearns, 2002). In true LVCs such as to have a laugh w"
I13-1038,W07-1102,0,0.191858,"t candidate extraction methods (earlier published methods and new solutions implemented by us). • We defined and evaluated several new feature templates like semantic or morphological features to select LVCs in context from extracted candidates. 2 Related Work Two approaches have been introduced for LVC detection. In the first approach, LVC candidates (usually verb-object pairs including one verb from a well-defined set of 3-10 verbs) are extracted from the corpora and these tokens – without contextual information – are then classified as LVCs or not (Stevenson et al., 2004; Tan et al., 2006; Fazly and Stevenson, 2007; Van de Cruys and Moir´on, 2007; Gurrutxaga and Alegria, 2011). As a gold standard, lists collected from dictionaries or other annotated corpora are used: if the extracted candidate is classified as an LVC and can be found on the list, it is a true positive, regardless of the fact whether it was a genuine LVC in its context. In the second approach, the goal is to detect individual LVC token instances in a running text, taking contextual information into account (Diab and Bhutada, 2009; Tu and Roth, 2011; Nagy T. et al., 2011). While the first approach assumes that a specific candidate in all"
I13-1038,W04-0401,0,0.400891,"stematically compare and evaluate different candidate extraction methods (earlier published methods and new solutions implemented by us). • We defined and evaluated several new feature templates like semantic or morphological features to select LVCs in context from extracted candidates. 2 Related Work Two approaches have been introduced for LVC detection. In the first approach, LVC candidates (usually verb-object pairs including one verb from a well-defined set of 3-10 verbs) are extracted from the corpora and these tokens – without contextual information – are then classified as LVCs or not (Stevenson et al., 2004; Tan et al., 2006; Fazly and Stevenson, 2007; Van de Cruys and Moir´on, 2007; Gurrutxaga and Alegria, 2011). As a gold standard, lists collected from dictionaries or other annotated corpora are used: if the extracted candidate is classified as an LVC and can be found on the list, it is a true positive, regardless of the fact whether it was a genuine LVC in its context. In the second approach, the goal is to detect individual LVC token instances in a running text, taking contextual information into account (Diab and Bhutada, 2009; Tu and Roth, 2011; Nagy T. et al., 2011). While the first appro"
I13-1038,W06-2407,0,0.113416,"Missing"
I13-1038,W11-0802,0,0.0236786,"nd new solutions implemented by us). • We defined and evaluated several new feature templates like semantic or morphological features to select LVCs in context from extracted candidates. 2 Related Work Two approaches have been introduced for LVC detection. In the first approach, LVC candidates (usually verb-object pairs including one verb from a well-defined set of 3-10 verbs) are extracted from the corpora and these tokens – without contextual information – are then classified as LVCs or not (Stevenson et al., 2004; Tan et al., 2006; Fazly and Stevenson, 2007; Van de Cruys and Moir´on, 2007; Gurrutxaga and Alegria, 2011). As a gold standard, lists collected from dictionaries or other annotated corpora are used: if the extracted candidate is classified as an LVC and can be found on the list, it is a true positive, regardless of the fact whether it was a genuine LVC in its context. In the second approach, the goal is to detect individual LVC token instances in a running text, taking contextual information into account (Diab and Bhutada, 2009; Tu and Roth, 2011; Nagy T. et al., 2011). While the first approach assumes that a specific candidate in all of its occurrences constitutes an LVC or not (i.e. there are no"
I13-1038,W11-0807,0,0.165256,"-noun combinations in Dutch. Their method relies on selectional preferences for both the noun and the verb. Idiomatic and light verb noun + verb combinations were extracted from Basque texts by employing statistical methods (Gurrutxaga and Alegria, 2011). Diab and Bhutada (2009) and Nagy T. et al. (2011) employed ruled-based methods to detect LVCs, which are usually based on (shallow) linguistic information, while the domain specificity of the problem was highlighted in Nagy T. et al. (2011). Both statistical and linguistic information were applied by the hybrid LVC systems (Tan et al., 2006; Tu and Roth, 2011; Samardˇzi´c and Merlo, 2010), which resulted in better recall scores. English and German LVCs were analysed in parallel corpora: the authors of Samardˇzi´c and Merlo (2010) focus on their manual and automatic alignment. They found that linguistic features (e.g. the degree of compositionality) and the frequency of the construction both have an impact on the alignment of the constructions. Tan et al. (2006) applied machine learning techniques to extract LVCs. They combined statistical and linguistic features, and trained a random forest classifier to separate LVC candidates. Tu and Roth (2011)"
I13-1038,W07-1104,0,0.0770712,"Missing"
I13-1038,P03-1054,0,0.0105105,"Missing"
I13-1038,vincze-2012-light,1,0.837926,"there has been a considerable amount of previous work on LVC detection, but some authors seek to capture just verb–object pairs, while others just verbs with prepositional complements. Actually, many of them exploited only constructions formed with a limited set of light verbs and identified or extracted just a specific type of LVCs. However, we cannot see any benefit that any NLP application could get from these limitations and here, we focus on the full-coverage identification of LVCs. We train and evaluate statistical models on the Wiki50 (Vincze et al., 2011) and SzegedParalellFX (SZPFX) (Vincze, 2012) corpora that have recently been published with full-coverage LVC annotation. We employ a two-stage procedure. First, The identification of light verb constructions (LVC) is an important task for several applications. Previous studies focused on some limited set of light verb constructions. Here, we address the full coverage of LVCs. We investigate the performance of different candidate extraction methods on two English full-coverage LVC annotated corpora, where we found that less severe candidate extraction methods should be applied. Then we follow a machine learning approach that makes use o"
I13-1038,W04-2705,0,\N,Missing
I13-1038,R11-1040,1,\N,Missing
I13-2005,I11-1130,1,0.9066,"Missing"
I13-2005,S10-1004,0,0.0193639,"ted subcorpora – we relied on the workshop papers present in the ACL Anthology Corpus (Sch¨afer et al., 2012). 3.1 Single-Document Keyphrase Extraction System To have an efficient representation of the documents we first used our single-document keyphrase extraction system. Keyphrase extraction was treated as a supervised learning task where successive n-grams extracted from a document (i.e. keyphrase candidates) have to be classified as proper and improper keyphrases. We utilized the NUS Keyphrase Corpus (2007) and the database of the SemEval-2 shared task on scientific keyphrase extraction (Kim et al., 2010) as training data for our supervised keyphrase candidate ranker. Our keyphrase ranking solution was based on the posterior probability of a “keyphrase or not” binary MaxEnt model trained within the MALLET (2002) framework and using a combination of our feature sets from our previous works on keyphrase extraction as described in (2010) and (2011). 3.2 Visualizing and partitioning the document set Keyphrases extracted from the individual papers were used next as an input for the construction of a similarity graph which served as the basis of visualization. 18 3.2.1 Similarity graph Gn,t = (V, En"
I13-2005,W12-3210,0,0.0608725,"Missing"
I13-2005,S10-1040,1,0.889532,"Missing"
J12-2004,W07-1011,0,0.381457,"Missing"
J12-2004,W10-3017,0,0.0948903,"d “pseudo-triggers”. A pseudo-trigger is a superstring of a cue and it is basically used for recognizing contexts where a cue does not imply uncertainty (i.e., it can be regarded as a hand-crafted cue disambiguation module). MacKinlay, Martinez, and Baldwin (2009) introduced a system which also used non-consecutive tokens as cues (like not+as+yet). Utilizing manually labeled corpora, machine learning–based uncertainty cue detectors have also been developed (to the best of our knowledge each of them uses an in-domain training data set). They use token classiﬁcation (Morante and Daelemans 2009; Clausen 2010; Fernandes, Crestana, and Milidiu´ 2010; S´anchez, Li, and Vogel 2010) or sequence labeling approaches (Li et al. 2010; Rei and Briscoe 2010; Tang et al. 2010; Zhang et al. 2010). In both cases the tokens are labeled according to whether they are part of a cue. The latter assigns a label sequence to a sentence (a sequence of 344 Szarvas et al. Cross-Genre and Cross-Domain Detection of Semantic Uncertainty tokens) thus it naturally deals with the context of a particular word. On the other hand, context information for a token is built into the feature space of the token classiﬁcation ¨ ur ¨ an"
J12-2004,W09-1318,0,0.0333556,"Missing"
J12-2004,P07-2009,0,0.0431689,"Missing"
J12-2004,P07-1033,0,0.0872072,"Missing"
J12-2004,W10-3001,1,0.879192,"Missing"
J12-2004,P09-2044,0,0.188168,"Missing"
J12-2004,W10-3004,0,0.129684,"Missing"
J12-2004,W08-0607,0,0.0742456,"Missing"
J12-2004,W09-1418,0,0.0271284,"Missing"
J12-2004,W09-1401,0,0.038846,"Missing"
J12-2004,W10-3011,0,0.0641227,"re a cue does not imply uncertainty (i.e., it can be regarded as a hand-crafted cue disambiguation module). MacKinlay, Martinez, and Baldwin (2009) introduced a system which also used non-consecutive tokens as cues (like not+as+yet). Utilizing manually labeled corpora, machine learning–based uncertainty cue detectors have also been developed (to the best of our knowledge each of them uses an in-domain training data set). They use token classiﬁcation (Morante and Daelemans 2009; Clausen 2010; Fernandes, Crestana, and Milidiu´ 2010; S´anchez, Li, and Vogel 2010) or sequence labeling approaches (Li et al. 2010; Rei and Briscoe 2010; Tang et al. 2010; Zhang et al. 2010). In both cases the tokens are labeled according to whether they are part of a cue. The latter assigns a label sequence to a sentence (a sequence of 344 Szarvas et al. Cross-Genre and Cross-Domain Detection of Semantic Uncertainty tokens) thus it naturally deals with the context of a particular word. On the other hand, context information for a token is built into the feature space of the token classiﬁcation ¨ ur ¨ and Radev (2009) and Velldal (2010) match cues from a lexicon then approaches. Ozg apply a binary classiﬁer based on feat"
J12-2004,W04-3103,0,0.0604055,"Missing"
J12-2004,W09-1410,0,0.0488634,"Missing"
J12-2004,P07-1125,0,0.422088,"g corpora and uncertainty recognition tools and our chief goal here is to provide a computational linguistics-oriented classiﬁcation. With this in mind, our subclasses are intended to be well-deﬁned and easily identiﬁable by automatic tools. Moreover, this classiﬁcation allows different applications to choose the subset of phenomena to be recognized in accordance with their main task (i.e., we tried to avoid an overly coarse or ﬁne-grained categorization). 2.1 Classiﬁcation of Uncertainty Types Several corpora annotated for uncertainty have been published in different domains such as biology (Medlock and Briscoe 2007; Kim, Ohta, and Tsujii 2008; Settles, Craven, and Friedland 2008; Shatkay et al. 2008; Vincze et al. 2008; Nawaz, Thompson, and Ananiadou 2010), medicine (Uzuner, Zhang, and Sibanda 2009), news media (Rubin, Liddy, and Kando 2005; Wilson 2008; Saur´ı and Pustejovsky 2009; Rubin 2010), and encyclopedia (Farkas et al. 2010). As can be seen from publicly available annotation guidelines, there are many overlaps but differences as well in the understanding of uncertainty, which is sometimes connected to domain- and genre-speciﬁc features of the texts. Here we introduce a domain- and genre-independ"
J12-2004,W09-1304,0,0.0179162,"expressions to deﬁne cues and “pseudo-triggers”. A pseudo-trigger is a superstring of a cue and it is basically used for recognizing contexts where a cue does not imply uncertainty (i.e., it can be regarded as a hand-crafted cue disambiguation module). MacKinlay, Martinez, and Baldwin (2009) introduced a system which also used non-consecutive tokens as cues (like not+as+yet). Utilizing manually labeled corpora, machine learning–based uncertainty cue detectors have also been developed (to the best of our knowledge each of them uses an in-domain training data set). They use token classiﬁcation (Morante and Daelemans 2009; Clausen 2010; Fernandes, Crestana, and Milidiu´ 2010; S´anchez, Li, and Vogel 2010) or sequence labeling approaches (Li et al. 2010; Rei and Briscoe 2010; Tang et al. 2010; Zhang et al. 2010). In both cases the tokens are labeled according to whether they are part of a cue. The latter assigns a label sequence to a sentence (a sequence of 344 Szarvas et al. Cross-Genre and Cross-Domain Detection of Semantic Uncertainty tokens) thus it naturally deals with the context of a particular word. On the other hand, context information for a token is built into the feature space of the token classiﬁca"
J12-2004,W10-3006,0,0.060851,"Missing"
J12-2004,W10-3112,0,0.388287,"Missing"
J12-2004,D09-1145,0,0.0310857,"Missing"
J12-2004,W10-3008,0,0.0728038,"t imply uncertainty (i.e., it can be regarded as a hand-crafted cue disambiguation module). MacKinlay, Martinez, and Baldwin (2009) introduced a system which also used non-consecutive tokens as cues (like not+as+yet). Utilizing manually labeled corpora, machine learning–based uncertainty cue detectors have also been developed (to the best of our knowledge each of them uses an in-domain training data set). They use token classiﬁcation (Morante and Daelemans 2009; Clausen 2010; Fernandes, Crestana, and Milidiu´ 2010; S´anchez, Li, and Vogel 2010) or sequence labeling approaches (Li et al. 2010; Rei and Briscoe 2010; Tang et al. 2010; Zhang et al. 2010). In both cases the tokens are labeled according to whether they are part of a cue. The latter assigns a label sequence to a sentence (a sequence of 344 Szarvas et al. Cross-Genre and Cross-Domain Detection of Semantic Uncertainty tokens) thus it naturally deals with the context of a particular word. On the other hand, context information for a token is built into the feature space of the token classiﬁcation ¨ ur ¨ and Radev (2009) and Velldal (2010) match cues from a lexicon then approaches. Ozg apply a binary classiﬁer based on features describing the co"
J12-2004,W10-3018,0,0.132999,"Missing"
J12-2004,P08-1033,1,0.873695,"ing applications), and a recent pilot task sought to exploit negation and hedge cue detectors in machine reading (Morante and Daelemans 2011). As the focus of our paper is cue recognition, however, we omit their detailed description here. 4.1 In-Domain Cue Detection In-domain uncertainty detectors have been developed since the mid 1990s. Most of these systems use hand-crafted lexicons for cue recognition and they treat each occurrence of the lexicon items as a cue—that is, they do not address the problem of disambiguating cues (Friedman et al. 1994; Light, Qiu, and Srinivasan 2004; Farkas and Szarvas 2008; Saur´ı 2008; Conway, Doan, and Collier 2009; Van Landeghem et al. 2009). ConText (Chapman, Chu, and Dowling 2007) uses regular expressions to deﬁne cues and “pseudo-triggers”. A pseudo-trigger is a superstring of a cue and it is basically used for recognizing contexts where a cue does not imply uncertainty (i.e., it can be regarded as a hand-crafted cue disambiguation module). MacKinlay, Martinez, and Baldwin (2009) introduced a system which also used non-consecutive tokens as cues (like not+as+yet). Utilizing manually labeled corpora, machine learning–based uncertainty cue detectors have al"
J12-2004,W10-3012,0,0.0255504,"Missing"
J12-2004,W10-3002,0,0.214012,".e., it can be regarded as a hand-crafted cue disambiguation module). MacKinlay, Martinez, and Baldwin (2009) introduced a system which also used non-consecutive tokens as cues (like not+as+yet). Utilizing manually labeled corpora, machine learning–based uncertainty cue detectors have also been developed (to the best of our knowledge each of them uses an in-domain training data set). They use token classiﬁcation (Morante and Daelemans 2009; Clausen 2010; Fernandes, Crestana, and Milidiu´ 2010; S´anchez, Li, and Vogel 2010) or sequence labeling approaches (Li et al. 2010; Rei and Briscoe 2010; Tang et al. 2010; Zhang et al. 2010). In both cases the tokens are labeled according to whether they are part of a cue. The latter assigns a label sequence to a sentence (a sequence of 344 Szarvas et al. Cross-Genre and Cross-Domain Detection of Semantic Uncertainty tokens) thus it naturally deals with the context of a particular word. On the other hand, context information for a token is built into the feature space of the token classiﬁcation ¨ ur ¨ and Radev (2009) and Velldal (2010) match cues from a lexicon then approaches. Ozg apply a binary classiﬁer based on features describing the context of the cue c"
J12-2004,W10-3022,0,0.044217,"Missing"
J12-2004,W10-2605,0,0.0210482,"Missing"
J12-2004,W09-1419,0,0.0223659,"Missing"
J12-2004,W10-3007,0,0.0436532,"Missing"
J12-2004,W08-0606,1,0.908141,"Missing"
J12-2004,W10-3013,0,0.0602854,"arded as a hand-crafted cue disambiguation module). MacKinlay, Martinez, and Baldwin (2009) introduced a system which also used non-consecutive tokens as cues (like not+as+yet). Utilizing manually labeled corpora, machine learning–based uncertainty cue detectors have also been developed (to the best of our knowledge each of them uses an in-domain training data set). They use token classiﬁcation (Morante and Daelemans 2009; Clausen 2010; Fernandes, Crestana, and Milidiu´ 2010; S´anchez, Li, and Vogel 2010) or sequence labeling approaches (Li et al. 2010; Rei and Briscoe 2010; Tang et al. 2010; Zhang et al. 2010). In both cases the tokens are labeled according to whether they are part of a cue. The latter assigns a label sequence to a sentence (a sequence of 344 Szarvas et al. Cross-Genre and Cross-Domain Detection of Semantic Uncertainty tokens) thus it naturally deals with the context of a particular word. On the other hand, context information for a token is built into the feature space of the token classiﬁcation ¨ ur ¨ and Radev (2009) and Velldal (2010) match cues from a lexicon then approaches. Ozg apply a binary classiﬁer based on features describing the context of the cue candidate. Each of th"
J12-2004,W10-3009,0,\N,Missing
J13-1005,E06-2001,0,0.074573,"e derivational rule applied at the node in question. The last and biggest group of the pattern features is formed by the bilexical dependencies. They are based on the head word of the constituent node in question and its daughters. Versley and Rehbein (2009) have also introduced features that exploit statistical information gathered from an external data set and aim to resolve PP attachment ambiguity. Mutual information values were gathered on the association between nouns and immediately following prepositions, as well as between prepositions and closely following verbs on the DE-WaC corpus (Baroni and Kilgarriff 2006). These feature values were then used at NP→PP and VP→PP daughter attachments. A total of 2.7 million features ﬁred in the Tiger train. We ignored features ﬁring in less than ﬁve sentences for computational efﬁciency, resulting in 117,000 extremely sparse features. 7.3 Monolingual Reranking Experiments We rerank 100-best lists from BitPar (Schmid 2004), which uses the grammar extraction procedure and lexical resources introduced in Section 3. In each of the experiments we extracted the grammar from the Tiger train and used it to obtain the 100-best parses for the sentences of the evaluation co"
J13-1005,H91-1060,0,0.502125,"l reranking, which will be discussed later. 70 Fraser et al. Knowledge Sources for Parsing German to the same format as the gold standard trees by undoing Steps 2, 3, and 4 of Section 3.1. This conversion involves four steps: 1. Demarkovization removes all the auxiliary nodes introduced by markovization and raises their children to the next non-auxiliary node. 2. The added unary-branching nodes are eliminated. 3. The original grammatical function labels NK inside of NPs and PPs, and CJ inside of coordinated phrases, are restored. 4. All feature annotations are deleted. We use PARSEVAL scores (Black et al. 1991) and the standard evaluation tool evalb16 to compare the converted parse trees with the gold standard parse trees using labeled F-score. We report accuracies for all test sentences and not just sentences of length up to 40. We do not evaluate parsers with gold standard POS tags, but instead automatically infer them. These considerations make our evaluation setting as close to the real-world setting as possible. We report results for evaluations with and without grammatical functions. We report PARSEVAL scores with grammatical functions inside parentheses after the results using only basic cons"
J13-1005,A00-1031,0,0.0930958,"ecause some of the rules which are not markovized are also covered by markovization rules. 3.7 Dealing with Unknown Words and Unseen POS Tags BitPar includes a sophisticated POS guesser that uses several strategies to deal with unknown words and unseen POS tags of known words. Unknown words are divided into eight classes11 based on regular expressions that are manually deﬁned. These classes distinguish between lower-case words, capitalized words, all upper-case words, hyphenated words, numbers, and so forth. For each word class, BitPar builds a sufﬁx tree (Weischedel et al. 1993; Schmid 1995; Brants 2000) from the sufﬁxes of all words in the lexicon up to a length of 7. At each node of the sufﬁx tree, it sums up the conditional POS probabilities (given the word) over all known words with that sufﬁx. By summing POS probabilities rather than frequencies, all words have the same weight, which is appropriate here because we need to model the POS probabilities of infrequent words. BitPar computes POS probability estimates for each node using the sum of probabilities as a pseudo-frequency for each tag. The estimates are recursively smoothed with the Witten-Bell method using the smoothed POS probabil"
J13-1005,N10-1015,0,0.0304786,"Missing"
J13-1005,D08-1092,0,0.164596,"(+1.06) +0.78 (+1.00) +0.09 (+0.01) +0.78 (+0.70) The parse tree in Figure 6 demonstrates the value of bilingual features. It was produced by the monolingual reranker and it incorrectly combines the two adverbs aber and ebenso into an adverbial phrase and places this under the VP. The bilingual reranker instead attaches the two adverbs separately at the S level. The attachment to the S node indicates that the two adverbs modify the modal verb kann and not the full verb sagen. This is triggered by the feature POSPar2Prj. 8.3 Previous Work on Bitext Parsing Bitext parsing was also addressed by Burkett and Klein (2008). In that work, they use feature functions deﬁned on triples of (English parse tree, Chinese parse tree, alignment) which are combined in a log-linear model, much as we do. In later work (Burkett, Blitzer, and Klein 2010), they developed a uniﬁed joint model for solving the same problem using a weakly synchronized grammar. To train these models they use a small parallel Treebank that contains gold standard trees for parallel sentences in Chinese and English, whereas we only require gold standard trees for the language we are reranking. Another important difference is that Burkett and Klein (20"
J13-1005,P11-2037,0,0.0377588,"Missing"
J13-1005,P04-1082,0,0.0497864,"Missing"
J13-1005,P05-1022,0,0.827942,"at the gain of the two sets of reranking features (monolingual and bilingual) is additive, suggesting that they capture different types of information. The resulting parser is currently the best constituent parser for German (with or without bilingual features). In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCF"
J13-1005,P97-1003,0,0.510396,"es without a subject. We also mark conjunct clauses with the feature nosubj if they are neither headed by an imperative nor contain a child node with the grammatical function SB (subject) or EP (expletive). This is useful in order to correctly parse coordinations where the subject is dropped in the second conjunct. 3.6 Markovization The Tiger Treebank uses rather ﬂat structures where nodes have up to 25 child nodes. This causes sparse data problems because only some of the possible rules of that length actually appear in the training corpus. The sparse data problem is solved by markovization (Collins 1997; Klein and Manning 2003), which splits long rules into a set of shorter rules. The shorter rules generate the child nodes of the original rule one by one. First, the left siblings of the head child of the rule are generated from left to right, then the right siblings are generated from right to left. Finally, the head is generated. Figure 4 shows the markovization of the rule NP → NM NN PP PP. The auxiliary symbols that are used here encode information about the parent category, the head child, and previously generated children. Because all auxiliary symbols encode the head category, the head"
J13-1005,A92-1018,0,0.0352465,"Missing"
J13-1005,W06-2929,0,0.0602476,"Missing"
J13-1005,P03-1013,0,0.0390987,"generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previ"
J13-1005,P01-1024,0,0.0588643,"ment by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information"
J13-1005,P08-1109,0,0.0939797,"Missing"
J13-1005,W07-1203,0,0.0147603,"d parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the monolingual feature set of Versley and Rehbein in our reranker, but add further monolingual features as well as bilingu"
J13-1005,2008.amta-srw.2,0,0.0296618,"-HD VP-OC Man kann AVP-MO one can ADV-MO ADV-HD aber ebenso but just-as-well VVINF-HD , sagen say S-OC , KOUS-CP PPER-SB ADJD-PD VAFIN-HD dass sie anspruchsvoll sind that they demanding are Figure 6 Erroneous parse produced by the reranker using only monolingual features, which is corrected by bilingual features. The sentence means One can, however, just as well say that they are demanding. 81 Computational Linguistics Volume 39, Number 1 improve ranking of German BitPar parses in the held-out test sets, which is a form of self-training. Two other interesting studies in this area are those of Fossum and Knight (2008) and of Huang, Jiang, and Liu (2009). They improve English prepositional phrase attachment using features from a Chinese sentence. Unlike our approach, however, they do not require a Chinese syntactic parse as the word order in Chinese is sufﬁcient to unambiguously determine the correct attachment point of the prepositional phrase in the English sentence without using a Chinese syntactic parse. We know of no other work that has investigated to what extent monolingual and bilingual features in parse reranking are complementary. In particular, the work on bitext parsing by Burkett and Klein (200"
J13-1005,E09-1033,1,0.938949,"nominal head. The extraction of verbal heads is somewhat more complicated. In order to obtain the correct verbal head of a clause irrespective of the verb position (verb-ﬁrst, verbsecond, verb-ﬁnal), we extract all verbs that are dominated by the clause and a possibly empty sequence of VP-OC or VP-PD (statal passive) nodes and an optional VZ-HD node. Then we take the ﬁrst non-ﬁnite verb, or alternatively the ﬁrst ﬁnite verb if all verbs were ﬁnite. In order to avoid sparse data problems caused by the many different inﬂections of German verbs, we lemmatize the verbs. ¨ 21 In Fraser, Wang, and Schutze (2009) we used Minimum Error Rate Training. Once we made this change to maximum entropy the results on small feature sets became similar (details omitted). 22 An exception to this is that if a PP argument dominates a node of category PROAV-PH, it is considered a PROAV-PH argument. An example is the sentence Er [he] wartet [waits] (PP-OP (PROAV-PH darauf [for this]), (S-RE dass [that] sie [she] kommt [comes])). 74 Fraser et al. Knowledge Sources for Parsing German Table 2 Arguments used in extracted subcategorization frames. NP-SB, PN-SB, CNP-SB, S-SB, VP-SB NP-OA, PN-OA, CNP-OA NP-DA, PN-DA, CNP-DA"
J13-1005,N06-1024,0,0.0274491,"Missing"
J13-1005,W08-1007,0,0.160992,"sing is which type of parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but"
J13-1005,W08-2122,0,0.027458,". The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the mon"
J13-1005,P08-1067,0,0.0386001,"ious state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been deve"
J13-1005,D09-1127,0,0.0481369,"Missing"
J13-1005,J98-4004,0,0.233603,"s the chart as a large bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and lexicon used by our generative parser are extracted from the Tiger2 Treebank (Brants et al. 2002). Similar to Johnson (1998) and Klein and Manning (2003) we improve the accuracy of the unlexicalized parser by reﬁning the non-terminal symbols of the grammar to encode relevant contextual information. This reﬁnement weakens the strong independence assumptions of PCFGs and improves parsing accuracy. The extraction of the grammar and lexicon involves the following steps: 1. Discontinuous constituents are eliminated (Section 3.2). 2. Treebank annotations are transformed (Section 3.4) and augmented (Section 3.5). 3. Grammar rules, lexical rules, and their frequencies are extracted from the annotated parse trees. 4. The gr"
J13-1005,P03-1054,0,0.408779,"rge bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and lexicon used by our generative parser are extracted from the Tiger2 Treebank (Brants et al. 2002). Similar to Johnson (1998) and Klein and Manning (2003) we improve the accuracy of the unlexicalized parser by reﬁning the non-terminal symbols of the grammar to encode relevant contextual information. This reﬁnement weakens the strong independence assumptions of PCFGs and improves parsing accuracy. The extraction of the grammar and lexicon involves the following steps: 1. Discontinuous constituents are eliminated (Section 3.2). 2. Treebank annotations are transformed (Section 3.4) and augmented (Section 3.5). 3. Grammar rules, lexical rules, and their frequencies are extracted from the annotated parse trees. 4. The grammar is markovized (Section"
J13-1005,2005.mtsummit-papers.11,0,0.0116501,"to German, and sums all the span differences. It is measured in words. In addition to PPParentPrjWord we implement two bonus features, NonPPWord and NonPPPer. The former simply calculates the number of words that 79 Computational Linguistics Volume 39, Number 1 do not belong to PP phrases in the sentence, and the latter computes the non-PP proportion in a character-based fashion. These can be thought of as tunable parameters which adjust PPParentPrjWord to not disfavor large PPs. The other selected projection features are described in Table 4. Probabilistic Feature Functions. We use Europarl (Koehn 2005), from which we extract a parallel corpus of approximately 1.22 million sentence pairs, to estimate the probabilistic feature functions described in this section. We describe the feature PTag, despite the fact that it was not selected by the feature analysis, because several variations (described next) were selected. PTag measures tagging inconsistency based on estimating the probability for each English word that it has a particular POS tag, given the aligned German word’s POS tag. To avoid noisy feature values due to outliers and parse errors, we bound the value of PTag at 5.26 We use relati"
J13-1005,W06-1614,0,0.0820292,"Missing"
J13-1005,P04-1042,0,0.0790196,"Missing"
J13-1005,N06-1020,0,0.165602,"Missing"
J13-1005,P06-1043,0,0.0877529,"Missing"
J13-1005,E06-1011,0,0.0241518,"key question for MR&LC parsing is which type of parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with con"
J13-1005,W98-0509,0,0.0308318,"roduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performa"
J13-1005,N07-1051,0,0.0190713,"information. The resulting parser is currently the best constituent parser for German (with or without bilingual features). In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2. Previous Work Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the extension of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Wo"
J13-1005,W08-1005,0,0.136381,"ge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein a"
J13-1005,W06-1608,0,0.0290991,"for German previously by Versley and Rehbein (2009). We show that the richer subcategorization-based framework for monolingual reranking is effective; it has comparable performance to the sparse feature set—moreover, they complement each other. For bilingual reranking, we present our approach to bitext parsing, where a German parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver 2006). Improved parses of bitext should result in improved machine translation. Second, as more and more texts are available in several languages, it will be increasingly the case that a text to be parsed is itself part of a bitext. Third, we hope that the improved parses of bitext can serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky, Charniak, and Johnson 2006a). We show that the three different knowledge sources we use in this paper (lexical knowledge, monolingual features, and bilingual features) are valuable separately. W"
J13-1005,P05-1034,0,0.0754638,"Missing"
J13-1005,W08-1006,0,0.02696,"tent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexica"
J13-1005,N10-1049,0,0.0149329,"search question.3 Constituent parses often provide more information than dependency parses. An example is the coordination ambiguity in old men and women versus old men and children. The correct constituent parse for the ﬁrst expression contains a coordination at the noun level whereas the parse for the second expression coordinates at the level of NPs. The dependency structures of both expressions, on the other hand, are usually identical and thus unable to reﬂect the fact that old modiﬁes women but not children. It is possible, in principle, to encode the difference in dependency trees (cf. Rambow 2010), 2 This is due to how the evalb tool used to calculate PARSEVAL works. If a constituent is not perfectly matched, the grammatical function is considered to be wrong, even if there was a partial match (at the token level). This is not a problem with dependency-based evaluation. For further discussion of the PARSEVAL metric and dependency-based evaluation see, for example, Rehbein and van Genabith (2007) and Tsarfaty, Nivre, and Andersson (2012). 3 Two possible solutions are to use TedEval (Tsarfaty, Nivre, and Andersson 2012), or to conduct an analysis of grammatical functions at the token lev"
J13-1005,W07-2460,0,0.0876378,"Missing"
J13-1005,C04-1056,0,0.0313236,"ky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 Fraser et al. Knowledge Sources for Parsing German context-free grammar (PCFG) parser with latent feature annotations. Charniak and Johnson (2005) and Huang (2008) have introduced a signiﬁcant improvement by feature-rich discriminative reranking as well. The number of treebank constituent parsers for German is smaller. Dubey and Keller (2003) adapted Collins’s (1997) lexicalized parser to German. An unlexicalized PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German ¨ (Kubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers ¨ have been developed by Menzel and Schroder (1998), Duchier and Debusmann (2001), Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name a few. There is also some previous work on German parse reranking. Forst (2007) presented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to"
J13-1005,C04-1024,1,0.911442,"y and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also reﬁne treebank labels to increase parsing performance, but add more information and achieve a larger improvement. We use the monolingual feature set of Versley and Rehbein in our reranker, but add further monolingual features as well as bilingual features. 3. Generative Parsing Framework Our generative parser is an unlexicalized PCFG parser which is based on the BitPar parser (Schmid 2004). BitPar uses a fast bitvector-based implementation of the wellknown Cocke-Younger-Kasami algorithm and stores the chart as a large bit vector. This representation is memory efﬁcient and allows full parsing (without search space pruning) with large treebank grammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and-operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n-best parse trees. 3.1 Grammar The grammar and l"
J13-1005,P06-1023,1,0.822361,"tuents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparison is not fair as it required phrase boundaries to be correct on the constituent side while the tokens were the unit of evaluation on the dependency side.2 How to carry out an absolutely fair comparison of the two representations is still an open research question.3 Consti"
J13-1005,schmid-etal-2004-smor,1,0.827637,"Missing"
J13-1005,C10-2129,0,0.260946,"parsing formalism to adopt, constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for parsing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulick 2006; Schmid 2006; Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well. ¨ The overview paper of the Parsing German Shared Task (Kubler 2008) reports higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparis"
J13-1005,P10-1111,0,0.0405122,"Missing"
J13-1005,P08-1066,0,0.0270618,"Missing"
J13-1005,E12-1006,0,0.13257,"Missing"
J13-1005,W10-1401,0,0.107052,"Missing"
J13-1005,C10-1123,0,0.0139946,"ion, acting together. The most natural way of doing this in a language like German is to perform this integration of the two knowledge sources directly as part of parsing. We do this by annotating constituent labels with grammatical function where appropriate. In contrast with syntactic parses of strongly conﬁgurational languages like English, syntactic parses of German are not useful for most tasks without having 4 We do note, however, that there are a few translation systems which use a dependency representation directly (e.g., Quirk, Menezes, and Cherry 2005; Shen, Xu, and Weischedel 2008; Tu et al. 2010). 61 Computational Linguistics Volume 39, Number 1 grammatical functions indicated. It is not even possible to access the basic subcategorization of the verb (such as determining the subject) without grammatical functions. We argue that MR&LC languages like German should always be evaluated on labelscum-grammatical-function. Our last main contribution in this paper concerns the fact that we believe that MR&LC languages give rise to more ambiguity than languages that are predominantly conﬁgurational or morphological. As an example consider the German sentence “Die [the] Katze [cat] jagt [hunts]"
J13-1005,W09-3820,0,0.334604,"disambiguation. We believe that this distinguishing characteristic of MR&LC languages makes it necessary to tap additional knowledge sources. In this paper, we look at two such knowledge sources: monolingual reranking (which captures global properties of well-formed parses for additional disambiguation) and bilingual reranking (which exploits parallel text in a different language for disambiguation). For monolingual reranking, we deﬁne a novel set of rich features based on subcategorization frames. We compare our compact feature set with a sparse feature set designed for German previously by Versley and Rehbein (2009). We show that the richer subcategorization-based framework for monolingual reranking is effective; it has comparable performance to the sparse feature set—moreover, they complement each other. For bilingual reranking, we present our approach to bitext parsing, where a German parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quirk and Corston-Oliver 2006). Improved parses of b"
J13-1005,J93-2006,0,0.218488,"re spurious ambiguities. They arise because some of the rules which are not markovized are also covered by markovization rules. 3.7 Dealing with Unknown Words and Unseen POS Tags BitPar includes a sophisticated POS guesser that uses several strategies to deal with unknown words and unseen POS tags of known words. Unknown words are divided into eight classes11 based on regular expressions that are manually deﬁned. These classes distinguish between lower-case words, capitalized words, all upper-case words, hyphenated words, numbers, and so forth. For each word class, BitPar builds a sufﬁx tree (Weischedel et al. 1993; Schmid 1995; Brants 2000) from the sufﬁxes of all words in the lexicon up to a length of 7. At each node of the sufﬁx tree, it sums up the conditional POS probabilities (given the word) over all known words with that sufﬁx. By summing POS probabilities rather than frequencies, all words have the same weight, which is appropriate here because we need to model the POS probabilities of infrequent words. BitPar computes POS probability estimates for each node using the sum of probabilities as a pseudo-frequency for each tag. The estimates are recursively smoothed with the Witten-Bell method usin"
J13-1005,W08-1008,0,\N,Missing
J13-1005,P02-1018,0,\N,Missing
J13-1005,J05-1003,0,\N,Missing
L18-1061,L16-1021,0,0.0222883,"d at automatic coreference resolution. There is coreference annotation in the DIRNDL and ANCOR Centre corpora, containing German and French spoken language data (Muzerelle et al., 2014; Bj¨orkelund et al., 2014). As for Japanese, the corpus NAIST Text contains coreference annotation, together with predicate-argument structure (Iida et al., 2007). A large coreference corpus is also available for Polish (Ogrodniczuk et al., 2014; Ogrodniczuk et al., 2013b), moreover, there are annotated coreference corpora for Dutch (Hendrickx et al., 2008) and Czech (Nedoluzhko et al., 2009) as well. Recently, Ghaddar and Langlais (2016) reported on WikiCoref, a coreference corpus of English Wikipedia articles. A small dataset with manual coreference annotation was earlier published for Hungarian (Mih´altz, 2012). In contrast, here we present our large corpus, SzegedKoref, which has been manually annotated for coreference data. Due to its size, the corpus can be used for training and evaluating machine learning-based systems, which is nowadays the most popular approach used for coreference resolution (Pradhan et al., 2012). In morphologically rich languages like Hungarian, some issues might occur concerning the annotation pro"
L18-1061,hendrickx-etal-2008-coreference,0,0.309591,"an et al., 2011) and CoNLL-2012 (Pradhan et al., 2012) shared tasks, which aimed at automatic coreference resolution. There is coreference annotation in the DIRNDL and ANCOR Centre corpora, containing German and French spoken language data (Muzerelle et al., 2014; Bj¨orkelund et al., 2014). As for Japanese, the corpus NAIST Text contains coreference annotation, together with predicate-argument structure (Iida et al., 2007). A large coreference corpus is also available for Polish (Ogrodniczuk et al., 2014; Ogrodniczuk et al., 2013b), moreover, there are annotated coreference corpora for Dutch (Hendrickx et al., 2008) and Czech (Nedoluzhko et al., 2009) as well. Recently, Ghaddar and Langlais (2016) reported on WikiCoref, a coreference corpus of English Wikipedia articles. A small dataset with manual coreference annotation was earlier published for Hungarian (Mih´altz, 2012). In contrast, here we present our large corpus, SzegedKoref, which has been manually annotated for coreference data. Due to its size, the corpus can be used for training and evaluating machine learning-based systems, which is nowadays the most popular approach used for coreference resolution (Pradhan et al., 2012). In morphologically r"
L18-1061,W07-1522,0,0.0255214,"oNotes contains coreference annotation for English, Chinese and Arabic (Weischedel et al., 2011; Pradhan et al., 2007). This database formed the training and test sets of the CoNLL-2011 (Pradhan et al., 2011) and CoNLL-2012 (Pradhan et al., 2012) shared tasks, which aimed at automatic coreference resolution. There is coreference annotation in the DIRNDL and ANCOR Centre corpora, containing German and French spoken language data (Muzerelle et al., 2014; Bj¨orkelund et al., 2014). As for Japanese, the corpus NAIST Text contains coreference annotation, together with predicate-argument structure (Iida et al., 2007). A large coreference corpus is also available for Polish (Ogrodniczuk et al., 2014; Ogrodniczuk et al., 2013b), moreover, there are annotated coreference corpora for Dutch (Hendrickx et al., 2008) and Czech (Nedoluzhko et al., 2009) as well. Recently, Ghaddar and Langlais (2016) reported on WikiCoref, a coreference corpus of English Wikipedia articles. A small dataset with manual coreference annotation was earlier published for Hungarian (Mih´altz, 2012). In contrast, here we present our large corpus, SzegedKoref, which has been manually annotated for coreference data. Due to its size, the co"
L18-1061,muzerelle-etal-2014-ancor,0,0.0187535,"e special attention from the viewpoint of coreference resolution. 2. Related Work There are several coreference corpora available for many languages, for instance, OntoNotes contains coreference annotation for English, Chinese and Arabic (Weischedel et al., 2011; Pradhan et al., 2007). This database formed the training and test sets of the CoNLL-2011 (Pradhan et al., 2011) and CoNLL-2012 (Pradhan et al., 2012) shared tasks, which aimed at automatic coreference resolution. There is coreference annotation in the DIRNDL and ANCOR Centre corpora, containing German and French spoken language data (Muzerelle et al., 2014; Bj¨orkelund et al., 2014). As for Japanese, the corpus NAIST Text contains coreference annotation, together with predicate-argument structure (Iida et al., 2007). A large coreference corpus is also available for Polish (Ogrodniczuk et al., 2014; Ogrodniczuk et al., 2013b), moreover, there are annotated coreference corpora for Dutch (Hendrickx et al., 2008) and Czech (Nedoluzhko et al., 2009) as well. Recently, Ghaddar and Langlais (2016) reported on WikiCoref, a coreference corpus of English Wikipedia articles. A small dataset with manual coreference annotation was earlier published for Hung"
L18-1061,ogrodniczuk-etal-2014-polish,0,0.0378524,"Missing"
L18-1061,W11-1901,0,0.0199418,"nal coreference (hypernyms, synonyms etc.), and we offer several examples of each annotated category. We also mark zero anaphors and pronouns coreferential with subordinate clauses since these are two linguistic phenomena of Hungarian that deserve special attention from the viewpoint of coreference resolution. 2. Related Work There are several coreference corpora available for many languages, for instance, OntoNotes contains coreference annotation for English, Chinese and Arabic (Weischedel et al., 2011; Pradhan et al., 2007). This database formed the training and test sets of the CoNLL-2011 (Pradhan et al., 2011) and CoNLL-2012 (Pradhan et al., 2012) shared tasks, which aimed at automatic coreference resolution. There is coreference annotation in the DIRNDL and ANCOR Centre corpora, containing German and French spoken language data (Muzerelle et al., 2014; Bj¨orkelund et al., 2014). As for Japanese, the corpus NAIST Text contains coreference annotation, together with predicate-argument structure (Iida et al., 2007). A large coreference corpus is also available for Polish (Ogrodniczuk et al., 2014; Ogrodniczuk et al., 2013b), moreover, there are annotated coreference corpora for Dutch (Hendrickx et al."
L18-1061,W12-4501,0,0.0203421,"tc.), and we offer several examples of each annotated category. We also mark zero anaphors and pronouns coreferential with subordinate clauses since these are two linguistic phenomena of Hungarian that deserve special attention from the viewpoint of coreference resolution. 2. Related Work There are several coreference corpora available for many languages, for instance, OntoNotes contains coreference annotation for English, Chinese and Arabic (Weischedel et al., 2011; Pradhan et al., 2007). This database formed the training and test sets of the CoNLL-2011 (Pradhan et al., 2011) and CoNLL-2012 (Pradhan et al., 2012) shared tasks, which aimed at automatic coreference resolution. There is coreference annotation in the DIRNDL and ANCOR Centre corpora, containing German and French spoken language data (Muzerelle et al., 2014; Bj¨orkelund et al., 2014). As for Japanese, the corpus NAIST Text contains coreference annotation, together with predicate-argument structure (Iida et al., 2007). A large coreference corpus is also available for Polish (Ogrodniczuk et al., 2014; Ogrodniczuk et al., 2013b), moreover, there are annotated coreference corpora for Dutch (Hendrickx et al., 2008) and Czech (Nedoluzhko et al.,"
L18-1208,C10-1011,0,0.116171,"Missing"
L18-1208,A00-1031,0,0.489098,"Missing"
L18-1208,P07-2053,0,0.0731944,"Missing"
L18-1208,halacsy-etal-2004-creating,0,0.172087,"Missing"
L18-1208,U08-1016,0,0.0609112,"Missing"
L18-1208,novak-2014-new,1,0.883351,"Missing"
L18-1208,R13-1071,1,0.901269,"Missing"
L18-1208,P06-1055,0,0.0450326,"Missing"
L18-1208,P99-1034,0,0.195182,"Missing"
L18-1208,E14-1015,1,0.911134,"Missing"
L18-1208,szarvas-etal-2006-highly,1,0.794467,"Missing"
L18-1208,W02-2024,0,0.347412,"Missing"
L18-1208,tron-etal-2006-morphdb,1,0.758805,"Missing"
L18-1208,vincze-etal-2010-hungarian,1,0.778219,"Missing"
L18-1208,E17-1034,1,0.865126,"Missing"
L18-1208,R13-1099,1,0.88567,"Missing"
P13-2046,W10-3704,0,0.0486031,"Missing"
P13-2046,W07-1101,0,0.0195743,"described below. The candidate extraction method investigated the dependency relation among the verbs and nouns. Verb-object, verb-subject, verbprepositional object, verb-other argument (in the case of Hungarian) and noun-modifier pairs were collected from the texts. The dependency labels were provided by the Bohnet parser (Bohnet, 2010) for English and by magyarlanc 2.0 (Zsibrita et al., 2013) for Hungarian. Related Work Recently, LVCs have received special interest in the NLP research community. They have been automatically identified in several languages such as English (Cook et al., 2007; Bannard, 2007; Vincze et al., 2011a; Tu and Roth, 2011), Dutch (Van de Cruys and Moir´on, 2007), Basque (Gurrutxaga and Alegria, 2011) and German (Evert and Kermes, 2003). Parallel corpora are of high importance in the automatic identification of multiword expressions: it is usually one-to-many correspondence that is exploited when designing methods for detecting multiword expressions. Caseli et al. (2010) developed an alignment-based method for extracting multiword expressions from Portuguese–English parallel corpora. Samardˇzi´c and Merlo (2010) analyzed English and German light verb constructions in par"
P13-2046,C10-1011,0,0.0699556,"ased approach was applied. This method first parsed each sentence and extracted potential LVCs. Afterwards, a binary classification method was utilized, which can automatically classify potential LVCs as an LVC or not. This binary classifier was based on a rich feature set described below. The candidate extraction method investigated the dependency relation among the verbs and nouns. Verb-object, verb-subject, verbprepositional object, verb-other argument (in the case of Hungarian) and noun-modifier pairs were collected from the texts. The dependency labels were provided by the Bohnet parser (Bohnet, 2010) for English and by magyarlanc 2.0 (Zsibrita et al., 2013) for Hungarian. Related Work Recently, LVCs have received special interest in the NLP research community. They have been automatically identified in several languages such as English (Cook et al., 2007; Bannard, 2007; Vincze et al., 2011a; Tu and Roth, 2011), Dutch (Van de Cruys and Moir´on, 2007), Basque (Gurrutxaga and Alegria, 2011) and German (Evert and Kermes, 2003). Parallel corpora are of high importance in the automatic identification of multiword expressions: it is usually one-to-many correspondence that is exploited when desig"
P13-2046,W10-2108,0,0.0311527,"Missing"
P13-2046,W07-1106,0,0.110007,"a rich feature set described below. The candidate extraction method investigated the dependency relation among the verbs and nouns. Verb-object, verb-subject, verbprepositional object, verb-other argument (in the case of Hungarian) and noun-modifier pairs were collected from the texts. The dependency labels were provided by the Bohnet parser (Bohnet, 2010) for English and by magyarlanc 2.0 (Zsibrita et al., 2013) for Hungarian. Related Work Recently, LVCs have received special interest in the NLP research community. They have been automatically identified in several languages such as English (Cook et al., 2007; Bannard, 2007; Vincze et al., 2011a; Tu and Roth, 2011), Dutch (Van de Cruys and Moir´on, 2007), Basque (Gurrutxaga and Alegria, 2011) and German (Evert and Kermes, 2003). Parallel corpora are of high importance in the automatic identification of multiword expressions: it is usually one-to-many correspondence that is exploited when designing methods for detecting multiword expressions. Caseli et al. (2010) developed an alignment-based method for extracting multiword expressions from Portuguese–English parallel corpora. Samardˇzi´c and Merlo (2010) analyzed English and German light verb const"
P13-2046,E03-1080,0,0.248517,"positional object, verb-other argument (in the case of Hungarian) and noun-modifier pairs were collected from the texts. The dependency labels were provided by the Bohnet parser (Bohnet, 2010) for English and by magyarlanc 2.0 (Zsibrita et al., 2013) for Hungarian. Related Work Recently, LVCs have received special interest in the NLP research community. They have been automatically identified in several languages such as English (Cook et al., 2007; Bannard, 2007; Vincze et al., 2011a; Tu and Roth, 2011), Dutch (Van de Cruys and Moir´on, 2007), Basque (Gurrutxaga and Alegria, 2011) and German (Evert and Kermes, 2003). Parallel corpora are of high importance in the automatic identification of multiword expressions: it is usually one-to-many correspondence that is exploited when designing methods for detecting multiword expressions. Caseli et al. (2010) developed an alignment-based method for extracting multiword expressions from Portuguese–English parallel corpora. Samardˇzi´c and Merlo (2010) analyzed English and German light verb constructions in parallel corpora: they pay special attention to their manual and automatic alignment. Zarrieß 256 The features used by the binary classifier can be categorised"
P13-2046,W09-2906,0,0.0297624,"of integrating language specific features into the systems and we explore how the systems could be further improved. For this purpose, we make use of the English–Hungarian parallel corpus SzegedParalellFX (Vincze, 2012), where LVCs have been manually annotated. 255 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 255–261, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics and Kuhn (2009) argued that multiword expressions can be reliably detected in parallel corpora by using dependency-parsed, word-aligned sentences. Sinha (2009) detected Hindi complex predicates (i.e. a combination of a light verb and a noun, a verb or an adjective) in a Hindi–English parallel corpus by identifying a mismatch of the Hindi light verb meaning in the aligned English sentence. Many-to-one correspondences were also exploited by Attia et al. (2010) when identifying Arabic multiword expressions relying on asymmetries between paralell entry titles of Wikipedia. Tsvetkov and Wintner (2010) identified Hebrew multiword expressions by searching for misalignments in an English–Hebrew parallel corpus. To the best of our knowledge, parallel corpora"
P13-2046,W07-1102,0,0.0909469,"ly bleached (Apresjan, 2004; Alonso Ramos, 2004; Sanrom´an Vilas, 2009) since it also adds important aspects to the meaning of the construction (for instance, the beginning of an action, such as set on fire, see Mel’ˇcuk (2004)). The meaning of LVCs can be only partially computed on the basis of the meanings of their parts and the way they are related to each other, hence it is important to treat them in a special way in many NLP applications. LVCs are usually distinguished from productive or literal verb + noun constructions on the one hand and idiomatic verb + noun expressions on the other (Fazly and Stevenson, 2007). Variativity and omitting the verb play the most significant role in distinguishing LVCs from productive constructions and idioms (Vincze, 2011). Variativity reflects the fact that LVCs can be often substituted by a verb derived from the same root as the nominal component within the construction: productive constructions and idioms can be rarely substituted by a single verb (like make a decision – decide). Omitting the verb exploits the fact that it is the nominal component that mostly bears the semantic content of the LVC, hence the event denoted by the construction can be determined even wi"
P13-2046,W11-0802,0,0.0607681,"nouns. Verb-object, verb-subject, verbprepositional object, verb-other argument (in the case of Hungarian) and noun-modifier pairs were collected from the texts. The dependency labels were provided by the Bohnet parser (Bohnet, 2010) for English and by magyarlanc 2.0 (Zsibrita et al., 2013) for Hungarian. Related Work Recently, LVCs have received special interest in the NLP research community. They have been automatically identified in several languages such as English (Cook et al., 2007; Bannard, 2007; Vincze et al., 2011a; Tu and Roth, 2011), Dutch (Van de Cruys and Moir´on, 2007), Basque (Gurrutxaga and Alegria, 2011) and German (Evert and Kermes, 2003). Parallel corpora are of high importance in the automatic identification of multiword expressions: it is usually one-to-many correspondence that is exploited when designing methods for detecting multiword expressions. Caseli et al. (2010) developed an alignment-based method for extracting multiword expressions from Portuguese–English parallel corpora. Samardˇzi´c and Merlo (2010) analyzed English and German light verb constructions in parallel corpora: they pay special attention to their manual and automatic alignment. Zarrieß 256 The features used by the b"
P13-2046,W04-0401,0,0.0699871,"Missing"
P13-2046,C10-2144,0,0.0218564,"mputational Linguistics and Kuhn (2009) argued that multiword expressions can be reliably detected in parallel corpora by using dependency-parsed, word-aligned sentences. Sinha (2009) detected Hindi complex predicates (i.e. a combination of a light verb and a noun, a verb or an adjective) in a Hindi–English parallel corpus by identifying a mismatch of the Hindi light verb meaning in the aligned English sentence. Many-to-one correspondences were also exploited by Attia et al. (2010) when identifying Arabic multiword expressions relying on asymmetries between paralell entry titles of Wikipedia. Tsvetkov and Wintner (2010) identified Hebrew multiword expressions by searching for misalignments in an English–Hebrew parallel corpus. To the best of our knowledge, parallel corpora have not been used for testing the efficiency of an MWE-detecting method for two languages at the same time. Here, we investigate the performance of our base LVC-detector on English and Hungarian and pay special attention to the added value of language-specific features. ring made of gold (non-LVC) and He gave her a ring because he wanted to hear her voice (LVC), hence it is important to identify them in context. In theoretical linguistics"
P13-2046,W11-0807,0,0.646827,"it is important to identify them in context. In theoretical linguistics, Kearns (2002) distinguishes between two subtypes of light verb constructions. True light verb constructions such as to give a wipe or to have a laugh and vague action verbs such as to make an agreement or to do the ironing differ in some syntactic and semantic features and can be separated by various tests, e.g. passivization, WH-movement, pronominalization etc. This distinction also manifests in natural language processing as several authors pay attention to the identification of just true light verb constructions, e.g. Tu and Roth (2011). However, here we do not make such a distinction and aim to identify all types of light verb constructions both in English and in Hungarian, in accordance with the annotation principles of SZPFX. The canonical form of a Hungarian light verb construction is a bare noun + third person singular verb. However, they may occur in non-canonical versions as well: the verb may precede the noun, or the noun and the verb may be not adjacent due to the free word order. Moreover, as Hungarian is a morphologically rich language, the verb may occur in different surface forms inflected for tense, mood, perso"
P13-2046,W07-1104,0,0.209543,"Missing"
P13-2046,C10-1125,1,0.899485,"ede the noun, or the noun and the verb may be not adjacent due to the free word order. Moreover, as Hungarian is a morphologically rich language, the verb may occur in different surface forms inflected for tense, mood, person and number. These features will be paid attention to when implementing our system for detecting Hungarian LVCs. 3 4 Experiments In our investigations we made use of the SzegedParalellFX English-Hungarian parallel corpus, which consists of 14,000 sentences and contains about 1370 LVCs for each language. In addition, we are aware of two other corpora – the Szeged Treebank (Vincze and Csirik, 2010) and Wiki50 (Vincze et al., 2011b) –, which were manually annotated for LVCs on the basis of similar principles as SZPFX, so we exploited these corpora when defining our features. To automatically identify LVCs in running texts, a machine learning based approach was applied. This method first parsed each sentence and extracted potential LVCs. Afterwards, a binary classification method was utilized, which can automatically classify potential LVCs as an LVC or not. This binary classifier was based on a rich feature set described below. The candidate extraction method investigated the dependency"
P13-2046,W11-0817,1,0.898653,"b may be not adjacent due to the free word order. Moreover, as Hungarian is a morphologically rich language, the verb may occur in different surface forms inflected for tense, mood, person and number. These features will be paid attention to when implementing our system for detecting Hungarian LVCs. 3 4 Experiments In our investigations we made use of the SzegedParalellFX English-Hungarian parallel corpus, which consists of 14,000 sentences and contains about 1370 LVCs for each language. In addition, we are aware of two other corpora – the Szeged Treebank (Vincze and Csirik, 2010) and Wiki50 (Vincze et al., 2011b) –, which were manually annotated for LVCs on the basis of similar principles as SZPFX, so we exploited these corpora when defining our features. To automatically identify LVCs in running texts, a machine learning based approach was applied. This method first parsed each sentence and extracted potential LVCs. Afterwards, a binary classification method was utilized, which can automatically classify potential LVCs as an LVC or not. This binary classifier was based on a rich feature set described below. The candidate extraction method investigated the dependency relation among the verbs and nou"
P13-2046,R11-1040,1,0.931733,"b may be not adjacent due to the free word order. Moreover, as Hungarian is a morphologically rich language, the verb may occur in different surface forms inflected for tense, mood, person and number. These features will be paid attention to when implementing our system for detecting Hungarian LVCs. 3 4 Experiments In our investigations we made use of the SzegedParalellFX English-Hungarian parallel corpus, which consists of 14,000 sentences and contains about 1370 LVCs for each language. In addition, we are aware of two other corpora – the Szeged Treebank (Vincze and Csirik, 2010) and Wiki50 (Vincze et al., 2011b) –, which were manually annotated for LVCs on the basis of similar principles as SZPFX, so we exploited these corpora when defining our features. To automatically identify LVCs in running texts, a machine learning based approach was applied. This method first parsed each sentence and extracted potential LVCs. Afterwards, a binary classification method was utilized, which can automatically classify potential LVCs as an LVC or not. This binary classifier was based on a rich feature set described below. The candidate extraction method investigated the dependency relation among the verbs and nou"
P13-2046,vincze-2012-light,1,0.827914,"t differences among languages and the usefulness of techniques that are applied. In this paper, we focus on the task of identifying light verb constructions (LVCs) in English and Hungarian free texts. Thus, the same task will be carried out for English and a morphologically rich language. We compare whether the same set of features can be used for both languages, we investigate the benefits of integrating language specific features into the systems and we explore how the systems could be further improved. For this purpose, we make use of the English–Hungarian parallel corpus SzegedParalellFX (Vincze, 2012), where LVCs have been manually annotated. 255 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 255–261, c Sofia, Bulgaria, August 4-9 2013. 2013 Association for Computational Linguistics and Kuhn (2009) argued that multiword expressions can be reliably detected in parallel corpora by using dependency-parsed, word-aligned sentences. Sinha (2009) detected Hindi complex predicates (i.e. a combination of a light verb and a noun, a verb or an adjective) in a Hindi–English parallel corpus by identifying a mismatch of the Hindi light verb meaning in the"
P13-2046,W09-2904,0,0.0702218,"Missing"
Q13-1034,C00-2143,1,0.361351,"bank covered by morphological analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training"
Q13-1034,boguslavsky-etal-2002-development,1,0.676986,"cal analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Russian Language Institute of the Russian Academy of Sciences and tokenized by the ETAP-3 analyzer. 4 Joint Morphology and Syntax We start by exploring different ways of integrating morphology and syntax in a data-driven setting, that is, where our only knowledge source is the annotated training corpus. At both learning a"
Q13-1034,E12-1009,1,0.573095,"ther support for this choice, at least for the languages considered in this paper. Note also that the choice is not motivated by efficiency concerns, since increasing the values of kp and km has only a marginal effect on running time, as explained in Section 2.4. Finally, the choice not to consider k-best lemmas is dictated by the fact that our lemmatizer only provides a 1-best analysis. For the first three models, we use the same feature representations as Bohnet and Nivre (2012),9 consisting of their adaptation of the features used by Zhang and Nivre (2011), the graph completion features of Bohnet and Kuhn (2012), and the special features over k-best tags introduced specifically for joint tagging and parsing by Bohnet and Nivre (2012). For the J OINT model, we simply add features over the k-best morphological descriptions analogous to the features over k-best tags.10 Experimental results for these four models can be found in Table 2. From the P IPELINE results, we see that the 1-best accuracy of the preprocessing tagger ranges from 95.0 (Finnish) to 99.2 (Czech) for POS, and from 89.4 (Finnish) to 96.5 (Hungarian) for MOR. The lemmatizer does a good job for four of the languages (93.9–97.9) but has re"
Q13-1034,D12-1133,1,0.0763756,"s, which tend to assume that all morphological disambiguation has been performed before syntactic analysis begins. However, as argued by Lee et al. (2011), in morphologically rich languages there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. Lee et al. (2011) go on to show that a discriminative model for joint morphological disambiguation and dependency parsing gives consistent improvements in morphological and syntactic accuracy, compared to a pipeline model, for Ancient Greek, Czech, Hungarian and Latin. Similarly, Bohnet and Nivre (2012) propose a model for 1 See https://sites.google.com/site/spmrl2013/home/sharedtask. 415 Transactions of the Association for Computational Linguistics, 1 (2013) 415–428. Action Editor: Brian Roark. c Submitted 7/2013; Revised 9/2013; Published 10/2013. 2013 Association for Computational Linguistics. joint part-of-speech tagging and dependency parsing and report improved accuracy for Czech and German (but also for Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approa"
Q13-1034,C10-1011,1,0.684406,"nguages. For Czech, the best previous UAS on the standard train-test split of the PDT is 87.32, reported by Koo et al. (2010) with a parser using non-projective head automata and dual decomposition, while the best LAS is 78.82 LAS from Nilsson et al. (2006), using a greedy arc-eager transitionbased system with pseudo-projective parsing. Our best results are 1.7 percentage points better for UAS (89.0) and almost 5 percentage points better for LAS (83.7).14 For Finnish, the only previous results are from Haverinen et al. (2013), who achieve 81.01 LAS and 84.97 UAS with the graph-based parser of Bohnet (2010). We get substantial improvements with 83.1 LAS and 86.6 UAS. We also improve slightly over their best POS score, obtained with the HunPos tagger (Hal´acsy et al., 2007) together with the OMorFi analyzer (95.7 vs. 95.4). For German, the best previous results on the same train-test split are from Seeker and Kuhn (2012), using the graphbased parser of Bohnet (2010) in a pipeline architecture. With the same evaluation setup as in this paper, they achieve 91.50 LAS and 93.48 UAS – 13 L EX S OFT averages 0.132 ms per sentence on an Intel i73930K processor with 6 cores, against 0.112 ms for P IPELIN"
Q13-1034,J92-4003,0,0.242366,"striking for German, where the soft lexical constraints are clearly beneficial (especially for the MOR score) despite not being quite compatible with the morphological descriptions in the training set. In terms of statistical signifance, L EX S OFT outperforms the J OINT model with respect to the PMD score for all languages (p < 0.01). It is also significantly better than L EX H ARD for all languages except Finnish (p < 0.01). 6 Word Clusters Finally, we add word cluster features to the best model for each language (L EX H ARD for Finnish, L EX S OFT for the others).11 We use Brown clusters (Brown et al., 1992), with 800 clusters for all languages, and we use the same feature representation as Bohnet and Nivre (2012). The results in Table 2 show small but consistent improvements in almost all metrics for all languages, confirming the benefit of cluster features for morphologically rich languages. It is worth noting that we see the biggest improvement for Finnish, the language with the smallest training set and therefore most likely to 11 The best model was selected according to results on the dev set (cross-validation on the training set for Finnish). suffer from sparse data, where the syntactic acc"
Q13-1034,W06-2920,0,0.719913,"re languages, it has also been observed that typological differences between languages lead to new challenges. In particular, it has been found over and over again that languages exhibiting rich morphological structure, often together with a relatively free word order, usually obtain lower parsing accuracy, especially in comparison to English. One striking demonstration of this tendency can be found in the CoNLL shared tasks on multilingual dependency parsing, organized in 2006 and 2007, where richly inflected languages clustered at the lower end of the scale with respect to parsing accuracy (Buchholz and Marsi, 2006; Nivre et al., 2007). These and similar observations have led to an increased interest in the special challenges posed by parsing morphologically rich languages, as evidenced most clearly by a new series of workshops devoted to this topic (Tsarfaty et al., 2010), as well as a special issue in Computational Linguistics (Tsarfaty et al., 2013) and a shared task on parsing morphologically rich languages.1 One hypothesized explanation for the lower parsing accuracy observed for richly inflected languages is the strict separation of morphological and syntactic analysis assumed in many parsing fram"
Q13-1034,D07-1022,0,0.0694561,"ish), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that"
Q13-1034,D11-1114,0,0.0374383,"Missing"
Q13-1034,P04-1015,0,0.261816,"put sentence x with weight vector w. The symbols h.c, h.s and h.f denote, respectively, the configuration, score and feature vector of a hypothesis h; Γc denotes the MS-parse defined by c. to 0.0, make N iterations over the training data and update the weight vector for every sentence x where the transition sequence C0,m corresponding to the gold parse is different from the highest scoring tran4 More precisely, we use the ∗ sition sequence C0,m 0. passive-aggressive update of Crammer et al. (2006). We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010). This means that, at learning time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4 Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-de"
Q13-1034,W02-1001,0,0.162454,"inear for natural language data sets, due to the sparsity of non-projective dependencies (Nivre, 2009). The running time is also linear in |D |+ |P × M |, which means that joint prediction only gives a linear increase in running time, often quite marginal because |D |> |P × M |. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all weights 3 While there exist exact dynamic programming algorithms for projective transition systems (Huang and Sagae, 2010; Kuhlmann et al., 2011) and even for restricted non-projective systems (Cohen et al., 2011), parsing is intractable for systems like ours that permit arbitrary non-projective trees. PARSE(x, w) 1 h0 .c ← cs (x) 2 h0 .s ← 0.0 3 h0 .f ← {0.0}dim(w) 4 B EAM ← [h0 ] 5 while ∃h ∈ B EAM : h.c 6∈ Ct 6 T MP ← [ ] 7 foreach h ∈ B EAM 8 foreach t ∈ T : P ERMISSIBLE(h.c, t) 9 h.f ← h.f + f(x, h.c"
Q13-1034,H05-1100,0,0.0303135,"and German (but also for Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus"
Q13-1034,E12-1007,1,0.93185,"22 1105 33 151,971 71,263 200,249,814 538,138 14 454 78 97,905 35,039 195,897,041 639,446 Table 1: Statistics about data sets and resources used in the experiments. Treebank: number of tokens in data sets; number of labels in label sets. Morphology: number of word forms and lemmas in treebank covered by morphological analyzer. Clusters: number of tokens and types in unlabeled corpus. treebank annotation we have to rely on a heuristic mapping between the two. Word clusters are derived from the so-called Huge German Corpus.7 Hungarian For training and test we use the Szeged Dependency Treebank (Farkas et al., 2012). We use a finite-state morphological analyzer constructed from the morphdb.hu lexical resource (Tr´on et al., 2006), and word clusters come from the Hungarian National Corpus (V´aradi, 2002). Russian Parsers are trained and tested on data from the SynTagRus Treebank (Boguslavsky et al., 2000; Boguslavsky et al., 2002). The morphological analyzer is a module of the ETAP-3 linguistic processor (Apresian et al., 2003) with a dictionary comprising more than 130,000 lexemes (Iomdin and Sizov, 2008). Word clusters have been produced on the basis of an unlabeled corpus of Russian compiled by the Rus"
Q13-1034,W09-1205,0,0.0234606,"binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependen"
Q13-1034,J13-1007,0,0.0248062,"Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of lexical features can also be tackled by the use of distributional word clusters as pioneered by Koo et al. (2008). In this paper, we present a transition-based model that jointly predicts complex morphological representations and dependency relations, generalizing the approach of Bohnet and Nivre (2012) to include the full range"
Q13-1034,P08-1043,0,0.0558272,"case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-"
Q13-1034,P98-1080,1,0.597993,"Missing"
Q13-1034,A00-2013,0,0.0703501,"Missing"
Q13-1034,P07-2053,0,0.0543962,"Missing"
Q13-1034,I11-1136,0,0.0554181,"hang and Clark (2008), we assume that the score is given by a linear model whose feature representations decompose in the same way: s(x, C0,m ) = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has show"
Q13-1034,P10-1110,0,0.18704,"near increase in running time, often quite marginal because |D |> |P × M |. This assumes that the lemma is predicted deterministically given a tag and a morphological description, an assumption that is enforced in all our experiments. 2.5 Learning In order to learn a weight vector w from a training set of sentences with gold parses, we use a variant of the structured perceptron, introduced by Collins (2002) and first used for transition-based parsing by Zhang and Clark (2008). We initialize all weights 3 While there exist exact dynamic programming algorithms for projective transition systems (Huang and Sagae, 2010; Kuhlmann et al., 2011) and even for restricted non-projective systems (Cohen et al., 2011), parsing is intractable for systems like ours that permit arbitrary non-projective trees. PARSE(x, w) 1 h0 .c ← cs (x) 2 h0 .s ← 0.0 3 h0 .f ← {0.0}dim(w) 4 B EAM ← [h0 ] 5 while ∃h ∈ B EAM : h.c 6∈ Ct 6 T MP ← [ ] 7 foreach h ∈ B EAM 8 foreach t ∈ T : P ERMISSIBLE(h.c, t) 9 h.f ← h.f + f(x, h.c, t) 10 h.s ← h.s + f(x, h.c, t) · w 11 h.c ← t(h.c) 12 T MP ← I NSERT(h, T MP) 13 B EAM ← P RUNE(T MP) 14 h∗ ← T OP(B EAM) 15 return Γh∗c Figure 2: Beam search algorithm for finding the best MSparse for input s"
Q13-1034,P08-1068,0,0.0257504,"rphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and Elhadad (2013) show that integrating an external wide-coverage lexicon with a treebank-trained PCFG parser improves parsing accuracy for Modern Hebrew, which is in line with earlier studies of part-of-speech tagging for morphologically rich languages (Hajiˇc, 2000). The sparsity of lexical features can also be tackled by the use of distributional word clusters as pioneered by Koo et al. (2008). In this paper, we present a transition-based model that jointly predicts complex morphological representations and dependency relations, generalizing the approach of Bohnet and Nivre (2012) to include the full range of morphological information. We start by investigating different ways of integrating morphological features into the model, go on to examine the effect of using rule-based morphological analyzers to derive hard or soft constraints on the morphological analysis, and finally add word cluster features to combat lexical sparsity. We evaluate our methods on data from Czech, Finnish,"
Q13-1034,D10-1125,0,0.0274644,"Missing"
Q13-1034,P11-1068,0,0.0182537,"Missing"
Q13-1034,P11-1089,0,0.0278511,"al., 2010), as well as a special issue in Computational Linguistics (Tsarfaty et al., 2013) and a shared task on parsing morphologically rich languages.1 One hypothesized explanation for the lower parsing accuracy observed for richly inflected languages is the strict separation of morphological and syntactic analysis assumed in many parsing frameworks (Tsarfaty et al., 2010; Tsarfaty et al., 2013). This is true in particular for data-driven dependency parsers, which tend to assume that all morphological disambiguation has been performed before syntactic analysis begins. However, as argued by Lee et al. (2011), in morphologically rich languages there is often considerable interaction between morphology and syntax, such that neither can be disambiguated without the other. Lee et al. (2011) go on to show that a discriminative model for joint morphological disambiguation and dependency parsing gives consistent improvements in morphological and syntactic accuracy, compared to a pipeline model, for Ancient Greek, Czech, Hungarian and Latin. Similarly, Bohnet and Nivre (2012) propose a model for 1 See https://sites.google.com/site/spmrl2013/home/sharedtask. 415 Transactions of the Association for Computa"
Q13-1034,P06-1033,1,0.867756,"Missing"
Q13-1034,W09-3811,1,0.599747,"ng time, we terminate the beam search as soon as the hypothesis corresponding to the gold parse is pruned from the beam and then update with respect to the partial transition sequences constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors seen in training, as originally proposed by Collins (2002). 4 Note that there may be more than one transition sequence corresponding to the gold parse, in which case we pick the canonical transition sequence that processes all left-dependents before right-dependents and applies the lazy swapping strategy of Nivre et al. (2009). 419 3 Data Sets and Resources Throughout the paper, we experiment with data from five languages: Czech, Finnish, German, Hungarian, and Russian. For each language, we use a morphologically and syntactically annotated corpus (treebank), divided into a training set, a development set and a test set. In addition, we use a lexicon generated by a rule-based morphological analyzer, and distributional word clusters derived from a large unlabeled corpus. Below we describe the specific resources used for each language. Table 1 provides descriptive statistics about the resources. Czech For training an"
Q13-1034,W03-3017,1,0.552345,"ections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the S WAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly different impl"
Q13-1034,W04-0308,1,0.586101,"e representations decompose in the same way: s(x, C0,m ) = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark,"
Q13-1034,P09-1040,1,0.939947,"Γ = (A, π, µ, λ, δ) is an MS-parse for x. We take the initial configuration for a sentence x = w1 , . . . , wn to be cs (x) = ([0], [1, . . . , n], (∅, ⊥, ⊥, ⊥, ⊥)), where ⊥ is the function that is undefined for all arguments, and we take the set Ct of terminal configurations to be the set of all configurations of the form c = ([0], [ ], Γ) (for any Γ). The MS-parse defined for x by c = (Σ, B, (A, π, µ, λ, δ)) is Γc = (A, π, µ, λ, δ), and the MS-parse defined for x by a complete transition sequence C0,m is Γtm (cm ) . The set T of transitions is shown in Figure 1. It is based on the system of Nivre (2009), where a dependency tree is built by repeated applications of the L EFT-A RCd and R IGHT-A RCd transitions, which add an arc (with some label d ∈ D) between the two topmost nodes on the stack (with the leftmost or rightmost node as the dependent, respectively). The S HIFT transition is used to move nodes from the buffer to the stack, and the S WAP transition is used to permute nodes in order to allow non-projective dependencies. Bohnet and Nivre (2012) modified this system by replacing the simple S HIFT transition by S HIFTp , which not only moves a node from the buffer to the stack but also"
Q13-1034,W11-4644,0,0.0793275,"Missing"
Q13-1034,W09-3829,0,0.0396525,"Missing"
Q13-1034,schmid-etal-2004-smor,0,0.0195468,"Missing"
Q13-1034,seeker-kuhn-2012-making,0,0.0289485,"Missing"
Q13-1034,C10-2129,1,0.896137,"Missing"
Q13-1034,spoustova-spousta-2012-high,0,0.0221884,"Missing"
Q13-1034,W07-2218,0,0.0373151,") = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search deco"
Q13-1034,tron-etal-2006-morphdb,0,0.119292,"Missing"
Q13-1034,W10-1401,0,0.0166567,"Missing"
Q13-1034,J13-1003,1,0.829911,"Missing"
Q13-1034,P06-3009,0,0.0901789,"Chinese and English), although in this case the joint model is limited to basic part-ofspeech tags and does not involve the full complex of morphological features. An integrated approach to morphological and syntactic analysis can also be found in grammar-based dependency parsers, such as the ETAP-3 linguistic processor (Apresian et al., 2003), where morphological disambiguation is mostly carried out together with syntactic analysis. Finally, it is worth noting that joint models of morphology and syntax have been more popular in constituency-based statistical parsing (Cowan and Collins, 2005; Tsarfaty, 2006; Cohen and Smith, 2007; Goldberg and Tsarfaty, 2008). Another hypothesis from the literature is that the high type-token ratio resulting from large morphological paradigms leads to data sparseness when estimating the parameters of a statistical parsing model (Tsarfaty et al., 2010; Tsarfaty et al., 2013). In particular, for many words in the language, only a subset of its morphological forms will be observed at training time. This suggests that using rule-based morphological analyzers or other lexical resources may be a viable strategy to improve coverage and performance. Thus, Goldberg and E"
Q13-1034,varadi-2002-hungarian,0,0.105288,"Missing"
Q13-1034,W03-3023,0,0.0799723,"tantiation of the model in Sections 4–6. 2 Hatori et al. (2011) previously made the same modification to the arc-standard system (Nivre, 2004), without the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the S WAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly"
Q13-1034,D08-1059,0,0.738873,"so that a node moved from the buffer to the stack is assigned not only a tag p but also a morphological description m and a lemma l. In this way, we get a joint model for the prediction of part-ofspeech tags, morphological features, lemmas, and dependency trees. 2.3 Scoring In transition-based parsing, we score parses in an indirect fashion by scoring transition sequences. In general, we assume that the score function s factors by configuration-transition pairs: s(x, C0,m ) = m X s(x, ci , ti ) (1) i=0 Moreover, when using structured learning, as first proposed for transition-based parsing by Zhang and Clark (2008), we assume that the score is given by a linear model whose feature representations decompose in the same way: s(x, C0,m ) = f (x, C0,m ) · w m X = f (x, ci , ti ) · w (2) i=0 Here, f (x, c, t) is a high-dimensional feature vector, where each component fi (x, c, t) is a nonnegative numerical feature (usually binary), and w is a weight vector of the same dimensionality, where each component wi is the real-valued weight of the feature fi (x, c, t). The choice of features to include in f (x, c, t) is discussed separately for each instantiation of the model in Sections 4–6. 2 Hatori et al. (2011)"
Q13-1034,P11-2033,1,0.457721,"ection 7, we present an empirical analysis that gives further support for this choice, at least for the languages considered in this paper. Note also that the choice is not motivated by efficiency concerns, since increasing the values of kp and km has only a marginal effect on running time, as explained in Section 2.4. Finally, the choice not to consider k-best lemmas is dictated by the fact that our lemmatizer only provides a 1-best analysis. For the first three models, we use the same feature representations as Bohnet and Nivre (2012),9 consisting of their adaptation of the features used by Zhang and Nivre (2011), the graph completion features of Bohnet and Kuhn (2012), and the special features over k-best tags introduced specifically for joint tagging and parsing by Bohnet and Nivre (2012). For the J OINT model, we simply add features over the k-best morphological descriptions analogous to the features over k-best tags.10 Experimental results for these four models can be found in Table 2. From the P IPELINE results, we see that the 1-best accuracy of the preprocessing tagger ranges from 95.0 (Finnish) to 99.2 (Czech) for POS, and from 89.4 (Finnish) to 96.5 (Hungarian) for MOR. The lemmatizer does a"
Q13-1034,C12-2136,1,0.0524599,"out the S WAP transition. Similarly, Titov and Henderson (2007) added a word parameter to the S HIFT transition to get a joint model of word strings and dependency trees. A similar model was considered but finally not used by Gesmundo et al. (2009). 418 2.4 Decoding Exact decoding for transition-based parsing is hard in general.3 Early transition-based parsers mostly relied on greedy, deterministic decoding, which makes for very efficient parsing (Yamada and Matsumoto, 2003; Nivre, 2003), but research has shown that accuracy can be improved by using beam search instead (Zhang and Clark, 2008; Zhang and Nivre, 2012). While still not exact, beam search decoders explore a larger part of the search space than greedy parsers, which is likely to be especially important for joint models, where the search space is larger than for plain dependency parsing without morphology (even more so with the S WAP transition for nonprojectivity). Figure 2 outlines the beam search algorithm used for decoding with our model. Different instantiations of the model will require slightly different implementations of the permissibility condition invoked in line 8, which can be used to filter out labels that are improbable or incom"
Q13-1034,C98-1077,0,\N,Missing
Q13-1034,W09-1201,1,\N,Missing
Q13-1034,D07-1096,1,\N,Missing
R13-1099,C10-1011,0,0.0132619,"rsing There are two mainstream approaches to syntactic parsing: the one based on constituency grammar and the other one based on dependency grammar. Dependency parsers are believed to be especially useful for parsing languages with free word order such as Hungarian since these parsers are able to connect grammatically related words that are not adjacent. 767 Borpancsol´okra , zajong´okra e´ s a´ llatk´ınz´okra nagyon sz´am´ıtanak . Farkas et al. (2012) made the first experiments on applying state-of-the-art dependency parsers to Hungarian. Since their results indicated that the Bohnet parser (Bohnet, 2010) was the most efficient on Hungarian dependency parsing, we integrated this parser into magyarlanc. The applied model was trained on the Szeged Dependency Treebank, which consists of 82,000 sentences, is manually POS-tagged and contains manually annotated dependency parses for each sentence (Vincze et al., 2010). Multiword named entities (e.g. Coca Cola Ltd.) and multiword numbers (e.g. 42 million) are treated in a special way. We consider the last word as the head because the last word of multiword units gets inflected in Hungarian and all the previous elements are attached to the succeeding"
R13-1099,E12-1007,1,0.927764,"of the methodology for morphosyntactic analysis has been developed for English. However, the linguistic analysis of morphologically rich and free word order languages requires special techniques. Hence, it was not sufficient to simply employ available tools and retrain on Hungarian corpora, we had to modify/adapt them. We hope that our findings and experiences gained during this 2 Grammatical Features of Hungarian In this section, we provide a basic description of the Hungarian language with special emphasis on the phenomena that are important for morphological and syntactic parsing, based on Farkas et al. (2012). For a better understanding of the phenomena described, English will be used as a contrast language. 763 Proceedings of Recent Advances in Natural Language Processing, pages 763–771, Hissar, Bulgaria, 7-13 September 2013. Figure 1: Dependency graph of the sentence V´artalak tegnap este “I was waiting for you last night”. Hungarian is an agglutinative language, thus a word can have hundreds of word forms due to inflectional or derivational affixation. Grammatical information is usually encoded in morphology and Hungarian is a typical morphologically rich language. Word order is free in the sen"
R13-1099,C94-1097,0,0.218107,"Missing"
R13-1099,C12-2105,1,0.832546,"attached to the last word, the antepenultimate word to the penultimate one etc. with an NE relation for named entities and a NUM relation for numbers. In the verbless clauses the Szeged Dependency Treebank introduces virtual nodes. This solution means that a similar tree structure is ascribed to the same sentence in the present third person singular / plural and all the other tenses / persons (see Figure 2). A further argument for the use of a virtual node is that the virtual node is always present at the syntactic level since it is overt in all the other forms, tenses and moods of the verb. Seeker et al. (2012) experimented with several methods for inserting virtual nodes into the verbless clauses. Although their results indicate that this issue still requires further investigation, in magyarlanc, we follow their complex label approach, which means that children of a virtual node are assigned a complex dependency label (e.g. ROOT-VAN-SUBJ), referring to the fact that the specific node is the subject of a virtual node (here VAN) which is itself not present in the sentence but functions as the root. Figure 2 shows variations of a sentence in the past tense and in the present tense with a virtual node"
R13-1099,N03-1033,0,0.00502307,"essive form of the noun, e.g. Ajk´an Ajka-SUP (a town in Hungary) or lip-SUP “in Ajka” or “on his lip” and here the reduced codes also differ from each other. An inflected form of a third person singular possessive form of a noun with front vowels may coincide with the inflected possessed form of the same noun, e.g. e´ nek´et song-3 SGPOSS-ACC or song-POSS-ACC “his song” or “that of his song”, egyed@Nn-sn eszik@Vmmp2s—y egy@Mc-snd—-s2 where the lemma and the morphological code are separated by an @ sign. 5.3 POS-tagging POS-tagging is executed by a modified version of the Stanford POS-tagger (Toutanova et al., 2003), which is based on a Maximum Entropy classifier and makes use of the possible tags provided 2 http://morphadorner.northwestern.edu/ 766 Feature SubPOS Num Cas NumP PerP NumPd Mood Tense Per Def Deg Clitic Form Coord Type N • • • • • • V • • V • • • • • • n A • • • • • • • P • • • • • • T • R • • • R l • S • C • M • • • • • • • • • I I o X Y Z O • • • • • • O e/d/n • • • • • • • • • Table 1: Relevant features for each part of speech and subtypes of parts of speech: type – SubPOS, number – Num, case – Cas, number of possessor – NumP, person of possessor – PerP, number of possessed – NumPd, mood"
R13-1099,W05-1106,0,0.345567,"Missing"
R13-1099,tron-etal-2006-morphdb,0,0.838656,"Missing"
R13-1099,varadi-2002-hungarian,0,0.318574,"Missing"
R13-1099,E03-1012,0,\N,Missing
R13-1099,vincze-etal-2010-hungarian,1,\N,Missing
R13-1099,halacsy-etal-2004-creating,0,\N,Missing
S07-1033,W02-1027,0,0.218371,"language processing applications ranging from information extraction to machine translation. Metonymic usage of named entities is frequent in natural language. On the basic NER categories person, place, organisation state-of-the-art systems generally perform in the mid to the high nineties. These systems typically do not distinguish between literal or metonymic usage of entity names, even though this would be helpful for most applications. Resolving metonymic usage of proper names would therefore directly benefit NER and indirectly all NLP tasks (such as anaphor resolution) that require NER. Markert and Nissim (2002) outlined a corpusbased approach to proper name metonymy as a semantic classification problem that forms the basis of the 2007 SemEval metonymy resolution task. Instances like ‘He was shocked by Vietnam’ or ‘Schengen boosted tourism’ were assigned to broad categories like place-for-event, sometimes ignoring narrower distinctions, such as the fact that it wasn’t the signing of the treaty at Schengen but rather its actual implementation (which didn’t take place at Schengen) that boosted tourism. But the corpus makes clear that even with these (sometimes coarse) class distinctions, several metony"
S07-1033,P03-1008,0,0.403468,"orward, however, to assign determiners to the PMWs without proper syntactic analysis. After some experiments, we linked the nearest determiner and the PMW together if we found only adjectives (or nothing) between them. 3.1 3.3 3 Feature Engineering Grammatical annotations We used the grammatical annotations provided for each PMW in several ways. First, we used as a feature the type of the grammatical relation and the word form of the related word. (If there was more than one related word, each became a feature.) To overcome data sparseness, it is useful to generalize from individual headwords Markert and Nissim (2003). We used three different methods to achieve this: Number This feature was particularly useful to separate metonymies of the org-for-product class. We assumed that only PMWs ending with letter s might be in plural form, and for them we compared the web search result numbers obtained by the Google API. We ran two queries for each PMWs, one for the full name, and one for the name without its last character. If we observed a significant increase in the number of hits returned by Google for the shorter phrase, 1 http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html we set this feature for plu"
S07-1033,S07-1007,0,\N,Missing
S10-1040,S10-1004,0,0.0341817,"eature is assigned a true value for keyphrase aspirants for which there exists a Wikipedia article with the same title. Preliminary experiments showed that this feature is noisy, thus we also investigated a relaxed version of it, where occurrences of Wikipedia article titles were looked for only in the title and abstract of a paper. Besides using Wikipedia for feature calculation, it was also utilized to retrieve semantic orientations of phrases. Making use of redirect links of Wikipedia, the semantic relation of synonymity Results and discussion The training and test sets of the shared task (Kim et al., 2010) consisted of 144 and 100 scientific publications from the ACL repository, respectively. Since the primary evaluation of the shared task was based on the top-15 ranked automatic keyphrases compared to the keyphrases assigned by the readers of the articles, these results are reported here. The evaluation results can be seen in Table 2 where the individual effect of each feature is given in combination with the standard features. It is interesting to note the improvement obtained by extending standard features with the simple feature of phrase length. This indicates that though the basic feature"
S10-1040,P03-1054,0,0.00343905,"ly selecting the most frequently occurring one among the top 10 responses provided by the Google API. This title was added to the document, and all the lines before the first occurrence of the line Abstract were omitted. Lines unlikely to contain valuable information were also excluded from the documents. These lines were identified according to statistical data of their surface forms (e.g. the average and the deviation of line lengths) and regular expressions. Lastly, section and sentence boundaries were found in a rule-based way, and the POS and syntactic tagging (using the Stanford parser (Klein and Manning, 2003)) of each sentence were carried out. When syntactically parsed sentences were obtained, keyphrase aspirants were extracted. The 1 to 4-long token sequences that did not start or end with a stopword and consisted only of POS-codes of an adjective, a noun or a verb were defined to be possible keyphrases (resulting in classification instances). Tokens of key phrase aspirants were stemmed to store them in a uniform way, but they were also appended by the POS-code of the derived form, so that the same root forms were distinguished if they came from tokens having different POS-codes, like there show"
S10-1040,D09-1027,0,0.0633098,"Missing"
S13-2092,W11-0705,0,0.113254,"Missing"
S13-2092,baccianella-etal-2010-sentiwordnet,0,0.0294005,"ng corpus. 550 We have chosen this method because we would like to automatically detect those words which are not relevant in the classification. Before the normalization step, the dictionary contained approximately 41, 000 words. After the above introduced steps we managed to reduce the size of the dictionary to 15, 000 words. 2.2 Features After normalizing Twitter messages, we searched for special features which characterize the polarity of the tweets. One such feature is the polarity of each word in a message. To determine the polarity of a word, we used the SentiWordNet sentiment lexicon (Baccianella et al., 2010). In this lexicon, a positive, negative and an objective real value belong to each word, which describes the polarity of the given word. We consider a word as positive if the related positive value is greater than 0.3, we consider it as negative if the related negative value is greater than 0.2 and we consider it as objective if the related objective value is greater than 0.8. The threshold of the objective value is high because most words are objective in this lexicon. After calculating the polarity of each word we created three new features for each tweet which are the number of positive, ne"
S13-2092,C10-2005,0,0.117606,"Missing"
S13-2092,P11-1016,0,0.0799697,"Missing"
S13-2092,W12-0607,0,0.0456508,"assify tweets into three classes (positive, negative or neutral) by their contents. To solve this problem we basically followed the supervised learning approach and proposed several domain (i.e. microblog) specific improvements including text preprocessing and feature engineering. Beyond the supervised setting we also introduce some early results employing a huge, automatically annotated tweet dataset. 1 2 Introduction In the past few years, the popularity of social media has increased. Many studies have been made in the area (Jansen et al., 2009; O’Connor et al., 2010; Bifet and Frank, 2010; Sang and Bos, 2012). People post messages on a variety of topics, for example products, political issues, etc. Thus a big amount of user generated data is created day-by-day. The manual processing of this data is impossible, therefore automatic procedures are needed. In this paper we introduce an approach which is able to assign sentiment labels to Twitter messages. More precisely, it classifies tweets into positive, negative or neutral polarity classes. The system participated in the SemEval-2013 Task 2: Sentiment Analysis in Twitter, Task–B Message Polarity Classification (Wilson et al., 2013). In our approach"
S13-2092,S13-2052,0,0.0343322,"Missing"
S14-2107,baccianella-etal-2010-sentiwordnet,0,0.0451238,"larity value for each word in a text and created three new features for the machine learning algorithm, which are the number of positive, negative and objective words in the given document. For this we used weighted feature vectors, and weighted each n-gram feature by its distance in tokens from the mention of the given aspect: 1 e 1 |i−j| n , where n is the length of the review and the values i, j are the positions of the actual word and the mentioned aspect. 2.2 Polarity Lexicon 2.3 To examine the polarity of the words comprising a review, we incorporated the SentiWordNet sentiment lexicon (Baccianella et al., 2010) into our feature set. In this resource, synsets – i.e. sets of word forms sharing some common meaning – are assigned positivity, negativity and objectivity scores. These scores can be interpreted as the probabilities of seeing some representatives of the synsets in a positive, negative and neutral meaning, respectively. However, it is not unequivocal to determine automatically which particular synset a given word belongs to with respect its context. Consider the word form great for instance, which might have multiple, fundamentally different sentiment connotations in different contexts, e.g."
S14-2107,C10-1011,0,0.0357434,"olarity of an opinion, is the polarity of words’ modifiers. We defined a feature template for tokens whose syntactic head is present in 611 ROOT S DT NN The food VBD ADJP was JJ DT . VP NP but VP NP . S CC S NN the service VBD ADJP JJ was awful great Figure 2: Constituency parse tree (Stanford parser). words, we counted the number of opinion indicator words in the subtree as additional features. We used the Stanford constituency parser (Klein and Manning, 2003) trained on the Penn Treebank for these experiments. our positive or negative lexicon. For dependency parsing we used the MATE parser (Bohnet, 2010) trained on the Penn Treebank (penn2malt conversion), an example can be seen on Figure 1. Besides using words that refer to a given aspect, we tried to identify subsentences which refers to the aspect mention. In a sentence we can express our opinions about more than one aspect, so it is important not to use subsentences containing opinions about other aspects. We developed a simple rule based method for selecting the appropriate subtree from the constituent parse of the sentence in question (see Figure 2). In this method, the root of this subtree is the leaf which contains the given aspect in"
S14-2107,P11-4018,0,0.034679,"tional Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 610 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 610–614, Dublin, Ireland, August 23-24, 2014. P ROOT CONJ COORD NMOD <ROOT> The DT food NN SBJ PRD was VBD NMOD great JJ but CC the DT SBJ service NN PRD was VBD awful JJ . . Figure 1: Dependency parse tree (MATE parser). synsets, e.g. good versus big. We count down the frequency of the phrases food is good and food is big in a huge set of in-domain documents (Ceylan and Mihalcea, 2011). Than we choose the meaning which has the highest probability, good in this case. This way we assign a polarity value for each word in a text and created three new features for the machine learning algorithm, which are the number of positive, negative and objective words in the given document. For this we used weighted feature vectors, and weighted each n-gram feature by its distance in tokens from the mention of the given aspect: 1 e 1 |i−j| n , where n is the length of the review and the values i, j are the positions of the actual word and the mentioned aspect. 2.2 Polarity Lexicon 2.3 To e"
S14-2107,P03-1054,0,0.00436744,"l path between them in the dependency tree. We gather adjectives in proximity less than 6. Another feature, which is not aspect specific but can indicate the polarity of an opinion, is the polarity of words’ modifiers. We defined a feature template for tokens whose syntactic head is present in 611 ROOT S DT NN The food VBD ADJP was JJ DT . VP NP but VP NP . S CC S NN the service VBD ADJP JJ was awful great Figure 2: Constituency parse tree (Stanford parser). words, we counted the number of opinion indicator words in the subtree as additional features. We used the Stanford constituency parser (Klein and Manning, 2003) trained on the Penn Treebank for these experiments. our positive or negative lexicon. For dependency parsing we used the MATE parser (Bohnet, 2010) trained on the Penn Treebank (penn2malt conversion), an example can be seen on Figure 1. Besides using words that refer to a given aspect, we tried to identify subsentences which refers to the aspect mention. In a sentence we can express our opinions about more than one aspect, so it is important not to use subsentences containing opinions about other aspects. We developed a simple rule based method for selecting the appropriate subtree from the c"
S14-2107,S14-2004,0,0.0387093,"challenge. We participated in the aspect term polarity subtask where the goal was to classify opinions which are related to a given aspect into positive, negative, neutral or conflict classes. We employed supervised machine learning techniques exploiting a rich feature set for target polarity detection, with a special emphasis on features that deal with the detection of aspect scopes. Our system achieved an accuracy of 0.752 and 0.669 for the restaurant and laptop domains, respectively. In this paper, we introduce our contributions to the SemEval-2014 Task 4 – Aspect Based Sentiment Analysis (Pontiki et al., 2014) challenge. We participated in the aspect term polarity subtask where the goal was to classify opinions related to a given aspect into positive, negative, neutral or conflict classes. To solve this problem, we employed supervised machine learning techniques exploiting a rich feature set. Our feature templates exploited both phrase structure and dependency parses. 1 Introduction 2 The booming volume of user-generated content and the consequent popularity growth of online review sites has led to vast amount of user reviews that are becoming increasingly difficult to grasp. There is desperate nee"
S14-2108,W09-1119,0,0.188299,"3-24, 2014. 2.2 UMLS Dictionary tation of text segments. Illinois NER contains several representation schemes such as BIO and BILOU - two of the most popular schemes. The BIO scheme is employed to train classifiers that identify Beginning, the Inside and the Outside of the text segment. The BILOU scheme is employed to train classifiers that identify the Beginning, the Inside and the Last tokens of multi-token chunks as well as Unit-length chunks. We used the BILOU scheme. The key intuition behind non-local features in NER has been that identical tokens should have identical label assignments. Ratinov and Roth (2009) consider three approaches proposed in the literature namely context aggregation, two-stage prediction aggregation and extended prediction history. The combination of these approaches is more stable and better than any approach taken alone. In our experiments we used the combination of context aggregation and two-stage prediction aggregation. Context aggregation is the following approach in Illinois NER: for each token instance xi we used the tokens in the window of size two around it as features: ci = xi−2 , xi−1 , xi , xi+1 , xi+2 . If the same token (t) appears in several locations in the t"
S14-2108,skeppstedt-etal-2012-rule,0,0.0314757,"of a NER system is to carry out contextsensitive tagging. Our system’s performance was 0.345 F-measure in terms of strict evaluation and 0.551 F-measure in terms of relaxed evaluation. 1 • The rhythm appears to be atrial fibrillation. ,,atrial fibrillation” is a mention of type disorders with CUI C0004238 • The left atrium is moderately dilated. ,,left atrium [...] dilated” is a mention of type disorders with CUI C0344720 • 53 year old man s/p fall from ladder. ,,fall from ladder” is a mention of type disorders with CUI C0337212 Many approaches have been published to solve these problems cf. (Skeppstedt et al., 2012; Pestian et al., 2007). Introduction Clinical notes and discharge summaries from the patient’s medical history contain a huge amount of useful information for medical researchers and also for hospitals. The automatic identification of these unstructured information is an important task for analysis of free-text electronic health records. Natural Language Processing (NLP) techniques provide a solution to process clinical documents and to help patients understand the contents of their clinical records (Tang et al., 2012; Lee et al., 2004). In this paper we introduce an approach which discovers"
S14-2108,W02-1001,0,0.148848,"to the UMLS semantic group “disorder”, which can be viewed as a subclass of named entities, so NER approach is effective for this assignment. For training, we used the Illinois Named Entity Recognition (Ratinov and Roth, 2009) system. By default, Illinois NER contains Wikipedia gazetters and categories, but in this task, we need one or more dictionary which contains disorders and other clinical text terminology. NER is typically viewed as a sequence labeling problem. The typical models include HMM (Rabiner, 1989), CRF (Lafferty et al., 2001) and sequential application of Perceptron or Winnow (Collins, 2002). Illinois NER has several inference algorithms: Viterbi, beamsearch, greedy leftto-right decoding. In our approach, we used beamsearch. The beamsize was 3. Initially, we used bigger beamsize, but our empirical studies showed that applying a small beamsize is more effective. Beside the decoding algorithm, an important question that has been studied extensively in the context of shallow parsing which was somewhat overlooked in the NER literature is the represen3 Experimental Results Our system was developed and trained only on the training set provided by the organizers and was evaluated on the"
S14-2108,W04-1215,0,0.0426814,"s have been published to solve these problems cf. (Skeppstedt et al., 2012; Pestian et al., 2007). Introduction Clinical notes and discharge summaries from the patient’s medical history contain a huge amount of useful information for medical researchers and also for hospitals. The automatic identification of these unstructured information is an important task for analysis of free-text electronic health records. Natural Language Processing (NLP) techniques provide a solution to process clinical documents and to help patients understand the contents of their clinical records (Tang et al., 2012; Lee et al., 2004). In this paper we introduce an approach which discovers mentions of disorders in the free-text of discharge summaries. The system participated in the SemEval-2014 Task 7: Analysis of Clinical Text, Task A. Task A aims at the identifying of mention concepts that belong to the UMLS (Bodenreider, 2004) semantic group ”disorders” and Task B is for mapping from each mention to 2 Approach After a text-normalization step we run a Named Entity Recogniser (NER) on the documents. This NER model was trained on the training set of the shared task. It also employs a dictionary gathered from UMLS through M"
S14-2108,W07-1013,0,0.0316632,"ry out contextsensitive tagging. Our system’s performance was 0.345 F-measure in terms of strict evaluation and 0.551 F-measure in terms of relaxed evaluation. 1 • The rhythm appears to be atrial fibrillation. ,,atrial fibrillation” is a mention of type disorders with CUI C0004238 • The left atrium is moderately dilated. ,,left atrium [...] dilated” is a mention of type disorders with CUI C0344720 • 53 year old man s/p fall from ladder. ,,fall from ladder” is a mention of type disorders with CUI C0337212 Many approaches have been published to solve these problems cf. (Skeppstedt et al., 2012; Pestian et al., 2007). Introduction Clinical notes and discharge summaries from the patient’s medical history contain a huge amount of useful information for medical researchers and also for hospitals. The automatic identification of these unstructured information is an important task for analysis of free-text electronic health records. Natural Language Processing (NLP) techniques provide a solution to process clinical documents and to help patients understand the contents of their clinical records (Tang et al., 2012; Lee et al., 2004). In this paper we introduce an approach which discovers mentions of disorders i"
szarvas-etal-2006-highly,W04-1903,1,\N,Missing
szarvas-etal-2006-highly,W04-1213,0,\N,Missing
szarvas-etal-2006-highly,W03-0419,0,\N,Missing
szarvas-etal-2006-highly,W02-2024,0,\N,Missing
vincze-etal-2014-szeged,R13-1099,1,\N,Missing
vincze-etal-2014-szeged,tron-etal-2006-morphdb,0,\N,Missing
W08-0606,E99-1043,0,0.0344432,"display different properties in the use of speculative or negated phrases. Take, for instance, the Conclusions section of scientific papers that tends to contain significantly more uncertain or negative findings than the description of Experimental settings and methods. Scientific abstracts are the main targets for various Text Mining applications like proteinprotein interaction mining due to their public accessibility (e.g. through PubMed). We therefore decided to include quite a lot of texts from the abstracts of scientific papers. This is why we included the abstracts of the Genia corpus (Collier et al., 1999). This decision was straightforward for two reasons. First, the Genia corpus contains syntax tree annotation, which allows a comparison between scope annotation and syntactic structure. Being syntactic in nature, scopes should align with the bracket structure of syntax trees, while scope resolution algorithms that exploit treebank data can be used as a theoretical upper bound for the evaluation of parsers for resolving negative/hedge scopes. The other reason was that scope annotation can mutually benefit from the rich annotations of the Genia corpus, such as term annotation (evaluation) and ev"
W08-0606,W04-3103,0,0.587853,"are also encoded within the system, thus it enables them to make a distinction between negated/uncertain concepts and factual information which is crucial in information retrieval. Elkin et al. (2005) use a list of negation words and a list of negation scope-ending words in order to identify negated statements and their scope. Although a fair amount of literature on uncertainty (or hedging) in scientific texts has been produced since the 1990s (e.g. Hyland, 1994), speculative language from a Natural Language Processing perspective has only been studied in the past few years. Previous studies (Light et al., 2004) showed that the detection of hedging can be solved effectively by looking for specific keywords which imply speculative content. Another possibility is to treat the problem as a classification task and train a statistical model to discriminate speculative and non-speculative 39 assertions. This approach requires the availability of labeled instances to train the models on. Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. Their system"
W08-0606,P07-1125,0,0.819191,"scientific texts has been produced since the 1990s (e.g. Hyland, 1994), speculative language from a Natural Language Processing perspective has only been studied in the past few years. Previous studies (Light et al., 2004) showed that the detection of hedging can be solved effectively by looking for specific keywords which imply speculative content. Another possibility is to treat the problem as a classification task and train a statistical model to discriminate speculative and non-speculative 39 assertions. This approach requires the availability of labeled instances to train the models on. Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data. Their system focuses on locating hedge cues in text and thus they do not determine the scopes (in other words in a text they define the scope to be a whole sentence). 1.2 Related resources Even though the problems of negation (mainly in the medical domain) and hedging (mainly in the scientific domain) have received much interest in the past few years, open access annotated resources for training, testing and comp"
W08-0606,W07-1013,0,0.0264665,"apers and biological paper abstracts (texts from Genia). Table 1 summarises the chief characteristics of the three subcorpora. The 3rd and 5th rows of the table show the ratio of sentences which contain negated or uncertain statements. The 4rd and 6th rows show the number of negation and hedge cue occurrences in the given corpus. A major part of the corpus consists of clinical free-texts. We chose to add medical texts to the corpus in order to facilitate research on negation/hedge detection in the clinical domain. The 43 radiology report corpus that was used for the clinical coding challenge (Pestian et al., 2007) organised by the Computational Medicine Center in Cincinatti, Ohio in 2007 was annotated for negations and uncertainty along with the scopes of each phenomenon. This part contains 1954 documents, each having a clinical history and an impression part, the latter being denser in negated and speculative parts. Another part of the corpus consists of full scientific articles. 5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for"
W09-1420,W09-1401,0,0.0609198,"ults on the BioNLP’09 Shared Task on Event Extraction evaluation datasets, and also on an external dataset for negation and speculation detection. 1 Introduction When we consider the sizes of publicly available biomedical scientific literature databases for researchers, valuable biological knowledge is accessible today in enormous amounts. The efficient processing of these large text collections is becoming an increasingly important issue in Natural Language Processing. For a survey on techniques used in biological Information Extraction, see (Tuncbag et al., 2009). The BioNLP’09 Shared Task (Kim et al., 2009) involved the recognition of bio-molecular events in scientific abstracts. In this paper we describe our systems submitted to the event detection and characterization (Task1) and the recognition of negations and speculations (Task3) subtasks. Our experiments can be regarded as case studies on i) how to define a framework for a hybrid human-machine biological information extraction system, ii) how the linguistic scopes of negation/speculation keywords relate to biological event annotations. ∗ On leave from RGAI of Hungarian Acad. Sci. 137 Event detection We formulated the event extraction task"
W09-1420,W08-0606,1,0.885413,"Missing"
W09-3601,E09-2004,0,0.010392,"la and Blockeel, 2000). They were expert systems with hand-crafted rules or induced rules used in a supervised manner and based on labeled corpora. The next generation of approaches on the other hand work in weakly-supervised settings (Etzioni et al., 2005; Sekine, 2006; Bellare et al., 2007). Here, the input is a seed list of target information pairs and the goal is to gather a set of pairs which are related to each other in the same manner as the seed pairs. These pairs may contain related entities (for example, country - capital city in (Etzioni et al., 2005) and celebrity partnerships in (Cheng et al., 2009)) or form an entity-attribute pair (like Nobel Prize recipient - year in (Feiyu Xu, 2007)) or may be concerned with retrieving all available attributes for entities (Bellare et al., 2007; Pas¸ca, 2009). These systems generally download web pages which contain the seed pairs then learn syntactical/semantical rules from the sentences of the pairs (they generally use the positive instances for one case as negative instances for another case). 3 The architecture of the system The general task of our system is to gather scientific social information from the homepages of researchers. In the use cas"
W09-3601,P07-1074,0,0.0343803,"Missing"
W09-3601,W06-1312,0,0.0189186,"nalysis as an application point of view and from a Web Content Mining point of view as well. 2.1 Researcher affiliation extraction Scientific social network analysis has become a growing area in recent years ((Yang et al., 2009; Robardet and Fleury, 2009; Said et al., 2008) just to name a few in recent studies). Its goal is to provide a deeper insight into a research field or into the personal connections among fields by analysing relationships among researchers. The existing studies use the co-authorship (e.g. (Newman, 2001; Barab´asi et al., 2002)) or/and the citation (Goodrum et al., 2001; Teufel et al., 2006) information – generally by constructing a graph with nodes representing researchers – as the basis for their investigations. Apart from publication-related relationships – which are presented in structured scholarly datasets –, useful scientific social information can 1 Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries, ACL-IJCNLP 2009, pages 1–9, c Suntec, Singapore, 7 August 2009. 2009 ACL and AFNLP According to these patterns, they can download a new set of web pages and parse them to acquire new pairs. These seed-based systems exploit the redun"
W09-3601,E09-1073,0,0.0588296,"Missing"
W09-3601,P06-2094,0,0.0321976,"differs from the popular techniques used nowadays. The aim of Web Content Mining (Liu and Chen-ChuanChang, 2004) is to extract useful information from the natural language-written parts of websites. The first attempts on Web Content Mining began with the Internet around 1998-’99 (Adelberg, 1998; Califf and Mooney, 1999; Freitag, 1998; Kosala and Blockeel, 2000). They were expert systems with hand-crafted rules or induced rules used in a supervised manner and based on labeled corpora. The next generation of approaches on the other hand work in weakly-supervised settings (Etzioni et al., 2005; Sekine, 2006; Bellare et al., 2007). Here, the input is a seed list of target information pairs and the goal is to gather a set of pairs which are related to each other in the same manner as the seed pairs. These pairs may contain related entities (for example, country - capital city in (Etzioni et al., 2005) and celebrity partnerships in (Cheng et al., 2009)) or form an entity-attribute pair (like Nobel Prize recipient - year in (Feiyu Xu, 2007)) or may be concerned with retrieving all available attributes for entities (Bellare et al., 2007; Pas¸ca, 2009). These systems generally download web pages which"
W10-3001,W07-1011,0,0.139993,"hose not backed up by facts (e.g. references) should be avoided (see 3.2 for details). Thus, the community-edited encyclopedia, Wikipedia became one of the subjects of the shared task as well. The term hedging was originally introduced by Lakoff (1972). However, hedge detection has received considerable interest just recently in the NLP community. Light et al. (2004) used a handcrafted list of hedge cues to identify speculative sentences in MEDLINE abstracts and several biomedical NLP applications incorporate rules for identifying the certainty of extracted information (Friedman et al., 1994; Chapman et al., 2007; Aramaki et al., 2009; Conway et al., 2009). The most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora. Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. Kilicoglu and Bergler (2008) proposed a linguistically motiva"
W10-3001,W09-1318,0,0.0289259,") should be avoided (see 3.2 for details). Thus, the community-edited encyclopedia, Wikipedia became one of the subjects of the shared task as well. The term hedging was originally introduced by Lakoff (1972). However, hedge detection has received considerable interest just recently in the NLP community. Light et al. (2004) used a handcrafted list of hedge cues to identify speculative sentences in MEDLINE abstracts and several biomedical NLP applications incorporate rules for identifying the certainty of extracted information (Friedman et al., 1994; Chapman et al., 2007; Aramaki et al., 2009; Conway et al., 2009). The most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora. Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. Kilicoglu and Bergler (2008) proposed a linguistically motivated approach based on syntactic information"
W10-3001,W10-3011,0,0.0922122,"Missing"
W10-3001,P09-2044,0,0.611839,"on exploit machine learning models that utilize manually labeled corpora. Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. Kilicoglu and Bergler (2008) proposed a linguistically motivated approach based on syntactic information to semi-automatically refine a list of hedge cues. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags and syntactic patterns. The BioScope corpus (Vincze et al., 2008) is manually annotated with negation and speculation cues and their linguistic scope. It consists of clinical free-texts, biological texts from full papers and scientific abstracts. Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a su¨ ur pervised sequence labeling approach while Ozg¨ and Radev (2009) developed a rule-based system that exploits syntactic"
W10-3001,W04-3103,0,0.868901,"es. Uncertainty detection is also important, e.g. in encyclopedias, where the goal is to collect reliable world knowledge about real-world concepts and topics. For example, Wikipedia explicitly declares that statements reflecting author opinions or those not backed up by facts (e.g. references) should be avoided (see 3.2 for details). Thus, the community-edited encyclopedia, Wikipedia became one of the subjects of the shared task as well. The term hedging was originally introduced by Lakoff (1972). However, hedge detection has received considerable interest just recently in the NLP community. Light et al. (2004) used a handcrafted list of hedge cues to identify speculative sentences in MEDLINE abstracts and several biomedical NLP applications incorporate rules for identifying the certainty of extracted information (Friedman et al., 1994; Chapman et al., 2007; Aramaki et al., 2009; Conway et al., 2009). The most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora. Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-aut"
W10-3001,W10-3005,0,0.0502528,"arge pool of in-domain texts without time-wasting pre-processing tasks (cleaning and sentence splitting). Tables 1, 2 and 3 contain the results of the submitted systems for Task1 and Task2. The last name of the first author of the system description paper (published in these proceedings) is used here as a system name3 . The last column contains the type of submission. The system of Kilicoglu and Bergler (2010) is the only open submission. They adapted their system introduced in Kilicoglu and Bergler (2008) to the datasets of the shared task. Regarding cross submissions, Zhao et al. (2010) and Ji et al. (2010) managed to achieve a noticeable improvement by exploiting cross-domain 5.4 Data Format Both training and evaluation data were released in a custom XML format. For each task, a separate XML file was made available containing the 3 6 ¨ ur did not publish a description of her system. Ozg¨ Name Georgescul Ji Chen Morante Zhang Zheng T¨ackstr¨om Mamani S´anchez Tang Kilicoglu Tjong Kim Sang Clausen ¨ ur Ozg¨ Zhou Li Prabhakaran Ji P/R/F 72.0 / 51.7 / 60.2 62.7 / 55.3 / 58.7 68.0 / 49.7 / 57.4 80.6 / 44.5 / 57.3 76.6 / 44.4 / 56.2 76.3 / 43.6 / 55.5 78.3 / 42.8 / 55.4 68.3 / 46.2 / 55.1 82.3 / 41.4"
W10-3001,P07-1125,0,0.698493,"ll. The term hedging was originally introduced by Lakoff (1972). However, hedge detection has received considerable interest just recently in the NLP community. Light et al. (2004) used a handcrafted list of hedge cues to identify speculative sentences in MEDLINE abstracts and several biomedical NLP applications incorporate rules for identifying the certainty of extracted information (Friedman et al., 1994; Chapman et al., 2007; Aramaki et al., 2009; Conway et al., 2009). The most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora. Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. Kilicoglu and Bergler (2008) proposed a linguistically motivated approach based on syntactic information to semi-automatically refine a list of hedge cues. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing un"
W10-3001,W09-1304,0,0.813023,"d features. Kilicoglu and Bergler (2008) proposed a linguistically motivated approach based on syntactic information to semi-automatically refine a list of hedge cues. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags and syntactic patterns. The BioScope corpus (Vincze et al., 2008) is manually annotated with negation and speculation cues and their linguistic scope. It consists of clinical free-texts, biological texts from full papers and scientific abstracts. Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a su¨ ur pervised sequence labeling approach while Ozg¨ and Radev (2009) developed a rule-based system that exploits syntactic patterns. Several related works have also been published within the framework of The BioNLP’09 Shared Task on Event Extraction (Kim et al., 2009), where a separate subtask was dedicated to predicting whether the recognized biological events are under negation or speculation, based on the GENIA event corpus annotations (Kilicoglu and Bergler, 2009; Van Landeghem et al., 2009). 3 3.1 Hedges in Biological Scientific Articles In the bi"
W10-3001,W10-3006,0,0.538411,"Missing"
W10-3001,W08-0607,0,0.827806,"cted information (Friedman et al., 1994; Chapman et al., 2007; Aramaki et al., 2009; Conway et al., 2009). The most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora. Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. Kilicoglu and Bergler (2008) proposed a linguistically motivated approach based on syntactic information to semi-automatically refine a list of hedge cues. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags and syntactic patterns. The BioScope corpus (Vincze et al., 2008) is manually annotated with negation and speculation cues and their linguistic scope. It consists of clinical free-texts, biological texts from full papers and scientific abstracts. Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a"
W10-3001,D09-1145,0,0.737415,"Missing"
W10-3001,W09-1418,0,0.0379406,"rom full papers and scientific abstracts. Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a su¨ ur pervised sequence labeling approach while Ozg¨ and Radev (2009) developed a rule-based system that exploits syntactic patterns. Several related works have also been published within the framework of The BioNLP’09 Shared Task on Event Extraction (Kim et al., 2009), where a separate subtask was dedicated to predicting whether the recognized biological events are under negation or speculation, based on the GENIA event corpus annotations (Kilicoglu and Bergler, 2009; Van Landeghem et al., 2009). 3 3.1 Hedges in Biological Scientific Articles In the biomedical domain, sentences were manually annotated for both hedge cues and their linguistic scope. Hedging is typically expressed by using specific linguistic devices (which we refer to as cues in this article) that modify the meaning or reflect the author’s attitude towards the content of the text. Typical hedge cues fall into the following categories: • auxiliaries: may, might, can, would, should, could, etc. • verbs of hedging or verbs with speculative content: suggest, question, presume, suspect, indicat"
W10-3001,P08-1033,1,0.708595,"o identify speculative sentences in MEDLINE abstracts and several biomedical NLP applications incorporate rules for identifying the certainty of extracted information (Friedman et al., 1994; Chapman et al., 2007; Aramaki et al., 2009; Conway et al., 2009). The most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora. Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features. Kilicoglu and Bergler (2008) proposed a linguistically motivated approach based on syntactic information to semi-automatically refine a list of hedge cues. Ganter and Strube (2009) proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags and syntactic patterns. The BioScope corpus (Vincze et al., 2008) is manually annotated with negation and speculation cues and their linguistic scope. It consists of c"
W10-3001,W10-3010,0,0.200503,"tral database) and 1 million paragraphs from Wikipedia were offered to the participants as well. These datasets did not contain any manual annotation for uncertainty, but their usage permitted data sampling from a large pool of in-domain texts without time-wasting pre-processing tasks (cleaning and sentence splitting). Tables 1, 2 and 3 contain the results of the submitted systems for Task1 and Task2. The last name of the first author of the system description paper (published in these proceedings) is used here as a system name3 . The last column contains the type of submission. The system of Kilicoglu and Bergler (2010) is the only open submission. They adapted their system introduced in Kilicoglu and Bergler (2008) to the datasets of the shared task. Regarding cross submissions, Zhao et al. (2010) and Ji et al. (2010) managed to achieve a noticeable improvement by exploiting cross-domain 5.4 Data Format Both training and evaluation data were released in a custom XML format. For each task, a separate XML file was made available containing the 3 6 ¨ ur did not publish a description of her system. Ozg¨ Name Georgescul Ji Chen Morante Zhang Zheng T¨ackstr¨om Mamani S´anchez Tang Kilicoglu Tjong Kim Sang Clausen"
W10-3001,W10-3002,0,0.549474,"Missing"
W10-3001,W09-1401,0,0.0810938,"c patterns. The BioScope corpus (Vincze et al., 2008) is manually annotated with negation and speculation cues and their linguistic scope. It consists of clinical free-texts, biological texts from full papers and scientific abstracts. Using BioScope for training and evaluation, Morante and Daelemans (2009) developed a scope detector following a su¨ ur pervised sequence labeling approach while Ozg¨ and Radev (2009) developed a rule-based system that exploits syntactic patterns. Several related works have also been published within the framework of The BioNLP’09 Shared Task on Event Extraction (Kim et al., 2009), where a separate subtask was dedicated to predicting whether the recognized biological events are under negation or speculation, based on the GENIA event corpus annotations (Kilicoglu and Bergler, 2009; Van Landeghem et al., 2009). 3 3.1 Hedges in Biological Scientific Articles In the biomedical domain, sentences were manually annotated for both hedge cues and their linguistic scope. Hedging is typically expressed by using specific linguistic devices (which we refer to as cues in this article) that modify the meaning or reflect the author’s attitude towards the content of the text. Typical h"
W10-3001,W09-1419,0,0.0654244,"Missing"
W10-3001,W08-0606,1,0.625107,"Missing"
W10-3001,W10-3013,0,0.0292459,"at biological sentences have relatively simple patterns. Thus the context of the cue words (token classification-based approaches used features derived from a window of the token in question, thus, they exploited the relationship among the tokens and their contexts) can be utilized while Wikipedia weasels have a diverse nature. Another observation is that the top systems in both Task1B and Task1W are the ones which did not derive features from syntactic parsing. Each Task2 system was built upon a Task1 system, i.e. they attempted to recognize the scopes for the predicted cue phrases (however, Zhang et al. (2010) have argued that the objective functions of Task1 and Task2 cue detection problems are different because of sentences containing multiple hedge spans). Most systems regarded multiple cues in a sentence to be independent from each other and formed different classification instances from them. There were three systems which incorporated information about other hedge cues (e.g. their distance) of the sentence into the feature space and Zhang et al. (2010) constructed a cascade system which utilized directly the predicted scopes (it processes cue phrases from left to right) during predicting othe"
W10-3001,W10-3014,0,0.00980276,"data sampling from a large pool of in-domain texts without time-wasting pre-processing tasks (cleaning and sentence splitting). Tables 1, 2 and 3 contain the results of the submitted systems for Task1 and Task2. The last name of the first author of the system description paper (published in these proceedings) is used here as a system name3 . The last column contains the type of submission. The system of Kilicoglu and Bergler (2010) is the only open submission. They adapted their system introduced in Kilicoglu and Bergler (2008) to the datasets of the shared task. Regarding cross submissions, Zhao et al. (2010) and Ji et al. (2010) managed to achieve a noticeable improvement by exploiting cross-domain 5.4 Data Format Both training and evaluation data were released in a custom XML format. For each task, a separate XML file was made available containing the 3 6 ¨ ur did not publish a description of her system. Ozg¨ Name Georgescul Ji Chen Morante Zhang Zheng T¨ackstr¨om Mamani S´anchez Tang Kilicoglu Tjong Kim Sang Clausen ¨ ur Ozg¨ Zhou Li Prabhakaran Ji P/R/F 72.0 / 51.7 / 60.2 62.7 / 55.3 / 58.7 68.0 / 49.7 / 57.4 80.6 / 44.5 / 57.3 76.6 / 44.4 / 56.2 76.3 / 43.6 / 55.5 78.3 / 42.8 / 55.4 68.3 / 46"
W10-3001,W10-3015,0,0.0866111,"Missing"
W10-3001,W09-1324,0,\N,Missing
W11-2924,D10-1125,0,0.0414044,"Missing"
W11-2924,C10-1011,1,0.837107,"tituent labels (noGF) and on the conflation of these labels and grammatical functions (GF). We have to mention that our F-values are not comparable to the official results of PaGe – which was our original goal – because the evaluation metric there was a special imExperiments We evaluate our approach on the Tiger corpora of the Parsing German Shared Task (PaGe) (K¨ubler, 2008). Its training, development, and test datasets consist of 20894, 2611 and 2611 sentences respectively. We decided to use these corpora to be able to compare our results with other results. We used the dependency parser of Bohnet (2010) to generate the parses for the feature extraction. We selected the parser since it had top scores for German in the CoNLL Shared Task 2009. The parser is a second order dependency parser that models the interaction between siblings as well as grandchildren. The parser was after the Shared Task enhanced by a Hash Kernel, which leads to significantly higher accuracy. We generated the dependency structures by 10-fold cross-validation training of the training corpus. The model for the annotation of the test set and development set was trained on the entire training corpus. We evaluated the depend"
W11-2924,W08-2102,0,0.0262582,"discriminative dependency parsers – is also manifest which we will address as future work. Some generative parsing approaches exploited the difference between phrase-structure and dependency parsers. For instance, Klein and Manning (2003) introduced an approach where the objective function is the product of the probabilities of a generative phrase-structure and a dependency parsers. Model 1 of Collins (2003) is based on the dependencies between pairs of head words. On the other hand, the related work on this topic for discriminative parsing is sparse, we are only aware of the following works. Carreras et al. (2008) and Koo et al. (2010) introduced frameworks for joint learning of phrase-structure and dependency 209 Proceedings of the 12th International Conference on Parsing Technologies, pages 209–214, c 2011 Association for Computational Linguistics October 5-7, 2011, Dublin City University. have the corresponding arcs in the dependency tree. goal is to investigate the extension of the standard feature set of these models by features extracted from the automatic dependency parse of the sentence in question. 3 ConstRel features are similar to POSRel but use the constituent labels rather than the POS tag"
W11-2924,W09-0424,0,0.0189035,"es. Our prior experiments found the forest pruning threshold to be optimal at the order of 10−2 which resulted in packed forests with average node number of 108. The oracle scores were 87.1 and 91.4 for the 100-best lists and packed forests, respectively. At the second stage, we filtered out rare features (which occurred in less than 5 sentences). The new dependency parse-based feature set consists of 9240 and 5359 features before and after filtering. We employed the ranking MaxEnt implementation of the MALLET package (McCallum, 2002) and the average perceptron training of the Joshua package (Li et al., 2009). The update mechanism of the latter one was extended by using the F-score of the candidate full parse against the oracle parse as a loss function (see MIRA (Crammer and Singer, 2003) for the motivation). We used the state-of-the-art feature set of the German phrase-structure parse reranker of Versley and Rehbein (2009) as a baseline feature set. This feature set is rich and consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (like the clustering of unknown words according to their context of"
W11-2924,P05-1022,0,0.919132,"hes have been proved to be effective for phrase-structure and dependency parsers in the last decade. Here, we aim to exploit the divergence in these approaches and show the utility of features extracted from the automatic dependency parses of sentences for a discriminative phrase-structure parser. Our experiments show a significant improvement over the state-of-the-art German discriminative constituent parser. 2 1 Introduction Feature-Rich Parse Reranking The most successful supervised phrase-structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consists of two stages. At the first stage they apply a PCFG to extract possible parses. The full set of possible parses cannot be iterated through in practice, and is usually pruned as a consequence. The n-best list parsers keep just the 50-100 best parses according to the PCFG. Other methods remove nodes and hyperedges whose posterior probability is under a predefined threshold from the forest (chart). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set). These methods employ a large feature set (usua"
W11-2924,H05-1066,0,0.0766452,"plicated in the forest-based approaches. The conditional random field methods usually use only local features (Miyao and Tsujii, 2002; Finkel et al., 2008). Huang (2008) introduced a beam-search and average perceptron-based procedure for incorporating them, however his empirical results show only minor improvement from incorporating non-local features. In this study, we experiment with n-best list reranking and a packed-forest based model as well along with local features exclusively. Our Both phrase-structure and dependency parsers have developed a lot in the last decade (Nivre et al., 2004; McDonald et al., 2005; Charniak and Johnson, 2005; Huang, 2008). Different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used (and a growing gap between researcher communities). In this work, we exploit this divergence and show the added value of features extracted from automatic dependency parses of sentences for a discriminative phrase-structure parser. We report results on German phrase-structure parsing, however, we note that the reverse direction of our approach – i.e. defining features from automatic phrase-structure parses for di"
W11-2924,J03-4003,0,0.0488488,"se-structure parser. We report results on German phrase-structure parsing, however, we note that the reverse direction of our approach – i.e. defining features from automatic phrase-structure parses for discriminative dependency parsers – is also manifest which we will address as future work. Some generative parsing approaches exploited the difference between phrase-structure and dependency parsers. For instance, Klein and Manning (2003) introduced an approach where the objective function is the product of the probabilities of a generative phrase-structure and a dependency parsers. Model 1 of Collins (2003) is based on the dependencies between pairs of head words. On the other hand, the related work on this topic for discriminative parsing is sparse, we are only aware of the following works. Carreras et al. (2008) and Koo et al. (2010) introduced frameworks for joint learning of phrase-structure and dependency 209 Proceedings of the 12th International Conference on Parsing Technologies, pages 209–214, c 2011 Association for Computational Linguistics October 5-7, 2011, Dublin City University. have the corresponding arcs in the dependency tree. goal is to investigate the extension of the standard"
W11-2924,P08-1109,0,0.0209595,"d from the forest (chart). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set). These methods employ a large feature set (usually a few millions features) (Collins, 2000; Charniak and Johnson, 2005). The n-best list approaches can straightforwardly employ local and non-local features as well because they decide at the sentence-level (Charniak and Johnson, 2005). Involving non-local features is more complicated in the forest-based approaches. The conditional random field methods usually use only local features (Miyao and Tsujii, 2002; Finkel et al., 2008). Huang (2008) introduced a beam-search and average perceptron-based procedure for incorporating them, however his empirical results show only minor improvement from incorporating non-local features. In this study, we experiment with n-best list reranking and a packed-forest based model as well along with local features exclusively. Our Both phrase-structure and dependency parsers have developed a lot in the last decade (Nivre et al., 2004; McDonald et al., 2005; Charniak and Johnson, 2005; Huang, 2008). Different approaches have been proved to be effective for these two parsing tasks which ha"
W11-2924,W04-2407,0,0.163726,"features is more complicated in the forest-based approaches. The conditional random field methods usually use only local features (Miyao and Tsujii, 2002; Finkel et al., 2008). Huang (2008) introduced a beam-search and average perceptron-based procedure for incorporating them, however his empirical results show only minor improvement from incorporating non-local features. In this study, we experiment with n-best list reranking and a packed-forest based model as well along with local features exclusively. Our Both phrase-structure and dependency parsers have developed a lot in the last decade (Nivre et al., 2004; McDonald et al., 2005; Charniak and Johnson, 2005; Huang, 2008). Different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used (and a growing gap between researcher communities). In this work, we exploit this divergence and show the added value of features extracted from automatic dependency parses of sentences for a discriminative phrase-structure parser. We report results on German phrase-structure parsing, however, we note that the reverse direction of our approach – i.e. defining features from automatic phrase-"
W11-2924,W08-1007,0,0.0231942,"dels the interaction between siblings as well as grandchildren. The parser was after the Shared Task enhanced by a Hash Kernel, which leads to significantly higher accuracy. We generated the dependency structures by 10-fold cross-validation training of the training corpus. The model for the annotation of the test set and development set was trained on the entire training corpus. We evaluated the dependency parses themselves in line with PaGe. Table 1 shows the labeled (LAS) and unlabeled attachment scores (UAS) of the dependency parser and compares it with the Malt parser (Nivre et al., 2004; Hall and Nivre, 2008), which was the only and therefore best dependency parser that participated in the PaGe’s dependency parsing track. Bohnet’s parser reaches higher labeled and unlabeled scores. The last row shows the parsing accuracy with predicted Part-ofSpeech. We used the parses with predicted pos tags for our reranking experiments. 211 Table 3: Results achieved by the enriched feature set. Develop. Test noGF GF noGF GF Rafferty’08 77.40 – – – Versley’09 78.43 67.90 – – Baseline 78.48 66.29 79.21 66.63 RR 80.51 68.55 80.95 68.67 Dep 80.35 68.48 80.56 68.39 RR+Dep 81.34 69.73 81.49 69.44 AvgPer 81.41 69.67 8"
W11-2924,W08-1006,0,0.0260334,"0 – – Baseline 78.48 66.29 79.21 66.63 RR 80.51 68.55 80.95 68.67 Dep 80.35 68.48 80.56 68.39 RR+Dep 81.34 69.73 81.49 69.44 AvgPer 81.41 69.67 81.68 69.42 Table 2: Results achieved by dependency feature-based reranking. noGF GF Baseline 78.48 66.34 outArc 79.19 67.21 POSRel 79.99 68.13 ConstRel 79.67 67.72 All 80.20 68.32 All+Case 80.35 68.48 plementation for calculating F-value (which differs from evalb for example in handling punctuation marks) and it used gold-standard POS tags in the input (which we thought to be unrealistic). On the other hand, our results are comparable with results of Rafferty and Manning (2008) and Versley and Rehbein (2009). Table 2 shows the results achieved by the MaxEnt 100-best list reranker using one out of the three feature templates alone and their union (All) on the development set. All+Case refers to the enriched feature set incorporating case information for POS tag and grammatical functions for labels. Baseline here refers to the top parse of Bitpar (the first stage parser). We note that the inside probability estimation of Bitpar for an edge is always in our feature set. Each of the three feature templates achieved significant improvements over a strong baseline – note"
W11-2924,P08-1067,0,0.536996,"ffective for phrase-structure and dependency parsers in the last decade. Here, we aim to exploit the divergence in these approaches and show the utility of features extracted from the automatic dependency parses of sentences for a discriminative phrase-structure parser. Our experiments show a significant improvement over the state-of-the-art German discriminative constituent parser. 2 1 Introduction Feature-Rich Parse Reranking The most successful supervised phrase-structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; Huang, 2008). These approaches consists of two stages. At the first stage they apply a PCFG to extract possible parses. The full set of possible parses cannot be iterated through in practice, and is usually pruned as a consequence. The n-best list parsers keep just the 50-100 best parses according to the PCFG. Other methods remove nodes and hyperedges whose posterior probability is under a predefined threshold from the forest (chart). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set). These methods employ a large feature set (usually a few mill"
W11-2924,C04-1024,1,0.870116,"ndency tree lays outside the span of words in question. We use the absolute count and the ratio of outArcs among the words of the span. The more arcs go out, the further away is the dependency subtree over the words of the constituent from a dominating subtree. Hence, these features try to capture the ”phraseness” of the span of words in question based on the dependency tree. For E1 we have outArc=2 and outArcRatio=2/4 as the parent of Inseln and von lay outside the constituent. For E2 we have outArc=1 and outArcRatio=1/5. 4 Two-Stage Parsing of German As a first-stage parser, we used BitPar (Schmid, 2004), a fast unlexicalized PCFG parser based on a first pass where non-probabilistic bottom-up parsing and top-down pruning is efficiently carried out by storing the chart in bit vectors. Bitpar constructs the probabilistic forest only after top-down pruning, i.e. after computing the posterior probability of each hyperedge given the input sentence. The forest is pruned by deleting hyperedges whose posterior probability is below some threshold. We used a treebank grammar enriched with case information, lexicalization of selected prepositions, conjunctions, and punctuation symbols, coarse parent cat"
W11-2924,W09-3820,0,0.676679,"ch occurred in less than 5 sentences). The new dependency parse-based feature set consists of 9240 and 5359 features before and after filtering. We employed the ranking MaxEnt implementation of the MALLET package (McCallum, 2002) and the average perceptron training of the Joshua package (Li et al., 2009). The update mechanism of the latter one was extended by using the F-score of the candidate full parse against the oracle parse as a loss function (see MIRA (Crammer and Singer, 2003) for the motivation). We used the state-of-the-art feature set of the German phrase-structure parse reranker of Versley and Rehbein (2009) as a baseline feature set. This feature set is rich and consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (like the clustering of unknown words according to their context of occurrences and PP attachment statistics gathered from the automatic POS tagged DE-WaC corpus, a 1.7G words sample of the German-language WWW). This feature set consists of 1.7 and 0.2 million of features before and after filtering and enables the direct comparison of our results with state-of-theart discriminative resu"
W11-2924,C10-2148,0,0.0425065,"POSRel but use the constituent labels rather than the POS tags of the heads. Thus, once again we do not have any positive feature for E1 , but for E2 we extract: VP-NP, VP-NP-OBJA, VP-PP, VP-PP-PP. We also investigated the role of case and grammatical functions and extended the POSRel and ConstRel feature sets by adding this information to the labels. For instance besides VVFIN-NN-OBJA and VP-NP-OBJA from our example E2 we also used VVFIN-NN-Acc-OBJA and VP-NP-OA-OBJA. Note that the value of outArc is 1 iff the word span in question has a dominating dependency subtree in the automatic parse. Wang and Zong (2010) prune hyperedges with outArc6= 1 thus this feature can be regarded as a generalization of their approach. Dependency Parse-Based Features for Phrase-Structure Parsing Given the automatic (1-best) dependency parse of the sentence in question, we defined three feature templates for representing hyperedges (i.e. a CFG rule applied over a certain span of words). We illustrate them on two hyperedges E1 = (NP die Inseln (PP von Rußland)) and E2 = (VP fordern (NP die Inseln) (PP von Rußland)). Let’s assume that the corresponding dependency subtree consists of the followDET ing arcs: ROOT→fordern, In"
W11-2924,W08-1008,0,\N,Missing
W12-4503,W11-1905,1,0.784051,"Missing"
W12-4503,W05-0406,0,0.03202,"the higher threshold improved in all coreference metrics, and gave an increase of about 0.5 in the official CoNLL score. The feature set used by the classifiers describes the (in-sentence) context of the pronoun. It consists of the uni-, bi-, and trigrams of word forms and POS tags in a window of ±5; the position inside the sen50 tence; the preceding and following verb and adjective; the distance to the following named entity; the genre of the document; and whether the mention is between quotes. For English, we additionally extended this general feature set by re-implementing the features of Boyd et al. (2005). We investigated similar classifiers for Arabic and Chinese as well. We selected targets based on the frequency statistics of tokens being referential and non-referential on the training set and used the general feature set described above. However, these classifiers did not contribute to the more complex coreference system, hence the non-referential classifiers are included only in the English system. 3 Training Instance generation To generate training instances for the pair-wise classifier, we employed the approach described by Soon et al. (2001). In this approach, for every extracted anaph"
W12-4503,H05-1083,0,0.0175744,"spaces, while still remaining reasonably fast. We exploited this by building a large number of parametrized feature templates, that allowed us to experiment easily and quickly with different feature sets. Additionally, since our classifiers are linear, we also evaluated a large number of feature conjunctions, which proved to be crucial to gain reasonable performance. Due to space restrictions we can not list the complete set of features used in this paper but mention briefly what type of features we used. Most of them are taken from previous work on coreference resolution (Soon et al., 2001; Luo and Zitouni, 2005; Sapena et al., 2010; Bj¨orkelund and Nugues, 2011). For a complete list of features the reader can refer to the download of the resolver, which includes the feature sets and parameters used for every language. One set of feature templates we use is based on surface forms and part-of-speech tags of the first and last, previous and following, and head tokens of the spans that make up mentions. Another set of templates are based on the syntax trees, including both subcategorization frames as well as paths in the syntax tree. To extract head words of mentions, we used the head percolation rules"
W12-4503,P10-1142,0,0.41448,"Shared Task.1 We present a novel decoding algorithm for coreference resolution which is combined with a standard pair-wise coreference resolver in a stacking approach. The stacked decoders are evaluated on the three languages of the Shared Task. We obtain an official overall score of 58.25 which is the second highest in the Shared Task. 1 Introduction In this paper we present our contribution to the CoNLL 2012 Shared Task (Pradhan et al., 2012). We follow the standard architecture where mentions are extracted in the first step, then they are clustered using a pair-wise classifier (see e.g., (Ng, 2010)). For English, the set of extracted mentions is filtered by removing non-referential occurrences of certain pronouns. Our coreference resolver at its core relies on a pair-wise classifier. To overcome the problems associated with the isolated pair-wise decisions, we devised a novel decoding algorithm which compares a mention to partially built clusters. For our Shared Task contribution we combined this algorithm with conventional pair-wise decoding algorithms in a stacking approach. In the Shared Task evaluation, our system received an overall official score of 58.25, which is the second high"
W12-4503,W12-4501,0,0.0905394,"as Institute for Natural Language Processing University of Stuttgart {anders,farkas}@ims.uni-stuttgart.de Abstract 2 This paper describes our contribution to the CoNLL 2012 Shared Task.1 We present a novel decoding algorithm for coreference resolution which is combined with a standard pair-wise coreference resolver in a stacking approach. The stacked decoders are evaluated on the three languages of the Shared Task. We obtain an official overall score of 58.25 which is the second highest in the Shared Task. 1 Introduction In this paper we present our contribution to the CoNLL 2012 Shared Task (Pradhan et al., 2012). We follow the standard architecture where mentions are extracted in the first step, then they are clustered using a pair-wise classifier (see e.g., (Ng, 2010)). For English, the set of extracted mentions is filtered by removing non-referential occurrences of certain pronouns. Our coreference resolver at its core relies on a pair-wise classifier. To overcome the problems associated with the isolated pair-wise decisions, we devised a novel decoding algorithm which compares a mention to partially built clusters. For our Shared Task contribution we combined this algorithm with conventional pair-"
W12-4503,C10-2125,0,0.0811315,"Missing"
W12-4503,J01-4004,0,0.971685,"ature set by re-implementing the features of Boyd et al. (2005). We investigated similar classifiers for Arabic and Chinese as well. We selected targets based on the frequency statistics of tokens being referential and non-referential on the training set and used the general feature set described above. However, these classifiers did not contribute to the more complex coreference system, hence the non-referential classifiers are included only in the English system. 3 Training Instance generation To generate training instances for the pair-wise classifier, we employed the approach described by Soon et al. (2001). In this approach, for every extracted anaphoric mention mj , we create a positive training instance with its closest preceding antecedent mi : P = {(mi , mj )}. Negative examples are constructed by considering all the pairs of mj and the (non-coreferent) mentions mk between mi and mj : N = {(mk , mj )|i < k < j}. We extract the training examples on the version of the training set that uses predicted information, and restrict the mentions considered to the ones extracted by our mention extraction module. Using these training examples, we train a linear logistic regression classifier using the"
W12-4503,J11-1005,0,0.00598325,"plete list of features the reader can refer to the download of the resolver, which includes the feature sets and parameters used for every language. One set of feature templates we use is based on surface forms and part-of-speech tags of the first and last, previous and following, and head tokens of the spans that make up mentions. Another set of templates are based on the syntax trees, including both subcategorization frames as well as paths in the syntax tree. To extract head words of mentions, we used the head percolation rules of Choi and Palmer (2010) for Arabic and English, and those of Zhang and Clark (2011) for Chinese. While Chinese and English display no or relatively small variety in morphological inflection, Arabic has a very complex morphology. This means that Arabic suffers from greater data sparseness with respect to lexical features. This is exaggerated by the fact that the Arabic training set is considerably smaller than the Chinese and English ones. Hence, we used the lemmas and unvocalised Buckwalter forms that were provided in the Arabic dataset. We also tried to extract number and gender information based on affixes of Arabic surface forms. These features did, however, not help much"
W13-2213,D11-1033,0,0.0919379,"Missing"
W13-2213,P05-1066,0,0.0443099,"a are also automatically tagged and phrases with words and POS tags on both sides are extracted. The POSbased OSM model is only used in the German-toEnglish and English-to-German experiments.4 So far, we only used coarse POS tags without gender and case information. 4 Constituent Parse Reordering Our German-to-English system used constituent parses for pre-ordering of the input. We parsed all of the parallel German to English data available, and the tuning, test and blind-test sets. We then applied reordering rules to these parses. We used the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up t"
W13-2213,P11-1105,1,0.934423,"rd Farkas4 1 2 University of Edinburgh – dnadir@inf.ed.ac.uk Ludwig Maximilian University Munich – schmid,fraser@cis.uni-muenchen.de 3 Qatar Computing Research Institute – hsajjad@qf.org.qa 4 University of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our proces"
W13-2213,N13-1001,1,0.917412,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,P13-2071,1,0.919884,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,W13-2212,1,0.928384,"ty of Szeged – rfarkas@inf.u-szeged.hu Abstract reordering operations and learns a Markov model over a sequence of operations. Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks. Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system. The earlier decoder (Durrani et al., 2011) was based on minimal units. But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors (Durrani et al., 2013a) than MTU-based decoding. We have therefore shifted to phrase-based search on top of the OSM model. This paper is organized as follows. Section 2 gives a short description of the model and search as used in the OSM decoder. In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments. Section 4 describes our processing of the German and English data for German-English and English-German experiments. In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and"
W13-2213,J13-1005,1,0.871716,"Missing"
W13-2213,W09-0420,1,0.89655,"both sides are extracted. The POSbased OSM model is only used in the German-toEnglish and English-to-German experiments.4 So far, we only used coarse POS tags without gender and case information. 4 Constituent Parse Reordering Our German-to-English system used constituent parses for pre-ordering of the input. We parsed all of the parallel German to English data available, and the tuning, test and blind-test sets. We then applied reordering rules to these parses. We used the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged"
W13-2213,W10-1734,1,0.864372,"Missing"
W13-2213,schmid-etal-2004-smor,1,0.739052,"Missing"
W13-2213,W11-2123,0,0.045987,"source-side cepts and source-word deletion. However, it doesn’t provide a mechanism to deal with unaligned and discontinuous target cepts. These are handled through a 3-step process3 in which we modify the alignments to remove discontinuous and unaligned target MTUs. Please see Durrani et al. (2011) for details. After modifying the alignments, we convert each bilingual sentence pair and its alignments into a sequence of operations as described above and learn an OSM model. To this end, a Kneser-Ney (Kneser and Ney, 1995) smoothed 9-gram model is trained with SRILM (Stolcke, 2002) while KenLM (Heafield, 2011) is used at runtime. Figure 1: Bilingual Sentence with Alignments sentence pair and its alignments as a unique sequence of operations. An operation either jointly generates source and target words, or it performs reordering by inserting gaps or jumping to gaps. We then learn a Markov model over a sequence of operations o1 , o2 , . . . , oJ that encapsulate MTUs and reordering information as: posm (o1 , ..., oJ ) = J Y j=1 p(oj |oj−n+1 , ..., oj−1 ) 2.3 We use additional features for our model and employ the standard log-linear approach (Och and Ney, 2004) to combine and tune them. We search fo"
W13-2213,I08-2089,0,0.179256,"estimation of the translation models is: de–en ≈ 4.5M and ru–en ≈ 2M parallel sentences. We were able to use all the available data for cs-to-en (≈ 15.6M sentences). However, sub-sampled data was used for en-to-cs (≈ 3M sentences), en-to-fr (≈ 7.8M sentences) and es–en (≈ 3M sentences). Monolingual Language Model: We used all the available training data (including LDC Gigaword data) for the estimation of monolingual language models: en ≈ 287.3M sentences, fr ≈ 91M, es ≈ 65.7M, cs ≈ 43.4M and ru ≈ 21.7M sentences. All data except for ru-en and en-ru was true-cased. We followed the approach of Schwenk and Koehn (2008) by training language models from each sub-corpus separately and then linearly interpolated them using SRILM with weights optimized on the held-out dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large dev-set5 in order to obtain more stable weights (Koehn and Haddow, 2012). Decoder Settings: For each extracted input phrase only 15-best translation options were used during decoding.6 We used a hard reordering limit 5 For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used the first half for tu"
W13-2213,W13-2230,1,0.864769,"Missing"
W13-2213,W12-3139,0,0.0378184,"odel: We used all the available training data (including LDC Gigaword data) for the estimation of monolingual language models: en ≈ 287.3M sentences, fr ≈ 91M, es ≈ 65.7M, cs ≈ 43.4M and ru ≈ 21.7M sentences. All data except for ru-en and en-ru was true-cased. We followed the approach of Schwenk and Koehn (2008) by training language models from each sub-corpus separately and then linearly interpolated them using SRILM with weights optimized on the held-out dev-set. We concatenated the news-test sets from four years (2008-2011) to obtain a large dev-set5 in order to obtain more stable weights (Koehn and Haddow, 2012). Decoder Settings: For each extracted input phrase only 15-best translation options were used during decoding.6 We used a hard reordering limit 5 For Russian-English and English-Russian language pairs, we divided the tuning-set news-test 2012 into two halves and used the first half for tuning and second for test. 6 We could not experiment with higher n-best translation options due to a bug that was not fixed in time and hindered us from scaling. Sub-sampling Because of scalability problems we were not able to use the entire data made available for build125 of 16 words which disallows a jump b"
W13-2213,E03-1076,0,0.439555,"Missing"
W13-2213,koen-2004-pharaoh,0,0.0671416,"ering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data (training, tuning and test data). To produce the parses, we started with the generative BitPar parser trained on the Tiger treebank with optimizations of the grammar, as described by (Fraser et al., 2013). We then performed self-training using the high quality Europarl corpus - we parsed it, and then retrained the parser on the output. Decoder The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that translates all the words in the foreign sentence. During the hypothesis extension each extracted phrase is translated into a sequence of operations. The reordering opera4 This work is ongoing and we will present detailed experiments in the future. 124 ing the translation model in some cases. We used modified Moore-Lewis sampli"
W13-2213,J06-4004,0,0.0984652,"Missing"
W13-2213,J04-4002,0,0.0848361,"d with SRILM (Stolcke, 2002) while KenLM (Heafield, 2011) is used at runtime. Figure 1: Bilingual Sentence with Alignments sentence pair and its alignments as a unique sequence of operations. An operation either jointly generates source and target words, or it performs reordering by inserting gaps or jumping to gaps. We then learn a Markov model over a sequence of operations o1 , o2 , . . . , oJ that encapsulate MTUs and reordering information as: posm (o1 , ..., oJ ) = J Y j=1 p(oj |oj−n+1 , ..., oj−1 ) 2.3 We use additional features for our model and employ the standard log-linear approach (Och and Ney, 2004) to combine and tune them. We search for a target string E which maximizes a linear combination of feature functions: By coupling reordering with lexical generation, each (translation or reordering) decision depends on n − 1 previous (translation and reordering) decisions spanning across phrasal boundaries. The reordering decisions therefore influence lexical selection and vice versa. A heterogeneous mixture of translation and reordering operations enables us to memorize reordering patterns and lexicalized triggers unlike the classic N-gram model where translation and reordering are modeled se"
W13-2213,P11-1044,1,0.696753,"ing. We do not have such a list and making one is a cumbersome process. Instead, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ in both direction and symmetrize the alignments using the grow-diag-final-and heuristic. We extract all word pairs which occur as 1to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied in a post-processing step to transliterate OOVs. Please refer to Sajjad et al. (2013) for further details on our transliteration work. 6 7 Experiments Parallel Corpus: The amount of bitext used for the estimation of the translation models is: de–en ≈ 4.5M and ru–en ≈ 2M parallel sentences. We were able to u"
W13-2213,P12-1049,1,0.737125,"on system fails to translate out-of-vocabulary words (OOVs) as they are unknown to the training data. Most of the OOVs are named entities and simply passing them to the output often produces correct translations if source and target language use the same script. If the scripts are different transliterating them to the target language script could solve this problem. However, building a transliteration system requires a list of transliteration pairs for training. We do not have such a list and making one is a cumbersome process. Instead, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ in both direction and symmetrize the alignments using the grow-diag-final-and heuristic. We extract all word pairs which occur as 1to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and"
W13-2213,D11-1017,0,\N,Missing
W13-2213,E12-1074,1,\N,Missing
W13-2213,C04-1024,1,\N,Missing
W13-2213,W13-2228,1,\N,Missing
W13-2230,W10-1749,0,0.0262519,"highest usefulness scores for the reordering task. Then we trained a new grammar on the concatenation of the Tiger corpus and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009) and the word order indicated by the automatic word alignment between the German and English sentences in Europarl. We used the Kendall’s Tau Distance as the similarity metric of two word orderings (as suggested by Birch and Osborne (2010)). Following this, we performed linguisticallyinformed compound splitting, using the system of Fritzinger and Fraser (2010), which disambiguates competing analyses from the high-recall Stuttgart Morphological Analyzer SMOR (Schmid et al., 2004) using corpus statistics. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES"
W13-2230,P12-1050,0,0.0143602,"tuent parses for pre-reordering. For DE-EN we also deal with word formation issues such as compound splitting. We did not perform inflectional normalization or generation for German due to time constraints, instead focusing 236 system our efforts on these issues for French and Russian as previously described. German to English German has a wider diversity of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Tre"
W13-2230,P05-1022,0,0.0609343,".36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the different clausal orders in German is difficult. For our English to German systems, we solved this by parsing the English and applying the system of Gojun and Fraser (2012) to reorder English into the correct German clausal order (depending on the clause type which is detected using the English parse, see (Gojun and Fraser, 2012) for further details). We primarily used the Charniak-Johnson generative parser (Charniak and Johnson, 2005) to parse the English Europarl data and the test data. However, due to time constraints we additionally used Berkeley parses of about 400K Europarl sentences and the other English parallel training data. We also left a small amount of the English parallel training data unparsed, which means that it was not reordered. For tune, test and blindtest (WMT2013), we used the Charniak-Johnson generative parser. Experiments and results We used all available training data for constrained systems; results for the WMT-2013 set are given in table 8. For the contrastive BitPar results, we reparsed WMT-2013."
W13-2230,N12-1047,0,0.0466778,"Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 1 2 3 4 5 System Baseline Simplified French* Removal of empty lines Conversion of HTML special characters like &quot; to the corresponding characters Unification of words that were written both with an œ or with an oe to only one spelling Punctuation normalization and tokenization Putting together clitics and apostrophes like l ’ or d ’ to l’ and d’ la / l’ / les → le un / une → un Infl. form → lemma e. g. au → a` le Redu"
W13-2230,P05-1066,0,0.216656,"Missing"
W13-2230,P11-1105,1,0.789613,"eneral translation model, this method also allows the generation of inflected word forms which do not occur in the training data. 2 Experimental setup The translation experiments in this paper are carried out with either a standard phrase-based Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sofia, Bulgaria, August 8-9, 2013 2013 Association for Computational Linguistics 1 2 3 4 5 System Baseline Simplified French* Removal of empty lines Conversion of HTML special characters like &quot; to the corresponding characters Unification of words that we"
W13-2230,N13-1001,1,0.816849,"lly complex target language, we describe a two-step translation system built on non-inflected word stems with a post-processing component for predicting morphological features and the generation of inflected forms. In addition to the advantage of a more general translation model, this method also allows the generation of inflected word forms which do not occur in the training data. 2 Experimental setup The translation experiments in this paper are carried out with either a standard phrase-based Moses system (DE-EN, EN-DE, EN-FR and FR-EN) or with an operation sequence model (RU-EN, DEEN), cf. Durrani et al. (2013b) for more details. An operation sequence model (OSM) is a stateof-the-art SMT-system that learns translation and reordering patterns by representing a sentence pair and its word alignment as a unique sequence of operations (see e.g. Durrani et al. (2011), Durrani et al. (2013a) for more details). For the Moses systems we used the old train-model perl scripts rather than the EMS, so we did not perform Good-Turing smoothing; parameter tuning was carried out with batch-mira (Cherry and Foster, 2012). 232 Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232–239, c Sof"
W13-2230,2012.eamt-1.42,1,0.834142,"bmitted systems for DE-EN and EN-DE which used constituent parses for pre-reordering. For DE-EN we also deal with word formation issues such as compound splitting. We did not perform inflectional normalization or generation for German due to time constraints, instead focusing 236 system our efforts on these issues for French and Russian as previously described. German to English German has a wider diversity of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Frase"
W13-2230,E12-1068,1,0.847569,"ng all necessary morphological features for the translation output, which are then used to generate fully inflected forms. This two-step setup decreases the complexity of the translation task by removing languagespecific features from the translation model. Furthermore, generating inflected forms based on word stems and morphological features allows to gener233 ate forms which do not occur in the parallel training data – this is not possible in a standard SMT setup. The idea of separating the translation into two steps to deal with complex morphology was introduced by Toutanova et al. (2008). Fraser et al. (2012) applied this method to the language pair English-German with an additional special focus on word formation issues such as the splitting and merging of portmanteau prepositions and compounds. The presented inflection prediction systems focuses on nominal inflection; verbal inflection is not addressed. Morphological analysis and resources The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological features, we use an ext"
W13-2230,J13-1005,1,0.858728,"Missing"
W13-2230,W09-0420,1,0.87823,"of clausal orderings than English, all of which need to be mapped to the English SVO order. This is a difficult problem to solve during inference, as shown for hierarchical SMT by Fabienne Braune and Fraser (2012) and for phrase-based SMT by Bisazza and Federico (2012). We syntactically parsed all of the source side sentences of the parallel German to English data available, and the tuning, test and blindtest sets. We then applied reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Treebank (Brants et al., 2002) along with utilizing the Europarl corpus as unlabeled data. At the training of Bitpar, we followed the targeted self-training approach (Katz-Brown et al., 2011) as follows. We parsed the whole Europarl corpus using a grammar trained on the Tiger corpus and extracted the 100best parse trees for each sentence. We sel"
W13-2230,W10-1734,1,0.788681,"us and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009) and the word order indicated by the automatic word alignment between the German and English sentences in Europarl. We used the Kendall’s Tau Distance as the similarity metric of two word orderings (as suggested by Birch and Osborne (2010)). Following this, we performed linguisticallyinformed compound splitting, using the system of Fritzinger and Fraser (2010), which disambiguates competing analyses from the high-recall Stuttgart Morphological Analyzer SMOR (Schmid et al., 2004) using corpus statistics. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the diffe"
W13-2230,E12-1074,1,0.864449,"s. We also split German portmanteaus like zum → zu dem (meaning to the). DE-EN (OSM) DE-EN (OSM) BitPar not self-trained DE-EN (Moses) DE-EN (Moses) BitPar not self-trained EN-DE (Moses) BLEU (ci) 27.60 27.48 BLEU (cs) 26.12 25.99 system name 27.14 25.65 26.82 25.36 MES-Szegedreorder-split not submitted 19.68 18.97 MES-reorder MES not submitted Table 8: Results on WMT-2013 (blindtest) English to German The task of mapping English SVO order to the different clausal orders in German is difficult. For our English to German systems, we solved this by parsing the English and applying the system of Gojun and Fraser (2012) to reorder English into the correct German clausal order (depending on the clause type which is detected using the English parse, see (Gojun and Fraser, 2012) for further details). We primarily used the Charniak-Johnson generative parser (Charniak and Johnson, 2005) to parse the English Europarl data and the test data. However, due to time constraints we additionally used Berkeley parses of about 400K Europarl sentences and the other English parallel training data. We also left a small amount of the English parallel training data unparsed, which means that it was not reordered. For tune, test"
W13-2230,D11-1017,0,0.051958,"d reordering rules to these parses. We use the rules for reordering German constituent parses of Collins et al. (2005) together with the additional rules described by Fraser (2009). These are applied as a preprocess to all German data. For parsing the German sentences, we used the generative phrase-structure parser BitPar with optimizations of the grammar, as described by Fraser et al. (2013). The parser was trained on the Tiger Treebank (Brants et al., 2002) along with utilizing the Europarl corpus as unlabeled data. At the training of Bitpar, we followed the targeted self-training approach (Katz-Brown et al., 2011) as follows. We parsed the whole Europarl corpus using a grammar trained on the Tiger corpus and extracted the 100best parse trees for each sentence. We selected the parse tree among the 100 candidates which got the highest usefulness scores for the reordering task. Then we trained a new grammar on the concatenation of the Tiger corpus and the automatic parses from Europarl. The usefulness score estimates the value of a parse tree for the reordering task. We calculated this score as the similarity between the word order achieved by applying the parse tree-based reordering rules of Fraser (2009"
W13-2230,P10-1052,0,0.0314476,"Missing"
W13-2230,C12-1121,0,0.0602483,"Missing"
W13-2230,P11-1044,1,0.749892,"problem by stemming the OOVs based on a list of suffixes ( , , , , , ) and transliterating the stemmed forms. Voice Aspect Type Degree Type Formation Table 6: Rules for simplifying the morphological complexity for RU. training and extracts transliteration pairs that can be used for the training of the transliteration system. The procedure of mining transliteration pairs and transliterating OOVs is described as follows: We word-align the parallel corpus using GIZA++ and symmetrize the alignments using the grow-diagfinal-and heuristic. We extract all word pairs which occur as 1-to-1 alignments (Sajjad et al., 2011) and later refer to them as a list of word pairs. We train the unsupervised transliteration mining system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied as a post-processing step to transliterate OOVs. The morphological reduction of Russian (cf. section 5) does not process most of the OOVs as they are also unknown to the POS tagger. So OOVs that we get are in their original form. When translitExperiments and results We trained the systems separately on GIZA++"
W13-2230,P12-1049,1,0.744729,", particles, interjections and abbreviations) have no morphological attributes. The list of the original and the reduced attributes is given in Table 6. Transliteration mining to handle OOVs The machine translation system fails to translate out-ofvocabulary words (OOVs) as they are unknown to the training data. Most of the OOVs are named entities and transliterating them to the target language script could solve this problem. The transliteration system requires a list of transliteration pairs for training. As we do not have such a list, we use the unsupervised transliteration mining system of Sajjad et al. (2012) that takes a list of word pairs for Part of Speech Noun Pronoun Verb Adjective Preposition Conjunction Attributes RFTagger Type Gender Number Case Reduced attributes Type Gender Number Case nom,gen,dat,acc,instr,prep gen,notgen Animate Case 2 Person Gender Number Case Person Gender Number Case nom,gen,dat,acc,instr,prep nom,notnom Syntactic type Animated Type VForm Tense Person Number Gender Voice Definiteness Aspect Case Type Degree Gender Number Case Definiteness Type Formation Case Type Formation SYS GIZA++ TA-GIZA++ Original corpus WMT-2012 WMT-2013 32.51 25.5 33.40 25.9* SYS GIZA++ TA-GI"
W13-2230,W13-2228,1,0.735928,"ng system on the list of word pairs and extract transliteration pairs. We use these mined pairs to build a transliteration system using the Moses toolkit. The transliteration system is applied as a post-processing step to transliterate OOVs. The morphological reduction of Russian (cf. section 5) does not process most of the OOVs as they are also unknown to the POS tagger. So OOVs that we get are in their original form. When translitExperiments and results We trained the systems separately on GIZA++ and transliteration augmented-GIZA++ (TA-GIZA++) to compare their results; for more details see Sajjad et al. (2013). All systems are tuned using PROv1 (Nakov et al., 2012). The translation output is postprocessed to transliterate OOVs. Table 7 summarizes the results of RU-EN translation systems trained on the original corpus and on the morph-reduced corpus. Using TA-GIZA++ alignment gives the best results for both WMT2012 and WMT-2013, leading to an improvement of 0.4 BLEU points. The system built on the morph-reduced data leads to decreased BLEU results. However, the percentage of OOVs is reduced for both test sets when using the morph-reduced data set compared to the original data. An analysis of the out"
W13-2230,C08-1098,1,0.776757,"reas adjectives in English are not inflected at all. This causes data sparsity in coverage of French inflected forms. We try to overcome this problem by simplifying French inflected forms in a pre-processing step in order to adapt the French input better to the English output. Processing of the training and test data The pre-processing of the French input consists of two steps: (1) normalizing not well-formed data (cf. table 1) and (2) morphological simplification. In the second step, the normalized training data is annotated with Part-of-Speech tags (PoS-tags) and word lemmas using RFTagger (Schmid and Laws, 2008) which was trained on the French treebank (Abeill´e et al., 2003). French forms are then simplified according to the rules given in table 2. Data and experiments We trained a French to English Moses system on the preprocessed and BLEU (ci) 31.02 30.83 Table 3: Results of the French to English system (WMT-2012). The marked system (*) corresponds to the system submitted for manual evaluation. (cs: case-sensitive, ci: case-insensitive) Table 1: Text normalization for FR-EN. Definite determiners Indefinite determiners Adjectives Portmanteaus Verb participles inflected for gender and number ending"
W13-2230,schmid-etal-2004-smor,1,0.771053,"Missing"
W13-2230,I08-2089,0,0.135299,"h an œ or with an oe to only one spelling Punctuation normalization and tokenization Putting together clitics and apostrophes like l ’ or d ’ to l’ and d’ la / l’ / les → le un / une → un Infl. form → lemma e. g. au → a` le Reduced to non-inflected verb participle form ending in e´ d’ → de, qu’ → que, n’ → ne, ... Table 2: Rules for morphological simplification. The development data consists of the concatenated news-data sets from the years 2008-2011. Unless otherwise stated, we use all constrained data (parallel and monolingual). For the target-side language models, we follow the approach of Schwenk and Koehn (2008) and train a separate language model for each corpus and then interpolate them using weights optimized on development data. 3 French to English French has a much richer morphology than English; for example, adjectives in French are inflected with respect to gender and number whereas adjectives in English are not inflected at all. This causes data sparsity in coverage of French inflected forms. We try to overcome this problem by simplifying French inflected forms in a pre-processing step in order to adapt the French input better to the English output. Processing of the training and test data Th"
W13-2230,P08-1059,0,0.0269016,"step consists of predicting all necessary morphological features for the translation output, which are then used to generate fully inflected forms. This two-step setup decreases the complexity of the translation task by removing languagespecific features from the translation model. Furthermore, generating inflected forms based on word stems and morphological features allows to gener233 ate forms which do not occur in the parallel training data – this is not possible in a standard SMT setup. The idea of separating the translation into two steps to deal with complex morphology was introduced by Toutanova et al. (2008). Fraser et al. (2012) applied this method to the language pair English-German with an additional special focus on word formation issues such as the splitting and merging of portmanteau prepositions and compounds. The presented inflection prediction systems focuses on nominal inflection; verbal inflection is not addressed. Morphological analysis and resources The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological f"
W13-2230,W13-2213,1,\N,Missing
W13-3608,W02-1503,0,0.0851341,"Missing"
W13-3608,W13-1703,0,0.0939194,"egories. We focused on the two “nominal” error categories: We introduce here a participating system of the CoNLL-2013 Shared Task “Grammatical Error Correction”. We focused on the noun number and article error categories and constructed a supervised learning system for solving these tasks. We carried out feature engineering and we found that (among others) the f-structure of an LFG parser can provide very informative features for the machine learning system. 1 Introduction The CoNLL-2013 Shared Task aimed at identifying and correcting grammatical errors in the NUCLE learner corpus of English (Dahlmeier et al., 2013). This task has become popular in the natural language processing (NLP) community in the last few years (Dale and Kilgariff, 2010), which manifested in the organization of shared tasks. In 2011, the task Helping Our Own (HOO 2011) was held (Dale and Kilgariff, 2011), which targeted the promotion of NLP tools and techniques in improving the textual quality of papers written by non-native speakers of English within the field of NLP. The next year, HOO 2012 (Dale et al., 2012) specifically focused on the correction of determiner and preposition errors in a collection of essays written by candidat"
W13-3608,W10-4236,0,0.0258517,"k “Grammatical Error Correction”. We focused on the noun number and article error categories and constructed a supervised learning system for solving these tasks. We carried out feature engineering and we found that (among others) the f-structure of an LFG parser can provide very informative features for the machine learning system. 1 Introduction The CoNLL-2013 Shared Task aimed at identifying and correcting grammatical errors in the NUCLE learner corpus of English (Dahlmeier et al., 2013). This task has become popular in the natural language processing (NLP) community in the last few years (Dale and Kilgariff, 2010), which manifested in the organization of shared tasks. In 2011, the task Helping Our Own (HOO 2011) was held (Dale and Kilgariff, 2011), which targeted the promotion of NLP tools and techniques in improving the textual quality of papers written by non-native speakers of English within the field of NLP. The next year, HOO 2012 (Dale et al., 2012) specifically focused on the correction of determiner and preposition errors in a collection of essays written by candidates sitting for the Cambridge ESOL First Certificate in English (FCE) examination. In 2013, the CoNLL-2013 Shared Task has continue"
W13-3608,W11-2838,0,0.0446482,"Missing"
W13-3608,W12-2006,0,0.0626592,"oNLL-2013 Shared Task aimed at identifying and correcting grammatical errors in the NUCLE learner corpus of English (Dahlmeier et al., 2013). This task has become popular in the natural language processing (NLP) community in the last few years (Dale and Kilgariff, 2010), which manifested in the organization of shared tasks. In 2011, the task Helping Our Own (HOO 2011) was held (Dale and Kilgariff, 2011), which targeted the promotion of NLP tools and techniques in improving the textual quality of papers written by non-native speakers of English within the field of NLP. The next year, HOO 2012 (Dale et al., 2012) specifically focused on the correction of determiner and preposition errors in a collection of essays written by candidates sitting for the Cambridge ESOL First Certificate in English (FCE) examination. In 2013, the CoNLL-2013 Shared Task has continued this direction of research. The CoNLL-2013 Shared Task is based on the NUCLE corpus, which consists of about 1,400 1.1 Article and Determiner Errors This error type involved all kinds of errors which were related to determiners and articles (ArtOrDet). It required multiple correction strategies. On the one hand, superfluous articles or determin"
W13-3608,C08-1022,0,0.0640972,"Missing"
W13-3608,P02-1035,0,0.0477098,"grammatical errors in the sentence result in unusual constituency subtree patterns that could manifest in minimal governing phrases having too long spans for instance. The relative position of the candidate position inside the smallest dominating noun and prepositional phrases was also incorporated as a feature since this information might carry some information for noun errors. (ii) an Optimality Theory-style constraint mechanism for filtering and ranking competing analyses (Frank et al., 2001), and (iii) a stochastic disambiguation component which is based on a log-linear probability model (Riezler et al., 2002) and works on the packed representations. Although we use a deep, hand-crafted LFG grammar for processing the data, our approach is substantially different from other grammar-based approaches to CALL. For instance, Fortmann and Forst (2004) supplement a German LFG developed for newspaper text with so-called malrules that accept marked or ungrammatical input of some predefined types. In our work, we apply an LFG parser developed for standard texts to get a rich feature representation that can be exploited by a classifier. While malrules would certainly be useful for finding other error types, s"
W13-3608,W08-1705,0,\N,Missing
W13-4916,C10-1011,0,0.0619426,"igure 1 shows a schematic of the process. As a preprocessing step, we reduced the dependency label set for the Hungarian training data. The Hungarian dependency data set encodes ellipses through composite edge labels which leads to a proliferation of edge labels (more than 400). Since many of these labels are extremely rare and thus hard to learn for the parsers, we reduced the set of edge labels during the conversion. Specifically, we retained the 50 most frequent labels, while reducing the composite labels to their base label. For producing the initial n-best lists, we use the mate parser6 (Bohnet, 2010) and a variant of the EasyFirst parser (Goldberg and Elhadad, 2010), which we here call best-first parser. The mate parser is a state-of-the-art graph-based dependency parser that uses second-order features. 6 https://code.google.com/p/mate-tools The parser works in two steps. First, it uses dynamic programming to find the optimal projective tree using the Carreras (2007) decoder. It then applies the non-projective approximation algorithm proposed by McDonald and Pereira (2006) in order to produce non-projective parse trees. The nonprojective approximation algorithm is a greedy hill climbing a"
W13-4916,D07-1101,0,0.0310944,"uced the set of edge labels during the conversion. Specifically, we retained the 50 most frequent labels, while reducing the composite labels to their base label. For producing the initial n-best lists, we use the mate parser6 (Bohnet, 2010) and a variant of the EasyFirst parser (Goldberg and Elhadad, 2010), which we here call best-first parser. The mate parser is a state-of-the-art graph-based dependency parser that uses second-order features. 6 https://code.google.com/p/mate-tools The parser works in two steps. First, it uses dynamic programming to find the optimal projective tree using the Carreras (2007) decoder. It then applies the non-projective approximation algorithm proposed by McDonald and Pereira (2006) in order to produce non-projective parse trees. The nonprojective approximation algorithm is a greedy hill climbing algorithm that starts from the optimal projective parse and iteratively tries to reattach all tokens, one at a time, everywhere in the sentence as long as the tree property holds. It halts when the increase in the score of the tree according to the parsing model is below a certain threshold. n-best lists are obtained by applying the nonprojective approximation algorithm in"
W13-4916,P05-1022,0,0.335382,"Missing"
W13-4916,W99-1005,0,0.068476,"ctionaries for each language. For this, we analyzed the word forms provided in the data sets with language-specific morphological analyzers except for Hebrew and German where we just extracted the morphological information from the lattice files provided by the organizers. For the other languages we used the following tools: Arabic: AraMorph a reimplementation of Buckwalter (2002), Basque: Apertium (Forcada et al., 2011), French: an IMS internal tool,3 Hungarian: Magyarlanc (Zsibrita et al., 2013), Korean: HanNanum (Park et al., 2010), Polish: Morfeusz (Woli´nski, 2006), and Swedish: Granska (Domeij et al., 2000). The created dictionaries were shared with the other Shared Task participants. We used these dictionaries as additional features for MarMoT. For some languages we also integrated the predicted tags provided by the organizers into the feature model. These stacked models gave improvements for Swedish, Polish and Basque (cf. Table 1 for accuracies). For the full setting the training data was annotated using 5-fold jackknifing. In the 5k setting, we additionally added all sentences not present in the parser training data to the training data sets of the tagger. This is similar to the predicted 5k"
W13-4916,N10-1115,0,0.0701629,"cessing step, we reduced the dependency label set for the Hungarian training data. The Hungarian dependency data set encodes ellipses through composite edge labels which leads to a proliferation of edge labels (more than 400). Since many of these labels are extremely rare and thus hard to learn for the parsers, we reduced the set of edge labels during the conversion. Specifically, we retained the 50 most frequent labels, while reducing the composite labels to their base label. For producing the initial n-best lists, we use the mate parser6 (Bohnet, 2010) and a variant of the EasyFirst parser (Goldberg and Elhadad, 2010), which we here call best-first parser. The mate parser is a state-of-the-art graph-based dependency parser that uses second-order features. 6 https://code.google.com/p/mate-tools The parser works in two steps. First, it uses dynamic programming to find the optimal projective tree using the Carreras (2007) decoder. It then applies the non-projective approximation algorithm proposed by McDonald and Pereira (2006) in order to produce non-projective parse trees. The nonprojective approximation algorithm is a greedy hill climbing algorithm that starts from the optimal projective parse and iterativ"
W13-4916,C10-1045,0,0.0712278,"Missing"
W13-4916,P09-2056,0,0.0685142,"Missing"
W13-4916,D07-1102,0,0.107545,"aining data than the 5k was also used for prediction. Table 3 presents a comparison between our graphbased baseline parser using the preprocessing explained in this section (denoted mate) and the preprocessing provided by the organizers (denoted mate’). Our preprocessing yields improvements for all languages but Swedish. The worse performance for Swedish is due to the fact that the predictions provided by the organizers were produced by models that were trained on a much larger data 3 The French morphology was written by Zhenxia Zhou, Max Kisselew and Helmut Schmid. It is an extension of Zhou (2007) and implemented in SFST (Schmid, 2005). Berkeley Replaced Product Reranked Arabic 78.24 78.70 80.30 81.24 Basque 69.17 84.33 86.21 87.35 French 79.74 79.68 81.42 82.49 German 81.74 82.74 84.56 85.01 Hebrew Hungarian Korean Polish Swedish 87.83 83.90 70.97 84.11 74.50 89.55 89.08 82.84 87.12 75.52 90.49 89.80 84.15 88.32 79.25 90.49 91.07 84.63 88.40 79.53 Table 2: PARSEVAL scores on the development sets. set. The comparison with other parsers demonstrates that for some languages (e.g., Hebrew or Korean) the improvements due to better preprocessing can be greater than the improvements due to a"
W13-4916,P07-1050,0,0.021567,"gical features, we mark whether it is the same case or not, denoted case. Function label uniqueness – on each training set we extracted a list of function labels that generally occur at most once as the dependent of a node, e.g., subjects or objects. Features are then extracted from all nodes that have one or more dependents of each label aimed at capturing mistakes such as double subjects on a verb. This template is denoted FL. In addition to the features mentioned above, we experimented with a variety of feature templates, including features drawn from previous work on dependency reranking (Hall, 2007), e.g., lexical and POS-based features over edges, “subcategorization” frames (i.e., the concatenation of POS-tags that are headed by a certain node in the tree), etc, although these features did not seem to help. For German we created feature templates based on the constraints used in the constraint-based parser by Seeker and Kuhn (2013). This includes, e.g., violations in case or number agreement between heads and dependents, as well as more complex features that consider labels on entire verb complexes. None of these features yielded any clear improvements though. We also experimented with"
W13-4916,P07-1077,0,0.0135969,"; BMeProd denotes the sum of B and M in e-space, i.e., eB+M ; reBMT, reBT, reMT denote the normalized product of the corresponding scores, where scores are normalized in a softmax fashion such that all features take on values in the interval (0, 1). Projectivity features (Hall et al., 2007) – the number of non-projective edges in a tree, denoted np. Whether a tree is ill-nested, denoted I. Since illnested trees are extremely rare in the treebanks, this helps the ranker filter out unlikely candidates from the n-best lists. For a definition and further discussion of ill-nestedness, we refer to (Havelka, 2007). Constituent features – from the constituent track we also have constituent trees of all sentences which can be used for feature extraction. Specifically, for every head-dependent pair, we extract the path in the constituent tree between the nodes, denoted ptbp. 140 Case agreement – on head-dependent pairs that both have a case value assigned among their morphological features, we mark whether it is the same case or not, denoted case. Function label uniqueness – on each training set we extracted a list of function labels that generally occur at most once as the dependent of a node, e.g., subj"
W13-4916,D10-1004,0,0.0378661,"e best-first parser is allowed to choose as head any node of an adjacent substructure instead of only the root, which increases complexity to O(n2 ), but accounts for a big part of possible non-projective structures. We additionally implemented a swapoperation (Nivre, 2009; Tratz and Hovy, 2011) to account for the more complex structures. The bestfirst parser relies on a beam-search strategy7 to pur7 Due to the nature of the decoder, the parser can produce 139 sue multiple derivations, which we also use to produce the n-best output. In the scoring step, we additionally apply the turboparser8 (Martins et al., 2010), which is based on linear programming relaxations.9 We changed all three parsers such that they would return a score for a given tree. We use this to extract scores from each parser for all trees in the n-best lists. It is important to have a score from every parser for every tree, as previously observed by Zhang et al. (2009) in the context of constituency reranking. 4.1 Ranking Table 3 shows the performance of the individual parsers measured on the development sets. It also displays the oracle scores over the different n-best lists, i.e., the maximal possible score over an n-best list if th"
W13-4916,E06-1011,0,0.0174354,"t labels, while reducing the composite labels to their base label. For producing the initial n-best lists, we use the mate parser6 (Bohnet, 2010) and a variant of the EasyFirst parser (Goldberg and Elhadad, 2010), which we here call best-first parser. The mate parser is a state-of-the-art graph-based dependency parser that uses second-order features. 6 https://code.google.com/p/mate-tools The parser works in two steps. First, it uses dynamic programming to find the optimal projective tree using the Carreras (2007) decoder. It then applies the non-projective approximation algorithm proposed by McDonald and Pereira (2006) in order to produce non-projective parse trees. The nonprojective approximation algorithm is a greedy hill climbing algorithm that starts from the optimal projective parse and iteratively tries to reattach all tokens, one at a time, everywhere in the sentence as long as the tree property holds. It halts when the increase in the score of the tree according to the parsing model is below a certain threshold. n-best lists are obtained by applying the nonprojective approximation algorithm in a non-greedy manner, exploring multiple possibilities. All trees are collected in a list, and when no new t"
W13-4916,D13-1032,1,0.820471,"Missing"
W13-4916,nivre-etal-2006-talbanken05,0,0.177802,"Missing"
W13-4916,P09-1040,0,0.0250735,"e baseline mate parse is also our overall baseline in the dependency track. The best-first parser deviates from the EasyFirst parser in several small respects: The EasyFirst decoder creates dependency links between the roots of adjacent substructures, which gives an O(n log n) complexity, but restricts the output to projective trees. The best-first parser is allowed to choose as head any node of an adjacent substructure instead of only the root, which increases complexity to O(n2 ), but accounts for a big part of possible non-projective structures. We additionally implemented a swapoperation (Nivre, 2009; Tratz and Hovy, 2011) to account for the more complex structures. The bestfirst parser relies on a beam-search strategy7 to pur7 Due to the nature of the decoder, the parser can produce 139 sue multiple derivations, which we also use to produce the n-best output. In the scoring step, we additionally apply the turboparser8 (Martins et al., 2010), which is based on linear programming relaxations.9 We changed all three parsers such that they would return a score for a given tree. We use this to extract scores from each parser for all trees in the n-best lists. It is important to have a score fr"
W13-4916,P06-1055,0,0.041165,"e. While this approach has been studied for constituency parsing (Zhang et al., 2009; Johnson and Ural, 2010; Wang and Zong, 2011), it is, to our knowledge, the first time this has been applied successfully within dependency parsing. We experimented with different kinds of features in the ranker and developed feature models for each language. Our system ranked first out of seven systems for all languages except French. For the constituency track, we experimented with an alternative way of handling unknown words and applied a products of Context Free Grammars with Latent Annotations (PCFG-LA) (Petrov et al., 2006), whose output was reranked to select the best analysis. The additional reranking step improved results for all languages. Our system beats various baselines provided by the organizers for all languages. Unfortunately, no one else participated in this track. For both settings, we made an effort to automatically annotate our data with the best possible preprocessing (POS, morphological information). We used a multi-layered CRF (M¨uller et al., 2013) to annotate each data set, stacking with the information provided by the organizers when this was beneficial. The high quality of our preprocessing"
W13-4916,seeker-kuhn-2012-making,1,0.360841,"Missing"
W13-4916,D11-1116,0,0.0140358,"te parse is also our overall baseline in the dependency track. The best-first parser deviates from the EasyFirst parser in several small respects: The EasyFirst decoder creates dependency links between the roots of adjacent substructures, which gives an O(n log n) complexity, but restricts the output to projective trees. The best-first parser is allowed to choose as head any node of an adjacent substructure instead of only the root, which increases complexity to O(n2 ), but accounts for a big part of possible non-projective structures. We additionally implemented a swapoperation (Nivre, 2009; Tratz and Hovy, 2011) to account for the more complex structures. The bestfirst parser relies on a beam-search strategy7 to pur7 Due to the nature of the decoder, the parser can produce 139 sue multiple derivations, which we also use to produce the n-best output. In the scoring step, we additionally apply the turboparser8 (Martins et al., 2010), which is based on linear programming relaxations.9 We changed all three parsers such that they would return a score for a given tree. We use this to extract scores from each parser for all trees in the n-best lists. It is important to have a score from every parser for eve"
W13-4916,W10-1401,0,0.0158928,"pendency tracks, and achieve state-of-theart for all languages. For both tracks we make significant improvements through high quality preprocessing and (re)ranking on top of strong baselines. Our system came out first for both tracks. 1 Introduction In this paper, we present our contribution to the 2013 Shared Task on Parsing Morphologically Rich Languages (MRLs). MRLs pose a number of interesting challenges to today’s standard parsing algorithms, for example a free word order and, due to their rich morphology, greater lexical variation that aggravates out-of-vocabulary problems considerably (Tsarfaty et al., 2010). Given the wide range of languages encompassed by the term MRL, there is, as of yet, no clear consensus on what approaches and features are generally important for parsing MRLs. However, developing tailored solutions for each language is timeconsuming and requires a good understanding of the language in question. In our contribution to the SPMRL 2013 Shared Task (Seddah et al., 2013), we therefore chose an approach that we could apply to all languages in the Shared Task, but that would also allow us to fine-tune it for individual languages by varying certain components. ∗ Authors in alphabeti"
W13-4916,P12-2002,0,0.0435376,"90.80/88.66 90.54/88.37 91.64/89.65 Hebrew 76.49/69.97 81.05/73.63 85.88/79.67 86.70/80.89 Hungarian 80.72/70.15 88.93/84.97 89.09/85.31 89.81/86.13 Korean 85.72/82.06 85.84/82.65 87.41/85.51 88.47/86.62 Polish 82.19/75.63 88.12/82.56 90.30/85.51 91.75/87.07 Swedish 80.29/73.21 87.28/80.88 86.85/80.67 88.06/82.13 Table 8: Final UAS/LAS scores for dependencies on the test sets for the predicted setting. Other denotes the highest scoring other participant in the Shared Task. ST Baseline denotes the MaltParser baseline provided by the Shared Task organizers. Table 6 shows the unlabeled TedEval (Tsarfaty et al., 2012) scores (accuracy/exact match) on the test sets for the predicted segmentation setting for Arabic and Hebrew. Note that these figures only include sentences of length less than or equal to 70. Since TedEval enables cross-framework comparison, we compare our submissions from the dependency track to our submission from the constituency track. In these runs we used the same systems that were used for the gold segmentation with predicted tags track. The predicted segmentation was provided by the Shared Task organizers. We also compare our results to the best other system from the Shared Task (deno"
W13-4916,P13-2103,0,0.05061,"Missing"
W13-4916,I11-1140,0,0.0140623,"ming and requires a good understanding of the language in question. In our contribution to the SPMRL 2013 Shared Task (Seddah et al., 2013), we therefore chose an approach that we could apply to all languages in the Shared Task, but that would also allow us to fine-tune it for individual languages by varying certain components. ∗ Authors in alphabetical order. For the dependency track, we combined the nbest output of multiple parsers and subsequently ranked them to obtain the best parse. While this approach has been studied for constituency parsing (Zhang et al., 2009; Johnson and Ural, 2010; Wang and Zong, 2011), it is, to our knowledge, the first time this has been applied successfully within dependency parsing. We experimented with different kinds of features in the ranker and developed feature models for each language. Our system ranked first out of seven systems for all languages except French. For the constituency track, we experimented with an alternative way of handling unknown words and applied a products of Context Free Grammars with Latent Annotations (PCFG-LA) (Petrov et al., 2006), whose output was reranked to select the best analysis. The additional reranking step improved results for al"
W13-4916,D09-1161,0,0.0775599,"red solutions for each language is timeconsuming and requires a good understanding of the language in question. In our contribution to the SPMRL 2013 Shared Task (Seddah et al., 2013), we therefore chose an approach that we could apply to all languages in the Shared Task, but that would also allow us to fine-tune it for individual languages by varying certain components. ∗ Authors in alphabetical order. For the dependency track, we combined the nbest output of multiple parsers and subsequently ranked them to obtain the best parse. While this approach has been studied for constituency parsing (Zhang et al., 2009; Johnson and Ural, 2010; Wang and Zong, 2011), it is, to our knowledge, the first time this has been applied successfully within dependency parsing. We experimented with different kinds of features in the ranker and developed feature models for each language. Our system ranked first out of seven systems for all languages except French. For the constituency track, we experimented with an alternative way of handling unknown words and applied a products of Context Free Grammars with Latent Annotations (PCFG-LA) (Petrov et al., 2006), whose output was reranked to select the best analysis. The add"
W13-4916,N10-1095,0,\N,Missing
W13-4916,C08-1112,0,\N,Missing
W13-4916,N10-1003,0,\N,Missing
W13-4916,W13-4917,1,\N,Missing
W13-4916,J13-1004,1,\N,Missing
W13-4916,vincze-etal-2010-hungarian,0,\N,Missing
W13-4917,P06-1084,0,0.0139791,"s of incomplete lexicon coverage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leadi"
W13-4917,P08-1083,1,0.743016,"in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respectable accuracy.25 4.7 The Hungarian Treebank Hungarian is an agglutinative language, thus a lemma can have hundreds of word forms due to derivational or inflectional affixation (nomina"
W13-4917,W13-4903,0,0.0228459,"such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Re"
W13-4917,W10-1411,1,0.835873,"challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and w"
W13-4917,W10-1408,1,0.383126,"Missing"
W13-4917,E12-2012,1,0.0774441,"parsing evaluation campaign SANCL 2012 (Petrov and McDonald, 2012). The present shared task was extremely demanding on our participants. From 30 individuals or teams who registered and obtained the data sets, we present results for the seven teams that accomplished successful executions on these data in the relevant scenarios in the given the time frame. 5.1 Dependency Track Seven teams participated in the dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To"
W13-4917,W13-4907,0,0.0733412,"Missing"
W13-4917,W10-1404,0,0.0222482,"merged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and"
W13-4917,W13-4916,1,0.230959,"Missing"
W13-4917,H91-1060,0,0.199934,"n the expected performance of parsers in real-world scenarios. Results reported for MRLs using gold morphological information are then, at best, optimistic. One reason for adopting this less-than-realistic evaluation scenario in previous tasks has been the lack of sound metrics for the more realistic scenario. Standard evaluation metrics assume that the number of terminals in the parse hypothesis equals the number of terminals in the gold tree. When the predicted morphological segmentation leads to a different number of terminals in the gold and parse trees, standard metrics such as ParsEval (Black et al., 1991) or Attachment Scores (Buchholz and Marsi, 2006) fail to produce a score. In this task, we use TedEval (Tsarfaty et al., 2012b), a metric recently suggested for joint morpho-syntactic evaluation, in which normalized tree-edit distance (Bille, 2005) on morphosyntactic trees allows us to quantify the success on the joint task in realistic parsing scenarios. Finally, the previous tasks focused on dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performa"
W13-4917,D12-1133,1,0.807979,"cy-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed"
W13-4917,C10-1011,0,0.0102695,"r system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-"
W13-4917,W07-1506,0,0.220289,"s of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version is available from http://www.ims. uni-stuttgart.de/forschung/ressourcen/ korpora/tiger.html 159 to the &quot;raising&quot; algorithm described by Boyd (2007). In a third steps, all those newly introduced nodes that did not cover the head daughter of the original discontinuous node were deleted. For the second and the third step, we used the same script as for the Swedish constituency data. Predicted Morphology For the predicted scenario, a single sequence of POS tags and morphological features has been assigned using the MATE toolchain via a model trained on the train set via crossvalidation on the training set. The MATE toolchain was used to provide predicted annotation for lemmas, POS tags, morphology, and syntax. In order to achieve the best re"
W13-4917,W06-2920,0,0.827477,"ouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency relations are marked between input tokens directly, and allow the annotation of non-projective dependencies that are parseable efficiently. Dependency syntax was applied to the description of different types of languages (Tesnière, 1959; Mel’ˇcuk, 2001), which raised the hope that in these settings, parsing MRLs will further improve. However, the 2007 shared task organizers (Nivre et al., 2007a) concluded that: &quot;[Performance] classes are more ea"
W13-4917,W10-1409,1,0.0435485,"for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing"
W13-4917,candito-etal-2010-statistical,1,0.0386487,"g of 18,535 sentences,18 split into 14,759 sentences for training, 1,235 sentences for development, and 2,541 sentences for the final evaluation.19 Adapting the Data to the Shared Task The constituency trees are provided in an extended PTB bracketed format, with morphological features at the pre-terminal level only. They contain slight, automatically performed, modifications with respect to the original trees of the French treebank. The syntagmatic projection of prepositions and complementizers was normalized, in order to have prepositions and complementizers as heads in the dependency trees (Candito et al., 2010). The dependency representations are projective dependency trees, obtained through automatic conversion from the constituency trees. The conversion procedure is an enhanced version of the one described by Candito et al. (2010). Both the constituency and the dependency representations make use of coarse- and fine-grained POS tags (CPOS and FPOS respectively). The CPOS are the categories from the original treebank. The FPOS 18 The process of functional annotation is still ongoing, the objective of the FTB providers being to have all the 20000 sentences annotated with functional tags. 19 The firs"
W13-4917,W08-2102,0,0.0353476,"troduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality par"
W13-4917,A00-2018,0,0.0705659,"n analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing E"
W13-4917,W11-3801,1,0.926035,"ers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard Engli"
W13-4917,chrupala-etal-2008-learning,0,0.045003,"Missing"
W13-4917,W10-1406,0,0.0618994,"Missing"
W13-4917,W13-4909,0,0.199525,"derived from the Hebrew Treebank V2 (Sima’an et al., 2001; Guthmann et al., 2009). The treebank is based on just over 6000 sentences from the daily newspaper ‘Ha’aretz’, manually annotated with morphological information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same"
W13-4917,J03-4003,0,0.48866,"omparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the ma"
W13-4917,W13-4905,1,0.719588,"method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZE"
W13-4917,W13-4906,1,0.680312,"dependency track. Two participating systems are based on MaltParser: M ALTOPTIMIZER (Ballesteros, 2013) and AI:KU (Cirik and Sensoy, ¸ 2013). M ALTOPTIMIZER uses a variant of MaltOptimizer (Ballesteros and Nivre, 2012) to explore features relevant for the processing of morphological information. AI:KU uses a combination of MaltParser and the original MaltOptimizer. Their system development has focused on the integration of an unsupervised word clustering method using contextual and morphological properties of the words, to help combat sparseness. Similarly to MaltParser A LPAGE :DYALOG (De La Clergerie, 2013) also uses a shift-reduce transition-based parser but its training and decoding algorithms are based on beam search. This parser is implemented on top of the tabular logic programming system DyALog. To the best of our knowledge, this is the first dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 200"
W13-4917,W08-1301,0,0.0393335,"Missing"
W13-4917,P98-1062,0,0.0491049,"Missing"
W13-4917,P08-1109,0,0.0220424,"ences. In order to avoid comparing apples and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Str"
W13-4917,J13-1005,1,0.838989,"html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? How to parse effectively in the face of resource scarcity? The first step to answering all of these"
W13-4917,W13-4908,1,0.872762,"Missing"
W13-4917,W10-1412,1,0.789087,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,N10-1115,1,0.576439,"Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally"
W13-4917,P08-1085,1,0.364225,"overage. The morphologically disambiguated input files for the Raw (1-best) scenario were produced by running the raw text through the morphological disam23 Note that this additional layer in the constituency treebank adds a relatively easy set of nodes to the trees, thus “inflating” the evaluation scores compared to previously reported results. To compensate, a stricter protocol than is used in this task would strip one of the two POS layers prior to evaluation. 24 This split is slightly different than the split in previous studies. 160 biguator (tagger) described in Adler and Elhadad (2006; Goldberg et al. (2008),Adler (2007). The disambiguator is based on the same lexicon that is used to produce the lattice files, but utilizes an extra module for dealing with unknown tokens Adler et al. (2008). The core of the disambiguator is an HMM tagger trained on about 70M unannotated tokens using EM, and being supervised by the lexicon. As in the case of Arabic, we also provided data for the Predicted (gold token / predicted morphology) scenario. We used the same sequence labeler, Morfette (Chrupała et al., 2008), trained on the concatenation of POS and morphological gold features, leading to a model with respe"
W13-4917,E09-1038,1,0.867766,"ices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming to the lexical resource used to build the lattices, and is shared by the two treebanks. The higher level is syntactic, and follows the tag set and annotation decisions of the original constituency treebank.23 In addition, we unified the representation of morphological features, and fixed inconsistencies and mistakes in the treebanks. Data Split The Hebrew treebank is one of the smallest in our language set, and hence it is provided in only the small (5k) setting. For the sake of comparabilit"
W13-4917,C10-1045,1,0.826872,"nflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Haba"
W13-4917,W12-3410,0,0.0157938,"umulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realis"
W13-4917,J13-1009,1,0.747017,"Missing"
W13-4917,P09-2056,1,0.833708,".2 The Arabic Treebanks Arabic is a morphologically complex language which has rich inflectional and derivational morphology. It exhibits a high degree of morphological ambiguity due to the absence of the diacritics and inconsistent spelling of letters, such as Alif and Ya. As a consequence, the Buckwalter Standard Arabic Morphological Analyzer (Buckwalter, 2004; Graff et al., 2009) produces an average of 12 analyses per word. Data Sets The Arabic data set contains two treebanks derived from the LDC Penn Arabic Treebanks (PATB) (Maamouri et al., 2004b):11 the Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), a dependency treebank, and the Stanford version of the PATB (Green and Manning, 2010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional A"
W13-4917,D07-1116,1,0.604822,"010), a phrasestructure treebank. We preprocessed the treebanks to obtain strict token matching between the treebanks and the morphological analyses. This required nontrivial synchronization at the tree token level between the PATB treebank, the CATiB treebank and the morphologically predicted data, using the PATB source tokens and CATiB feature word form as a dual synchronized pivot. The Columbia Arabic Treebank The Columbia Arabic Treebank (CATiB) uses a dependency representation that is based on traditional Arabic grammar and that emphasizes syntactic case relations (Habash and Roth, 2009; Habash et al., 2007). The CATiB treebank uses the word tokenization of the PATB 11 The LDC kindly provided their latest version of the Arabic Treebanks. In particular, we used PATB 1 v4.1 (Maamouri et al., 2005), PATB 2 v3.1 (Maamouri et al., 2004a) and PATB 3 v3.3. (Maamouri et al., 2009) train: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS tags #total NTs Dep. Label Set Size train5k: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Tokens Ratio #NT/#Sents #Non Terminals #POS Tags #total NTs Dep. Label Set Size dev: #Sents #Tokens Lex. Size Avg. Length Ratio #NT/#Toke"
W13-4917,P07-2053,0,0.0323622,"Missing"
W13-4917,D07-1097,1,0.346865,"Missing"
W13-4917,D10-1002,0,0.0151688,"oaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predica"
W13-4917,P08-1067,0,0.0226773,"a-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information co"
W13-4917,J98-4004,0,0.0891486,"ir strengths and weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying t"
W13-4917,J13-1006,1,0.798597,"hbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer and Maier, 2013), the use of factored lexica (Green et al., 2013), the use of bilingual data (Fraser et al., 2013), and more developments that are currently under way. With new models and data, and with lingering interest in parsing non-standard English data, questions begin to emerge, such as: What is the realistic performance of parsing MRLs using today’s methods? How do the different models compare with one another? How do different representation types deal with parsing one particular language? Does the success of a parsing model on a language correlate with its representation type and learning method? Ho"
W13-4917,P03-1054,0,0.00438043,"d weaknesses. Finally, we summarize and conclude with challenges to address in future shared tasks (§8). 2 2.1 Background A Brief History of the SPMRL Field Statistical parsing saw initial success upon the availability of the Penn Treebank (PTB, Marcus et al., 1994). With that large set of syntactically annotated sentences at their disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank"
W13-4917,W06-1614,1,0.812546,"nd machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) hi"
W13-4917,kubler-etal-2008-compare,1,0.91565,"node to the root node in the output tree and the corresponding path in the gold tree. The path consists of a sequence of node labels between the terminal node and the root node, and the similarity of two paths is calculated by using the Levenshtein distance. This distance is normalized by path length, and the score of the tree is an aggregated score of the values for all terminals in the tree (xt is the leaf-ancestor path of t in tree x). P LA(h, g) = t∈yield(g) Lv(ht ,gt )/(len(ht )+len(gt )) |yield(g)| This metric was shown to be less sensitive to differences between annotation schemes in (Kübler et al., 2008), and was shown by Rehbein and van Genabith (2007a) to evaluate trees more faithfully than ParsEval in the face of certain annotation decisions. We used the implementation of Wagner (2012).6 3.4.2 Evaluation Metrics for Dependency Structures Attachment Scores Labeled and Unlabeled Attachment scores have been proposed as evaluation metrics for dependency parsing in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007a) and have since assumed the role of standard metrics in multiple shared tasks and independent studies. Assume that g, h are gold and hypothesized dependency trees"
W13-4917,W12-3408,1,0.878953,"Missing"
W13-4917,P03-1056,0,0.0207769,"disposal, researchers could apply advanced statistical modeling and machine learning techniques in order to obtain high quality structure prediction. The first statistical parsing models were generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on depend"
W13-4917,W12-4615,1,0.809959,"ly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This was done in three steps. In the first step, the head daughters of all nodes were marked using a simple heuristic. In case there was a daughter with the edge label HD, this daughter was marked, i.e., existing head markings were honored. Otherwise, if existing, the rightmost daughter with edge label NK (noun kernel) was marked. Otherwise, as default, the leftmost daughter was marked. In a second step, for each continuous part of a discontinuous constituent, a separate node was introduced. This corresponds 21 This version"
W13-4917,J93-2004,0,0.0437888,"participants, and then provide an analysis and comparison of the parsers across languages and frameworks, reported for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend."
W13-4917,D10-1004,0,0.0390834,"nd MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2013b) uses their variant of the easy-first parser combined with a feature-rich ensemble of lexical and syntactic resources. Four of the participating teams use external resources in addition to the parser. The IMS:S ZEGED :CIS team uses external morphological analyzers. C ADIM uses SAMA (Graff et al., 2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for"
W13-4917,J13-1008,1,0.913933,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,W13-4910,1,0.915357,". Additionally, new questions emerged as to the evaluation of parsers in such languages – are the word-based metrics used for English well-equipped to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint"
W13-4917,N06-1020,0,0.225446,"for gold input as well as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on"
W13-4917,P05-1012,0,0.042194,"Missing"
W13-4917,moreno-etal-2000-treebank,0,0.0581254,"e generative and based on treebank grammars (Charniak, 1997; Johnson, 1998; Klein and Manning, 2003; Collins, 2003; Petrov et al., 2006; McClosky et al., 2006), leading to high phrase-structure accuracy. Encouraged by the success of phrase-structure parsers for English, treebank grammars for additional languages have been developed, starting with Czech (Hajiˇc et al., 2000) then with treebanks of Chinese (Levy and Manning, 2003), Arabic (Maamouri et al., 2004b), German (Kübler et al., 2006), French (Abeillé et al., 2003), Hebrew (Sima’an et al., 2001), Italian (Corazza et al., 2004), Spanish (Moreno et al., 2000), and more. It quickly became apparent that applying the phrase-based treebank grammar techniques is sensitive to language and annotation properties, and that these models are not easily portable across languages and schemes. An exception to that is the approach by Petrov (2009), who trained latentannotation treebank grammars and reported good accuracy on a range of languages. The CoNLL shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007a) highlighted the usefulness of an alternative linguistic formalism for the development of competitive parsing models. Dependency"
W13-4917,nivre-etal-2006-talbanken05,1,0.442193,"subject agreement with respect to person and number has been dropped in modern Swedish. The Data Set The Swedish data sets are taken from the Talbanken section of the Swedish Treebank (Nivre and Megyesi, 2007). Talbanken is a syntactically annotated corpus developed in the 1970s, originally annotated according to the MAMBA scheme (Teleman, 1974) with a syntactic layer consisting of flat phrase structure and grammatical functions. The syntactic annotation was later automatically converted to full phrase structure with grammatical functions and from that to dependency structure, as described by Nivre et al. (2006). Both the phrase structure and the dependency version use the functional labels from the original MAMBA scheme, which provides a fine-grained classification of syntactic functions with 65 different labels, while the phrase structure annotation (which had to be inferred automatically) uses a coarse set of only 8 labels. For the release of the Swedish treebank, the POS level was re-annotated to conform to the current de facto standard for Swedish, which is the Stockholm-Umeå tagset (Ejerhed et al., 1992) with 25 base tags and 25 morpho-syntactic features, which together produce over 150 complex"
W13-4917,P06-1055,0,0.480329,"as more realistic parsing scenarios. 1 Introduction Syntactic parsing consists of automatically assigning to a natural language sentence a representation of its grammatical structure. Data-driven approaches to this problem, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it"
W13-4917,N10-1003,0,0.0195824,"2009) for Arabic morphology. A LPAGE :DYALOG and IGM:A LPAGE use external lexicons for French. IGM:A LPAGE additionally uses Morfette (Chrupała et al., 2008) for morphological analysis and POS tagging. Finally, as already mentioned, AI:KU clusters words and POS tags in an unsupervised fashion exploiting additional, un-annotated data. 5.2 Constituency Track A single team participated in the constituency parsing task, the IMS:S ZEGED :CIS team (Björkelund et al., 2013). Their phrase-structure parsing system uses a combination of 8 PCFG-LA parsers, trained using a product-of-grammars procedure (Petrov, 2010). The 50-best parses of this combination are then reranked by a model based on the reranker by Charniak and Johnson (2005).33 5.3 6.1 Baselines We additionally provide the results of two baseline systems for the nine languages, one for constituency parsing and one for dependency parsing. For the dependency track, our baseline system is MaltParser in its default configuration (the arc-eager algorithm and liblinear for training). Results marked as BASE :M ALT in the next two sections report the results of this baseline system in different scenarios. The constituency parsing baseline is based on"
W13-4917,W07-2460,0,0.109747,"Missing"
W13-4917,D07-1066,0,0.0884872,"Missing"
W13-4917,W11-3808,0,0.027114,"rameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCFRS parsing (Kallmeyer an"
W13-4917,N06-2033,0,0.0563478,"rst dependency parser capable of handling word lattice input. 163 Three participating teams use the MATE parser (Bohnet, 2010) in their systems: the BASQUE T EAM (Goenaga et al., 2013), IGM:A LPAGE (Constant et al., 2013) and IMS:S ZEGED :CIS (Björkelund et al., 2013). The BASQUE T EAM uses the MATE parser in combination with MaltParser (Nivre et al., 2007b). The system combines the parser outputs via MaltBlender (Hall et al., 2007). IGM:A LPAGE also uses MATE and MaltParser, once in a pipeline architecture and once in a joint model. The models are combined via a re-parsing strategy based on (Sagae and Lavie, 2006). This system mainly focuses on M WEs in French and uses a CRF tagger in combination with several large-scale dictionaries to handle M WEs, which then serve as input for the two parsers. The IMS:S ZEGED :CIS team participated in both tracks, with an ensemble system. For the dependency track, the ensemble includes the MATE parser (Bohnet, 2010), a best-first variant of the easy-first parser by Goldberg and Elhadad (2010b), and turbo parser (Martins et al., 2010), in combination with a ranker that has the particularity of using features from the constituent parsed trees. C ADIM (Marton et al., 2"
W13-4917,schmid-etal-2004-smor,0,0.00857226,"information and phrase-structure trees and extended with head information as described in Tsarfaty (2010, ch. 5). The unlabeled dependency version was produced by conversion from the constituency treebank as described in Goldberg (2011). Both the constituency and dependency trees were annotated with a set grammatical function labels conforming to Unified Stanford Dependencies by Tsarfaty (2013). 22 We also provided a predicted-all scenario, in which we provided morphological analysis lattices with POS and morphological information derived from the analyses of the SMOR derivational morphology (Schmid et al., 2004). These lattices were not used by any of the participants. Adapting the Data to the Shared Task While based on the same trees, the dependency and constituency treebanks differ in their POS tag sets, as well as in some of the morphological segmentation decisions. The main effort towards the shared task was unifying the two resources such that the two treebanks share the same lexical yields, and the same pre-terminal labels. To this end, we took the layering approach of Goldberg et al. (2009), and included two levels of POS tags in the constituency trees. The lower level is lexical, conforming t"
W13-4917,W10-1410,1,0.889145,"Missing"
W13-4917,seeker-kuhn-2012-making,1,0.106665,"n constituency data set is based on the TiGer treebank release 2.2.21 The original annotation scheme represents discontinuous constituents such that all arguments of a predicate are always grouped under a single node regardless of whether there is intervening material between them or not (Brants et al., 2002). Furthermore, punctuation and several other elements, such as parentheses, are not attached to the tree. In order to make the constituency treebank usable for PCFG parsing, we adapted this treebank as described shortly. The conversion of TiGer into dependencies is a variant of the one by Seeker and Kuhn (2012), which does not contain empty nodes. It is based on the same TiGer release as the one used for the constituency data. Punctuation was attached as high as possible, without creating any new non-projective edges. Adapting the Data to the Shared Task For the constituency version, punctuation and other unattached elements were first attached to the tree. As attachment target, we used roughly the respective least common ancestor node of the right and left terminal neighbor of the unattached element (see Maier et al. (2012) for details), and subsequently, the crossing branches were resolved. This w"
W13-4917,P12-1046,0,0.00731402,"based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formatio"
W13-4917,W11-3803,0,0.0414253,"to capture performance across frameworks, or performance in the face of morphological complexity? This event provoked active discussions and led to the establishment of a series of SPMRL events for the discussion of shared challenges and cross-fertilization among researchers working on parsing MRLs. The body of work on MRLs that was accumulated through the SPMRL workshops2 and hosting ACL venues contains new results for Arabic (Attia et al., 2010; Marton et al., 2013a), Basque (Bengoetxea and Gojenola, 2010), Croatian (Agic et al., 2013), French (Seddah et al., 2010; Candito and Seddah, 2010; Sigogne et al., 2011), German (Rehbein, 2011), Hebrew (Tsarfaty and Sima’an, 2010; Goldberg and 1 http://alpage.inria.fr/iwpt09/panel.en. html 2 See http://www.spmrl.org/ and related workshops. 148 Elhadad, 2010a), Hindi (Ambati et al., 2010), Korean (Chung et al., 2010; Choi and Palmer, 2011) and Spanish (Le Roux et al., 2012), Tamil (Green et al., 2012), amongst others. The awareness of the modeling challenges gave rise to new lines of work on topics such as joint morpho-syntactic processing (Goldberg and Tsarfaty, 2008), Relational-Realizational Parsing (Tsarfaty, 2010), EasyFirst Parsing (Goldberg, 2011), PLCF"
W13-4917,W10-1405,1,0.891538,"Missing"
W13-4917,W10-1401,1,0.779419,"sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 146–182, c Seattle, Washington, USA, 18 October 2013. 2013 Association for Computational Linguistics recently, advances in PCFG-LA parsing (Petrov et al., 2006) and language-agnostic data-driven dependency parsing (McD"
W13-4917,D11-1036,1,0.926772,"dependency parsing. When providing both constituency-based and dependency-based tracks, it is interesting to compare results across these frameworks so as to better understand the differences in performance between parsers of different types. We are now faced with an additional question: how can we compare parsing results across different frameworks? Adopting standard metrics will not suffice as we would be comparing apples and oranges. In contrast, TedEval is defined for both phrase structures and dependency structures through the use of an intermediate representation called function trees (Tsarfaty et al., 2011; Tsarfaty et al., 2012a). Using TedEval thus allows us to explore both dependency and constituency parsing frameworks and meaningfully compare the performance of parsers of different types. 149 3 3.1 Defining the Shared-Task Input and Output We define a parser as a structure prediction function that maps sequences of space-delimited input tokens (henceforth, tokens) in a language to a set of parse trees that capture valid morpho-syntactic structures in that language. In the case of constituency parsing, the output structures are phrase-structure trees. In dependency parsing, the output consis"
W13-4917,E12-1006,1,0.148172,"er languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure of sentences is expressed through word formation, rather than constituent-order patterns as is the case in English and other configurational languages. MRLs express information concerning the grammatical function of a word and its grammatical relation to other words at the word level, via phenomena such as inflectional affixes, pronominal clitics, and so on (Tsarfaty et al., 2012c). The non-rigid tree structures and morphological ambiguity of input words contribute to the challenges of parsing MRLs. In addition, insufficient language resources were shown to also contribute to parsing difficulty (Tsarfaty et al., 2010; Tsarfaty et al., 2012c, and references therein). These challenges have initially been addressed by native-speaking experts using strong in-domain knowledge of the linguistic phenomena and annotation idiosyncrasies to improve the accuracy and efficiency of parsing models. More 146 Proceedings of the Fourth Workshop on Statistical Parsing of Morphologicall"
W13-4917,P13-2103,1,0.111695,"les and oranges, we use the unlabeled TedEval metric, which converts all representation types internally into the same kind of structures, called function trees. Here we use TedEval’s crossframework protocol (Tsarfaty et al., 2012a), which accomodates annotation idiosyncrasies. • Cross-Language Evaluation. Here, we compare parsers for the same representation type across different languages. Conducting a complete and faithful evaluation across languages 151 would require a harmonized universal annotation scheme (possibly along the lines of (de Marneffe and Manning, 2008; McDonald et al., 2013; Tsarfaty, 2013)) or task based evaluation. As an approximation we use unlabeled TedEval. Since it is unlabeled, it is not sensitive to label set size. Since it internally uses function-trees, it is less sensitive to annotation idiosyncrasies (e.g., head choice) (Tsarfaty et al., 2011). The former two dimensions are evaluated on the full sets. The latter two are evaluated on smaller, comparable, test sets. For completeness, we provide below the formal definitions and essential modifications of the evaluation software that we used. 3.4.1 Evaluation Metrics for Phrase Structures ParsEval The ParsEval metrics (B"
W13-4917,P11-2033,1,0.563308,"em, both for constituency-based and dependency-based parsing, have seen a surge of interest in the last two decades. These data-driven parsing approaches obtain state-of-the-art results on the de facto standard Wall Street Journal data set (Marcus et al., 1993) of English (Charniak, 2000; Collins, 2003; Charniak and Johnson, 2005; McDonald et al., 2005; McClosky et al., 2006; Petrov et al., 2006; Nivre et al., 2007b; Carreras et al., 2008; Finkel et al., 2008; ∗ Contact authors: djame.seddah@paris-sorbonne.fr, reut.tsarfaty@weizmann.ac.il, skuebler@indiana.edu Huang, 2008; Huang et al., 2010; Zhang and Nivre, 2011; Bohnet and Nivre, 2012; Shindo et al., 2012), and provide a foundation on which many tasks operating on semantic structure (e.g., recognizing textual entailments) or even discourse structure (coreference, summarization) crucially depend. While progress on parsing English — the main language of focus for the ACL community — has inspired some advances on other languages, it has not, by itself, yielded high-quality parsing for other languages and domains. This holds in particular for morphologically rich languages (MRLs), where important information concerning the predicate-argument structure o"
W13-4917,R13-1099,1,0.0375053,"orphology In order to provide the same POS tag set for the constituent and dependency treebanks, we used the dependency POS tagset for both treebank instances. Both versions of the treebank are available with gold standard and automatic morphological annotation. The automatic POS tagging was carried out by a 10-fold cross-validation on the shared task data set by magyarlanc, a natural language toolkit for processing Hungarian texts (segmentation, morphological analysis, POS tagging, and dependency parsing). The annotation provides POS tags and deep morphological features for each input token (Zsibrita et al., 2013).28 28 The full data sets of both the constituency and dependency versions of the Szeged Treebank are available at 161 4.8 The Korean Treebank The Treebank The Korean corpus is generated by collecting constituent trees from the K AIST Treebank (Choi et al., 1994), then converting the constituent trees to dependency trees using head-finding rules and heuristics. The K AIST Treebank consists of about 31K manually annotated constituent trees from 97 different sources (e.g., newspapers, novels, textbooks). After filtering out trees containing annotation errors, a total of 27,363 trees with 350,090"
W13-4917,E93-1064,0,\N,Missing
W13-4917,C00-1001,0,\N,Missing
W13-4917,C10-1061,1,\N,Missing
W13-4917,J13-1003,1,\N,Missing
W13-4917,C08-1112,1,\N,Missing
W13-4917,W08-1008,1,\N,Missing
W13-4917,P05-1022,0,\N,Missing
W13-4917,P98-1063,0,\N,Missing
W13-4917,C98-1060,0,\N,Missing
W13-4917,vincze-etal-2010-hungarian,1,\N,Missing
W13-4917,D07-1096,1,\N,Missing
W14-6110,W11-3802,0,0.12707,"Missing"
W14-6110,C12-1052,1,0.848221,"ical annotation of POS tags, we use a preterminal set which carries more linguistic information while still keeping it compact. We follow the merge procedure for morphological feature values of Sz´ant´o and Farkas (2014). This procedure outputs a clustering of full morphological descriptions and we use the cluster IDs as preterminal labels for training the Berkeley Parser. Reranking at the constituency parsing side is enriched by novel features. We define feature templates exploiting co-occurrence statistics from the unlabeled datasets; automatic dependency parses of the sentence in question (Farkas and Bohnet, 2012); Brown clusters (Brown et al., 1992); and atomic morphological feature values (Sz´ant´o and Farkas, 2014). 6 The organizers later resolved this issue by patching the data, although time constraints prevented us from using the patched data. 99 4 Conclusion This paper describes our plans for the SPMRL 2014 Shared Task, most of which are yet to be implemented. For the actual system description and our results, we refer the interested reader to (Bj¨orkelund et al., 2014) and (Seddah et al., 2014). Acknowledgements Agnieszka Fale´nska is funded through the Project International computer science an"
W14-6110,P06-1037,0,0.0318535,"vided morphological analyses since the annotations on the labeled and unlabeled data were inconsistent for some languages.6 3.2 Dependency Parsing We pursue two different ways of integrating additional information into our system from the SPMRL 2013 Shared Task (Bj¨orkelund et al., 2013): supertags and co-training. Supertags (Bangalore and Joshi, 1999) are tags that encode more syntactic information than standard part-of-speech tags. Supertags have been used in deep grammar formalisms like CCG or HPSG to prune the search space for the parser. The idea has been applied to dependency parsing by Foth et al. (2006) and recently to statistical dependency parsing (Ouchi et al., 2014; Ambati et al., 2014), where supertags are used as features rather than to prune the search space. Since the supertag set is dynamically derived from the gold-standard syntactic structures, we can encode different kinds of information into a supertag, in particular also morphological information. Supertags are predicted before parsing using MarMoT and are then used as features in the mate parser and the turboparser. We will use a variant of co-training (Blum and Mitchell, 1998) by applying two different parsers to select addit"
W14-6110,N10-1115,0,0.0226874,"gration of predicted tags provided by the organizers and observed that these stacked models help improve Basque, Polish, and Swedish preprocessing. The stacked models provided additional information to our tagger since the provided predictions were coming from models trained on larger training sets than the shared task training sets. 2.2 Dependency Parsing The dependency parsing architecture of our SPMRL 2013 Shared Task contribution is summarized in Figure 1. The first step combines the n-best trees of two parsers, namely the mate parser4 (Bohnet, 2010) and a variant of the EasyFirst parser (Goldberg and Elhadad, 2010), which we call best-first parser. We merged the 50-best analyses from these parsers into one n-best list of 50 to 100 trees. We then added parsing scores to the n-best trees from the two parsers, and additionally from the turboparser5 (Martins et al., 2010). Parsing Ranking scores mate parser IN best-first parser turboparser merged list of 50-100 best trees/sentence merged list scored by all parsers ranker OUT features scores ptb trees scores Figure 1: Architecture of the dependency ranking system from (Bj¨orkelund et al., 2013). The scored trees are fed into the ranking system. The ranker ut"
W14-6110,C10-1045,0,0.0506468,"Missing"
W14-6110,P09-2056,0,0.0396032,"Missing"
W14-6110,D10-1004,0,0.0954613,"Missing"
W14-6110,D13-1032,1,0.898395,"Missing"
W14-6110,nivre-etal-2006-talbanken05,0,0.0726064,"Missing"
W14-6110,E14-4030,0,0.016915,"nd unlabeled data were inconsistent for some languages.6 3.2 Dependency Parsing We pursue two different ways of integrating additional information into our system from the SPMRL 2013 Shared Task (Bj¨orkelund et al., 2013): supertags and co-training. Supertags (Bangalore and Joshi, 1999) are tags that encode more syntactic information than standard part-of-speech tags. Supertags have been used in deep grammar formalisms like CCG or HPSG to prune the search space for the parser. The idea has been applied to dependency parsing by Foth et al. (2006) and recently to statistical dependency parsing (Ouchi et al., 2014; Ambati et al., 2014), where supertags are used as features rather than to prune the search space. Since the supertag set is dynamically derived from the gold-standard syntactic structures, we can encode different kinds of information into a supertag, in particular also morphological information. Supertags are predicted before parsing using MarMoT and are then used as features in the mate parser and the turboparser. We will use a variant of co-training (Blum and Mitchell, 1998) by applying two different parsers to select additional training material from unlabeled data. We use the mate parser"
W14-6110,P06-1055,0,0.0257704,"Missing"
W14-6110,D07-1111,0,0.0255085,"res, we can encode different kinds of information into a supertag, in particular also morphological information. Supertags are predicted before parsing using MarMoT and are then used as features in the mate parser and the turboparser. We will use a variant of co-training (Blum and Mitchell, 1998) by applying two different parsers to select additional training material from unlabeled data. We use the mate parser and the turboparser to parse the unlabeled data provided by the organizers. We then select sentences where both parsers agree on the structure as additional training examples following Sagae and Tsujii (2007). We then train two more models: one on the labeled training data and the unlabeled data selected by the two parsers, and one only on the unlabeled data. These two models are then integrated into our parsing system from 2013 as additional scorers to score the n-best list. Their scores are used as features in the ranker. Before we parse the unlabeled data to obtain the training sentences, we filter it in order to arrive at a cleaner corpus. Most importantly, we only keep sentences up to length 50, and which contain at maximum two unknown words (compared to the labeled training data). 3.3 Consti"
W14-6110,seeker-kuhn-2012-making,1,0.896194,"Missing"
W14-6110,E14-1015,1,0.891269,"Missing"
W14-6110,P13-2103,0,0.0482158,"Missing"
W14-6110,J99-2004,0,\N,Missing
W14-6110,C10-1011,0,\N,Missing
W14-6110,C08-1112,0,\N,Missing
W14-6110,W13-4916,1,\N,Missing
W14-6110,J92-4003,0,\N,Missing
W14-6110,P05-1022,0,\N,Missing
W14-6110,N10-1003,0,\N,Missing
W14-6110,W13-4917,1,\N,Missing
W14-6110,E14-4031,0,\N,Missing
W14-6110,vincze-etal-2010-hungarian,0,\N,Missing
