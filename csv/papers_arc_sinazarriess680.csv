2021.sigdial-1.43,Diversity as a By-Product: Goal-oriented Language Generation Leads to Linguistic Variation,2021,-1,-1,3,1,1565,simeon schuz,Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"The ability for variation in language use is necessary for speakers to achieve their conversational goals, for instance when referring to objects in visual environments. We argue that diversity should not be modelled as an independent objective in dialogue, but should rather be a result or by-product of goal-oriented language generation. Different lines of work in neural language generation investigated decoding methods for generating more diverse utterances, or increasing the informativity through pragmatic reasoning. We connect those lines of work and analyze how pragmatic reasoning during decoding affects the diversity of generated image captions. We find that boosting diversity itself does not result in more pragmatically informative captions, but pragmatic reasoning does increase lexical diversity. Finally, we discuss whether the gain in informativity is achieved in linguistically plausible ways."
2021.reinact-1.7,Decoupling Pragmatics: Discriminative Decoding for Referring Expression Generation,2021,-1,-1,2,1,1565,simeon schuz,Proceedings of the Reasoning and Interaction Conference (ReInAct 2021),0,"The shift to neural models in Referring Expression Generation (REG) has enabled more natural set-ups, but at the cost of interpretability. We argue that integrating pragmatic reasoning into the inference of context-agnostic generation models could reconcile traits of traditional and neural REG, as this offers a separation between context-independent, literal information and pragmatic adaptation to context. With this in mind, we apply existing decoding strategies from discriminative image captioning to REG and evaluate them in terms of pragmatic informativity, likelihood to ground-truth annotations and linguistic diversity. Our results show general effectiveness, but a relatively small gain in informativity, raising important questions for REG in general."
2021.lantern-1.5,What Did This Castle Look like before? Exploring Referential Relations in Naturally Occurring Multimodal Texts,2021,-1,-1,2,0,5534,ronja utescher,Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN),0,"Multi-modal texts are abundant and diverse in structure, yet Language {\&} Vision research of these naturally occurring texts has mostly focused on genres that are comparatively light on text, like tweets. In this paper, we discuss the challenges and potential benefits of a L{\&}V framework that explicitly models referential relations, taking Wikipedia articles about buildings as an example. We briefly survey existing related tasks in L{\&}V and propose multi-modal information extraction as a general direction for future research."
2021.inlg-1.41,"Decoding, Fast and Slow: A Case Study on Balancing Trade-Offs in Incremental, Character-level Pragmatic Reasoning",2021,-1,-1,1,1,1567,sina zarriess,Proceedings of the 14th International Conference on Natural Language Generation,0,"Recent work has adopted models of pragmatic reasoning for the generation of informative language in, e.g., image captioning. We propose a simple but highly effective relaxation of fully rational decoding, based on an existing incremental and character-level approach to pragmatically informative neural image captioning. We implement a mixed, {`}fast{'} and {`}slow{'}, speaker that applies pragmatic reasoning occasionally (only word-initially), while unrolling the language model. In our evaluation, we find that increased informativeness through pragmatic decoding generally lowers quality and, somewhat counter-intuitively, increases repetitiveness in captions. Our mixed speaker, however, achieves a good balance between quality and informativeness."
2021.hcinlp-1.11,Challenges in Designing Natural Language Interfaces for Complex Visual Models,2021,-1,-1,4,0,6051,henrik voigt,Proceedings of the First Workshop on Bridging Human{--}Computer Interaction and Natural Language Processing,0,"Intuitive interaction with visual models becomes an increasingly important task in the field of Visualization (VIS) and verbal interaction represents a significant aspect of it. Vice versa, modeling verbal interaction in visual environments is a major trend in ongoing research in NLP. To date, research on Language {\&} Vision, however, mostly happens at the intersection of NLP and Computer Vision (CV), and much less at the intersection of NLP and Visualization, which is an important area in Human-Computer Interaction (HCI). This paper presents a brief survey of recent work on interactive tasks and set-ups in NLP and Visualization. We discuss the respective methods, show interesting gaps, and conclude by suggesting neural, visually grounded dialogue modeling as a promising potential for NLIs for visual models."
2020.lrec-1.710,Object Naming in Language and Vision: A Survey and a New Dataset,2020,-1,-1,2,0,18053,carina silberer,Proceedings of the 12th Language Resources and Evaluation Conference,0,"People choose particular names for objects, such as dog or puppy for a given dog. Object naming has been studied in Psycholinguistics, but has received relatively little attention in Computational Linguistics. We review resources from Language and Vision that could be used to study object naming on a large scale, discuss their shortcomings, and create a new dataset that affords more opportunities for analysis and modeling. Our dataset, ManyNames, provides 36 name annotations for each of 25K objects in images selected from VisualGenome. We highlight the challenges involved and provide a preliminary analysis of the ManyNames data, showing that there is a high level of agreement in naming, on average. At the same time, the average number of name types associated with an object is much higher in our dataset than in existing corpora for Language and Vision, such that ManyNames provides a rich resource for studying phenomena like hierarchical variation (chihuahua vs. dog), which has been discussed at length in the theoretical literature, and other less well studied phenomena like cross-classification (cake vs. dessert)."
2020.inlg-1.38,From {``}Before{''} to {``}After{''}: Generating Natural Language Instructions from Image Pairs in a Simple Visual Domain,2020,-1,-1,5,0,16790,robin rojowiec,Proceedings of the 13th International Conference on Natural Language Generation,0,"While certain types of instructions can be com-pactly expressed via images, there are situations where one might want to verbalise them, for example when directing someone. We investigate the task of Instruction Generation from Before/After Image Pairs which is to derive from images an instruction for effecting the implied change. For this, we make use of prior work on instruction following in a visual environment. We take an existing dataset, the BLOCKS data collected by Bisk et al. (2016) and investigate whether it is suitable for training an instruction generator as well. We find that it is, and investigate several simple baselines, taking these from the related task of image captioning. Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement. We find that captioning models get some way towards solving the task, but have some difficulty with it, and future improvements must lie in the way the change is detected in the instruction."
2020.coling-main.172,Humans Meet Models on Object Naming: A New Dataset and Analysis,2020,-1,-1,2,0,18053,carina silberer,Proceedings of the 28th International Conference on Computational Linguistics,0,"We release ManyNames v2 (MN v2), a verified version of an object naming dataset that contains dozens of valid names per object for 25K images. We analyze issues in the data collection method originally employed, standard in Language {\&} Vision (L{\&}V), and find that the main source of noise in the data comes from simulating a naming context solely from an image with a target object marked with a bounding box, which causes subjects to sometimes disagree regarding which object is the target. We also find that both the degree of this uncertainty in the original data and the amount of true naming variation in MN v2 differs substantially across object domains. We use MN v2 to analyze a popular L{\&}V model and demonstrate its effectiveness on the task of object naming. However, our fine-grained analysis reveals that what appears to be human-like model behavior is not stable across domains, e.g., the model confuses people and clothing objects much more frequently than humans do. We also find that standard evaluations underestimate the actual effectiveness of the naming model: on the single-label names of the original dataset (Visual Genome), it obtains â27{\%} accuracy points than on MN v2, that includes all valid object names."
2020.acl-main.584,{K}nowledge Supports Visual Language Grounding: {A} Case Study on Colour Terms,2020,-1,-1,2,1,1565,simeon schuz,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"In human cognition, world knowledge supports the perception of object colours: knowing that trees are typically green helps to perceive their colour in certain contexts. We go beyond previous studies on colour terms using isolated colour swatches and study visual grounding of colour terms in realistic objects. Our models integrate processing of visual information and object-specific knowledge via hard-coded (late) or learned (early) fusion. We find that both models consistently outperform a bottom-up baseline that predicts colour terms solely from visual inputs, but show interesting differences when predicting atypical colours of so-called colour diagnostic objects. Our models also achieve promising results when tested on new object categories not seen during training."
W19-8618,Sketch Me if You Can: Towards Generating Detailed Descriptions of Object Shape by Grounding in Images and Drawings,2019,0,0,2,1,1566,ting han,Proceedings of the 12th International Conference on Natural Language Generation,0,"A lot of recent work in Language {\&} Vision has looked at generating descriptions or referring expressions for objects in scenes of real-world images, though focusing mostly on relatively simple language like object names, color and location attributes (e.g., brown chair on the left). This paper presents work on Draw-and-Tell, a dataset of detailed descriptions for common objects in images where annotators have produced fine-grained attribute-centric expressions distinguishing a target object from a range of similar objects. Additionally, the dataset comes with hand-drawn sketches for each object. As Draw-and-Tell is medium-sized and contains a rich vocabulary, it constitutes an interesting challenge for CNN-LSTM architectures used in state-of-the-art image captioning models. We explore whether the additional modality given through sketches can help such a model to learn to accurately ground detailed language referring expressions to object shapes. Our results are encouraging."
W19-8621,Tell Me More: A Dataset of Visual Scene Description Sequences,2019,0,0,2,1,14068,nikolai ilinykh,Proceedings of the 12th International Conference on Natural Language Generation,0,"We present a dataset consisting of what we call image description sequences, which are multi-sentence descriptions of the contents of an image. These descriptions were collected in a pseudo-interactive setting, where the describer was told to describe the given image to a listener who needs to identify the image within a set of images, and who successively asks for more information. As we show, this setup produced nicely structured data that, we think, will be useful for learning models capable of planning and realising such description discourses."
P19-1063,Know What You Don{'}t Know: Modeling a Pragmatic Speaker that Refers to Objects of Unknown Categories,2019,0,1,1,1,1567,sina zarriess,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Zero-shot learning in Language {\&} Vision is the task of correctly labelling (or naming) objects of novel categories. Another strand of work in L{\&}V aims at pragmatically informative rather than {``}correct{''} object descriptions, e.g. in reference games. We combine these lines of research and model zero-shot reference games, where a speaker needs to successfully refer to a novel object in an image. Inspired by models of {``}rational speech acts{''}, we extend a neural generator to become a pragmatic speaker reasoning about uncertain object categories. As a result of this reasoning, the generator produces fewer nouns and names of distractor categories as compared to a literal speaker. We show that this conversational strategy for dealing with novel objects often improves communicative success, in terms of resolution accuracy of an automatic listener."
W18-6906,Being data-driven is not enough: Revisiting interactive instruction giving as a challenge for {NLG},2018,0,1,1,1,1567,sina zarriess,Proceedings of the Workshop on {NLG} for Human{--}Robot Interaction,0,"Modeling traditional NLG tasks with data-driven techniques has been a major focus of research in NLG in the past decade. We argue that existing modeling techniques are mostly tailored to textual data and are not sufficient to make NLG technology meet the requirements of agents which target fluid interaction and collaboration in the real world. We revisit interactive instruction giving as a challenge for datadriven NLG and, based on insights from previous GIVE challenges, propose that instruction giving should be addressed in a setting that involves visual grounding and spoken language. These basic design decisions will require NLG frameworks that are capable of monitoring their environment as well as timing and revising their verbal output. We believe that these are core capabilities for making NLG technology transferrable to interactive systems."
W18-6547,The Task Matters: Comparing Image Captioning and Task-Based Dialogical Image Description,2018,0,2,2,1,14068,nikolai ilinykh,Proceedings of the 11th International Conference on Natural Language Generation,0,"Image captioning models are typically trained on data that is collected from people who are asked to describe an image, without being given any further task context. As we argue here, this context independence is likely to cause problems for transferring to task settings in which image description is bound by task demands. We demonstrate that careful design of data collection is required to obtain image descriptions which are contextually bounded to a particular meta-level task. As a task, we use MeetUp!, a text-based communication game where two players have the goal of finding each other in a visual environment. To reach this goal, the players need to describe images representing their current location. We analyse a dataset from this domain and show that the nature of image descriptions found in MeetUp! is diverse, dynamic and rich with phenomena that are not present in descriptions obtained through a simple image captioning task, which we ran for comparison."
W18-6563,Decoding Strategies for Neural Referring Expression Generation,2018,0,2,1,1,1567,sina zarriess,Proceedings of the 11th International Conference on Natural Language Generation,0,"RNN-based sequence generation is now widely used in NLP and NLG (natural language generation). Most work focusses on how to train RNNs, even though also decoding is not necessarily straightforward: previous work on neural MT found seq2seq models to radically prefer short candidates, and has proposed a number of beam search heuristics to deal with this. In this work, we assess decoding strategies for referring expression generation with neural models. Here, expression length is crucial: output should neither contain too much or too little information, in order to be pragmatically adequate. We find that most beam search heuristics developed for MT do not generalize well to referring expression generation (REG), and do not generally outperform greedy decoding. We observe that beam search heuristics for termination seem to override the model{'}s knowledge of what a good stopping point is. Therefore, we also explore a recent approach called trainable decoding, which uses a small network to modify the RNN{'}s hidden state for better decoding results. We find this approach to consistently outperform greedy decoding for REG."
W17-5529,Beyond On-hold Messages: Conversational Time-buying in Task-oriented Dialogue,2017,13,3,2,0,31509,soledad gambino,Proceedings of the 18th Annual {SIG}dial Meeting on Discourse and Dialogue,0,"A common convention in graphical user interfaces is to indicate a {``}wait state{''}, for example while a program is preparing a response, through a changed cursor state or a progress bar. What should the analogue be in a spoken conversational system? To address this question, we set up an experiment in which a human information provider (IP) was given their information only in a delayed and incremental manner, which systematically created situations where the IP had the turn but could not provide task-related information. Our data analysis shows that 1) IPs bridge the gap until they can provide information by re-purposing a whole variety of task- and grounding-related communicative actions (e.g. echoing the user{'}s request, signaling understanding, asserting partially relevant information), rather than being silent or explicitly asking for time (e.g. {``}please wait{''}), and that 2) IPs combined these actions productively to ensure an ongoing conversation. These results, we argue, indicate that natural conversational interfaces should also be able to manage their time flexibly using a variety of conversational resources."
W17-3509,Refer-i{TTS}: A System for Referring in Spoken Installments to Objects in Real-World Images,2017,10,0,1,1,1567,sina zarriess,Proceedings of the 10th International Conference on Natural Language Generation,0,"Current referring expression generation systems mostly deliver their output as one-shot, written expressions. We present on-going work on incremental generation of spoken expressions referring to objects in real-world images. This approach extends upon previous work using the words-as-classifier model for generation. We implement this generator in an incremental dialogue processing framework such that we can exploit an existing interface to incremental text-to-speech synthesis. Our system generates and synthesizes referring expressions while continuously observing non-verbal user reactions."
W17-3516,The {C}ode2{T}ext Challenge: Text Generation in Source Libraries,2017,21,1,2,0,3542,kyle richardson,Proceedings of the 10th International Conference on Natural Language Generation,0,"We propose a new shared task for tactical data-to-text generation in the domain of source code libraries. Specifically, we focus on text generation of function descriptions from example software projects. Data is drawn from existing resources used for studying the related problem of semantic parser induction, and spans a wide variety of both natural languages and programming languages. In this paper, we describe these existing resources, which will serve as training and development data for the task, and discuss plans for building new independent test sets."
P17-1023,Obtaining referential word meanings from visual and distributional information: Experiments on object naming,2017,29,4,1,1,1567,sina zarriess,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We investigate object naming, which is an important sub-task of referring expression generation on real-world images. As opposed to mutually exclusive labels used in object recognition, object names are more flexible, subject to communicative preferences and semantically related to each other. Therefore, we investigate models of referential word meaning that link visual to lexical information which we assume to be given through distributional word embeddings. We present a model that learns individual predictors for object names that link visual and distributional aspects of word meaning during training. We show that this is particularly beneficial for zero-shot learning, as compared to projecting visual objects directly into the distributional space. In a standard object naming task, we find that different ways of combining lexical and visual information achieve very similar performance, though experiments on model combination suggest that they capture complementary aspects of referential meaning."
E17-2014,"Is this a Child, a Girl or a Car? Exploring the Contribution of Distributional Similarity to Learning Referential Word Meanings",2017,0,6,1,1,1567,sina zarriess,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",0,"There has recently been a lot of work trying to use images of referents of words for improving vector space meaning representations derived from text. We investigate the opposite direction, as it were, trying to improve visual word predictors that identify objects in images, by exploiting distributional similarity information during training. We show that for certain words (such as entry-level nouns or hypernyms), we can indeed learn better referential word meanings by taking into account their semantic similarity to other words. For other words, there is no or even a detrimental effect, compared to a learning setup that presents even semantically related objects as negative instances."
D17-1100,Deriving continous grounded meaning representations from referentially structured multimodal contexts,2017,22,0,1,1,1567,sina zarriess,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"Corpora of referring expressions paired with their visual referents are a good source for learning word meanings directly grounded in visual representations. Here, we explore additional ways of extracting from them word representations linked to multi-modal context: through expressions that refer to the same object, and through expressions that refer to different objects in the same scene. We show that continuous meaning representations derived from these contexts capture complementary aspects of similarity, , even if not outperforming textual embeddings trained on very large amounts of raw text when tested on standard similarity benchmarks. We propose a new task for evaluating grounded meaning representations{---}detection of potentially co-referential phrases{---}and show that it requires precise denotational representations of attribute meanings, which our method provides."
W16-6642,Towards Generating Colour Terms for Referents in Photographs: Prefer the Expected or the Unexpected?,2016,22,3,1,1,1567,sina zarriess,Proceedings of the 9th International Natural Language Generation conference,0,None
P16-1058,Easy Things First: Installments Improve Referring Expression Generation for Objects in Photographs,2016,33,6,1,1,1567,sina zarriess,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,None
P16-1115,Resolving References to Objects in Photographs using the Words-As-Classifiers Model,2016,29,6,2,0,4242,david schlangen,Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"A common use of language is to refer to visually present objects. Modelling it in computers requires modelling the link between language and perception. The xe2x80x9cwords as classifiersxe2x80x9d model of grounded semantics views words as classifiers of perceptual contexts, and composes the meaning of a phrase through composition of the denotations of its component words. It was recently shown to perform well in a game-playing scenario with a small number of object types. We apply it to two large sets of real-world photographs that contain a much larger variety of object types and for which referring expressions are available. Using a pre-trained convolutional neural network to extract image region features, and augmenting these with positional information, we show that the model achieves performance competitive with the state of the art in a reference resolution task (given expression, find bounding box of its referent), while, as we argue, being conceptually simpler and more flexible."
L16-1019,{P}ento{R}ef: A Corpus of Spoken References in Task-oriented Dialogues,2016,17,9,1,1,1567,sina zarriess,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"PentoRef is a corpus of task-oriented dialogues collected in systematically manipulated settings. The corpus is multilingual, with English and German sections, and overall comprises more than 20000 utterances. The dialogues are fully transcribed and annotated with referring expressions mapped to objects in corresponding visual scenes, which makes the corpus a rich resource for research on spoken referring expressions in generation and resolution. The corpus includes several sub-corpora that correspond to different dialogue situations where parameters related to interactivity, visual access, and verbal channel have been manipulated in systematic ways. The corpus thus lends itself to very targeted studies of reference in spontaneous dialogue."
W15-4705,Reading Times Predict the Quality of Generated Text Above and Beyond Human Ratings,2015,34,3,1,1,1567,sina zarriess,Proceedings of the 15th {E}uropean Workshop on Natural Language Generation ({ENLG}),0,"Typically, human evaluation of NLG output is based on user ratings. We collected ratings and reading time data in a simple, low-cost experimental paradigm for text generation. Participants were presented corpus texts, automatically linearised texts, and texts containing predicted referring expressions and automatic linearisation. We demonstrate that the reading time metrics outperform the ratings in classifying texts according to their quality. Regression analyses showed that self-reported ratings discriminated poorly between the kinds of manipulation, especially between defects in word order and text coherence. In contrast, a combination of objective measures from the low-cost mouse contingent reading paradigm provided very high classification accuracy and thus, greater insight into the actual quality of an automatically generated text."
W13-3608,{LFG}-based Features for Noun Number and Article Grammatical Errors,2013,10,6,3,0,1666,gabor berend,Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task,0,We introduce here a participating system of the CoNLL-2013 Shared Task xe2x80x9cGrammatical Error Correctionxe2x80x9d. We focused on the noun number and article error categories and constructed a supervised learning system for solving these tasks. We carried out feature engineering and we found that (among others) the f-structure of an LFG parser can provide very informative features for the machine learning system.
W13-2130,An Automatic Method for Building a Data-to-Text Generator,2013,2,3,1,1,1567,sina zarriess,Proceedings of the 14th {E}uropean Workshop on Natural Language Generation,0,"We describe our contribution to the Generating from Knowledge Bases (KBgen) challenge. Our system is learned in a bottom-up fashion, by inducing a probabilistic grammar that represents alignments between strings and parts of a knowledge graph. From these alignments, we extract information about the linearization and lexical choices associated with the target knowledge base, and build a simple generate-and-rank system in the style of (Langkilde and Knight, 1998).1"
P13-1152,Combining Referring Expression Generation and Surface Realization: A Corpus-Based Investigation of Architectures,2013,39,8,1,1,1567,sina zarriess,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We suggest a generation task that integrates discourse-level referring expression generation and sentence-level surface realization. We present a data set of German articles annotated with deep syntax and referents, including some types of implicit referents. Our experiments compare several architectures varying the order of a set of trainable modules. The results suggest that a revision-based pipeline, with intermediate linearization, significantly outperforms standard pipelines or a parallel architecture."
ziering-etal-2012-corpus,A Corpus-based Study of the {G}erman Recipient Passive,2012,15,0,2,0,32558,patrick ziering,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper, we investigate the usage of a non-canonical German passive alternation for ditransitive verbs, the recipient passive, in naturally occuring corpus data. We propose a classifier that predicts the voice of a ditransitive verb based on the contextually determined properties its arguments. As the recipient passive is a low frequent phenomenon, we first create a special data set focussing on German ditransitive verbs which are frequently used in the recipient passive. We use a broad-coverage grammar-based parser, the German LFG parser, to automatically annotate our data set for the morpho-syntactic properties of the involved predicate arguments. We train a Maximum Entropy classifier on the automatically annotated sentences and achieve an accuracy of 98.05{\%}, clearly outperforming the baseline that always predicts active voice baseline (94.6{\%})."
E12-1078,To what extent does sentence-internal realisation reflect discourse context? A study on word order,2012,24,2,1,1,1567,sina zarriess,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"We compare the impact of sentence-internal vs. sentence-external features on word order prediction in two generation settings: starting out from a discriminative surface realisation ranking model for an LFG grammar of German, we enrich the feature set with lexical chain features from the discourse context which can be robustly detected and reflect rough grammatical correlates of notions from theoretical approaches to discourse coherence. In a more controlled setting, we develop a constituent ordering classifier that is trained on a German treebank with gold coreference annotation. Surprisingly, in both settings, the sentence-external features perform poorly compared to the sentence-internal ones, and do not improve over a baseline model capturing the syntactic functions of the constituents."
D12-1085,Generating Non-Projective Word Order in Statistical Linearization,2012,33,5,5,0,16528,bernd bohnet,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"We propose a technique to generate non-projective word orders in an efficient statistical linearization system. Our approach predicts liftings of edges in an unordered syntactic tree by means of a classifier, and uses a projective algorithm for tree linearization. We obtain statistically significant improvements on six typologically different languages: English, German, Dutch, Danish, Hungarian, and Czech."
P11-1101,Underspecifying and Predicting Voice for Surface Realisation Ranking,2011,29,6,1,1,1567,sina zarriess,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"This paper addresses a data-driven surface realisation model based on a large-scale reversible grammar of German. We investigate the relationship between the surface realisation performance and the character of the input to generation, i.e. its degree of underspecification. We extend a syntactic surface realisation system, which can be trained to choose among word order variants, such that the candidate set includes active and passive variants. This allows us to study the interaction of voice and word order alternations in realistic German corpus data. We show that with an appropriately underspecified input, a linguistically informed realisation model trained to regenerate strings from the underlying semantic representation achieves 91.5% accuracy (over a baseline of 82.5%) in the prediction of the original voice."
W10-2106,A Cross-Lingual Induction Technique for {G}erman Adverbial Participles,2010,10,2,1,1,1567,sina zarriess,Proceedings of the 2010 Workshop on {NLP} and Linguistics: Finding the Common Ground,0,"We provide a detailed comparison of strategies for implementing medium-to-low frequency phenomena such as German adverbial participles in a broad-coverage, rule-based parsing system. We show that allowing for general adverb conversion of participles in the German LFG grammar seriously affects its overall performance, due to increased spurious ambiguity. As a solution, we present a corpus-based cross-lingual induction technique that detects adverbially used participles in parallel text. In a grammar-based evaluation, we show that the automatically induced resource appropriately restricts the adverb conversion to a limited class of participles, and improves parsing quantitatively as well as qualitatively."
dione-etal-2010-design,"Design and Development of Part-of-Speech-Tagging Resources for {W}olof ({N}iger-{C}ongo, spoken in {S}enegal)",2010,-1,-1,3,0,5821,cheikh dione,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we report on the design of a part-of-speech-tagset for Wolof and on the creation of a semi-automatically annotated gold standard. In order to achieve high-quality annotation relatively fast, we first generated an accurate lexicon that draws on existing word and name lists and takes into account inflectional and derivational morphology. The main motivation for the tagged corpus is to obtain data for training automatic taggers with machine learning approaches. Hence, we took machine learning considerations into account during tagset design and we present training experiments as part of this paper. The best automatic tagger achieves an accuracy of 95.2{\%} in cross-validation experiments. We also wanted to create a basis for experimenting with annotation projection techniques, which exploit parallel corpora. For this reason, it was useful to use a part of the Bible as the gold standard corpus, for which sentence-aligned parallel versions in many languages are easy to obtain. We also report on preliminary experiments exploiting a statistical word alignment of the parallel text."
C10-2163,Cross-Lingual Induction for Deep Broad-Coverage Syntax: A Case Study on {G}erman Participles,2010,11,0,1,1,1567,sina zarriess,Coling 2010: Posters,0,"This paper is a case study on cross-lingual induction of lexical resources for deep, broad-coverage syntactic analysis of German. We use a parallel corpus to induce a classifier for German participles which can predict their syntactic category. By means of this classifier, we induce a resource of adverbial participles from a huge monolingual corpus of German. We integrate the resource into a German LFG grammar and show that it improves parsing coverage while maintaining accuracy."
W09-2904,Exploiting Translational Correspondences for Pattern-Independent {MWE} Identification,2009,14,20,1,1,1567,sina zarriess,"Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications ({MWE} 2009)",0,"Based on a study of verb translations in the Europarl corpus, we argue that a wide range of MWE patterns can be identified in translations that exhibit a correspondence between a single lexical item in the source language and a group of lexical items in the target language. We show that these correspondences can be reliably detected on dependency-parsed, word-aligned sentences. We propose an extraction method that combines word alignment with syntactic filters and is independent of the structural pattern of the translation."
W09-2602,Developing {G}erman Semantics on the basis of Parallel {LFG} Grammars,2009,16,4,1,1,1567,sina zarriess,Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks ({GEAF} 2009),0,"This paper reports on the development of a core semantics for German which was implemented on the basis of an English semantics that converts LFG f-structures to flat meaning representations in a Neo-Davidsonian style. Thanks to the parallel design of the broad-coverage LFG grammars written in the context of the ParGram project (Butt et al., 2002) and the general surface independence of LFG f-structure analyses, the development process was substantially facilitated. We also discuss the overall architecture of the semantic conversion system from a crosslinguistic, theoretical perspective."
W06-2108,A Conceptual Analysis of the Notion of Instrumentality via a Multilingual Analysis,2006,0,0,8,0,44122,asanee kawtrakul,Proceedings of the Third {ACL}-{SIGSEM} Workshop on Prepositions,0,None
