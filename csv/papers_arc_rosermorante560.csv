2021.latechclfl-1.1,The Early {M}odern {D}utch Mediascape. Detecting Media Mentions in Chronicles Using Word Embeddings and {CRF},2021,-1,-1,2,0,5464,alie lassche,"Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature",0,"While the production of information in the European early modern period is a well-researched topic, the question how people were engaging with the information explosion that occurred in early modern Europe, is still underexposed. This paper presents the annotations and experiments aimed at exploring whether we can automatically extract media related information (source, perception, and receiver) from a corpus of early modern Dutch chronicles in order to get insight in the mediascape of early modern middle class people from a historic perspective. In a number of classification experiments with Conditional Random Fields, three categories of features are tested: (i) raw and binary word embedding features, (ii) lexicon features, and (iii) character features. Overall, the classifier that uses raw embeddings performs slightly better. However, given that the best F-scores are around 0.60, we conclude that the machine learning approach needs to be combined with a close reading approach for the results to be useful to answer history research questions."
2021.argmining-1.5,Is Stance Detection Topic-Independent and Cross-topic Generalizable? - A Reproduction Study,2021,-1,-1,3,0,2837,myrthe reuver,Proceedings of the 8th Workshop on Argument Mining,0,"Cross-topic stance detection is the task to automatically detect stances (pro, against, or neutral) on unseen topics. We successfully reproduce state-of-the-art cross-topic stance detection work (Reimers et. al, 2019), and systematically analyze its reproducibility. Our attention then turns to the cross-topic aspect of this work, and the specificity of topics in terms of vocabulary and socio-cultural context. We ask: To what extent is stance detection topic-independent and generalizable across topics? We compare the model{'}s performance on various unseen topics, and find topic (e.g. abortion, cloning), class (e.g. pro, con), and their interaction affecting the model{'}s performance. We conclude that investigating performance on different topics, and addressing topic-specific vocabulary and context, is a future avenue for cross-topic stance detection. References Nils Reimers, Benjamin Schiller, Tilman Beck, Johannes Daxenberger, Christian Stab, and Iryna Gurevych. 2019. Classification and Clustering of Arguments with Contextualized Word Embeddings. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 567{--}578, Florence, Italy. Association for Computational Linguistics."
2020.lrec-1.611,Annotating Perspectives on Vaccination,2020,-1,-1,1,1,5465,roser morante,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper we present the Vaccination Corpus, a corpus of texts related to the online vaccination debate that has been annotated with three layers of information about perspectives: attribution, claims and opinions. Additionally, events related to the vaccination debate are also annotated. The corpus contains 294 documents from the Internet which reflect different views on vaccinations. It has been compiled to study the language of online debates, with the final goal of experimenting with methodologies to extract and contrast perspectives in the framework of the vaccination debate."
2020.lrec-1.703,Must Children be Vaccinated or not? Annotating Modal Verbs in the Vaccination Debate,2020,-1,-1,2,0,18045,liza king,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this paper we analyze the use of modal verbs in a corpus of texts related to the vaccination debate. Broadly speaking, the vaccination debate centers around whether vaccination is safe, and whether it is morally acceptable to enforce mandatory vaccination. In order to successfully intervene and curb the spread of preventable diseases due to low vaccination rates, health practitioners need to be adequately informed on public perception of the safety and necessity of vaccines. Public perception can relate to the strength of conviction that an individual may have towards a proposition (e.g. {`}one must vaccinate{'} versus {`}one should vaccinate{'}), as well as qualify the type of proposition, be it related to morality ({`}government should not interfere in my personal choice{'}) or related to possibility ({`}too many vaccines at once could hurt my child{'}). Text mining and analysis of modal auxiliaries are economically viable means of gaining insights into these perspectives, particularly on a large scale due to the widespread use of social media and blogs as vehicles of communication."
2020.lrec-1.853,Detecting Negation Cues and Scopes in {S}panish,2020,-1,-1,2,0.958297,18300,salud jimenezzafra,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this work we address the processing of negation in Spanish. We first present a machine learning system that processes negation in Spanish. Specifically, we focus on two tasks: i) negation cue detection and ii) scope identification. The corpus used in the experimental framework is the SFU Corpus. The results for cue detection outperform state-of-the-art results, whereas for scope detection this is the first system that performs the task for Spanish. Moreover, we provide a qualitative error analysis aimed at understanding the limitations of the system and showing which negation cues and scopes are straightforward to predict automatically, and which ones are challenging."
2020.law-1.2,Provenance for Linguistic Corpora through Nanopublications,2020,-1,-1,4,0,18497,timo lek,Proceedings of the 14th Linguistic Annotation Workshop,0,"Research in Computational Linguistics is dependent on text corpora for training and testing new tools and methodologies. While there exists a plethora of annotated linguistic information, these corpora are often not interoperable without significant manual work. Moreover, these annota-tions might have evolved into different versions, making it challenging for researchers to know the data{'}s provenance. This paper addresses this issue with a case study on event annotated corpora and by creating a new, more interoperable representation of this data in the form of nanopublications. We demonstrate how linguistic annotations from separate corpora can be reliably linked from the start, and thereby be accessed and queried as if they were a single dataset. We describe how such nanopublications can be created and demonstrate how SPARQL queries can be performed to extract interesting content from the new representations. The queries show that information of multiple corpora can be retrieved more easily and effectively because the information of different corpora is represented in a uniform data format."
2020.cl-1.5,Corpora Annotated with Negation: An Overview,2020,71,0,2,0.958297,18300,salud jimenezzafra,Computational Linguistics,0,"Negation is a universal linguistic phenomenon with a great qualitative impact on natural language processing applications. The availability of corpora annotated with negation is essential to training negation processing systems. Currently, most corpora have been annotated for English, but the presence of languages other than English on the Internet, such as Chinese or Spanish, is greater every day. In this study, we present a review of the corpora annotated with negation information in several languages with the goal of evaluating what aspects of negation have been annotated and how compatible the corpora are. We conclude that it is very difficult to merge the existing corpora because we found differences in the annotation schemes used, and most importantly, in the annotation guidelines: the way in which each corpus was tokenized and the negation elements that have been annotated. Differently than for other well established tasks like semantic role labeling or parsing, for negation there is no standard annotation scheme nor guidelines, which hampers progress in its treatment."
W18-5207,Annotating Claims in the Vaccination Debate,2018,0,0,2,0,28008,benedetta torsi,Proceedings of the 5th Workshop on Argument Mining,0,"In this paper we present annotation experiments with three different annotation schemes for the identification of argument components in texts related to the vaccination debate. Identifying claims about vaccinations made by participants in the debate is of great societal interest, as the decision to vaccinate or not has impact in public health and safety. Since most corpora that have been annotated with argumentation information contain texts that belong to a specific genre and have a well defined argumentation structure, we needed to adjust the annotation schemes to our corpus, which contains heterogeneous texts from the Web. We started with a complex annotation scheme that had to be simplified due to low IAA. In our final experiment, which focused on annotating claims, annotators reached 57.3{\%} IAA."
L18-1051,Systems{'} Agreements and Disagreements in Temporal Processing: An Extensive Error Analysis of the {T}emp{E}val-3 Task,2018,0,0,2,0,6,tommaso caselli,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"In this article we review Temporal Processing systems that participated in the TempEval-3 task as a basis to develop our own system, that we also present and release. The system incorporates high level lexical semantic features, obtaining the best scores for event detection (F1-Class 72.24) and second best result for temporal relation classification from raw text (F1 29.69) when evaluated on the TempEval-3 data. Additionally, we analyse the errors of all TempEval-3 systems for which the output is publicly available with the purpose of finding out what are the weaknesses of current approaches. Although incorporating lexical semantics features increases the performance of our system, the error analysis shows that systems should incorporate inference mechanisms and world knowledge, as well as having strategies to compensate for data skewness."
L18-1178,Resource Interoperability for Sustainable Benchmarking: The Case of Events,2018,0,1,3,1,17878,chantal son,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
C18-1078,A review of {S}panish corpora annotated with negation,2018,0,1,2,0.958297,18300,salud jimenezzafra,Proceedings of the 27th International Conference on Computational Linguistics,0,"The availability of corpora annotated with negation information is essential to develop negation processing systems in any language. However, there is a lack of these corpora even for languages like English, and when there are corpora available they are small and the annotations are not always compatible across corpora. In this paper we review the existing corpora annotated with negation in Spanish with the purpose of first, gathering the information to make it available for other researchers and, second, analyzing how compatible are the corpora and how has the linguistic phenomenon been addressed. Our final aim is to develop a supervised negation processing system for Spanish, for which we need training and test data. Our analysis shows that it will not be possible to merge the small corpora existing for Spanish due to lack of compatibility in the annotations."
C18-1191,Scoring and Classifying Implicit Positive Interpretations: A Challenge of Class Imbalance,2018,0,0,2,1,17878,chantal son,Proceedings of the 27th International Conference on Computational Linguistics,0,"This paper reports on a reimplementation of a system on detecting implicit positive meaning from negated statements. In the original regression experiment, different positive interpretations per negation are scored according to their likelihood. We convert the scores to classes and report our results on both the regression and classification tasks. We show that a baseline taking the mean score or most frequent class is hard to beat because of class imbalance in the dataset. Our error analysis indicates that an approach that takes the information structure into account (i.e. which information is new or contrastive) may be promising, which requires looking beyond the syntactic and semantic characteristics of negated statements."
W17-1808,Annotating Negation in {S}panish Clinical Texts,2017,6,2,2,0,32021,noa cruz,Proceedings of the Workshop Computational Semantics Beyond Events and Roles,0,"In this paper we present on-going work on annotating negation in Spanish clinical documents. A corpus of anamnesis and radiology reports has been annotated by two domain expert annotators with negation markers and negated events. The Dice coefficient for inter-annotator agreement is higher than 0.94 for negation markers and higher than 0.72 for negated events. The corpus will be publicly released when the annotation process is finished, constituting the first corpus annotated with negation for Spanish clinical reports available for the NLP community."
W16-5007,Building a Dictionary of Affixal Negations,2016,0,1,3,1,17878,chantal son,Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics ({E}x{P}ro{M}),0,"This paper discusses the need for a dictionary of affixal negations and regular antonyms to facilitate their automatic detection in text. Without such a dictionary, affixal negations are very difficult to detect. In addition, we show that the set of affixal negations is not homogeneous, and that different NLP tasks may require different subsets. A dictionary can store the subtypes of affixal negations, making it possible to select a certain subset or to make inferences on the basis of these subtypes. We take a first step towards creating a negation dictionary by annotating all direct antonym pairs inWordNet using an existing typology of affixal negations. By highlighting some of the issues that were encountered in this annotation experiment, we hope to provide some insights into the necessary steps of building a negation dictionary."
W16-3207,Pragmatic Factors in Image Description: The Case of Negations,2016,16,2,2,0,3387,emiel miltenburg,Proceedings of the 5th Workshop on Vision and Language,0,"We provide a qualitative analysis of the descriptions containing negations (no, not, n't, nobody, etc) in the Flickr30K corpus, and a categorization of negation uses. Based on this analysis, we provide a set of requirements that an image description system should have in order to generate negation sentences. As a pilot experiment, we used our categorization to manually annotate sentences containing negations in the Flickr30K corpus, with an agreement score of K=0.67. With this paper, we hope to open up a broader discussion of subjective language in image descriptions."
W16-2819,Unshared Task at the 3rd Workshop on Argument Mining: Perspective Based Local Agreement and Disagreement in Online Debate,2016,7,0,5,1,17878,chantal son,Proceedings of the Third Workshop on Argument Mining ({A}rg{M}ining2016),0,This paper proposes a new task in argument mining in online debates. The task includes three annotations steps that result in fine-grained annotations of agreement and disagreement at a propositional level. We report on the results of a pilot annotation task on identifying sentences that are directly addressed in the comment.
S16-1193,{VUACLTL} at {S}em{E}val 2016 Task 12: A {CRF} Pipeline to Clinical {T}emp{E}val,2016,14,3,2,0.21184,6,tommaso caselli,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper describes VUACLTL, the system the CLTL Lab submitted to the SemEval 2016 Task Clinical TempEval. The system is based on a purely data-driven approach based on a cascade of seven CRF classifiers which use generic features and little domain knowledge. The challenge consisted in six subtasks related to temporal processing clinical notes from raw text (event and temporal expression detection and attribute classification, temporal relation classification between events and the Document Creation Time, and narrative container detection). The system was initially developed to process newswire texts and then re-trained to process clinical notes. This had an impact on the results, which are not equally competitive for all the subtasks."
L16-1187,{GR}a{SP}: A Multilayered Annotation Scheme for Perspectives,2016,17,3,5,1,17878,chantal son,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents a framework and methodology for the annotation of perspectives in text. In the last decade, different aspects of linguistic encoding of perspectives have been targeted as separated phenomena through different annotation initiatives. We propose an annotation scheme that integrates these different phenomena. We use a multilayered annotation approach, splitting the annotation of different aspects of perspectives into small subsequent subtasks in order to reduce the complexity of the task and to better monitor interactions between layers. Currently, we have included four layers of perspective annotation: events, attribution, factuality and opinion. The annotations are integrated in a formal model called GRaSP, which provides the means to represent instances (e.g. events, entities) and propositions in the (real or assumed) world in relation to their mentions in text. Then, the relation between the source and target of a perspective is characterized by means of perspective annotations. This enables us to place alternative perspectives on the same entity, event or proposition next to each other."
S15-2133,{SPINOZA}{\\_}{VU}: An {NLP} Pipeline for Cross Document {T}ime{L}ines,2015,13,8,3,0.21184,6,tommaso caselli,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes the system SPINOZA VU developed for the SemEval 2015 Task 4: Cross Document TimeLines. The system integrates output from the NewsReader Natural Language Processing pipeline and is designed following an entity based model. The poor performance of the submitted runs are mainly a consequence of error propagation. Nevertheless, the error analysis has shown that the interpretation module behind the system performs correctly. An out of competition version of the system has fixed some errors and obtained competitive results. Therefore, we consider the system an important step towards a more complex task such as storyline extraction."
S12-1035,*{SEM} 2012 Shared Task: Resolving the Scope and Focus of Negation,2012,23,69,1,1,5465,roser morante,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"The Joint Conference on Lexical and Computational Semantics (*SEM) each year hosts a shared task on semantic related topics. In its first edition held in 2012, the shared task was dedicated to resolving the scope and focus of negation. This paper presents the specifications, datasets and evaluation criteria of the task. An overview of participating systems is provided and their results are summarized."
N12-4006,Processing modality and negation,2012,0,1,1,1,5465,roser morante,Tutorial Abstracts at the Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"Modality and negation are ubiquitous phenomena in language. Generally speaking, modality is a grammatical category that allows to express aspects related to the speaker's attitude towards her statements in terms of degree of certainty, reliability, and subjectivity. In this tutorial modality is understood in a broad sense, which involves related concepts like subjectivity, hedging, evidentiality, uncertainty, committed belief, and factuality. Negation is a grammatical category that allows to change the truth value of a proposition. Modality and negation are treated together because they are interrelated phenomena and are protypically expressed by linguistic devices that share some formal characteristics. For example, modality and negation cues function as operators that scope over certain parts of the sentence."
morante-daelemans-2012-conandoyle,{C}onan{D}oyle-neg: Annotation of negation cues and their scope in Conan Doyle stories,2012,10,18,1,1,5465,roser morante,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper we present ConanDoyle-neg, a corpus of stories by Conan Doyle annotated with negation information. The negation cues and their scope, as well as the event or property that is negated have been annotated by two annotators. The inter-annotator agreement is measured in terms of F-scores at scope level. It is higher for cues (94.88 and 92.77), less high for scopes (85.04 and 77.31), and lower for the negated event (79.23 and 80.67). The corpus is publicly available."
kestemont-etal-2012-netlog,The Netlog Corpus. A Resource for the Study of {F}lemish {D}utch {I}nternet Language,2012,0,3,6,0,1954,mike kestemont,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Although in recent years numerous forms of Internet communication â such as e-mail, blogs, chat rooms and social network environments â have emerged, balanced corpora of Internet speech with trustworthy meta-information (e.g. age and gender) or linguistic annotations are still limited. In this paper we present a large corpus of Flemish Dutch chat posts that were collected from the Belgian online social network Netlog. For all of these posts we also acquired the users' profile information, making this corpus a unique resource for computational and sociolinguistic research. However, for analyzing such a corpus on a large scale, NLP tools are required for e.g. automatic POS tagging or lemmatization. Because many NLP tools fail to correctly analyze the surface forms of chat language usage, we propose to normalize this Âanomalous' input into a format suitable for existing NLP solutions for standard Dutch. Additionally, we have annotated a substantial part of the corpus (i.e. the Chatty subset) to provide a gold standard for the evaluation of future approaches to automatic (Flemish) chat language normalization."
J12-2001,Modality and Negation: An Introduction to the Special Issue,2012,118,84,1,1,5465,roser morante,Computational Linguistics,0,"Traditionally, most research in NLP has focused on propositional aspects of meaning. To truly understand language, however, extra-propositional aspects are equally important. Modality and negation typically contribute significantly to these extra-propositional meaning aspects. Although modality and negation have often been neglected by mainstream computational linguistics, interest has grown in recent years, as evidenced by several annotation projects dedicated to these phenomena. Researchers have started to work on modeling factuality, belief and certainty, detecting speculative sentences and hedging, identifying contradictions, and determining the scope of expressions of modality and negation. In this article, we will provide an overview of how modality and negation have been modeled in computational linguistics."
D12-1053,A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories,2012,27,25,3,0,38992,mathias verbeke,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,"Evidence-based medicine is an approach whereby clinical decisions are supported by the best available findings gained from scientific research. This requires efficient access to such evidence. To this end, abstracts in evidence-based medicine can be labeled using a set of predefined medical categories, the so-called PICO criteria. This paper presents an approach to automatically annotate sentences in medical abstracts with these labels. Since both structural and sequential information are important for this classification task, we use kLog, a new language for statistical relational learning with kernels. Our results show a clear improvement with respect to state-of-the-art systems."
W11-0141,Corpus-based approaches to processing the scope of negation cues: an evaluation of the state of the art,2011,24,8,1,1,5465,roser morante,Proceedings of the Ninth International Conference on Computational Semantics ({IWCS} 2011),0,"In this paper we summarize existing work on the recently introduced task of processing the scope of negation and modality cues; we analyse the scope model that existing systems can process, which is mainly the model reflected in the annotations of the biomedical corpus on which the systems have been trained; and we point out aspects of the scope finding task that would be different based on observations from a corpus from a different domain and nature."
W10-3006,Memory-Based Resolution of In-Sentence Scopes of Hedge Cues,2010,21,33,1,1,5465,roser morante,Proceedings of the Fourteenth Conference on Computational Natural Language Learning {--} Shared Task,0,"In this paper we describe the machine learning systems that we submitted to the CoNLL-2010 Shared Task on Learning to Detect Hedges and Their Scope in Natural Language Text. Task 1 on detecting uncertain information was performed by an SVM-based system to process the Wikipedia data and by a memory-based system to process the biological data. Task 2 on resolving in-sentence scopes of hedge cues, was performed by a memorybased system that relies on information from syntactic dependencies. This system scored the highest F1 (57.32) of Task 2."
W10-1916,Semantic Role Labeling of Gene Regulation Events: Preliminary Results,2010,6,0,1,1,5465,roser morante,Proceedings of the 2010 Workshop on Biomedical Natural Language Processing,0,This abstract describes work in progress on semantic role labeling of gene regulation events. We present preliminary results of a supervised semantic role labeler that has been trained and tested on the GREC corpus.
S10-1008,{S}em{E}val-2010 Task 10: Linking Events and Their Participants in Discourse,2010,6,67,3,0.606061,3382,josef ruppenhofer,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"We describe the SemEval-2010 shared task on Linking Events and Their Participants in Discourse. This task is an extension to the classical semantic role labeling task. While semantic role labeling is traditionally viewed as a sentence-internal task, local semantic argument structures clearly interact with each other in a larger context, e.g., by sharing references to specific discourse entities or events. In the shared task we looked at one particular aspect of cross-sentence links between argument structures, namely linking locally uninstantiated roles to their co-referents in the wider discourse context (if such co-referents exist). This task is potentially beneficial for a number of NLP applications, such as information extraction, question answering or text summarization."
morante-2010-descriptive,Descriptive Analysis of Negation Cues in Biomedical Texts,2010,16,22,1,1,5465,roser morante,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper we present a description of negation cues and their scope in biomedical texts, based on the cues that occur in the BioScope corpus. We provide information about the morphological type of the cue, the characteristics of the scope in relation to the morpho-syntactic features of the cue and of the clause, and the ambiguity level of the cue by describing in which cases certain negation cues do not express negation. Additionally, we provide positive and negative examples per cue from the BioScope corpus. We show that the scope depends mostly on the part-of-speech of the cue and on the syntactic features of the clause. Although several studies have focused on processing negation in biomedical texts, we are not aware of publicly available resources that describe the scope of negation cues in detail. This paper aims at providing information for producing guidelines to annotate corpora with a negation layer, and for building resources that find the scope of negation cues automatically."
W09-2417,{S}em{E}val-2010 Task 10: Linking Events and Their Participants in Discourse,2009,18,19,3,0.606061,3382,josef ruppenhofer,Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions ({SEW}-2009),0,"In this paper, we describe the SemEval-2010 shared task on Linking Events and Their Participants in Discourse. This task is a variant of the classical semantic role labelling task. The novel aspect is that we focus on linking local semantic argument structures across sentence boundaries. Specifically, the task aims at linking locally uninstantiated roles to their co-referents in the wider discourse context (if such co-referents exist). This task is potentially beneficial for a number of NLP applications and we hope that it will not only attract researchers from the semantic role labelling community but also from co-reference resolution and information extraction."
W09-1408,A memory-based learning approach to event extraction in biomedical texts,2009,20,8,1,1,5465,roser morante,Proceedings of the {B}io{NLP} 2009 Workshop Companion Volume for Shared Task,0,In this paper we describe the memory-based machine learning system that we submitted to the BioNLP Shared Task on Event Extraction. We modeled the event extraction task using an approach that has been previously applied to other natural language processing tasks like semantic role labeling or negation scope finding. The results obtained by our system (30.58 F-score in Task 1 and 29.27 in Task 2) suggest that the approach and the system need further adaptation to the complexity involved in extracting biomedical events.
W09-1304,Learning the Scope of Hedge Cues in Biomedical Texts,2009,25,102,1,1,5465,roser morante,Proceedings of the {B}io{NLP} 2009 Workshop,0,"Identifying hedged information in biomedical literature is an important subtask in information extraction because it would be misleading to extract speculative information as factual information. In this paper we present a machine learning system that finds the scope of hedge cues in biomedical texts. The system is based on a similar system that finds the scope of negation cues. We show that the same scope finding approach can be applied to both negation and hedging. To investigate the robustness of the approach, the system is tested on the three subcorpora of the BioScope corpus that represent different text types."
W09-1203,Joint Memory-Based Learning of Syntactic and Semantic Dependencies in Multiple Languages,2009,8,11,1,1,5465,roser morante,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL} 2009): Shared Task,0,"In this paper we present a system submitted to the CoNLL Shared Task 2009 performing the identification and labeling of syntactic and semantic dependencies in multiple languages. Dependencies are truly jointly learned, i.e. as if they were a single task. The system works in two phases: a classification phase in which three classifiers predict different types of information, and a ranking phase in which the output of the classifiers is combined."
W09-1105,A Metalearning Approach to Processing the Scope of Negation,2009,18,93,1,1,5465,roser morante,Proceedings of the Thirteenth Conference on Computational Natural Language Learning ({C}o{NLL}-2009),0,"Finding negation signals and their scope in text is an important subtask in information extraction. In this paper we present a machine learning system that finds the scope of negation in biomedical texts. The system combines several classifiers and works in two phases. To investigate the robustness of the approach, the system is tested on the three subcorpora of the BioScope corpus representing different text types. It achieves the best results to date for this task, with an error reduction of 32.07% compared to current state of the art results."
R09-1051,Dependency Parsing and Semantic Role Labeling as a Single Task,2009,17,2,1,1,5465,roser morante,Proceedings of the International Conference {RANLP}-2009,0,"We present a comparison between two systems for establishing syntactic and semantic dependencies: one that performs dependency parsing and semantic role labeling as a single task, and another that performs the two tasks in isolation. The systems are based on local memorybased classiers predicting syntactic and semantic dependency relations between pairs of words. In a second global phase, the systems perform a deterministic ranking procedure in which the output of the local classiers is combined per sentence into a dependency graph and semantic role labeling assignments for all predicates. The comparison shows that in the learning phase a joint approach produces better-scoring classiers, while after the ranking phase the isolated approach produces the most accurate syntactic dependencies, while the joint approach yields the most accurate semantic role assignments."
W08-2128,A Combined Memory-Based Semantic Role Labeler of {E}nglish,2008,14,14,1,1,5465,roser morante,{C}o{NLL} 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,0,"We describe the system submitted to the closed challenge of the CoNLL-2008 shared task on joint parsing of syntactic and semantic dependencies. Syntactic dependencies are processed with the Malt-Parser 0.4. Semantic dependencies are processed with a combination of memory-based classifiers. The system achieves 78.43 labeled macro F1 for the complete problem, 86.07 labeled attachment score for syntactic dependencies, and 70.51 labeled F1 for semantic dependencies."
W08-1129,{CNTS}: Memory-Based Learning of Generating Repeated References,2008,6,1,4,1,16715,iris hendrickx,Proceedings of the Fifth International Natural Language Generation Conference,0,"In this paper we describe our machine learning approach to the generation of referring expressions. As our algorithm we use memory-based learning. Our results show that in case of predicting the TYPE of the expression, having one general classifier gives the best results. On the contrary, when predicting the full set of properties of an expression, a combined set of specialized classifiers for each subdomain gives the best performance."
morante-2008-semantic,Semantic Role Labeling Tools Trained on the {C}ast3{LB}-{C}o{NNL}-{S}em{R}ol Corpus,2008,22,4,1,1,5465,roser morante,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"In this paper we present the Cast3LB-CoNLL-SemRol corpus, currently the only corpus of Spanish annotated with dependency syntax and semantic roles, and the tools that have been trained on the corpus: an ensemble of parsers and two dependency-based semantic role labelers that are the only semantic role labelers based on dependency syntax available for Spanish at this moment. One of the systems uses information from gold standard syntax, whereas the other one uses information from predicted syntax. The results of the first system (86 F1) are comparable to current state of the art results for constituent-based semantic role labeling of Spanish. The results of the second are 11 points lower. This work has been carried out as part of the project T{\'e}cnicas semiautom{\'a}ticas para el etiquetado de roles sem{\'a}nticos en corpus del espa{\~n}ol."
D08-1075,Learning the Scope of Negation in Biomedical Texts,2008,24,68,1,1,5465,roser morante,Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we present a machine learning system that finds the scope of negation in biomedical texts. The system consists of two memory-based engines, one that decides if the tokens in a sentence are negation signals, and another that finds the full scope of these negation signals. Our approach to negation detection differs in two main aspects from existing research on negation. First, we focus on finding the scope of negation signals, instead of determining whether a term is negated or not. Second, we apply supervised machine learning techniques, whereas most existing systems apply rule-based algorithms. As far as we know, this way of approaching the negation scope finding task is novel."
W07-2449,Dialogue Simulation and Context Dynamics for Dialogue Management,2007,6,5,2,0,16749,simon keizer,Proceedings of the 16th Nordic Conference of Computational Linguistics ({NODALIDA} 2007),0,"In this paper we describe DISCUS, a research tool for developing a context model and update algorithm for dialogue management. The model builds on Dynamic Interpretation Theory (DIT), in which dialogue is modelled in terms of dialogue acts operating on the information state of the dialogue participants. On the basis of dialogue act specifications of both system and user utterances, DISCUS performs the update of the systemxe2x80x99s context model. The context model is structured into several components and contains complex elements involving the beliefs and goals of both system and user. We will present simulations of two dialogues, one for demonstrating the context update model, and another in which the system utterances are generated automatically."
S07-1038,{ILK}2: Semantic Role Labeling of {C}atalan and {S}panish using {T}i{MBL},2007,8,6,1,1,5465,roser morante,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper we present a semantic role labeling system submitted to the task Multi-level Semantic Annotation of Catalan and Spanish in the context of SemEval-2007. The core of the system is a memory-based classifier that makes use of full syntactic information. Building on standard features, we train two classifiers to predict separately the semantic class of the verb and the semantic roles."
S07-1039,{ILK}: Machine learning of semantic relations with shallow features and almost no data,2007,14,8,2,0,16715,iris hendrickx,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"This paper summarizes our approach to the Semeval 2007 shared task on Classification of Semantic Relations between Nominals. Our overall strategy is to develop machine-learning classifiers making use of a few easily computable and effective features, selected independently for each classifier in wrapper experiments. We train two types of classifiers for each of the seven relations: with and without WordNet information."
2007.sigdial-1.49,An Empirically Based Computational Model of Grounding in Dialogue,2007,-1,-1,2,0,16745,harry bunt,Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,0,None
