1994.tc-1.4,P91-1022,0,0.067315,"Missing"
1994.tc-1.4,1992.tc-1.5,0,0.0784461,"Missing"
1994.tc-1.4,C92-2097,0,0.0396543,"Missing"
1994.tc-1.4,P91-1023,0,0.04319,"Missing"
1994.tc-1.4,1993.tmi-1.4,0,0.0878051,"Missing"
1994.tc-1.4,P94-1051,1,0.838877,"Missing"
1994.tc-1.4,C90-3044,0,0.0269542,"Missing"
1994.tc-1.4,C92-4203,0,0.0355657,"Missing"
1994.tc-1.4,1992.tmi-1.7,0,0.0652338,"Missing"
1994.tc-1.4,1988.tmi-1.13,0,0.0718608,"Missing"
1999.tc-1.6,J93-2003,0,0.0045877,"Missing"
1999.tc-1.6,C92-2097,0,0.0538319,"Missing"
1999.tc-1.6,C96-1070,0,0.0221221,"Missing"
1999.tc-1.6,P91-1023,0,0.0854072,"Missing"
1999.tc-1.6,C92-2101,0,0.0469319,"Missing"
1999.tc-1.6,1993.tmi-1.4,0,0.0693851,"Missing"
1999.tc-1.6,C92-2107,0,0.037489,"Missing"
1999.tc-1.6,A94-1013,0,0.0726621,"Missing"
1999.tc-1.6,P94-1051,1,0.902464,"Missing"
1999.tc-1.6,A97-1004,0,0.0473446,"Missing"
1999.tc-1.6,C90-3101,0,0.0217914,"Missing"
1999.tc-1.6,C92-4203,0,0.0295825,"Missing"
1999.tc-1.6,C90-3044,0,0.0511049,"Missing"
1999.tc-1.6,1992.tmi-1.7,0,0.0933808,"Missing"
1999.tc-1.6,P91-1024,0,0.017594,"Missing"
1999.tc-1.6,1995.tmi-1.20,0,0.0671598,"Missing"
1999.tc-1.6,C92-2115,0,0.0442245,"Missing"
1999.tc-1.6,C94-1003,0,0.0315329,"Missing"
2000.bcs-1.1,C00-1075,1,\N,Missing
2000.bcs-1.1,C92-2101,0,\N,Missing
2000.bcs-1.1,1999.tc-1.11,0,\N,Missing
2000.bcs-1.1,J94-4004,0,\N,Missing
2000.bcs-1.3,P94-1051,1,\N,Missing
2020.iwltp-1.15,W16-3503,1,0.91547,"PI Manager Workflow Manager Preprocessing Provisioning of Datasets and Content Language Identification Storage Knowledge Graph File Storage Duplicate Detection Document Structure Analysis Semantic Analysis Content Generation Summarization Named Entity Recognition and Linking Paraphrasing Temporal Expression Analysis Machine Translation Relation Extraction Semantic Storytelling Event Detection Security Figure 5: Technical architecture of the QURATOR platform velops a curation technology platform, which is also being populated with services, simplifying and accelerating the curation of content (Bourgonje et al., 2016a; Rehm et al., 2019a; Schneider and Rehm, 2018a; Schneider and Rehm, 2018b). The project develops, evaluates and integrates services for preprocessing, analyzing and generating content, spanning use cases from the sectors of culture, media, health and industry. To process and transform incoming data, text or multimedia streams into device-adapted, publishable content, various groups of components, services and technologies are applied. These include adapters to data, content and knowledge sources, as well as infrastructural tools and AI methods for the acquisition, analysis and generation of"
2020.iwltp-1.15,2020.lrec-1.696,1,0.735511,"nt annotation schemes can refer to. (2) Multiple OLiA Annotation Models formalize annotation schemes and tagsets. Fig. 8 illustrates this with an annotation model developed as part of the Korean NLP2RDF stack (Hahm et al., 2012). (3) For every annotation model, a linking model defines subclass-relationships between concepts in the annotation model and the reference model. Linking models are interpretations of annotation model concepts and properties in terms of the reference model. (4) Similarly, other community-maintained vocabularies are linked with OLiA, e. g., the CLARIN Concept Registry (Chiarcos et al., 2020). OLiA was developed as part of an infrastructure for the sustainable maintenance of linguistic resources (Wörner et al., 2006; Schmidt et al., 2006; Rehm et al., 2008b; Witt et al., 2009; Rehm et al., 2009). Its field of application included the formalization of annotation schemes and concept-based querying over heterogeneously annotated corpora (Rehm et al., 2008a). As several institutions and resources from various disciplines were involved, no holistic annotation standard could be enforced onto the contributors. 101 3.4. Figure 8: Modular OLiA ontologies 3.2. Level 1: Simple Cross-Platform"
2020.iwltp-1.15,W12-5201,0,0.0160466,"tral hub for linguistic annotation terminology in the web of data. OLiA was designed for mediating between various terminology repositories on the one hand and annotated resources (i. e., their annotation schemes), on the other. Four different types of ontologies are distinguished (Fig. 8): (1) The OLiA Reference Model is an OWL ontology that specifies the common terminology that different annotation schemes can refer to. (2) Multiple OLiA Annotation Models formalize annotation schemes and tagsets. Fig. 8 illustrates this with an annotation model developed as part of the Korean NLP2RDF stack (Hahm et al., 2012). (3) For every annotation model, a linking model defines subclass-relationships between concepts in the annotation model and the reference model. Linking models are interpretations of annotation model concepts and properties in terms of the reference model. (4) Similarly, other community-maintained vocabularies are linked with OLiA, e. g., the CLARIN Concept Registry (Chiarcos et al., 2020). OLiA was developed as part of an infrastructure for the sustainable maintenance of linguistic resources (Wörner et al., 2006; Schmidt et al., 2006; Rehm et al., 2008b; Witt et al., 2009; Rehm et al., 2009"
2020.iwltp-1.15,2020.lrec-1.420,1,0.820145,"Missing"
2020.iwltp-1.15,W17-4212,1,0.852914,". g., provisioning content, language and duplicate detection as well as document structure recognition. (2) Semantic analysis services process a document and add information in the form of annotations, e. g., NER, temporal expression analysis, relation extraction, event detection, fake news as well as discourse analysis (Bourgonje et al., 2016b; Srivastava et al., 2016; Rehm et al., 2017b; Ostendorff et al., 2019). (3) Content generation services enable the creation of a new piece of content, e. g., summarization, paraphrasing, and semantic storytelling (Rehm et al., 2019c; Rehm et al., 2018; Moreno-Schneider et al., 2017; Rehm et al., 2017a; Schneider et al., 2017; Schneider et al., 2016). ENVISIONED SOLUTION Pilot Contracts Pilot GeoThermal Pilot Labor Law Legal Knowledge Graph Workflows Ontologies ... Smart Services Vocabulary ETL linking annotation classification Legal resources Language resources Standards Linked Data Private documents Other open data Documents Figure 6: The Lynx technology platform The platform’s microservice architecture is a variant of the service-oriented architecture (SOA), in which an application is structured as a collection of loosely coupled services. It uses Docker containers ho"
2020.iwltp-1.15,2020.iwltp-1.12,1,0.914049,"ments, yet others provide a user interface. The Document Manager provides the storage and annotation of documents with an emphasis on keeping them synchronized, providing read and write access, as well as updates of documents and annotations. It can be queried in terms of annotations and documents, through REST APIs. The interface includes a set of create, read, update, and delete APIs to manage collections, documents and annotations. The orchestration and execution of services involved in more complex tasks is addressed by a Workflow Manager. It defines combinations of services as workflows (Moreno-Schneider et al., 2020b; Bourgonje et al., 2016a; Schneider and Rehm, 2018a; Schneider and Rehm, 2018b). Workflows are described using BPMN and executed using Camunda.8 Interoperability is addressed at the following levels: Since the QURATOR platform is a closed ecosystem, the platform can be thought of as an experimental toolbox with services customised by the partners for their own use cases. As the platform is used only by the QURATOR partners, it does not contain a catalogue or any kind or structured metadata. However, two of the ten QURATOR projects have a focus on service composition and workflows with protot"
2020.iwltp-1.15,2020.lrec-1.284,1,0.886537,"Missing"
2020.iwltp-1.15,piperidis-2012-meta,1,0.875093,"t least upon a certain (obligatory) subset (Labropoulou et al., 2020; McCrae et al., 2015). Such a more detailed, semantics-driven approach enables more efficient and more user-friendly search results from multiple platforms that can be visually aggregated and also easily ranked. The actual search can be performed through publicly available APIs but returned objects would be semantically richer. Alternatively, the metadata records of external repositories can be harvested using standard protocols such as OAI-PMH, which allow the construction of a master index out of decentralised inventories (Piperidis, 2012). A known issue that needs to be addressed using such an approach involves the detection of duplicate resources. Figure 9: A cross-platform workflow example A similar approach was implemented in the project OpenMinTeD (OMTD) (Labropoulou et al., 2018) using the Galaxy workflow management system.10 Three types of LT components are supported: (1) components packaged in Docker images that follow the OMTD specifications; (2) components wrapped with UIMA or GATE, available in a Maven repository; (3) Text and Data Mining web services that run outside the OMTD platform and that follow the OMTD specif"
2020.iwltp-1.15,L18-1519,1,0.396376,"ed in AI4EU Experiments. 2.2. European Language Grid (ELG) Multilingualism and cross-lingual communication in Europe can only be enabled through Language Technologies (LTs) (Rehm et al., 2016). The European LT landscape is fragmented (Vasiljevs et al., 2019), holding back its impact. Another crucial issue is that many languages are underresourced and, thus, in danger of digital extinction (Rehm and Uszkoreit, 2012; Kornai, 2013; Rehm et al., 2014). There is an enormous need for an European LT platform as a unifying umbrella (Rehm and Uszkoreit, 2013; Rehm et al., 2016; STOA, 2017; Rehm, 2017; Rehm and Hegele, 2018; European Parliament, 2018; Rehm et al., 2020c). The project European Language Grid (2019-2021) attempts to establish the primary platform and marketplace for the European LT community, both industry and research (Rehm et al., 2020a). This scalable cloud platform will provide access to hundreds of LTs for all European languages, including running services as well as data sets. ELG will enable the European LT community to upload their technologies and data sets, to deploy them, and to connect with other resources. ELG caters for commercial and non-commercial LTs (i. e., LTs with a high Technol"
2020.iwltp-1.15,rehm-etal-2008-ontology,1,0.781144,"Missing"
2020.iwltp-1.15,W17-2707,1,0.837412,"road groups: (1) Preprocessing encompasses services for obtaining and processing information from different content sources so that they can be used in the platform and integrated into other services (Schneider et al., 2018), e. g., provisioning content, language and duplicate detection as well as document structure recognition. (2) Semantic analysis services process a document and add information in the form of annotations, e. g., NER, temporal expression analysis, relation extraction, event detection, fake news as well as discourse analysis (Bourgonje et al., 2016b; Srivastava et al., 2016; Rehm et al., 2017b; Ostendorff et al., 2019). (3) Content generation services enable the creation of a new piece of content, e. g., summarization, paraphrasing, and semantic storytelling (Rehm et al., 2019c; Rehm et al., 2018; Moreno-Schneider et al., 2017; Rehm et al., 2017a; Schneider et al., 2017; Schneider et al., 2016). ENVISIONED SOLUTION Pilot Contracts Pilot GeoThermal Pilot Labor Law Legal Knowledge Graph Workflows Ontologies ... Smart Services Vocabulary ETL linking annotation classification Legal resources Language resources Standards Linked Data Private documents Other open data Documents Figure 6:"
2020.iwltp-1.15,2020.lrec-1.413,1,0.802365,"Missing"
2020.iwltp-1.15,2016.tc-1.14,1,0.737947,"n be divided into three broad groups: (1) Preprocessing encompasses services for obtaining and processing information from different content sources so that they can be used in the platform and integrated into other services (Schneider et al., 2018), e. g., provisioning content, language and duplicate detection as well as document structure recognition. (2) Semantic analysis services process a document and add information in the form of annotations, e. g., NER, temporal expression analysis, relation extraction, event detection, fake news as well as discourse analysis (Bourgonje et al., 2016b; Srivastava et al., 2016; Rehm et al., 2017b; Ostendorff et al., 2019). (3) Content generation services enable the creation of a new piece of content, e. g., summarization, paraphrasing, and semantic storytelling (Rehm et al., 2019c; Rehm et al., 2018; Moreno-Schneider et al., 2017; Rehm et al., 2017a; Schneider et al., 2017; Schneider et al., 2016). ENVISIONED SOLUTION Pilot Contracts Pilot GeoThermal Pilot Labor Law Legal Knowledge Graph Workflows Ontologies ... Smart Services Vocabulary ETL linking annotation classification Legal resources Language resources Standards Linked Data Private documents Other open data"
2020.iwltp-1.5,L18-1515,1,0.861276,"Missing"
2020.iwltp-1.5,L18-1210,1,0.883378,"Missing"
2020.iwltp-1.5,gavrilidou-etal-2012-meta,1,0.873564,"Missing"
2020.iwltp-1.5,2020.lrec-1.420,1,0.867196,"Missing"
2020.iwltp-1.5,L18-1205,1,0.86912,"Missing"
2020.iwltp-1.5,piperidis-2012-meta,1,0.79099,"semantic and structural mapping had 4.1. META META-SHARE36 has been developed as the infrastructural arm of META-NET37 and has served as a component of a language technology marketplace for researchers, developers, professionals and industrial players, catering for the full development cycle of language technology, from research to innovative products and services. It has been designed as a network of repositories that store language resources (data, tools and processing services) documented with high-quality metadata, aggregated in central inventories allowing for uniform search and access (Piperidis, 2012). Repositories can be local, set up and maintained 28 https://www.sshopencloud.eu/news/using-corporaimplementing-validation-sshoc-masterclass 29 http://delad.net 30 https://ace.ruhosting.nl 31 https://tla.mpi.nl/ 32 https://talkbank.org/ 33 https://gdpr-info.eu/ 34 https://www.europeana.eu/ 35 https://www.eric-forum.eu/the-eric-landscape/ www.meta-share.eu 37 www.meta-net.eu 36 31 cessing service (e.g. sentence splitting, part-of-speech tagging), running either locally or remotely. This implementation has been used for powering the language processing layer of the CLARIN:EL node (Piperidis et"
2020.iwltp-1.5,2020.lrec-1.407,1,0.850312,"Missing"
2020.iwltp-1.5,2020.lrec-1.406,1,0.820998,"Missing"
2020.iwltp-1.5,2020.lrec-1.405,1,0.789844,"Missing"
2020.lr4sshoc-1.4,L18-1443,0,0.0314586,"obic attitudes. VA involves using messages to attack other people or those aspects of their lives that are extensions of their identity (Hamilton and Hample, 2011). The forms of aggression are manifold and vary from expressions of disgust and contempt, to threats, slander, insults, and hatred (Rȍsner and Krȁmer, 2016). The close relation of online VA with xenophobia is also demonstrated by the hate speech literature and especially by approaches that focus on xenophobia-related types of hate speech like racist (Kwok and Wang, 2013; Waseem and Hovy, 2016) and hate speech directed to immigrants (Sanguinetti et al., 2018) or to specific ethnic groups (Warner and Hirschberg, 2012), even though no explicit reference to xenophobia is made. In this paper we present a replication of the VA analysis framework three years later; in 2019 Greece is in the post financial crisis era, but the refugee crisis is still ongoing. In addition, the centre-right party New Democracy has won the 2019 general election ousting the left-wing Prime Minister Alexis Tsipras, while Golden Dawn -a neo-Nazi party that evolved from a marginal group into Greece’s third-largest party during the financial crisis- was knocked out of the Parliame"
2020.lr4sshoc-1.4,strotgen-gertz-2012-temporal,0,0.0561096,"Missing"
2020.lr4sshoc-1.4,W12-2103,0,0.0395872,"er people or those aspects of their lives that are extensions of their identity (Hamilton and Hample, 2011). The forms of aggression are manifold and vary from expressions of disgust and contempt, to threats, slander, insults, and hatred (Rȍsner and Krȁmer, 2016). The close relation of online VA with xenophobia is also demonstrated by the hate speech literature and especially by approaches that focus on xenophobia-related types of hate speech like racist (Kwok and Wang, 2013; Waseem and Hovy, 2016) and hate speech directed to immigrants (Sanguinetti et al., 2018) or to specific ethnic groups (Warner and Hirschberg, 2012), even though no explicit reference to xenophobia is made. In this paper we present a replication of the VA analysis framework three years later; in 2019 Greece is in the post financial crisis era, but the refugee crisis is still ongoing. In addition, the centre-right party New Democracy has won the 2019 general election ousting the left-wing Prime Minister Alexis Tsipras, while Golden Dawn -a neo-Nazi party that evolved from a marginal group into Greece’s third-largest party during the financial crisis- was knocked out of the Parliament, as a result of the last elections. The research goal is"
2020.lr4sshoc-1.4,N16-2013,0,0.0157411,"ssive messages targeting foreigners can be indicative of xenophobic attitudes. VA involves using messages to attack other people or those aspects of their lives that are extensions of their identity (Hamilton and Hample, 2011). The forms of aggression are manifold and vary from expressions of disgust and contempt, to threats, slander, insults, and hatred (Rȍsner and Krȁmer, 2016). The close relation of online VA with xenophobia is also demonstrated by the hate speech literature and especially by approaches that focus on xenophobia-related types of hate speech like racist (Kwok and Wang, 2013; Waseem and Hovy, 2016) and hate speech directed to immigrants (Sanguinetti et al., 2018) or to specific ethnic groups (Warner and Hirschberg, 2012), even though no explicit reference to xenophobia is made. In this paper we present a replication of the VA analysis framework three years later; in 2019 Greece is in the post financial crisis era, but the refugee crisis is still ongoing. In addition, the centre-right party New Democracy has won the 2019 general election ousting the left-wing Prime Minister Alexis Tsipras, while Golden Dawn -a neo-Nazi party that evolved from a marginal group into Greece’s third-largest"
2020.lr4sshoc-1.4,papageorgiou-etal-2002-multi,1,0.296446,"Missing"
2020.lrec-1.407,gavrilidou-etal-2012-meta,1,0.919419,"Missing"
2020.lrec-1.407,2020.lrec-1.420,1,0.860379,"Missing"
2020.lrec-1.407,L18-1213,1,0.894888,"Missing"
2020.lrec-1.407,piperidis-etal-2014-meta,1,0.824391,"ween 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META-NET results (Rehm and Uszkoreit, 2012), funded a"
2020.lrec-1.407,piperidis-2012-meta,1,0.92358,"n 34 European countries. META-NET was, between 2010 and 2017, supported through the EU projects T4ME, CESAR, METANET4U, META-NORD and CRACKER. One of its main goals is technology support for all European languages as well as fostering innovative research by providing strategic recommendations with regard to key research topics (Rehm and Uszkoreit, 2013). META-SHARE3 is an infrastructure that brings together providers and consumers of language data, tools and services. It is a network of repositories that store resources, documented with high-quality metadata aggregated in central inventories (Piperidis, 2012; Gavrilidou et al., 2012; Piperidis et al., 2014). CLARIN ERIC The CLARIN European Research Infrastructure for Language Resources and Technology is a legal entity set up in 2012, with 20 member countries at present.4 CLARIN makes language resources available to scholars, researchers, and students from all disciplines with a focus on the humanities and social sciences. CLARIN offers solutions and services for deploying, connecting, analyzing and sustaining digital language data and tools. Call ICT-17-2014 – “Cracking the Language Barrier” The EU call ICT-17-2014, which was informed by key META"
2020.lrec-1.407,L16-1251,1,0.865781,"Missing"
2020.lrec-1.407,2020.lrec-1.413,1,0.785764,"Missing"
2020.lrec-1.413,cassidy-etal-2014-alveo,0,0.0760054,"Missing"
2020.lrec-1.413,W03-0810,0,0.137563,"Missing"
2020.lrec-1.413,gavrilidou-etal-2012-meta,1,0.915791,"Missing"
2020.lrec-1.413,hinrichs-krauwer-2014-clarin,0,0.182909,"Missing"
2020.lrec-1.413,P10-4005,0,0.0528445,"Missing"
2020.lrec-1.413,2020.lrec-1.420,1,0.821941,"Missing"
2020.lrec-1.413,L18-1213,1,0.812955,"0b) and plan to integrate experimental workflow functionality into ELG. SHARE metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent activities such as ELRC-SHARE (Lösch et al., 2018; Piperidis et al., 2018) and META-SHARE (Piperidis, 2012; Piperidis et al., 2014). Table 2 provides an overview of what has been identified in these repositories and what is planned to be ingested into ELG, if their access and licensing conditions allow it. Corpora Lexicons Models Total ELRA ELRC-SHARE META-SHARE ELG 848 396 1580 78 1084 132 1261 109 0 0 18 76 1932 528 2859 263 Total 2902 2586 94 5582 Table 2: Identified LRs in the ELG consortium LR modalities covered are text (corpora, lexicons, etc.), speech/audio, video/audiovisual, images/OCR, sign language, and others. About 220 addition"
2020.lrec-1.413,2020.iwltp-1.12,1,0.789706,"ercial services, written in disparate programming languages (Java/Spring, .NET, Python) with just a few days work in the first iteration, falling to a few hours once developers became more familiar with the infrastructure and required formats. 14 These requests are received and handled by the LT Service Execution Server (Section 3.1). 3370 The composition of individual services offered by ELG directly or other cloud platforms is not addressed by ELG itself. However, we experiment with workflow composition and platform interoperability in other contexts (Rehm et al., 2020a; Rehm et al., 2020b; Moreno-Schneider et al., 2020a; Moreno-Schneider et al., 2020b) and plan to integrate experimental workflow functionality into ELG. SHARE metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent"
2020.lrec-1.413,2020.lrec-1.284,1,0.363908,"Missing"
2020.lrec-1.413,piperidis-etal-2014-meta,1,0.89681,"metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent activities such as ELRC-SHARE (Lösch et al., 2018; Piperidis et al., 2018) and META-SHARE (Piperidis, 2012; Piperidis et al., 2014). Table 2 provides an overview of what has been identified in these repositories and what is planned to be ingested into ELG, if their access and licensing conditions allow it. Corpora Lexicons Models Total ELRA ELRC-SHARE META-SHARE ELG 848 396 1580 78 1084 132 1261 109 0 0 18 76 1932 528 2859 263 Total 2902 2586 94 5582 Table 2: Identified LRs in the ELG consortium LR modalities covered are text (corpora, lexicons, etc.), speech/audio, video/audiovisual, images/OCR, sign language, and others. About 220 additional repositories have been located so far, which will increase the numbers in Table"
2020.lrec-1.413,L18-1205,1,0.945027,"tities of interest to users (Section 3.6), appropriately indexed and described so that they can easily search, find and select the resources that meet their requirements and deploy them, as well as visualise the LT domain activities, stakeholders and resources with specific criteria (e. g., service type, language, etc.). All entities are described in compliance with the ELG-SHARE metadata schema (Labropoulou et al., 2019; Labropoulou et al., 2020).7 The schema builds upon, consolidates and updates previous activities, especially the META-SHARE schema and its profiles (Gavrilidou et al., 2012; Piperidis et al., 2018; Labropoulou et al., 2018), taking into account the ELG user requirements (Melnika et al., 2019a), recent developments in the (meta)data domain (e. g., FAIR8 , data and software citation recommendations9 , Open Science movement, etc.), and the need for establishing a common pool of resources through exchange mechanisms with collaborating projects and initiatives (Rehm et al., 2020c), cf. Section 3.6. The schema caters for the description of the ELG core entities (Figure 2), i. e., Language Technologies (tools/services), including functional services and nonfunctional ones (e. g., downloadable"
2020.lrec-1.413,piperidis-2012-meta,1,0.90149,"y into ELG. SHARE metadata schemas and a set of resources has already been ingested from each of them into ELG (Table 3). ELRA ELRC-SHARE META-SHARE Corpora Lexicons Models 20 180 52 2 7 12 – – 7 3.5. Data Sets and Language Resources The ELG consortium has defined an LR identification and sharing strategy. It starts by liaising with and capitalizing on existing activities to ingest LRs into the ELG. We have started by focusing on providers who are part of the consortium (ELDA/ELRA and ELG) and on recent activities such as ELRC-SHARE (Lösch et al., 2018; Piperidis et al., 2018) and META-SHARE (Piperidis, 2012; Piperidis et al., 2014). Table 2 provides an overview of what has been identified in these repositories and what is planned to be ingested into ELG, if their access and licensing conditions allow it. Corpora Lexicons Models Total ELRA ELRC-SHARE META-SHARE ELG 848 396 1580 78 1084 132 1261 109 0 0 18 76 1932 528 2859 263 Total 2902 2586 94 5582 Table 2: Identified LRs in the ELG consortium LR modalities covered are text (corpora, lexicons, etc.), speech/audio, video/audiovisual, images/OCR, sign language, and others. About 220 additional repositories have been located so far, which will incr"
2020.lrec-1.413,L18-1519,1,0.634981,"any are world-class, with technologies that outperform the global players. However, European LT business is also fragmented – by nation states, languages, domains and sectors (Vasiljevs et al., 2019) –, significantly holding back its impact. In addition, many European languages are severely under-resourced and, thus, in danger of digital language exinction (Rehm and Uszkoreit, 2012; Kornai, 2013; Rehm et al., 2014; Rehm et al., 2016a), which is why there is an enormous need for a European LT platform as a unifying umbrella (Rehm and Uszkoreit, 2013; Rehm et al., 2016b; STOA, 2017; Rehm, 2017; Rehm and Hegele, 2018; European Parliament, 2018). The project European Language Grid (ELG; 2019-2021) addresses this fragmentation by establishing the ELG as the primary platform and marketplace for the European LT community, both industry and research.1 The ELG is developed to be a scalable cloud platform, providing, in an easy-to-integrate way, access to hundreds of commercial and non-commercial LTs for all European languages, including running tools and services as well as data sets and 1 https://www.european-language-grid.eu resources. Once fully operational, it will enable the commercial and non-commercial E"
2020.lrec-1.413,L16-1251,1,0.856739,"Missing"
2020.lrec-1.413,P14-5010,0,\N,Missing
2020.lrec-1.420,broeder-etal-2012-standardizing,0,0.0591638,"Missing"
2020.lrec-1.420,gavrilidou-etal-2012-meta,1,0.80935,"Missing"
2020.lrec-1.420,jorg-etal-2010-lt,0,0.0940319,"Missing"
2020.lrec-1.420,P15-4017,1,0.844943,"functionalities of the ELG platform as well as for future extensions and collaborations with other platforms(Rehm et al., 2020b). Thus, format and language can be used to match together tools/services with candidate input resources and initiate their processing; for instance, a tool that takes as input PDF files can be matched with datasets in PDF format. Similar information can also be used to semi-automatically compose workflows of tools and/or match together tools with compatible ancillary resources (annotation resources, ontologies, ML models) to create services and end-user applications (Piperidis et al., 2015; Labropoulou et al., 2018). Figure 3 shows a simplified subset of the metadata schema with its structuring layers and optionality status. Figure 3: Simplified subset of the ELG metadata schema 4.3. Describing LT-related entities ELG intends to offer the who is who of actors and projects in LT. Thus, the module for actors and projects, in comparison to META-SHARE profiles, has been enriched. Besides identification and descriptive metadata elements, such as name/title, identifier(s), contact information, etc., of particular importance are features related to and/or promoting LT activities, prod"
2020.lrec-1.420,L18-1205,1,0.686988,"). Its main source is META-SHARE, a wellestablished and widely used schema catering for the description of LRTs in the LT domain, together with its application profiles6 , which adapt the core properties and re6 It should be noted that META-SHARE is also registered in the CLARIN Component Registry (https://catalog.clarin.eu/ ds/ComponentRegistry) and used in the Greek CLARIN (https: //www.clarin.gr/) and various META-SHARE nodes harvested by the Virtual Language Observatory (https://vlo.clarin.eu/). 3429 lations to the needs of specific platforms (Gavrilidou et al., 2012; McCrae et al., 2015; Piperidis et al., 2018; Labropoulou et al., 2018). META-SHARE was based on an extensive study of related metadata schemas and catalogues, focusing mainly on LRTs but also taking into account general trends in the metadata domain (Desipri et al., 2012). In the course of time, its principles and implementation policies have been updated to reflect advancements in the metadata area. In ELG, modifications, updates and extensions in the contents (metadata elements and values) are made in response to user requirements (Melnika et al., 2019a) and new descriptive needs, such as: • integration and deployment of functional s"
2020.lrec-1.420,piperidis-2012-meta,1,0.867004,") are described with mainly bibliographic metadata and, optionally, a category of the LT area to which they belong. Licences and terms of use are described by a set of mainly administrative metadata (e.g., licence name, access URL) and elements facilitating human users to understand the main access conditions (Rodriguez-Doncel and Labropoulou, 2015). The module will also include a set of information for billing requirements of commercial services (currently work in progress). 3432 5. Language Technology Taxonomy For standardization purposes, the ELG schema, in line with META-SHARE principles (Piperidis, 2012), favours controlled vocabularies over free-text fields, especially when these are associated with internationally acknowledged standards, best practices or widespread vocabularies (e.g., ISO 3166 for region codes, RFC 5646 for languages, etc.). Specially devised vocabularies are used for various metadata elements, mainly for features specific to the LT sector. One such prominent case is the LT application area. The ’LT application area’ element is the main linking bridge between all entities in the ELG catalogue. It is used, for instance, to classify LTs by the function/task they perform (’se"
2020.lrec-1.420,L18-1519,1,0.401448,"-to-integrate way, access to hundreds of commercial and non-commercial LTs for all European languages, including running tools and services as well as data resources. Discovery of and access to these resources can only be achieved through an appropriate metadata schema. We present here the ELG-SHARE schema, which is used for the description of LT-related resources shared through the ELG platform and its contribution to the project goals. 2. Objectives The ELG project (Rehm et al., 2020a) aims to foster European LT by addressing the fragmentation that hinders its development; see indicatively (Rehm and Hegele, 2018; Rehm et al., 2016). To this end, it builds a platform dedicated to the distribution and deployment of Language Resources and Technologies (LRT), aspiring to establish it as the primary platform and marketplace for industry-relevant LT in Europe. The promotion of LT stakeholders and activities and growth of their visibility and outreach is also one of its goals. Together with complementary material in the portal (e.g., training material, information on events, job offerings, etc.), ELG offers a comprehensive picture of the European LT sector. The ELG platform5 will offer access to hundreds of"
2020.lrec-1.420,L16-1251,1,0.79915,"Missing"
2020.lrec-1.420,2020.lrec-1.413,1,0.821544,"Missing"
2020.lrec-1.420,2020.iwltp-1.15,1,0.820346,"Missing"
2021.eacl-demos.26,hinrichs-krauwer-2014-clarin,0,0.0190659,"arts in February 2021 with a duration of 912 months. In the first call, 110 proposals were accepted for evaluation with applicants from 29 countries. We received more proposals from SMEs (62) than re search organisations (48). While 79 proposals fo 2.10 Legal Entity 3 Related Work ELG builds upon previous work of the ELG con sortium and the wider European LT community, es pecially METANET/META and ELRC. In addition, we have collected more than 30 plat forms, projects or initiatives that can be considered relevant for ELG including, among others, UIMA (Ferrucci and Lally, 2003), CLARIN (Hinrichs and Krauwer, 2014), DKPro (Gurevych et al., 2007); Rehm et al. (2020a) provide an exhaustive com parison. They share at least one of the following goals with ELG, i. e., they provide: 1) a collec tion of LT/NLP tools or data sets; 2) a platform, which harvests metadata records from distributed sources, 3) a platform for the sharing of tools or data sets. While related projects do exist, the ap proach of ELG is unique. The platform that most closely resembles ELG is the National Platform for LT, operated by the Ministry of Electronics and In formation Technology in India.16 Several global technology enterpri"
2021.eacl-demos.26,2020.iwltp-1.12,1,0.888601,"Missing"
2021.eacl-demos.26,piperidis-2012-meta,1,0.736597,"four TTS and two text categori sation services. Further services are being added on a regular basis with 200+ additional IE and text analysis services, 21 MT, eight ASR and nine TTS scheduled to be included by the time of ELG Re lease 2 in February 2021. We aim to make it as simple as possible for LT providers to integrate their services, but in a Already now ELG provides access to more than 2700 language resources. We ingested substan tial resources from existing repositories, especially ELDA/ELRA, ELRCSHARE (Lösch et al., 2018; Piperidis et al., 2018; Smal et al., 2020) and META SHARE (Piperidis, 2012; Piperidis et al., 2014). We have also been working on ‘external’ reposito ries, about 220 of which have been identified so far. Some (e. g., Zenodo, Quantum Stat) are al ready being ingested together with two reposito ries related to ELG, LINDAT/CLARIAHCZ and ELRASHARELRs (LRs published at LREC). 2.6 Access Methods and User Interfaces Our main groups of users are: (1) LT/LR providers – companies or research organisations with tools, services or data that can be provided through the ELG; (2) Developers and integrators – companies and research institutions interested in using LT; (3) Gen"
2021.eacl-demos.26,L18-1205,1,0.930475,"ps://www.postgresql.org 8 https://www.keycloak.org 9 https://prometheus.io 10 https://helm.sh 5 2.3 Catalogue The metadata records stored in the catalogue en able access to services and data resources. They are described using the ELG metadata schema (Labropoulou et al., 2020) and can be browsed and explored. The catalogue also includes a registry of stakeholders who develop LT services or products, and relevant projects, thus providing an overview of the whole European LT landscape. The ELG metadata schema builds upon, consolidates and updates the METASHARE schema (Gavrilidou et al., 2012; Piperidis et al., 2018; Labropoulou et al., 2018), taking into account ELG’s require ments, recent developments in the metadata do main (e. g., FAIR11 ), and the need for creating a common pool of resources through exchange mechanisms with collaborating initiatives. The metadata schema caters for the descrip tion of the ELG core entities, i. e., Language Technologies (tools/services), including functional services and nonfunctional ones, and Data Lan guage Resources, comprising data sets (corpora), language descriptions (i. e., models) and lexical/ conceptual resources (e. g., gazetteers, ontologies, etc.). I"
2021.eacl-demos.26,piperidis-etal-2014-meta,1,0.869104,"text categori sation services. Further services are being added on a regular basis with 200+ additional IE and text analysis services, 21 MT, eight ASR and nine TTS scheduled to be included by the time of ELG Re lease 2 in February 2021. We aim to make it as simple as possible for LT providers to integrate their services, but in a Already now ELG provides access to more than 2700 language resources. We ingested substan tial resources from existing repositories, especially ELDA/ELRA, ELRCSHARE (Lösch et al., 2018; Piperidis et al., 2018; Smal et al., 2020) and META SHARE (Piperidis, 2012; Piperidis et al., 2014). We have also been working on ‘external’ reposito ries, about 220 of which have been identified so far. Some (e. g., Zenodo, Quantum Stat) are al ready being ingested together with two reposito ries related to ELG, LINDAT/CLARIAHCZ and ELRASHARELRs (LRs published at LREC). 2.6 Access Methods and User Interfaces Our main groups of users are: (1) LT/LR providers – companies or research organisations with tools, services or data that can be provided through the ELG; (2) Developers and integrators – companies and research institutions interested in using LT; (3) General LT information seeke"
2021.eacl-demos.26,L16-1251,1,0.869271,"Missing"
2021.eacl-demos.26,L18-1519,1,0.849444,"et al., 2019; Rehm et al., 2020d). We describe Release 2 of the European Lan guage Grid (ELG) cloud platform.1 This scal able system is targeted to evolve into the primary 1 https://www.europeanlanguagegrid.eu. We provide a screencast demo video at https://youtu.be/LD6QadkkZiM. platform for LT in Europe. It will provide one umbrella platform for all LTs developed by the European LT landscape, including research and industry, addressing a gap that has been repeat edly raised by the European LT community for many years (Rehm and Uszkoreit, 2013; Rehm et al., 2016b; STOA, 2017; Rehm, 2017; Rehm and Hegele, 2018; European Parliament, 2018). ELG is meant to be a virtual home and marketplace for all products, services and organisations active in the LT space in Europe (Rehm et al., 2020a). The platform can be used by all stakeholders to show case, share and distribute their products, services, tools and resources. At the end of the EU project ELG (20192022), which will establish a legal en tity in early 2022, the platform will provide access to approx. 1300 commercial and noncommercial tools and services for all European languages, as well as thousands of language resources (LRs). ELG will enable t"
2021.eacl-demos.26,2020.lrec-1.422,0,0.0498058,"Missing"
boutsis-etal-2000-robust,M95-1014,0,\N,Missing
boutsis-etal-2000-robust,A97-1012,0,\N,Missing
boutsis-etal-2000-robust,A97-1046,0,\N,Missing
boutsis-etal-2000-robust,C90-3030,0,\N,Missing
boutsis-etal-2000-robust,P96-1034,0,\N,Missing
boutsis-etal-2000-robust,C92-3150,0,\N,Missing
boutsis-etal-2000-robust,P96-1003,0,\N,Missing
boutsis-etal-2000-robust,P95-1003,0,\N,Missing
boutsis-etal-2000-robust,M92-1019,0,\N,Missing
C00-1075,J96-1003,0,\N,Missing
C00-1075,A94-1016,0,\N,Missing
C00-1075,C94-1003,0,\N,Missing
C00-1075,C92-2107,0,\N,Missing
C00-1075,C92-2101,0,\N,Missing
C00-1075,C96-1070,0,\N,Missing
C00-1075,1999.tc-1.11,0,\N,Missing
C00-1075,J94-4004,0,\N,Missing
C00-1075,C90-3101,0,\N,Missing
C00-1075,W98-1503,1,\N,Missing
C00-1075,C94-1014,0,\N,Missing
calzolari-etal-2004-enabler,binnenpoorte-etal-2002-field,0,\N,Missing
demiros-etal-2000-named,W98-1120,0,\N,Missing
demiros-etal-2000-named,M98-1004,0,\N,Missing
demiros-etal-2000-named,M98-1012,0,\N,Missing
demiros-etal-2000-named,M98-1014,0,\N,Missing
demiros-etal-2000-named,M98-1021,0,\N,Missing
demiros-etal-2000-named,M98-1018,0,\N,Missing
demiros-etal-2000-named,M98-1019,0,\N,Missing
demiros-etal-2000-named,M98-1020,0,\N,Missing
demiros-etal-2000-named,M95-1014,0,\N,Missing
demiros-etal-2000-named,M95-1012,0,\N,Missing
demiros-etal-2000-named,C96-1072,0,\N,Missing
demiros-etal-2000-named,A97-1031,0,\N,Missing
demiros-etal-2000-named,M95-1017,0,\N,Missing
demiros-etal-2000-named,A97-1029,0,\N,Missing
gavrilidou-etal-2006-language,J03-3002,0,\N,Missing
gavrilidou-etal-2006-language,calzolari-etal-2004-enabler,1,\N,Missing
gavrilidou-etal-2006-language,erjavec-2004-multext,0,\N,Missing
gavrilidou-etal-2006-language,J03-3001,0,\N,Missing
gavrilidou-etal-2012-meta,piperidis-2012-meta,1,\N,Missing
gavrilidou-etal-2012-meta,broeder-etal-2010-data,0,\N,Missing
gavrilidou-etal-2012-meta,federmann-etal-2012-meta,0,\N,Missing
georgantopoulos-piperidis-2000-term,C92-3150,0,\N,Missing
hatzigeorgiu-etal-2000-design,A97-1004,0,\N,Missing
hatzigeorgiu-etal-2000-design,A94-1013,0,\N,Missing
L16-1144,C12-1013,0,0.071274,"Missing"
L16-1144,D13-1174,0,0.0223533,"er of applications (Tiedemann, 2011) including SMT, induction of bilingual lexica and contrastive studies of language use. Tlaxcala (Toral, 2014) was the first publicly available collection of parallel and monolingual corpora acquired from independent news sources. The largest parallel corpus in this 15-language resource is English-Spanish with 66.8K sentence pairs. Rettinger et al. (2014) compiled a parallel corpus of 300 English/Spanish/German GV articles, which they hand-annotated with semantic groundings of named entities and concepts to cross-lingual linked data extracted from Wikipedia. Chahuneau et al. (2013) used an English-Swahili parallel corpus obtained by crawling GV and reported significant improvements in translation quality when translating to Swahili. Finally, a GV MalagasyEnglish parallel corpus, collected and aligned at sentence level by V. Chahuneau, is available from http://www. ark.cs.cmu.edu/global-voices/. This work is to the best of our knowledge the first that extracts parallel and monolingual resources for all languages and language pairs in the GV websites. The datasets comprising this resource are smaller than the ones obtained from mining large scale crawls (e.g. Smith et al."
L16-1144,W13-2506,1,0.928378,"Missing"
L16-1144,rettinger-etal-2014-recsa,0,0.0258923,"f the potential use of the parallel corpora presented here, we use them to examine methods for the detection of parallel web pages and discuss results in Section 5. 2. Related Work Parallel corpora like PGV are important for a number of applications (Tiedemann, 2011) including SMT, induction of bilingual lexica and contrastive studies of language use. Tlaxcala (Toral, 2014) was the first publicly available collection of parallel and monolingual corpora acquired from independent news sources. The largest parallel corpus in this 15-language resource is English-Spanish with 66.8K sentence pairs. Rettinger et al. (2014) compiled a parallel corpus of 300 English/Spanish/German GV articles, which they hand-annotated with semantic groundings of named entities and concepts to cross-lingual linked data extracted from Wikipedia. Chahuneau et al. (2013) used an English-Swahili parallel corpus obtained by crawling GV and reported significant improvements in translation quality when translating to Swahili. Finally, a GV MalagasyEnglish parallel corpus, collected and aligned at sentence level by V. Chahuneau, is available from http://www. ark.cs.cmu.edu/global-voices/. This work is to the best of our knowledge the fir"
L16-1144,P13-1135,0,0.187184,"t al. (2013) used an English-Swahili parallel corpus obtained by crawling GV and reported significant improvements in translation quality when translating to Swahili. Finally, a GV MalagasyEnglish parallel corpus, collected and aligned at sentence level by V. Chahuneau, is available from http://www. ark.cs.cmu.edu/global-voices/. This work is to the best of our knowledge the first that extracts parallel and monolingual resources for all languages and language pairs in the GV websites. The datasets comprising this resource are smaller than the ones obtained from mining large scale crawls (e.g. Smith et al. (2013)). In contrast, this work is a focused effort to extract highly parallel documents by exploiting the well-defined structure of a multilingual site. In another research line, Harlow and Johnson (2011) discuss how the 2011 Egyptian protests were depicted in, among other sources, 66 stories from a major US newspaper and 49 documents on the English GV site. The datasets presented in this paper could make similar comparisons easier, even from a multilingual perspective. 3. Acquisition and Processing The content of the GV websites was crawled in July-August 2015 and in January 2016 by the authors. T"
L16-1144,toral-2014-tlaxcala,0,0.0181812,"Voices content was crawled, processed and aligned at document and sentence level. Section 4 provides details on the size and characteristics of monolingual and parallel sub-corpora in PGV and on format and availability. As an example of the potential use of the parallel corpora presented here, we use them to examine methods for the detection of parallel web pages and discuss results in Section 5. 2. Related Work Parallel corpora like PGV are important for a number of applications (Tiedemann, 2011) including SMT, induction of bilingual lexica and contrastive studies of language use. Tlaxcala (Toral, 2014) was the first publicly available collection of parallel and monolingual corpora acquired from independent news sources. The largest parallel corpus in this 15-language resource is English-Spanish with 66.8K sentence pairs. Rettinger et al. (2014) compiled a parallel corpus of 300 English/Spanish/German GV articles, which they hand-annotated with semantic groundings of named entities and concepts to cross-lingual linked data extracted from Wikipedia. Chahuneau et al. (2013) used an English-Swahili parallel corpus obtained by crawling GV and reported significant improvements in translation qual"
L18-1205,L18-1213,1,0.698225,"Missing"
L18-1205,W13-2506,0,0.0683994,"user role accordance to its licensing conditions. Contributions may also come from ELRC members using the editor interface, in which case the LRs are deposited straight into the repository, again as a zipped file. To upload the resource, the minimal information must have already been encoded for the resource. The description can still continue to be updated at any time, before and after uploading. In addition, ELRC resources may be generated by using an automatic language resource discovery (Papavassiliou et al., 2018) and compilation system (ILSP-FC). ILSP-FC ((Papavassiliou et al., 2016); (Papavassiliou et al., 2013)) is essentially a pipeline of tools that, given a set of seed URLs, and optionally a domain profile in the form of a list of domain specific terms, crawl the web, fetch web pages, check their domainness, pair the translated web pages and align them at sentence level, thus generating a TMX file. The ILSP-FC system automatically extracts the required metadata and renders them in the ELRC-SHARE profile form, ready to be automatically uploaded to the repository. All LRs residing in the repository undergo a systematic validation procedure (L¨osch et al., 2018), the results of which are coded in th"
L18-1205,W16-2375,1,0.919658,"Missing"
L18-1205,L18-1599,1,0.769267,"will be downloadable by users, in 1291 7 http://eurovoc.europa.eu/ Figure 1: Available user rights per user role accordance to its licensing conditions. Contributions may also come from ELRC members using the editor interface, in which case the LRs are deposited straight into the repository, again as a zipped file. To upload the resource, the minimal information must have already been encoded for the resource. The description can still continue to be updated at any time, before and after uploading. In addition, ELRC resources may be generated by using an automatic language resource discovery (Papavassiliou et al., 2018) and compilation system (ILSP-FC). ILSP-FC ((Papavassiliou et al., 2016); (Papavassiliou et al., 2013)) is essentially a pipeline of tools that, given a set of seed URLs, and optionally a domain profile in the form of a list of domain specific terms, crawl the web, fetch web pages, check their domainness, pair the translated web pages and align them at sentence level, thus generating a TMX file. The ILSP-FC system automatically extracts the required metadata and renders them in the ELRC-SHARE profile form, ready to be automatically uploaded to the repository. All LRs residing in the repository"
L18-1205,piperidis-2012-meta,1,0.807543,"which contain statistical information that assigns a probability to a piece of unseen text, based on some training data). • notification and reporting mechanisms for the efficient monitoring of updates of the hosted LRs. ELRC-SHARE is based on a META-SHARE software instance, its latest version building on META-SHARE v3.1.1. The software has been adapted to the operational needs of ELRC and it has been evolving to respond to specific requirements of its stakeholders. The ELRC-SHARE repository can be replicated on additional servers. However, unlike the META-SHARE distributed network structure (Piperidis, 2012), ELRC-SHARE is deployed as a single repository (i.e. one central, managing, node in METASHARE terminology) centrally managed by the ELRC consortium. Furthermore, following ELRC requirements, new user roles have been added (namely technical and legal reviewing roles with their own class of access rights), the metadata schema is updated to reflect, for instance, evolution in the open data licensing policies of countries, and new functionalities for reporting, data exporting and packaging have been implemented. 3. ELRC-SHARE metadata schema ELRC LRs are (formally) documented using the ELRCSHARE"
L18-1205,broeder-etal-2008-foundation,1,0.729493,"description of resources (with the ELRC-SHARE metadata schema) For the general public: a simple and faceted search and browsing of the resources inventory. • flexibility, empowered with a two-level approach, where the initial level (minimal schema) consists of a set of basic elements required for at least identifying and accessing a LR, and a second level (maximal schema) with a higher degree of granularity of information • modularity, implemented in the form of “components”, i.e. groups of semantically coherent elements, following the Component MetaData Infrastructure (CMDI) recommendations (Broeder et al., 2008) • a module for storing LRs, together with their respective metadata records and accompanying documentation (e.g. deposition and licensing documents, validation report); • standardisation: where possible, controlled vocabularies are preferred over free text for the value space of elements, especially when these can be associated with internationally acknowledged standards, best practices or widespread vocabularies (e.g. ISO 3166 for country codes, RFC 5646 for languages, IANA mimetypes etc.) • a user management module assigning specific access rights to the resources and the repository operati"
L18-1213,L18-1599,1,0.756254,"/Licence Ouverte, for France). LRs provided can be classified and viewed depending on the licence available: public domain, open under PSI, open licenses, standard licenses, and non-standard licenses. Validation of Language Resources within ELRC Validation Guidelines Implementation Validation can be understood as the quality control of a LR against a list of relevant criteria (Schneller et al., 2017). Due to the high number of LRs required within the project, the ELRC consortium decided to complement the donated LRs with additional LRs produced from scratch through a website crawling process (Papavassiliou et al, 2018). Web crawling was conducted using ILSP-FC, a comprehensive end-to-end solution for the acquisition of domain-specific monolingual and bilingual corpora from the web. Data Processing Each LR is analysed and processed by ELRC experts to ensure compliance with the Language Resources Data 12 https://www.maxprograms.com/products/tmxvalidator.html https://www.microsoft.com/en-us/download/ details.aspx?id=52608 14 https://github.com/aboSamoor/pycld2 13 10 11 http://lr-coordination.eu/helpdesk http://helpdesk.lr-coordination.eu/overview 1341 The ELRC partners (the National Anchor Points) initially id"
L18-1213,W12-0102,0,0.040596,"Missing"
L18-1213,L18-1391,1,0.797927,"eHealth Business Registers Interconnection System Safer Internet Cybersecurity Public Open Data Europeana Domain Consumers’ rights Social security, insurance Public procurement, contractual agreements Justice, Law Health, Medicine Business, market ICT ICT Multiple domains Culture Table 1: CEF Digital Service Infrastructures (DSIs) and their domains Even though the PSI Directive is an important instrument to open up public sector data, there are many challenges in collecting LRs from public services, such as lack of awareness, lack of technical or legal competence, poor data management, etc. (Vasiļjevs et al., 2018). 1.3 Setting up a European Language Resource Coordination (ELRC) European, national and regional public administrations deal with a huge amount of multilingual textual information in original and translated form. By sharing this linguistic data and turning it into language resources (LRs), they can improve the quality, coverage and performance of CEF eTranslation that needs multilingual LRs to train MT systems. In April 2015, the ELRC Consortium was set up through EC’s Connecting Europe Facility SMART 2014/1074 programme to initiate a number of actions with the aim to support the collection o"
L18-1599,L18-1213,1,0.823712,"Missing"
L18-1599,W13-2506,1,0.77513,"rocess until an expiration criterion is reached. In the case of focused crawls for domain-specific content, the input expected from the user also includes a domain profile, i.e. a list of terms that describe the domain. In order to ensure scalability, the system is based on opensource libraries that allow configuration of workflows that can be executed on top of the Hadoop framework for distributed data processing. Due to its modular architecture, each of the system’s components can be easily substituted by alternatives with the same functionalities. The main components integrated in ILSP-FC (Papavassiliou et al., 2013) are: Page Fetcher adopts a multi-threaded crawling implementation in order to ensure concurrent visiting of multiple web pages/hosts and fetching of user-targeted specific document types (e.g. html, docx, pdf). Normalizer detects the text encoding of the downloaded web pages and if needed, converts it to UTF-8. It also parses the structure of each web page and extracts its metadata (e.g. title, description, keywords, publisher, author, license etc.). In order to extract textual content and metadata from a set of formats (txt, docx and pdf), it uses open libraries2 . Cleaner segments the main"
L18-1599,W16-2375,1,0.892996,"Missing"
L18-1599,L18-1205,1,0.769505,"truct a mono/bilingual collection for each website. Finally, the outcomes of the websites were merged based on the language and the relevance of their content. For instance, the acquired content from websites of Polish cultural organizations was merged to generate a monolingual LR of 10.2M tokens and a parallel EN-PL LR of 36.3K TUs. Although crawling with the tool for the purposes of ELRC is ongoing work, parallel LRs for several language pairs have already been generated and a number of them (ENEL, EN-BG, EN-MT, EN-SV, EN-IS, EN-ET, EN-ES) have become available through the ELRC repository9 (Piperidis et al., 2018) by consortium members. 4. Evaluation experiments Assessing the usefulness of a system that discovers, acquires and transforms bitexts from the web involves many different evaluation questions: Does the system identify most of the document pairs published on a web site? Are these document pairs as noise-free as possible? Are the aligned sentences extracted from the document pairs clean enough for training MT systems? Apart from our participation in the WMT 2016 shared task, we also conducted experiments covering a variety of language pairs, in order to evaluate both the acquisition procedure a"
L18-1599,L16-1144,1,0.908094,"Missing"
L18-1599,steinberger-etal-2012-jrc,0,0.0437698,"Missing"
L18-1599,W15-4924,0,0.266299,"Missing"
marzelou-etal-2008-building,nivre-etal-2006-maltparser,0,\N,Missing
marzelou-etal-2008-building,papageorgiou-etal-2000-unified,1,\N,Missing
marzelou-etal-2008-building,J94-4002,0,\N,Missing
marzelou-etal-2008-building,papageorgiou-etal-2002-multi,1,\N,Missing
marzelou-etal-2008-building,giouli-etal-2006-multi,1,\N,Missing
marzelou-etal-2008-building,L06-1000,0,\N,Missing
P15-4017,soria-etal-2012-flarenet,1,0.846018,"esource, with the member maintaining the repository undertaking its curation. Metadata records are harvested and stored in the METASHARE central servers, which maintain an inventory including metadata of all resources available in the distributed network. METASHARE users, depending on their role, are able to create a user profile, log-in, browse and search 1 Introduction Language technology research and development relies on the deployment of appropriate resources and processing services more than ever before. However, the resources and services landscape is unorganized and highly fragmented (Soria et al., 2012). Recently, initiatives like CLARIN (Wittenburg et al., 2010), Language Grid (Ishida, 2011), Panacea (Poch and Bel, 2011), LAPPS Grid (Ide et al., 2014) have been launched aiming at improving discoverability and accessibility of resources and services, as well as their lawful re-use and direct deployment in modern computational environments. In this paper, we present META-SHARE/QT21, a prototype implementa1 ISO 12620, http://www.isocat.org. 97 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 97–102, c Beijing, China, July 26-31, 2015. 2015 ACL and AFNLP Figure 1: Dynamically generat"
P15-4017,gavrilidou-etal-2012-meta,1,0.88691,"ilingual resources of various formats are provided (e.g. XCES, TXT, TMX). From the legal framework point of view, a simple operational model is adopted by which only openly licensed datasets can be processed by openly licensed services. 2 META-SHARE design and repository META-SHARE is designed as a network of distributed repositories of language data, tools and web services, documented with high-quality metadata, aggregated in central inventories allowing for uniform search and access to resources and services. Language resources and services are documented with the METASHARE metadata schema (Gavrilidou et al., 2012)1 which builds upon previous initiatives (Broeder et al., 2010), including elements, most of which are linked to ISOCat Data Categories1, as well as relations (e.g. is_part_of, is_annotation_of) used to describe and link resources that are included in the META-SHARE repository. Every resource in META-SHARE is primarily assigned to one of the network&apos;s repositories, implementing the notion of a master copy of a resource, with the member maintaining the repository undertaking its curation. Metadata records are harvested and stored in the METASHARE central servers, which maintain an inventory inc"
P15-4017,wittenburg-etal-2010-resource,1,0.783338,"rtaking its curation. Metadata records are harvested and stored in the METASHARE central servers, which maintain an inventory including metadata of all resources available in the distributed network. METASHARE users, depending on their role, are able to create a user profile, log-in, browse and search 1 Introduction Language technology research and development relies on the deployment of appropriate resources and processing services more than ever before. However, the resources and services landscape is unorganized and highly fragmented (Soria et al., 2012). Recently, initiatives like CLARIN (Wittenburg et al., 2010), Language Grid (Ishida, 2011), Panacea (Poch and Bel, 2011), LAPPS Grid (Ide et al., 2014) have been launched aiming at improving discoverability and accessibility of resources and services, as well as their lawful re-use and direct deployment in modern computational environments. In this paper, we present META-SHARE/QT21, a prototype implementa1 ISO 12620, http://www.isocat.org. 97 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 97–102, c Beijing, China, July 26-31, 2015. 2015 ACL and AFNLP Figure 1: Dynamically generating annotation Figure 2: Presenting the processing services r"
P15-4017,piperidis-2012-meta,1,0.93306,"Missing"
P15-4017,ide-etal-2014-language,0,0.0401345,"Missing"
P94-1051,A92-1013,0,0.0252445,"Missing"
P94-1051,P91-1022,0,0.338886,"Missing"
P94-1051,P93-1001,0,0.0618018,"Missing"
P94-1051,A92-1018,0,0.106884,"Missing"
P94-1051,P91-1023,0,0.306401,"Missing"
P94-1051,1992.tmi-1.7,0,0.257694,"Missing"
P94-1051,J93-1004,0,\N,Missing
papageorgiou-etal-2000-unified,W96-0102,0,\N,Missing
papageorgiou-etal-2000-unified,A92-1018,0,\N,Missing
papageorgiou-etal-2000-unified,A88-1019,0,\N,Missing
papageorgiou-etal-2000-unified,J94-2001,0,\N,Missing
papageorgiou-etal-2000-unified,P98-1080,0,\N,Missing
papageorgiou-etal-2000-unified,C98-1077,0,\N,Missing
papageorgiou-etal-2000-unified,P98-2186,0,\N,Missing
papageorgiou-etal-2000-unified,C98-2181,0,\N,Missing
papageorgiou-etal-2002-multi,boutsis-etal-2000-robust,1,\N,Missing
papageorgiou-etal-2002-multi,papageorgiou-etal-2000-unified,1,\N,Missing
papageorgiou-etal-2002-multi,W00-1003,0,\N,Missing
papageorgiou-etal-2002-multi,J94-4002,0,\N,Missing
piperidis-2012-meta,gavrilidou-etal-2012-meta,1,\N,Missing
piperidis-2012-meta,federmann-etal-2012-meta,0,\N,Missing
piperidis-etal-2014-meta,wittenburg-etal-2010-resource,1,\N,Missing
piperidis-etal-2014-meta,choukri-etal-2012-using,1,\N,Missing
piperidis-etal-2014-meta,piperidis-2012-meta,1,\N,Missing
piperidis-etal-2014-meta,gavrilidou-etal-2012-meta,1,\N,Missing
piperidis-etal-2014-meta,broeder-etal-2010-data,0,\N,Missing
piperidis-etal-2014-meta,soria-etal-2012-flarenet,1,\N,Missing
piperidis-etal-2014-meta,federmann-etal-2012-meta,1,\N,Missing
prokopidis-etal-2008-condensing,W04-2407,0,\N,Missing
prokopidis-etal-2008-condensing,W03-0501,0,\N,Missing
prokopidis-etal-2008-condensing,daelemans-etal-2004-automatic,0,\N,Missing
prokopidis-etal-2008-condensing,hatzigeorgiu-etal-2000-design,1,\N,Missing
prokopidis-etal-2008-condensing,papageorgiou-etal-2002-multi,1,\N,Missing
rehm-etal-2014-strategic,P07-2045,0,\N,Missing
rehm-etal-2014-strategic,piperidis-etal-2014-meta,1,\N,Missing
rehm-etal-2014-strategic,piperidis-2012-meta,1,\N,Missing
W16-2375,J03-3002,0,\N,Missing
W16-2375,2012.eamt-1.38,1,\N,Missing
W16-2375,C12-1013,0,\N,Missing
W16-2375,P13-1135,0,\N,Missing
W16-2375,W15-3022,1,\N,Missing
W16-2375,W13-2506,1,\N,Missing
W18-6484,W13-2506,1,0.811065,"rors concern the accuracy of the language identification process. Even when the language of a web page is correctly detected at document level, it is possible that small parts of the page are written in another language. Thus, ignoring language detection at paragraph or sentence level may lead to sentence pairs with the wrong language in the source and/or the target side. Finally, misalignments at document and/or sentence level generate sentence pairs that are not translations of each other. System architecture Our submission system is based on the cleaning module of the ILSP Focused Crawler (Papavassiliou et al., 2013), an open-source toolkit2 that integrates all necessary software3 for the creation of high-precision parallel resources from the web in a language-independent fashion. The toolkit and its cleaning module have been used in research projects like the European Language Resource Coordination for the acquisition of high-precision parallel language resources (Papavassiliou et al., 2018). 2.1 2.2 Filter-based clustering Given that the existence of the types of noise discussed above is not strongly influenced by the targeted language pair, we developed a language agnostic method with the purpose of cl"
W18-6484,P13-2061,0,0.237802,"orpora in order to get word alignments, which are then used to identify mistranslations. Denkowski et al. (2012) use N-gram language models built from monolingual corpora to estimate probabilities of source and target sentences, in a manner of assigning high scores to grammatical sentences and lower scores to ungrammatical sentences and non-sentences such as site maps, large lists of names, and blog comments. Aiming to select sentence pairs of good adequacy and fluency, Xu and Koehn (2017) generate probabilistic dictionaries and n-gram models from Europarl corpora. Taghipour et al. (2011) and Cui et al. (2013) extract features based on translation and language models, and word alignments from the dataset under examination (i.e. this dataset is used to train models instead of using external language resources) and then apply unsupervised techniques such as outlier detection of estimated probability density and graph-based random walk algorithm to discard sentence pairs that are of limited or no importance. In the case of web acquired data, shallow features like aligners’ scores, length ratio, and patterns in URLs from which the content was originated, have been proposed (Espl`a-Gomis and Forcada, 20"
W18-6484,P02-1040,0,0.105411,"Missing"
W18-6484,W12-3131,0,0.0549702,"Missing"
W18-6484,P13-2119,0,0.0232269,"e. this dataset is used to train models instead of using external language resources) and then apply unsupervised techniques such as outlier detection of estimated probability density and graph-based random walk algorithm to discard sentence pairs that are of limited or no importance. In the case of web acquired data, shallow features like aligners’ scores, length ratio, and patterns in URLs from which the content was originated, have been proposed (Espl`a-Gomis and Forcada, 2010). In a different manner, many researchers have approached data selection as a domain-matching issue. For instance, Duh et al. (2013) proposed the use of a neural language model trained on a domain-specific corpus to identify in-domain sentence pairs in a large corpus. This paper describes the submission of ILSP/ARC for the WMT 2018 Parallel Corpus Filtering shared task. The task consisted in cleaning a very noisy English-German parallel corpus of 104 million sentence pairs provided by the organizers, with each EN-DE sentence pair accompanied by a score generated by the Hunalign sentence aligner. This paper describes the submission of the Institute for Language and Speech Processing/Athena Research and Innovation Center (IL"
W18-6484,2011.mtsummit-papers.47,0,0.670929,"already available parallel corpora in order to get word alignments, which are then used to identify mistranslations. Denkowski et al. (2012) use N-gram language models built from monolingual corpora to estimate probabilities of source and target sentences, in a manner of assigning high scores to grammatical sentences and lower scores to ungrammatical sentences and non-sentences such as site maps, large lists of names, and blog comments. Aiming to select sentence pairs of good adequacy and fluency, Xu and Koehn (2017) generate probabilistic dictionaries and n-gram models from Europarl corpora. Taghipour et al. (2011) and Cui et al. (2013) extract features based on translation and language models, and word alignments from the dataset under examination (i.e. this dataset is used to train models instead of using external language resources) and then apply unsupervised techniques such as outlier detection of estimated probability density and graph-based random walk algorithm to discard sentence pairs that are of limited or no importance. In the case of web acquired data, shallow features like aligners’ scores, length ratio, and patterns in URLs from which the content was originated, have been proposed (Espl`a"
W18-6484,P18-4020,0,0.0419971,"Missing"
W18-6484,D17-1319,0,0.261196,"Athens, Greece {vpapa, s sofian, prokopis, spip}@ilsp.gr Abstract Zarin¸a et al. (2015) exploit already available parallel corpora in order to get word alignments, which are then used to identify mistranslations. Denkowski et al. (2012) use N-gram language models built from monolingual corpora to estimate probabilities of source and target sentences, in a manner of assigning high scores to grammatical sentences and lower scores to ungrammatical sentences and non-sentences such as site maps, large lists of names, and blog comments. Aiming to select sentence pairs of good adequacy and fluency, Xu and Koehn (2017) generate probabilistic dictionaries and n-gram models from Europarl corpora. Taghipour et al. (2011) and Cui et al. (2013) extract features based on translation and language models, and word alignments from the dataset under examination (i.e. this dataset is used to train models instead of using external language resources) and then apply unsupervised techniques such as outlier detection of estimated probability density and graph-based random walk algorithm to discard sentence pairs that are of limited or no importance. In the case of web acquired data, shallow features like aligners’ scores,"
W18-6484,W15-4924,0,0.0597815,"Missing"
W18-6484,P07-2045,0,0.0111307,"Missing"
W18-6484,L18-1599,1,0.828515,"misalignments at document and/or sentence level generate sentence pairs that are not translations of each other. System architecture Our submission system is based on the cleaning module of the ILSP Focused Crawler (Papavassiliou et al., 2013), an open-source toolkit2 that integrates all necessary software3 for the creation of high-precision parallel resources from the web in a language-independent fashion. The toolkit and its cleaning module have been used in research projects like the European Language Resource Coordination for the acquisition of high-precision parallel language resources (Papavassiliou et al., 2018). 2.1 2.2 Filter-based clustering Given that the existence of the types of noise discussed above is not strongly influenced by the targeted language pair, we developed a language agnostic method with the purpose of clustering sentence pairs in respect of their quality, i.e. of their correctness and usefulness for training MT engines. The first cluster, C0 , includes obviously noisy sentence pairs. We assign to these pairs a 0 score in order to prohibit their participation in the subsamples to be used for training. Sentence pairs in C0 match one of the following patterns: Noise in Web acquired"
W98-1503,W96-0107,0,0.109832,"acting translation patterns of noun phrases from English-French parallel corpora. The corpus is tagged at partof~spcech (POS) level and then finite-state recognizers specified by regular expressions defined in tenns of POS categories detect noun phrases on either side. Probabilities of correspondences are then calculated using an iterative EM-like algorithm. Kumano and Hirakawa (1994) presuppose an ordinary bilingual dictimmy and non-parallel corpora, attempting to find bilingual conespondences in a Japanese-English setting at word, noun phrase and unknown word level. Extending previous work, Kitamura and Matsumoto (1996) apply the Dice coefficient on word sequence correspondence extraction. This paper describes a method for the automatic alignment of parallel texts at clause level. Texts are first aligned at sentence level using statistical techniques. Part-of-speech tagging takes place next annotating each word form with the appropriate part of speech. Processing in this step and the next one is monolingual, so each language side of the text is treated independently of the other. Surface syntactic analysis is performed next on the basis of regular grammars. Shallow parsing results in the recognition of claus"
W98-1503,C94-1009,0,0.0151592,"een instances of the English collocation and various single word candidates in English-French aligned corpora. Recent work has broadened the scope identifying correspondences between word sequences. Kupiec (1993) proposes a method for extracting translation patterns of noun phrases from English-French parallel corpora. The corpus is tagged at partof~spcech (POS) level and then finite-state recognizers specified by regular expressions defined in tenns of POS categories detect noun phrases on either side. Probabilities of correspondences are then calculated using an iterative EM-like algorithm. Kumano and Hirakawa (1994) presuppose an ordinary bilingual dictimmy and non-parallel corpora, attempting to find bilingual conespondences in a Japanese-English setting at word, noun phrase and unknown word level. Extending previous work, Kitamura and Matsumoto (1996) apply the Dice coefficient on word sequence correspondence extraction. This paper describes a method for the automatic alignment of parallel texts at clause level. Texts are first aligned at sentence level using statistical techniques. Part-of-speech tagging takes place next annotating each word form with the appropriate part of speech. Processing in this"
W98-1503,C88-1016,0,0.289933,"Missing"
W98-1503,P93-1003,0,0.0533769,"coefficient with comparable performance. Collocational conespondences have been studied by Smadja (1992) and Smadja et al. (1996), in an attempt to find h·anslation patterns for continuous and discontinuous collocations in English and French. Meaningful collocations are first extracted in the source language while their corresponding French ones are found by calculating the mutual information between instances of the English collocation and various single word candidates in English-French aligned corpora. Recent work has broadened the scope identifying correspondences between word sequences. Kupiec (1993) proposes a method for extracting translation patterns of noun phrases from English-French parallel corpora. The corpus is tagged at partof~spcech (POS) level and then finite-state recognizers specified by regular expressions defined in tenns of POS categories detect noun phrases on either side. Probabilities of correspondences are then calculated using an iterative EM-like algorithm. Kumano and Hirakawa (1994) presuppose an ordinary bilingual dictimmy and non-parallel corpora, attempting to find bilingual conespondences in a Japanese-English setting at word, noun phrase and unknown word level"
W98-1503,P91-1022,0,0.079511,"et language in the following ways: A. 1-0 and 0-1, when a clause of the source or the target sentence has no equivalent clause in the other language. B. 1-1, when a clause of the source sentence is translated into one clause of the target sentence. C. 1-2 and 2-1, when a clause of the source is translated into two clauses of the target or two clauses of the source translate into one of the target. D. 2-2, when two clauses jointly translate into two clauses of the other language. We view each group of aligned sentences of the parallel text as a sequence of clause-beads (after sentencebeads in (Brown et al., 1991)) where a bead accounts for a group of clauses that align with each other according to one of the above mentioned ways. A clause-alignment 20 Ai = { ail ai2 ... a in } for a given pair i of sentences Bead 1 is a set of clause-beads a ti covering all clauses of the Bead 2 Bead 3 ~····~·-~-""~-.-.,.--~~ 8 8 8 8 8 ______ 8 source and target sentence under the condition that each clause participates to one and only one clause-bead. Figure 3 shows a schematic example of a clausealignment between two sentences containing four and three clauses each. Making the assumption that translation of clauses i"
W98-1503,P93-1004,0,0.0394775,"Missing"
W98-1503,1992.tmi-1.7,0,0.0837968,"Missing"
W98-1503,J96-1001,0,0.047615,"same Dice coefficient to calculate the word similarity between Japanese-English parallel corpora. Single word correspondences have also been investigated by Gale and Church (1991 b) using a statistical evaluation of contingency tables. Piperidis et al. ( 1997) and Boutsis and Piperidis ( 1996) describe methods for extracting single and multi-word equivalences based on a parallel corpus statistically aligned at sentence level and employing a similarity metric along the lines of the Dice coefficient with comparable performance. Collocational conespondences have been studied by Smadja (1992) and Smadja et al. (1996), in an attempt to find h·anslation patterns for continuous and discontinuous collocations in English and French. Meaningful collocations are first extracted in the source language while their corresponding French ones are found by calculating the mutual information between instances of the English collocation and various single word candidates in English-French aligned corpora. Recent work has broadened the scope identifying correspondences between word sequences. Kupiec (1993) proposes a method for extracting translation patterns of noun phrases from English-French parallel corpora. The corp"
W98-1503,J90-2002,0,\N,Missing
W98-1503,J93-1006,0,\N,Missing
W98-1503,H91-1026,0,\N,Missing
