1993.eamt-1.16,J92-2002,0,\N,Missing
1993.eamt-1.16,P90-1017,0,\N,Missing
1993.eamt-1.16,P91-1025,0,\N,Missing
2013.mtsummit-wmwumttt.6,W03-1812,0,0.657202,"ut of so.’s sails”). Objectives and State of the Art Our approach to the identification of German MWEs (of the type preposition+noun+verb) makes use of their morpho-syntactic properties and their semantic transparency vs. opacity. We classify MWEs on the level of lexical types into idiomatic ones vs. trivial (non-idiomatic) word combinations. We start from the widely shared assumption that idiomaticity is often correlated with morphosyntactic fixedness, e.g. Bannard (2007), Fazly and Stevenson (2006), Weller and Heid (2010) and that idiomaticity implies an element of noncompositionality, e.g. Baldwin et al. (2003). The former type of features is observable in morphosyntactically analysed data; for the latter, which is not directly observable in monolingual corpora, we follow Villada Moir´on and Tiedemann (2006) and Fritzinger (2010) and induce transparency vs. opacity from bilingual corpora. We operate on MWE types, not on tokens; we consider individual occurrences and then sum up and average the feature values observed for one MWE type. Obviously, not all co-occurrences of lexemes that can be part of an MWE neccessarily can be interpreted as being idiomatic (cf. work on token-based analysis, e.g. Cook"
2013.mtsummit-wmwumttt.6,W07-1101,0,0.427007,"candidates identified as verb+PP collocations may be part of larger patterns, such as den Wind aus den Segeln nehmen (“to take the wind out of so.’s sails”). Objectives and State of the Art Our approach to the identification of German MWEs (of the type preposition+noun+verb) makes use of their morpho-syntactic properties and their semantic transparency vs. opacity. We classify MWEs on the level of lexical types into idiomatic ones vs. trivial (non-idiomatic) word combinations. We start from the widely shared assumption that idiomaticity is often correlated with morphosyntactic fixedness, e.g. Bannard (2007), Fazly and Stevenson (2006), Weller and Heid (2010) and that idiomaticity implies an element of noncompositionality, e.g. Baldwin et al. (2003). The former type of features is observable in morphosyntactically analysed data; for the latter, which is not directly observable in monolingual corpora, we follow Villada Moir´on and Tiedemann (2006) and Fritzinger (2010) and induce transparency vs. opacity from bilingual corpora. We operate on MWE types, not on tokens; we consider individual occurrences and then sum up and average the feature values observed for one MWE type. Obviously, not all co-o"
2013.mtsummit-wmwumttt.6,W09-2903,0,0.0200014,"olingual corpora, we follow Villada Moir´on and Tiedemann (2006) and Fritzinger (2010) and induce transparency vs. opacity from bilingual corpora. We operate on MWE types, not on tokens; we consider individual occurrences and then sum up and average the feature values observed for one MWE type. Obviously, not all co-occurrences of lexemes that can be part of an MWE neccessarily can be interpreted as being idiomatic (cf. work on token-based analysis, e.g. Cook et al. (2008), Fritzinger et al. (2010)). However, in lack of respective hand-crafted data, a classification on token level, as in e.g. Diab and Bhutada (2009) is beyond the scope of the present paper. 2.2 3 Preprocessing: Feature Collection In this section, we describe how all occurrences of the MWE candidates and their features are extracted. Later, in Section 4.2, we describe how the feature values of all occurrences of lexically identical MWE candidates are averaged and integrated into the classifier. 3.1 Candidate Extraction As German allows for a flexible constituent order, the components of an MWE need not always occur adjacently1 . Consider the following example sentence, where the verbal component of im Raum stehen (lit. “stand in the room”"
2013.mtsummit-wmwumttt.6,P01-1025,0,0.0362554,"ed by different researchers to identify MWEs: i) word association measures, ii) morpho-syntactic fixedness, iii) semantic opacity. Approaches based on word association measures exploit estimated vs. observed co-occurrence frequencies of an MWE’s content words and the expression as a whole to identify valid MWEs (e.g. Church and Hanks (1990)). Such approaches proved to work well, but their performance can easily be enhanced by additionally checking for syntactic consistency of the MWEs. This can be realised either by restricting the candidate list to a certain syntactic MWE pattern beforehand (Evert and Krenn, 2001) or by filtering out syntactically inconsistent MWEs after having identified highly associated word pairs (Smadja, 1993). More recently, some approaches came up with combinations of features addressing different characteristics of MWEs. (Ramisch et al., 2010) combine word association measures with alignmentbased approaches and use Bayesian Networks to predict MWEs, while (Weller and Fritzinger, 2010) combine morpho-syntactic fixedness with translational equivalences. In contrast, (Fothergill and Baldwin, 2011) combine morpho-syntactic fixedness with lexical hypernyms and (Tsvetkov 40 level bec"
2013.mtsummit-wmwumttt.6,evert-etal-2004-identifying,1,0.759068,"edness features (cf. Section 3.2) are extracted. While the dependency-parsed representation allows for the extraction of different syntactic patterns, we focus on preposition-noun-verb triples in the present paper. Specificities of MWE Extraction for German German has a relatively rich inflectional morphology, both in the nominal and verbal domain. Strong morpho-syntactic preferences in a word combination may thus indicate idiomatisation (i.e. MWE status). German also has a relatively free constituent order and, despite its morphological richness, substantial syncretism in nominal morphology (Evert et al., 2004); as a consequence, POS-pattern based approaches to MWE extraction tend to have low recall. As suggested by e.g. Seretan (2011), we thus use dependency parsing (Schiehlen, 2003) and extract MWE candidates from the parse output. In this paper, we concentrate on the extraction of verb+PP collocations. Examples are zur Sprache bringen (lit.: “to bring to language”, idiom.: to 3.2 Morpho-Syntactic Features MWEs often exhibit a certain degree of fixedness with respect to morphological or syntacti1 However, the words of semantically opaque MWEs mostly do occur adjacently and we use this adjacency as"
2013.mtsummit-wmwumttt.6,E06-1043,0,0.158523,"ified as verb+PP collocations may be part of larger patterns, such as den Wind aus den Segeln nehmen (“to take the wind out of so.’s sails”). Objectives and State of the Art Our approach to the identification of German MWEs (of the type preposition+noun+verb) makes use of their morpho-syntactic properties and their semantic transparency vs. opacity. We classify MWEs on the level of lexical types into idiomatic ones vs. trivial (non-idiomatic) word combinations. We start from the widely shared assumption that idiomaticity is often correlated with morphosyntactic fixedness, e.g. Bannard (2007), Fazly and Stevenson (2006), Weller and Heid (2010) and that idiomaticity implies an element of noncompositionality, e.g. Baldwin et al. (2003). The former type of features is observable in morphosyntactically analysed data; for the latter, which is not directly observable in monolingual corpora, we follow Villada Moir´on and Tiedemann (2006) and Fritzinger (2010) and induce transparency vs. opacity from bilingual corpora. We operate on MWE types, not on tokens; we consider individual occurrences and then sum up and average the feature values observed for one MWE type. Obviously, not all co-occurrences of lexemes that c"
2013.mtsummit-wmwumttt.6,J93-1007,0,0.4392,"and cross-lingual features (cf. “all” and “best”) lead to even higher f-scores with a statistically significant improvement with respect to the two baselines. Similarly, the percentage of correct classification decisions in Table 6 shows that combining morpho-syntactic and cross-lingual features results in higher prediction accuracy. The results in Table 6 and Table 5 confirms that features of different and independent dimensions (morpho-syntax vs. semantics) benefit from each other, and as a consequence, that their combination leads to an improved classification into MWEs and approach lang. (Smadja, 1993) (Bannard, 2007) (Baldwin et al., 2003) (Villada Moir´on and Tiedemann, 2006) (Weller and Fritzinger, 2010) (Ramisch et al., 2010) (Fothergill and Baldwin, 2011) (Tsvetkov and Wintner, 2011) present paper EN EN EN NL DE PT JA HE DE pattern? yes no X X X X X X X X X classification rank. sup. unsup. X X X X X X X X X frq. X identification m-s. sem. wa. X X X X X X X X X X X X X X X Table 7: Non-exhaustive overview of different approaches dealing with the identification of MWE types. The approaches are classified according to the following categories: pattern? (= is it restricted to MWEs of a cer"
2013.mtsummit-wmwumttt.6,I11-1102,0,0.0182961,"patterns, we focus on preposition-noun-verb triples in the present paper. Specificities of MWE Extraction for German German has a relatively rich inflectional morphology, both in the nominal and verbal domain. Strong morpho-syntactic preferences in a word combination may thus indicate idiomatisation (i.e. MWE status). German also has a relatively free constituent order and, despite its morphological richness, substantial syncretism in nominal morphology (Evert et al., 2004); as a consequence, POS-pattern based approaches to MWE extraction tend to have low recall. As suggested by e.g. Seretan (2011), we thus use dependency parsing (Schiehlen, 2003) and extract MWE candidates from the parse output. In this paper, we concentrate on the extraction of verb+PP collocations. Examples are zur Sprache bringen (lit.: “to bring to language”, idiom.: to 3.2 Morpho-Syntactic Features MWEs often exhibit a certain degree of fixedness with respect to morphological or syntacti1 However, the words of semantically opaque MWEs mostly do occur adjacently and we use this adjacency as an additional fixedness feature, as described in Section 3.2 below. 35 A B C name refl n-adj det-fus neg vorf num det adja des"
2013.mtsummit-wmwumttt.6,D11-1077,0,0.0358513,"Missing"
2013.mtsummit-wmwumttt.6,fritzinger-etal-2010-survey,1,0.80471,"e of features is observable in morphosyntactically analysed data; for the latter, which is not directly observable in monolingual corpora, we follow Villada Moir´on and Tiedemann (2006) and Fritzinger (2010) and induce transparency vs. opacity from bilingual corpora. We operate on MWE types, not on tokens; we consider individual occurrences and then sum up and average the feature values observed for one MWE type. Obviously, not all co-occurrences of lexemes that can be part of an MWE neccessarily can be interpreted as being idiomatic (cf. work on token-based analysis, e.g. Cook et al. (2008), Fritzinger et al. (2010)). However, in lack of respective hand-crafted data, a classification on token level, as in e.g. Diab and Bhutada (2009) is beyond the scope of the present paper. 2.2 3 Preprocessing: Feature Collection In this section, we describe how all occurrences of the MWE candidates and their features are extracted. Later, in Section 4.2, we describe how the feature values of all occurrences of lexically identical MWE candidates are averaged and integrated into the classifier. 3.1 Candidate Extraction As German allows for a flexible constituent order, the components of an MWE need not always occur adjac"
2013.mtsummit-wmwumttt.6,W06-2405,0,0.0691754,"Missing"
2013.mtsummit-wmwumttt.6,2005.mtsummit-papers.11,0,0.0116145,"Missing"
2013.mtsummit-wmwumttt.6,weller-heid-2010-extraction,1,0.901355,"s may be part of larger patterns, such as den Wind aus den Segeln nehmen (“to take the wind out of so.’s sails”). Objectives and State of the Art Our approach to the identification of German MWEs (of the type preposition+noun+verb) makes use of their morpho-syntactic properties and their semantic transparency vs. opacity. We classify MWEs on the level of lexical types into idiomatic ones vs. trivial (non-idiomatic) word combinations. We start from the widely shared assumption that idiomaticity is often correlated with morphosyntactic fixedness, e.g. Bannard (2007), Fazly and Stevenson (2006), Weller and Heid (2010) and that idiomaticity implies an element of noncompositionality, e.g. Baldwin et al. (2003). The former type of features is observable in morphosyntactically analysed data; for the latter, which is not directly observable in monolingual corpora, we follow Villada Moir´on and Tiedemann (2006) and Fritzinger (2010) and induce transparency vs. opacity from bilingual corpora. We operate on MWE types, not on tokens; we consider individual occurrences and then sum up and average the feature values observed for one MWE type. Obviously, not all co-occurrences of lexemes that can be part of an MWE nec"
2013.mtsummit-wmwumttt.6,W09-2904,0,0.0155536,"ches tackling the opaque semantics of MWEs: they are based on the assumption that the semantics of the expression as a whole cannot be derived from the semantics of its constituent words. While Baldwin et al. (2003) use Latent Semantic Analysis for this task, Villada Moir´on and Tiedemann (2006) present an approach that approximates the MWE’s semantics by deriving translational equivalences from parallel text. While Villada Moir´on and Tiedemann (2006) use word alignment only for ranking MWE candidates identified separately by means of syntactic patterns in parsed data, other approaches, e.g. Zarrieß and Kuhn (2009), de Caseli et al. (2010) use word alignment as basis for MWE extraction itself. The task of automatically identifying MWEs has gained much attention in the NLP research community in the past. The approaches that emerged are just as multi-dimensional as the phenomenon of MWEs itself, each tackling one (or more) specific characteristics of MWEs. Consider Table 7 for a partial overview. There are three of these characteristics that have been repeatedly implemented by different researchers to identify MWEs: i) word association measures, ii) morpho-syntactic fixedness, iii) semantic opacity. Appro"
2013.mtsummit-wmwumttt.6,W97-0207,0,0.392378,"Missing"
2013.mtsummit-wmwumttt.6,J03-1002,0,0.00630949,"Missing"
2013.mtsummit-wmwumttt.6,E03-1087,0,0.0504112,"f an MWE need not always occur adjacently1 . Consider the following example sentence, where the verbal component of im Raum stehen (lit. “stand in the room”, idiom. “to be dealt with”) occurs 4 words to the left of the preposition and the noun: (2) Also Thus steht das Ger¨ucht stands the rumor weiter still im in the Raum room Thus the rumor to be dealt with is still Thus the rumor is still to be dealt with A deep syntactic analysis is thus required in order to reliably extract candidate triples, regardless of the actual constituent order or the distance of their component words. We use FSPAR (Schiehlen, 2003), a finite-state based dependency parser providing good lexical coverage and a full morpho-syntactic analysis (including POS, lemma, gender, number, case, compound splitting). Based on this annotation, the morphosyntactic fixedness features (cf. Section 3.2) are extracted. While the dependency-parsed representation allows for the extraction of different syntactic patterns, we focus on preposition-noun-verb triples in the present paper. Specificities of MWE Extraction for German German has a relatively rich inflectional morphology, both in the nominal and verbal domain. Strong morpho-syntactic"
2014.eamt-1.3,I05-1062,0,0.029267,"s to specifically indicate how a term in a given context should be translated. For example, it provides the means to guarantee that a source-language term in plural is translated by the corresponding targetlanguage term in plural, regardless of whether the required inflected form occurs in the training data. Although there are exceptions such as furnitureSG → meublesP L , we believe they play a negligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which crea"
2014.eamt-1.3,P11-2071,0,0.0480483,"Missing"
2014.eamt-1.3,2012.amta-monomt.1,0,0.0225543,"ochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table entries dynamically. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga e"
2014.eamt-1.3,E12-1068,1,0.838785,"ally. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga et al. (2012) use a component for targetside morphological generation to translate news and web-log data. In contrast to our work, they do not deal with nominal morphology, but model verb inflection: this is important for web-log data, as second-person verb forms rarely appear in Europarltype training data. Wu et al. (2008) use dictionary entries for adapting a system trained on Europarl to news, but without applying morphological modelling to their EN-FR system. Furthermore, news and also web-log data are considerably more similar to Europarl than technical data. Our main contributi"
2014.eamt-1.3,P08-1088,0,0.0349715,"te how a term in a given context should be translated. For example, it provides the means to guarantee that a source-language term in plural is translated by the corresponding targetlanguage term in plural, regardless of whether the required inflected form occurs in the training data. Although there are exceptions such as furnitureSG → meublesP L , we believe they play a negligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table en"
2014.eamt-1.3,P10-1052,0,0.0644516,"Missing"
2014.eamt-1.3,P11-1133,0,0.0177919,"r example, it provides the means to guarantee that a source-language term in plural is translated by the corresponding targetlanguage term in plural, regardless of whether the required inflected form occurs in the training data. Although there are exceptions such as furnitureSG → meublesP L , we believe they play a negligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table entries dynamically. Pinnis and Skadins (2012) also studied mini"
2014.eamt-1.3,C08-1098,0,0.103118,"F] vendre[VPP] ` a[P] le<+DET>[ART] r´ eseau<M.Sg>[N] pred. feat. M.Sg M.Sg – F.Sg – – M.Sg – M.Sg M.Sg gen. forms le exc`es de e´ nergie peut eˆ tre vendu a` le r´eseau postproc. l’ exc`es d’ e´ nergie peut eˆ tre vendu au r´eseau gloss the excess of energy can be sold to the grid Table 2: Processing steps for the EN input sentence [ ... ] excess energy can be sold back to the grid. 4 Inflection prediction system To build the morphology-aware system, the targetside data (parallel and language model data) is transformed into a stemmed format, based on the annotation of a morphological tagger (Schmid and Laws, 2008). This representation contains translationrelevant feature markup: nouns are marked with gender (considered part of the stem) and number. Assuming that source-side nouns are translated by nouns with the same number value, this feature is indirectly determined by the source-side input. The number markup is thus needed to ensure that the source-side number information is transferred to the target side. For a better generalization, we split portmanteau prepositions into article and preposition (au → a` +le: to+the). For predicting the morphological features of the SMT output (number and gender),"
2014.eamt-1.3,schmid-etal-2004-smor,1,0.646479,"n CRFs on combinations of the wind corpus and the FR part of the parallel data. The CRF has access to the basic features stem and POS tag as well as gender and number within a window of 5 positions to each side of the current word. The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological features, we use an extended version of the finitestate morphology FRMOR (Zhou, 2007). FRMOR is a morphology tool similar to SMOR (Schmid et al., 2004), which allows to analyze and generate inflected word forms. The term alignment requires a general language dictionary6 from which we use the 36,963 1-to-1 entries. 8 7 Data and resources Our experiments are carried out on an EN-FR standard phrase-based Moses5 system which is adapted to the domain of wind energy. As a basis for terminology mining, we compiled a target-language corpus for that domain. This included documents obtained by automatic crawling (de Groc, 2011), and manually obtained data from various web-sites. In total, the corpus consists of 161.367 sentences (4.136.751 words). For"
2014.eamt-1.3,I08-2089,0,0.0267387,"features. However, this creates two new problems: first, the representation without number markup loses discriminatory power4 . For example, there is no way to guarantee subject-verb agreement without number information on nouns. The second problem is that parallel domain-specific data is needed to train the models for feature prediction. While we believe that removing number markup in the translation step is a sounder way to deal with targetside morphology in this application, we leave this extension of our model to future work due to the practical problems that arise with this. approach of Schwenk and Koehn (2008). For the feature prediction, we used the Wapiti toolkit (Lavergne et al., 2010) to train CRFs on combinations of the wind corpus and the FR part of the parallel data. The CRF has access to the basic features stem and POS tag as well as gender and number within a window of 5 positions to each side of the current word. The morphological analysis of the French training data is obtained using RFTagger, which is designed for annotating fine-grained morphological tags (Schmid and Laws, 2008). For generating inflected forms based on stems and morphological features, we use an extended version of the"
2014.eamt-1.3,P08-1059,0,0.0801463,"phrase table entries dynamically. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga et al. (2012) use a component for targetside morphological generation to translate news and web-log data. In contrast to our work, they do not deal with nominal morphology, but model verb inflection: this is important for web-log data, as second-person verb forms rarely appear in Europarltype training data. Wu et al. (2008) use dictionary entries for adapting a system trained on Europarl to news, but without applying morphological modelling to their EN-FR system. Furthermore, news and also web-log data are considerably more similar to Europarl than technical"
2014.eamt-1.3,weller-heid-2012-analyzing,1,0.925147,"gligible role when translating under-resourced domains. 2 Related work There has been considerable interest in mining translations directly from comparable corpora. A few representative examples are (Daille and Morin, 2005; Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011; Prochasson and Fung, 2011), all 12 of which mine terms using distributional similarity. These approaches tend to favor recall over precision. In contrast, we use a high-precision method consisting in recognizing term candidates by means of partof-speech patterns with an alignment method relying on dictionary entries (Weller and Heid, 2012). A second strand of relevant work is the integration of terms into SMT decoding. H´alek et al. (2011) integrated named entity translations mined from Wikipedia using the XML mode of Moses, which creates new phrase table entries dynamically. Pinnis and Skadins (2012) also studied mining named entities, as well as using a high quality terminological database, and added these resources to the parallel training data. We compare these two options (XML vs. added parallel data) and show that adding the terms to the parallel training data leads to better results. To deal with the issue of obtaining t"
2014.eamt-1.3,C08-1125,0,0.0283419,"the issue of obtaining the proper inflection of mined terms, we implemented a morphology-aware English to French translation system that separates the translation task into two steps (translation + inflection generation), following Toutanova et al. (2008) and Fraser et al. (2012). Formiga et al. (2012) use a component for targetside morphological generation to translate news and web-log data. In contrast to our work, they do not deal with nominal morphology, but model verb inflection: this is important for web-log data, as second-person verb forms rarely appear in Europarltype training data. Wu et al. (2008) use dictionary entries for adapting a system trained on Europarl to news, but without applying morphological modelling to their EN-FR system. Furthermore, news and also web-log data are considerably more similar to Europarl than technical data. Our main contribution is that we show how to combine three areas of research: bilingual term mining, using terms in SMT, and generation of inflection for SMT. We describe a novel end-to-end morphology-aware solution for using bilingual term mining in SMT decoding. 3 Bilingual terminology mining In contrast to parallel corpora, which are difficult to ob"
C10-2070,W09-0212,1,0.943508,"f-speech patterns based on a version of the corpus tagged with TreeTagger (Schmid, 1994). We use lemmas instead of surface forms. Because we perform the SimRank matrix multiplications in memory, we need to filter out rare words and relations; otherwise, running SimRank to convergence would not be feasible. For adjective-noun pairs, we apply a filter on de en n a v 34,545 10,067 2,828 22,257 12,878 4,866 ncrd amod dobj 65,299 417,151 143,906 288,889 686,073 510,351 Table 2: Node and edge statistics 4 SimRank Our work is based on the SimRank graph similarity algorithm (Jeh and Widom, 2002). In (Dorow et al., 2009), we proposed a formulation of SimRank in terms of matrix operations, which can be applied to (i) weighted graphs and (ii) bilingual problems. We now briefly review SimRank and its bilingual extension. For more details we refer to (Dorow et al., 2009). The basic idea of SimRank is to consider two nodes as similar if they have similar neighborhoods. Node similarity scores are recursively computed from the scores of neighboring nodes: the similarity Sij of two nodes i and j is computed 616 as the normalized sum of the pairwise similarities of their neighbors: X c Skl . Sij = |N (i) ||N (j)| k∈N"
C10-2070,J93-1003,0,0.0215787,"ject subcategorization a man sleeps poss n, n possessive the child’s toy acrd a, a adjective coordination red or blue car Table 1: Relations used in this paper (top) and possible extensions (bottom). dobj amod ncrd verb adjective noun interesting article idea like political book magazine pair frequency (≥ 3). We process noun pairs by applying a frequency threshold on words (≥ 100) and pairs (≥ 3). Verb-object pairs (the smallest data set) were not frequency-filtered. Based on the resulting frequency counts, we calculate association scores for all relationships using the loglikelihood measure (Dunning, 1993). For noun pairs, we discard all pairs with an association score &lt; 3.84 (significance at α = .05). For all three relations, we discard pairs whose observed frequency was smaller than their expected frequency (Evert, 2004, p. 76). As a last step, we further reduce noise by removing nodes of degree 1. Key statistics for the resulting graphs are given in Table 2. We have found that accuracy of extraction is poor if unweighted edges are used. Using the log-likelihood score directly as edge weight gives too much weight to “semantically weak” highfrequency words like put and take. We therefore use t"
C10-2070,C04-1024,0,0.0229047,"fore use the logarithms of the log-likelihood score as edge weights in all SimRank computations reported in this paper. nodes promote de en Figure 2: Graph snippet with typed edges edges promote. Based on amod and dobj, the four nouns are equally similar to each other. However, the greater similarity of article, book, and magazine to each other can be deduced from the fact that these three nouns also occur in the relation ncrd. We exploit this information in the MEE method. Data and Preprocessing. Our corpus in this paper is the Wikipedia. We parse all German and English articles with BitPar (Schmid, 2004) to extract verb-argument relations. We extract adjective-noun modification and noun coordinations with part-of-speech patterns based on a version of the corpus tagged with TreeTagger (Schmid, 1994). We use lemmas instead of surface forms. Because we perform the SimRank matrix multiplications in memory, we need to filter out rare words and relations; otherwise, running SimRank to convergence would not be feasible. For adjective-noun pairs, we apply a filter on de en n a v 34,545 10,067 2,828 22,257 12,878 4,866 ncrd amod dobj 65,299 417,151 143,906 288,889 686,073 510,351 Table 2: Node and edg"
C10-2070,P98-1069,0,0.323919,"hampered by the lack of a common benchmark; we therefore publish a benchmark and the performance of MEE as a baseline for future research. The paper discusses related work in Section 2. We then describe our translation model (Section 3) and multi-edge extraction (Section 4). The benchmark we publish as part of this paper is described in Section 5. Section 6 presents our experimental results and Section 7 analyzes and discusses them. Section 8 summarizes. 2 Related Work Rapp (1999) uses word cooccurrence in a vector space model for bilingual lexicon extraction. Details are given in Section 5. Fung and Yee (1998) also use a vector space approach, but use TF/IDF values in the vector components and experiment with different vector similarity measures for ranking the translation candidates. Koehn and Knight (2002) combine 614 Coling 2010: Poster Volume, pages 614–622, Beijing, August 2010 a vector-space approach with other clues such as orthographic similarity and frequency. They report an accuracy of .39 on the 1000 most frequent English-German noun translation pairs. Garera et al. (2009) use a vector space model with dependency links as dimensions instead of cooccurring words. They report outperforming"
C10-2070,W09-1117,0,0.456159,"999) uses word cooccurrence in a vector space model for bilingual lexicon extraction. Details are given in Section 5. Fung and Yee (1998) also use a vector space approach, but use TF/IDF values in the vector components and experiment with different vector similarity measures for ranking the translation candidates. Koehn and Knight (2002) combine 614 Coling 2010: Poster Volume, pages 614–622, Beijing, August 2010 a vector-space approach with other clues such as orthographic similarity and frequency. They report an accuracy of .39 on the 1000 most frequent English-German noun translation pairs. Garera et al. (2009) use a vector space model with dependency links as dimensions instead of cooccurring words. They report outperforming a cooccurrence vector model by 16 percentage points accuracy on English-Spanish. Haghighi et al. (2008) use a probabilistic model over word feature vectors containing cooccurrence and orthographic features. They then use canonical correlation analysis to find matchings between words in a common latent space. They evaluate on multiple languages and report high precision even without a seed lexicon. Most previous work has used vector spaces and (except for Garera et al. (2009)) c"
C10-2070,P08-1088,0,0.352091,"and experiment with different vector similarity measures for ranking the translation candidates. Koehn and Knight (2002) combine 614 Coling 2010: Poster Volume, pages 614–622, Beijing, August 2010 a vector-space approach with other clues such as orthographic similarity and frequency. They report an accuracy of .39 on the 1000 most frequent English-German noun translation pairs. Garera et al. (2009) use a vector space model with dependency links as dimensions instead of cooccurring words. They report outperforming a cooccurrence vector model by 16 percentage points accuracy on English-Spanish. Haghighi et al. (2008) use a probabilistic model over word feature vectors containing cooccurrence and orthographic features. They then use canonical correlation analysis to find matchings between words in a common latent space. They evaluate on multiple languages and report high precision even without a seed lexicon. Most previous work has used vector spaces and (except for Garera et al. (2009)) cooccurrence data. Our approach uses linguistic relations like subcategorization, modification and coordination in a graph-based model. Further, we evaluate our approach on different parts of speech, whereas some previous"
C10-2070,W02-0902,0,0.367552,"cribe our translation model (Section 3) and multi-edge extraction (Section 4). The benchmark we publish as part of this paper is described in Section 5. Section 6 presents our experimental results and Section 7 analyzes and discusses them. Section 8 summarizes. 2 Related Work Rapp (1999) uses word cooccurrence in a vector space model for bilingual lexicon extraction. Details are given in Section 5. Fung and Yee (1998) also use a vector space approach, but use TF/IDF values in the vector components and experiment with different vector similarity measures for ranking the translation candidates. Koehn and Knight (2002) combine 614 Coling 2010: Poster Volume, pages 614–622, Beijing, August 2010 a vector-space approach with other clues such as orthographic similarity and frequency. They report an accuracy of .39 on the 1000 most frequent English-German noun translation pairs. Garera et al. (2009) use a vector space model with dependency links as dimensions instead of cooccurring words. They report outperforming a cooccurrence vector model by 16 percentage points accuracy on English-Spanish. Haghighi et al. (2008) use a probabilistic model over word feature vectors containing cooccurrence and orthographic feat"
C10-2070,michelbacher-etal-2010-building,1,0.875682,"Missing"
C10-2070,P99-1067,0,0.579143,"vel method, multi-edge extraction, which is both modular and scalable; (iv) progress in bilingual lexicon extraction has been hampered by the lack of a common benchmark; we therefore publish a benchmark and the performance of MEE as a baseline for future research. The paper discusses related work in Section 2. We then describe our translation model (Section 3) and multi-edge extraction (Section 4). The benchmark we publish as part of this paper is described in Section 5. Section 6 presents our experimental results and Section 7 analyzes and discusses them. Section 8 summarizes. 2 Related Work Rapp (1999) uses word cooccurrence in a vector space model for bilingual lexicon extraction. Details are given in Section 5. Fung and Yee (1998) also use a vector space approach, but use TF/IDF values in the vector components and experiment with different vector similarity measures for ranking the translation candidates. Koehn and Knight (2002) combine 614 Coling 2010: Poster Volume, pages 614–622, Beijing, August 2010 a vector-space approach with other clues such as orthographic similarity and frequency. They report an accuracy of .39 on the 1000 most frequent English-German noun translation pairs. Gare"
C10-2070,C98-1066,0,\N,Missing
C12-1068,E06-2001,0,0.028167,"Missing"
C12-1068,C10-1011,0,0.0139818,"eled as exclusively belonging to the MAN class. A careful scrutiny however shows that nachlabern can also occur with the CRE reading. 1120 nach-reading DIR MAN CRE OMR CONT P 0.889 0.716 0.865 0.755 0.876 Pe 0.689 0.642 0.774 0.626 0.811 κ 0.642 0.205 0.403 0.346 0.344 Table 4: Inter-annotator agreement on nach reading wrt. lemmas syntactic features appearing with the nach-PVs. We chose two parsers based on different concepts to complement one another, i.e. by taking the individual strengths of each parser into account when extracting indicators from their results. The Bohnet-Parser (BP), cf. Bohnet (2010), is a data-driven state-of-the-art dependency parser. It makes use of a rich feature model and a second order maximum-spanning-tree algorithm (McDonald and Pereira, 2006). The parser also includes its own processing pipeline containing statistical lemmatization, part-of-speech tagging, and morphological tagging on an already tokenized input. The output structure are non-projective dependency trees in the tabular representation format of CoNLL 2009’s shared task. Regarding labeled syntactic accuracy in this shared task, the Bohnet-Parser was the second best system and the best system for Engli"
C12-1068,W99-0623,0,0.0353532,"bination To extract reading indicators from the large data set, we make use of our findings on the test set. The quality of the accusative and dative argument recognition is seen as an approximation of the overall parsing quality relative to the task of indicator identification. To extract more reliable indicators, we combine the results of FSPar and the Bohnet-Parser. By this approach, we trust in the hypothesis that the combined result exceeds the best single result, which has been confirmed for a set of speech recognition systems by Fiscus (1997), for a set of constituency-based parsers by Henderson and Brill (1999) and for a set of dependency parsers by Zeman and Žabokrtský (2005), among others. As our combination is task specific, we do not make use of complex heuristics or approaches handling the complete parse, but define some extraction rules based on the evaluation results from Section 4.1. Tables 6 show the combination rules which we applied in the indicator extraction. Due to the underspecification representation of FSPar the combination rules distinguish between the two binary features “nach-PV has an argument of case X”, where X is in {DAT,ACC}, and the feature denoting the argument form. Table"
C12-1068,E06-1011,0,0.0177967,"AN CRE OMR CONT P 0.889 0.716 0.865 0.755 0.876 Pe 0.689 0.642 0.774 0.626 0.811 κ 0.642 0.205 0.403 0.346 0.344 Table 4: Inter-annotator agreement on nach reading wrt. lemmas syntactic features appearing with the nach-PVs. We chose two parsers based on different concepts to complement one another, i.e. by taking the individual strengths of each parser into account when extracting indicators from their results. The Bohnet-Parser (BP), cf. Bohnet (2010), is a data-driven state-of-the-art dependency parser. It makes use of a rich feature model and a second order maximum-spanning-tree algorithm (McDonald and Pereira, 2006). The parser also includes its own processing pipeline containing statistical lemmatization, part-of-speech tagging, and morphological tagging on an already tokenized input. The output structure are non-projective dependency trees in the tabular representation format of CoNLL 2009’s shared task. Regarding labeled syntactic accuracy in this shared task, the Bohnet-Parser was the second best system and the best system for English and German. The model we utilized in our experiments was trained on a dependency version of the German TiGer treebank (Brants et al., 2002), as described in Seeker and"
C12-1068,D07-1043,0,0.0279358,"beyond argument structure, as described in Section 2.2, we successively add four other types of features: (i) the word form of the dative/accusative arguments, (ii) a combination of preposition form, case value, and prepositional object form for each prepositional dependent of the verb, (iii) the word form of adverbials depending on the verb, and (iv) the presence of clausal objects. We use Ward’s algorithm (Ward, 1963) to produce the clustering of the verbs in our gold standard with the number of output clusters set to 18.6 In order to evaluate our clusters, we use the v-measure proposed in Rosenberg and Hirschberg (2007), which is defined as the harmonic mean of homogeneity and completeness. Both metrics are defined based on entropy of the clusters, where homogeneity measures the distribution of gold standard classes within each cluster and completeness measures the distribution of clusters within each gold standard class.7 features (added up) dat,acc ⊕ datform,accform ⊕ pp-form-case-pobjform ⊕ adverbials ⊕ clausal objects homogeneity BP FSPar combined 32.96 37.62 38.23 33.24 33.53 36.04 34.40 35.18 36.08 35.78 37.77 41.76 39.56 39.31 41.49 completeness BP FSPar combined 28.20 30.11 30.23 30.27 28.19 29.82 30"
C12-1068,E03-1087,0,0.0184479,"s own processing pipeline containing statistical lemmatization, part-of-speech tagging, and morphological tagging on an already tokenized input. The output structure are non-projective dependency trees in the tabular representation format of CoNLL 2009’s shared task. Regarding labeled syntactic accuracy in this shared task, the Bohnet-Parser was the second best system and the best system for English and German. The model we utilized in our experiments was trained on a dependency version of the German TiGer treebank (Brants et al., 2002), as described in Seeker and Kuhn (2012). FSPar (FP), cf. Schiehlen (2003), is a rule-based dependency parser based on the approach by Abney (1996) of partial parsing by finite state cascades. FSPar also processes its own internal pipeline, which includes lexically informed tokenizing and lemmatizing and part-of-speech tagging with the TreeTagger, cf. Schmid (1994). Not only the tokenizing step but also the parsing makes use of a large integrated lexical knowledge base, e.g. including named entities. FSPar generates underspecified dependency graphs. Underspecification is applied with respect to head selection as well as dependency labels. If the attachment to a head"
C12-1068,seeker-kuhn-2012-making,1,0.725485,"eira, 2006). The parser also includes its own processing pipeline containing statistical lemmatization, part-of-speech tagging, and morphological tagging on an already tokenized input. The output structure are non-projective dependency trees in the tabular representation format of CoNLL 2009’s shared task. Regarding labeled syntactic accuracy in this shared task, the Bohnet-Parser was the second best system and the best system for English and German. The model we utilized in our experiments was trained on a dependency version of the German TiGer treebank (Brants et al., 2002), as described in Seeker and Kuhn (2012). FSPar (FP), cf. Schiehlen (2003), is a rule-based dependency parser based on the approach by Abney (1996) of partial parsing by finite state cascades. FSPar also processes its own internal pipeline, which includes lexically informed tokenizing and lemmatizing and part-of-speech tagging with the TreeTagger, cf. Schmid (1994). Not only the tokenizing step but also the parsing makes use of a large integrated lexical knowledge base, e.g. including named entities. FSPar generates underspecified dependency graphs. Underspecification is applied with respect to head selection as well as dependency l"
C12-1068,springorum-etal-2012-automatic,0,0.0238027,"ows a range of different meanings. Haselbach (2011) provides a partial classification of nach into five readings that behave differently with respect to licensing a dative argument: 1. 2. ⊕DAT: direction reading (DIR) ⊕DAT: copy manner reading (MAN) 3. 4. 5. ⊖DAT: copy creation reading (CRE) ⊖DAT: once-more/restitution reading (OMR) ⊖DAT: continuation reading (CONT) This classification does not cover yet e.g. an intensifying reading such as in nachdenken (‘to reflect’) or a prove/check reading such as in nachprüfen (‘to recheck’). 1 For similar work on the German verb particle an (≈ ‘on’) see Springorum et al. (2012) 1114 2.1 Modeling at the syntax-semantics interface (Haselbach, 2011) provides a syntactico-semantic modeling of the five readings of nach in terms of Discourse Representation Theory (e.g. Kamp and Reyle, 1993; Roßdeutscher and Kamp, 2010), combined with word-syntactic principles from Distributed Morphology (Halle and Marantz, 1993). Haselbach (2011) implements them by means of the extended VP-shell hypothesis (Larson, 1990). His syntactico-semantic modeling comes close to Nicol’s (2002) implementation who argues that verb particles are spelled out instances of functional heads in the verbal"
C12-1068,W05-1518,0,0.01246,"make use of our findings on the test set. The quality of the accusative and dative argument recognition is seen as an approximation of the overall parsing quality relative to the task of indicator identification. To extract more reliable indicators, we combine the results of FSPar and the Bohnet-Parser. By this approach, we trust in the hypothesis that the combined result exceeds the best single result, which has been confirmed for a set of speech recognition systems by Fiscus (1997), for a set of constituency-based parsers by Henderson and Brill (1999) and for a set of dependency parsers by Zeman and Žabokrtský (2005), among others. As our combination is task specific, we do not make use of complex heuristics or approaches handling the complete parse, but define some extraction rules based on the evaluation results from Section 4.1. Tables 6 show the combination rules which we applied in the indicator extraction. Due to the underspecification representation of FSPar the combination rules distinguish between the two binary features “nach-PV has an argument of case X”, where X is in {DAT,ACC}, and the feature denoting the argument form. Tables 6a and b show the combination rules for the binary features. ⊕DAT"
eberle-etal-2012-tool,riester-etal-2010-recursive,0,\N,Missing
eberle-etal-2012-tool,W07-1501,0,\N,Missing
evert-etal-2004-identifying,heid-etal-2004-tools,1,\N,Missing
evert-etal-2004-identifying,evert-2004-statistical,1,\N,Missing
faass-etal-2010-design,E03-1087,0,\N,Missing
faass-etal-2010-design,E06-2001,0,\N,Missing
faass-etal-2010-design,quasthoff-etal-2006-corpus,0,\N,Missing
faass-etal-2010-design,hinrichs-etal-2010-weblicht,0,\N,Missing
faass-etal-2010-design,schmid-etal-2004-smor,1,\N,Missing
faass-etal-2010-design,heid-etal-2010-corpus,1,\N,Missing
fritzinger-etal-2010-survey,sporleder-etal-2010-idioms,0,\N,Missing
fritzinger-etal-2010-survey,E03-1087,0,\N,Missing
fritzinger-etal-2010-survey,W06-1203,0,\N,Missing
fritzinger-etal-2010-survey,E09-1086,0,\N,Missing
fritzinger-etal-2010-survey,W07-1101,0,\N,Missing
fritzinger-etal-2010-survey,J09-1005,0,\N,Missing
fritzinger-etal-2010-survey,W03-1812,0,\N,Missing
fritzinger-etal-2010-survey,2005.mtsummit-papers.11,0,\N,Missing
fritzinger-etal-2010-survey,E06-1043,0,\N,Missing
gojun-etal-2012-adapting,C08-1098,0,\N,Missing
gojun-etal-2012-adapting,W00-0901,0,\N,Missing
gojun-etal-2012-adapting,C94-1084,0,\N,Missing
gojun-etal-2012-adapting,I08-2084,0,\N,Missing
gojun-etal-2012-adapting,schmid-etal-2004-smor,1,\N,Missing
haselbach-heid-2010-development,W96-0102,0,\N,Missing
haselbach-heid-2010-development,C08-1098,0,\N,Missing
haselbach-heid-2010-development,A00-1031,0,\N,Missing
haselbach-heid-2010-development,W09-0706,1,\N,Missing
heid-etal-2004-querying,mengel-lezius-2000-xml,0,\N,Missing
heid-etal-2004-querying,bird-etal-2000-towards,0,\N,Missing
heid-etal-2004-querying,P03-1068,1,\N,Missing
heid-etal-2004-querying,milde-gut-2002-tasx,1,\N,Missing
heid-etal-2010-corpus,hinrichs-etal-2010-weblicht,1,\N,Missing
heid-etal-2010-corpus,C04-1024,1,\N,Missing
heid-etal-2010-corpus,W07-1501,0,\N,Missing
heid-etal-2010-corpus,kountz-etal-2008-laf,1,\N,Missing
heid-etal-2010-corpus,P10-4005,1,\N,Missing
heid-etal-2010-term,weller-heid-2010-extraction,1,\N,Missing
heid-etal-2010-term,ivanova-etal-2008-evaluating,1,\N,Missing
heid-etal-2010-term,C04-1024,0,\N,Missing
heid-etal-2010-term,E03-1087,0,\N,Missing
heid-etal-2010-term,W03-0804,0,\N,Missing
heid-etal-2010-term,hinrichs-etal-2010-weblicht,1,\N,Missing
heid-etal-2010-term,P10-4005,1,\N,Missing
heid-etal-2010-term,heid-etal-2010-corpus,1,\N,Missing
heid-weller-2008-tools,todirascu-etal-2008-hybrid,1,\N,Missing
heid-weller-2008-tools,steinberger-etal-2006-jrc,0,\N,Missing
heid-weller-2008-tools,J93-1007,0,\N,Missing
heid-weller-2008-tools,W06-1006,0,\N,Missing
heid-weller-2008-tools,P01-1025,0,\N,Missing
heid-weller-2008-tools,ritz-heid-2006-extraction,1,\N,Missing
heid-weller-2008-tools,E06-1043,0,\N,Missing
I08-1051,burchardt-etal-2006-salsa,1,0.931521,"ularity offered by a given annotation layer may diverge considerably from the granularity that is needed for the integration of corpus-derived data in large symbolic processing architectures or general lexical resources. This problem is multiplied when more than one layer of annotation is considered, for example in the characterisation of interface phenomena. While it may be possible to obtain coarser-grained representations procedurally by collapsing categories, such procedures are not flexibly configurable. Figure 1 illustrates these difficulties with a sentence from the SALSA/TIGER corpus (Burchardt et al., 2006), a manually annotated German newspaper corpus which contains role-semantic analyses in the FrameNet paradigm (Fillmore et al., 2003) on top of syntactic structure (Brants et al., 2002).1 The se1 While FrameNet was originally developed for English, the majority of frames has been found to generalise well to other 389 which the official Croatia but in significant international-law difficulties bring would Figure 1: Multi-layer annotation of a German phrase with syntax and frame semantics (‘which would bring official Croatia into significant difficulties with international law’) mantic structure"
I08-1051,E03-1068,0,0.0163518,"namely 4 missing metaphor flags and 4 omitted underspecification links. On the semantic level, we extracted annotation instances (in context) for metaphorical vs. nonmetaphorical readings, or frames that are involved in underspecification in certain sentences, but not in others. While the result sets thus obtained still require manual inspection, they clearly illustrate how the detection of inconsistencies can be enhanced by a declarative formalisation of the annotation scheme. Another strategy could be to concentrate on frames or lemmas exhibiting proportionally high variation in annotation (Dickinson and Meurers, 2003). 6 Conclusion In this paper, we have constructed a Description Logics-based lexicon model directly from multi-layer linguistic corpus annotations. We have shown how such a model allows for explicit data modelling, and for flexible and fine-grained definition of various degrees of abstractions over corpus annotations. Furthermore, we have demonstrated that a powerful logical formalisation which integrates an underlying annotation scheme can be used to directly control consistency of the annotations using general KR techniques. It can also overcome limitations of current XML-based search tools"
I08-1051,J02-3001,0,0.00609142,"roblematic are intersecting hierarchies, i.e., tree-shaped analyses on multiple linguistic levels. Introduction Over the years, much effort has gone into the creation of large corpora with multiple layers of linguistic annotation, such as morphology, syntax, semantics, and discourse structure. Such corpora offer the possibility to empirically investigate the interactions between different levels of linguistic analysis. Currently, the most common use of such corpora is the acquisition of statistical models that make use of the “more shallow” levels to predict the “deeper” levels of annotation (Gildea and Jurafsky, 2002; Miltsakaki et al., 2005). While these models fill an important need for practical applications, they fall short of the general task of lexicon modelling, i.e., creating an abstracted and compact representation of the corpus information that lends itself to ’linguistically informed’ usages such as human interpretation or integration with other knowledge sources (e.g., deep grammar resources or ontologies). In practice, this task faces three major problems: ∗ At the time of writing, Sebastian Padó and Dennis Spohr were affiliated with Saarland University, and Anette Frank with DFKI Saarbrücken"
I08-1051,U04-1019,0,0.0261719,"heme. We present a general approach to formally modelling corpora with multi-layered annotation, thereby inducing a lexicon model in a typed logical representation language, OWL DL. This model can be interpreted as a graph structure that offers flexible querying functionality beyond current XML-based query languages and powerful methods for consistency control. We illustrate our approach by applying it to the syntactically and semantically annotated SALSA/TIGER corpus. 1 4 Dept. of Linguistics Stanford University Stanford, CA Querying multiple layers of linguistic annotation. A recent survey (Lai and Bird, 2004) found that currently available XML-based corpus query tools support queries operating on multiple linguistic levels only in very restricted ways. Particularly problematic are intersecting hierarchies, i.e., tree-shaped analyses on multiple linguistic levels. Introduction Over the years, much effort has gone into the creation of large corpora with multiple layers of linguistic annotation, such as morphology, syntax, semantics, and discourse structure. Such corpora offer the possibility to empirically investigate the interactions between different levels of linguistic analysis. Currently, the m"
I08-1051,W06-1007,0,0.0219647,"mantics of the model makes it possible to use general and efficient knowledge representation techniques for consistency control. Finally, we can extract specific subsets from a corpus by defining task-specific views on the graph. After a short discussion of related approaches in languages (Burchardt et al., 2006; Boas, 2005). Section 2, Section 3 provides details on our methodology. Sections 4 and 5 demonstrate the benefits of our strategy on a model of the SALSA/TIGER data. Section 6 concludes. 2 Related Work One recent approach to lexical resource modelling is the Lexical Systems framework (Polguère, 2006), which aims at providing a highly general representation for arbitrary kinds of lexica. While this is desirable from a representational point of view, the resulting models are arguably too generic to support strong consistency checks on the encoded data. A further proposal is the currently evolving Lexical Markup Framework (LMF; Francopoulo et al. (2006)), an ISO standard for lexical resource modelling, and an LMF version of FrameNet exists. However, we believe that our usage of a typed formalism takes advantage of a strong logical foundation and the notions of inheritance and entailment (cf."
I08-1051,W06-0609,0,\N,Missing
ivanova-etal-2008-evaluating,schulte-im-walde-2002-subcategorisation,1,\N,Missing
ivanova-etal-2008-evaluating,heid-weller-2008-tools,1,\N,Missing
ivanova-etal-2008-evaluating,C00-2105,1,\N,Missing
ivanova-etal-2008-evaluating,E99-1016,0,\N,Missing
ivanova-etal-2008-evaluating,E06-2001,1,\N,Missing
ivanova-etal-2008-evaluating,evert-2004-statistical,0,\N,Missing
kliche-etal-2014-eidentity,C10-1011,0,\N,Missing
kliche-etal-2014-eidentity,C08-1098,0,\N,Missing
kliche-etal-2014-eidentity,hinrichs-etal-2010-weblicht,0,\N,Missing
kliche-etal-2014-eidentity,W13-2708,1,\N,Missing
kountz-etal-2008-laf,W07-1501,0,\N,Missing
kountz-etal-2008-laf,ide-romary-2006-representing,0,\N,Missing
L16-1454,C10-3009,0,0.037639,"Missing"
L16-1454,W09-1210,0,0.0137257,"e English corpus consists of 164,562 sentences and 2,240,839 tokens which was divided into two subcorpora as well. The development set consists of 86,004 sentences and the evaluation set of 78,558 sentences. 2.2. Linguistic corpus annotation For the annotation of the corpora we used several tools. The requirements were exported from a standard requirements engineering database and saved in a format for tokenizing (Krisch, 2013). Further annotations were represented in the format defined in CoNLL-2009 (Hajiˇc et al., 2009). We use a specific tokenizer (Krisch, 2013) and make use of mate tools (Bohnet, 2009; Bj¨orkelund et al., 2010) for lemmatization and parsing; for part-of-speech tagging and morphological tagging we used MarMot (M¨uller et al., 2013). The trainable tools were used without extra training on the specification texts, i.e. with the standard models acquired from news texts. After the linguistic annotation, the resulting corpus was converted into a format which can be processed by the search and retrieval tool Corpus Workbench, CWB (Evert and Hardie, 2011; Evert, 2010; Krisch, 2013). The corpus also contains word, sentence and requirement identifiers. 2.3. Weak word candidate list"
L16-1454,W09-1201,0,0.0258257,"Missing"
L16-1454,D13-1032,0,0.025313,"Missing"
lapshinova-koltunski-heid-2008-head,W02-1503,0,\N,Missing
lapshinova-koltunski-heid-2008-head,copestake-etal-2004-lexicon,0,\N,Missing
lapshinova-koltunski-heid-2008-head,schmid-etal-2004-smor,1,\N,Missing
michelbacher-etal-2010-building,1998.amta-tutorials.5,0,\N,Missing
michelbacher-etal-2010-building,D09-1124,0,\N,Missing
michelbacher-etal-2010-building,P99-1067,0,\N,Missing
michelbacher-etal-2010-building,J08-4004,0,\N,Missing
michelbacher-etal-2010-building,zesch-etal-2008-extracting,0,\N,Missing
michelbacher-etal-2010-building,P99-1004,0,\N,Missing
ritz-heid-2006-extraction,J93-1007,0,\N,Missing
schmid-etal-2004-smor,heid-etal-2002-using,1,\N,Missing
soria-etal-2002-advanced,bernsen-etal-2002-nite,1,\N,Missing
todirascu-etal-2008-hybrid,E06-1020,1,\N,Missing
todirascu-etal-2008-hybrid,steinberger-etal-2006-jrc,1,\N,Missing
todirascu-etal-2008-hybrid,J93-1007,0,\N,Missing
todirascu-etal-2008-hybrid,J07-3002,0,\N,Missing
todirascu-etal-2008-hybrid,tufis-2004-term,0,\N,Missing
todirascu-etal-2008-hybrid,ritz-heid-2006-extraction,1,\N,Missing
todirascu-etal-2008-hybrid,E06-1043,0,\N,Missing
todirascu-etal-2012-french,C10-1011,0,\N,Missing
todirascu-etal-2012-french,C94-2174,0,\N,Missing
todirascu-etal-2012-french,E06-2001,0,\N,Missing
todirascu-etal-2012-french,J00-4001,0,\N,Missing
W06-2409,J96-2002,0,0.0901758,"Missing"
W06-2409,evert-etal-2004-identifying,1,0.833192,"and a collocate, where the base is autosemantic and thus 2 Collocation Data Properties of collocations. A mere list of word pairs or sequences (give a talk, lose one’s patience) is not a collocation dictionary. For use in NLP, linguistic properties of the collocations and of their components must be provided: these include the category of the components (giveV + talkN ), the 65 distribution of base (talk) and collocate (give), as well as morphosyntactic preferences, e.g. with respect to the number of an element (e.g. have high hopes), the use of a determiner (lose one’sposs |{} patience, cf. Evert et al. (2004)). For collocations to be identifiable in the context of a sentence (e.g. to avoid attachment ambiguity in parsing) and, conversely, in generation, to be correctly inserted into a sentence, the syntagmatic behavior of collocations must be described. This includes their function within a sentence (e.g in the case of adverbial NPs) and the subcategorization of their components, e.g. with support verb constructions (make the proposal to + INF). As subcategorization is not fully predictable from the subcategorization of the noun (how to explain the preposition choice in Unterst¨utzung finden bei j"
W09-0706,J96-1002,0,0.0285219,"Missing"
W09-0706,A00-1031,0,0.538399,"Missing"
W09-0706,W07-1709,0,0.0735765,"Missing"
W09-0706,C08-1098,0,\N,Missing
W13-2708,C10-1011,0,0.0287056,"d a system to identify direct and indirect speech and a sentiment system to determine the orientation of the statement. These systems in turn need various kinds of preprocessing starting from tokenization over syntactic parsing up to coreference resolution. The Complex Concept Builder is the collection of all these systems with the goal to assist the political scientists. So far, the Complex Concept Builder implements tokenization (Schmid, 2009), lemmatisation (Schmid, 1995), part-of-speech tagging (Schmid and Laws, 2008), named entity detection (Faruqui and Pad´o, 2010), syntactical parsing (Bohnet, 2010), coreference analysis for German (Lappin and Leass, 1994; Stuckardt, 2001), relation extraction (Blessing et al., 2012) and sentiment analysis for English (Taboada et al., 2011). It is important for a researcher of the humanities to be able to adapt existing classification systems according to his own needs. A common procedure in both, NLP and political sciences, is to annotate data. Therefore, one major goal of the project and the Complex Concept Builder is to provide machine learning systems with a wide range of possible features — including high level information like sentiment, text type,"
W13-2708,J96-2004,0,0.103544,"ists as the separation of metadata and 6 Conclusion and Outlook We developed and implemented a pipeline of various text processing tools which is designed to assist political scientists in finding specific, complex concepts within large amounts of text. Our case studies showed that our approach can provide beneficial assistance for the research of political scientists as well as researcher from other social sciences and the humanities. A future aspect will be to find metrics to evaluate our pipeline. In recently started annotation experiments on topic classification Cohen’s kappa coefficient (Carletta, 1996) is mediocre. It may very well be possible that the complex concepts, like multiple collective identities, are intrinsically hard to detect, and the annotations cannot be improved substantially. The extension of the NLP pipeline will be another major working area in the future. Examples are sentiment analysis for German, adding world knowledge about named entities (e.g. persons and events), identification of relations between entities. Finally, all these systems need to be evaluated not only in terms of f-score, precision and recall, but also in terms of usability for the political scientists."
W13-2708,C08-1098,0,0.0274623,"tician who tries to rally support for his political party. In order to detect such text, we need a system to identify direct and indirect speech and a sentiment system to determine the orientation of the statement. These systems in turn need various kinds of preprocessing starting from tokenization over syntactic parsing up to coreference resolution. The Complex Concept Builder is the collection of all these systems with the goal to assist the political scientists. So far, the Complex Concept Builder implements tokenization (Schmid, 2009), lemmatisation (Schmid, 1995), part-of-speech tagging (Schmid and Laws, 2008), named entity detection (Faruqui and Pad´o, 2010), syntactical parsing (Bohnet, 2010), coreference analysis for German (Lappin and Leass, 1994; Stuckardt, 2001), relation extraction (Blessing et al., 2012) and sentiment analysis for English (Taboada et al., 2011). It is important for a researcher of the humanities to be able to adapt existing classification systems according to his own needs. A common procedure in both, NLP and political sciences, is to annotate data. Therefore, one major goal of the project and the Complex Concept Builder is to provide machine learning systems with a wide ra"
W13-2708,N12-1066,0,0.0162412,"pic filter Concept detection Web-based Userinterface Data cleaning is important for the data-driven studies. Not only duplicate articles have a negative impact, also articles which are not of interest for the given topic have to be filtered out. There are different approaches to classify articles into a range of predefined topics. In the last years LDA (Blei et al., 2003; Niekler and J¨ahnichen, 2012) is one of the most successful methods to find topics in articles. But for social scientists the categories typically used in LDA are not sufficient. We follow the idea of Dualist (Settles, 2011; Settles and Zhu, 2012) which is an interactive method for classification. The architecture of Dualist is based on MALLET (McCallum, 2002) which is easily integrable into our architecture. Our goal is to design the correct feature to find relevant articles for a given topic. Word features are not sufficient since we have to model more complex features (cf. Section 2.1). Figure 2: Overview of the complete processing chain. We split the workflow for the user into two parts: The first part is only used if the user imports new data into the repository. For that he can use the exploration workbench (Section 3.1). Secondl"
W13-2708,P10-4005,0,0.0309161,"ation is gathered and visualised as well. Major differences between the EMM and our approach are the user group and the domain of the corpus. The complex concepts political scientists are interested in are much more nuanced than the concepts relevant for topic detection and the construction of social networks. Additionally, the EMM does not allow its users to look for their own concepts and issues, while this interactivity is a central contribution of our approach (cf. Sections 1, 2.1 and 3.2). The CLARIN-D project also provides a webbased platform to create NLP-chains. It is called WebLicht (Hinrichs et al., 2010), but in its current form, the tool is not immediately usable for social scientists as the separation of metadata and 6 Conclusion and Outlook We developed and implemented a pipeline of various text processing tools which is designed to assist political scientists in finding specific, complex concepts within large amounts of text. Our case studies showed that our approach can provide beneficial assistance for the research of political scientists as well as researcher from other social sciences and the humanities. A future aspect will be to find metrics to evaluate our pipeline. In recently sta"
W13-2708,D11-1136,0,0.0485983,"cept Builder Topic filter Concept detection Web-based Userinterface Data cleaning is important for the data-driven studies. Not only duplicate articles have a negative impact, also articles which are not of interest for the given topic have to be filtered out. There are different approaches to classify articles into a range of predefined topics. In the last years LDA (Blei et al., 2003; Niekler and J¨ahnichen, 2012) is one of the most successful methods to find topics in articles. But for social scientists the categories typically used in LDA are not sufficient. We follow the idea of Dualist (Settles, 2011; Settles and Zhu, 2012) which is an interactive method for classification. The architecture of Dualist is based on MALLET (McCallum, 2002) which is easily integrable into our architecture. Our goal is to design the correct feature to find relevant articles for a given topic. Word features are not sufficient since we have to model more complex features (cf. Section 2.1). Figure 2: Overview of the complete processing chain. We split the workflow for the user into two parts: The first part is only used if the user imports new data into the repository. For that he can use the exploration workbenc"
W13-2708,W04-0213,1,0.689214,"ally by the political scientists. The following are further applications of the identified indirect speeches a) using the frequency of speeches per text as a feature for classification; e.g. a classification system for news reports/commentaries as described in Section 4.4 b) a project-goal is to find texts in which collective A useful distinction for political scientists dealing with newspaper articles is the distinction between articles that report objectively on events or backgrounds and editorials or press commentaries. We first extracted opinionated and objective texts from DeReKo corpus (Stede, 2004; Kupietz et al., 2010). Some texts were removed in order to balance the corpus. The balanced corpus contains 2848 documents and has been split into a development and a training and test set. 570 documents were used for the manual creation of features. The remaining 2278 documents were used to train and evaluate classifiers using 10-fold cross-validation with the WEKA machine learning toolkit (Hall et al., 2009) and various classifiers (cf. Table 1). The challenge is that the newspaper articles from the training and evaluation corpus come from different newspapers and, of course, from differen"
W13-2708,kupietz-etal-2010-german,0,0.0200728,"olitical scientists. The following are further applications of the identified indirect speeches a) using the frequency of speeches per text as a feature for classification; e.g. a classification system for news reports/commentaries as described in Section 4.4 b) a project-goal is to find texts in which collective A useful distinction for political scientists dealing with newspaper articles is the distinction between articles that report objectively on events or backgrounds and editorials or press commentaries. We first extracted opinionated and objective texts from DeReKo corpus (Stede, 2004; Kupietz et al., 2010). Some texts were removed in order to balance the corpus. The balanced corpus contains 2848 documents and has been split into a development and a training and test set. 570 documents were used for the manual creation of features. The remaining 2278 documents were used to train and evaluate classifiers using 10-fold cross-validation with the WEKA machine learning toolkit (Hall et al., 2009) and various classifiers (cf. Table 1). The challenge is that the newspaper articles from the training and evaluation corpus come from different newspapers and, of course, from different authors. Commentaries"
W13-2708,J01-4002,0,0.0247788,"to determine the orientation of the statement. These systems in turn need various kinds of preprocessing starting from tokenization over syntactic parsing up to coreference resolution. The Complex Concept Builder is the collection of all these systems with the goal to assist the political scientists. So far, the Complex Concept Builder implements tokenization (Schmid, 2009), lemmatisation (Schmid, 1995), part-of-speech tagging (Schmid and Laws, 2008), named entity detection (Faruqui and Pad´o, 2010), syntactical parsing (Bohnet, 2010), coreference analysis for German (Lappin and Leass, 1994; Stuckardt, 2001), relation extraction (Blessing et al., 2012) and sentiment analysis for English (Taboada et al., 2011). It is important for a researcher of the humanities to be able to adapt existing classification systems according to his own needs. A common procedure in both, NLP and political sciences, is to annotate data. Therefore, one major goal of the project and the Complex Concept Builder is to provide machine learning systems with a wide range of possible features — including high level information like sentiment, text type, relations to other texts, etc. — that can be used by non-experts for semia"
W13-2708,J11-2001,1,0.14676,"cessing starting from tokenization over syntactic parsing up to coreference resolution. The Complex Concept Builder is the collection of all these systems with the goal to assist the political scientists. So far, the Complex Concept Builder implements tokenization (Schmid, 2009), lemmatisation (Schmid, 1995), part-of-speech tagging (Schmid and Laws, 2008), named entity detection (Faruqui and Pad´o, 2010), syntactical parsing (Bohnet, 2010), coreference analysis for German (Lappin and Leass, 1994; Stuckardt, 2001), relation extraction (Blessing et al., 2012) and sentiment analysis for English (Taboada et al., 2011). It is important for a researcher of the humanities to be able to adapt existing classification systems according to his own needs. A common procedure in both, NLP and political sciences, is to annotate data. Therefore, one major goal of the project and the Complex Concept Builder is to provide machine learning systems with a wide range of possible features — including high level information like sentiment, text type, relations to other texts, etc. — that can be used by non-experts for semiautomatic annotation and text selection. Active learning is used to provide immediate results that 3.3 I"
W13-2708,J94-4002,0,\N,Missing
W16-4706,C92-2082,0,0.593453,"mal lines= compounds and their nominal paraphrases (synonymy), dashed lines= compound analysis (hyponymy), broad lines= compounds and their verbal paraphrases (associated events), dotted lines= GermaNet (hyponymy). Not included due to space restrictions are verbs and their arguments. 3 3.1 Identifying relations between domain objects Relevant phenomena Taxonomic relations between domain objects: Taxonomic (= hyponymy) relations can be extracted from definition-like sentences (“an X is a Y which ...”) and from list-like enumerations (“Xs, such as Y1, Y2 ...”), as first discussed for English by Hearst (1992). Such relations may also be extracted from parsed text by use of verbal predicates which denote class membership (e.g. geh¨oren zu (“belong to”), z¨ahlen zu (“be part of”) etc.). Similarly, determinative compounds can be interpreted as hyponyms of their morphological heads (Band|s¨age → S¨age, “band|saw”→ “saw”). Figure 3: A subset of relations found for Bohrer using Hearst patterns; arrows indicate a relation of hyponymy, e.g. “Bohrer is-a Schneidewerkzeug”. Figures 3 and 4 show an exemplary subset of taxonomic relations for the term Bohrer (drill). The figures show partial hierarchies deriv"
W16-4706,P03-1040,0,0.0120989,"rence resolver for German. In a post-processing step, we annotate personal, possessive, demonstrative and relative pronouns with the closest non-pronominal antecedent identified by the resolver. Experiments on the use of coreference resolution to enhance recall in the extraction of verbs and their arguments can be found in Section 4.2.3. For compound splitting we use CompoST (Cap, 2014), a compound splitter which combines the use of a rule-based morphology system (SMOR (Schmid et al., 2004)) with morpheme verification in corpus data, thereby extending and improving on the approach proposed by Koehn and Knight (2003) for statistical machine translation. For all components of a compound, including those which are complex themselves, the tool verifies the presence and number of occurrences in a (set of) texts. In our application, the do-it-yourself corpus is used as a knowledge source for this check, in addition to a (newspaper-based) general language corpus. Splits that involve implausible or rare components are dispreferred. 1 2 A typical forum of this type is “1-2-do.com” Work on quantifying the terminological richness of more vs. less oral/CMC texts is under way. 42 Pattern-based search on all levels, w"
W16-4706,L16-1024,1,0.831504,"Missing"
W16-4706,C08-1098,0,0.0112431,"od measures (such as Ahmad et al. (1992)’s weirdness ratio) to rank candidates by comparison with a general-language corpus (SdeWaC (Faaß and Eckart, 2013)). In the standard term candidate extraction mode, domain experts are then asked to verify the term candidates. Variant recognition is an optional part of the same architecture. pre− processing pattern search corpus ranking term candidate list Figure 1: Steps in term candidate extraction: overview The texts are tokenized and normalized (homogeneous orthography of e.g. numeric indications, cf. 60x40 cm), tagged and lemmatized using RFTagger (Schmid and Laws, 2008), and dependency parsed using the mate parser (Bohnet, 2010). An automatic correction step is applied for lemmatization. Dependency parses are in addition annotated with phrase boundaries and heads, such that information corresponding to both techniques, constituent and dependency parsing, is available: the full verb of each sentence, its subject and complements, as well as adjuncts and negation are annotated and thus retrievable as context parameters. An additional step of linguistic annotation is coreference resolution and discourse processing. We use IMS HotCoref DE (R¨osiger and Kuhn, 2016"
W16-4706,schmid-etal-2004-smor,1,0.68937,"coreference resolution and discourse processing. We use IMS HotCoref DE (R¨osiger and Kuhn, 2016), a state-of-the-art coreference resolver for German. In a post-processing step, we annotate personal, possessive, demonstrative and relative pronouns with the closest non-pronominal antecedent identified by the resolver. Experiments on the use of coreference resolution to enhance recall in the extraction of verbs and their arguments can be found in Section 4.2.3. For compound splitting we use CompoST (Cap, 2014), a compound splitter which combines the use of a rule-based morphology system (SMOR (Schmid et al., 2004)) with morpheme verification in corpus data, thereby extending and improving on the approach proposed by Koehn and Knight (2003) for statistical machine translation. For all components of a compound, including those which are complex themselves, the tool verifies the presence and number of occurrences in a (set of) texts. In our application, the do-it-yourself corpus is used as a knowledge source for this check, in addition to a (newspaper-based) general language corpus. Splits that involve implausible or rare components are dispreferred. 1 2 A typical forum of this type is “1-2-do.com” Work o"
W17-7002,2014.amta-researchers.5,0,0.288616,"Missing"
W17-7002,W16-4011,0,0.0411369,"Missing"
W17-7002,W14-4807,0,0.0275089,"rk Existing Benchmark Datasets for Term Extraction There exists a range of terminology benchmark datasets which vary in the specificity of their topic, their definition of termhood and writing styles. Wellknown datasets are the Genia (Kim et al. (2003)) and the CRAFT corpus (Bada et al. (2012)) with term annotations in the biomedical domain. Genia contains 2000 MEDLINE abstracts with almost 100,000 annotations by two domain experts. CRAFT consists of 67 biomedical journal articles of various biological domains (plus unpublished articles) with more than 100,000 concept annotations. ACL RD-TEC (Handschuh and QasemiZadeh (2014)) is a gold standard in the domain of computational linguistics. It consists of 10,922 ACL conference papers published between 1965 and 2006. From those more than 83, 000 term candidates have been extracted and evaluated; 22,000 candidates are annotated as valid and 61,000 as invalid terms by one annotator. An extension is ACL RD-TEC 2.0 (QasemiZadeh and Schumann (2016)), a further annotation of 300 ACL abstracts with a broad subclassification of the terms. corpora breadth registers token-based guidelines ACL 1.0 ACL 2.0 B/C Bitter TTC Genia Craft our approach ** * broad ** * + broad **/* * +"
W17-7002,L16-1294,0,0.17117,"bstracts with almost 100,000 annotations by two domain experts. CRAFT consists of 67 biomedical journal articles of various biological domains (plus unpublished articles) with more than 100,000 concept annotations. ACL RD-TEC (Handschuh and QasemiZadeh (2014)) is a gold standard in the domain of computational linguistics. It consists of 10,922 ACL conference papers published between 1965 and 2006. From those more than 83, 000 term candidates have been extracted and evaluated; 22,000 candidates are annotated as valid and 61,000 as invalid terms by one annotator. An extension is ACL RD-TEC 2.0 (QasemiZadeh and Schumann (2016)), a further annotation of 300 ACL abstracts with a broad subclassification of the terms. corpora breadth registers token-based guidelines ACL 1.0 ACL 2.0 B/C Bitter TTC Genia Craft our approach ** * broad ** * + broad **/* * + mid/strict ** * + broad ** ** mid * * + strict ** * + strict *** *** + mid Table 1: Comparison of terminology gold standards Bernier-Colborne and Drouin (2014) (B/C) analysed three textbooks on automotive engineering. In addition to the annotation, they assign attributes to the terms (e.g. for acronyms or multiwords) and mark orthographic variants. Other reference sets"
W17-7002,2007.jeptalnrecital-poster.28,0,0.0643637,"g in one domain but also in other domains or in general language (e.g. Trimble (1985), Beck et al. (2002)). The model by Roelcke (1999) consists of four layers (Figure 1), where the most restrictive one is the intra-subject terminology which is specific to the domain. The inter-subject terminology is used in the respective domain, but also in others. The extra-subject terminology is terminology which does not belong to the domain but is used within it (we call such terms borrowed terms). The last group, the nonsubject terminology, consists of all items used across almost all specific domains. Tutin (2007) calls this ’transdisciplinary vocbulary’: it includes the domain-unspecific language of scientific writing (e.g. evaluation, estimation, observation) and non-specialized abstract vocabulary (e.g. to present a problem, to result in). Our annotation approach is liberal and our notion of termhood comprises the first three layers of Roelcke’s model. As a consequence, often no clear borderline between the DIY domain and other domains can be drawn; following the example of the TaaS project (www.taas-project.eu), we therefore provide the annotation with confidence scores about how many of the annota"
W17-7002,P13-4001,0,0.188363,"Missing"
W19-0803,benikova-zesch-2017-different,0,0.0246388,"ed in terms of e.g. synonym substitution or part substitution. In total they describe 25 possible substitution types. Some of these types are also contained in our dataset of clause titles and model clause titles. Kovatchev et al. (2018) compare texts with different lengths on the similarity of their meaning. They attach much importance to detailed error analysis and have built a corpus in which paraphrases and negations are annotated. For the text pairs, the similarity is measured by paraphrase deductions in both texts. Another approach focusing on the analysis of paraphrases is described by Benikova and Zesch (2017). In this paper, different granulation levels of paraphrase sentences and annotated verb argument structures of paraphrases are compared for the similarity calculation. They distinguish between event paraphrase, lexical paraphrase, wording and inverse lexical paraphrase. In (Agirre et al., 2012) the semantic equivalence of two texts with paraphrase differences is measured. This is achieved by using common tokens in the sentence. For the vectors of the sentences the cosine similarity is calculated. The text pairs in their work consist of 51 words up to 126 words. Gomaa and Fahmy (2013) suggest"
W19-0803,S12-1059,0,0.0125358,"use. 2 Related Work The calculation of text similarity is used in many applications and projects and is constantly extended and improved. To calculate similarities between very short text pairs and to match the correct titles of the model clauses with the extracted headings, we have used state-of-the-art methods and measurement approaches which we have adapted for our application and trained with our data set of contract texts. The particular problem we faced is that the text pairs are very short. On average, the titles consist of 24 characters and not a single title has more than nine words. Bär et al. (2012) define a semantic textual similarity with character and word n-grams by a semantic vector comparison and a word similarity comparison based on lexical-semantic sources is performed using various similarity features. The authors apply a logarithmic-linear regression model and use Explicit Semantic Analysis, a vector based representation of text for semantic similarity measurements, to replace nouns. Further evaluations of similarity measurements of longer sentences are described by Achananuparp et al. (2008). Their evaluation measures are based on semantic equivalence, when the sentence pairs"
W19-0803,N16-1108,0,0.0205633,"Distance, Cosine similarity and Jaccard Distance. Also Aldarmaki and Diab (2018) evaluate combined models for similarity measurement and evaluate the results of a logistic regression classifier by calculating the cosine similarity between two sentence vectors. Lan and Xu (2018) compare and evaluate seven LSTM-based methods for sentence pair modeling on eight commonly used datasets, such as Quora (Question Pairs Dataset), Twitter URL Corpus, and PIT-2015 (Paraphrase and Semantic Similarity in Twitter). For small datasets, they propose the method Pairwise Word Interaction Model (introduced in (He and Lin, 2016)). Boom et al. (2015) recommend a combined method of word embedding and tf.idf weighting to calculate the similarity of text fragments (20 words per fragment). In this method, text parts with terms of a high tf.idf weighting are used. Kenter and de Rijke (2015) present a text similarity calculation, where they use the similarity of word vectors to derive semantic meta features, which in turn are used for training a supervised classifier. Kusner et al. (2015) present a distance measurement between text documents based on word embeddings and the dissimilarity of two probability distributions ove"
W19-0803,L18-1221,0,0.0146265,"ed by Achananuparp et al. (2008). Their evaluation measures are based on semantic equivalence, when the sentence pairs do not have the same surface shape. Whereby: sentences are similar, when they are paraphrases of each other, contain the same subject, or when one sentence is the super set of the other. 24 In (Bhagat and Hovy, 2013) similarities of paraphrases are defined and analyzed in terms of e.g. synonym substitution or part substitution. In total they describe 25 possible substitution types. Some of these types are also contained in our dataset of clause titles and model clause titles. Kovatchev et al. (2018) compare texts with different lengths on the similarity of their meaning. They attach much importance to detailed error analysis and have built a corpus in which paraphrases and negations are annotated. For the text pairs, the similarity is measured by paraphrase deductions in both texts. Another approach focusing on the analysis of paraphrases is described by Benikova and Zesch (2017). In this paper, different granulation levels of paraphrase sentences and annotated verb argument structures of paraphrases are compared for the similarity calculation. They distinguish between event paraphrase,"
W19-0803,C18-1328,0,0.0198478,"suggest to combine several similarity metrics to determine string-based, corpus-based, and knowledge-based similarities. For the string based approach they use the Longest Common Sub String (LCS) algorithm and various editing distance metrics like Jaro, Damerau-Levenshtein and N-grams. For the term-based similarity measurement Manhattan Distance, Cosine similarity and Jaccard Distance. Also Aldarmaki and Diab (2018) evaluate combined models for similarity measurement and evaluate the results of a logistic regression classifier by calculating the cosine similarity between two sentence vectors. Lan and Xu (2018) compare and evaluate seven LSTM-based methods for sentence pair modeling on eight commonly used datasets, such as Quora (Question Pairs Dataset), Twitter URL Corpus, and PIT-2015 (Paraphrase and Semantic Similarity in Twitter). For small datasets, they propose the method Pairwise Word Interaction Model (introduced in (He and Lin, 2016)). Boom et al. (2015) recommend a combined method of word embedding and tf.idf weighting to calculate the similarity of text fragments (20 words per fragment). In this method, text parts with terms of a high tf.idf weighting are used. Kenter and de Rijke (2015)"
weller-heid-2010-extraction,fritzinger-etal-2010-pattern,1,\N,Missing
weller-heid-2010-extraction,W06-2405,0,\N,Missing
weller-heid-2010-extraction,sporleder-etal-2010-idioms,0,\N,Missing
weller-heid-2010-extraction,E03-1087,0,\N,Missing
weller-heid-2010-extraction,W07-1103,0,\N,Missing
weller-heid-2010-extraction,fritzinger-etal-2010-survey,1,\N,Missing
weller-heid-2010-extraction,E06-1043,0,\N,Missing
weller-heid-2012-analyzing,E03-1076,0,\N,Missing
zinsmeister-etal-2014-adapting,haselbach-heid-2010-development,1,\N,Missing
zinsmeister-etal-2014-adapting,windhouwer-2012-relcat,0,\N,Missing
zinsmeister-etal-2014-adapting,W10-1827,0,\N,Missing
zinsmeister-etal-2014-adapting,C08-1098,0,\N,Missing
zinsmeister-etal-2014-adapting,petrov-etal-2012-universal,0,\N,Missing
zinsmeister-etal-2014-adapting,J13-1004,0,\N,Missing
zinsmeister-etal-2014-adapting,P07-1033,0,\N,Missing
