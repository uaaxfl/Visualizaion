2021.clpsych-1.5,Demonstrating the Reliability of Self-Annotated Emotion Data,2021,-1,-1,5,0,11571,anton malko,Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access,0,"Vent is a specialised iOS/Android social media platform with the stated goal to encourage people to post about their feelings and explicitly label them. In this paper, we study a snapshot of more than 100 million messages obtained from the developers of Vent, together with the labels assigned by the authors of the messages. We establish the quality of the self-annotated data by conducting a qualitative analysis, a vocabulary based analysis, and by training and testing an emotion classifier. We conclude that the self-annotated labels of our corpus are indeed indicative of the emotional contents expressed in the text and thus can support more detailed analyses of emotion expression on social media, such as emotion trajectories and factors influencing them."
2020.alta-1.17,Overview of the 2020 {ALTA} Shared Task: Assess Human Behaviour,2020,-1,-1,1,1,11574,diego molla,Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association,0,"The 2020 ALTA shared task is the 11th in stance of a series of shared tasks organised by ALTA since 2010. The task is to classify texts posted in social media according to human judgements expressed in them. The data used for this task is a subset of SemEval 2018 AIT DISC, which has been annotated by domain experts for this task. In this paper we introduce the task, describe the data and present the results of participating systems."
U19-1026,Overview of the 2019 {ALTA} Shared Task: Sarcasm Target Identification,2019,-1,-1,1,1,11574,diego molla,Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association,0,"We present an overview of the 2019 ALTA shared task. This is the 10th of the series of shared tasks organised by ALTA since 2010. The task was to detect the target of sarcastic comments posted on social media. We intro- duce the task, describe the data and present the results of baselines and participants. This year{'}s shared task was particularly challenging and no participating systems improved the re- sults of our baseline."
W18-5604,Supervised Machine Learning for Extractive Query Based Summarisation of Biomedical Data,2018,0,2,2,0,27891,mandeep kaur,Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis,0,"The automation of text summarisation of biomedical publications is a pressing need due to the plethora of information available online. This paper explores the impact of several supervised machine learning approaches for extracting multi-document summaries for given queries. In particular, we compare classification and regression approaches for query-based extractive summarisation using data provided by the BioASQ Challenge. We tackled the problem of annotating sentences for training classification systems and show that a simple annotation approach outperforms regression-based summarisation."
W18-5303,{M}acquarie {U}niversity at {B}io{ASQ} 6b: Deep learning and deep reinforcement learning for query-based summarisation,2018,0,2,1,1,11574,diego molla,Proceedings of the 6th {B}io{ASQ} Workshop A challenge on large-scale biomedical semantic indexing and question answering,0,"This paper describes Macquarie University{'}s contribution to the BioASQ Challenge (BioASQ 6b, Phase B). We focused on the extraction of the ideal answers, and the task was approached as an instance of query-based multi-document summarisation. In particular, this paper focuses on the experiments related to the deep learning and reinforcement learning approaches used in the submitted runs. The best run used a deep learning model under a regression-based framework. The deep learning architecture used features derived from the output of LSTM chains on word embeddings, plus features based on similarity with the query, and sentence position. The reinforcement learning approach was a proof-of-concept prototype that trained a global policy using REINFORCE. The global policy was implemented as a neural network that used tf.idf features encoding the candidate sentence, question, and context."
U18-1011,Overview of the 2018 {ALTA} Shared Task: Classifying Patent Applications,2018,0,2,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2018,0,"We present an overview of the 2018 ALTA shared task. This is the 9th of the series of shared tasks organised by ALTA since 2010. The task was to classify Australian patent classifications following the sections defined by the International Patient Classification (IPC), using data made available by IP Australia. We introduce the task, describe the data and present the results of the participating teams. Some of the participating teams outperformed state of the art."
W17-2308,{M}acquarie {U}niversity at {B}io{ASQ} 5b {--} Query-based Summarisation Techniques for Selecting the Ideal Answers,2017,6,0,1,1,11574,diego molla,{B}io{NLP} 2017,0,"Macquarie University{'}s contribution to the BioASQ challenge (Task 5b Phase B) focused on the use of query-based extractive summarisation techniques for the generation of the ideal answers. Four runs were submitted, with approaches ranging from a trivial system that selected the first $n$ snippets, to the use of deep learning approaches under a regression framework. Our experiments and the ROUGE results of the five test batches of BioASQ indicate surprisingly good results for the trivial approach. Overall, most of our runs on the first three test batches achieved the best ROUGE-SU4 results in the challenge."
W16-4205,Semi-supervised Clustering of Medical Text,2016,10,0,4,0,33603,pracheta sahoo,Proceedings of the Clinical Natural Language Processing Workshop ({C}linical{NLP}),0,"Semi-supervised clustering is an attractive alternative for traditional (unsupervised) clustering in targeted applications. By using the information of a small annotated dataset, semi-supervised clustering can produce clusters that are customized to the application domain. In this paper, we present a semi-supervised clustering technique based on a multi-objective evolutionary algorithm (NSGA-II-clus). We apply this technique to the task of clustering medical publications for Evidence Based Medicine (EBM) and observe an improvement of the results against unsupervised and other semi-supervised clustering techniques."
U16-1020,Overview of the 2016 {ALTA} Shared Task: Cross-{KB} Coreference,2016,7,0,3,0,28711,andrew chisholm,Proceedings of the Australasian Language Technology Association Workshop 2016,0,None
U15-1006,Similarity Metrics for Clustering {P}ub{M}ed Abstracts for Evidence Based Medicine,2015,11,0,2,0,28448,hamed hassanzadeh,Proceedings of the Australasian Language Technology Association Workshop 2015,0,None
U15-1017,Overview of the 2015 {ALTA} Shared Task: Identifying {F}rench Cognates in {E}nglish Text,2015,-1,-1,2,0,34164,laurianne sitbon,Proceedings of the Australasian Language Technology Association Workshop 2015,0,None
U14-1010,Impact of Citing Papers for Summarisation of Clinical Documents,2014,11,3,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2014,0,"In this paper we show that information from citing papers can help perform extractive summarisation of medical publications, especially when the amount of text available for development is limited. We used the data of the TAC 2014 biomedical summarisation task. We report several methods to find the reference paper sentences that best match the citation text from the citing papers (xe2x80x9ccitancesxe2x80x9d). We observed that methods that incorporate lexical domain information from UMLS, and methods that use extended training data, perform best. We then used these ranked sentences to perform extractive summarisation and observed a dramatic improvement of ROUGE-L scores when compared with methods that do not use information from citing papers."
U14-1022,Overview of the 2014 {ALTA} Shared Task: Identifying Expressions of Locations in Tweets,2014,12,4,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2014,0,"This year was the fifth in the ALTA series of shared tasks. The topic of the 2014 ALTA shared task was to identify location information in tweets. As in past competitions, we used Kaggle in Class as the framework for submission, evaluation and communication with the participants. In this paper we describe the details of the shared task, evaluation method, and results of the participating systems."
W13-3405,"Learning from {O}z{CLO}, the {A}ustralian Computational and Linguistics Olympiad",2013,5,1,4,0,29014,dominique estival,Proceedings of the Fourth Workshop on Teaching {NLP} and {CL},0,"The Australian Computational and Linguistics Olympiad (OzCLO) started in 2008 in only two locations and has since grown to a nationwide competition with almost 1500 high school students participating in 2013. An Australian team has participated in the International Linguistics Olympiad (ILO) every year since 2009. This paper describes how the competition is run (with a regional First Round and a final National Round) and the organisation of the competition (a National Steering Committee and Local Organising Committees for each region) and discusses the particular challenges faced by Australia (timing of the competition and distance between the major population centres). One major factor in the growth and success of OzCLO has been the introduction of the online competition, allowing participation of students from rural and remote country areas. The organisation relies on the good-will and volunteer work of university and school staff but the strong interest among students and teachers shows that OzCLO is responding to a demand for linguistic challenges."
U13-1008,Multi-Objective Optimization for Clustering of Medical Publications,2013,25,3,3,0.0868865,363,asif ekbal,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"Clustering the results of a search can help a multi-document summarizer present a summary for evidence based medicine (EBM). In this work, we introduce a clustering technique that is based on multiobjective (MOO) optimization. MOO is a technique that shows promise in the areas of machine learning and natural language processing. In our approach we show how MOO based semi-supervised clustering technique can be effectively used for EBM."
U13-1019,Overview of the 2013 {ALTA} Shared Task,2013,33,22,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2013 ({ALTA} 2013),0,"We present the design, preparation, results and analysis of the Cancer Genetics (CG) event extraction task, a main task of the BioNLP Shared Task (ST) 2013. The CG task is an information extraction task targeting the recognition of events in text, represented as structured n-ary associations of given physical entities. In addition to addressing the cancer domain, the CG task is differentiated from previous event extraction tasks in the BioNLP ST series in addressing a wide range of pathological processes and multiple levels of biological organization, ranging from the molecular through the cellular and organ levels up to whole organisms. Final test set submissions were accepted from six teams. The highest-performing system achieved an Fscore of 55.4%. This level of performance is broadly comparable with the state of the art for established molecular-level extraction tasks, demonstrating that event extraction resources and methods generalize well to higher levels of biological organization and are applicable to the analysis of scientific texts on cancer. The CG task continues as an open challenge to all interested parties, with tools and resources available from http://2013. bionlp-st.org/."
U12-1017,Overview of the {ALTA} 2012 Shared Task,2012,8,12,3,0,42589,iman amini,Proceedings of the Australasian Language Technology Association Workshop 2012,0,"The ALTA shared task ran for the third time in 2012, with the aim of bringing research students together to work on the same task and data set, and compare their methods in a current research problem. The task was based on a recent study to build classifiers for automatically labeling sentences to a pre-defined set of categories, in the domain of Evidence Based Medicine (EBM). The partaking groups demonstrated strong skills this year, outperforming our proposed benchmark systems. In this overview paper we explain the process of building the benchmark classifiers and data set, and present the submitted systems and their performance."
U12-1020,Experiments with Clustering-based Features for Sentence Classification in Medical Publications: {M}acquarie Test{'}s participation in the {ALTA} 2012 shared task.,2012,2,2,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2012,0,In our contribution to the ALTA 2012 shared task we experimented with the use of cluster-based features for sentence classification. In a first stage we cluster the documents according to the distribution of sentence labels. We then use this information as a feature in standard classifiers. We observed that the cluster-based feature improved the results for Naive-Bayes classifiers but not for better-informed classifiers such as MaxEnt or Logistic Regression.
U11-1003,Automatic Grading of Evidence: the 2011 {ALTA} Shared Task,2011,14,4,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2011,0,"The ALTA shared tasks are programming competitions where all participants attempt to solve the same problem, and the winner is the system with the best results. The 2011 ALTA shared task is the second in the series and it focuses on trying to automatically grade the level of clinical evidence in medical research papers. In this paper we describe the task, present the results of several baselines, and the results of our method. We apply a sequence of high precision machine learning classifiers with varying feature sets for each. In addition to usingn-grams, we incorporate domain knowledge by representing specific medical concepts using their semantic categories. We also apply a specialised rule-based approach for automatically identifying the publication types of articles, which is then used as a feature set. Our approach obtains an accuracy of 62.84% which is a significant improvement over the baselines."
U11-1012,Development of a Corpus for Evidence Based Medicine Summarisation,2011,32,24,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2011,0,"In this paper we introduce some of the key NLP-related problems related to the practice of Evidence Based Medicine and propose the task of multi-document query-focused summarisation as a key approach to solve these problems. We have completed a corpus for the development of such multi-document queryfocused summarisation task. The process to build the corpus combined the use of automated extraction of text, manual annotation, and crowdsourcing to find the reference IDs. We perform a statistical analysis of the corpus for the particular use of single-document summarisation and show that there is still a lot of room for improvement from the current baselines."
U11-1014,Outcome Polarity Identification of Medical Papers,2011,29,11,2,0,1157,abeed sarker,Proceedings of the Australasian Language Technology Association Workshop 2011,0,"A medical publication may or may not present an outcome. When an outcome is present, its polarity may be positive, negative or neutral. Information about the polarity of an outcome is a vital one, particularly for practitioners who use the outcome information for decision making. We model the problem of automatic outcome polarity identification as a three-way document classification problem and attempt to solve it via supervised machine learning. We combine domain knowledge and linguistic features of medical text, and apply natural language processing to extract features for the chosen classifiers. We introduce two novel features xe2x80x94 Relative Average Negation Count and Sentence Signature xe2x80x94 and show that they are effective in improving classification accuracy. We also include features, such as n-grams and semantic orientation of terms, that have been used for similar text classification problems in other domains. Using these features, we obtain a maximum accuracy of 74.9% for the classification problem. Our experiments suggest that through careful feature selection, machine learning can be used to solve this problem."
U10-1012,A Corpus for Evidence Based Medicine Summarisation,2010,14,6,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Association Workshop 2010,0,"In this paper we motivate the need for a corpus for the development and testing of summarisation systems for evidencebased medicine. We describe the corpus which we are currently creating, and show its applicability by evaluating several simple query-based summarisation techniques using a small fragment of the corpus."
W08-1810,Indexing on Semantic Roles for Question Answering,2008,20,21,2,1,47728,luiz pizzato,Coling 2008: Proceedings of the 2nd workshop on Information Retrieval for Question Answering,0,"Semantic Role Labeling (SRL) has been used successfully in several stages of automated Question Answering (QA) systems but its inherent slow procedures make it difficult to use at the indexing stage of the document retrieval component. In this paper we confirm the intuition that SRL at indexing stage improves the performance of QA and propose a simplified technique named the Question Prediction Language Model (QPLM), which provides similar information with a much lower cost. The methods were tested on four different QA systems and the results suggest that QPLM can be used as a good compromise between speed and accuracy."
U07-1010,Named Entity Recognition in Question Answering of Speech Data,2007,12,11,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Workshop 2007,0,"Question answering on speech transcripts (QAst) is a pilot track of the CLEF competition. In this paper we present our contribution to QAst, which is centred on a study of Named Entity (NE) recognition on speech transcripts, and how it impacts on the accuracy of the final question answering system. We have ported AFNER, the NE recogniser of the AnswerFinder questionanswering project, to the set of answer types expected in the QAst track. AFNER uses a combination of regular expressions, lists of names (gazetteers) and machine learning to find NeWS in the data. The machine learning component was trained on a development set of the AMI corpus. In the process we identified various problems with scalability of the system and the existence of errors of the extracted annotation, which lead to relatively poor performance in general. Performance was yet comparable with state of the art, and the system was second (out of three participants) in one of the QAst subtasks."
U07-1014,Question Prediction Language Model,2007,11,4,2,1,47728,luiz pizzato,Proceedings of the Australasian Language Technology Workshop 2007,0,"This paper proposes the use of a language representation that specifies the relationship between terms of a sentence using question words. The proposed representation is tailored to help the search for documents containing an answer for a natural language question. This study presents the construction of this language model, the framework where it is used, and its evaluation."
J07-1004,Question Answering in Restricted Domains: An Overview,2007,57,134,1,1,11574,diego molla,Computational Linguistics,0,"Automated question answering has been a topic of research and development since the earliest AI applications. Computing power has increased since the first such systems were developed, and the general methodology has changed from the use of hand-encoded knowledge bases about simple domains to the use of text collections as the main knowledge source over more complex domains. Still, many research issues remain. The focus of this article is on the use of restricted domains for automated question answering. The article contains a historical perspective on question answering over restricted domains and an overview of the current methods and applications used in restricted domains. A main characteristic of question answering in restricted domains is the integration of domain-specific information that is either developed for question answering or that has been developed for other purposes. We explore the main methods developed to leverage this domain-specific information."
W06-3807,Learning of Graph-based Question Answering Rules,2006,20,27,1,1,11574,diego molla,Proceedings of {T}ext{G}raphs: the First Workshop on Graph Based Methods for Natural Language Processing,0,In this paper we present a graph-based approach to question answering. The method assumes a graph representation of question sentences and text sentences. Question answering rules are automatically learnt from a training corpus of questions and answer sentences with the answer annotated. The method is independent from the graph representation formalism chosen. A particular example is presented that uses a specific graph representation of the logical contents of sentences.
U06-1009,Named Entity Recognition for Question Answering,2006,14,55,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Workshop 2006,0,"Current text-based question answering (QA) systems usually contain a named entity recogniser (NER) as a core component. Named entity recognition has traditionally been developed as a component for information extraction systems, and current techniques are focused on this end use. However, no formal assessment has been done on the characteristics of a NER within the task of question answering. In this paper we present a NER that aims at higher recall by allowing multiple entity labels to strings. The NER is embedded in a question answering system and the overall QA system performance is compared to that of one with a traditional variation of the NER that only allows single entity labels. It is shown that the added noise produced introduced by the additional labels is offset by the higher recall gained, therefore enabling the QA system to have a better chance to find the answer."
U06-1013,Pseudo Relevance Feedback Using Named Entities for Question Answering,2006,14,22,2,1,47728,luiz pizzato,Proceedings of the Australasian Language Technology Workshop 2006,0,"Relevance feedback has already proven its usefulness in probabilistic information retrieval (IR). In this research we explore whether a pseudo relevance feedback technique on IR can improve the Question Answering task (QA). The basis of our exploration is the use of relevant named entities from the top retrieved documents as clues of relevance. We discuss two interesting findings from these experiments: the reasons the results were not improved, and the fact that todayxe2x80x99s metrics of IR evaluation on QA do not reflect the results obtained by a QA system."
U05-1005,Learning of Graph Rules for Question Answering,2005,21,15,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Workshop 2005,0,"AnswerFinder is a framework for the development of question-answering systems. AnswerFinder is currently being used to test the applicability of graph representations for the detection and extraction of answers. In this paper we briefly describe AnswerFinder and introduce our method to learn graph patterns that link questions with their corresponding answers in arbitrary sentences. The method is based on the translation of the logical forms of questions and answer sentences into graphs, and the application of operations based on graph overlaps and the construction of paths within graphs. The method is general and can be applied to any graph-based representation of the contents of questions and answers."
U05-1016,Extracting Exact Answers using a Meta Question Answering System,2005,28,21,2,1,47728,luiz pizzato,Proceedings of the Australasian Language Technology Workshop 2005,0,This work concerns a question answering tool that uses multiple Web search engines and Web question answering systems to retrieve snippets of text that may contain an exact answer for a natural language question. The method described here treats each Web information retrieval system in a unique manner in order to extract the best results they can provide. The results obtained suggest that our method is comparable with some of todayxe2x80x99s state-of-the-art systems.
U04-1002,"{A}nswerfinder: Question Answering by Combining Lexical, Syntactic and Semantic Information",2004,10,20,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Workshop 2004,0,"We present a question answering system that combines information at the lexical, syntactic, and semantic levels, in the process to find and rank the candidate answer sentences. The candidate exact answers are extracted from the candidate answer sentences by means of a combination of information-extraction techniques (named entity recognition) and patterns based on logical forms. The system participated in the question answering track of TREC 2004."
W03-2806,Intrinsic versus Extrinsic Evaluations of Parsing Systems,2003,16,23,1,1,11574,diego molla,"Proceedings of the {EACL} 2003 Workshop on Evaluation Initiatives in Natural Language Processing: are evaluation methods, metrics and resources reusable?",0,"A wide range of parser and/or grammar evaluation methods have been reported in the literature. However, in most cases these evaluations take the parsers independently (intrinsic evaluations), and only in a few cases has the effect of different parsers in real applications been measured (extrinsic evaluations). This paper compares two evaluations of the Link Grammar parser and the Conexor Functional Dependency Grammar parser. The parsing systems, despite both being dependency-based, return different types of dependencies, making a direct comparison impossible. In the intrinsic evaluation, the accuracy of the parsers is compared independently by converting the dependencies into grammatical relations and using the methodology of Carroll et al. (1998) for parser comparison. In the extrinsic evaluation, the parsers' impact in a practical application is compared within the context of answer extraction. The differences in the results are significant."
W03-1604,Exploiting Paraphrases in a Question Answering System,2003,20,63,5,0,1251,fabio rinaldi,Proceedings of the Second International Workshop on Paraphrasing,0,"We present a Question Answering system for technical domains which makes an intelligent use of paraphrases to increase the likelihood of finding the answer to the user's question. The system implements a simple and efficient logic representation of questions and answers that maps paraphrases to the same underlying semantic representation. Further, paraphrases of technical terminology are dealt with by a separate process that detects surface variants."
U03-1014,Towards semantic-based overlap measures for question-answering,2003,16,11,1,1,11574,diego molla,Proceedings of the Australasian Language Technology Workshop 2003,0,None
W00-0604,Answer Extraction Towards better Evaluations of {NLP} Systems,2000,10,6,2,0,11492,rolf schwitter,{ANLP}-{NAACL} 2000 Workshop: Reading Comprehension Tests as Evaluation for Computer-Based Language Understanding Systems,0,"We argue that reading comprehension tests are not particularly suited for the evaluation of NLP systems. Reading comprehension tests are specifically designed to evaluate human reading skills, and these require vast amounts of world knowledge and common-sense reasoning capabilities. Experience has shown that this kind of full-fledged question answering (QA) over texts from a wide range of domains is so difficult for machines as to be far beyond the present state of the art of NLP. To advance the field we propose a much more modest evaluation set-up, viz. Answer Extraction (AE) over texts from highly restricted domains. AE aims at retrieving those sentences from documents that contain the explicit answer to a user query. AE is less ambitious than full-fledged QA but has a number of important advantages over QA. It relies mainly on linguistic knowledge and needs only a very limited amount of world knowledge and few inference rules. However, it requires the solution of a number of key linguistic problems. This makes AE a suitable task to advance NLP techniques in a measurable way. Finally, there is a real demand for working AE systems in technical domains. We outline how evaluation procedures for AE systems over real world domains might look like and discuss their feasibility."
