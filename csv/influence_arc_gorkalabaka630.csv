2005.mtsummit-osmtw.2,W04-0813,0,0.0554133,"Missing"
2005.mtsummit-osmtw.2,2001.mtsummit-papers.14,0,0.286088,"our group (Díaz de Ilarraza et al., 2000) but is now integrated in the OpenTrad initiative, a larger government-funded project shared 7 1. An open source shallow-transfer machine translation engine for the Romance languages of Spain (the main ones being Spanish, Catalan and Galician). The MT architecture proposed uses finite-state transducers for lexical processing, hidden Markov models for part-of-speech tagging, and finite-state based chunking for structural transfer, and is largely based upon that of systems already developed by the Transducens group such as InterNOSTRUM (Spanish-Catalan, Canals-Marote et al., 2001) and Traductor Universia (SpanishPortuguese, Garrido-Alenda, 2003). 2. A deeper-transfer engine for the Spanish— Basque pair, which will be described in this paper. Some of the components (modules, data formats and compilers) from the first architecture will also be useful for the second. Indeed, an important additional goal of this work is testing which modules from the first architecture can be integrated in deeper-transfer architectures for more difficult language pairs. We expect that the introduction of an open source MT architecture will help finding solutions for well known problems in"
2005.mtsummit-osmtw.2,carreras-etal-2004-freeling,1,0.827581,"m Spanish to Basque and generation of the Basque output. It is based on the previous work of our group (Díaz de Ilarraza et al., 2000) but with new features and a new aim: interoperability with other linguistic resources and convergence with the other engines in the OpenTrad project through the use of XML . The previous objectoriented architecture is being rewritten into a open source one which will use modules which are shared with other engines in the OpenTrad project and will comply with its format specifications. The main modules are five: de-formatter, Spanish analysis based on FreeLing (Carreras et al., 2004), Spanish-Basque transfer, Basque generation and re-formatter. De-Formatter --&gt; Spanish | Analyzer | | | Transfer | | De-Formatter <-- Generation The following sections describe each module. The transfer and generation phases work in three levels: lexical form (tagged as node), chunk and sentence. No semantic disambiguation is applied, but a large number of multi-word units representing collocations, named-entities and complex terms are being included in the bilingual dictionary in order to minimize this limitation. 2.1. The de-formatter The de-formatter separates the text to be translated fro"
2005.mtsummit-osmtw.2,2005.eamt-1.12,1,0.803665,"Missing"
2007.mtsummit-papers.40,P80-1024,0,0.0669602,"Missing"
2007.mtsummit-papers.40,2005.mtsummit-osmtw.4,0,0.102763,"Missing"
2007.mtsummit-papers.40,carreras-etal-2004-freeling,0,0.0289062,"a shallowtransfer engine suited to machine translation between Matxin is a classical transfer system consisting of three main components: (i) analysis of the source language into a dependency tree structure, (ii) transfer from the source language dependency tree to a target language dependency structure, and (iii) generation of the output translation from the target dependency structure. These three components are described in more detail in what follows. Analysis The analysis of the Spanish source sentences into dependency trees is performed using an adapted version of the FreeLing toolkit (Carreras et al., 2004).2 FreeLing contains a partofspeech tagger and a shallow parser (or chunker) for Spanish. In Freeling, tagging and shallow parsing are performed using the Machine Learning AdaBoost models (Freund & Schapire, 1997). The shallow parses provided by Freeling are then augmented with dependency information, using a set of rules that identify the dependencies in the sentence. First, the relationships between chunks is established, based on their labels. As an example, consider the chunked Spanish sentence in (1): [np] Bagdad (a three-pronged attack rocked Baghdad) Here the dependency parser identif"
2007.mtsummit-papers.40,2005.eamt-1.12,1,0.888458,"Missing"
2007.mtsummit-papers.40,2004.tmi-1.11,1,0.821473,"recognizes syntactic structures by means of features assigned to word units, following the constraint grammar formalism (Karlsson, 1995). An example of chunked sentences is given in (3), for Spanish and Basque: (3) Spanish: Un triple atentado sacude Bagdad: sacude [np] Bagdad Basque: atentatu hirukoitz batek Bagdad astintzen du =&gt; [np] atentatu hirukoitz batek [np] Bagdad [verbchain] astintzen du Note that, since each module of the system can be changed independently of the others, it is possible to use a variety of chunkers, including those of the Markerbased approach, used in other works (Gough & Way, 2004; Stroppa et al., 2006; Stroppa & Way, 2006). The translation process can be decomposed as follows: the aligned sourcetarget sentences are passed in turn to the Figure 1: Translation Process in MaTrEx Alignment Strategies Word alignment Word alignment is performed using the Giza++ statistical word alignment toolkit and we followed the “refined” method of (Koehn et al., 2003) to extract a set of highquality word alignments from the original uni directional alignment sets. These along with the extracted chunk alignments were passed to the translation decoder. Chunk alignment In order to align"
2007.mtsummit-papers.40,N03-1017,0,0.0232144,"verbchain] astintzen du Note that, since each module of the system can be changed independently of the others, it is possible to use a variety of chunkers, including those of the Markerbased approach, used in other works (Gough & Way, 2004; Stroppa et al., 2006; Stroppa & Way, 2006). The translation process can be decomposed as follows: the aligned sourcetarget sentences are passed in turn to the Figure 1: Translation Process in MaTrEx Alignment Strategies Word alignment Word alignment is performed using the Giza++ statistical word alignment toolkit and we followed the “refined” method of (Koehn et al., 2003) to extract a set of highquality word alignments from the original uni directional alignment sets. These along with the extracted chunk alignments were passed to the translation decoder. Chunk alignment In order to align the chunks obtained by the chunking procedures introduced in Section “Chunking”, we make use of an “editdistance style” dynamic programming alignment algorithm, as described in (Stroppa et al., 2006). This algorithm works as follows. First, a “similarity” measure is determined for each pair of sourcetarget chunks. Then, given these similarities, we use a modified version o"
2007.mtsummit-papers.40,E06-1031,0,0.012599,"r. Chunk alignment In order to align the chunks obtained by the chunking procedures introduced in Section “Chunking”, we make use of an “editdistance style” dynamic programming alignment algorithm, as described in (Stroppa et al., 2006). This algorithm works as follows. First, a “similarity” measure is determined for each pair of sourcetarget chunks. Then, given these similarities, we use a modified version of the editdistance alignment algorithm to find the optimal alignment between the source and the target chunks. The modification consists of allowing for jumps in the alignment process (Leusch et al., 2006), which is a desirable property for translating between languages showing significant syntactic differences. This is the case for Spanish and Basque, where the order of the constituents in a sentence can be very different. To compute the “similarity” between pair of chunks, we rely on the information contained within the chunks. More precisely, we relate chunks by using the wordto word probabilities that were extracted from the word alignment module. The relationship between a source chunk and a target chunk is computed thanks to a model similar to IBM model 1 (Stroppa et al., 2006). Integra"
2007.mtsummit-papers.40,P03-1021,0,0.00941508,"to combine elements from EBMT and SMT to create hybrid datadriven systems capable of outperforming the baseline systems from which they are derived, as shown in (Groves and Way, 2005). Therefore, we also make use of SMT phrasal alignments, which are added to the aligned chunks extracted by the chunk alignment module. The SMT phrasal alignment follows the procedure of (Koehn et al., 2003). Decoder The decoding module is capable of retrieving already translated sentences and also provides a wrapper around Moses, a phrasebased decoder. This decoder also implements MinimumErrorRate Training (Och, 2003) within a loglinear framework (Och & Ney, 2002). The BLEU metric (Papineni et al., 2002) is optimized on a development set. We use a loglinear combination of several common feature functions: phrase translation probabilities (in both directions), wordbased translation probabilities (lexicon model, in both directions), a phrase length penalty and a target language model. The decoder also relies on a target language model. The Basque language model is a simple 3gram language model trained on the Basque portion of the training data, using the SRI Language Modeling Toolkit,4 with modified Knes"
2007.mtsummit-papers.40,W06-3112,1,0.877091,"Missing"
2007.mtsummit-papers.40,P02-1040,0,0.0792267,"apable of outperforming the baseline systems from which they are derived, as shown in (Groves and Way, 2005). Therefore, we also make use of SMT phrasal alignments, which are added to the aligned chunks extracted by the chunk alignment module. The SMT phrasal alignment follows the procedure of (Koehn et al., 2003). Decoder The decoding module is capable of retrieving already translated sentences and also provides a wrapper around Moses, a phrasebased decoder. This decoder also implements MinimumErrorRate Training (Och, 2003) within a loglinear framework (Och & Ney, 2002). The BLEU metric (Papineni et al., 2002) is optimized on a development set. We use a loglinear combination of several common feature functions: phrase translation probabilities (in both directions), wordbased translation probabilities (lexicon model, in both directions), a phrase length penalty and a target language model. The decoder also relies on a target language model. The Basque language model is a simple 3gram language model trained on the Basque portion of the training data, using the SRI Language Modeling Toolkit,4 with modified KneserNey smoothing. 4  MorphemeBased Machine Translation Basque is an agglutinative langu"
2007.mtsummit-papers.40,W05-0908,0,0.0240718,"Missing"
2007.mtsummit-papers.40,2006.amta-papers.25,0,0.0503217,"ss to one Basque reference translation per sentence. Evaluation is performed in a caseinsensitive manner. Because of the specific nature of Basque, we perform two types of evaluation: a wordbased evaluation, and a morpheme based evaluation. Since human evaluation is an expensive process, we selected 50 sentences from the ConsumerTest corpus to be human evaluated; this corpus is referred to as ConsumerTestHuman. The same applies to EitbTest, yielding EitbTestHuman. We used the editdistance metric (Przybocki et al., 2006) called HTER or Translation Error Rate with humantargeted references (Snover et al., 2006). Edit distance is defined as the number of modifications a native Basque professional translator has to make so that the resulting edited translation is an easily understandable Basque sentence that contains the complete meaning of the source sentence. We used the software described in (Snover et al., 2006) to compute HTER. The postediting work took 6 hours in total. Automatic Evaluation Results For the ConsumerTest corpus, the results obtained with the MaTrEx system are higher than those obtained with the Matxin system. With respect to the BLEU score, this difference is 1.58 points absolute"
2007.mtsummit-papers.40,2006.amta-papers.26,1,0.731084,"Missing"
2007.mtsummit-papers.40,2006.iwslt-evaluation.4,1,0.921046,"• A definition of Basque paradigms (sets of correspondences between partial surface forms and partial lexical forms). Those paradigms are similar to continuation classes in twolevel morphology (Koskeniemmi, 1983). Lists of surface form to lexical form correspondences for complex lexical units (including multiword units). This dictionary is compiled into a finitestate transducer which is used to perform the morphological generation of Basque words. A more detailed description of this process can be found in (ArmentanoOller et al., 2005). 3  MaTrEx: a DataDriven System The MaTrEx system (Stroppa & Way, 2006) used in our experiments is a modular datadriven MT engine, which consists of a number of extendible and reimplementable modules, the most important of which are: • • • • Word Alignment Module: takes as its input an aligned corpus and outputs a set of word alignments. Chunking Module: takes in an aligned corpus and produces source and target chunks. Chunk Alignment Module: takes the source and target chunks and aligns them on a sentenceby sentence level. Decoder: searches for a translation using the original aligned corpus and derived chunk and word alignments. The Word Alignment and the D"
2007.mtsummit-papers.40,E06-1032,0,\N,Missing
2007.mtsummit-papers.40,przybocki-etal-2006-edit,0,\N,Missing
2008.amta-papers.1,carreras-etal-2004-freeling,0,0.0374271,"Missing"
2008.amta-papers.1,A94-1016,0,0.0450113,"Missing"
2008.amta-papers.1,D07-1029,0,0.0211514,"Missing"
2008.amta-papers.1,2005.mtsummit-papers.11,0,0.0116101,"their knowledge on aligned bilingual corpora, and the accuracy of their output depends heavily on the quality and the size of these corpora. When the pair of languages used in translation, such as Spanish and Basque, has very different structures and word orders, the corpus obviously needs to be 37 bigger. However, since Basque is a lesser-used language, large and reliable bilingual corpora are unavailable. At present, domain-specific translation memories for Basque are no bigger than two or three million words, much smaller than corpora used for other languages; for example, Europarl corpus (Koehn, 2005), a standard resource, has 30 million words. So, although domain-restricted corpus-based MT for Basque shows promising results, it is still not ready for general use. Therefore, it is clear that we should combine the basic techniques for MT (rule-based and corpusbased) in order to build a hybrid system with better performance. Due to the pressing need for translation in public administration and taking into account that huge parallel corpora for Basque are not available, we have tested a first strategy by building a MT engine for a restricted domain related to public administration for which t"
2008.amta-papers.1,P07-2045,0,0.00538525,"have been implemented: a conventional SMT system and a morpheme-based system. These corpus-based approaches have been carried out in collaboration with the National Center for Language Technology in Dublin. The system exploits SMT technology to extract a dataset of aligned chunks. Based on a training corpus, we conducted Spanish-to-Basque translation experiments (Labaka et al., 2007). We used freely available tools to develop the SMT systems: • GIZA++ toolkit (Och, 2003) for training the word/morpheme alignment. • SRILM toolkit (Stolcke, 2002) for building the language model. • Moses Decoder (Koehn et al., 2007) for translating the sentences. Due to the morphological richness of Basque, some Spanish words, like prepositions or articles, correspond to one or more suffixes in Basque. In order to deal with this problem, we built a morpheme-based SMT system. Adapting the SMT system to work at the morpheme level consists of training the basic SMT on the segmented text. The translation system trained on this data will generate a sequence of morphemes as output. In order to obtain the final Basque text, words have to be generated from those morphemes. To obtain the segmented text, we analyzed Basque texts u"
2008.amta-papers.1,2007.mtsummit-papers.40,1,0.910093,"huge parallel corpus available. This hybrid proposal is based on the combination of three different MT paradigms: Example-Based MT, Statistical MT and RuleBased MT. We have evaluated the system, reporting automatic evaluation metrics for a corpus in a test domain. The first results obtained are encouraging. 1 Introduction Machine translation for Basque is both a real need and a testing ground for our strategy to develop language tools. The first development was Matxin, a Rule-Based MT system (Mayor, 2007). Later on a Data-Driven Machine Translation system was built and both systems compared (Labaka et al., 2007). As both approaches have their limits, and each deals with a different kind of knowledge, it was decided to try combining them to improve their results. On the one hand, after improvements in 2007 (Labaka et al., 2007) the Spanish-to-Basque RBMT system Matxin proved useful for assimilation, but is still not suitable for unrestricted use in text dissemination. On the other hand, data-driven MT systems base their knowledge on aligned bilingual corpora, and the accuracy of their output depends heavily on the quality and the size of these corpora. When the pair of languages used in translation, s"
2008.amta-papers.1,D07-1105,0,0.0221994,"Missing"
2008.amta-papers.1,E06-1005,0,0.0276355,"Missing"
2008.amta-papers.1,1999.tmi-1.10,0,0.036401,"ltiEngine MT system In the next subsections we explain the three single MT strategies we have developed: ExampleBased Approach, Statistical Machine Translation Approach and Rule-Based Machine Translation Approach. Finally, we explain how we have combined these three approaches. 4.1 Example Based Approach In this subsection we explain how we automatically extract translation patterns from the bilingual parallel corpus and how we exploit them. Translation patterns are generalizations of sentences that are translations of each other, replacing various sequences of one or more words by variables (McTait, 1999). Starting from the aligned corpus we carry out two steps to automatically extract translation patterns. First, we detect some concrete units (mainly entities) in the aligned sentences and then we replace these units by variables. To detect the units, due to the morphosyntactic differences between Spanish and Basque, we need to execute particular algorithms for each language. We have developed algorithms to determine the boundaries of dates, numbers, named entities, abbreviations and enumerations. After detecting the units, they must be aligned, relating the Spanish and Basque units of the sam"
2008.amta-papers.1,2006.amta-papers.13,0,0.0224397,"Missing"
2008.amta-papers.1,P02-1040,0,0.0836136,"Missing"
2008.amta-papers.1,N07-1029,0,0.0234727,"Missing"
2008.amta-papers.1,2006.amta-papers.25,0,0.0150697,"tures are added to the whole noun phrase at the end of the last word), but in verb chains other words need morphological generation. We adapted a previous morphological analyzer/generator for Basque (Alegria et al., 1996) and transformed it according to the format used in Apertium. The results for the Spanish-Basque system using FreeLing and Matxin are promising. The quantitative evaluation uses the open-source evaluation tool 41 IQMT and we give figures using BLEU and NIST measures (Gim´enez et al., 2005). We also carried out an additional user-based evaluation, using Translation Error Rate (Snover et al., 2006). (Mayor, 2007) shows the results of the RBMT system’s evaluation: 9.30, using the BLEU accuracy measure. In interpreting the results, we need to keep in mind that the development of this RBMT system was based on texts of newspapers. We adapted this RBMT system to the domain of Labor Agreements in three main ways: 1. Terminology. Semiautomatic extraction of terminology using Elexbi, a bilingual terminology extractor for noun phrases (Alegria et al., 2006). Additionally, we carried out an automatic format conversion to the monolingual and bilingual lexicons for the selected terms. We extracted"
2008.amta-papers.1,2005.mtsummit-papers.23,0,0.0972435,"Missing"
2009.eamt-1.11,J04-2003,0,0.0319622,"3 Related work SMT systems The main deal of this work is to measure the impact of different segmentation options on a Spanish-Basque SMT system. In order to measure this impact we have compared the quality of the baseline system which does not use segmentation at all, with systems that use different segmentation options. the development of those systems has been carried out using freely available tools: Many researchers have tried to use morphological information in improving machine translation quality. In (Koehn and Knight, 2003), the authors got improvements splitting compounds in German. Nießen and Ney (2004) achieved a similar level of alignment quality with a smaller corpora restructuring the source based on morphosyntactic information when translating from German to English. More recently, on (Goldwater and McClosky, 2005) the authors achieved improvements in Czech-English MT optimizing a set of possible source transformations, incorporating morphology. • GIZA++ toolkit (Och and H. Ney, 2003) was used for training the word alignment. • SRILM toolkit (Stolcke, 2002) was used for building the language model. • Moses Decoder (Koehn et al., 2007) was used for translating the test sentences. In gene"
2009.eamt-1.11,J03-1002,0,0.00658393,"Missing"
2009.eamt-1.11,P02-1038,0,0.0162784,"se of segmentation does not get any improvement at translation, but combining segmentation with a word-level language model (incorporated by using n-best list re-scoring) and setting as unlimited the value of the distortion limit (in order to deal with the great order difference between both languages) they achieve a significant improvement over the baseline. 3.1 Baseline We have trained Moses on the tokenized corpus (without any segmentation) as baseline system. Moses and the scripts provided with it allow to easily train a state-of-the-art phrase-based SMT system. We have used a log-linear (Och and Ney, 2002) combination of several common feature functions: phrase translation probabilities (in both directions), word-based translation probabilities (lexicon model, in both directions), a phrase length penalty and a target language model. The decoder also relies on a target language model. The language model is a simple 5-gram language model trained on the Basque portion of the training data, using the SRI Language Modeling Toolkit, with modified Kneser-Ney smoothing. Finally, we have also used a lexical reordering model (one of the advanced features provided by Moses1 ), trained using Moses scripts"
2009.eamt-1.11,P03-1021,0,0.0148598,"del, in both directions), a phrase length penalty and a target language model. The decoder also relies on a target language model. The language model is a simple 5-gram language model trained on the Basque portion of the training data, using the SRI Language Modeling Toolkit, with modified Kneser-Ney smoothing. Finally, we have also used a lexical reordering model (one of the advanced features provided by Moses1 ), trained using Moses scripts and ’msdbidirectional-fe’ option. The general design of the baseline system is presented on Figure 1. Moses also implements Minimum-Error-Rate Training (Och, 2003) within a log-linear framework for parameter optimization. The metric used to carry out this optimization is BLEU (Papineni et al., 2002). Segmentation is the most usual way to translate into highly inflected languages, but other approaches have been also tried. In (Bojar, 2007) factored translation have been used on EnglishCzech translation. Words of both languages are tagged with morphological information creating different factors which are translated independently and combined in a generation stage. Finally, in (Minkov et al., 2007) the authors have divided translation in two steps where t"
2009.eamt-1.11,W07-0704,0,0.0601227,"s Decoder (Koehn et al., 2007) was used for translating the test sentences. In general most experiments are focused on translating from morphologically rich languages into English. But last years some works have experimented on the opposite direction. For example, in (Ramanathan et al., 2008), the authors segmented Hindi in English-Hindi statistical machine translation separating suffixes and lemmas and, in combination with the reordering of the source words based on English syntactic analysis, they got a significant improvement both in automatic and human evaluation metrics. In a similar way Oflazer and El-Kahlout (2007) also segmented Turkish words when translate from English. The isolated use of segmentation does not get any improvement at translation, but combining segmentation with a word-level language model (incorporated by using n-best list re-scoring) and setting as unlimited the value of the distortion limit (in order to deal with the great order difference between both languages) they achieve a significant improvement over the baseline. 3.1 Baseline We have trained Moses on the tokenized corpus (without any segmentation) as baseline system. Moses and the scripts provided with it allow to easily trai"
2009.eamt-1.11,P02-1040,0,0.0762767,"odel. The language model is a simple 5-gram language model trained on the Basque portion of the training data, using the SRI Language Modeling Toolkit, with modified Kneser-Ney smoothing. Finally, we have also used a lexical reordering model (one of the advanced features provided by Moses1 ), trained using Moses scripts and ’msdbidirectional-fe’ option. The general design of the baseline system is presented on Figure 1. Moses also implements Minimum-Error-Rate Training (Och, 2003) within a log-linear framework for parameter optimization. The metric used to carry out this optimization is BLEU (Papineni et al., 2002). Segmentation is the most usual way to translate into highly inflected languages, but other approaches have been also tried. In (Bojar, 2007) factored translation have been used on EnglishCzech translation. Words of both languages are tagged with morphological information creating different factors which are translated independently and combined in a generation stage. Finally, in (Minkov et al., 2007) the authors have divided translation in two steps where they first use usual SMT system to translate from English to Russian lemmas and in a second step they decide the inflection of each lemma"
2009.eamt-1.11,W07-0735,0,0.0136028,"with modified Kneser-Ney smoothing. Finally, we have also used a lexical reordering model (one of the advanced features provided by Moses1 ), trained using Moses scripts and ’msdbidirectional-fe’ option. The general design of the baseline system is presented on Figure 1. Moses also implements Minimum-Error-Rate Training (Och, 2003) within a log-linear framework for parameter optimization. The metric used to carry out this optimization is BLEU (Papineni et al., 2002). Segmentation is the most usual way to translate into highly inflected languages, but other approaches have been also tried. In (Bojar, 2007) factored translation have been used on EnglishCzech translation. Words of both languages are tagged with morphological information creating different factors which are translated independently and combined in a generation stage. Finally, in (Minkov et al., 2007) the authors have divided translation in two steps where they first use usual SMT system to translate from English to Russian lemmas and in a second step they decide the inflection of each lemma using bilingual information. 3.2 Morpheme-based statistical machine translation Basque is an agglutinative language, so words may be made up s"
2009.eamt-1.11,I08-1067,0,0.158868,", on (Goldwater and McClosky, 2005) the authors achieved improvements in Czech-English MT optimizing a set of possible source transformations, incorporating morphology. • GIZA++ toolkit (Och and H. Ney, 2003) was used for training the word alignment. • SRILM toolkit (Stolcke, 2002) was used for building the language model. • Moses Decoder (Koehn et al., 2007) was used for translating the test sentences. In general most experiments are focused on translating from morphologically rich languages into English. But last years some works have experimented on the opposite direction. For example, in (Ramanathan et al., 2008), the authors segmented Hindi in English-Hindi statistical machine translation separating suffixes and lemmas and, in combination with the reordering of the source words based on English syntactic analysis, they got a significant improvement both in automatic and human evaluation metrics. In a similar way Oflazer and El-Kahlout (2007) also segmented Turkish words when translate from English. The isolated use of segmentation does not get any improvement at translation, but combining segmentation with a word-level language model (incorporated by using n-best list re-scoring) and setting as unlim"
2009.eamt-1.11,H05-1085,0,0.0147352,"baseline system which does not use segmentation at all, with systems that use different segmentation options. the development of those systems has been carried out using freely available tools: Many researchers have tried to use morphological information in improving machine translation quality. In (Koehn and Knight, 2003), the authors got improvements splitting compounds in German. Nießen and Ney (2004) achieved a similar level of alignment quality with a smaller corpora restructuring the source based on morphosyntactic information when translating from German to English. More recently, on (Goldwater and McClosky, 2005) the authors achieved improvements in Czech-English MT optimizing a set of possible source transformations, incorporating morphology. • GIZA++ toolkit (Och and H. Ney, 2003) was used for training the word alignment. • SRILM toolkit (Stolcke, 2002) was used for building the language model. • Moses Decoder (Koehn et al., 2007) was used for translating the test sentences. In general most experiments are focused on translating from morphologically rich languages into English. But last years some works have experimented on the opposite direction. For example, in (Ramanathan et al., 2008), the autho"
2009.eamt-1.11,zhang-etal-2004-interpreting,0,0.0454873,"Missing"
2009.eamt-1.11,E03-1076,0,0.0279604,"ings of the 13th Annual Conference of the EAMT, pages 74–80, Barcelona, May 2009 74 2 3 Related work SMT systems The main deal of this work is to measure the impact of different segmentation options on a Spanish-Basque SMT system. In order to measure this impact we have compared the quality of the baseline system which does not use segmentation at all, with systems that use different segmentation options. the development of those systems has been carried out using freely available tools: Many researchers have tried to use morphological information in improving machine translation quality. In (Koehn and Knight, 2003), the authors got improvements splitting compounds in German. Nießen and Ney (2004) achieved a similar level of alignment quality with a smaller corpora restructuring the source based on morphosyntactic information when translating from German to English. More recently, on (Goldwater and McClosky, 2005) the authors achieved improvements in Czech-English MT optimizing a set of possible source transformations, incorporating morphology. • GIZA++ toolkit (Och and H. Ney, 2003) was used for training the word alignment. • SRILM toolkit (Stolcke, 2002) was used for building the language model. • Mose"
2009.eamt-1.11,P07-2045,0,0.0120996,"rs got improvements splitting compounds in German. Nießen and Ney (2004) achieved a similar level of alignment quality with a smaller corpora restructuring the source based on morphosyntactic information when translating from German to English. More recently, on (Goldwater and McClosky, 2005) the authors achieved improvements in Czech-English MT optimizing a set of possible source transformations, incorporating morphology. • GIZA++ toolkit (Och and H. Ney, 2003) was used for training the word alignment. • SRILM toolkit (Stolcke, 2002) was used for building the language model. • Moses Decoder (Koehn et al., 2007) was used for translating the test sentences. In general most experiments are focused on translating from morphologically rich languages into English. But last years some works have experimented on the opposite direction. For example, in (Ramanathan et al., 2008), the authors segmented Hindi in English-Hindi statistical machine translation separating suffixes and lemmas and, in combination with the reordering of the source words based on English syntactic analysis, they got a significant improvement both in automatic and human evaluation metrics. In a similar way Oflazer and El-Kahlout (2007)"
2009.eamt-1.9,W07-1608,0,0.0185651,"he preposition translation module is later used in subsequent modules in the structural transfer and generation phases. Note that errors from previous modules affect the quality of the preposition translation phase, and this makes the separate evaluation of preposition translation a difficult task. We will get back to this problem in Section 6. tactic and semantic information. While the latter rules have been coded manually, the first two resources have been automatically extracted from monolingual corpora. One important contribution of this paper is the evaluation methodology. Previous work (Husain et al., 2007; Gustavii, 2005) on preposition translation measured only accuracy gains with respect to simple baselines, and focused on small sets of frequent prepositions. Our methodology measures both precision and recall over all prepositions occurring in a small corpus of randomly chosen sentences. Once the evaluation corpus has been compiled, the evaluation is fully automatic. The results of this paper shows that all proposed techniques improve over the baselines, including a translation dictionary compiled from an aligned corpus, and over a full-fledged statistical machine translation (SMT) system. T"
2009.eamt-1.9,P91-1020,0,0.200151,"ual corpora. The results obtained using a new evaluation methodology show that all proposed techniques improve precision over the baselines, including a translation dictionary compiled from an aligned corpus, and a state-of-the-art statistical Machine Translation system. The results also show that linguistic information in all three techniques are complementary, and that a combination of them obtains the best F-score results overall. 1 Introduction Since the first Machine Translation (MT) systems up to today’s, performing well the translation of the prepositions is relevant for any MT system; Japkowicz and Wiebe (1991) claimed that doing it correctly is difficult because prepositions cannot be translated in a systematic or coherent way. Koehn (2003) remarked the importance of the correct translation of prepositions and he also reported that the main reason for noun phrase (NP) and 1 When we use here the word postposition, we would like to refer to grammatical cases and postpositions c 2009 European Association for Machine Translation. Proceedings of the 13th Annual Conference of the EAMT, pages 58–65, Barcelona, May 2009 58 mation. The freely available open-source Matxin system is the first MT system availa"
2009.eamt-1.9,N03-1017,0,0.00828042,"s were used to reduce the errors caused by unergative verbs and wrong verb attachment decisions. 4.2 Head word PRONOUN PRONOUN PERSON LOCATION talde (group) LOCATION ORGANIZATION partidu (match) Table 2: Dependency triples for verb ikusi. pendency triples to disambiguate the prepositions heading verbal complements. 5.1 Baselines The baseline dictionary uses the preposition translations in the Elhuyar dictionary (Elhuyar, 2000), the most popular Spanish-Basque dictionary. The first postposition is taken as the preferred translation. The aligned corpora baseline was constructed applying Giza++ (Koehn et al., 2003) to the Consumer magazine parallel corpus (Alcazar, 2006). This corpus contains 60,000 parallel sentences in Spanish (1.3 Mwords) and Basque (1 Mwords). The Basque part of the corpus was morphologically analyzed and segmented, i.e. word forms were split into their lemma and postposition (e.g.: etxetik (from the house) → etxe (the house) + tik (from)). After preprocessing the Basque sentences, we aligned the text automatically and extracted for each Spanish preposition its most frequent corresponding Basque postposition. This alignment technique proved to be superior to wordbase alignment (Agir"
2009.eamt-1.9,W06-3114,0,0.0168814,"erent baselines and techniques to translate prepositions. Our evaluation methodology is proposed in Section 6, which is followed by Section 7 with the results. Finally, Section 8 is devoted to conclusions and future work. 2 Preposition translation in RBMT The last decade has seen the raise of SMT techniques, and less research on rule-based techniques. Nevertheless, translation involving a lessresourced language poses serious difficulties for SMT, specially caused by the smaller size of parallel corpora. Morphologically-rich languages have also been proved to be difficult for SMT, as shown in (Koehn and Monz, 2006), where SMT systems lag well behind commercial RBMT systems. At present, domain-specific translation memories for Basque are no bigger than two or three million words, much smaller than corpora used for other languages (the Europarl parallel corpus, for instance, has ca. 30 Mwords). Having limited digital resources, the rule-based approach is suitable for the development of an MT system for Basque, along with a focus on the enhancement of the core RBMT system with statistical and linguistic infor3 Related work Koehn (2003) envisages MT as a divide and conquer task where improving NP/PP transla"
2009.eamt-1.9,2007.mtsummit-papers.40,1,0.920443,"Missing"
2009.eamt-1.9,W04-2608,0,0.0291545,"focus on the enhancement of the core RBMT system with statistical and linguistic infor3 Related work Koehn (2003) envisages MT as a divide and conquer task where improving NP/PP translation will carry an improvement of the whole system. That study concluded that the main source of re-ranking errors in NP/PPs translation was the inability to correctly predict the phrase start (preposition or determiner) without context; it can sometimes only be resolved when the English verb is chosen and its subcategorization is known. There are two main approaches to disambiguate prepositions (Mamidi, 2004; Alam, 2004; Trujillo, 1992): context based (used in transfer systems and more suitable for languages that are structurally different) and concept based (used in interlingua 59 Freq. 4289.78 1534.24 975.31 476.70 166.68 systems and more suitable for languages which are very close). Most of the systems are context based and they use transfer rules given with semantic information for the nouns which are head and complement of the preposition. Transitivity transitive intransitive transitive intransitive transitive Postpositions ABS,ERG ABS ABS,ERG,INE ABS,INE ABS,ERG,INS Table 1: Subcategorization for verb"
2009.eamt-1.9,przybocki-etal-2006-edit,0,0.127068,". It is a rule-based transfer system based on deep syntactic analysis. which currently translates from Spanish into Basque, and is currently being adapted to the English-Basque pair. The current development status shows that it is useful for content assimilation, for text understanding indeed, but that it is not yet suitable for unrestricted use in text dissemination. Matxin has been evaluated and compared with the state-of-the-art corpus-based Matrex MT system (Stroppa et al., 2006; Labaka, 2007) translating from Spanish to Basque. The evaluation was performed using the edit-distance metric (Przybocki et al., 2006), based on the HTER (humantargeted translation edit rate) presented in (Snover et al., 2006), and the comparative results have shown that Matxin performs significantly better: 43.60 vs. 57.97 in the parallel corpus where Matrex was trained, and 40.41 vs. 71.87 in an out-ofdomain corpus. The preposition translation module of Matxin is located in the structural transfer phase and uses the information carried over from the syntactic analysis and lexical transfer modules. The system currently uses Freeling analyzer for Spanish (Atserias et al., 2006). The output of the preposition translation modu"
2009.eamt-1.9,atserias-etal-2006-freeling,0,0.0225619,"Missing"
2009.eamt-1.9,2006.amta-papers.25,0,0.0164625,"es from Spanish into Basque, and is currently being adapted to the English-Basque pair. The current development status shows that it is useful for content assimilation, for text understanding indeed, but that it is not yet suitable for unrestricted use in text dissemination. Matxin has been evaluated and compared with the state-of-the-art corpus-based Matrex MT system (Stroppa et al., 2006; Labaka, 2007) translating from Spanish to Basque. The evaluation was performed using the edit-distance metric (Przybocki et al., 2006), based on the HTER (humantargeted translation edit rate) presented in (Snover et al., 2006), and the comparative results have shown that Matxin performs significantly better: 43.60 vs. 57.97 in the parallel corpus where Matrex was trained, and 40.41 vs. 71.87 in an out-ofdomain corpus. The preposition translation module of Matxin is located in the structural transfer phase and uses the information carried over from the syntactic analysis and lexical transfer modules. The system currently uses Freeling analyzer for Spanish (Atserias et al., 2006). The output of the preposition translation module is later used in subsequent modules in the structural transfer and generation phases. Not"
2009.eamt-1.9,1992.tmi-1.2,0,0.307609,"e enhancement of the core RBMT system with statistical and linguistic infor3 Related work Koehn (2003) envisages MT as a divide and conquer task where improving NP/PP translation will carry an improvement of the whole system. That study concluded that the main source of re-ranking errors in NP/PPs translation was the inability to correctly predict the phrase start (preposition or determiner) without context; it can sometimes only be resolved when the English verb is chosen and its subcategorization is known. There are two main approaches to disambiguate prepositions (Mamidi, 2004; Alam, 2004; Trujillo, 1992): context based (used in transfer systems and more suitable for languages that are structurally different) and concept based (used in interlingua 59 Freq. 4289.78 1534.24 975.31 476.70 166.68 systems and more suitable for languages which are very close). Most of the systems are context based and they use transfer rules given with semantic information for the nouns which are head and complement of the preposition. Transitivity transitive intransitive transitive intransitive transitive Postpositions ABS,ERG ABS ABS,ERG,INE ABS,INE ABS,ERG,INS Table 1: Subcategorization for verb ikusi (to see). ("
2009.eamt-1.9,2005.eamt-1.16,0,0.110714,"ation module is later used in subsequent modules in the structural transfer and generation phases. Note that errors from previous modules affect the quality of the preposition translation phase, and this makes the separate evaluation of preposition translation a difficult task. We will get back to this problem in Section 6. tactic and semantic information. While the latter rules have been coded manually, the first two resources have been automatically extracted from monolingual corpora. One important contribution of this paper is the evaluation methodology. Previous work (Husain et al., 2007; Gustavii, 2005) on preposition translation measured only accuracy gains with respect to simple baselines, and focused on small sets of frequent prepositions. Our methodology measures both precision and recall over all prepositions occurring in a small corpus of randomly chosen sentences. Once the evaluation corpus has been compiled, the evaluation is fully automatic. The results of this paper shows that all proposed techniques improve over the baselines, including a translation dictionary compiled from an aligned corpus, and over a full-fledged statistical machine translation (SMT) system. The results also s"
2009.eamt-1.9,E06-1032,0,\N,Missing
2009.eamt-1.9,W06-2113,0,\N,Missing
2009.eamt-1.9,2006.amta-papers.26,1,\N,Missing
2009.mtsummit-posters.4,carreras-etal-2004-freeling,0,0.0687006,"Missing"
2009.mtsummit-posters.4,2006.iwslt-papers.4,0,0.0174712,"erman and some local reordering for English-Spanish and German-Spanish language pairs. More recently, on (Ramanathan et al., 2008), authors combine Hindi language segmentation with some reordering applied on the syntactic analysis of the source to improve the quality of the English-Hindi SMT baseline system. Many other research works try to learn the possible reordering automatically from the training corpus, instead of defining them manually. Some of those extract source reordering rules from the word alignment, based on different levels of linguistic analysis, from Part-of-Speech labelling (Chen et al., 2006) to shallow parsing (Zhang et al., 2007). Some other research works (Sanchis and Casacuberta, 2007; Costa-juss`a and Fonollosa, 2006) consider the source reordering as a translation process, learning a SMT system to “translate” from the original source sentences to the reordered source sentences. 3 Reordering techniques The main deal of this work is to analyse the impact of different reordering techniques on SMT. For this purpose, we have compared the results obtained by Spanish-Basque translation systems which implement the following reordering techniques. 3.1 Lexicalized reordering The first"
2009.mtsummit-posters.4,W06-1609,0,0.0263404,"Missing"
2009.mtsummit-posters.4,2009.eamt-1.11,1,0.797537,"Missing"
2009.mtsummit-posters.4,P07-2045,0,0.0106015,"porated using nbest lists reranking. Figure 4 shows the general design of the system used in this work. Systems’ overview In order to measure the impact of the reordering techniques presented above, we built systems which uses those techniques (as well as baselines which uses distance-based reordering) and we compared their performance. The development of all those systems has been carried out using freely available tools: • GIZA++ toolkit (Och and H. Ney, 2003) was used for training the word alignment. • SRILM toolkit (Stolcke, 2002) was used for building the language model. • Moses Decoder (Koehn et al., 2007) was used for translating the test sentences. Figure 4: Design of the segmentation-based SMT system Over the segmented target text, we have trained nine different systems combining three possible source text preprocessing (without reordering, Syntax-Based reordering and statistical reordering) and three reordering configurations at decoding (monotone, distance-based and lexicalized reordering). Besides, we have also trained three more SMT systems, one for each reordering configurations at decoding, over the original (unsegmented) target text, in order to compare the results obtained using segm"
2009.mtsummit-posters.4,J03-1002,0,0.00683551,"Missing"
2009.mtsummit-posters.4,P02-1038,0,0.0659838,"t text, in order to compare the results obtained using segmentation with a real state-of-the-art system. sentences training development test Spanish Basque (tokenized) Basque (segmented) Spanish Basque (tokenized) Basque (segmented) Spanish Basque (tokenized) Basque (segmented) 58,202 1,456 1,446 tokens vocabulary singletons 1,284,089 1,010,545 1,546,304 32,740 25,778 39,429 31,002 24,372 37,361 46,636 87,763 40,288 7,074 9,030 6,189 6,838 8,695 5,974 19,256 46,929 19,031 4,351 6,339 3,464 4,281 6,077 3,301 Table 1: Some statistics of the corpora. All the systems use a log-linear combination (Och and Ney, 2002) of several common feature functions: phrase translation probabilities (in both directions), word-based translation probabilities (lexicon model, in both directions), a phrase length penalty, a word length penalty and a target language model. Both the language model used at decoding (based on the segmented text) and the language model which is incorporated after generation (based on the final words) are 5-gram models trained on the Basque portion of the bilingual corpus, using the SRI Language Modeling Toolkit, with modified Kneser-Ney smoothing. We have used Minimum-Error-Rate Training (Och,"
2009.mtsummit-posters.4,P03-1021,0,0.0276829,"2002) of several common feature functions: phrase translation probabilities (in both directions), word-based translation probabilities (lexicon model, in both directions), a phrase length penalty, a word length penalty and a target language model. Both the language model used at decoding (based on the segmented text) and the language model which is incorporated after generation (based on the final words) are 5-gram models trained on the Basque portion of the bilingual corpus, using the SRI Language Modeling Toolkit, with modified Kneser-Ney smoothing. We have used Minimum-Error-Rate Training (Och, 2003) within a log-linear framework for parameter optimization. The metric used to carry out this optimization is BLEU (Papineni et al., 2002). 5 5.1 Experimental results Data and evaluation In order to carry out this experiment we used the Consumer Eroski parallel corpus (Alc´azar, 2005). This corpus is a collection of 1036 articles written in Spanish (January 1998 to May 2005, Consumer Eroski magazine, http://revista.consumer.es) along with their Basque, Catalan and Galician translations. It contains more than 1,200,000 Spanish words and more than 1,000,000 Basque words. This corpus was automatic"
2009.mtsummit-posters.4,P02-1040,0,0.0845459,"abilities (lexicon model, in both directions), a phrase length penalty, a word length penalty and a target language model. Both the language model used at decoding (based on the segmented text) and the language model which is incorporated after generation (based on the final words) are 5-gram models trained on the Basque portion of the bilingual corpus, using the SRI Language Modeling Toolkit, with modified Kneser-Ney smoothing. We have used Minimum-Error-Rate Training (Och, 2003) within a log-linear framework for parameter optimization. The metric used to carry out this optimization is BLEU (Papineni et al., 2002). 5 5.1 Experimental results Data and evaluation In order to carry out this experiment we used the Consumer Eroski parallel corpus (Alc´azar, 2005). This corpus is a collection of 1036 articles written in Spanish (January 1998 to May 2005, Consumer Eroski magazine, http://revista.consumer.es) along with their Basque, Catalan and Galician translations. It contains more than 1,200,000 Spanish words and more than 1,000,000 Basque words. This corpus was automatically aligned at sentence level2 and it is available3 for research. Consumer Eroski magazine is composed by the articles which compare the"
2009.mtsummit-posters.4,popovic-ney-2006-pos,0,0.0391642,"Missing"
2009.mtsummit-posters.4,I08-1067,0,0.0194955,"ng German sentences based on the syntactic parsing. They define a small amount of rules to reorder verbal clauses in German, obtaining a English-like word order. In this way, they get an significant improvement both in BLEU and human judgments. Later, similar attempts are carried out for different languages. For example, Popovic and Ney (2006) proposed different reordering rules depending on the languages involved on the translation. They defined long-range reordering when translate into German and some local reordering for English-Spanish and German-Spanish language pairs. More recently, on (Ramanathan et al., 2008), authors combine Hindi language segmentation with some reordering applied on the syntactic analysis of the source to improve the quality of the English-Hindi SMT baseline system. Many other research works try to learn the possible reordering automatically from the training corpus, instead of defining them manually. Some of those extract source reordering rules from the word alignment, based on different levels of linguistic analysis, from Part-of-Speech labelling (Chen et al., 2006) to shallow parsing (Zhang et al., 2007). Some other research works (Sanchis and Casacuberta, 2007; Costa-juss`a"
2009.mtsummit-posters.4,2007.tmi-papers.23,0,0.0342084,"More recently, on (Ramanathan et al., 2008), authors combine Hindi language segmentation with some reordering applied on the syntactic analysis of the source to improve the quality of the English-Hindi SMT baseline system. Many other research works try to learn the possible reordering automatically from the training corpus, instead of defining them manually. Some of those extract source reordering rules from the word alignment, based on different levels of linguistic analysis, from Part-of-Speech labelling (Chen et al., 2006) to shallow parsing (Zhang et al., 2007). Some other research works (Sanchis and Casacuberta, 2007; Costa-juss`a and Fonollosa, 2006) consider the source reordering as a translation process, learning a SMT system to “translate” from the original source sentences to the reordered source sentences. 3 Reordering techniques The main deal of this work is to analyse the impact of different reordering techniques on SMT. For this purpose, we have compared the results obtained by Spanish-Basque translation systems which implement the following reordering techniques. 3.1 Lexicalized reordering The first method we have tried in this work is the lexicalized reordering1 implemented in Moses. This metho"
2009.mtsummit-posters.4,W07-0401,0,0.0454088,"lish-Spanish and German-Spanish language pairs. More recently, on (Ramanathan et al., 2008), authors combine Hindi language segmentation with some reordering applied on the syntactic analysis of the source to improve the quality of the English-Hindi SMT baseline system. Many other research works try to learn the possible reordering automatically from the training corpus, instead of defining them manually. Some of those extract source reordering rules from the word alignment, based on different levels of linguistic analysis, from Part-of-Speech labelling (Chen et al., 2006) to shallow parsing (Zhang et al., 2007). Some other research works (Sanchis and Casacuberta, 2007; Costa-juss`a and Fonollosa, 2006) consider the source reordering as a translation process, learning a SMT system to “translate” from the original source sentences to the reordered source sentences. 3 Reordering techniques The main deal of this work is to analyse the impact of different reordering techniques on SMT. For this purpose, we have compared the results obtained by Spanish-Basque translation systems which implement the following reordering techniques. 3.1 Lexicalized reordering The first method we have tried in this work is th"
2011.mtsummit-papers.63,2010.eamt-1.33,0,0.129673,"p towards hybridization. Although it has been shown to help in improving translation quality, the combination does not represent a real hybridization since systems do not interact among them (see Thurmair 555 (2009) for a classiﬁcation of HMT architectures). In the case of actual interdependences, one of the systems in action leads the translation process and the other ones strengthen it. Much work has been done in building systems where the statistical component is in charge of the translation and the companion system provides complementary information. For instance, Eisele et al. (2008) and Chen and Eisele (2010) introduce lexical information coming from a rule-based translator into an SMT system, in the form of new phrase pairs for the translation table. In both cases results are positive on out-of-domain tests. The opposite direction, that is, where the RBMT system leads the translation and the SMT system provides complementary information, has been less explored. Habash et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally,"
2011.mtsummit-papers.63,W08-0328,0,0.0945801,"s’ outputs, is a ﬁrst step towards hybridization. Although it has been shown to help in improving translation quality, the combination does not represent a real hybridization since systems do not interact among them (see Thurmair 555 (2009) for a classiﬁcation of HMT architectures). In the case of actual interdependences, one of the systems in action leads the translation process and the other ones strengthen it. Much work has been done in building systems where the statistical component is in charge of the translation and the companion system provides complementary information. For instance, Eisele et al. (2008) and Chen and Eisele (2010) introduce lexical information coming from a rule-based translator into an SMT system, in the form of new phrase pairs for the translation table. In both cases results are positive on out-of-domain tests. The opposite direction, that is, where the RBMT system leads the translation and the SMT system provides complementary information, has been less explored. Habash et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their"
2011.mtsummit-papers.63,W10-1708,0,0.424766,"arge of the translation and the companion system provides complementary information. For instance, Eisele et al. (2008) and Chen and Eisele (2010) introduce lexical information coming from a rule-based translator into an SMT system, in the form of new phrase pairs for the translation table. In both cases results are positive on out-of-domain tests. The opposite direction, that is, where the RBMT system leads the translation and the SMT system provides complementary information, has been less explored. Habash et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally, their results improve the individual systems when the hybrid system is applied to translate into languages with a richer morphology than the source. Similar in spirit to Federmann et al. (2010), translations given by SMatxinT are controlled by the RBMT system in a way that will be clariﬁed in the following sections, but SMatxinT is enriched with a wider variety of SMT translation options. 3 3.1 A Hybrid MT Model Guided by RBMT Individual MT Systems Our hybrid model builds"
2011.mtsummit-papers.63,P07-2045,0,0.00881348,"way that will be clariﬁed in the following sections, but SMatxinT is enriched with a wider variety of SMT translation options. 3 3.1 A Hybrid MT Model Guided by RBMT Individual MT Systems Our hybrid model builds on three individual machine translation systems, a rule-based SpanishBasque system and two variants of regular phrase based statistical MT systems. These three subsystems are described below. SMT basic system (SMTb) The development of the baseline system was carried out using available state-of-the-art tools: GIZA++ toolkit (Och, 2003), SRILM toolkit (Stolcke, 2002) and Moses Decoder (Koehn et al., 2007). More particularly, we used a log-linear combination of several common feature functions: phrase translation probabilities (in both directions), word-based translation probabilities (lexicon model, in both directions), a phrase length penalty and the target language model. The language model is a simple 3-gram language model Figure 1: General architecture of SMatxinT. The RBMT modules which guide the MT process are the grey boxes with modiﬁed Kneser-Ney smoothing. We also used a lexical reordering model (‘msd-bidirectional-fe’ training option). Parameter optimization was done following the us"
2011.mtsummit-papers.63,W04-3250,0,0.076376,"Missing"
2011.mtsummit-papers.63,P03-1021,0,0.0159102,"ons given by SMatxinT are controlled by the RBMT system in a way that will be clariﬁed in the following sections, but SMatxinT is enriched with a wider variety of SMT translation options. 3 3.1 A Hybrid MT Model Guided by RBMT Individual MT Systems Our hybrid model builds on three individual machine translation systems, a rule-based SpanishBasque system and two variants of regular phrase based statistical MT systems. These three subsystems are described below. SMT basic system (SMTb) The development of the baseline system was carried out using available state-of-the-art tools: GIZA++ toolkit (Och, 2003), SRILM toolkit (Stolcke, 2002) and Moses Decoder (Koehn et al., 2007). More particularly, we used a log-linear combination of several common feature functions: phrase translation probabilities (in both directions), word-based translation probabilities (lexicon model, in both directions), a phrase length penalty and the target language model. The language model is a simple 3-gram language model Figure 1: General architecture of SMatxinT. The RBMT modules which guide the MT process are the grey boxes with modiﬁed Kneser-Ney smoothing. We also used a lexical reordering model (‘msd-bidirectional-"
2011.mtsummit-papers.63,P02-1040,0,0.0860558,"ieces of the source language corresponding to the tree constituents. The ﬁnal decoding accounts also for ﬂuency by using language models, and can be monotonic (and so, fast) because the structure has been already decided by the RBMT component. As a proof of concept we have instantiated and applied the SMatxinT architecture to a pair of structurally and morphologically distant languages, Spanish and Basque. The results obtained on several benchmark corpora show that the hybrid approach is able to signiﬁcantly improve the out-of-domain results of the best individual SMT system in terms of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores. A manual evaluation has been performed on a set of 100 samples from the test set verifying the signiﬁcant advantage of the SMatxinT hybrid system. More detailed analyses reveal that all the components of the hybrid system play an important role in the system (i.e., RBMT structural translation, SMT translation candidates and RBMT original translation). We think that the improvement obtained is remarkable given the simple statistical decoding process implemented so far. Indeed, the upper bound performance for the hybrid method calculated with the current se"
2011.mtsummit-papers.63,2006.amta-papers.25,0,0.0157519,"responding to the tree constituents. The ﬁnal decoding accounts also for ﬂuency by using language models, and can be monotonic (and so, fast) because the structure has been already decided by the RBMT component. As a proof of concept we have instantiated and applied the SMatxinT architecture to a pair of structurally and morphologically distant languages, Spanish and Basque. The results obtained on several benchmark corpora show that the hybrid approach is able to signiﬁcantly improve the out-of-domain results of the best individual SMT system in terms of BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores. A manual evaluation has been performed on a set of 100 samples from the test set verifying the signiﬁcant advantage of the SMatxinT hybrid system. More detailed analyses reveal that all the components of the hybrid system play an important role in the system (i.e., RBMT structural translation, SMT translation candidates and RBMT original translation). We think that the improvement obtained is remarkable given the simple statistical decoding process implemented so far. Indeed, the upper bound performance for the hybrid method calculated with the current setting reveals that there is st"
2011.mtsummit-papers.63,2009.mtsummit-posters.21,0,0.336101,"Missing"
2012.freeopmt-1.7,E06-1032,0,0.0360443,"h et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally, their results improve the individual systems when the hybrid system is applied to translate into languages with a richer morphology than the source. Regarding the evaluation of the final system and its components, still nowadays, the BLEU metric (Papineni et al., 2002) is the most used metric in MT, but several doubts have arisen around it (Melamed et al., 2003, Callison-Burch et al., 2006, Koehn and Monz, 2006). In addition to the fact that it is extremely difficult to interpret what is being expressed in BLEU (Melamed et al., 2003), improving its value neither guarantees an improvement in the translation quality (Callison-Burch et al., 2006) nor offers such high correlation with human judgment as was believed (Koehn and Monz, 2006). In the last few years, several new evaluation metrics have been suggested to consider a higher level of linguistic information (Liu and Gildea, 2005, Popovi´c and Ney, 2007, Chan and Ng, 2008), and different methods of metric combination have been"
2012.freeopmt-1.7,P08-1007,0,0.0201128,"have arisen around it (Melamed et al., 2003, Callison-Burch et al., 2006, Koehn and Monz, 2006). In addition to the fact that it is extremely difficult to interpret what is being expressed in BLEU (Melamed et al., 2003), improving its value neither guarantees an improvement in the translation quality (Callison-Burch et al., 2006) nor offers such high correlation with human judgment as was believed (Koehn and Monz, 2006). In the last few years, several new evaluation metrics have been suggested to consider a higher level of linguistic information (Liu and Gildea, 2005, Popovi´c and Ney, 2007, Chan and Ng, 2008), and different methods of metric combination have been tested. Due to its simplicity, we decided to use the idea presented by Gim´enez and M`arquez (2008), where a set of simple metrics are combined by means of the arithmetic mean. 66 This work presents a deep evaluation experiment of a hybrid architecture that tries to get the best of both worlds, rule-based and statistical. The results obtained corroborated the known doubts about BLEU. And suggests that the further development of the hybrid system should be guided by a linguistically more informed metric that should be able to capture the s"
2012.freeopmt-1.7,2011.mtsummit-papers.63,1,0.814633,"Missing"
2012.freeopmt-1.7,W10-1708,0,0.0154751,"n applied to corpora different from those used for training (out-of-domain evaluation). Because of these complementary virtues and drawbacks several works are being devoted to build hybrid systems with components of both approaches. A classification and a summary of hybrid architectures can be seen in Thurmair (2009). The case we present here is within the philosophy of those systems where the RBMT system leads the translation and the SMT system provides complementary information. Following this line, Habash et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally, their results improve the individual systems when the hybrid system is applied to translate into languages with a richer morphology than the source. Regarding the evaluation of the final system and its components, still nowadays, the BLEU metric (Papineni et al., 2002) is the most used metric in MT, but several doubts have arisen around it (Melamed et al., 2003, Callison-Burch et al., 2006, Koehn and Monz, 2006). In addition to the fact that it is extremely difficult to i"
2012.freeopmt-1.7,W08-0332,1,0.87217,"Missing"
2012.freeopmt-1.7,P07-2045,0,0.00584996,"cing the sparseness produced by the agglutinative nature of Basque and the small amount of parallel corpora. Adapting the baseline system to work at the morpheme level mainly consists of training the decoder on the segmented text. The SMT system trained on segmented words generates a sequence of morphemes. So, in order to obtain the final Basque text from the segmented output, a word-generation post-process is applied. State-of-the-art tools are used in this case. GIZA++ toolkit (Och, 2003) is used for the alignments, SRILM toolkit (Stolcke, 2002) for the language model and the Moses Decoder (Koehn et al., 2007). We used a log-linear functions: phrase translation probabilities (in both directions), word-based translation probabilities (lexicon model, in both directions), a phrase length penalty and the target language model. The language model is a simple 3gram language model with modified Kneser-Ney smoothing. We also used a lexical reordering 1 http://www.opentrad.com 67 model (‘msd-bidirectional-fe’ training option). Parameter optimization was done following the usual practice, i.e., Minimum-Error-Rate Training (Och, 2003), however, the metric used for the optimization is not only BLEU, but it dep"
2012.freeopmt-1.7,W06-3114,0,0.0279294,"ctionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally, their results improve the individual systems when the hybrid system is applied to translate into languages with a richer morphology than the source. Regarding the evaluation of the final system and its components, still nowadays, the BLEU metric (Papineni et al., 2002) is the most used metric in MT, but several doubts have arisen around it (Melamed et al., 2003, Callison-Burch et al., 2006, Koehn and Monz, 2006). In addition to the fact that it is extremely difficult to interpret what is being expressed in BLEU (Melamed et al., 2003), improving its value neither guarantees an improvement in the translation quality (Callison-Burch et al., 2006) nor offers such high correlation with human judgment as was believed (Koehn and Monz, 2006). In the last few years, several new evaluation metrics have been suggested to consider a higher level of linguistic information (Liu and Gildea, 2005, Popovi´c and Ney, 2007, Chan and Ng, 2008), and different methods of metric combination have been tested. Due to its sim"
2012.freeopmt-1.7,W05-0904,0,0.0204949,"the most used metric in MT, but several doubts have arisen around it (Melamed et al., 2003, Callison-Burch et al., 2006, Koehn and Monz, 2006). In addition to the fact that it is extremely difficult to interpret what is being expressed in BLEU (Melamed et al., 2003), improving its value neither guarantees an improvement in the translation quality (Callison-Burch et al., 2006) nor offers such high correlation with human judgment as was believed (Koehn and Monz, 2006). In the last few years, several new evaluation metrics have been suggested to consider a higher level of linguistic information (Liu and Gildea, 2005, Popovi´c and Ney, 2007, Chan and Ng, 2008), and different methods of metric combination have been tested. Due to its simplicity, we decided to use the idea presented by Gim´enez and M`arquez (2008), where a set of simple metrics are combined by means of the arithmetic mean. 66 This work presents a deep evaluation experiment of a hybrid architecture that tries to get the best of both worlds, rule-based and statistical. The results obtained corroborated the known doubts about BLEU. And suggests that the further development of the hybrid system should be guided by a linguistically more informed"
2012.freeopmt-1.7,N03-2021,0,0.0335585,"owing this line, Habash et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally, their results improve the individual systems when the hybrid system is applied to translate into languages with a richer morphology than the source. Regarding the evaluation of the final system and its components, still nowadays, the BLEU metric (Papineni et al., 2002) is the most used metric in MT, but several doubts have arisen around it (Melamed et al., 2003, Callison-Burch et al., 2006, Koehn and Monz, 2006). In addition to the fact that it is extremely difficult to interpret what is being expressed in BLEU (Melamed et al., 2003), improving its value neither guarantees an improvement in the translation quality (Callison-Burch et al., 2006) nor offers such high correlation with human judgment as was believed (Koehn and Monz, 2006). In the last few years, several new evaluation metrics have been suggested to consider a higher level of linguistic information (Liu and Gildea, 2005, Popovi´c and Ney, 2007, Chan and Ng, 2008), and different methods of"
2012.freeopmt-1.7,P03-1021,0,0.00972803,"system, words are split into several morphemes by using a Basque morphological analyzer/lemmatizer, aiming at reducing the sparseness produced by the agglutinative nature of Basque and the small amount of parallel corpora. Adapting the baseline system to work at the morpheme level mainly consists of training the decoder on the segmented text. The SMT system trained on segmented words generates a sequence of morphemes. So, in order to obtain the final Basque text from the segmented output, a word-generation post-process is applied. State-of-the-art tools are used in this case. GIZA++ toolkit (Och, 2003) is used for the alignments, SRILM toolkit (Stolcke, 2002) for the language model and the Moses Decoder (Koehn et al., 2007). We used a log-linear functions: phrase translation probabilities (in both directions), word-based translation probabilities (lexicon model, in both directions), a phrase length penalty and the target language model. The language model is a simple 3gram language model with modified Kneser-Ney smoothing. We also used a lexical reordering 1 http://www.opentrad.com 67 model (‘msd-bidirectional-fe’ training option). Parameter optimization was done following the usual practic"
2012.freeopmt-1.7,P02-1040,0,0.0992093,"he RBMT system leads the translation and the SMT system provides complementary information. Following this line, Habash et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally, their results improve the individual systems when the hybrid system is applied to translate into languages with a richer morphology than the source. Regarding the evaluation of the final system and its components, still nowadays, the BLEU metric (Papineni et al., 2002) is the most used metric in MT, but several doubts have arisen around it (Melamed et al., 2003, Callison-Burch et al., 2006, Koehn and Monz, 2006). In addition to the fact that it is extremely difficult to interpret what is being expressed in BLEU (Melamed et al., 2003), improving its value neither guarantees an improvement in the translation quality (Callison-Burch et al., 2006) nor offers such high correlation with human judgment as was believed (Koehn and Monz, 2006). In the last few years, several new evaluation metrics have been suggested to consider a higher level of linguistic informati"
2012.freeopmt-1.7,W07-0707,0,0.0606548,"Missing"
2012.freeopmt-1.7,2009.mtsummit-posters.21,0,0.0266657,"nslation more locally and have problems with long distance reordering. They also tend to produce very obvious errors, which are annoying for regular users, e.g., lack of gender and number agreement, bad punctuation, etc. Moreover, SMT systems can experience a severe degradation of performance when applied to corpora different from those used for training (out-of-domain evaluation). Because of these complementary virtues and drawbacks several works are being devoted to build hybrid systems with components of both approaches. A classification and a summary of hybrid architectures can be seen in Thurmair (2009). The case we present here is within the philosophy of those systems where the RBMT system leads the translation and the SMT system provides complementary information. Following this line, Habash et al. (2009) enrich the dictionary of a RBMT system with phrases from an SMT system. Federmann et al. (2010) use the translations obtained with a RBMT system and substitute selected noun phrases by their SMT counterparts. Globally, their results improve the individual systems when the hybrid system is applied to translate into languages with a richer morphology than the source. Regarding the evaluati"
2014.amta-wptp.2,2000.bcs-1.2,1,0.552993,"Missing"
2014.amta-wptp.2,2012.amta-papers.22,0,0.0899779,"ent stages of the translation workflow. It couples translation memory (TM) and machine translation (MT) capabilities within a simple work environment. BTS was designed with lay users in mind. The work environment offers a simple layout with a top bar with the main action buttons and job information (see Figure 1). Below, the source text is split into segments and the target side is filled with either TM (fuzzy-)matches or MT candidates for the reviewer to work on. It is a plain tool as opposed to more sophisticated software developed in the CASCAMAT2 and MateCat3 projects (Alabau et al. 2013; Federico et al., 2012), which include interactive translation prediction and track post-editing operations. 1 http://www.bologna-translation.eu/ http://www.casmacat.eu/ 3 http://www.matecat.com/ 2 21 Figure 1. Screenshot of the translation environment at BTS. For the current experiment, the BTS platform was enhanced with an English to Basque MT system. A standard phrase-based statistical machine translation system was built based on Moses using a parallel corpus of 14.58 million English tokens and 12.50 million Basque tokens (1.3 million parallel sentences) which includes localization texts (graphic user interface"
2014.amta-wptp.2,C10-2032,0,0.031537,"ber of linguistic features (including lexical, morphological, syntactic and pragmatic features) present in the translations and post-edited versions of Texts A and B (see Table 8). We observe that out of the 96 features studied, Text B has a higher number of occurrences for 63 for both translators and users, and Text A for 25 and 17, for translators and users, respectively, having no occurrences for 8 and 6 features. Additioanlly, we have considered the 10 most predictive features for complexity according to the same authors, which include a number of the most predictive features according to Feng et al. (2010), namely, partof-speech ratios for nouns. We see that Text B appears to be more complex, scoring higher in 7 out of the 10 features. Number of features analysed Number of features with more hits12 Number of features with no hits Ratios Proper nouns / common nouns Appositions / noun phrases Appositions / all phrases Named entities / common nouns Unique lemmas / all lemmas Acronyms / all words Causative verbs / all verbs Text A Translators 96 25 8 Text A Users 96 17 6 Text B Translators 96 63 8 Text B Users 96 63 13 0.01077 0.04433 0 0.14422 0.03586 0.24811 0.00137 0.01830 0.03040 0.00065 0.1822"
2014.amta-wptp.2,C14-1033,1,0.856838,"Missing"
2014.amta-wptp.2,2009.mtsummit-btm.7,0,0.141172,"tput. We observe that translators and users perceive MT differently. Additionally, a preliminary analysis seems to suggest that familiarity with the domain, source text complexity and MT quality might affect potential productivity gain. 1. Introduction Thanks to the significant improvement of machine translation (MT) over the past two decades, the translation industry has already started to exploit it, mainly by combining it with post-editing. A good number of recent works report a productivity increase thanks to postediting of MT output as compared to the traditional human translation (e.g., Guerberof, 2009; Plitt and Masselot, 2010; Garcia, 2011; Pouliquen et al., 2011; Skadiņš et al., 2011; den Bogaert and Sutter, 2013; Green et al., 2013; Läubli et al., 2013). Most post-editing research is designed with professional translators in mind (even if often post-editors involved in experiments are non-professionals and students). However, it is not only language professionals who can benefit from MT in their daily tasks but also regular users who might need to perform a translation sporadically. In this work, we aim to compare the post-editing productivity between professional translators and lay us"
2014.amta-wptp.2,W14-0307,0,0.0777638,"Missing"
2014.amta-wptp.2,2007.mtsummit-papers.40,1,0.870315,"Missing"
2014.amta-wptp.2,2002.eamt-1.11,0,0.192745,"Missing"
2014.amta-wptp.2,P03-1021,0,0.0117749,"El-Kahlout (2007). We first asked Moses to generate a translation candidate ranking based on the segmented training explained above. Next, these candidates were postprocessed. We then recalculated the total cost of each candidate by including the cost assigned by the new word form-based LM in the models used during decoding. Finally, the candidate list was re-ranked according to this new total cost. This somehow revises the candidate list to promote the ones that are more likely to be real word-form sequences. The weight for the word formbased LM was optimized at Minimum Error Rate Training (Och, 2003) together with the weights for the rest of the models. 22 2.2. The Texts Two texts of around 1200 words each were selected for the experiment. Because the SMT system was trained on science and localization texts among others, it was deemed convenient to use texts from related domains. Text A consists of short 1st year computer science course descriptions from a UK university, and Text B is a collection of six short science articles from www.sciencenews.org, the flagship website by the Society for Science & the Public (SSP), dedicated to public engagement in scientific research and education. T"
2014.amta-wptp.2,W07-0704,0,0.0130047,". Thus, on splitting a word, we generated, at most, three tokens (prefixes, lemma and suffixes). Moses was trained and optimized on segmented text. Note that when using segmented text for training, the output of the system is also segmented text. Real words are not available to the statistical decoder. This means that a generation postprocess (unsegmentation step) is needed to obtain real word forms. We incorporated a second language model (LM) based on real word forms to be used after the morphological postprocess. We implemented the word form-based LM by using an n-best list, as was done in Oflazer and El-Kahlout (2007). We first asked Moses to generate a translation candidate ranking based on the segmented training explained above. Next, these candidates were postprocessed. We then recalculated the total cost of each candidate by including the cost assigned by the new word form-based LM in the models used during decoding. Finally, the candidate list was re-ranked according to this new total cost. This somehow revises the candidate list to promote the ones that are more likely to be real word-form sequences. The weight for the word formbased LM was optimized at Minimum Error Rate Training (Och, 2003) togethe"
2014.amta-wptp.2,2011.eamt-1.2,0,0.0276549,"ifferently. Additionally, a preliminary analysis seems to suggest that familiarity with the domain, source text complexity and MT quality might affect potential productivity gain. 1. Introduction Thanks to the significant improvement of machine translation (MT) over the past two decades, the translation industry has already started to exploit it, mainly by combining it with post-editing. A good number of recent works report a productivity increase thanks to postediting of MT output as compared to the traditional human translation (e.g., Guerberof, 2009; Plitt and Masselot, 2010; Garcia, 2011; Pouliquen et al., 2011; Skadiņš et al., 2011; den Bogaert and Sutter, 2013; Green et al., 2013; Läubli et al., 2013). Most post-editing research is designed with professional translators in mind (even if often post-editors involved in experiments are non-professionals and students). However, it is not only language professionals who can benefit from MT in their daily tasks but also regular users who might need to perform a translation sporadically. In this work, we aim to compare the post-editing productivity between professional translators and lay users. We consider the regular example of professional translators"
2014.amta-wptp.2,2011.eamt-1.7,0,0.0545869,"Missing"
2014.amta-wptp.2,2013.mtsummit-user.12,0,0.0976866,"Missing"
2015.eamt-1.2,de-marneffe-etal-2006-generating,0,0.0611683,"Missing"
2015.eamt-1.2,W12-6212,1,0.848227,"forms, relative clauses, completives, conditionals and a number of adverbial clauses (time, place and reason). I drive my car to university every morning input pattern to verb transfer drive[VBP]+[subj1s][dObj3s][iObj00]+[paradigm2]+gidatu target pattern assigned by grammar gidatu{Asp}{Mod+Asp}{Aux}{Tense}{Subj}{dObj}{iObj} transformed pattern gidatu{IMPERF}{}{edun}{A1}{subj1s}{dObj3s} Nik nire autoa gidatzen dut unibertsitatera goizero. Figure 6: Dummy example of verb transfer steps. Verb transfer in the Matxin architecture is carried out using finite-state transducers (Alegria et al., 2005; Mayor et al., 2012). In short, the transducers take the source verb phrase as input, perform a number of replacements and create the final output which is ready for the syntactic and morphological generators to interpret. We kept the three-step organization of the grammar used in the original language pair. 1. Identification of the Basque verbal schema corresponding to the source verbal chunk. We use 21 patterns that we then unify into 5 general schemes corresponding to simple tenses (works, worked), compound tenses (have worked, will work), continuous tenses (is working, had been working), simple tenses precede"
2015.eamt-1.2,2009.eamt-1.9,1,0.895457,"Missing"
2015.eamt-1.2,2011.eamt-1.22,0,0.0708766,"Missing"
2015.eamt-1.2,E06-1032,0,0.0331929,"ceded by a modal (should work), and compound or continuous tenses preceded by a modal (must have worked). 3.3 Movements It is the flexibility to move information along the dependency tree-nodes that provides the Matxin architecture with the capacity to tackle dissimilar 2. Resolution of the values for the attributes in each of the Basque schemes. 7 human evaluation even when it is known that automatic scores tend to favor SMT systems over RBMT systems because they do not consider the correctness of the output but rather compare the difference between the output and the reference translations (Callison-Burch et al., 2006). And the use of a single reference accentuates this. To get a perspective on the overall performance, we ran the evaluation for two additional systems, an in-house statistical system, SMTs, and Google Translate, as well as Matxin ENEUS. Our SMT system was trained on a parallel corpus of 12 million Basque words and 14 million English words comprising user manuals, academic books and web data. We implemented a phrase-based system using Moses (Koehn et al., 2007). To better deal with the agglutinative nature of Basque, we trained the system on morpheme-level segmented data (Labaka, 2010). As a r"
2015.eamt-1.2,C02-1014,1,0.758963,"Missing"
2015.eamt-1.2,W07-0704,0,\N,Missing
2015.eamt-1.2,sangodkar-damani-2012-ordering,0,\N,Missing
2015.eamt-1.3,2011.eamt-1.28,0,0.0196105,"ut it has been progressively replaced by Statistical Machine Translation (SMT) since the 1990s (Hutchins, 2007). Example-Based Machine Translation (EBMT), the other main MT paradigm, has never attracted that much attention: even though it gives excellent results with repetitive text for which accurate matches are found in the parallel corpus, its quality quickly degrades as more generalization is needed. Nevertheless, it has been argued that, along with the raise of hybrid systems that try to combine multiple paradigms, EBMT can help to overcome some of the weaknesses of the other approaches (Dandapat et al., 2011)1 . c 2015 The authors. This article is licensed under a Creative Commons 3.0 licence, no derivative works, attribution, CCBY-ND. 1 This paper refers to as hybridization to any combination of MT paradigms, no matter if they are integrated in a single 11 In this paper, we propose one such system based on a multi-pass system combination: an EBMT preprocessor translates those fragments of the input text for which accurate matches are found in the parallel corpus, generating a high-quality partial translation that is then completed by the main translator, which can be either rule-based or statisti"
2015.eamt-1.3,W12-0106,0,0.0434817,"Missing"
2015.eamt-1.3,P07-1003,0,0.0209164,"sh, whereas we used Moses (Koehn et al., 2007) as our SMT engine for both language pairs. 4 Results and discussion This section presents the outcomes of the experiments described in Section 3. The results for the quality and coverage experiment are discussed in Section 4.1, and the RBMT and SMT hybridization in Sections 4.2 and 4.3. 4.1 Quality and coverage of EBMT Table 3 shows the number of tokens translated by the EBMT preprocessor according to each generalization mechanism. In the case of chunk generalization, we tried both GIZA++ and Berkeley aligner with and without syntactic tailoring (DeNero and Klein, 2007), which could presumably generate more chunk alignments that meet the restrictions of our translation process. However, contrary to our expectations syntactic tailoring gave the worst results by far both in terms of coverage and translation quality, apparently because it is still an experimental feature, and it was the default HMM mode of Berkeley Aligner which clearly outperformed the rest. We will consequently refer to the results obtained by this aligner in the remaining of this section. As we expected, Table 3 reflects that the cover15 age of the EBMT preprocessing clearly depends on the s"
2015.eamt-1.3,P98-1062,0,0.112629,"or. Two steps are required for this: the analysis step, presented in Section 2.1.1, and the alignment step, presented in Section 2.1.2. The resulting data is encoded in a custom binary format based on suffix arrays (Manber and Myers, 1990) for its efficient retrieval by the EBMT preprocessor. 2.1.1 Analysis The analysis step involves the tokenization, NE recognition and classification, lemmatization and parsing of each side of the parallel corpus. We have used Freeling (Padr´o and Stanilovsky, 2012) as our analyzer for Spanish, Stanford CoreNLP (Socher et al., 2013) for English and Eustagger (Ezeiza et al., 1998) for Basque, with a custom regex-based handling for numerals. The resulting constituency-based parse tree is simplified by removing inner nodes that correspond to part-ofspeech tags and representing NEs as single leaves. In the case of Basque, our analyzer is only capable of shallow parsing, so we have generated a dummy tree in which chunks are the only inner nodes. 2.1.2 Alignment The alignment step involves establishing the translation relationships among the tokens2 and NEs of the parallel corpus. This is done separately because the latter serves as the basis for NE generalization as discus"
2015.eamt-1.3,W05-0833,0,0.0265803,"hat do not. • Chunk generalization, giving the option to reuse examples in a subsentential level. Several other methods that combine EBMT and TM with other MT paradigms have been proposed in the literature. Koehn and Senellart (2010) use an SMT system to fill the mismatched parts from a fuzzy search in a TM. Similarly, Shirai et al. (1997) use a RBMT engine to complete the mismatched fragments from an EBMT system and smooth the resulting output using linguistic rules. On the other hand, Dandapat et al. (2012) integrate SMT phrase tables into an EBMT framework. Following the opposite approach, Groves and Way (2005) feed an SMT system with alignments obtained using EBMT techniques. S´anchez-Mart´ınez et al. (2009) use EBMT techniques to obtain bilingual chunks that are then integrated into a RBMT system. Lastly, Alegria et al. (2008) propose a multi-engine system that selects the best translation created by a RBMT, an SMT and an EBMT engine. However, to the best of our knowledge, the use of a generic multi-pass hybridization method for EBMT that works with both SMT and RBMT has never been reported so far. The remaining of this paper is structured as follows. The proposed method is presented in Section 2."
2015.eamt-1.3,2010.jec-1.4,0,0.0260355,"milar to those used by second and third generation TM systems (Gotti et al., 2005): • Named-entity (NE) generalization, giving the option to replace NEs like proper names and numerals in the parallel corpus with any other found in the text to translate. engine or not. However, some authors distinguish between hybridization for systems that meet this requirement and combination for systems that do not. • Chunk generalization, giving the option to reuse examples in a subsentential level. Several other methods that combine EBMT and TM with other MT paradigms have been proposed in the literature. Koehn and Senellart (2010) use an SMT system to fill the mismatched parts from a fuzzy search in a TM. Similarly, Shirai et al. (1997) use a RBMT engine to complete the mismatched fragments from an EBMT system and smooth the resulting output using linguistic rules. On the other hand, Dandapat et al. (2012) integrate SMT phrase tables into an EBMT framework. Following the opposite approach, Groves and Way (2005) feed an SMT system with alignments obtained using EBMT techniques. S´anchez-Mart´ınez et al. (2009) use EBMT techniques to obtain bilingual chunks that are then integrated into a RBMT system. Lastly, Alegria et"
2015.eamt-1.3,P07-2045,0,0.0122782,"Missing"
2015.eamt-1.3,N06-1014,0,0.0323184,"not enough evidence to do so. This way, word-alignment produces a set An for each nth sentence pair where (i, j) ∈ An if and only if there is a translation relationship between the ith token in the source language and the jth token in the target language, as well as the lexical weightings or translation probabilities in both directions, that is, a set of p(e|f ) and p(f |e) probabilities that express the likelihood of the f token to be translated as e and the e token to be translated as f , respectively. Our system has been integrated both with GIZA++ (Och and Ney, 2003) and Berkeley Aligner (Liang et al., 2006). As for NE alignment, we align NEs if and only if they have the same written form, are equivalent 2 We refer as tokens to the leaves of the parse tree obtained in the analysis phase, which implies that NEs are considered (multiword) tokens. numerals or are found in either of the following dictionaries: • A manually built dictionary, mostly consisting of translation relationships between proper names like countries. • An automatically generated dictionary from Wikipedia article titles with support for redirections. • An automatically generated dictionary from word-alignment, consisting of ever"
2015.eamt-1.3,J03-1002,0,0.00504898,"t aligning NEs in this level if there is not enough evidence to do so. This way, word-alignment produces a set An for each nth sentence pair where (i, j) ∈ An if and only if there is a translation relationship between the ith token in the source language and the jth token in the target language, as well as the lexical weightings or translation probabilities in both directions, that is, a set of p(e|f ) and p(f |e) probabilities that express the likelihood of the f token to be translated as e and the e token to be translated as f , respectively. Our system has been integrated both with GIZA++ (Och and Ney, 2003) and Berkeley Aligner (Liang et al., 2006). As for NE alignment, we align NEs if and only if they have the same written form, are equivalent 2 We refer as tokens to the leaves of the parse tree obtained in the analysis phase, which implies that NEs are considered (multiword) tokens. numerals or are found in either of the following dictionaries: • A manually built dictionary, mostly consisting of translation relationships between proper names like countries. • An automatically generated dictionary from Wikipedia article titles with support for redirections. • An automatically generated dictiona"
2015.eamt-1.3,padro-stanilovsky-2012-freeling,0,0.0223958,"Missing"
2015.eamt-1.3,P02-1040,0,0.0908721,"Missing"
2015.eamt-1.3,P13-1045,0,0.0514619,"arallel corpus to be used by the EBMT preprocessor. Two steps are required for this: the analysis step, presented in Section 2.1.1, and the alignment step, presented in Section 2.1.2. The resulting data is encoded in a custom binary format based on suffix arrays (Manber and Myers, 1990) for its efficient retrieval by the EBMT preprocessor. 2.1.1 Analysis The analysis step involves the tokenization, NE recognition and classification, lemmatization and parsing of each side of the parallel corpus. We have used Freeling (Padr´o and Stanilovsky, 2012) as our analyzer for Spanish, Stanford CoreNLP (Socher et al., 2013) for English and Eustagger (Ezeiza et al., 1998) for Basque, with a custom regex-based handling for numerals. The resulting constituency-based parse tree is simplified by removing inner nodes that correspond to part-ofspeech tags and representing NEs as single leaves. In the case of Basque, our analyzer is only capable of shallow parsing, so we have generated a dummy tree in which chunks are the only inner nodes. 2.1.2 Alignment The alignment step involves establishing the translation relationships among the tokens2 and NEs of the parallel corpus. This is done separately because the latter ser"
2020.acl-main.658,P19-1310,0,0.0576863,"Missing"
2020.acl-main.658,D18-1214,0,0.0511819,"Missing"
2020.acl-main.658,D18-1549,0,0.113759,"Missing"
2020.acl-main.658,2020.acl-main.421,1,0.822517,"RT (mBERT) has been shown to also be effective at learning cross-lingual representations in an unsupervised way.1 The main idea is to combine monolingual corpora in different languages, upsampling those with less data, and training a regular BERT model on the combined data. Conneau and Lample (2019) follow a similar approach but perform a more thorough evaluation and report substantially 1 https://github.com/google-research/ bert/blob/master/multilingual.md stronger results,2 which was further scaled up by Conneau et al. (2019). Several recent studies (Wu and Dredze, 2019; Pires et al., 2019; Artetxe et al., 2020b; Wu et al., 2019) analyze mBERT to get a better understanding of its capabilities. Unsupervised machine translation Early attempts to build machine translation systems using monolingual data alone go back to statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012, 2013). However, this approach was only shown to work in limited settings, and the first convincing results on standard benchmarks were achieved by Artetxe et al. (2018c) and Lample et al. (2018a) on unsupervised Neural Machine Translation (NMT). Both approaches rely on cross-lingual word embeddings to initialize a sha"
2020.acl-main.658,P18-1231,0,0.0275146,"named entities and frequent words, and have pervasive gaps in the gold-standard targets (Czarnowska et al., 2019; Kementchedjhieva et al., 2019). More generally, most of these datasets are limited to relatively close languages and comparable corpora. Lack of an established cross-lingual benchmark. At the same time, there is no de facto standard benchmark to evaluate cross-lingual models beyond translation. Existing approaches have been evaluated in a wide variety of tasks including dependency parsing (Schuster et al., 2019), named entity recognition (Rahimi et al., 2019), sentiment analysis (Barnes et al., 2018), natural language inference (Conneau et al., 2018b), and document classification (Schwenk and Li, 2018). XNLI (Conneau et al., 2018b) and MLDoc (Schwenk and Li, 2018) are common choices, but they have their own problems: MultiNLI, the dataset from which XNLI was derived, has been shown to contain superficial cues that can be exploited (Gururangan et al., 2018), while MLDoc can be solved by keyword matching (Artetxe et al., 2020b). There are nonEnglish counterparts for more challenging tasks such as question answering (Cui et al., 2019; Hsu et al., 2019), but these only exist for a handful of"
2020.acl-main.658,Q17-1010,0,0.0770184,"they assume document-level sequences (Conneau and Lample, 2019) or sentence-level sequences (Artetxe et al., 2018c; Lample et al., 2018a). Nature of atomic symbols. A more important consideration is the nature of the atomic symbols in such sequences. To the best of our knowledge, previous work assumes some form of word segmentation or tokenization (e.g., splitting by whitespaces or punctuation marks). Early work on cross-lingual word embeddings considered such tokens as atomic units. However, more recent work (Hoshen and Wolf, 2018; Glavaš et al., 2019) has primarily used fastText embeddings (Bojanowski et al., 2017) which incorporate subword information into the embedding learning, although the vocabulary is still defined at the token level. In addition, there have also been approaches that incorporate character-level information into the alignment learning itself (Heyman et al., 2017; Riley and Gildea, 2018). In contrast, most work on contextual word embeddings and unsupervised machine translation operates with a subword vocabulary (Devlin et al., 2019; Conneau and Lample, 2019). While the above distinction might seem irrelevant from a practical perspective, we think that it is important from a more fun"
2020.acl-main.658,buck-etal-2014-n,0,0.0197389,"Missing"
2020.acl-main.658,D18-1024,0,0.0275962,"s is acceptable and ultimately necessary for UCL. However, we believe that any connection stemming from a (partly) shared writing system belongs to a different category, and should be considered a separate cross-lingual signal. Our rationale is that a given writing system pertains to a specific form to encode a language, but cannot be considered to be part of the language itself.6 4.3 Multilinguality While most work in unsupervised cross-lingual learning considers two languages at a time, there have recently been some attempts to extend these methods to multiple languages (Duong et al., 2017; Chen and Cardie, 2018; Heyman et al., 2019), and most work on unsupervised cross-lingual pretraining is multilingual (Pires et al., 2019; Conneau 6 As a matter of fact, languages existed well before writing was invented, and a given language can have different writing systems or new ones can be designed. 7379 Monolingual signal Cross-lingual signal Sequence of symbols Sets of sentences/documents Tokens/subwords Linguistic analysis Shared writing system Identical words String similarity Table 1: Different types of monolingual and crosslingual signals that have been used for unsupervised cross-lingual learning, orde"
2020.acl-main.658,P17-1176,0,0.0594735,"s String similarity Table 1: Different types of monolingual and crosslingual signals that have been used for unsupervised cross-lingual learning, ordered roughly from least to most linguistic knowledge (top to bottom). and Lample, 2019). When considering parallel data across a subset of the language pairs, multilinguality gives rise to additional scenarios. For instance, the scenario where two languages have no parallel data between each other but are well connected through a third (pivot) language has been explored by several authors in the context of machine translation (Cheng et al., 2016; Chen et al., 2017). However, given that the languages in question are still indirectly connected through parallel data, this scenario does not fall within the unsupervised category, and is instead commonly known as zero-resource machine translation. An alternative scenario explored in the contemporaneous work of Liu et al. (2020) is where a set of languages are connected through parallel data, and there is a separate language with monolingual data only. We argue that, when it comes to the isolated language, such a scenario should still be considered as UCL, as it does not rely on any parallel data for that part"
2020.acl-main.658,D18-1269,0,0.171286,"unt of supervision required was greatly reduced via crosslingual word embedding mappings, which work by separately learning monolingual word embeddings in each language and mapping them into a shared space through a linear transformation. Early work required a bilingual dictionary to learn such a transformation (Mikolov et al., 2013a; Faruqui and Dyer, 2014). This requirement was later reduced with self-learning (Artetxe et al., 2017), and ultimately removed via unsupervised initialization heuristics (Artetxe et al., 2018a; Hoshen and Wolf, 2018) and adversarial learning (Zhang et al., 2017a; Conneau et al., 2018a). Finally, several recent methods have formulated cross-lingual embedding alignment as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2019; Alvarez-Melis and Jaakkola, 2018). 2.2 Deep multilingual pretraining Following the success in learning shallow word embeddings (Mikolov et al., 2013b; Pennington et al., 2014), there has been an increasing interest in learning contextual word representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018). Recent research has been dominated by BERT (Devlin et al., 2019), which uses a bidirectional transformer encoder tra"
2020.acl-main.658,D19-1169,0,0.021601,"recognition (Rahimi et al., 2019), sentiment analysis (Barnes et al., 2018), natural language inference (Conneau et al., 2018b), and document classification (Schwenk and Li, 2018). XNLI (Conneau et al., 2018b) and MLDoc (Schwenk and Li, 2018) are common choices, but they have their own problems: MultiNLI, the dataset from which XNLI was derived, has been shown to contain superficial cues that can be exploited (Gururangan et al., 2018), while MLDoc can be solved by keyword matching (Artetxe et al., 2020b). There are nonEnglish counterparts for more challenging tasks such as question answering (Cui et al., 2019; Hsu et al., 2019), but these only exist for a handful of languages. More recent datasets such as XQuAD 7381 Methodological issues Examples Validation and hyperparameter tuning Systematic tuning with parallel data or on test data Evaluation on favorable conditions Typologically similar languages; always including English; training on the same domain Over-reliance on translation tasks Overfitting to bilingual lexicon induction; known issues with existing datasets Lack of an established benchmark Evaluation on many different tasks; problems with common tasks (MLDoc and XNLI) Table 2: Methodolog"
2020.acl-main.658,D13-1173,0,0.0177374,"of tokenization. Such a tabula rasa approach is potentially applicable to any arbitrary language, even when its writing system is not known, but has so far only been explored for a limited number of languages in a monolingual setting (Hahn and Baroni, 2019). Linguistic information. Finally, one can exploit additional linguistic knowledge through linguistic analysis such as lemmatization, part-of-speech tagging, or syntactic parsing. For instance, before the advent of unsupervised NMT, statistical deci7378 pherment was already shown to benefit from incorporating syntactic dependency relations (Dou and Knight, 2013). For other tasks such as unsupervised POS tagging (Snyder et al., 2008), monolingual tag dictionaries have been used. While such approaches could still be considered unsupervised from a cross-lingual perspective, we argue that the interest of this research direction is greatly limited by two factors: (i) from a theoretical perspective, it assumes some fundamental knowledge that is not directly inferred from the raw monolingual corpora; and (ii) from a more practical perspective, it is not reasonable to assume that such resources are available in the less resourced settings where this research"
2020.acl-main.658,E17-1084,0,0.0251037,"inguistics universals is acceptable and ultimately necessary for UCL. However, we believe that any connection stemming from a (partly) shared writing system belongs to a different category, and should be considered a separate cross-lingual signal. Our rationale is that a given writing system pertains to a specific form to encode a language, but cannot be considered to be part of the language itself.6 4.3 Multilinguality While most work in unsupervised cross-lingual learning considers two languages at a time, there have recently been some attempts to extend these methods to multiple languages (Duong et al., 2017; Chen and Cardie, 2018; Heyman et al., 2019), and most work on unsupervised cross-lingual pretraining is multilingual (Pires et al., 2019; Conneau 6 As a matter of fact, languages existed well before writing was invented, and a given language can have different writing systems or new ones can be designed. 7379 Monolingual signal Cross-lingual signal Sequence of symbols Sets of sentences/documents Tokens/subwords Linguistic analysis Shared writing system Identical words String similarity Table 1: Different types of monolingual and crosslingual signals that have been used for unsupervised cross"
2020.acl-main.658,E14-1049,0,0.0301901,"deep multilingual pre-training (§2.2), and unsupervised machine translation (§2.3). 2.1 2.3 Cross-lingual word embeddings Cross-lingual word embedding methods traditionally relied on parallel corpora (Gouws et al., 2015; Luong et al., 2015). Nonetheless, the amount of supervision required was greatly reduced via crosslingual word embedding mappings, which work by separately learning monolingual word embeddings in each language and mapping them into a shared space through a linear transformation. Early work required a bilingual dictionary to learn such a transformation (Mikolov et al., 2013a; Faruqui and Dyer, 2014). This requirement was later reduced with self-learning (Artetxe et al., 2017), and ultimately removed via unsupervised initialization heuristics (Artetxe et al., 2018a; Hoshen and Wolf, 2018) and adversarial learning (Zhang et al., 2017a; Conneau et al., 2018a). Finally, several recent methods have formulated cross-lingual embedding alignment as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2019; Alvarez-Melis and Jaakkola, 2018). 2.2 Deep multilingual pretraining Following the success in learning shallow word embeddings (Mikolov et al., 2013b; Pennington et al., 2014), the"
2020.acl-main.658,P19-1070,1,0.884346,"Missing"
2020.acl-main.658,L18-1550,0,0.0236778,"s3 of which nearly half have less than 10,000 articles. While one could hope to overcome this by taking the entire web as a corpus, as facilitated by Common Crawl4 and similar initiatives, this is not 3 https://en.wikipedia.org/wiki/List_ of_Wikipedias 4 https://commoncrawl.org/ always feasible for low-resource languages. First, the presence of less resourced languages on the web is very limited, with only a few hundred languages recognized as being used in websites.5 This situation is further complicated by the limited coverage of existing tools such as language detectors (Buck et al., 2014; Grave et al., 2018), which only cover a few hundred languages. Alternatively, speech could also serve as a source of monolingual data (e.g., by recording public radio stations). However, this is an unexplored direction within UCL, and collecting, processing and effectively capitalizing on speech data is far from trivial, particularly for low-resource languages. All in all, we conclude that the alleged scenario involving no parallel data and sufficient monolingual data is not met in the real world in the terms explored by recent UCL research. Needless to say, effectively exploiting unlabeled data is important in"
2020.acl-main.658,N18-2017,0,0.0393367,"Missing"
2020.acl-main.658,D19-1632,0,0.14985,"ols in different languages to be disjoint, without prior knowledge of the relationship between them. Needless to say, any form of learning requires making assumptions, as one needs some criterion to prefer one mapping over another. In the case of UCL, such assumptions stem from the structural similarity across languages (e.g. semantically equivalent words in different languages are assumed to occur in similar contexts). In practice, these assumptions weaken as the distribution of the datasets diverges, and some UCL models have been reported to break under a domain shift (Søgaard et al., 2018; Guzmán et al., 2019; Marchisio et al., 2020). Similarly, approaches that leverage linguistic features such as syntactic dependencies may assume that these are similar across languages. In addition, one can also assume that the sets of symbols that are used to represent different languages have some commonalities. This departs from the strict definition of UCL above, establishing some prior connections between the sets of symbols in different languages. Such an assumption is reasonable from a practical perspective, as there are a few scripts (e.g. Latin, Arabic or Cyrillic) that cover a large fraction of language"
2020.acl-main.658,Q19-1033,0,0.0144797,"derlying assumptions might not generalize to different writing systems (e.g. logographic instead of alphabetic). For instance, subword tokenization has been shown to perform poorly on reduplicated words (Vania and Lopez, 2017). In relation to that, one could also consider the text in each language as a stream of discrete character-like symbols without any notion of tokenization. Such a tabula rasa approach is potentially applicable to any arbitrary language, even when its writing system is not known, but has so far only been explored for a limited number of languages in a monolingual setting (Hahn and Baroni, 2019). Linguistic information. Finally, one can exploit additional linguistic knowledge through linguistic analysis such as lemmatization, part-of-speech tagging, or syntactic parsing. For instance, before the advent of unsupervised NMT, statistical deci7378 pherment was already shown to benefit from incorporating syntactic dependency relations (Dou and Knight, 2013). For other tasks such as unsupervised POS tagging (Snyder et al., 2008), monolingual tag dictionaries have been used. While such approaches could still be considered unsupervised from a cross-lingual perspective, we argue that the inte"
2020.acl-main.658,N19-1188,0,0.0821336,"Missing"
2020.acl-main.658,E17-1102,0,0.0631211,"Missing"
2020.acl-main.658,D18-1043,0,0.121563,"corpora (Gouws et al., 2015; Luong et al., 2015). Nonetheless, the amount of supervision required was greatly reduced via crosslingual word embedding mappings, which work by separately learning monolingual word embeddings in each language and mapping them into a shared space through a linear transformation. Early work required a bilingual dictionary to learn such a transformation (Mikolov et al., 2013a; Faruqui and Dyer, 2014). This requirement was later reduced with self-learning (Artetxe et al., 2017), and ultimately removed via unsupervised initialization heuristics (Artetxe et al., 2018a; Hoshen and Wolf, 2018) and adversarial learning (Zhang et al., 2017a; Conneau et al., 2018a). Finally, several recent methods have formulated cross-lingual embedding alignment as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2019; Alvarez-Melis and Jaakkola, 2018). 2.2 Deep multilingual pretraining Following the success in learning shallow word embeddings (Mikolov et al., 2013b; Pennington et al., 2014), there has been an increasing interest in learning contextual word representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018). Recent research has been dominated by BERT (Devl"
2020.acl-main.658,P18-1031,1,0.811822,"initialization heuristics (Artetxe et al., 2018a; Hoshen and Wolf, 2018) and adversarial learning (Zhang et al., 2017a; Conneau et al., 2018a). Finally, several recent methods have formulated cross-lingual embedding alignment as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2019; Alvarez-Melis and Jaakkola, 2018). 2.2 Deep multilingual pretraining Following the success in learning shallow word embeddings (Mikolov et al., 2013b; Pennington et al., 2014), there has been an increasing interest in learning contextual word representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018). Recent research has been dominated by BERT (Devlin et al., 2019), which uses a bidirectional transformer encoder trained on masked language modeling and next sentence prediction, which led to impressive gains on various downstream tasks. While the above approaches are limited to a single language, a multilingual extension of BERT (mBERT) has been shown to also be effective at learning cross-lingual representations in an unsupervised way.1 The main idea is to combine monolingual corpora in different languages, upsampling those with less data, and training a regular BERT model on the combined"
2020.acl-main.658,D19-1607,0,0.0194325,"i et al., 2019), sentiment analysis (Barnes et al., 2018), natural language inference (Conneau et al., 2018b), and document classification (Schwenk and Li, 2018). XNLI (Conneau et al., 2018b) and MLDoc (Schwenk and Li, 2018) are common choices, but they have their own problems: MultiNLI, the dataset from which XNLI was derived, has been shown to contain superficial cues that can be exploited (Gururangan et al., 2018), while MLDoc can be solved by keyword matching (Artetxe et al., 2020b). There are nonEnglish counterparts for more challenging tasks such as question answering (Cui et al., 2019; Hsu et al., 2019), but these only exist for a handful of languages. More recent datasets such as XQuAD 7381 Methodological issues Examples Validation and hyperparameter tuning Systematic tuning with parallel data or on test data Evaluation on favorable conditions Typologically similar languages; always including English; training on the same domain Over-reliance on translation tasks Overfitting to bilingual lexicon induction; known issues with existing datasets Lack of an established benchmark Evaluation on many different tasks; problems with common tasks (MLDoc and XNLI) Table 2: Methodological issues pertain"
2020.acl-main.658,kamholz-etal-2014-panlex,0,0.0171766,"irs in the real world” (Xu et al., 2018) is largely inaccurate. For instance, the JW300 parallel corpus covers 343 languages with around 100,000 parallel sentences per language pair on average (Agi´c and Vuli´c, 2019), and the multilingual Bible corpus collected by Mayer and Cysouw (2014) covers 837 language varieties (each with a unique ISO 639-3 code). Moreover, the PanLex project aims to collect multilingual lexica for all human languages in the world, and already covers 6,854 language varieties with at least 20 lexemes, 2,364 with at least 200 lexemes, and 369 with at least 2,000 lexemes (Kamholz et al., 2014). While 20 or 200 lexemes might seem insufficient, weakly supervised cross-lingual word embedding methods already proved effective with as little as 25 word pairs (Artetxe et al., 2017). More recent methods have focused on completely removing this weak supervision (Conneau et al., 2018a; Artetxe et al., 2018a), which can hardly be justified from a practical perspective given the existence of such resources and additional training signals stemming from a (partially) shared script (§4.2). Finally, given the availability of sufficient monolingual data, noisy parallel data can often be obtained by"
2020.acl-main.658,D19-1328,0,0.0166423,"eam tasks. In particular, they observe that some mapping methods that are specifically designed for bilingual lexicon induction perform poorly on other tasks, showing the risk of relying excessively on translation benchmarks for evaluating cross-lingual models. Moreover, existing translation benchmarks have been shown to have several issues on their own. In particular, bilingual lexicon induction datasets have been reported to misrepresent morphological variations, overly focus on named entities and frequent words, and have pervasive gaps in the gold-standard targets (Czarnowska et al., 2019; Kementchedjhieva et al., 2019). More generally, most of these datasets are limited to relatively close languages and comparable corpora. Lack of an established cross-lingual benchmark. At the same time, there is no de facto standard benchmark to evaluate cross-lingual models beyond translation. Existing approaches have been evaluated in a wide variety of tasks including dependency parsing (Schuster et al., 2019), named entity recognition (Rahimi et al., 2019), sentiment analysis (Barnes et al., 2018), natural language inference (Conneau et al., 2018b), and document classification (Schwenk and Li, 2018). XNLI (Conneau et al"
2020.acl-main.658,J82-2005,0,0.68359,"Missing"
2020.acl-main.658,2020.tacl-1.47,0,0.107835,"ase-based Statistical Machine Translation (SMT), obtaining large improvements over the original NMT-based systems (Lample et al., 2018b; Artetxe et al., 2018b). This alternative approach uses cross-lingual n-gram embeddings to build an initial phrase table, which is combined with an n-gram language model and a distortion model, and further refined through iterative backtranslation. There have been several follow-up attempts to combine NMT and SMT based approaches (Marie and Fujita, 2018; Ren et al., 2019; Artetxe et al., 2019b). More recently, Conneau and Lample (2019), Song et al. (2019) and Liu et al. (2020) obtain strong results using deep multilingual pretraining rather than cross-lingual word embeddings to initialize unsupervised NMT systems. 3 Motivating fully unsupervised learning In this section, we challenge the narrative of motivating UCL based on a lack of parallel resources. We argue that the strict unsupervised scenario cannot be motivated from an immediate practical perspective, and elucidate what we believe should be the true goals of this research direction. 2 The full version of their model (XLM) requires parallel corpora for their translation language modeling objective, but the a"
2020.acl-main.658,W15-1521,0,0.0312387,"translation) in UCL (§6), and conclude with a summary of our recommendations (§7). 7375 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7375–7388 c July 5 - 10, 2020. 2020 Association for Computational Linguistics 2 Background In this section, we briefly review existing work on UCL, covering cross-lingual word embeddings (§2.1), deep multilingual pre-training (§2.2), and unsupervised machine translation (§2.3). 2.1 2.3 Cross-lingual word embeddings Cross-lingual word embedding methods traditionally relied on parallel corpora (Gouws et al., 2015; Luong et al., 2015). Nonetheless, the amount of supervision required was greatly reduced via crosslingual word embedding mappings, which work by separately learning monolingual word embeddings in each language and mapping them into a shared space through a linear transformation. Early work required a bilingual dictionary to learn such a transformation (Mikolov et al., 2013a; Faruqui and Dyer, 2014). This requirement was later reduced with self-learning (Artetxe et al., 2017), and ultimately removed via unsupervised initialization heuristics (Artetxe et al., 2018a; Hoshen and Wolf, 2018) and adversarial learning"
2020.acl-main.658,2020.wmt-1.68,0,0.0586124,"Missing"
2020.acl-main.658,D18-1399,1,0.927958,"ng autoencoding, backtranslation, and optionally adversarial learning. Subsequent work adapted these principles to unsupervised phrase-based Statistical Machine Translation (SMT), obtaining large improvements over the original NMT-based systems (Lample et al., 2018b; Artetxe et al., 2018b). This alternative approach uses cross-lingual n-gram embeddings to build an initial phrase table, which is combined with an n-gram language model and a distortion model, and further refined through iterative backtranslation. There have been several follow-up attempts to combine NMT and SMT based approaches (Marie and Fujita, 2018; Ren et al., 2019; Artetxe et al., 2019b). More recently, Conneau and Lample (2019), Song et al. (2019) and Liu et al. (2020) obtain strong results using deep multilingual pretraining rather than cross-lingual word embeddings to initialize unsupervised NMT systems. 3 Motivating fully unsupervised learning In this section, we challenge the narrative of motivating UCL based on a lack of parallel resources. We argue that the strict unsupervised scenario cannot be motivated from an immediate practical perspective, and elucidate what we believe should be the true goals of this research direction."
2020.acl-main.658,W19-5330,0,0.0262475,"optimal hyperparameter choice might not necessarily transfer well across languages. In contrast, Conneau et al. (2018a) and Lample et al. (2018a) propose an unsupervised validation criterion that is defined over monolingual data and shown to correlate well with test performance. This enables systematic tuning on the language pair of interest, but still requires parallel data to guide the development of the unsupervised validation criterion itself. A parallel validation set has also been used for systematic tuning in 7380 the context of unsupervised machine translation (Marie and Fujita, 2018; Marie et al., 2019; Stojanovski et al., 2019). While this is motivated as a way to abstract away the issue of unsupervised tuning—which the authors consider to be an open problem—we argue that any systematic use of parallel data should not be considered UCL. Finally, previous work often does not report the validation scheme used. In particular, unsupervised crosslingual word embedding methods have almost exclusively been evaluated on bilingual lexicons that do not have a validation set, and presumably use the test set to guide development to some extent. Our position is that a completely blind development model"
2020.acl-main.658,mayer-cysouw-2014-creating,0,0.0141436,"ual corpus. From this argument, it follows that monolingual data is cheaper to obtain than parallel data, so unsupervised crosslingual learning should in principle be more generally applicable than supervised learning. However, we argue that the common claim that the requirement for parallel data “may not be met for many language pairs in the real world” (Xu et al., 2018) is largely inaccurate. For instance, the JW300 parallel corpus covers 343 languages with around 100,000 parallel sentences per language pair on average (Agi´c and Vuli´c, 2019), and the multilingual Bible corpus collected by Mayer and Cysouw (2014) covers 837 language varieties (each with a unique ISO 639-3 code). Moreover, the PanLex project aims to collect multilingual lexica for all human languages in the world, and already covers 6,854 language varieties with at least 20 lexemes, 2,364 with at least 200 lexemes, and 369 with at least 2,000 lexemes (Kamholz et al., 2014). While 20 or 200 lexemes might seem insufficient, weakly supervised cross-lingual word embedding methods already proved effective with as little as 25 word pairs (Artetxe et al., 2017). More recent methods have focused on completely removing this weak supervision (Co"
2020.acl-main.658,D14-1162,0,0.0914393,"013a; Faruqui and Dyer, 2014). This requirement was later reduced with self-learning (Artetxe et al., 2017), and ultimately removed via unsupervised initialization heuristics (Artetxe et al., 2018a; Hoshen and Wolf, 2018) and adversarial learning (Zhang et al., 2017a; Conneau et al., 2018a). Finally, several recent methods have formulated cross-lingual embedding alignment as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2019; Alvarez-Melis and Jaakkola, 2018). 2.2 Deep multilingual pretraining Following the success in learning shallow word embeddings (Mikolov et al., 2013b; Pennington et al., 2014), there has been an increasing interest in learning contextual word representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018). Recent research has been dominated by BERT (Devlin et al., 2019), which uses a bidirectional transformer encoder trained on masked language modeling and next sentence prediction, which led to impressive gains on various downstream tasks. While the above approaches are limited to a single language, a multilingual extension of BERT (mBERT) has been shown to also be effective at learning cross-lingual representations in an unsupervised way.1 The main"
2020.acl-main.658,N18-1202,0,0.0160418,"oved via unsupervised initialization heuristics (Artetxe et al., 2018a; Hoshen and Wolf, 2018) and adversarial learning (Zhang et al., 2017a; Conneau et al., 2018a). Finally, several recent methods have formulated cross-lingual embedding alignment as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2019; Alvarez-Melis and Jaakkola, 2018). 2.2 Deep multilingual pretraining Following the success in learning shallow word embeddings (Mikolov et al., 2013b; Pennington et al., 2014), there has been an increasing interest in learning contextual word representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018). Recent research has been dominated by BERT (Devlin et al., 2019), which uses a bidirectional transformer encoder trained on masked language modeling and next sentence prediction, which led to impressive gains on various downstream tasks. While the above approaches are limited to a single language, a multilingual extension of BERT (mBERT) has been shown to also be effective at learning cross-lingual representations in an unsupervised way.1 The main idea is to combine monolingual corpora in different languages, upsampling those with less data, and training a regular BE"
2020.acl-main.658,P19-1493,0,0.0930796,"gual extension of BERT (mBERT) has been shown to also be effective at learning cross-lingual representations in an unsupervised way.1 The main idea is to combine monolingual corpora in different languages, upsampling those with less data, and training a regular BERT model on the combined data. Conneau and Lample (2019) follow a similar approach but perform a more thorough evaluation and report substantially 1 https://github.com/google-research/ bert/blob/master/multilingual.md stronger results,2 which was further scaled up by Conneau et al. (2019). Several recent studies (Wu and Dredze, 2019; Pires et al., 2019; Artetxe et al., 2020b; Wu et al., 2019) analyze mBERT to get a better understanding of its capabilities. Unsupervised machine translation Early attempts to build machine translation systems using monolingual data alone go back to statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012, 2013). However, this approach was only shown to work in limited settings, and the first convincing results on standard benchmarks were achieved by Artetxe et al. (2018c) and Lample et al. (2018a) on unsupervised Neural Machine Translation (NMT). Both approaches rely on cross-lingual word embeddin"
2020.acl-main.658,P19-1015,0,0.0363163,"morphological variations, overly focus on named entities and frequent words, and have pervasive gaps in the gold-standard targets (Czarnowska et al., 2019; Kementchedjhieva et al., 2019). More generally, most of these datasets are limited to relatively close languages and comparable corpora. Lack of an established cross-lingual benchmark. At the same time, there is no de facto standard benchmark to evaluate cross-lingual models beyond translation. Existing approaches have been evaluated in a wide variety of tasks including dependency parsing (Schuster et al., 2019), named entity recognition (Rahimi et al., 2019), sentiment analysis (Barnes et al., 2018), natural language inference (Conneau et al., 2018b), and document classification (Schwenk and Li, 2018). XNLI (Conneau et al., 2018b) and MLDoc (Schwenk and Li, 2018) are common choices, but they have their own problems: MultiNLI, the dataset from which XNLI was derived, has been shown to contain superficial cues that can be exploited (Gururangan et al., 2018), while MLDoc can be solved by keyword matching (Artetxe et al., 2020b). There are nonEnglish counterparts for more challenging tasks such as question answering (Cui et al., 2019; Hsu et al., 201"
2020.acl-main.658,P11-1002,0,0.0760115,"the combined data. Conneau and Lample (2019) follow a similar approach but perform a more thorough evaluation and report substantially 1 https://github.com/google-research/ bert/blob/master/multilingual.md stronger results,2 which was further scaled up by Conneau et al. (2019). Several recent studies (Wu and Dredze, 2019; Pires et al., 2019; Artetxe et al., 2020b; Wu et al., 2019) analyze mBERT to get a better understanding of its capabilities. Unsupervised machine translation Early attempts to build machine translation systems using monolingual data alone go back to statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012, 2013). However, this approach was only shown to work in limited settings, and the first convincing results on standard benchmarks were achieved by Artetxe et al. (2018c) and Lample et al. (2018a) on unsupervised Neural Machine Translation (NMT). Both approaches rely on cross-lingual word embeddings to initialize a shared encoder, and train it in conjunction with the decoder using a combination of denoising autoencoding, backtranslation, and optionally adversarial learning. Subsequent work adapted these principles to unsupervised phrase-based Statistical Machine Translat"
2020.acl-main.658,P18-2062,0,0.110805,"es some form of word segmentation or tokenization (e.g., splitting by whitespaces or punctuation marks). Early work on cross-lingual word embeddings considered such tokens as atomic units. However, more recent work (Hoshen and Wolf, 2018; Glavaš et al., 2019) has primarily used fastText embeddings (Bojanowski et al., 2017) which incorporate subword information into the embedding learning, although the vocabulary is still defined at the token level. In addition, there have also been approaches that incorporate character-level information into the alignment learning itself (Heyman et al., 2017; Riley and Gildea, 2018). In contrast, most work on contextual word embeddings and unsupervised machine translation operates with a subword vocabulary (Devlin et al., 2019; Conneau and Lample, 2019). While the above distinction might seem irrelevant from a practical perspective, we think that it is important from a more fundamental point of view (e.g. in relation to the distributional hypothesis as discussed in §3.2). Moreover, some of the underlying assumptions might not generalize to different writing systems (e.g. logographic instead of alphabetic). For instance, subword tokenization has been shown to perform poor"
2020.acl-main.658,D18-1042,1,0.810075,"h et al., 2017; Søgaard et al., 2018) or string-level similarity across languages (Riley and Gildea, 2018; Artetxe et al., 2019b) as training signals. Other methods use a joint subword vocabulary for all languages, indirectly exploiting the commonalities in their writing system (Lample et al., 2018b; Conneau and Lample, 2019). However, past work greatly differs on the nature and relevance that is attributed to such a training signal. The reliance on identically spelled words has been considered as a weak form of supervision in the cross-lingual word embedding literature (Søgaard et al., 2018; Ruder et al., 2018), and significant effort has been put into developing strictly unsupervised methods that do not rely on such signal (Conneau et al., 2018a). In contrast, the unsupervised machine translation literature has not payed much attention to this factor, and has often relied on identical words (Artetxe et al., 2018c), string-level similarity (Artetxe et al., 2019b), or a joint subword vocabulary (Lample et al., 2018b; Conneau and Lample, 2019) under the unsupervised umbrella. The same is true for unsupervised deep multilingual pretraining, where a shared subword vocabulary has been a common component"
2020.acl-main.658,N19-1162,0,0.0215779,"uction datasets have been reported to misrepresent morphological variations, overly focus on named entities and frequent words, and have pervasive gaps in the gold-standard targets (Czarnowska et al., 2019; Kementchedjhieva et al., 2019). More generally, most of these datasets are limited to relatively close languages and comparable corpora. Lack of an established cross-lingual benchmark. At the same time, there is no de facto standard benchmark to evaluate cross-lingual models beyond translation. Existing approaches have been evaluated in a wide variety of tasks including dependency parsing (Schuster et al., 2019), named entity recognition (Rahimi et al., 2019), sentiment analysis (Barnes et al., 2018), natural language inference (Conneau et al., 2018b), and document classification (Schwenk and Li, 2018). XNLI (Conneau et al., 2018b) and MLDoc (Schwenk and Li, 2018) are common choices, but they have their own problems: MultiNLI, the dataset from which XNLI was derived, has been shown to contain superficial cues that can be exploited (Gururangan et al., 2018), while MLDoc can be solved by keyword matching (Artetxe et al., 2020b). There are nonEnglish counterparts for more challenging tasks such as quest"
2020.acl-main.658,L18-1560,0,0.0284769,"al., 2019; Kementchedjhieva et al., 2019). More generally, most of these datasets are limited to relatively close languages and comparable corpora. Lack of an established cross-lingual benchmark. At the same time, there is no de facto standard benchmark to evaluate cross-lingual models beyond translation. Existing approaches have been evaluated in a wide variety of tasks including dependency parsing (Schuster et al., 2019), named entity recognition (Rahimi et al., 2019), sentiment analysis (Barnes et al., 2018), natural language inference (Conneau et al., 2018b), and document classification (Schwenk and Li, 2018). XNLI (Conneau et al., 2018b) and MLDoc (Schwenk and Li, 2018) are common choices, but they have their own problems: MultiNLI, the dataset from which XNLI was derived, has been shown to contain superficial cues that can be exploited (Gururangan et al., 2018), while MLDoc can be solved by keyword matching (Artetxe et al., 2020b). There are nonEnglish counterparts for more challenging tasks such as question answering (Cui et al., 2019; Hsu et al., 2019), but these only exist for a handful of languages. More recent datasets such as XQuAD 7381 Methodological issues Examples Validation and hyperpa"
2020.acl-main.658,D08-1109,0,0.0583697,"any arbitrary language, even when its writing system is not known, but has so far only been explored for a limited number of languages in a monolingual setting (Hahn and Baroni, 2019). Linguistic information. Finally, one can exploit additional linguistic knowledge through linguistic analysis such as lemmatization, part-of-speech tagging, or syntactic parsing. For instance, before the advent of unsupervised NMT, statistical deci7378 pherment was already shown to benefit from incorporating syntactic dependency relations (Dou and Knight, 2013). For other tasks such as unsupervised POS tagging (Snyder et al., 2008), monolingual tag dictionaries have been used. While such approaches could still be considered unsupervised from a cross-lingual perspective, we argue that the interest of this research direction is greatly limited by two factors: (i) from a theoretical perspective, it assumes some fundamental knowledge that is not directly inferred from the raw monolingual corpora; and (ii) from a more practical perspective, it is not reasonable to assume that such resources are available in the less resourced settings where this research direction has more potential for impact. 4.2 Cross-lingual training sig"
2020.acl-main.658,P18-1072,1,0.918484,"Missing"
2020.acl-main.658,W19-5344,0,0.0253622,"er choice might not necessarily transfer well across languages. In contrast, Conneau et al. (2018a) and Lample et al. (2018a) propose an unsupervised validation criterion that is defined over monolingual data and shown to correlate well with test performance. This enables systematic tuning on the language pair of interest, but still requires parallel data to guide the development of the unsupervised validation criterion itself. A parallel validation set has also been used for systematic tuning in 7380 the context of unsupervised machine translation (Marie and Fujita, 2018; Marie et al., 2019; Stojanovski et al., 2019). While this is motivated as a way to abstract away the issue of unsupervised tuning—which the authors consider to be an open problem—we argue that any systematic use of parallel data should not be considered UCL. Finally, previous work often does not report the validation scheme used. In particular, unsupervised crosslingual word embedding methods have almost exclusively been evaluated on bilingual lexicons that do not have a validation set, and presumably use the test set to guide development to some extent. Our position is that a completely blind development model without any parallel data"
2020.acl-main.658,P17-1184,0,0.022059,"n contextual word embeddings and unsupervised machine translation operates with a subword vocabulary (Devlin et al., 2019; Conneau and Lample, 2019). While the above distinction might seem irrelevant from a practical perspective, we think that it is important from a more fundamental point of view (e.g. in relation to the distributional hypothesis as discussed in §3.2). Moreover, some of the underlying assumptions might not generalize to different writing systems (e.g. logographic instead of alphabetic). For instance, subword tokenization has been shown to perform poorly on reduplicated words (Vania and Lopez, 2017). In relation to that, one could also consider the text in each language as a stream of discrete character-like symbols without any notion of tokenization. Such a tabula rasa approach is potentially applicable to any arbitrary language, even when its writing system is not known, but has so far only been explored for a limited number of languages in a monolingual setting (Hahn and Baroni, 2019). Linguistic information. Finally, one can exploit additional linguistic knowledge through linguistic analysis such as lemmatization, part-of-speech tagging, or syntactic parsing. For instance, before the"
2020.acl-main.658,D19-1449,0,0.0899592,"Missing"
2020.acl-main.658,P16-1024,0,0.106921,"Missing"
2020.acl-main.658,W18-5446,0,0.0677908,"Missing"
2020.acl-main.658,D19-1077,0,0.0171822,"language, a multilingual extension of BERT (mBERT) has been shown to also be effective at learning cross-lingual representations in an unsupervised way.1 The main idea is to combine monolingual corpora in different languages, upsampling those with less data, and training a regular BERT model on the combined data. Conneau and Lample (2019) follow a similar approach but perform a more thorough evaluation and report substantially 1 https://github.com/google-research/ bert/blob/master/multilingual.md stronger results,2 which was further scaled up by Conneau et al. (2019). Several recent studies (Wu and Dredze, 2019; Pires et al., 2019; Artetxe et al., 2020b; Wu et al., 2019) analyze mBERT to get a better understanding of its capabilities. Unsupervised machine translation Early attempts to build machine translation systems using monolingual data alone go back to statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012, 2013). However, this approach was only shown to work in limited settings, and the first convincing results on standard benchmarks were achieved by Artetxe et al. (2018c) and Lample et al. (2018a) on unsupervised Neural Machine Translation (NMT). Both approaches rely on cross-l"
2020.acl-main.658,D18-1268,0,0.0181008,"pervised variant using masked language modeling alone. 7376 3.1 How practical is the strict unsupervised scenario? Monolingual resources subsume parallel resources. For instance, each side of a parallel corpus effectively serves as a monolingual corpus. From this argument, it follows that monolingual data is cheaper to obtain than parallel data, so unsupervised crosslingual learning should in principle be more generally applicable than supervised learning. However, we argue that the common claim that the requirement for parallel data “may not be met for many language pairs in the real world” (Xu et al., 2018) is largely inaccurate. For instance, the JW300 parallel corpus covers 343 languages with around 100,000 parallel sentences per language pair on average (Agi´c and Vuli´c, 2019), and the multilingual Bible corpus collected by Mayer and Cysouw (2014) covers 837 language varieties (each with a unique ISO 639-3 code). Moreover, the PanLex project aims to collect multilingual lexica for all human languages in the world, and already covers 6,854 language varieties with at least 20 lexemes, 2,364 with at least 200 lexemes, and 369 with at least 2,000 lexemes (Kamholz et al., 2014). While 20 or 200 l"
2020.acl-main.658,P17-1179,0,0.199662,"include translation as well as pretraining multilingual representations. We will use the term interchangeably with “cross-lingual learning”. ∗ Equal contribution. Recent work in this direction has increasingly focused on purely unsupervised cross-lingual learning (UCL)—i.e., cross-lingual learning without any parallel signal across the languages. We provide an overview in §2. Such work has been motivated by the apparent dearth of parallel data for most of the world’s languages. In particular, previous work has noted that “data encoding cross-lingual equivalence is often expensive to obtain” (Zhang et al., 2017a) whereas “monolingual data is much easier to find” (Lample et al., 2018a). Overall, it has been argued that unsupervised cross-lingual learning “opens up opportunities for the processing of extremely low-resource languages and domains that lack parallel data completely” (Zhang et al., 2017a). We challenge this narrative and argue that the scenario of no parallel data and sufficient monolingual data is unrealistic and not reflected in the real world (§3.1). Nevertheless, UCL is an important research direction and we advocate for its study based on an inherent scientific interest (to better un"
2020.acl-main.658,D17-1207,0,0.119875,"include translation as well as pretraining multilingual representations. We will use the term interchangeably with “cross-lingual learning”. ∗ Equal contribution. Recent work in this direction has increasingly focused on purely unsupervised cross-lingual learning (UCL)—i.e., cross-lingual learning without any parallel signal across the languages. We provide an overview in §2. Such work has been motivated by the apparent dearth of parallel data for most of the world’s languages. In particular, previous work has noted that “data encoding cross-lingual equivalence is often expensive to obtain” (Zhang et al., 2017a) whereas “monolingual data is much easier to find” (Lample et al., 2018a). Overall, it has been argued that unsupervised cross-lingual learning “opens up opportunities for the processing of extremely low-resource languages and domains that lack parallel data completely” (Zhang et al., 2017a). We challenge this narrative and argue that the scenario of no parallel data and sufficient monolingual data is unrealistic and not reflected in the real world (§3.1). Nevertheless, UCL is an important research direction and we advocate for its study based on an inherent scientific interest (to better un"
2020.acl-main.658,D12-1025,0,\N,Missing
2020.acl-main.658,P17-1042,1,\N,Missing
2020.acl-main.658,P19-1494,1,\N,Missing
2020.acl-main.658,N19-1423,0,\N,Missing
2020.acl-main.658,D19-1090,1,\N,Missing
2020.acl-main.658,2020.emnlp-main.484,0,\N,Missing
2020.acl-main.658,2020.emnlp-main.618,1,\N,Missing
2020.acl-srw.34,P19-1309,1,0.667856,"ther language pairs. 1 Introduction Parallel corpora constitute an essential training data resource for machine translation as well as other cross-lingual NLP tasks. However, large parallel corpora are only available for a handful of language pairs while the rest relies on semi-supervised or unsupervised methods for training. Since monolingual data are generally more abundant, parallel sentence mining from non-parallel corpora provides another opportunity for low-resource language pairs. An effective approach to parallel data mining is based on multilingual sentence embeddings (Schwenk, 2018; Artetxe and Schwenk, 2019b). However, existing methods to generate crosslingual representations are either heavily supervised or only apply to static word embeddings. An alternative approach to unsupervised multilingual training is that of Devlin et al. (2018) or Lample and Conneau (2019), who train a masked language model (M-BERT, XLM) on a concatenation of monolingual corpora in different languages to learn a joint structure of these languages together. While several authors (Pires et al., 2019; Wu and Dredze, 2019; Karthikeyan et al., 2019; Libovick´y et al., 2019) bring evidence of cross-lingual transfer within th"
2020.acl-srw.34,Q19-1038,1,0.698776,"ther language pairs. 1 Introduction Parallel corpora constitute an essential training data resource for machine translation as well as other cross-lingual NLP tasks. However, large parallel corpora are only available for a handful of language pairs while the rest relies on semi-supervised or unsupervised methods for training. Since monolingual data are generally more abundant, parallel sentence mining from non-parallel corpora provides another opportunity for low-resource language pairs. An effective approach to parallel data mining is based on multilingual sentence embeddings (Schwenk, 2018; Artetxe and Schwenk, 2019b). However, existing methods to generate crosslingual representations are either heavily supervised or only apply to static word embeddings. An alternative approach to unsupervised multilingual training is that of Devlin et al. (2018) or Lample and Conneau (2019), who train a masked language model (M-BERT, XLM) on a concatenation of monolingual corpora in different languages to learn a joint structure of these languages together. While several authors (Pires et al., 2019; Wu and Dredze, 2019; Karthikeyan et al., 2019; Libovick´y et al., 2019) bring evidence of cross-lingual transfer within th"
2020.acl-srw.34,D18-2029,0,0.0564986,"Missing"
2020.acl-srw.34,W18-6317,0,0.025539,"rable Corpora 255 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 255–262 c July 5 - July 10, 2020. 2020 Association for Computational Linguistics et al. (2017) derive sentence embeddings from internal representations of a neural machine translation system with a shared encoder. The universal sentence encoder (USE) (Cer et al., 2018; Yang et al., 2019) family covers sentence embedding models with a multi-task dual-encoder training framework including the tasks of question-answer prediction or natural language inference. Guo et al. (2018) directly optimize the cosine similarity between the source and target sentences using a bidirectional dual-encoder. These approaches rely on heavy supervision by parallel corpora which is not available for low-resource languages. Unsupervised multilingual word embeddings. Cross-lingual embeddings of words can be obtained by post-hoc alignment of monolingual word embeddings (Mikolov et al., 2013) and mean-pooled with IDF weights to represent sentences (Litschko et al., 2019). Unsupervised techniques to find a linear mapping between embedding spaces were proposed by Artetxe et al. (2018) and Co"
2020.acl-srw.34,P19-1493,0,0.117045,"Missing"
2020.acl-srw.34,P19-1492,1,0.775032,"se approaches rely on heavy supervision by parallel corpora which is not available for low-resource languages. Unsupervised multilingual word embeddings. Cross-lingual embeddings of words can be obtained by post-hoc alignment of monolingual word embeddings (Mikolov et al., 2013) and mean-pooled with IDF weights to represent sentences (Litschko et al., 2019). Unsupervised techniques to find a linear mapping between embedding spaces were proposed by Artetxe et al. (2018) and Conneau et al. (2018), using iterative self-learning or adversarial training. Several recent studies (Patra et al., 2019; Ormazabal et al., 2019) criticize this simplified approach, showing that even the embedding spaces of closely related languages are not isometric. Vuli´c et al. (2019) question the robustness of unsupervised mapping methods in challenging circumstances. Cross-lingual LM pretraining. Ma et al. (2019); Reimers and Gurevych (2019) derive monolingual sentence embeddings by mean-pooling contextualized word embeddings from BERT. Schuster et al. (2019); Wang et al. (2019b) propose mapping such contextualized embeddings into the multilingual space and report favorable results on the task of dependency parsing. Pires et al."
2020.acl-srw.34,P19-1018,0,0.0258298,"al dual-encoder. These approaches rely on heavy supervision by parallel corpora which is not available for low-resource languages. Unsupervised multilingual word embeddings. Cross-lingual embeddings of words can be obtained by post-hoc alignment of monolingual word embeddings (Mikolov et al., 2013) and mean-pooled with IDF weights to represent sentences (Litschko et al., 2019). Unsupervised techniques to find a linear mapping between embedding spaces were proposed by Artetxe et al. (2018) and Conneau et al. (2018), using iterative self-learning or adversarial training. Several recent studies (Patra et al., 2019; Ormazabal et al., 2019) criticize this simplified approach, showing that even the embedding spaces of closely related languages are not isometric. Vuli´c et al. (2019) question the robustness of unsupervised mapping methods in challenging circumstances. Cross-lingual LM pretraining. Ma et al. (2019); Reimers and Gurevych (2019) derive monolingual sentence embeddings by mean-pooling contextualized word embeddings from BERT. Schuster et al. (2019); Wang et al. (2019b) propose mapping such contextualized embeddings into the multilingual space and report favorable results on the task of dependen"
2020.acl-srw.34,D19-1410,0,0.128866,"DF weights to represent sentences (Litschko et al., 2019). Unsupervised techniques to find a linear mapping between embedding spaces were proposed by Artetxe et al. (2018) and Conneau et al. (2018), using iterative self-learning or adversarial training. Several recent studies (Patra et al., 2019; Ormazabal et al., 2019) criticize this simplified approach, showing that even the embedding spaces of closely related languages are not isometric. Vuli´c et al. (2019) question the robustness of unsupervised mapping methods in challenging circumstances. Cross-lingual LM pretraining. Ma et al. (2019); Reimers and Gurevych (2019) derive monolingual sentence embeddings by mean-pooling contextualized word embeddings from BERT. Schuster et al. (2019); Wang et al. (2019b) propose mapping such contextualized embeddings into the multilingual space and report favorable results on the task of dependency parsing. Pires et al. (2019) extract contextualized embeddings directly from unsupervised multilingual LMs and use them for parallel sentence retrieval. Other authors improve the alignment of representations in a multilingual LM using a parallel corpus as an anchor (Cao et al., 2020) or using iterative self-learning (Wang et a"
2020.acl-srw.34,P19-1178,0,0.0378085,"Missing"
2020.acl-srw.34,N19-1162,0,0.0168312,"spaces were proposed by Artetxe et al. (2018) and Conneau et al. (2018), using iterative self-learning or adversarial training. Several recent studies (Patra et al., 2019; Ormazabal et al., 2019) criticize this simplified approach, showing that even the embedding spaces of closely related languages are not isometric. Vuli´c et al. (2019) question the robustness of unsupervised mapping methods in challenging circumstances. Cross-lingual LM pretraining. Ma et al. (2019); Reimers and Gurevych (2019) derive monolingual sentence embeddings by mean-pooling contextualized word embeddings from BERT. Schuster et al. (2019); Wang et al. (2019b) propose mapping such contextualized embeddings into the multilingual space and report favorable results on the task of dependency parsing. Pires et al. (2019) extract contextualized embeddings directly from unsupervised multilingual LMs and use them for parallel sentence retrieval. Other authors improve the alignment of representations in a multilingual LM using a parallel corpus as an anchor (Cao et al., 2020) or using iterative self-learning (Wang et al., 2019a). None of these works apply multilingual embeddings to mine parallel sentences. Our work is the first in impro"
2020.acl-srw.34,P18-2037,0,0.405792,"e results for other language pairs. 1 Introduction Parallel corpora constitute an essential training data resource for machine translation as well as other cross-lingual NLP tasks. However, large parallel corpora are only available for a handful of language pairs while the rest relies on semi-supervised or unsupervised methods for training. Since monolingual data are generally more abundant, parallel sentence mining from non-parallel corpora provides another opportunity for low-resource language pairs. An effective approach to parallel data mining is based on multilingual sentence embeddings (Schwenk, 2018; Artetxe and Schwenk, 2019b). However, existing methods to generate crosslingual representations are either heavily supervised or only apply to static word embeddings. An alternative approach to unsupervised multilingual training is that of Devlin et al. (2018) or Lample and Conneau (2019), who train a masked language model (M-BERT, XLM) on a concatenation of monolingual corpora in different languages to learn a joint structure of these languages together. While several authors (Pires et al., 2019; Wu and Dredze, 2019; Karthikeyan et al., 2019; Libovick´y et al., 2019) bring evidence of cross"
2020.acl-srw.34,W17-2619,0,0.0242961,"supervised methods to model multilingual sentence embeddings and unsupervised methods to model multilingual word embeddings which can be aggregated into sentences. Furthermore, our approach is closely related to the recent research in cross-lingual language model (LM) pretraining. Supervised multilingual sentence embeddings. The state-of-the-art performance in parallel data mining is achieved by LASER (Artetxe and Schwenk, 2019b) – a multilingual BiLSTM model sharing a single encoder for 93 languages trained on parallel corpora to produce language agnostic sentence representations. Similarly, Schwenk and Douze (2017); Schwenk (2018); Espana-Bonet 1 11th Workshop on Building and Using Comparable Corpora 255 Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 255–262 c July 5 - July 10, 2020. 2020 Association for Computational Linguistics et al. (2017) derive sentence embeddings from internal representations of a neural machine translation system with a shared encoder. The universal sentence encoder (USE) (Cer et al., 2018; Yang et al., 2019) family covers sentence embedding models with a multi-task dual-encoder training framework includi"
2020.acl-srw.34,P16-1162,0,0.0146403,"o the method remains unsupervised. In this section, we describe the pretrained model (Section 3.1), the fine-tuning objective (Section 3.2) and the extraction of sentence embeddings (Section 3.3). We provide details on the unsupervised MT system in Section 3.4. 3.1 XLM Pretraining The starting point for our experiments is a crosslingual language model (XLM) (Lample and Conneau, 2019) of the BERT family pretrained on concatenated monolingual texts in 100 languages using the masked language model (MLM) training objective (Devlin et al., 2018). The model processes the input in BPE subword units (Sennrich et al., 2016) with a shared vocabulary for all languages. In this work, we use the publicly available pretrained model XLM-1002 (Lample and Conneau, 2019) with 16 transformer layers, 16 attention heads and a hidden unit size of 1280. The model was trained on monolingual corpora in 100 languages with the BPE vocabulary of 240k subwords. 3.2 XLM Fine-tuning with a Translation Objective When parallel data is available, it can be leveraged in training of the multilingual language model using a translation language model loss (TLM) (Lample and Conneau, 2019). Pairs of sentences are concatenated, random tokens a"
2020.acl-srw.34,D19-1449,0,0.0533004,"Missing"
2020.acl-srw.34,D19-1575,0,0.0182848,"Artetxe et al. (2018) and Conneau et al. (2018), using iterative self-learning or adversarial training. Several recent studies (Patra et al., 2019; Ormazabal et al., 2019) criticize this simplified approach, showing that even the embedding spaces of closely related languages are not isometric. Vuli´c et al. (2019) question the robustness of unsupervised mapping methods in challenging circumstances. Cross-lingual LM pretraining. Ma et al. (2019); Reimers and Gurevych (2019) derive monolingual sentence embeddings by mean-pooling contextualized word embeddings from BERT. Schuster et al. (2019); Wang et al. (2019b) propose mapping such contextualized embeddings into the multilingual space and report favorable results on the task of dependency parsing. Pires et al. (2019) extract contextualized embeddings directly from unsupervised multilingual LMs and use them for parallel sentence retrieval. Other authors improve the alignment of representations in a multilingual LM using a parallel corpus as an anchor (Cao et al., 2020) or using iterative self-learning (Wang et al., 2019a). None of these works apply multilingual embeddings to mine parallel sentences. Our work is the first in improving unsupervised c"
2020.acl-srw.34,D19-1077,0,0.0143831,"ve approach to parallel data mining is based on multilingual sentence embeddings (Schwenk, 2018; Artetxe and Schwenk, 2019b). However, existing methods to generate crosslingual representations are either heavily supervised or only apply to static word embeddings. An alternative approach to unsupervised multilingual training is that of Devlin et al. (2018) or Lample and Conneau (2019), who train a masked language model (M-BERT, XLM) on a concatenation of monolingual corpora in different languages to learn a joint structure of these languages together. While several authors (Pires et al., 2019; Wu and Dredze, 2019; Karthikeyan et al., 2019; Libovick´y et al., 2019) bring evidence of cross-lingual transfer within the model, its internal representations are not entirely language agnostic. We propose a method to further align representations from such models into the cross-lingual space and use them to derive sentence embeddings. Our approach is completely unsupervised and is applicable even for very distant language pairs. The proposed method outperforms previous unsupervised approaches on the BUCC 20181 shared task, and is even competitive with several supervised baselines. The paper is organized as fol"
2020.acl-srw.34,W17-2512,0,0.0208881,"sentence mining task (News test set). The supervised and unsupervised winners are highlighted in bold. Artetxe and Schwenk (2019b) values obtained using the public implementation of the LASER toolkit. 4.4 Evaluation I: Parallel Corpus Mining We measure the performance of our method on the BUCC shared task of parallel corpus mining where the system is expected to search two comparable non-aligned corpora and identify pairs of parallel sentences. We evaluate on two data sets – the original BUCC 2018 corpus created by inserting parallel sentences into monolingual texts extracted from Wikipedia (Zweigenbaum et al., 2017) and a new BUCC-like data set (News train and test) which we created by shuffling 10k parallel sentence from News Commentary into 400k monolingual sentences from News Crawl. The BUCC and News data sets are comparable in size and contain parallel sentences from the same source, but differ in overall domain. In order to score all candidate sentence pairs, we use the margin-based approach of Artetxe and Schwenk (2019a) which was proved to eliminate the hubness problem of embedding spaces and yield superior results (Artetxe and Schwenk, 2019b). The score relies on cosine similarity to measure the"
2020.emnlp-main.618,2020.acl-main.421,1,0.946926,"ome previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively. 1 Introduction While most NLP resources are English-specific, there have been several recent efforts to build multilingual benchmarks. One possibility is to collect and annotate data in multiple languages separately (Clark et al., 2020), but most existing datasets have been created through translation (Conneau et al., 2018; Artetxe et al., 2020). This approach has two desirable properties: it relies on existing professional translation services rather than requiring expertise in multiple languages, and it results in parallel evaluation sets that offer a meaningful measure of the cross-lingual transfer gap of different models. The resulting multilingual datasets are generally used for evaluation only, relying on existing English datasets for training. Closely related to that, cross-lingual transfer learning aims to leverage large datasets available in one language—typically English—to build multilingual models that can generalize to o"
2020.emnlp-main.618,D15-1075,0,0.0417336,"for Question Answering (QA). A notable exception is TyDi QA (Clark et al., 2020), a contemporaneous QA dataset that was separately annotated in 11 languages. Other cross-lingual datasets leverage existing multilingual resources, as it is the case of MLDoc (Schwenk and Li, 2018) for document classification and Wikiann (Pan et al., 2017) for named entity recognition. Concurrent to our work, Hu et al. (2020) combine some of these datasets into a single multilingual benchmark, and evaluate some well-known methods on it. Annotation artifacts. Several studies have shown that NLI datasets like SNLI (Bowman et al., 2015) and MultiNLI (Williams et al., 2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al"
2020.emnlp-main.618,buck-etal-2014-n,0,0.150085,"Missing"
2020.emnlp-main.618,2020.lrec-1.677,0,0.0774837,"Missing"
2020.emnlp-main.618,2020.tacl-1.30,0,0.061861,"tly can reduce the lexical overlap between them, which current models are highly sensitive to. We show that some previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively. 1 Introduction While most NLP resources are English-specific, there have been several recent efforts to build multilingual benchmarks. One possibility is to collect and annotate data in multiple languages separately (Clark et al., 2020), but most existing datasets have been created through translation (Conneau et al., 2018; Artetxe et al., 2020). This approach has two desirable properties: it relies on existing professional translation services rather than requiring expertise in multiple languages, and it results in parallel evaluation sets that offer a meaningful measure of the cross-lingual transfer gap of different models. The resulting multilingual datasets are generally used for evaluation only, relying on existing English datasets for training. Closely related to that, cross-lingual transfer learning aims to leverage l"
2020.emnlp-main.618,2020.acl-main.747,0,0.0739969,"Missing"
2020.emnlp-main.618,D18-1269,0,0.390593,"ive to. We show that some previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively. 1 Introduction While most NLP resources are English-specific, there have been several recent efforts to build multilingual benchmarks. One possibility is to collect and annotate data in multiple languages separately (Clark et al., 2020), but most existing datasets have been created through translation (Conneau et al., 2018; Artetxe et al., 2020). This approach has two desirable properties: it relies on existing professional translation services rather than requiring expertise in multiple languages, and it results in parallel evaluation sets that offer a meaningful measure of the cross-lingual transfer gap of different models. The resulting multilingual datasets are generally used for evaluation only, relying on existing English datasets for training. Closely related to that, cross-lingual transfer learning aims to leverage large datasets available in one language—typically English—to build multilingual models t"
2020.emnlp-main.618,N19-1423,0,0.235386,"ffects the generalization ability of current models. Based on the gained insights, we improve the state-of-the-art in XNLI, and show that some previous findings need to be reconsidered in the light of this phenomenon. 2 Related work Cross-lingual transfer learning. Current crosslingual models work by pre-training multilingual representations using some form of language modeling, which are then fine-tuned on the relevant task and transferred to different languages. Some authors leverage parallel data to that end (Conneau and Lample, 2019; Huang et al., 2019), but training a model akin to BERT (Devlin et al., 2019) on the combination of monolingual corpora in multiple languages is also effective (Conneau et al., 2020). Closely related to our work, Singh et al. (2019) showed that replacing segments of the training data with their translation during fine-tuning is helpful. However, they attribute this behavior to a data augmentation effect, which we believe should be reconsidered given the new evidence we provide. Multilingual benchmarks. Most benchmarks covering a wide set of languages have been created through translation, as it is the case of XNLI (Conneau et al., 2018) for NLI, PAWS-X (Yang et al., 20"
2020.emnlp-main.618,N13-1073,0,0.0213103,"ed in English and translated into 6 other languages. In both cases, the translation was done by professional translators at the document level (i.e., when translating a question, the text answering it was also shown). For our BT-XX and MT-XX variants, we translate the context paragraph and the questions independently, and map the answer spans using the same procedure as Carrino et al. (2020).3 For the T RANSLATE -T EST approach, we use the official machine translated versions of MLQA, run inference over them, and map the predicted answer spans back to the target language.4 3 We use FastAlign (Dyer et al., 2013) for word alignment, and discard the few questions for which the mapping method fails (when none of the tokens in the answer span are aligned). 4 We use the same procedure as for the training set except that (i) given the small size of the test set, we combine it with WikiMatrix (Schwenk et al., 2019) to aid word alignment, (ii) we use Jieba for Chinese segmentation instead of the Moses tokenizer, and (iii) for the few unaligned spans, we return the English answer. 7676 Model Train en fr es de el bg ru tr ar vi th zh hi sw ur avg Test set machine translated into English (TRANSLATE-TEST) O RIG"
2020.emnlp-main.618,D18-1045,0,0.0203606,"v5.0 (Espl`a et al., 2019). For English-Finnish, we train for 40 epochs on Europarl and Wiki Titles from WMT 2019 (Barrault et al., 2019), ParaCrawl v5.0, and DGT, EUbookshop and TildeMODEL from OPUS (Tiedemann, 2012). In both cases, we remove sentences longer than 250 tokens, with a source/target ratio exceeding 1.5, or for which langid.py (Lui and Baldwin, 2012) predicts a different language, resulting in a final corpus size of 48M and 7M sentence pairs, respectively. We use sampling decoding with a temperature of 0.5 for inference, which produces more diverse translations than beam search (Edunov et al., 2018) and performed better in our preliminary experiments. 2 https://github.com/pytorch/fairseq 3.3 Tasks and evaluation procedure We use the following tasks for our experiments: Natural Language Inference (NLI). Given a premise and a hypothesis, the task is to determine whether there is an entailment, neutral or contradiction relation between them. We fine-tune our models on MultiNLI (Williams et al., 2018) for 10 epochs using the same settings as Liu et al. (2019). In most of our experiments, we evaluate on XNLI (Conneau et al., 2018), which comprises 2490 development and 5010 test instances in 1"
2020.emnlp-main.618,2020.acl-main.253,0,0.0311854,"h these artifacts in multilingual settings. Translationese. Translated texts are known to have unique features like simplification, explicitation, normalization and interference, which are refer to as translationese (Volansky et al., 2013). This phenomenon has been reported to have a notable impact in machine translation evaluation (Zhang and Toral, 2019; Graham et al., 2019). For instance, back-translation brings large BLEU gains for reversed test sets (i.e., when translationese is on the source side and original text is used as reference), but its effect diminishes in the natural direction (Edunov et al., 2020). While connected, the phenomenon we analyze is different in that it arises from translation inconsistencies due to the lack of context, and affects cross-lingual transfer learning rather than machine translation. 3 Experimental design Our goal is to analyze the effect of both human and machine translation in cross-lingual models. For that purpose, the core idea of our work is to (i) use machine translation to either translate the training set into other languages, or generate English paraphrases of it through back-translation, and (ii) evaluate the resulting systems on original, human transla"
2020.emnlp-main.618,W19-6721,0,0.0282282,"Missing"
2020.emnlp-main.618,P18-2103,0,0.0132646,"iNLI (Williams et al., 2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al., 2018; Glockner et al., 2018; Nie et al., 2020). Besides NLI, other tasks like QA have also been found to be susceptible to annotation artifacts (Jia and Liang, 2017; Kaushik and Lipton, 2018). While previous work has focused on the monolingual scenario, we show that translation can interfere with these artifacts in multilingual settings. Translationese. Translated texts are known to have unique features like simplification, explicitation, normalization and interference, which are refer to as translationese (Volansky et al., 2013). This phenomenon has been reported to have a notable impact in machine translation evaluati"
2020.emnlp-main.618,N18-2017,0,0.0579794,"Missing"
2020.emnlp-main.618,D17-1215,0,0.0280766,"ions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al., 2018; Glockner et al., 2018; Nie et al., 2020). Besides NLI, other tasks like QA have also been found to be susceptible to annotation artifacts (Jia and Liang, 2017; Kaushik and Lipton, 2018). While previous work has focused on the monolingual scenario, we show that translation can interfere with these artifacts in multilingual settings. Translationese. Translated texts are known to have unique features like simplification, explicitation, normalization and interference, which are refer to as translationese (Volansky et al., 2013). This phenomenon has been reported to have a notable impact in machine translation evaluation (Zhang and Toral, 2019; Graham et al., 2019). For instance, back-translation brings large BLEU gains for reversed test sets (i.e., whe"
2020.emnlp-main.618,D18-1546,0,0.0133113,"ururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al., 2018; Glockner et al., 2018; Nie et al., 2020). Besides NLI, other tasks like QA have also been found to be susceptible to annotation artifacts (Jia and Liang, 2017; Kaushik and Lipton, 2018). While previous work has focused on the monolingual scenario, we show that translation can interfere with these artifacts in multilingual settings. Translationese. Translated texts are known to have unique features like simplification, explicitation, normalization and interference, which are refer to as translationese (Volansky et al., 2013). This phenomenon has been reported to have a notable impact in machine translation evaluation (Zhang and Toral, 2019; Graham et al., 2019). For instance, back-translation brings large BLEU gains for reversed test sets (i.e., when translationese is on the"
2020.emnlp-main.618,D18-2012,0,0.0135019,"(BT-ES and BT-FI), and (iii) a machine translated version in Spanish or Finnish (MT-ES and MT-FI). For sentences occurring multiple times in the training set (e.g., premises repeated for multiple hypotheses), we use the exact same translation for all occurrences, as our goal is to understand the inherent effect of translation rather than its potential application as a data augmentation method. In order to train the machine translation systems for MT-XX and BT-XX, we use the big Transformer model (Vaswani et al., 2017) with the same settings as Ott et al. (2018) and SentencePiece tokenization (Kudo and Richardson, 2018) with a joint vocabulary of 32k subwords. For English-Spanish, we train for 10 epochs on all parallel data from WMT 2013 (Bojar et al., 2013) and ParaCrawl v5.0 (Espl`a et al., 2019). For English-Finnish, we train for 40 epochs on Europarl and Wiki Titles from WMT 2019 (Barrault et al., 2019), ParaCrawl v5.0, and DGT, EUbookshop and TildeMODEL from OPUS (Tiedemann, 2012). In both cases, we remove sentences longer than 250 tokens, with a source/target ratio exceeding 1.5, or for which langid.py (Lui and Baldwin, 2012) predicts a different language, resulting in a final corpus size of 48M and 7M"
2020.emnlp-main.618,2020.acl-main.653,0,0.456468,"u et al., 2020). Closely related to our work, Singh et al. (2019) showed that replacing segments of the training data with their translation during fine-tuning is helpful. However, they attribute this behavior to a data augmentation effect, which we believe should be reconsidered given the new evidence we provide. Multilingual benchmarks. Most benchmarks covering a wide set of languages have been created through translation, as it is the case of XNLI (Conneau et al., 2018) for NLI, PAWS-X (Yang et al., 2019) for adversarial paraphrase identification, and XQuAD (Artetxe et al., 2020) and MLQA (Lewis et al., 2020) for Question Answering (QA). A notable exception is TyDi QA (Clark et al., 2020), a contemporaneous QA dataset that was separately annotated in 11 languages. Other cross-lingual datasets leverage existing multilingual resources, as it is the case of MLDoc (Schwenk and Li, 2018) for document classification and Wikiann (Pan et al., 2017) for named entity recognition. Concurrent to our work, Hu et al. (2020) combine some of these datasets into a single multilingual benchmark, and evaluate some well-known methods on it. Annotation artifacts. Several studies have shown that NLI datasets like SNLI"
2020.emnlp-main.618,2021.ccl-1.108,0,0.119194,"Missing"
2020.emnlp-main.618,P12-3005,0,0.0226209,"th the same settings as Ott et al. (2018) and SentencePiece tokenization (Kudo and Richardson, 2018) with a joint vocabulary of 32k subwords. For English-Spanish, we train for 10 epochs on all parallel data from WMT 2013 (Bojar et al., 2013) and ParaCrawl v5.0 (Espl`a et al., 2019). For English-Finnish, we train for 40 epochs on Europarl and Wiki Titles from WMT 2019 (Barrault et al., 2019), ParaCrawl v5.0, and DGT, EUbookshop and TildeMODEL from OPUS (Tiedemann, 2012). In both cases, we remove sentences longer than 250 tokens, with a source/target ratio exceeding 1.5, or for which langid.py (Lui and Baldwin, 2012) predicts a different language, resulting in a final corpus size of 48M and 7M sentence pairs, respectively. We use sampling decoding with a temperature of 0.5 for inference, which produces more diverse translations than beam search (Edunov et al., 2018) and performed better in our preliminary experiments. 2 https://github.com/pytorch/fairseq 3.3 Tasks and evaluation procedure We use the following tasks for our experiments: Natural Language Inference (NLI). Given a premise and a hypothesis, the task is to determine whether there is an entailment, neutral or contradiction relation between them."
2020.emnlp-main.618,P19-1334,0,0.0178622,"rrent to our work, Hu et al. (2020) combine some of these datasets into a single multilingual benchmark, and evaluate some well-known methods on it. Annotation artifacts. Several studies have shown that NLI datasets like SNLI (Bowman et al., 2015) and MultiNLI (Williams et al., 2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al., 2018; Glockner et al., 2018; Nie et al., 2020). Besides NLI, other tasks like QA have also been found to be susceptible to annotation artifacts (Jia and Liang, 2017; Kaushik and Lipton, 2018). While previous work has focused on the monolingual scenario, we show that translation can interfere with these artifacts in multilingual settings. Translationese. Translated te"
2020.emnlp-main.618,C18-1198,0,0.0591891,"al., 2015) and MultiNLI (Williams et al., 2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al., 2018; Glockner et al., 2018; Nie et al., 2020). Besides NLI, other tasks like QA have also been found to be susceptible to annotation artifacts (Jia and Liang, 2017; Kaushik and Lipton, 2018). While previous work has focused on the monolingual scenario, we show that translation can interfere with these artifacts in multilingual settings. Translationese. Translated texts are known to have unique features like simplification, explicitation, normalization and interference, which are refer to as translationese (Volansky et al., 2013). This phenomenon has been reported to have a notable impact in machi"
2020.emnlp-main.618,2020.acl-main.441,0,0.0604596,"2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al., 2018; Glockner et al., 2018; Nie et al., 2020). Besides NLI, other tasks like QA have also been found to be susceptible to annotation artifacts (Jia and Liang, 2017; Kaushik and Lipton, 2018). While previous work has focused on the monolingual scenario, we show that translation can interfere with these artifacts in multilingual settings. Translationese. Translated texts are known to have unique features like simplification, explicitation, normalization and interference, which are refer to as translationese (Volansky et al., 2013). This phenomenon has been reported to have a notable impact in machine translation evaluation (Zhang and Toral"
2020.emnlp-main.618,W18-6301,0,0.0316787,"ack-translation using Spanish or Finnish as pivot (BT-ES and BT-FI), and (iii) a machine translated version in Spanish or Finnish (MT-ES and MT-FI). For sentences occurring multiple times in the training set (e.g., premises repeated for multiple hypotheses), we use the exact same translation for all occurrences, as our goal is to understand the inherent effect of translation rather than its potential application as a data augmentation method. In order to train the machine translation systems for MT-XX and BT-XX, we use the big Transformer model (Vaswani et al., 2017) with the same settings as Ott et al. (2018) and SentencePiece tokenization (Kudo and Richardson, 2018) with a joint vocabulary of 32k subwords. For English-Spanish, we train for 10 epochs on all parallel data from WMT 2013 (Bojar et al., 2013) and ParaCrawl v5.0 (Espl`a et al., 2019). For English-Finnish, we train for 40 epochs on Europarl and Wiki Titles from WMT 2019 (Barrault et al., 2019), ParaCrawl v5.0, and DGT, EUbookshop and TildeMODEL from OPUS (Tiedemann, 2012). In both cases, we remove sentences longer than 250 tokens, with a source/target ratio exceeding 1.5, or for which langid.py (Lui and Baldwin, 2012) predicts a differe"
2020.emnlp-main.618,P17-1178,0,0.0181614,"Most benchmarks covering a wide set of languages have been created through translation, as it is the case of XNLI (Conneau et al., 2018) for NLI, PAWS-X (Yang et al., 2019) for adversarial paraphrase identification, and XQuAD (Artetxe et al., 2020) and MLQA (Lewis et al., 2020) for Question Answering (QA). A notable exception is TyDi QA (Clark et al., 2020), a contemporaneous QA dataset that was separately annotated in 11 languages. Other cross-lingual datasets leverage existing multilingual resources, as it is the case of MLDoc (Schwenk and Li, 2018) for document classification and Wikiann (Pan et al., 2017) for named entity recognition. Concurrent to our work, Hu et al. (2020) combine some of these datasets into a single multilingual benchmark, and evaluate some well-known methods on it. Annotation artifacts. Several studies have shown that NLI datasets like SNLI (Bowman et al., 2015) and MultiNLI (Williams et al., 2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical cho"
2020.emnlp-main.618,S18-2023,0,0.0601046,"Missing"
2020.emnlp-main.618,D16-1264,0,0.0589293,"nstances in 15 languages. These were originally annotated in English, and the resulting premises and hypotheses were independently translated into the rest of the languages by professional translators. For the T RANSLATE -T EST approach, we use the machine translated versions from the authors. Following Conneau et al. (2020), we select the best epoch checkpoint according to the average accuracy in the development set. Question Answering (QA). Given a context paragraph and a question, the task is to identify the span answering the question in the context. We fine-tune our models on SQuAD v1.1 (Rajpurkar et al., 2016) for 2 epochs using the same settings as Liu et al. (2019), and report test results for the last epoch. We use two datasets for evaluation: XQuAD (Artetxe et al., 2020), a subset of the SQuAD development set translated into 10 other languages, and MLQA (Lewis et al., 2020) a dataset consisting of parallel context paragraphs plus the corresponding questions annotated in English and translated into 6 other languages. In both cases, the translation was done by professional translators at the document level (i.e., when translating a question, the text answering it was also shown). For our BT-XX an"
2020.emnlp-main.618,tiedemann-2012-parallel,0,0.0195398,"ation method. In order to train the machine translation systems for MT-XX and BT-XX, we use the big Transformer model (Vaswani et al., 2017) with the same settings as Ott et al. (2018) and SentencePiece tokenization (Kudo and Richardson, 2018) with a joint vocabulary of 32k subwords. For English-Spanish, we train for 10 epochs on all parallel data from WMT 2013 (Bojar et al., 2013) and ParaCrawl v5.0 (Espl`a et al., 2019). For English-Finnish, we train for 40 epochs on Europarl and Wiki Titles from WMT 2019 (Barrault et al., 2019), ParaCrawl v5.0, and DGT, EUbookshop and TildeMODEL from OPUS (Tiedemann, 2012). In both cases, we remove sentences longer than 250 tokens, with a source/target ratio exceeding 1.5, or for which langid.py (Lui and Baldwin, 2012) predicts a different language, resulting in a final corpus size of 48M and 7M sentence pairs, respectively. We use sampling decoding with a temperature of 0.5 for inference, which produces more diverse translations than beam search (Edunov et al., 2018) and performed better in our preliminary experiments. 2 https://github.com/pytorch/fairseq 3.3 Tasks and evaluation procedure We use the following tasks for our experiments: Natural Language Infere"
2020.emnlp-main.618,N18-1101,0,0.265601,"ble exception is TyDi QA (Clark et al., 2020), a contemporaneous QA dataset that was separately annotated in 11 languages. Other cross-lingual datasets leverage existing multilingual resources, as it is the case of MLDoc (Schwenk and Li, 2018) for document classification and Wikiann (Pan et al., 2017) for named entity recognition. Concurrent to our work, Hu et al. (2020) combine some of these datasets into a single multilingual benchmark, and evaluate some well-known methods on it. Annotation artifacts. Several studies have shown that NLI datasets like SNLI (Bowman et al., 2015) and MultiNLI (Williams et al., 2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline performs better than chance due to cues on their lexical choice and sentence length. Similarly, McCoy et al. (2019) showed that NLI models tend to predict entailment for sentence pairs with a high lexical overlap. Several authors have worked on adversarial datasets to diagnose these issues and provide a more challenging benchmark (Naik et al., 2018; Glockner et al., 2018; Nie e"
2020.emnlp-main.618,D19-1382,0,0.0655812,"n et al., 2019) on the combination of monolingual corpora in multiple languages is also effective (Conneau et al., 2020). Closely related to our work, Singh et al. (2019) showed that replacing segments of the training data with their translation during fine-tuning is helpful. However, they attribute this behavior to a data augmentation effect, which we believe should be reconsidered given the new evidence we provide. Multilingual benchmarks. Most benchmarks covering a wide set of languages have been created through translation, as it is the case of XNLI (Conneau et al., 2018) for NLI, PAWS-X (Yang et al., 2019) for adversarial paraphrase identification, and XQuAD (Artetxe et al., 2020) and MLQA (Lewis et al., 2020) for Question Answering (QA). A notable exception is TyDi QA (Clark et al., 2020), a contemporaneous QA dataset that was separately annotated in 11 languages. Other cross-lingual datasets leverage existing multilingual resources, as it is the case of MLDoc (Schwenk and Li, 2018) for document classification and Wikiann (Pan et al., 2017) for named entity recognition. Concurrent to our work, Hu et al. (2020) combine some of these datasets into a single multilingual benchmark, and evaluate so"
2020.emnlp-main.618,W19-5208,0,0.0387003,"e et al., 2020). Besides NLI, other tasks like QA have also been found to be susceptible to annotation artifacts (Jia and Liang, 2017; Kaushik and Lipton, 2018). While previous work has focused on the monolingual scenario, we show that translation can interfere with these artifacts in multilingual settings. Translationese. Translated texts are known to have unique features like simplification, explicitation, normalization and interference, which are refer to as translationese (Volansky et al., 2013). This phenomenon has been reported to have a notable impact in machine translation evaluation (Zhang and Toral, 2019; Graham et al., 2019). For instance, back-translation brings large BLEU gains for reversed test sets (i.e., when translationese is on the source side and original text is used as reference), but its effect diminishes in the natural direction (Edunov et al., 2020). While connected, the phenomenon we analyze is different in that it arises from translation inconsistencies due to the lack of context, and affects cross-lingual transfer learning rather than machine translation. 3 Experimental design Our goal is to analyze the effect of both human and machine translation in cross-lingual models. For"
2020.emnlp-main.618,L18-1560,0,0.0778383,"red given the new evidence we provide. Multilingual benchmarks. Most benchmarks covering a wide set of languages have been created through translation, as it is the case of XNLI (Conneau et al., 2018) for NLI, PAWS-X (Yang et al., 2019) for adversarial paraphrase identification, and XQuAD (Artetxe et al., 2020) and MLQA (Lewis et al., 2020) for Question Answering (QA). A notable exception is TyDi QA (Clark et al., 2020), a contemporaneous QA dataset that was separately annotated in 11 languages. Other cross-lingual datasets leverage existing multilingual resources, as it is the case of MLDoc (Schwenk and Li, 2018) for document classification and Wikiann (Pan et al., 2017) for named entity recognition. Concurrent to our work, Hu et al. (2020) combine some of these datasets into a single multilingual benchmark, and evaluate some well-known methods on it. Annotation artifacts. Several studies have shown that NLI datasets like SNLI (Bowman et al., 2015) and MultiNLI (Williams et al., 2018) contain spurious patterns that can be exploited to obtain strong results without making real inferential decisions. For instance, Gururangan et al. (2018) and Poliak et al. (2018) showed that a hypothesis-only baseline p"
2020.emnlp-main.618,P16-1009,0,0.0267267,"l models. In fact, the type of text a system is trained on does not typically match the type of text it is exposed to at test time: T RANSLATE -T EST systems are trained on original data and evaluated on machine translated test sets, Z ERO -S HOT systems are trained on original data and evaluated on human translated test sets, and T RANSLATE -T RAIN systems are trained on machine translated data and evaluated on human translated test sets. Despite overlooked to date, we show that such mismatch has a notable impact in the performance of existing cross-lingual models. By using back-translation (Sennrich et al., 2016) to paraphrase each training instance, we obtain another English version of the training set that better resembles the test set, obtaining substantial improvements for the T RANSLATE -T EST and Z ERO -S HOT approaches in cross-lingual Natural Language Inference (NLI). While improvements brought by machine translation have previously been attributed to data augmentation (Singh et al., 2019), we reject this hypothesis and show that the phenomenon is only present in translated test sets, but not in original ones. Instead, our analysis reveals that 1 We use the term original to refer to non-transl"
2020.emnlp-main.618,W13-2201,0,\N,Missing
2020.emnlp-main.618,W19-5301,0,\N,Missing
2020.wmt-1.96,W17-4715,0,0.0259726,"Missing"
2020.wmt-1.96,P19-1294,0,0.0250303,"ystems (same order as in Table 2). 7 Conclusion and future work In this work, we have presented a simple proposal using previously compiled corpora from the biomedical or clinical domain, as well as clinical terminology included directly to the training corpora. Apart from calculating BLEU scores, we have also calculated the average sentence length of the generated translations for en/es systems, and observed that the systems including terminologies performed generally worse than the baseline systems. As future work, we plan to incorporate these clinical terminologies in a more efficient way (Dinu et al., 2019; Wang et al., 2019). For improving both training and evaluation, we’ll also use bilingual clinical domain corpora being compiled now in collaboration with the Basque public health service (Osakidetza). Furthermore, since we have observed that some of the translations generated by the es-eu systems remain in Spanish, we’ll study techniques to leverage in-domain monolingual data in Basque like the one provided by the organisers from Wikipedia. Finally, we plan to keep reporting the consumed power and consequently generated CO2 emissions, probably making use of recently developed automatic tools"
2020.wmt-1.96,L16-1560,0,0.0597069,"Missing"
2020.wmt-1.96,P17-4012,0,0.0314254,"Soto et al. (2019b). 876 7 Due to privacy requirements, this corpus is not publicly available. Prior to use, it was de-identified by reordering sentences, and only authors who had previously signed a nondisclosure commitment had access to it. 8 https://lindat.mff.cuni.cz/ repository/xmlui/handle/11234/1-2122 Lang. System Baseline (Medline + TAUS) es-en Baseline + backtranslation (bt) Baseline + bt + terminologies Baseline (Medline + TAUS) en-es Baseline + forward translation (ft) Baseline + ft + terminologies All the systems are Transformer (Vaswani et al., 2017) models trained with OpenNMT (Klein et al., 2017), using the recommended hyperparameters.9 When necessary, we halved the batch-size so that it could fit in 2 GPUs, and accordingly doubled the value for gradient accumulation. We applied joint BPE-dropout (Provilkov et al., 2020), with 32,000 merge operations for en/es and 90,000 for es-eu. 5 Results Table 2 shows the BLEU scores of our systems on the validation (dev) and test sets presented in Table 1, together with previously published (es-eu) results for comparison. Lang. System Baseline (Medline + TAUS) es-en Baseline + backtranslation (bt) Baseline + bt + terminologies Baseline (Medline +"
2020.wmt-1.96,2020.acl-main.170,0,0.0113127,"had access to it. 8 https://lindat.mff.cuni.cz/ repository/xmlui/handle/11234/1-2122 Lang. System Baseline (Medline + TAUS) es-en Baseline + backtranslation (bt) Baseline + bt + terminologies Baseline (Medline + TAUS) en-es Baseline + forward translation (ft) Baseline + ft + terminologies All the systems are Transformer (Vaswani et al., 2017) models trained with OpenNMT (Klein et al., 2017), using the recommended hyperparameters.9 When necessary, we halved the batch-size so that it could fit in 2 GPUs, and accordingly doubled the value for gradient accumulation. We applied joint BPE-dropout (Provilkov et al., 2020), with 32,000 merge operations for en/es and 90,000 for es-eu. 5 Results Table 2 shows the BLEU scores of our systems on the validation (dev) and test sets presented in Table 1, together with previously published (es-eu) results for comparison. Lang. System Baseline (Medline + TAUS) es-en Baseline + backtranslation (bt) Baseline + bt + terminologies Baseline (Medline + TAUS) en-es Baseline + forward translation (ft) Baseline + ft + terminologies Soto et al. (2019a) es-eu Soto et al. (2019b) This work dev 56.57 61.60 60.95 48.02 50.20 49.92 11.30 11.85 6.21 test 52.55 57.25 56.89 46.30 47.19 47"
2020.wmt-1.96,P16-1009,0,0.0214011,"nish into Catalan (es-ca). This technique is useful when there are more bilingual in-domain sentences for each of the language pairs (en/es and es/ca) than for the desired source and target languages (en/ca). Since there are low resources for en/eu biomedical domain, but we have access to many resources for en/es and es/eu in the biomedical or clinical domain, we follow the same approach for translating the test sets from English into Basque (en-eu). Since most of the available in-domain corpus is monolingual, we also make use of traditional backtranslation and forward translation techniques (Sennrich et al., 2016). In our previous work for translating clinical texts between Basque and Spanish, we showed that including clinical terminologies directly into the training corpus was useful for domain adaptation when no bilingual in-domain sentences were available (Soto et al., 2019a). As clinical terminologies, we refer to the automatic translation into Basque of SNOMED CT (IHTSDO, 2014), which is considered the most comprehensive, multilingual clinical health care terminology collection in the world. In this work, we extend the number of clinical terminologies as part of the ongoing translation of SNOMED C"
2020.wmt-1.96,W19-7102,1,0.826571,"Missing"
2020.wmt-1.96,2020.nlpcovid19-acl.1,0,0.0164664,"0 Association for Computational Linguistics 2017), and include the provided ICD-10 resources plus other smaller terminology collections recently created for translating Covid-19 related texts. 3 Resources For training our baseline en/es systems, we make use of the Medline corpus provided by the organisers of the WMT20 Biomedical shared task, as well as the recently compiled TAUS Corona Crisis Corpus.1 For backtranslation (es-en) and forward translation (en-es), we use the English corpus prepared by Sketch Engine2 , based on the Covid-19 related corpus compiled for a recent Kaggle competition (Wang et al., 2020). As a final step, we include several clinical terminologies: 1) the ICD-10 (en-eu) corpus provided by the organisers of the WMT20 Biomedical shared task, adding the corresponding Spanish counterparts; 2) terms obtained from the automatic translation into Basque of SNOMED CT (Perez-deVi˜naspre, 2017), including terms up to 11 tokens; 3) a recent SNOMED CT interim release of Covid-19 related terms3 , manually translated into Basque by a translator of the Basque public health service (Osakidetza); and 4) a collection of Covid-19 related terms recently compiled by Elhuyar4 , including all the ter"
2021.acl-long.506,D18-1214,0,0.0326137,"Missing"
2021.acl-long.506,P17-1042,1,0.796074,"g maps that are only locally linear (Nakashole, 2018), or learning a separate map for each word (Glavaˇs and Vuli´c, 2020). However, all these methods are supervised, and have the same fundamental limitation of aligning a set of separately trained embeddings (Ormazabal et al., 2019). Self-learning. While early mapping methods relied on a bilingual dictionary to learn the alignment, this requirement was alleviated thanks to selflearning, which iteratively re-induces the dictionary during training. This enabled learning CLWEs in a semi-supervised fashion starting from a weak initial dictionary (Artetxe et al., 2017), or in a completely unsupervised manner when combined with adversarial training (Conneau et al., 2018a) or initialization heuristics (Artetxe et al., 2018; Hoshen and Wolf, 2018). Our proposed method also incorporates a self-learning procedure, showing that this technique can also be effective with non-mapping methods. Joint CLWE methods. Before the popularization of offline mapping, most CLWE methods extended monolingual embedding algorithms by either incorporating an explicit cross-lingual term in their learning objective, or directly replacing words with their translation equivalents in th"
2021.acl-long.506,P18-1073,1,0.87472,"present words from two or more languages in a shared space, so that semantically similar words in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora (Luong et al., 2015; Gouws et al., 2015) or bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016). However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hindering the performance of these methods (Søgaard et al., 2018; Nakashole and Flauger, 2018; Patra et al., 2019). In later work, Ormazabal et al. (2019) showed that this issue arises from trying to align separately trained e"
2021.acl-long.506,P19-1494,1,0.850814,"nitial dictionary has a negligible impact in the performance of our proposed method, which supports the idea that our approach converges to a similar solution given any reasonable initialization. We report our XNLI results in Table 5. We observe that our method is competitive with the baseline 5.3 Ablation study 12 In particular, most mapping methods use the official Wikipedia embeddings from fastText. Unfortunately, the preprocessed corpus used to train these embeddings is not public, so works that explore other approaches, like ours, need to use their own pre-processed copy of Wikipedia. 13 Artetxe et al. (2019) report even stronger results based on unsupervised machine translation instead of direct retrieval with CLWEs. Note, however, that their method still relies on cross-lingual embeddings to build the underlying phrase-table, so our improvements should be largely orthogonal to theirs. So as to understand the role of self-learning and the iterative restarts in our approach, we perform an ablation study and report our results in Table 6. We observe that the contribution of these components is greatly dependant on the initial dictionary. For the numeral initialization, the basic method works poorly"
2021.acl-long.506,2020.acl-main.421,1,0.777019,"pervision, ranging from bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016) to parallel or documentaligned corpora (Luong et al., 2015; Gouws et al., 2015; Vuli´c and Moens, 2016). More recently, Lample et al. (2018) reported positive results learning regular word embeddings over concatenated monolingual corpora in different languages, relying on identical words as anchor points. Wang et al. (2019) further improved this approach by applying a conventional mapping method afterwards. As shown later in our experiments, our approach outperforms theirs by a large margin. Freezing. Artetxe et al. (2020) showed that it is possible to transfer an English transformer to a new language by freezing all the inner parameters of the network and learning a new set of embeddings for the new language through masked language modeling. This works because the frozen transformer parameters constrain the resulting representations to be aligned with English. Similarly, our proposed approach uses frozen output vectors in the target language as anchor points to learn aligned embeddings in the source language. 3 Proposed method Let xi and x ˜i be the input and output vectors of the ith word in the source langua"
2021.acl-long.506,Q17-1010,0,0.0500202,"fer learning on XNLI. 6479 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6479–6489 August 1–6, 2021. ©2021 Association for Computational Linguistics 2 Related work Word embeddings. Embedding methods learn static word representations based on co-occurrence statistics from a corpus. Most approaches use two different matrices to represent the words and the contexts, which are known as the input and output vectors, respectively (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017). The output vectors play an auxiliary role, being discarded after training. Our method takes advantage of this fact, leveraging translated output vectors as anchor points to learn cross-lingual embeddings. To that end, we build on the Skip-Gram with Negative Sampling (SGNS) algorithm (Mikolov et al., 2013), which trains a binary classifier to distinguish whether each output word co-occurs with the given input word in the training corpus or was instead sampled from a noise distribution. Mapping CLWE methods. Offline mapping methods separately train word embeddings for each language, and then l"
2021.acl-long.506,D18-1269,0,0.300463,"ords in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora (Luong et al., 2015; Gouws et al., 2015) or bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016). However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hindering the performance of these methods (Søgaard et al., 2018; Nakashole and Flauger, 2018; Patra et al., 2019). In later work, Ormazabal et al. (2019) showed that this issue arises from trying to align separately trained embeddings, as joint learning methods are not susceptible to it. In this paper, we propose"
2021.acl-long.506,D16-1136,0,0.0852078,"initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task. 1 Introduction Cross-lingual word embeddings (CLWEs) represent words from two or more languages in a shared space, so that semantically similar words in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora (Luong et al., 2015; Gouws et al., 2015) or bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016). However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hi"
2021.acl-long.506,P19-1070,0,0.0240521,"Missing"
2021.acl-long.506,2020.acl-main.675,0,0.0486004,"Missing"
2021.acl-long.506,N15-1157,0,0.0889411,"uce the dependency on the initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task. 1 Introduction Cross-lingual word embeddings (CLWEs) represent words from two or more languages in a shared space, so that semantically similar words in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora (Luong et al., 2015; Gouws et al., 2015) or bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016). However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not genera"
2021.acl-long.506,D18-1043,0,0.290726,"or more languages in a shared space, so that semantically similar words in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora (Luong et al., 2015; Gouws et al., 2015) or bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016). However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hindering the performance of these methods (Søgaard et al., 2018; Nakashole and Flauger, 2018; Patra et al., 2019). In later work, Ormazabal et al. (2019) showed that this issue arises from trying to align separately trained embeddings, as joint lear"
2021.acl-long.506,D19-1328,0,0.0119385,"ping systems. We complement these results with additional experiments on a downstream task, where our method obtains competitive results, as well as an ablation study and a systematic error analysis. We identify a striking tendency of our method to translate words identically, even if it has no notion of the words being identically spelled. Thanks to this, our method is particularly strong at translating named entities, but we show that our improvements are not limited to this phenomenon. These insights confirm the value of accompanying quantitative results on BLI with qualitative evaluation (Kementchedjhieva et al., 2019) and/or other tasks (Glavaˇs et al., 2019). 6486 In the future, we would like to further explore CLWE methods that go beyond the currently dominant mapping paradigm. In particular, we would like to remove the requirement of a seed dictionary altogether by using adversarial learning, and explore more elaborated context translation and dictionary re-induction schemes. Acknowledgments Aitor Ormazabal, Aitor Soroa, Gorka Labaka and Eneko Agirre were supported by the Basque Government (excellence research group IT1343-19 and DeepText project KK-2020/00088), project BigKnowledge (Ayudas Fundaci´on B"
2021.acl-long.506,J82-2005,0,0.601739,"Missing"
2021.acl-long.506,2020.coling-main.526,0,0.044508,"Missing"
2021.acl-long.506,W15-1521,0,0.164949,"oints, and incorporates self-learning and iterative restarts to reduce the dependency on the initial dictionary. Our approach outperforms conventional mapping methods on bilingual lexicon induction, and obtains competitive results in the downstream XNLI task. 1 Introduction Cross-lingual word embeddings (CLWEs) represent words from two or more languages in a shared space, so that semantically similar words in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora (Luong et al., 2015; Gouws et al., 2015) or bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016). However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assump"
2021.acl-long.506,2020.emnlp-main.215,0,0.0175638,"ds separately train word embeddings for each language, and then learn a mapping to align them into a shared space. Most of these methods align the embeddings through a linear map—often enforcing orthogonality constraints—and, as such, they rely on the assumption that the geometric structure of the separately learned embeddings is similar. This assumption has been shown to fail under unfavorable conditions, severely hindering the performance of these methods (Søgaard et al., 2018; Vuli´c et al., 2020). Existing attempts to mitigate this issue include learning non-linear maps in a latent space (Mohiuddin et al., 2020), employing maps that are only locally linear (Nakashole, 2018), or learning a separate map for each word (Glavaˇs and Vuli´c, 2020). However, all these methods are supervised, and have the same fundamental limitation of aligning a set of separately trained embeddings (Ormazabal et al., 2019). Self-learning. While early mapping methods relied on a bilingual dictionary to learn the alignment, this requirement was alleviated thanks to selflearning, which iteratively re-induces the dictionary during training. This enabled learning CLWEs in a semi-supervised fashion starting from a weak initial di"
2021.acl-long.506,D18-1063,0,0.0500434,"Missing"
2021.acl-long.506,D18-1047,0,0.0161733,"a mapping to align them into a shared space. Most of these methods align the embeddings through a linear map—often enforcing orthogonality constraints—and, as such, they rely on the assumption that the geometric structure of the separately learned embeddings is similar. This assumption has been shown to fail under unfavorable conditions, severely hindering the performance of these methods (Søgaard et al., 2018; Vuli´c et al., 2020). Existing attempts to mitigate this issue include learning non-linear maps in a latent space (Mohiuddin et al., 2020), employing maps that are only locally linear (Nakashole, 2018), or learning a separate map for each word (Glavaˇs and Vuli´c, 2020). However, all these methods are supervised, and have the same fundamental limitation of aligning a set of separately trained embeddings (Ormazabal et al., 2019). Self-learning. While early mapping methods relied on a bilingual dictionary to learn the alignment, this requirement was alleviated thanks to selflearning, which iteratively re-induces the dictionary during training. This enabled learning CLWEs in a semi-supervised fashion starting from a weak initial dictionary (Artetxe et al., 2017), or in a completely unsupervise"
2021.acl-long.506,P18-2036,0,0.0134589,"ping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hindering the performance of these methods (Søgaard et al., 2018; Nakashole and Flauger, 2018; Patra et al., 2019). In later work, Ormazabal et al. (2019) showed that this issue arises from trying to align separately trained embeddings, as joint learning methods are not susceptible to it. In this paper, we propose an alternative approach that does not have this limitation, but can still work without any parallel resources. The core idea of our method is to fix the target language embeddings, and learn aligned embeddings for the source language from scratch. This prevents structural mismatches that result from independently training embeddings in different languages, as the learning of"
2021.acl-long.506,P19-1492,1,0.897614,"languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hindering the performance of these methods (Søgaard et al., 2018; Nakashole and Flauger, 2018; Patra et al., 2019). In later work, Ormazabal et al. (2019) showed that this issue arises from trying to align separately trained embeddings, as joint learning methods are not susceptible to it. In this paper, we propose an alternative approach that does not have this limitation, but can still work without any parallel resources. The core idea of our method is to fix the target language embeddings, and learn aligned embeddings for the source language from scratch. This prevents structural mismatches that result from independently training embeddings in different languages, as the learning of the source embeddings is tailored to each particular set of"
2021.acl-long.506,D14-1162,0,0.0995886,"o-shot crosslingual transfer learning on XNLI. 6479 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6479–6489 August 1–6, 2021. ©2021 Association for Computational Linguistics 2 Related work Word embeddings. Embedding methods learn static word representations based on co-occurrence statistics from a corpus. Most approaches use two different matrices to represent the words and the contexts, which are known as the input and output vectors, respectively (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017). The output vectors play an auxiliary role, being discarded after training. Our method takes advantage of this fact, leveraging translated output vectors as anchor points to learn cross-lingual embeddings. To that end, we build on the Skip-Gram with Negative Sampling (SGNS) algorithm (Mikolov et al., 2013), which trains a binary classifier to distinguish whether each output word co-occurs with the given input word in the training corpus or was instead sampled from a noise distribution. Mapping CLWE methods. Offline mapping methods separately train word embeddings for"
2021.acl-long.506,P18-1072,0,0.0395946,"Missing"
2021.acl-long.506,2020.emnlp-main.257,0,0.0204108,"Missing"
2021.acl-long.506,N18-1101,0,0.0117864,"ction (BLI) and Cross-lingual Natural Language Inference (XNLI). BLI. Following common practice, we induce a bilingual dictionary through CSLS retrieval (Conneau et al., 2018a) for each set of cross-lingual embeddings, and evaluate the precision at 1 (P@1) with respect to the gold standard test dictionary from the MUSE dataset (Conneau et al., 2018a). For the few out-of-vocabulary source words, we revert to copying as a back-off strategy,9 so our reported numbers are directly comparable to prior work in terms of coverage. XNLI. We train an English natural language inference model on MultiNLI (Williams et al., 2018), and evaluate the zero-shot cross-lingual transfer performance on the XNLI test set (Conneau et al., 2018b) for the subset of our languages covered by it. To that end, we follow Glavaˇs et al. (2019) and train an Enhanced Sequential Inference Model (ESIM) on top of our original English embeddings, which are kept frozen during training. At test time, we transfer into the rest of the languages by plugging in the corresponding aligned embeddings. Note that we use the exact same English model for our proposed method and the baseline MUSE and ICP systems,10 which only differ in the set of aligned"
2021.acl-long.506,D18-1268,0,0.0349071,"Missing"
2021.acl-long.506,P17-1179,0,0.0252406,"mantically similar words in different languages are close to each other. Early work focused on jointly learning CLWEs in two languages, relying on a strong cross-lingual supervision in the form of parallel corpora (Luong et al., 2015; Gouws et al., 2015) or bilingual dictionaries (Gouws and Søgaard, 2015; Duong et al., 2016). However, these approaches were later superseded by offline mapping methods, which separately train word embeddings in different languages and align them in an unsupervised manner through self-learning (Artetxe et al., 2018; Hoshen and Wolf, 2018) or adversarial training (Zhang et al., 2017; Conneau et al., 2018a). Despite the advantage of not requiring any parallel resources, mapping methods critically rely on the underlying embeddings having a similar structure, which is known as the isometry assumption. Several authors have observed that this assumption does not generally hold, severely hindering the performance of these methods (Søgaard et al., 2018; Nakashole and Flauger, 2018; Patra et al., 2019). In later work, Ormazabal et al. (2019) showed that this issue arises from trying to align separately trained embeddings, as joint learning methods are not susceptible to it. In t"
2021.acl-long.506,N19-1161,0,0.0387267,"Missing"
2021.emnlp-main.92,2020.acl-main.142,0,0.0194596,"edict the entire masked span. LUKE (Yamada et al., 2020) further pretrains a LM predicting entities from Wikipedia, and using entity information as an additional input embedding layer. K-Adapter (Wang et al., 2020) fixes the parameters of the pretrained LM and use Adapters to infuse factual and linguistic knowledge from Wikipedia and dependency parsing. TACRED (Zhang et al., 2017) is the largest and most widely used dataset for RE in English. It is derived from the TAC-KBP relation set, with labels obtained via crowdsourcing. Although alternate versions of TACRED have been published recently (Alt et al., 2020; Stoica et al., 2021), the state of the art is mainly tested in the original version. tual response to a given prompt. The manual generation of effective prompts is costly and requires domain expertise. Gao et al. (2020) provide an effective way to generate prompts for text classification tasks that surpasses the performance of hand picked ones. The approach uses few-shot training with a generative T5 model (Raffel et al., 2020) to learn to decode effective prompts. Similarly, Liu et al. (2021) automatically search prompts in a embedding space which can be simultaneously finetuned along with"
2021.emnlp-main.92,D15-1075,0,0.045924,"pirical Methods in Natural Language Processing, pages 1199–1212 c November 7–11, 2021. 2021 Association for Computational Linguistics tailment engine for few-shot RE. The results on the widely used TACRED (Zhang et al., 2017) RE dataset in zero- and few-shot scenarios are excellent, well over state-of-the-art systems using the same amount of data. In addition our method scales well with large pre-trained LMs and large amounts of training data, reporting the best results on TACRED to date. 2 Related Work Textual Entailment. It was first presented by Dagan et al. (2006) and further developed by Bowman et al. (2015) who called it Natural Language Inference (NLI). Given a textual premise and hypothesis, the task is to decide whether the premise entails or contradicts (or is neutral to) the hypothesis. The current state-of-the-art uses large pre-trained LM fine-tuned in NLI datasets (Lan et al., 2020; Liu et al., 2019; Conneau et al., 2020; Lewis et al., 2020; He et al., 2021). Relation Extraction. The best results to date on RE are obtained by fine-tuning large pre-trained language models equipped with a classification head. Joshi et al. (2020) pretrains a masked language model on random contiguous spans"
2021.emnlp-main.92,2021.naacl-main.272,0,0.0241625,"inference and the issue of detecting no-relation. Zero-Shot and Few-Shot learning. Brown et al. Partially vs. fullly unseen labels in RE. Exist(2020) showed that task descriptions (prompts) can ing zero/few-shot RE models usually see some labe fed into LMs for task-agnostic and few-shot per- bels during training (label partially unseen), which formance. In addition, (Schick and Schütze, 2020; helps generalize to the unseen label (Levy et al., Schick and Schütze, 2021; Tam et al., 2021) extend 2017; Obamuyide and Vlachos, 2018; Han et al., the method and allow finetuning of LMs on a va- 2018; Chen and Li, 2021). These approaches do riety of tasks. Prompt-based prediction treats the not fully address the data scarcity problem. In this downstream task as a (masked) language modeling work we address the more challenging label fully problem, where the model directly generates a tex- unseen scenario. 1200 Figure 1: General workflow of our entailment-based RE approach. 3 Entailment for RE In this section we describe our models for zeroand few-shot RE. 3.1 Zero-shot relation extraction We reformulate RE as an entailment task: given the input text containing the two entity mentions as the premise and the ve"
2021.emnlp-main.92,2020.acl-main.747,0,0.0279349,"same amount of data. In addition our method scales well with large pre-trained LMs and large amounts of training data, reporting the best results on TACRED to date. 2 Related Work Textual Entailment. It was first presented by Dagan et al. (2006) and further developed by Bowman et al. (2015) who called it Natural Language Inference (NLI). Given a textual premise and hypothesis, the task is to decide whether the premise entails or contradicts (or is neutral to) the hypothesis. The current state-of-the-art uses large pre-trained LM fine-tuned in NLI datasets (Lan et al., 2020; Liu et al., 2019; Conneau et al., 2020; Lewis et al., 2020; He et al., 2021). Relation Extraction. The best results to date on RE are obtained by fine-tuning large pre-trained language models equipped with a classification head. Joshi et al. (2020) pretrains a masked language model on random contiguous spans to learn span-boundaries and predict the entire masked span. LUKE (Yamada et al., 2020) further pretrains a LM predicting entities from Wikipedia, and using entity information as an additional input embedding layer. K-Adapter (Wang et al., 2020) fixes the parameters of the pretrained LM and use Adapters to infuse factual and l"
2021.emnlp-main.92,2020.emnlp-main.49,0,0.0187224,"e pre-trained language model. Note that previous prompt-based models run their zero-shot models on a semi-supervised setting in which some amount of labeled data is given in training. Prompts can be easily generated for text classification. Other tasks require more elaborate templates (Goswami et al., 2020; Li et al., 2021) and currently no effective prompt-based methods for RE exist. Besides prompt-based methods, the use of pivot tasks has been widely use for few/zero-shot learning. For instance, relation and event extraction have been cast as a question answering problem (Levy et al., 2017; Du and Cardie, 2020), associating each slot label to at least one natural language question. Closer to our work, NLI has been shown too to be a successful pivoting task for text classification (Yin et al., 2019, 2020; Wang et al., 2021; Sainz and Rigau, 2021). These works verbalize the labels, and apply an entailment engine to check whether the input text entails the label description. In similar work to ours, the relation between entailment and RE was explored by Obamuyide and Vlachos (2018). In their work they present some preliminary experiments where they cast RE as entailment, but only evaluate performance a"
2021.emnlp-main.92,D18-1514,0,0.0328217,"Missing"
2021.emnlp-main.92,2020.tacl-1.5,0,0.0206288,"st presented by Dagan et al. (2006) and further developed by Bowman et al. (2015) who called it Natural Language Inference (NLI). Given a textual premise and hypothesis, the task is to decide whether the premise entails or contradicts (or is neutral to) the hypothesis. The current state-of-the-art uses large pre-trained LM fine-tuned in NLI datasets (Lan et al., 2020; Liu et al., 2019; Conneau et al., 2020; Lewis et al., 2020; He et al., 2021). Relation Extraction. The best results to date on RE are obtained by fine-tuning large pre-trained language models equipped with a classification head. Joshi et al. (2020) pretrains a masked language model on random contiguous spans to learn span-boundaries and predict the entire masked span. LUKE (Yamada et al., 2020) further pretrains a LM predicting entities from Wikipedia, and using entity information as an additional input embedding layer. K-Adapter (Wang et al., 2020) fixes the parameters of the pretrained LM and use Adapters to infuse factual and linguistic knowledge from Wikipedia and dependency parsing. TACRED (Zhang et al., 2017) is the largest and most widely used dataset for RE in English. It is derived from the TAC-KBP relation set, with labels obt"
2021.emnlp-main.92,K17-1034,0,0.131227,"alizations (Puri and Catanzaro, 2019; Schick and Schütze, 2021; Schick and Schütze, 2020) as an alternative to standard fine-tuning (Gao et al., 2020; Scao and Rush, 2021). In these methods, the prompts are input to the LM together with the example, and the language modelling objective is used in learning and inference. In a different direction, some authors reformulate the target task (e.g. document classification) as a pivot task (typically question answering or textual entailment), which allows the use of readily available question answering (or entailment) training data (Yin et al., 2019; Levy et al., 2017). In all cases, the underlying idea is to cast the target task into a formulation which allows us to exploit the knowledge implicit in pre-trained LM (prompt-based) or general-purpose question answering or entailment engines (pivot tasks). Prompt-based approaches are very effective when the label verbalization is given by one or two words (e.g. text classification), as they can be easily predicted by language models, but strive in cases where the label requires a more elaborate description, as in RE. We thus propose to reformulate RE as an entailment problem, where the verbalizations of the re"
2021.emnlp-main.92,2020.acl-main.703,0,0.0143512,"In addition our method scales well with large pre-trained LMs and large amounts of training data, reporting the best results on TACRED to date. 2 Related Work Textual Entailment. It was first presented by Dagan et al. (2006) and further developed by Bowman et al. (2015) who called it Natural Language Inference (NLI). Given a textual premise and hypothesis, the task is to decide whether the premise entails or contradicts (or is neutral to) the hypothesis. The current state-of-the-art uses large pre-trained LM fine-tuned in NLI datasets (Lan et al., 2020; Liu et al., 2019; Conneau et al., 2020; Lewis et al., 2020; He et al., 2021). Relation Extraction. The best results to date on RE are obtained by fine-tuning large pre-trained language models equipped with a classification head. Joshi et al. (2020) pretrains a masked language model on random contiguous spans to learn span-boundaries and predict the entire masked span. LUKE (Yamada et al., 2020) further pretrains a LM predicting entities from Wikipedia, and using entity information as an additional input embedding layer. K-Adapter (Wang et al., 2020) fixes the parameters of the pretrained LM and use Adapters to infuse factual and linguistic knowledge"
2021.emnlp-main.92,2021.naacl-main.69,0,0.0117238,"the performance of hand picked ones. The approach uses few-shot training with a generative T5 model (Raffel et al., 2020) to learn to decode effective prompts. Similarly, Liu et al. (2021) automatically search prompts in a embedding space which can be simultaneously finetuned along with the pre-trained language model. Note that previous prompt-based models run their zero-shot models on a semi-supervised setting in which some amount of labeled data is given in training. Prompts can be easily generated for text classification. Other tasks require more elaborate templates (Goswami et al., 2020; Li et al., 2021) and currently no effective prompt-based methods for RE exist. Besides prompt-based methods, the use of pivot tasks has been widely use for few/zero-shot learning. For instance, relation and event extraction have been cast as a question answering problem (Levy et al., 2017; Du and Cardie, 2020), associating each slot label to at least one natural language question. Closer to our work, NLI has been shown too to be a successful pivoting task for text classification (Yin et al., 2019, 2020; Wang et al., 2021; Sainz and Rigau, 2021). These works verbalize the labels, and apply an entailment engine"
2021.emnlp-main.92,2021.ccl-1.108,0,0.0360333,"Missing"
2021.emnlp-main.92,W18-5511,0,0.0162897,"zero-shot learning. For instance, relation and event extraction have been cast as a question answering problem (Levy et al., 2017; Du and Cardie, 2020), associating each slot label to at least one natural language question. Closer to our work, NLI has been shown too to be a successful pivoting task for text classification (Yin et al., 2019, 2020; Wang et al., 2021; Sainz and Rigau, 2021). These works verbalize the labels, and apply an entailment engine to check whether the input text entails the label description. In similar work to ours, the relation between entailment and RE was explored by Obamuyide and Vlachos (2018). In their work they present some preliminary experiments where they cast RE as entailment, but only evaluate performance as binary entailment, not as a RE task. As a consequence they do not have competing positive labels and avoid RE inference and the issue of detecting no-relation. Zero-Shot and Few-Shot learning. Brown et al. Partially vs. fullly unseen labels in RE. Exist(2020) showed that task descriptions (prompts) can ing zero/few-shot RE models usually see some labe fed into LMs for task-agnostic and few-shot per- bels during training (label partially unseen), which formance. In additi"
2021.emnlp-main.92,2021.naacl-main.208,0,0.0675091,"Missing"
2021.emnlp-main.92,2021.eacl-main.20,0,0.510719,"upervised system on the same conditions), and only 4 points short of the state-of-the-art (which uses 20 times more training data). We also show that the performance can be improved significantly with larger entailment models, up to 12 points in zero-shot, giving the best results to date on TACRED when fully trained. The analysis shows that our few-shot systems are especially effective when discriminating between relations, and that the performance difference in low data regimes comes mainly from identifying no-relation cases. 1 Introduction and label verbalizations (Puri and Catanzaro, 2019; Schick and Schütze, 2021; Schick and Schütze, 2020) as an alternative to standard fine-tuning (Gao et al., 2020; Scao and Rush, 2021). In these methods, the prompts are input to the LM together with the example, and the language modelling objective is used in learning and inference. In a different direction, some authors reformulate the target task (e.g. document classification) as a pivot task (typically question answering or textual entailment), which allows the use of readily available question answering (or entailment) training data (Yin et al., 2019; Levy et al., 2017). In all cases, the underlying idea is to ca"
2021.emnlp-main.92,2021.emnlp-main.407,0,0.0425574,"e performance as binary entailment, not as a RE task. As a consequence they do not have competing positive labels and avoid RE inference and the issue of detecting no-relation. Zero-Shot and Few-Shot learning. Brown et al. Partially vs. fullly unseen labels in RE. Exist(2020) showed that task descriptions (prompts) can ing zero/few-shot RE models usually see some labe fed into LMs for task-agnostic and few-shot per- bels during training (label partially unseen), which formance. In addition, (Schick and Schütze, 2020; helps generalize to the unseen label (Levy et al., Schick and Schütze, 2021; Tam et al., 2021) extend 2017; Obamuyide and Vlachos, 2018; Han et al., the method and allow finetuning of LMs on a va- 2018; Chen and Li, 2021). These approaches do riety of tasks. Prompt-based prediction treats the not fully address the data scarcity problem. In this downstream task as a (masked) language modeling work we address the more challenging label fully problem, where the model directly generates a tex- unseen scenario. 1200 Figure 1: General workflow of our entailment-based RE approach. 3 Entailment for RE In this section we describe our models for zeroand few-shot RE. 3.1 Zero-shot relation extrac"
2021.emnlp-main.92,2020.emnlp-main.523,0,0.217584,"onstraints. In order to ensure that the manual work involved is limited and practical in real-world applications, we allowed at most 15 minutes of manual labor per relation. The verbalizations are used as-is for zero-shot RE, but we also recast labelled RE examples as entailment pairs and fine-tune the enGiven a context where two entities appear, the Relation Extraction (RE) task aims to predict the semantic relation (if any) holding between the two entities. Methods that fine-tune large pretrained language models (LM) with large amounts of labelled data have established the state of the art (Yamada et al., 2020). Nevertheless, due to differing languages, domains and the cost of human annotation, there is typically a very small number of labelled examples in real-world applications, and such models perform poorly (Schick and Schütze, 2021). As an alternative, methods that only need a few examples (few-shot) or no examples (zero-shot) 1 have emerged. For instance, prompt based learning Code and splits available at: https://github.com/ proposes hand-made or automatically learned task osainz59/Ask2Transformers 1199 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pa"
2021.emnlp-main.92,D19-1404,0,0.0863277,"ion and label verbalizations (Puri and Catanzaro, 2019; Schick and Schütze, 2021; Schick and Schütze, 2020) as an alternative to standard fine-tuning (Gao et al., 2020; Scao and Rush, 2021). In these methods, the prompts are input to the LM together with the example, and the language modelling objective is used in learning and inference. In a different direction, some authors reformulate the target task (e.g. document classification) as a pivot task (typically question answering or textual entailment), which allows the use of readily available question answering (or entailment) training data (Yin et al., 2019; Levy et al., 2017). In all cases, the underlying idea is to cast the target task into a formulation which allows us to exploit the knowledge implicit in pre-trained LM (prompt-based) or general-purpose question answering or entailment engines (pivot tasks). Prompt-based approaches are very effective when the label verbalization is given by one or two words (e.g. text classification), as they can be easily predicted by language models, but strive in cases where the label requires a more elaborate description, as in RE. We thus propose to reformulate RE as an entailment problem, where the verb"
2021.emnlp-main.92,2020.emnlp-main.660,0,0.0356535,"Missing"
2021.emnlp-main.92,D17-1004,0,0.342665,"rld applications, and such models perform poorly (Schick and Schütze, 2021). As an alternative, methods that only need a few examples (few-shot) or no examples (zero-shot) 1 have emerged. For instance, prompt based learning Code and splits available at: https://github.com/ proposes hand-made or automatically learned task osainz59/Ask2Transformers 1199 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1199–1212 c November 7–11, 2021. 2021 Association for Computational Linguistics tailment engine for few-shot RE. The results on the widely used TACRED (Zhang et al., 2017) RE dataset in zero- and few-shot scenarios are excellent, well over state-of-the-art systems using the same amount of data. In addition our method scales well with large pre-trained LMs and large amounts of training data, reporting the best results on TACRED to date. 2 Related Work Textual Entailment. It was first presented by Dagan et al. (2006) and further developed by Bowman et al. (2015) who called it Natural Language Inference (NLI). Given a textual premise and hypothesis, the task is to decide whether the premise entails or contradicts (or is neutral to) the hypothesis. The current stat"
2021.emnlp-main.92,N18-1101,0,0.0810662,"Missing"
alegria-etal-2010-morphological,E09-2008,0,\N,Missing
alegria-etal-2010-morphological,P84-1038,0,\N,Missing
alegria-etal-2010-morphological,W83-0114,0,\N,Missing
C10-1005,J93-2003,0,0.047958,"ient for the CL-ESA data requirements. 3.2 In this model an estimation of how likely is that d′ is a translation of dq is performed. It is based on the adaptation of the Bayes rule for MT: p(d′ |dq ) = p(d′ ) p(dq |d′ ) . p(dq ) (1) As p(dq ) does not depend on d′ , it is neglected. From an MT point of view, the conditional probability p(dq |d′ ) is known as translation model probability and is computed on the basis of a statistical bilingual dictionary. p(d′ ) is known as language model probability; it describes the target language L′ in order to obtain grammatically acceptable translations (Brown et al., 1993). Translating dq into L′ is not the concern of this method, rather it focuses on retrieving texts written in L′ which are potential translations of dq . Therefore, Barr´on-Cede˜no et al. (2008) proposed replacing the language model (the one used in T+MA) by that known as length model. This model depends on text’s character lengths instead of language structures. Multiple translations from d into L′ are possible, and it is uncommon to find a pair of translated texts d and d′ such that |d |= |d′ |. Nevertheless, the length of such translations is closely related to a translation length factor. I"
C10-1005,clough-etal-2002-building,0,0.11682,"1 where µ and σ are the mean and the standard deviation of the character lengths between translations of texts from L into L′ . If the length of d′ is not the expected given dq , it receives a low qualification. The translation model probability is defined as: p(d |d′ ) = YX p(x, y), In other Information Retrieval tasks a plethora of corpora is available for experimental and comparison purposes. However, plagiarism implies an ethical infringement and, to the best of our knowledge, there is no corpora of actual cases available, other than some seminal efforts on creating corpora of text reuse (Clough et al., 2002), artificial plagiarism (Potthast et al., 2009), and simulated plagiarism (Clough and Stevenson, 2010). The problem is worse for cross-language plagiarism. Therefore, in our experiments we use two parallel corpora: Software, an en-eu translation memory of software manuals generously supplied by Elhuyar Fundazioa5 ; and Consumer, a corpus extracted from a consumer oriented magazine that includes articles written in Spanish along with their Basque, Catalan, and Galician translations6 (Alc´azar, 2006). Software includes 288, 000 parallel sentences; 8.66 (6.83) words per sentence in the English (B"
C10-1005,P07-2045,0,0.00738927,"Missing"
C10-1005,N04-1034,0,0.0137599,"Missing"
C10-1005,J03-1002,0,0.00763746,"Missing"
C10-1005,steinberger-etal-2006-jrc,0,0.0300396,"m of CLPD in Basque, with source texts written in Spanish (the co-official language of the Figure 1: First sentences from the Wikipedia articles “Party of European Socialists” (en),“Partido Socialista Europeo” (es), and “Europako Alderdi Sozialista” (eu) (Wikipedia, 2010b). 100 words are contained in the en, es and eu articles, respectively). Of high relevance is that the two corpora used in this work were manually constructed by translating English and Spanish text into Basque. In the experiments carried out by Potthast et al. (2010), which inspired our work, texts from the JCRAcquis corpus (Steinberger et al., 2006) and Wikipedia were used. The first one is a multilingual corpus with no clear definition of source and target languages, whereas in Wikipedia no specific relationship exists between the different languages in which a topic may be broached. In some cases (cf. Fig. 1) they are clearly co-derived, but in others they are completely independent. CLPD has been investigated just recently, mainly by adapting models formerly proposed for cross-language information retrieval. This is the case of cross-language explicit semantic analysis (CL-ESA), proposed by Potthast et al. (2008). In this case the com"
C10-1005,barron-cedeno-etal-2010-corpus,1,\N,Missing
C16-1082,W03-1812,0,0.0217383,"eral and non-literal word combinations (Birke and Sarkar, 2006; Cook et al., 2008), whereas others propose a grading containing several MWE types based on semantic idiomaticity, considered as a continuum (Wulff, 2008). Within the Meaning-Text Theory, collocations are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not us"
C16-1082,E06-1042,0,0.0463699,"ms to work effectively (Sag et al., 2002), since these kinds of word combinations are very frequent in both text and speech. It is estimated that the number of MWEs in an English speaker’s vocabulary is of the same order of magnitude as that of single words (Jackendoff, 1997), and that at least one MWE is used per sentence on average (Sinclair, 1991). Various classifications of MWEs have been proposed, employing different criteria to match the requirements of a particular kind of target application. Some researchers propose a binary categorisation of literal and non-literal word combinations (Birke and Sarkar, 2006; Cook et al., 2008), whereas others propose a grading containing several MWE types based on semantic idiomaticity, considered as a continuum (Wulff, 2008). Within the Meaning-Text Theory, collocations are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 200"
C16-1082,W07-1102,0,0.0722873,"Missing"
C16-1082,P03-1065,0,0.0404403,"ions are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word for word. In the context of MT systems, Wehrli (2014) states “the non-identification of collocations dramatically affects the quality of the output”. 3 Linguistic Analysis The linguistic analysis we present here aims at improving MW"
C16-1082,P14-5010,0,0.00587255,"Missing"
C16-1082,W03-1810,1,0.832198,"ord combinations (Birke and Sarkar, 2006; Cook et al., 2008), whereas others propose a grading containing several MWE types based on semantic idiomaticity, considered as a continuum (Wulff, 2008). Within the Meaning-Text Theory, collocations are sorted according to the notion of lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word f"
C16-1082,padro-stanilovsky-2012-freeling,0,0.184284,"Missing"
C16-1082,P16-2081,0,0.0561217,"Missing"
C16-1082,E09-1086,0,0.0182944,"lexical functions (Mel’´cuk, 1998), that is, taking into account how the component words are semantically related. Furthermore, some experiments have investigated automatic methods—such as distributional similarity or word embeddings—for the task of classification, leading to fairly good results (Baldwin et al., 2003; McCarthy et al., 2003; Fazly et al., 2007; Rodr´ıguez-Fern´andez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word for word. In the context of MT systems, Wehrli (2014) states “the non-identification of collocations dramatically affects the quality of the output”. 3 Linguistic Analysis The linguistic analysis we present here aims at improving MWE processing in MT. More specifically, we base our"
C16-1082,W13-1009,0,0.0697427,"Missing"
C16-1082,vincze-2012-light,0,0.073371,"Missing"
C16-1082,W14-0804,0,0.0175347,"ndez et al., 2016). In addition to MWE classification, a great deal of work has been undertaken over the last two decades on MWE acquisition (Ramisch, 2015) and identification (Li et al., 2003; Seretan and Wehrli, 2009; Sporleder and Li, 2009). Precise and detailed syntactic information is crucial for both tasks, and, at the same time, MWE identification can also help parsers obtain better results (Seretan, 2013). Moreover, accurate MWE detection is crucial for MT, since MWEs vary greatly from one language to another, and are not usually translated word for word. In the context of MT systems, Wehrli (2014) states “the non-identification of collocations dramatically affects the quality of the output”. 3 Linguistic Analysis The linguistic analysis we present here aims at improving MWE processing in MT. More specifically, we base our study on Matxin (Mayor et al., 2011), a rule-based MT system for English-Basque and 2 Whereas English (Germanic) and Spanish (Romance) are Indo-European languages, Basque is a non-Indo-European language which moreover belongs to no known language family. 858 Spanish-Basque translation. One of the problems Matxin has concerning MWEs is that it currently fails to detect"
D16-1250,W15-1521,0,0.040811,"approach is to learn a linear mapping that minimizes the distances between equivalences listed in a bilingual dictionary. In this paper, we propose a framework that generalizes previous work, provides an efficient exact method to learn the optimal linear transformation and yields the best bilingual results in translation induction while preserving monolingual performance in an analogy task. 1 Introduction Bilingual word embeddings have attracted a lot of attention in recent times (Zou et al., 2013; Koˇcisk´y et al., 2014; Chandar A P et al., 2014; Gouws et al., 2014; Gouws and Søgaard, 2015; Luong et al., 2015; Wick et al., 2016). A common approach to obtain them is to train the embeddings in both languages independently and then learn a mapping that minimizes the distances between equivalences listed in a bilingual dictionary. The learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation (Mikolov et al., 2013b; Zhao et al., 2015). The first method to learn bilingual word embedding mappings was proposed by Mikolov et al. (2013b), who learn the linear transformation that minimizes the s"
D16-1250,N15-1104,0,0.671988,"Missing"
D16-1250,N15-1176,0,0.0219783,"ttracted a lot of attention in recent times (Zou et al., 2013; Koˇcisk´y et al., 2014; Chandar A P et al., 2014; Gouws et al., 2014; Gouws and Søgaard, 2015; Luong et al., 2015; Wick et al., 2016). A common approach to obtain them is to train the embeddings in both languages independently and then learn a mapping that minimizes the distances between equivalences listed in a bilingual dictionary. The learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation (Mikolov et al., 2013b; Zhao et al., 2015). The first method to learn bilingual word embedding mappings was proposed by Mikolov et al. (2013b), who learn the linear transformation that minimizes the sum of squared Euclidean distances for the dictionary entries. Subsequent work has proposed alternative optimization objectives to learn Beyond linear mappings, Lu et al. (2015) apply deep canonical correlation analysis to learn a nonlinear transformation for each language. Finally, additional techniques have been used to address the hubness problem in Mikolov et al. (2013b), both through the neighbor retrieval method (Dinu et al., 2015) a"
D16-1250,D13-1141,0,0.0114373,"into a single space has multiple applications. In order to map from a source space into a target space, a common approach is to learn a linear mapping that minimizes the distances between equivalences listed in a bilingual dictionary. In this paper, we propose a framework that generalizes previous work, provides an efficient exact method to learn the optimal linear transformation and yields the best bilingual results in translation induction while preserving monolingual performance in an analogy task. 1 Introduction Bilingual word embeddings have attracted a lot of attention in recent times (Zou et al., 2013; Koˇcisk´y et al., 2014; Chandar A P et al., 2014; Gouws et al., 2014; Gouws and Søgaard, 2015; Luong et al., 2015; Wick et al., 2016). A common approach to obtain them is to train the embeddings in both languages independently and then learn a mapping that minimizes the distances between equivalences listed in a bilingual dictionary. The learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation (Mikolov et al., 2013b; Zhao et al., 2015). The first method to learn bilingual word"
D16-1250,N15-1028,0,\N,Missing
D16-1250,E14-1049,0,\N,Missing
D18-1399,P17-1042,1,0.81531,"strict the vocabulary to the most frequent 200,000 unigrams, 400,000 bigrams and 400,000 trigrams. 3.2 Cross-lingual mapping Cross-lingual mapping methods take independently trained word embeddings in two languages, and learn a linear transformation to map them to a shared cross-lingual space (Mikolov et al., 2013a; Artetxe et al., 2018a). Most mapping methods are supervised, and rely on a bilingual dictionary, typically in the range of a few thousand entries, although a recent line of work has managed to achieve comparable results in a fully unsupervised manner based on either self-learning (Artetxe et al., 2017, 2018b) or adversarial training (Zhang et al., 2017a,b; Conneau et al., 2018). In our case, we use the method of Artetxe et al. 3634 (2018b) to map the n-gram embeddings to a shared cross-lingual space using their open source implementation VecMap1 . Originally designed for word embeddings, this method builds an initial mapping by connecting the intra-lingual similarity distribution of embeddings in different languages, and iteratively improves this solution through selflearning. The method applies a frequency-based vocabulary cut-off, learning the mapping over the 20,000 most frequent words"
D18-1399,P18-1073,1,0.685012,"ploit continuous representations that mitigate the sparsity problem, and overcome the locality problem by making use of unconstrained contexts. Thanks to this additional flexibility, NMT can more effectively exploit large parallel corpora, although SMT is still superior when the training corpus is not big enough (Koehn and Knowles, 2017). Somewhat paradoxically, while most machine translation research has focused on resource-rich settings where NMT has indeed superseded SMT, a recent line of work has managed to train an NMT system without any supervision, relying on monolingual corpora alone (Artetxe et al., 2018c; Lample et al., 2018). Given the scarcity of parallel corpora for most language pairs, including lessresourced languages but also many combinations of major languages, this research line opens exciting opportunities to bring effective machine translation to many more scenarios. Nevertheless, existing solutions are still far behind their supervised counterparts, greatly limiting their practical usability. For instance, existing unsupervised NMT systems obtain between 15-16 BLEU points in WMT 2014 English-French translation, whereas a state-of-the-art NMT system obtains around 41 (Artetxe et a"
D18-1399,D18-1549,0,0.135131,"Missing"
D18-1399,J90-2002,0,0.890624,"ints. The remaining of this paper is structured as follows. Section 2 introduces phrase-based SMT. Section 3 presents our unsupervised approach to learn cross-lingual n-gram embeddings, which are the basis of our proposal. Section 4 describes the proposed unsupervised SMT system itself, while Section 5 discusses its iterative refinement through backtranslation. Section 6 describes the experiments run and the results obtained. Section 7 discusses the related work on the topic, and Section 8 concludes the paper. 2 Background: phrase-based SMT While originally motivated as a noisy channel model (Brown et al., 1990), phrase-based SMT is now formulated as a log-linear combination of several statistical models that score translation candidates (Koehn et al., 2003). The parameters of these scoring functions are estimated independently based on frequency counts, and their weights are then tuned in a separate validation set. At inference time, a decoder tries to find the translation candidate with the highest score according to the resulting combined model. The specific scoring models found in a standard SMT system are as follows: • Phrase table. The phrase table is a collection of source language n-grams and"
D18-1399,D12-1025,0,0.320799,"ould get a reasonable understanding of the original text from them. This suggests that unsupervised machine translation can indeed be a usable alternative in low resource settings. 7 Related work Similar to our approach, statistical decipherment also attempts to build machine translation systems from monolingual corpora. For that purpose, existing methods treat the source language as ciphertext, and model its generation through a noisy channel model involving two steps: the generation of the original English sentence and the probabilistic replacement of the words in it (Ravi and Knight, 2011; Dou and Knight, 2012). The English generative process is modeled using an n-gram language model, and the channel model parameters are estimated using either expectation maximization or Bayesian inference. Subsequent work has attempted to enrich these models with additional information like syntactic knowledge (Dou and Knight, 2013) and word embeddings (Dou et al., 2015). Nevertheless, these systems work in a word-by-word basis and have 3639 only been shown to work in limited settings, being often evaluated in word-level translation. In contrast, our method builds a fully featured phrasebased SMT system, and achiev"
D18-1399,D13-1173,0,0.0486152,"l corpora. For that purpose, existing methods treat the source language as ciphertext, and model its generation through a noisy channel model involving two steps: the generation of the original English sentence and the probabilistic replacement of the words in it (Ravi and Knight, 2011; Dou and Knight, 2012). The English generative process is modeled using an n-gram language model, and the channel model parameters are estimated using either expectation maximization or Bayesian inference. Subsequent work has attempted to enrich these models with additional information like syntactic knowledge (Dou and Knight, 2013) and word embeddings (Dou et al., 2015). Nevertheless, these systems work in a word-by-word basis and have 3639 only been shown to work in limited settings, being often evaluated in word-level translation. In contrast, our method builds a fully featured phrasebased SMT system, and achieves competitive performance in a standard machine translation task. More recently, Artetxe et al. (2018c) and Lample et al. (2018) have managed to train a standard attentional encoder-decoder NMT system from monolingual corpora alone. For that purpose, they use a shared encoder for both languages with pretrained"
D18-1399,P15-1081,0,0.0191838,"ds treat the source language as ciphertext, and model its generation through a noisy channel model involving two steps: the generation of the original English sentence and the probabilistic replacement of the words in it (Ravi and Knight, 2011; Dou and Knight, 2012). The English generative process is modeled using an n-gram language model, and the channel model parameters are estimated using either expectation maximization or Bayesian inference. Subsequent work has attempted to enrich these models with additional information like syntactic knowledge (Dou and Knight, 2013) and word embeddings (Dou et al., 2015). Nevertheless, these systems work in a word-by-word basis and have 3639 only been shown to work in limited settings, being often evaluated in word-level translation. In contrast, our method builds a fully featured phrasebased SMT system, and achieves competitive performance in a standard machine translation task. More recently, Artetxe et al. (2018c) and Lample et al. (2018) have managed to train a standard attentional encoder-decoder NMT system from monolingual corpora alone. For that purpose, they use a shared encoder for both languages with pretrained cross-lingual embeddings, and train th"
D18-1399,N03-1017,0,0.0586958,"proves results further, yielding, for instance, 14.08 and 26.22 BLEU points in WMT 2014 English-German and English-French, respectively, an improvement of more than 7-10 BLEU points over previous unsupervised systems, and closing the gap with supervised SMT (Moses trained on Europarl) down to 2-5 BLEU points. Our implementation is available at https:// github.com/artetxem/monoses. 1 Introduction Neural Machine Translation (NMT) has recently become the dominant paradigm in machine translation (Vaswani et al., 2017). In contrast to more rigid Statistical Machine Translation (SMT) architectures (Koehn et al., 2003), NMT models are trained end-to-end, exploit continuous representations that mitigate the sparsity problem, and overcome the locality problem by making use of unconstrained contexts. Thanks to this additional flexibility, NMT can more effectively exploit large parallel corpora, although SMT is still superior when the training corpus is not big enough (Koehn and Knowles, 2017). Somewhat paradoxically, while most machine translation research has focused on resource-rich settings where NMT has indeed superseded SMT, a recent line of work has managed to train an NMT system without any supervision,"
D18-1399,P03-1021,0,0.0809954,"Missing"
D18-1399,J03-1002,0,0.0194585,"n a standard SMT system are as follows: • Phrase table. The phrase table is a collection of source language n-grams and a list of their possible translations in the target language along with different scores for each of 3633 them. So as to translate longer sequences, the decoder combines these partial n-gram translations, and ranks the resulting candidates according to their corresponding scores and the rest of scoring functions. In order to build the phrase table, SMT computes word alignments in both directions from a parallel corpus, symmetrizes these alignments using different heuristics (Och and Ney, 2003), extracts the set of consistent phrase pairs, and scores them based on frequency counts. For that purpose, standard SMT uses 4 scores for each phrase table entry: the direct and inverse lexical weightings, which are derived from word level alignments, and the direct and inverse phrase translation probabilities, which are computed at the phrase level. • Language model. The language model assigns a probability to a word sequence in the target language. Traditional SMT uses ngram language models for that, which use simple frequency counts over a large monolingual corpus with back-off and smoothi"
D18-1399,P11-1002,0,0.136607,"e and fluent, and one could get a reasonable understanding of the original text from them. This suggests that unsupervised machine translation can indeed be a usable alternative in low resource settings. 7 Related work Similar to our approach, statistical decipherment also attempts to build machine translation systems from monolingual corpora. For that purpose, existing methods treat the source language as ciphertext, and model its generation through a noisy channel model involving two steps: the generation of the original English sentence and the probabilistic replacement of the words in it (Ravi and Knight, 2011; Dou and Knight, 2012). The English generative process is modeled using an n-gram language model, and the channel model parameters are estimated using either expectation maximization or Bayesian inference. Subsequent work has attempted to enrich these models with additional information like syntactic knowledge (Dou and Knight, 2013) and word embeddings (Dou et al., 2015). Nevertheless, these systems work in a word-by-word basis and have 3639 only been shown to work in limited settings, being often evaluated in word-level translation. In contrast, our method builds a fully featured phrasebased"
D18-1399,N13-1073,0,0.0579698,"n the other direction. As detailed in Algorithm 2, this process is repeated iteratively until some convergence criterion is met. While this procedure would be expected to produce a more accurate model at each iteration, it also happens to be very expensive computationally. In order to accelerate our experiments, we use a random subset of 2 million sentences from each monolingual corpus for training4 , in addition to the 10,000 separate sentences that are held out as a validation set for MERT tuning, and perform a fixed number of 3 iterations of the above algorithm. Moreover, we use FastAlign (Dyer et al., 2013) instead of GIZA++ to make word alignment faster. Other than that, training over the synthetic 4 Note that we reuse the original language model, which is trained in the full corpus. 3636 WMT-14 WMT-16 FR-EN EN-FR DE-EN EN-DE DE-EN EN-DE Artetxe et al. (2018c) Lample et al. (2018) Yang et al. (2018) 15.56 14.31 15.58 15.13 15.05 16.97 10.21 - 6.55 - 13.33 14.62 9.64 10.86 Proposed system 25.87 26.22 17.43 14.08 23.05 18.23 Table 1: Results of the proposed method in comparison to existing unsupervised NMT systems (BLEU). parallel corpus is done through standard Moses tools with default settings."
D18-1399,P16-1009,0,0.776514,"ergence work well in practice. Finally, the word translation probabilities w(f¯i |¯ ej ) are computed using the same formula defined for phrase translation probabilities (see above), with the difference that the partition function goes over unigrams only. 4.2 Unsupervised tuning As discussed in Section 2, standard SMT uses MERT over a small parallel corpus to tune the weights of the different scoring functions combined through its log-linear model. Given that we only have access to monolingual corpora in our scenario, we propose to generate a synthetic parallel corpus through backtranslation (Sennrich et al., 2016) and apply MERT tuning over it, iteratively repeating the process in both directions (see Algorithm 1). For that purpose, we reserve a random subset of 10,000 sentences from each monolingual corpora, and run the proposed algorithm over them for 10 iterations, which we find to be enough for convergence. 5 Iterative refinement The procedure described in Section 4 suffices to train an SMT system from monolingual corpora which, as shown by our experiments in Section 6, already outperforms previous unsupervised systems. Nevertheless, our proposed method still makes important simplifications that co"
D18-1399,P13-2121,0,0.0726288,"Missing"
D18-1399,W17-3204,0,0.0369659,"m/monoses. 1 Introduction Neural Machine Translation (NMT) has recently become the dominant paradigm in machine translation (Vaswani et al., 2017). In contrast to more rigid Statistical Machine Translation (SMT) architectures (Koehn et al., 2003), NMT models are trained end-to-end, exploit continuous representations that mitigate the sparsity problem, and overcome the locality problem by making use of unconstrained contexts. Thanks to this additional flexibility, NMT can more effectively exploit large parallel corpora, although SMT is still superior when the training corpus is not big enough (Koehn and Knowles, 2017). Somewhat paradoxically, while most machine translation research has focused on resource-rich settings where NMT has indeed superseded SMT, a recent line of work has managed to train an NMT system without any supervision, relying on monolingual corpora alone (Artetxe et al., 2018c; Lample et al., 2018). Given the scarcity of parallel corpora for most language pairs, including lessresourced languages but also many combinations of major languages, this research line opens exciting opportunities to bring effective machine translation to many more scenarios. Nevertheless, existing solutions are s"
D18-1399,P18-1005,0,0.354176,"he scarcity of parallel corpora for most language pairs, including lessresourced languages but also many combinations of major languages, this research line opens exciting opportunities to bring effective machine translation to many more scenarios. Nevertheless, existing solutions are still far behind their supervised counterparts, greatly limiting their practical usability. For instance, existing unsupervised NMT systems obtain between 15-16 BLEU points in WMT 2014 English-French translation, whereas a state-of-the-art NMT system obtains around 41 (Artetxe et al., 2018c; Lample et al., 2018; Yang et al., 2018). In this paper, we explore whether the rigid and modular nature of SMT is more suitable for these unsupervised settings, and propose a novel unsupervised SMT system that can be trained on monolingual corpora alone. For that purpose, we present a natural extension of the skip-gram model (Mikolov et al., 2013b) that simultaneously learns word and phrase embeddings, which are then mapped to a cross-lingual space through selflearning (Artetxe et al., 2018b). We use the resulting cross-lingual phrase embeddings to induce a phrase table, and combine it with a language model and a distance-based dis"
D18-1399,P17-1179,0,0.0536574,"grams, 400,000 bigrams and 400,000 trigrams. 3.2 Cross-lingual mapping Cross-lingual mapping methods take independently trained word embeddings in two languages, and learn a linear transformation to map them to a shared cross-lingual space (Mikolov et al., 2013a; Artetxe et al., 2018a). Most mapping methods are supervised, and rely on a bilingual dictionary, typically in the range of a few thousand entries, although a recent line of work has managed to achieve comparable results in a fully unsupervised manner based on either self-learning (Artetxe et al., 2017, 2018b) or adversarial training (Zhang et al., 2017a,b; Conneau et al., 2018). In our case, we use the method of Artetxe et al. 3634 (2018b) to map the n-gram embeddings to a shared cross-lingual space using their open source implementation VecMap1 . Originally designed for word embeddings, this method builds an initial mapping by connecting the intra-lingual similarity distribution of embeddings in different languages, and iteratively improves this solution through selflearning. The method applies a frequency-based vocabulary cut-off, learning the mapping over the 20,000 most frequent words in each language. We kept this cut-off to learn the"
D18-1399,D17-1207,0,0.0421625,"grams, 400,000 bigrams and 400,000 trigrams. 3.2 Cross-lingual mapping Cross-lingual mapping methods take independently trained word embeddings in two languages, and learn a linear transformation to map them to a shared cross-lingual space (Mikolov et al., 2013a; Artetxe et al., 2018a). Most mapping methods are supervised, and rely on a bilingual dictionary, typically in the range of a few thousand entries, although a recent line of work has managed to achieve comparable results in a fully unsupervised manner based on either self-learning (Artetxe et al., 2017, 2018b) or adversarial training (Zhang et al., 2017a,b; Conneau et al., 2018). In our case, we use the method of Artetxe et al. 3634 (2018b) to map the n-gram embeddings to a shared cross-lingual space using their open source implementation VecMap1 . Originally designed for word embeddings, this method builds an initial mapping by connecting the intra-lingual similarity distribution of embeddings in different languages, and iteratively improves this solution through selflearning. The method applies a frequency-based vocabulary cut-off, learning the mapping over the 20,000 most frequent words in each language. We kept this cut-off to learn the"
D18-1399,N15-1176,0,0.0470213,"Missing"
K18-1028,Q16-1028,0,0.0229841,"rvised ones. 1 Introduction Word embeddings have recently become a central topic in natural language processing. Several unsupervised methods have been proposed to efficiently train dense vector representations of words (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017) and successfully applied in a variety of tasks like parsing (Bansal et al., 2014), topic modeling (Batmanghelich et al., 2016) and document classification (Taddy, 2015). While there is still an active research line to better understand these models from a theoretical perspective (Levy and Goldberg, 2014c; Arora et al., 2016; Gittens et al., 2017), the fundamental idea behind all of them is to assign a similar vector representation to similar words. For that purpose, most embedding models build upon co-occurrence statistics from large monolingual corpora, following the distributional hypothesis that similar words tend to occur in similar contexts (Harris, 1954). Nevertheless, the above argument does not formalize what “similar words” means, and it is not 1. We propose a linear transformation with a free parameter that adjusts the perfor1 Also referred to as functional similarity or just similarity. Also referred"
K18-1028,W16-2501,0,0.0409144,"Missing"
K18-1028,P14-2131,0,0.114359,"on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones. 1 Introduction Word embeddings have recently become a central topic in natural language processing. Several unsupervised methods have been proposed to efficiently train dense vector representations of words (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017) and successfully applied in a variety of tasks like parsing (Bansal et al., 2014), topic modeling (Batmanghelich et al., 2016) and document classification (Taddy, 2015). While there is still an active research line to better understand these models from a theoretical perspective (Levy and Goldberg, 2014c; Arora et al., 2016; Gittens et al., 2017), the fundamental idea behind all of them is to assign a similar vector representation to similar words. For that purpose, most embedding models build upon co-occurrence statistics from large monolingual corpora, following the distributional hypothesis that similar words tend to occur in similar contexts (Harris, 1954). Nevertheles"
K18-1028,N15-1184,0,0.236194,"ings, they might wrongly conclude that fasttext is vastly superior to glove at encoding semantic similarity information, but this proves to be a mere illusion after applying our post-processing. As such, intrinsic evaluation combined with our post-processing provides a more complete and dynamic picture of the information that is truly encoded by different embedding models. 6 Related work There have been several proposals to learn word embeddings that are specialized in certain linguistic aspects. For instance, Kiela et al. (2015) use a joint-learning approach and two variants of retrofitting (Faruqui et al., 2015a) to specialize word embeddings for either similarity or relatedness. At the same time, Levy and Goldberg (2014a) propose a modification of skip-gram that uses a dependency-based context instead of a sliding windows, which produces embeddings that are more tailored towards genuine similarity than relatedness. Bansal et al. (2014) follow a similar approach to train specialized embeddings that are used as features for dependency parsing. Finally, Mitchell and Steedman (2015) exploit morphology and word order information to learn embeddings that decompose into orthogonal • Supervised systems tha"
K18-1028,W16-2502,0,0.0256611,"decomposition, so given the co-occurrence matrix M = U SV T , the word vectors will correspond to the first n dimensions of W = U S α , where the parameter α plays a similar role as in our method. Note, however, that our proposal is more general and can be applied to any set of word vectors in a post-processing step, including neural embedding models that have superseded these traditional count-based models as we in fact do in this paper. Finally, there are others authors that have also pointed limitations in the intrinsic evaluation of word embeddings. For instance, Faruqui et al. (2016) and Batchkarov et al. (2016) argue that word similarity has many problems like the subjectivity and difficulty of the task, the lack of statistical significance and the inability to account for polysemy, warning that results should be interpreted with care. Chiu et al. (2016) analyze the correlation between results on word similarity benchmarks and sequence labeling tasks, and conAcknowledgments This research was partially supported by the Spanish MINECO (TUNER TIN2015-65308-C51-R, MUSTER PCIN-2015-226 and TADEEP TIN2015-70214-P, cofunded by EU FEDER), the UPV/EHU (excellence research group), and the NVIDIA GPU grant pro"
K18-1028,W16-2506,0,0.0278732,"trix using singular value decomposition, so given the co-occurrence matrix M = U SV T , the word vectors will correspond to the first n dimensions of W = U S α , where the parameter α plays a similar role as in our method. Note, however, that our proposal is more general and can be applied to any set of word vectors in a post-processing step, including neural embedding models that have superseded these traditional count-based models as we in fact do in this paper. Finally, there are others authors that have also pointed limitations in the intrinsic evaluation of word embeddings. For instance, Faruqui et al. (2016) and Batchkarov et al. (2016) argue that word similarity has many problems like the subjectivity and difficulty of the task, the lack of statistical significance and the inability to account for polysemy, warning that results should be interpreted with care. Chiu et al. (2016) analyze the correlation between results on word similarity benchmarks and sequence labeling tasks, and conAcknowledgments This research was partially supported by the Spanish MINECO (TUNER TIN2015-65308-C51-R, MUSTER PCIN-2015-226 and TADEEP TIN2015-70214-P, cofunded by EU FEDER), the UPV/EHU (excellence research group),"
K18-1028,P16-2087,0,0.0209852,"nguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones. 1 Introduction Word embeddings have recently become a central topic in natural language processing. Several unsupervised methods have been proposed to efficiently train dense vector representations of words (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017) and successfully applied in a variety of tasks like parsing (Bansal et al., 2014), topic modeling (Batmanghelich et al., 2016) and document classification (Taddy, 2015). While there is still an active research line to better understand these models from a theoretical perspective (Levy and Goldberg, 2014c; Arora et al., 2016; Gittens et al., 2017), the fundamental idea behind all of them is to assign a similar vector representation to similar words. For that purpose, most embedding models build upon co-occurrence statistics from large monolingual corpora, following the distributional hypothesis that similar words tend to occur in similar contexts (Harris, 1954). Nevertheless, the above argument does not formalize what"
K18-1028,P15-1144,0,0.120637,"ings, they might wrongly conclude that fasttext is vastly superior to glove at encoding semantic similarity information, but this proves to be a mere illusion after applying our post-processing. As such, intrinsic evaluation combined with our post-processing provides a more complete and dynamic picture of the information that is truly encoded by different embedding models. 6 Related work There have been several proposals to learn word embeddings that are specialized in certain linguistic aspects. For instance, Kiela et al. (2015) use a joint-learning approach and two variants of retrofitting (Faruqui et al., 2015a) to specialize word embeddings for either similarity or relatedness. At the same time, Levy and Goldberg (2014a) propose a modification of skip-gram that uses a dependency-based context instead of a sliding windows, which produces embeddings that are more tailored towards genuine similarity than relatedness. Bansal et al. (2014) follow a similar approach to train specialized embeddings that are used as features for dependency parsing. Finally, Mitchell and Steedman (2015) exploit morphology and word order information to learn embeddings that decompose into orthogonal • Supervised systems tha"
K18-1028,Q17-1010,0,0.686075,"refer to these two aspects as the two axes of similarity with two ends each: the semantics/syntax axis and the similarity/relatedness axis. In this paper, we propose a new method to tailor any given set of embeddings towards a specific end in these axes. Our method is inspired by the work on first order and second order cooccurrences (Sch¨utze, 1998), generalized as a continuous parameter of a linear transformation applied to the embeddings that we call similarity order. While there have been several proposals to learn specialized word embeddings (Levy and Goldberg, 2014a; Kiela et al., 2015; Bojanowski et al., 2017), previous work explicitly altered the training objective and often relied on external resources like knowledge bases, whereas the proposed method is applied as a post-processing of any pre-trained embedding model and does not require any additional resource. As such, our work shows that standard embedding models are able to encode divergent linguistic information but have limits on how this information is surfaced, and analyzes the implications that this has in both intrinsic evaluation and downstream tasks. This paper makes the following contributions: Following the recent success of word em"
K18-1028,P12-1015,0,0.0326848,"3). On the other hand, word similarity measures the correlation6 between the similarity scores produced by a model and a gold standard created by human annotators for a given set of word pairs. As discussed before, there is not a single definition of what human similarity scores should capture, which has lead to a distinction between genuine similarity datasets and relatedness datasets. In order to better understand the effect of our postprocessing in each case, we conduct our experiments in SimLex-999 (Hill et al., 2015), a genuine similarity dataset that consists of 999 word pairs, and MEN (Bruni et al., 2012), a relatedness dataset that consists of 3,000 word pairs7 . So as to make our evaluation more robust, we run the above experiments for three popular embedding methods, using large pre-trained models released by their respective authors as follows: Word2vec (Mikolov et al., 2013) is the original implementation of the CBOW and skip-gram architectures that popularized neural word embeddings. We use the pre-trained model published in the project homepage8 , which was trained on about 100 billion words of the Google News dataset and consists of 300-dimensional vectors for 3 million words and phras"
K18-1028,P17-1007,0,0.0146493,"duction Word embeddings have recently become a central topic in natural language processing. Several unsupervised methods have been proposed to efficiently train dense vector representations of words (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017) and successfully applied in a variety of tasks like parsing (Bansal et al., 2014), topic modeling (Batmanghelich et al., 2016) and document classification (Taddy, 2015). While there is still an active research line to better understand these models from a theoretical perspective (Levy and Goldberg, 2014c; Arora et al., 2016; Gittens et al., 2017), the fundamental idea behind all of them is to assign a similar vector representation to similar words. For that purpose, most embedding models build upon co-occurrence statistics from large monolingual corpora, following the distributional hypothesis that similar words tend to occur in similar contexts (Harris, 1954). Nevertheless, the above argument does not formalize what “similar words” means, and it is not 1. We propose a linear transformation with a free parameter that adjusts the perfor1 Also referred to as functional similarity or just similarity. Also referred to as associative simil"
K18-1028,J06-1003,0,0.415197,"et al., 2017)13 . This task is akin to word similarity, but instead of assessing the similarity of individual word pairs, it is the similarity of entire sentence pairs as scored by the model that is compared against the gold standard produced by human annotators14 . This evaluation is attractive for our purposes because, while the state-of-the-art systems are supervised and based on elaborated deep learning or feature engineer13 http://ixa2.si.ehu.es/stswiki/index. php/STSbenchmark 14 Following common practice, we report Pearson. 12 Agreeing with the fact that relatedness subsumes similarity (Budanitsky and Hirst, 2006) 286 Centroid DAM word2vec Original Best 65.77 66.43 α = -0.30 72.65 73.08 α = 0.10 glove Original Best 64.54 68.96 α = -0.50 74.89 76.36 α = -0.70 fasttext Original Best 69.84 70.74 α = -0.20 77.33 77.33 α = 0.00 Table 2: Results in semantic textual similarity as measured by Pearson correlation for the original embeddings and the best post-processed model with the corresponding value of α. The DAM scores are averaged across 10 runs. word2vec glove fasttext Pearson correlation 80 70 ●● ●● ●● ● ● ● ●● ●●●●●●● ● ● ●● ●● ● ●● ●●● ●● ●●●● ● ● ●● ● ● ● ● ●●● ●● ●●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● M"
K18-1028,J15-4004,0,0.0733024,"at the transformation can be smoothly adjusted to the desired level. 3 (Mikolov et al., 2013). On the other hand, word similarity measures the correlation6 between the similarity scores produced by a model and a gold standard created by human annotators for a given set of word pairs. As discussed before, there is not a single definition of what human similarity scores should capture, which has lead to a distinction between genuine similarity datasets and relatedness datasets. In order to better understand the effect of our postprocessing in each case, we conduct our experiments in SimLex-999 (Hill et al., 2015), a genuine similarity dataset that consists of 999 word pairs, and MEN (Bruni et al., 2012), a relatedness dataset that consists of 3,000 word pairs7 . So as to make our evaluation more robust, we run the above experiments for three popular embedding methods, using large pre-trained models released by their respective authors as follows: Word2vec (Mikolov et al., 2013) is the original implementation of the CBOW and skip-gram architectures that popularized neural word embeddings. We use the pre-trained model published in the project homepage8 , which was trained on about 100 billion words of t"
K18-1028,D15-1242,0,0.0521454,"Missing"
K18-1028,S17-2001,1,0.781404,"similarity order with our post-processing, as both models get practically the same results with differences below 0.1 points. At the same time, although less pronounced than with semantic/syntactic analogies12 , the results show clear differences in the optimal configurations for genuine similarity (SimLex-999) and relatedness (MEN), with smaller values of α (i.e. lower similarity levels) favoring the former. 4 Extrinsic evaluation In order to better understand the effect of the proposed post-processing in downstream systems, we adopt the STS Benchmark dataset on semantic textual similarity (Cer et al., 2017)13 . This task is akin to word similarity, but instead of assessing the similarity of individual word pairs, it is the similarity of entire sentence pairs as scored by the model that is compared against the gold standard produced by human annotators14 . This evaluation is attractive for our purposes because, while the state-of-the-art systems are supervised and based on elaborated deep learning or feature engineer13 http://ixa2.si.ehu.es/stswiki/index. php/STSbenchmark 14 Following common practice, we report Pearson. 12 Agreeing with the fact that relatedness subsumes similarity (Budanitsky an"
K18-1028,P14-2050,0,0.480599,"in sing - singing) (Mikolov et al., 2013). We refer to these two aspects as the two axes of similarity with two ends each: the semantics/syntax axis and the similarity/relatedness axis. In this paper, we propose a new method to tailor any given set of embeddings towards a specific end in these axes. Our method is inspired by the work on first order and second order cooccurrences (Sch¨utze, 1998), generalized as a continuous parameter of a linear transformation applied to the embeddings that we call similarity order. While there have been several proposals to learn specialized word embeddings (Levy and Goldberg, 2014a; Kiela et al., 2015; Bojanowski et al., 2017), previous work explicitly altered the training objective and often relied on external resources like knowledge bases, whereas the proposed method is applied as a post-processing of any pre-trained embedding model and does not require any additional resource. As such, our work shows that standard embedding models are able to encode divergent linguistic information but have limits on how this information is surfaced, and analyzes the implications that this has in both intrinsic evaluation and downstream tasks. This paper makes the following contrib"
K18-1028,J98-1004,0,0.487558,"Missing"
K18-1028,P15-2008,0,0.0222492,"n between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones. 1 Introduction Word embeddings have recently become a central topic in natural language processing. Several unsupervised methods have been proposed to efficiently train dense vector representations of words (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017) and successfully applied in a variety of tasks like parsing (Bansal et al., 2014), topic modeling (Batmanghelich et al., 2016) and document classification (Taddy, 2015). While there is still an active research line to better understand these models from a theoretical perspective (Levy and Goldberg, 2014c; Arora et al., 2016; Gittens et al., 2017), the fundamental idea behind all of them is to assign a similar vector representation to similar words. For that purpose, most embedding models build upon co-occurrence statistics from large monolingual corpora, following the distributional hypothesis that similar words tend to occur in similar contexts (Harris, 1954). Nevertheless, the above argument does not formalize what “similar words” means, and it is not 1. W"
K18-1028,W14-1618,0,0.4753,"in sing - singing) (Mikolov et al., 2013). We refer to these two aspects as the two axes of similarity with two ends each: the semantics/syntax axis and the similarity/relatedness axis. In this paper, we propose a new method to tailor any given set of embeddings towards a specific end in these axes. Our method is inspired by the work on first order and second order cooccurrences (Sch¨utze, 1998), generalized as a continuous parameter of a linear transformation applied to the embeddings that we call similarity order. While there have been several proposals to learn specialized word embeddings (Levy and Goldberg, 2014a; Kiela et al., 2015; Bojanowski et al., 2017), previous work explicitly altered the training objective and often relied on external resources like knowledge bases, whereas the proposed method is applied as a post-processing of any pre-trained embedding model and does not require any additional resource. As such, our work shows that standard embedding models are able to encode divergent linguistic information but have limits on how this information is surfaced, and analyzes the implications that this has in both intrinsic evaluation and downstream tasks. This paper makes the following contrib"
K18-1028,P15-1126,0,0.0175944,"in certain linguistic aspects. For instance, Kiela et al. (2015) use a joint-learning approach and two variants of retrofitting (Faruqui et al., 2015a) to specialize word embeddings for either similarity or relatedness. At the same time, Levy and Goldberg (2014a) propose a modification of skip-gram that uses a dependency-based context instead of a sliding windows, which produces embeddings that are more tailored towards genuine similarity than relatedness. Bansal et al. (2014) follow a similar approach to train specialized embeddings that are used as features for dependency parsing. Finally, Mitchell and Steedman (2015) exploit morphology and word order information to learn embeddings that decompose into orthogonal • Supervised systems that use pre-trained em288 clude that most intrinsic evaluations are poor predictors of downstream performance. In relation to that, our work explains how embeddings encode divergent linguistic information and the different effect this has in intrinsic evaluation and downstream tasks, showing that the proposed postprocessing can be easily used together with any intrinsic evaluation benchmark to get a more complete picture of the representations learned. semantic and syntactic"
K18-1028,D16-1244,0,0.0731773,"Missing"
K18-1028,D14-1162,0,0.108493,"out any external resource can tailor it to achieve better results in those aspects, providing a new perspective on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones. 1 Introduction Word embeddings have recently become a central topic in natural language processing. Several unsupervised methods have been proposed to efficiently train dense vector representations of words (Mikolov et al., 2013; Pennington et al., 2014; Bojanowski et al., 2017) and successfully applied in a variety of tasks like parsing (Bansal et al., 2014), topic modeling (Batmanghelich et al., 2016) and document classification (Taddy, 2015). While there is still an active research line to better understand these models from a theoretical perspective (Levy and Goldberg, 2014c; Arora et al., 2016; Gittens et al., 2017), the fundamental idea behind all of them is to assign a similar vector representation to similar words. For that purpose, most embedding models build upon co-occurrence statistics from large monolingual corpora, following th"
K18-1028,N16-1091,0,0.0386432,"Missing"
K18-1028,P16-2083,0,0.0590185,"Missing"
K18-1028,P13-2087,0,\N,Missing
L16-1351,W06-2810,0,0.0867338,"Missing"
L16-1351,W15-3402,0,0.0292475,"Missing"
L16-1351,W09-0432,0,0.0377943,"rpus in more than 2 BLEU points when translating texts from the Computer Science domain. Keywords: machine translation, domain adaptation, Wikipedia 1. 2. Introduction Domain adaptation has recently gained interest within statistical machine translation (SMT) as a way to cope with the performance drop observed when testing conditions deviate from training conditions. The basic idea is that indomain training data can be exploited to adapt all components of an already developed system. However, previous work showed small performance gains after adaptation using limited in-domain bilingual data (Bertoldi and Federico (2009), Daum´e III and Jagarlamudi (2011)). Our system is based on enriching a state-of-the-art SMT system with in-domain parallel corpora extracted from Wikipedia. We carried out an evaluation with a double objective: to evaluate the quality of the extracted data and to evaluate the improvement from the domain-adaptation method. We think this kind of domain adaptation can be very useful for languages with limited amount of parallel corpora, where in-domain data is crucial to improve the performance of MT. As a previous step, comparable corpora were extracted from Wikipedia using a graph-based selec"
L16-1351,2014.eamt-1.26,0,0.0575471,"4,707 132,159 720,715 4,537 53,919 9,796 90,992 517 3,014 141,955 811,707 5,054 56,933 Table 4: Size of the en-es parallel corpora obtained from fragments of the articles. System Sentences tokens Table 5: Size of the parallel corpora used in the baseline SMT systems. System Sentences tokens Computer Sc. en es 508,789 10,908,611 11,622,143 Europarl en es 1,965,734 55,031,614 57,139,119 Comp. Sc. and Science en es 4,522,339 85,899,900 93,160,232 Elhuyar en eu 1,290,501 16,280,750 14,952,275 4.1. Experimental Setup: Corpora The evaluation corpus is the development set used in the QTLeap project (Branco and Osenova, 2014; Agirre et al., 2015). The QTLeap project (Quality Translation by Deep Language Engineering Approaches) is a collaborative project that aims to produce high-quality outbound Machine Translation using deep language engineering approaches to achieve higher quality translations. The evaluation bench used in that project was provided by Higher Functions, and is based on applying Machine Translation to allow multilingual “online consultancy” which handles common problems in computer use. On the multilingual configuration of this application, users ask their questions in their own language. The sys"
L16-1351,P11-2071,0,0.0407407,"Missing"
L16-1351,W13-2509,0,0.0286732,"ology used to extract comparable corpora from Wikipedia. In Section 4 we describe how the parallel subcorpora obtained from them are used to feed the SMT translators, which are then evaluated. Finally, we draw the conclusions and show how this work is being continued. Related work Some effort has been devoted to improving MT using Wikipedia but generally domain-related parallel corpora from Wikipedia are not identified and only small units, mainly named-entities, are used. Wikipedia has been used mainly just with the aim of augmenting dictionaries (Jones et al. (2008), Nothman et al. (2013)). Gupta et al. (2013)) extract parallel fragments of texts from a comparable corpus built from Wikipedia documents, but they do it in general, without restriction to an specific domain. They improve the performance of an existing machine translation system. Looking at the problem of extracting parallel sentences from Wikipedia Adafre and De Rijke (2006) described two methods to extract parallel (similar) sentences directly. Patry and Langlais (2011) use a classifier with contentbased features (hapax words, numerical entities and punctuation marks) to extract parallel corpora from Wikipedia. The toolkit Accurat can"
L16-1351,I08-6005,0,0.0244405,"from Barr´on-Cede˜no et al. (2015) the methodology used to extract comparable corpora from Wikipedia. In Section 4 we describe how the parallel subcorpora obtained from them are used to feed the SMT translators, which are then evaluated. Finally, we draw the conclusions and show how this work is being continued. Related work Some effort has been devoted to improving MT using Wikipedia but generally domain-related parallel corpora from Wikipedia are not identified and only small units, mainly named-entities, are used. Wikipedia has been used mainly just with the aim of augmenting dictionaries (Jones et al. (2008), Nothman et al. (2013)). Gupta et al. (2013)) extract parallel fragments of texts from a comparable corpus built from Wikipedia documents, but they do it in general, without restriction to an specific domain. They improve the performance of an existing machine translation system. Looking at the problem of extracting parallel sentences from Wikipedia Adafre and De Rijke (2006) described two methods to extract parallel (similar) sentences directly. Patry and Langlais (2011) use a classifier with contentbased features (hapax words, numerical entities and punctuation marks) to extract parallel co"
L16-1351,W11-1212,0,0.018313,"only small units, mainly named-entities, are used. Wikipedia has been used mainly just with the aim of augmenting dictionaries (Jones et al. (2008), Nothman et al. (2013)). Gupta et al. (2013)) extract parallel fragments of texts from a comparable corpus built from Wikipedia documents, but they do it in general, without restriction to an specific domain. They improve the performance of an existing machine translation system. Looking at the problem of extracting parallel sentences from Wikipedia Adafre and De Rijke (2006) described two methods to extract parallel (similar) sentences directly. Patry and Langlais (2011) use a classifier with contentbased features (hapax words, numerical entities and punctuation marks) to extract parallel corpora from Wikipedia. The toolkit Accurat can be applied to Wikipedia to extract a general comparable corpus, operating on different levels (Pinnis et al., 2012). Similarly, CorpusPedia (Otero and L´opez, 2010) is a tool to extract comparable corpora from Wikipedia by considering a pair of languages and a category. For our aim we decided to use and evaluate the proposal from Barr´on-Cede˜no et al. (2015), since their method allows us to exploit the category graph informati"
L16-1351,P12-3016,0,0.0604147,"Missing"
L16-1351,zesch-etal-2008-extracting,0,0.0261406,"Missing"
L18-1397,W04-0407,0,0.0249872,"ate extraction (Ramisch, 2015) – mainly for lexicographic purposes– or identification of MWE occurrences in corpora (Savary et al., 2017). However, some research has also been conducted into improving Machine Translation (MT) quality by enhancing MWE processing (Kordoni and Simova, 2014; Seretan, 2014). Meanwhile, a considerable amount of resources have been created for several languages, including MWE lists, lexicons and MWE-annotated treebanks (Losnegaard et al., 2016). Concerning Basque phraseology, research has been done both to describe some linguistic phenomena and to develop NLP tools (Alegria et al., 2004; Gurrutxaga and Alegria, 2012), but researchers have had an almost exclusively monolingual perspective. Thus, our aim is, on the one hand, to analyse how MWEs are translated, and, on the other hand, to propose a method to improve their computational treatment in bilingual tools. The MWEs in the database were gathered from two main sources: the Elhuyar Spanish-Basque and Basque-Spanish dictionaries1 and the DiCE dictionary of Spanish collocations2 (Vincze et al., 2011). However, the detabase being part of an ongoing project, additional sources will probably be used in the future, such as a lis"
L18-1397,W11-0802,0,0.0285918,"ly monolingual perspective. Thus, our aim is, on the one hand, to analyse how MWEs are translated, and, on the other hand, to propose a method to improve their computational treatment in bilingual tools. The MWEs in the database were gathered from two main sources: the Elhuyar Spanish-Basque and Basque-Spanish dictionaries1 and the DiCE dictionary of Spanish collocations2 (Vincze et al., 2011). However, the detabase being part of an ongoing project, additional sources will probably be used in the future, such as a list of Basque MWEs extracted from corpora by using Gurrutxaga et al.’s method (Gurrutxaga and Alegria, 2011). NLP-applicable linguistic information was added afterwards. As this was done in several phases, the amount of linguistic data provided varies from one MWE to another. More information about the analysis will be given in the following paragraphs. 2.1. Verb+Noun MWEs in Spanish and Basque Whereas Spanish is a romance language, Basque is a non-indoeuropean language which does not belong to any known family. Their typological features are very different: In this paper, we will present Konbitzul, a database of verb+noun MWEs in Spanish and Basque. As well 2500 • Spanish is SVO-ordered, head-initi"
L18-1397,gurrutxaga-alegria-2012-measuring,0,0.0157038,"h, 2015) – mainly for lexicographic purposes– or identification of MWE occurrences in corpora (Savary et al., 2017). However, some research has also been conducted into improving Machine Translation (MT) quality by enhancing MWE processing (Kordoni and Simova, 2014; Seretan, 2014). Meanwhile, a considerable amount of resources have been created for several languages, including MWE lists, lexicons and MWE-annotated treebanks (Losnegaard et al., 2016). Concerning Basque phraseology, research has been done both to describe some linguistic phenomena and to develop NLP tools (Alegria et al., 2004; Gurrutxaga and Alegria, 2012), but researchers have had an almost exclusively monolingual perspective. Thus, our aim is, on the one hand, to analyse how MWEs are translated, and, on the other hand, to propose a method to improve their computational treatment in bilingual tools. The MWEs in the database were gathered from two main sources: the Elhuyar Spanish-Basque and Basque-Spanish dictionaries1 and the DiCE dictionary of Spanish collocations2 (Vincze et al., 2011). However, the detabase being part of an ongoing project, additional sources will probably be used in the future, such as a list of Basque MWEs extracted from"
L18-1397,C16-1082,1,0.884294,"Missing"
L18-1397,W17-1720,1,0.782418,"Missing"
L18-1397,kordoni-simova-2014-multiword,0,0.0131825,"ons). EN: take off ES: alzar el vuelo lit. raise the flight EU: aireratu lit. go-to-the-air Although interest in Phraseology has a longer history, studies on MWEs have multiplied considerably over the last two decades (Baldwin and Kim, 2010; Savary et al., 2015). Most of the work undertaken within the field of NLP focuses on MWE candidate extraction (Ramisch, 2015) – mainly for lexicographic purposes– or identification of MWE occurrences in corpora (Savary et al., 2017). However, some research has also been conducted into improving Machine Translation (MT) quality by enhancing MWE processing (Kordoni and Simova, 2014; Seretan, 2014). Meanwhile, a considerable amount of resources have been created for several languages, including MWE lists, lexicons and MWE-annotated treebanks (Losnegaard et al., 2016). Concerning Basque phraseology, research has been done both to describe some linguistic phenomena and to develop NLP tools (Alegria et al., 2004; Gurrutxaga and Alegria, 2012), but researchers have had an almost exclusively monolingual perspective. Thus, our aim is, on the one hand, to analyse how MWEs are translated, and, on the other hand, to propose a method to improve their computational treatment in bil"
L18-1397,L16-1364,0,0.0587801,"Missing"
L18-1397,padro-stanilovsky-2012-freeling,0,0.0581965,"Missing"
L18-1397,P02-1040,0,0.102662,"Missing"
L18-1397,W17-1704,0,0.0997271,"). It currently comprises 3,195 Spanish verb+noun MWEs (along with 7,132 translations) and 2,954 Basque noun+verb MWEs (along with 6,392 translations). EN: take off ES: alzar el vuelo lit. raise the flight EU: aireratu lit. go-to-the-air Although interest in Phraseology has a longer history, studies on MWEs have multiplied considerably over the last two decades (Baldwin and Kim, 2010; Savary et al., 2015). Most of the work undertaken within the field of NLP focuses on MWE candidate extraction (Ramisch, 2015) – mainly for lexicographic purposes– or identification of MWE occurrences in corpora (Savary et al., 2017). However, some research has also been conducted into improving Machine Translation (MT) quality by enhancing MWE processing (Kordoni and Simova, 2014; Seretan, 2014). Meanwhile, a considerable amount of resources have been created for several languages, including MWE lists, lexicons and MWE-annotated treebanks (Losnegaard et al., 2016). Concerning Basque phraseology, research has been done both to describe some linguistic phenomena and to develop NLP tools (Alegria et al., 2004; Gurrutxaga and Alegria, 2012), but researchers have had an almost exclusively monolingual perspective. Thus, our ai"
L18-1557,W15-1007,1,0.838381,"as it can be seen Tables 6 and 7. en de it es Precision 70.00 68.40 67.03 55.66 Recall 60.34 39.24 62.45 59.69 F1 64.81 49.87 64.66 57.60 Table 6: Evaluating Gold-standard trained CoNLL and Evalita models on Europarl test. Still, and even though our first results are quite promising, we should note that the results of the automatically generated models are much lower than those established by the upper-bound. 5. Related Work Traditionally, there are many studies and works exploring the contribution of semantic information or features with the aim of improving Machine Translation (Koehn, 2010; Artetxe et al., 2015) but the reverse has been rather uncommon. Among previous works using parallel texts to automatically induce linguistic processors, most of them focus on inducing Part of Speech taggers (Yarowsky et al., 2001; Precision 70.30 78.87 75.14 80.29 Recall 68.01 63.94 53.41 53.42 F1 69.14 70.62 62.44 64.16 Table 7: Evaluating models trained on automatically projected data. Ganchev and Das, 2013; T¨ackstr¨om et al., 2012; Fossum and Abney, 2005) although a very few of them worked on semantic tasks such as Named Entity Recognition (NER) (Yarowsky et al., 2001; Zhang et al., 2016) and Semantic Role Lab"
L18-1557,P11-1061,0,0.075948,"target language. Therefore, to our knowledge, no previous approach aims at doing transfer of semantic annotations as we propose in this paper. These previous works based on projection of annotations have shown that the projected labels can result in a very noisy training set in the target language. Various methods have been applied to address this problem, including smoothing techniques (Yarowsky et al., 2001) and the combination of token-level and type-level constraints to recalculate the probability distribution of the labels in a CRF for Part of Speech tagging (T¨ackstr¨om et al., 2012). (Das and Petrov, 2011) use the projected labels as contraints in a Posterior Regularization framework and (Ganchev and Das, 2013) extend this work by training directly discriminative models via cross lingual projection with Posterior Regularization. Finally, instead of using total counts of labels of a class to enforce the constraints, (Wang and Manning, 2014) define expectation constraints at token level for NERC. Closest to our work, Zhang et al. (2016) generate a highconfidence annotation set using strict rules on parallel corpora in order to project the Named Entity information from the source to the target. Th"
L18-1557,I05-1075,0,0.13152,"Missing"
L18-1557,D13-1205,0,0.0950755,"d by the upper-bound. 5. Related Work Traditionally, there are many studies and works exploring the contribution of semantic information or features with the aim of improving Machine Translation (Koehn, 2010; Artetxe et al., 2015) but the reverse has been rather uncommon. Among previous works using parallel texts to automatically induce linguistic processors, most of them focus on inducing Part of Speech taggers (Yarowsky et al., 2001; Precision 70.30 78.87 75.14 80.29 Recall 68.01 63.94 53.41 53.42 F1 69.14 70.62 62.44 64.16 Table 7: Evaluating models trained on automatically projected data. Ganchev and Das, 2013; T¨ackstr¨om et al., 2012; Fossum and Abney, 2005) although a very few of them worked on semantic tasks such as Named Entity Recognition (NER) (Yarowsky et al., 2001; Zhang et al., 2016) and Semantic Role Labelling (SRL) (Pad´o and Lapata, 2009). Furthermore, almost every previous approach is based on one-to-one projections using only one language pair to induce the linguistic processors. As far as we know, there are only two exceptions: Yarowsky et al. (2001) use bridging between two languages to perform lemmatization in a third target language, and Fossum and Abney (2005) train multiple POS"
L18-1557,2005.mtsummit-papers.11,0,0.0784197,"c (Agerri and Rigau, 2016). It is designed to work robustly across languages and datasets and it obtains state of the art results for the languages used in this study. We also use the following corpora: 1. Gold standard data for training the initial ixa-pipe-nerc models for the source languages. CoNLL 2002 and 2003 for German, English and Spanish, and Evalita 2009 for Italian. Both CoNLL and Evalita annotate the three entity types (location, organization and person) that we will use to induce our training data. 2. The Europarl parallel corpus on which to perform the cross-lingual projections (Koehn, 2005), word-aligned using Giza++ (Och and Ney, 2000) and divided into a training and a test set. 3. The Europarl gold-standard test set is a new manuallyannotated evaluation set taken from the Europarl. The test set contains 800 sentences manually annotated using the three entity types and following the CoNLL 2002 and 2003 guidelines for the 4 languages used in this paper. 4. Back-off corpora to resolve ties in the projection step. The idea is to compute the most frequent tag of a token in a large NER annotated resource. Thus, in case of ties during the annotation projection the most frequent entit"
L18-1557,J10-4005,0,0.0340331,"for German, as it can be seen Tables 6 and 7. en de it es Precision 70.00 68.40 67.03 55.66 Recall 60.34 39.24 62.45 59.69 F1 64.81 49.87 64.66 57.60 Table 6: Evaluating Gold-standard trained CoNLL and Evalita models on Europarl test. Still, and even though our first results are quite promising, we should note that the results of the automatically generated models are much lower than those established by the upper-bound. 5. Related Work Traditionally, there are many studies and works exploring the contribution of semantic information or features with the aim of improving Machine Translation (Koehn, 2010; Artetxe et al., 2015) but the reverse has been rather uncommon. Among previous works using parallel texts to automatically induce linguistic processors, most of them focus on inducing Part of Speech taggers (Yarowsky et al., 2001; Precision 70.30 78.87 75.14 80.29 Recall 68.01 63.94 53.41 53.42 F1 69.14 70.62 62.44 64.16 Table 7: Evaluating models trained on automatically projected data. Ganchev and Das, 2013; T¨ackstr¨om et al., 2012; Fossum and Abney, 2005) although a very few of them worked on semantic tasks such as Named Entity Recognition (NER) (Yarowsky et al., 2001; Zhang et al., 2016"
L18-1557,N06-1014,0,0.0848064,"d is generally inefficiently slow and, in most cases, unaffordable in terms of human resources and economic costs. Instead, we would like to be able to use already available semantic processors and texts in other languages to get a good statistical model for a new target language. Our method leverages existing semantic processors and annotations to overcome the lack of annotation data for a given language. The intuition is to transfer or project semantic annotations, from multiple sources to a target language, by statistical word alignment methods applied to parallel texts (Och and Ney, 2000; Liang et al., 2006). The projected annotations could then be used to automatically generate semantic processors for the target language. In this way we would be able to provide semantic processors without training data for a given language. Thus, this means that the problem can be decomposed into two smaller inter-related ones: (i) How to project semantic annotations across languages via parallel texts with a sufficient acceptable quality to train semi- or weakly-supervised semantic processors and (ii) how to effectively leverage the (potentially noisy) projected annotations to induce robust statistical models t"
L18-1557,N12-1052,0,0.124453,"Missing"
L18-1557,W03-0419,0,0.410018,"Missing"
L18-1557,W02-2024,0,0.5864,"Missing"
L18-1557,Q14-1005,0,0.0174165,"address this problem, including smoothing techniques (Yarowsky et al., 2001) and the combination of token-level and type-level constraints to recalculate the probability distribution of the labels in a CRF for Part of Speech tagging (T¨ackstr¨om et al., 2012). (Das and Petrov, 2011) use the projected labels as contraints in a Posterior Regularization framework and (Ganchev and Das, 2013) extend this work by training directly discriminative models via cross lingual projection with Posterior Regularization. Finally, instead of using total counts of labels of a class to enforce the constraints, (Wang and Manning, 2014) define expectation constraints at token level for NERC. Closest to our work, Zhang et al. (2016) generate a highconfidence annotation set using strict rules on parallel corpora in order to project the Named Entity information from the source to the target. The resulting annotated bitext is then used to train a LSTM model. They evaluate their work with respect to a baseline consisting of the projected tags via automatic word alignments. The results show that the word alignment method is much worse than the bitext trained LSTM model. It should be noted that they do not explain how the annotatio"
L18-1557,H01-1035,0,0.59009,"Europarl test. Still, and even though our first results are quite promising, we should note that the results of the automatically generated models are much lower than those established by the upper-bound. 5. Related Work Traditionally, there are many studies and works exploring the contribution of semantic information or features with the aim of improving Machine Translation (Koehn, 2010; Artetxe et al., 2015) but the reverse has been rather uncommon. Among previous works using parallel texts to automatically induce linguistic processors, most of them focus on inducing Part of Speech taggers (Yarowsky et al., 2001; Precision 70.30 78.87 75.14 80.29 Recall 68.01 63.94 53.41 53.42 F1 69.14 70.62 62.44 64.16 Table 7: Evaluating models trained on automatically projected data. Ganchev and Das, 2013; T¨ackstr¨om et al., 2012; Fossum and Abney, 2005) although a very few of them worked on semantic tasks such as Named Entity Recognition (NER) (Yarowsky et al., 2001; Zhang et al., 2016) and Semantic Role Labelling (SRL) (Pad´o and Lapata, 2009). Furthermore, almost every previous approach is based on one-to-one projections using only one language pair to induce the linguistic processors. As far as we know, there"
L18-1557,C16-1045,0,0.0988997,"ation (Koehn, 2010; Artetxe et al., 2015) but the reverse has been rather uncommon. Among previous works using parallel texts to automatically induce linguistic processors, most of them focus on inducing Part of Speech taggers (Yarowsky et al., 2001; Precision 70.30 78.87 75.14 80.29 Recall 68.01 63.94 53.41 53.42 F1 69.14 70.62 62.44 64.16 Table 7: Evaluating models trained on automatically projected data. Ganchev and Das, 2013; T¨ackstr¨om et al., 2012; Fossum and Abney, 2005) although a very few of them worked on semantic tasks such as Named Entity Recognition (NER) (Yarowsky et al., 2001; Zhang et al., 2016) and Semantic Role Labelling (SRL) (Pad´o and Lapata, 2009). Furthermore, almost every previous approach is based on one-to-one projections using only one language pair to induce the linguistic processors. As far as we know, there are only two exceptions: Yarowsky et al. (2001) use bridging between two languages to perform lemmatization in a third target language, and Fossum and Abney (2005) train multiple POS taggers from monolingual source data and combine their annotations to project them to a given target language. Therefore, to our knowledge, no previous approach aims at doing transfer of"
P17-1042,D16-1250,1,0.740024,"XA NLP group University of the Basque Country (UPV/EHU) {mikel.artetxe,gorka.labaka,e.agirre}@ehu.eus Abstract 2015; Vuli´c and Moens, 2016; Mogadala and Rettinger, 2016), but large amounts of such corpora are not always available for some language pairs. An alternative approach that we follow here is to independently train the embeddings for each language on monolingual corpora, and then learn a linear transformation to map the embeddings from one space into the other by minimizing the distances in a bilingual dictionary, usually in the range of a few thousand entries (Mikolov et al., 2013a; Artetxe et al., 2016). However, dictionaries of that size are not readily available for many language pairs, specially those involving less-resourced languages. In this work, we reduce the need of large bilingual dictionaries to much smaller seed dictionaries. Our method can work with as little as 25 word pairs, which are straightforward to obtain assuming some basic knowledge of the languages involved. The method can also work with trivially generated seed dictionaries of numerals (i.e. 1-1, 2-2, 3-3, 4-4...) making it possible to learn bilingual word embeddings without any real bilingual data. In either case, we"
P17-1042,C12-1089,0,0.55408,"sults comparable to those of systems that use richer resources. 1 Introduction Multilingual word embeddings have attracted a lot of attention in recent times. In addition to having a direct application in inherently crosslingual tasks like machine translation (Zou et al., 2013) and crosslingual entity linking (Tsai and Roth, 2016), they provide an excellent mechanism for transfer learning, where a model trained in a resource-rich language is transferred to a less-resourced one, as shown with part-of-speech tagging (Zhang et al., 2016), parsing (Xiao and Guo, 2014) and document classification (Klementiev et al., 2012). Most methods to learn these multilingual word embeddings make use of large parallel corpora (Gouws et al., 2015; Luong et al., 2015), but there have been several proposals to relax this requirement, given its scarcity in most language pairs. A possible relaxation is to use document-aligned or label-aligned comparable corpora (Søgaard et al., 451 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 451–462 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1042 D = 1-a, 2-b, 3-"
P17-1042,P15-2001,0,0.0192163,"thods, as statistical word alignment already provides a reliable way to derive dictionaries from bilingual corpora and, in fact, this is how the test dictionary itself is built in our case. For that reason, we carried out some experiments in crosslingual word similarity as a way to test our method in a different task and allowing to compare it to systems that use richer bilingual data. There are no many crosslingual word similarity datasets, and we used the RG-65 and WordSim353 crosslingual datasets for English-German and the WordSim-353 crosslingual dataset for EnglishItalian as published by Camacho-Collados et al. (2015) 5 . As for the convergence criterion, we decide to stop training when the improvement on the average dot product for the induced dictionary falls below a given threshold from one iteration to the next. After length normalization, the dot product ranges from -1 to 1, so we decide to set this threshold at 1e-6, which we find to be a very conservative value yet enough that training takes a reasonable amount of time. The curves in the next section confirm that this was a reasonable choice. This convergence criterion is usually met in less than 100 iterations, each of them taking 5 minutes on a mo"
P17-1042,P15-1027,0,0.494067,"embedding space into the other based on a bilingual dictionary. The first of such methods is due to Mikolov et al. (2013a), who learn the linear transformation that minimizes the sum of squared Euclidean distances for the dictionary entries. The same optimization objective is used by Zhang et al. (2016), who constrain the transformation matrix to be orthogonal. Xing et al. (2015) incorporate length normalization in the training of word embeddings and maximize the cosine similarity instead, enforcing the orthogonality constraint to preserve the length normalization after the mapping. Finally, Lazaridou et al. (2015) use max-margin optimization with intruder negative sampling. Instead of learning a single linear transformation from the source language into the target language, Faruqui and Dyer (2014) use canonical correlation analysis to map both languages to a shared vector space. Lu et al. (2015) extend this work and apply deep canonical correlation analysis to learn non-linear transformations. Artetxe et al. (2016) propose a general framework that clarifies the relation between Mikolov et al. (2013a), Xing et al. (2015), Faruqui and Dyer (2014) and Zhang et al. (2016) as variants of the 2.2 Unsupervise"
P17-1042,N15-1028,0,0.233964,"Missing"
P17-1042,W15-1521,0,0.693593,"on in recent times. In addition to having a direct application in inherently crosslingual tasks like machine translation (Zou et al., 2013) and crosslingual entity linking (Tsai and Roth, 2016), they provide an excellent mechanism for transfer learning, where a model trained in a resource-rich language is transferred to a less-resourced one, as shown with part-of-speech tagging (Zhang et al., 2016), parsing (Xiao and Guo, 2014) and document classification (Klementiev et al., 2012). Most methods to learn these multilingual word embeddings make use of large parallel corpora (Gouws et al., 2015; Luong et al., 2015), but there have been several proposals to relax this requirement, given its scarcity in most language pairs. A possible relaxation is to use document-aligned or label-aligned comparable corpora (Søgaard et al., 451 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 451–462 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1042 D = 1-a, 2-b, 3-c, 4-x, 5-y D= 1-a, 2-b, 3-c. Learn W using D and rotate X Learn D using nearest neighbor W X Z XW XW and Z in same space Figure 1: A"
P17-1042,P15-1081,0,0.0214277,"nstructs the original embeddings, and a discriminator that distinguishes mapped embeddings from real target language embeddings, whereas the latter adds a regularization term to the training of word embeddings that pushes the mean and variance of each dimension in different languages close to each other. Although promising, the reported performance in both cases is poor in comparison to other methods. Finally, the induction of bilingual knowledge from monolingual corpora is closely related to the decipherment scenario, for which models that incorporate word embeddings have also been proposed (Dou et al., 2015). However, decipherment is only concerned with translating text from one language to another and relies on complex statistical models that are designed specifically for that purpose, while our approach is more general and learns task-independent multilingual embeddings. 453 3.2 duction method that we adopt in our work with these efficiency requirements in mind. 3.1 As discussed in Section 2.1, practically all previous work uses nearest neighbor retrieval for word translation induction based on embedding mappings. In nearest neighbor retrieval, each source language word is assigned the closest"
P17-1042,P14-5010,0,0.0043412,"training set. In addition to English-Italian, we selected two other languages from different language families with publicly available resources. We thus created analogous datasets for English-German and English-Finnish. In the case of German, the embeddings were trained on the 0.9 billion word corpus SdeWaC, which is part of the WaCky collection (Baroni et al., 2009) that was also used for English and Italian. Given that Finnish is not included in this collection, we used the 2.8 billion word Common Crawl corpus provided at WMT 20164 instead, which we tokenized using the Stanford Tokenizer (Manning et al., 2014). In addition to that, we created training and test sets for both pairs from their respective Europarl dictionaries from OPUS following the exact same procedure used for English-Italian, and the word embeddings were also trained using the same configuration as Dinu et al. (2015). Given that the main focus of our work is on small seed dictionaries, we created random subsets of 2,500, 1,000, 500, 250, 100, 75, 50 and 25 entries from the original training dictionaries of 5,000 entries. This was done by shuffling once the training dictionaries and taking their first k entries, so it is guaranteed"
P17-1042,E14-1049,0,0.645265,"squared Euclidean distances for the dictionary entries. The same optimization objective is used by Zhang et al. (2016), who constrain the transformation matrix to be orthogonal. Xing et al. (2015) incorporate length normalization in the training of word embeddings and maximize the cosine similarity instead, enforcing the orthogonality constraint to preserve the length normalization after the mapping. Finally, Lazaridou et al. (2015) use max-margin optimization with intruder negative sampling. Instead of learning a single linear transformation from the source language into the target language, Faruqui and Dyer (2014) use canonical correlation analysis to map both languages to a shared vector space. Lu et al. (2015) extend this work and apply deep canonical correlation analysis to learn non-linear transformations. Artetxe et al. (2016) propose a general framework that clarifies the relation between Mikolov et al. (2013a), Xing et al. (2015), Faruqui and Dyer (2014) and Zhang et al. (2016) as variants of the 2.2 Unsupervised and weakly supervised bilingual embeddings As mentioned before, our method works with as little as 25 word pairs, while the methods discussed previously use thousands of pairs. The only"
P17-1042,W16-1614,0,0.11667,"and the dictionary inA practical aspect for reducing the need of bilingual supervision is on the design of the seed dictionary. This is analyzed in depth by Vuli´c and Korhonen (2016), who propose using documentaligned corpora to extract the training dictionary. A more common approach is to rely on shared words and cognates (Peirsman and Pad´o, 2010; Smith et al., 2017), eliminating the need of bilingual data in practice. Our use of shared numerals exploits the same underlying idea, but relies on even less bilingual evidence and should thus generalize better to distant language pairs. Miceli Barone (2016) and Cao et al. (2016) go one step further and attempt to learn bilingual embeddings without any bilingual evidence. The former uses adversarial autoencoders (Makhzani et al., 2016), combining an encoder that maps the source language embeddings into the target language, a decoder that reconstructs the original embeddings, and a discriminator that distinguishes mapped embeddings from real target language embeddings, whereas the latter adds a regularization term to the training of word embeddings that pushes the mean and variance of each dimension in different languages close to each other. Alth"
P17-1042,P16-1157,0,0.0152688,"nish is a non-indoeuropean agglutinative language, making the task considerably more difficult for this language pair. In this regard, we believe that the good results with small dictionaries are a strong indication of the robustness of our method, showing that it is able to learn good bilingual mappings from very little bilingual ev4.3 Crosslingual word similarity In addition to the baseline systems in Section 4.2, in the crosslingual similarity experiments we also tested the method by Luong et al. (2015), which is the state-of-the-art for bilingual word embeddings based on parallel corpora (Upadhyay et al., 2016)6 . As this method is an extension of word2vec, we used the same hyperparameters as for the monolingual embeddings when possible (see Section 4.1), and leave the default ones otherwise. We used Europarl as our parallel corpus to train this method as done by the authors, which consists of nearly 2 million parallel sentences. As shown in the results in Table 2, our method obtains the best results in all cases, surpassing the rest of the dictionary-based methods by 1-3 points depending on the dataset. But, most importantly, it does not suffer from any significant degradation for using smaller dic"
P17-1042,P16-1024,0,0.257326,"Missing"
P17-1042,N16-1083,0,0.0241103,"Missing"
P17-1042,D13-1168,0,0.0117963,"Missing"
P17-1042,N10-1135,0,0.0831751,"Missing"
P17-1042,W14-1613,0,0.032603,"atically generated list of numerals, obtaining results comparable to those of systems that use richer resources. 1 Introduction Multilingual word embeddings have attracted a lot of attention in recent times. In addition to having a direct application in inherently crosslingual tasks like machine translation (Zou et al., 2013) and crosslingual entity linking (Tsai and Roth, 2016), they provide an excellent mechanism for transfer learning, where a model trained in a resource-rich language is transferred to a less-resourced one, as shown with part-of-speech tagging (Zhang et al., 2016), parsing (Xiao and Guo, 2014) and document classification (Klementiev et al., 2012). Most methods to learn these multilingual word embeddings make use of large parallel corpora (Gouws et al., 2015; Luong et al., 2015), but there have been several proposals to relax this requirement, given its scarcity in most language pairs. A possible relaxation is to use document-aligned or label-aligned comparable corpora (Søgaard et al., 451 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 451–462 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association for Computational Linguistics"
P17-1042,P15-1165,0,0.14311,"Missing"
P17-1042,N15-1104,0,0.751757,"earn bilingual word embeddings. 2.1 Bilingual embedding mappings Methods to induce bilingual mappings work by independently learning the embeddings in each language using monolingual corpora, and then learning a transformation from one embedding space into the other based on a bilingual dictionary. The first of such methods is due to Mikolov et al. (2013a), who learn the linear transformation that minimizes the sum of squared Euclidean distances for the dictionary entries. The same optimization objective is used by Zhang et al. (2016), who constrain the transformation matrix to be orthogonal. Xing et al. (2015) incorporate length normalization in the training of word embeddings and maximize the cosine similarity instead, enforcing the orthogonality constraint to preserve the length normalization after the mapping. Finally, Lazaridou et al. (2015) use max-margin optimization with intruder negative sampling. Instead of learning a single linear transformation from the source language into the target language, Faruqui and Dyer (2014) use canonical correlation analysis to map both languages to a shared vector space. Lu et al. (2015) extend this work and apply deep canonical correlation analysis to learn"
P17-1042,N16-1156,0,0.53192,"rd dictionary or even an automatically generated list of numerals, obtaining results comparable to those of systems that use richer resources. 1 Introduction Multilingual word embeddings have attracted a lot of attention in recent times. In addition to having a direct application in inherently crosslingual tasks like machine translation (Zou et al., 2013) and crosslingual entity linking (Tsai and Roth, 2016), they provide an excellent mechanism for transfer learning, where a model trained in a resource-rich language is transferred to a less-resourced one, as shown with part-of-speech tagging (Zhang et al., 2016), parsing (Xiao and Guo, 2014) and document classification (Klementiev et al., 2012). Most methods to learn these multilingual word embeddings make use of large parallel corpora (Gouws et al., 2015; Luong et al., 2015), but there have been several proposals to relax this requirement, given its scarcity in most language pairs. A possible relaxation is to use document-aligned or label-aligned comparable corpora (Søgaard et al., 451 Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 451–462 c Vancouver, Canada, July 30 - August 4, 2017. 2017 Association"
P17-1042,N15-1176,0,0.010847,"Missing"
P17-1042,D13-1141,0,0.0449556,"e need of bilingual resources using a very simple self-learning approach that can be combined with any dictionary-based mapping technique. Our method exploits the structural similarity of embedding spaces, and works with as little bilingual evidence as a 25 word dictionary or even an automatically generated list of numerals, obtaining results comparable to those of systems that use richer resources. 1 Introduction Multilingual word embeddings have attracted a lot of attention in recent times. In addition to having a direct application in inherently crosslingual tasks like machine translation (Zou et al., 2013) and crosslingual entity linking (Tsai and Roth, 2016), they provide an excellent mechanism for transfer learning, where a model trained in a resource-rich language is transferred to a less-resourced one, as shown with part-of-speech tagging (Zhang et al., 2016), parsing (Xiao and Guo, 2014) and document classification (Klementiev et al., 2012). Most methods to learn these multilingual word embeddings make use of large parallel corpora (Gouws et al., 2015; Luong et al., 2015), but there have been several proposals to relax this requirement, given its scarcity in most language pairs. A possible"
P17-1042,C16-1171,0,\N,Missing
P18-1073,E14-1049,0,0.457923,"methods work by independently training word embeddings in two languages, and then mapping them to a shared space using a linear transformation. Most of these methods are supervised, and use a bilingual dictionary of a few thousand entries to learn the mapping. Existing approaches can be classified into regression methods, which map the embeddings in one language using a leastsquares objective (Mikolov et al., 2013; Shigeto et al., 2015; Dinu et al., 2015), canonical methods, which map the embeddings in both languages to a shared space using canonical correlation analysis and extensions of it (Faruqui and Dyer, 2014; Lu et al., 2015), orthogonal methods, which map the embeddings in one or both languages under the constraint of the transformation being orthogonal (Xing et al., 2015; Artetxe et al., 2016; Zhang et al., 2016; Smith et al., 2017), and margin methods, which map the embeddings in one language to maximize the margin between the correct translations and the rest of the candidates (Lazaridou et al., 2015). Artetxe et al. (2018a) showed that many of them could be generalized as part of a multi-step framework of linear transformations. A related research line is to adapt these methods to the semi-s"
P18-1073,P15-1027,0,0.383442,"ngs (see Figure 1). We combine this initialization with a more robust self-learning method, which is able to start from the weak initial solution and iteratively improve the mapping. Coupled together, we provide a fully unsupervised crosslingual mapping method that is effective in realistic settings, converges to a good solution in all cases tested, and sets a new state-of-the-art in bilingual lexicon extraction, even surpassing previous supervised methods. Introduction Cross-lingual embedding mappings have shown to be an effective way to learn bilingual word embeddings (Mikolov et al., 2013; Lazaridou et al., 2015). The underlying idea is to independently train the embeddings in different languages using monolingual corpora, and then map them to a shared space through a linear transformation. This allows to learn high-quality cross-lingual representations without expensive supervision, opening new research avenues like unsupervised neural machine translation (Artetxe et al., 2018b; Lample et al., 2018). While most embedding mapping methods rely on a small seed dictionary, adversarial training has recently produced exciting results in fully unsu789 Proceedings of the 56th Annual Meeting of the Associatio"
P18-1073,N15-1028,0,0.0657679,"ently training word embeddings in two languages, and then mapping them to a shared space using a linear transformation. Most of these methods are supervised, and use a bilingual dictionary of a few thousand entries to learn the mapping. Existing approaches can be classified into regression methods, which map the embeddings in one language using a leastsquares objective (Mikolov et al., 2013; Shigeto et al., 2015; Dinu et al., 2015), canonical methods, which map the embeddings in both languages to a shared space using canonical correlation analysis and extensions of it (Faruqui and Dyer, 2014; Lu et al., 2015), orthogonal methods, which map the embeddings in one or both languages under the constraint of the transformation being orthogonal (Xing et al., 2015; Artetxe et al., 2016; Zhang et al., 2016; Smith et al., 2017), and margin methods, which map the embeddings in one language to maximize the margin between the correct translations and the rest of the candidates (Lazaridou et al., 2015). Artetxe et al. (2018a) showed that many of them could be generalized as part of a multi-step framework of linear transformations. A related research line is to adapt these methods to the semi-supervised scenario"
P18-1073,D16-1250,1,0.91417,"bilingual dictionary of a few thousand entries to learn the mapping. Existing approaches can be classified into regression methods, which map the embeddings in one language using a leastsquares objective (Mikolov et al., 2013; Shigeto et al., 2015; Dinu et al., 2015), canonical methods, which map the embeddings in both languages to a shared space using canonical correlation analysis and extensions of it (Faruqui and Dyer, 2014; Lu et al., 2015), orthogonal methods, which map the embeddings in one or both languages under the constraint of the transformation being orthogonal (Xing et al., 2015; Artetxe et al., 2016; Zhang et al., 2016; Smith et al., 2017), and margin methods, which map the embeddings in one language to maximize the margin between the correct translations and the rest of the candidates (Lazaridou et al., 2015). Artetxe et al. (2018a) showed that many of them could be generalized as part of a multi-step framework of linear transformations. A related research line is to adapt these methods to the semi-supervised scenario, where the training dictionary is much smaller and used as part of a bootstrapping process. While similar ideas where already explored for traditional count-based vector s"
P18-1073,P17-1042,1,0.900071,"hich map the embeddings in one language to maximize the margin between the correct translations and the rest of the candidates (Lazaridou et al., 2015). Artetxe et al. (2018a) showed that many of them could be generalized as part of a multi-step framework of linear transformations. A related research line is to adapt these methods to the semi-supervised scenario, where the training dictionary is much smaller and used as part of a bootstrapping process. While similar ideas where already explored for traditional count-based vector space models (Peirsman and Pad´o, 2010; Vuli´c and Moens, 2013), Artetxe et al. (2017) brought this approach to pre-trained low-dimensional word A practical approach for reducing the need of bilingual supervision is to design heuristics to build the seed dictionary. The role of the seed lexicon in learning cross-lingual embedding mappings is analyzed in depth by Vuli´c and Korhonen (2016), who propose using document-aligned corpora to extract the training dictionary. A more common approach is to rely on shared words and cognates (Peirsman and Pad´o, 2010; Smith et al., 2017), while Artetxe et al. (2017) go further and restrict themselves to shared numerals. However, while these"
P18-1073,W16-1614,0,0.0654663,"xe et al. (2017) go further and restrict themselves to shared numerals. However, while these approaches are meant to eliminate the need of bilingual data in practice, they also make strong assumptions on the writing systems of languages (e.g. that they all use a common alphabet or Arabic numerals). Closer to our work, a recent line of fully unsupervised approaches drops these assumptions completely, and attempts to learn cross-lingual embedding mappings based on distributional information alone. For that purpose, existing methods rely on adversarial training. This was first proposed by Miceli Barone (2016), who combine an encoder that maps source language embeddings into the target language, a decoder that reconstructs the source language embeddings from the mapped embeddings, and a discriminator that discriminates between the mapped embeddings and the true target language embed790 and directly related to their Euclidean distance1 , and can be taken as a measure of their similarity. dings. Despite promising, they conclude that their model “is not competitive with other cross-lingual representation approaches”. Zhang et al. (2017a) use a very similar architecture, but incorporate additional tech"
P18-1073,N10-1135,0,0.0850369,"Missing"
P18-1073,D18-1549,0,0.156352,"Missing"
P18-1073,tiedemann-2012-parallel,0,0.0284518,"s work in different conditions, including more challenging settings, we carry out our experiments in the widely used dataset of Dinu et al. (2015) and the subsequent extensions of Artetxe et al. (2017, 2018a), which together comprise English-Italian, English-German, English-Finnish and EnglishSpanish. More concretely, the dataset consists of 300-dimensional CBOW embeddings trained on WacKy crawling corpora (English, Italian, German), Common Crawl (Finnish) and WMT News Crawl (Spanish). The gold standards were derived from dictionaries built from Europarl word alignments and available at OPUS (Tiedemann, 2012), split in a test set of 1,500 entries and a training set of 5,000 that we do not use in our experiments. The datasets are freely available. As a non-european agglutinative language, the English-Finnish pair is particularly challengIn order to build the initial dictionary, we compute X ′ and Z ′ as detailed in Section 3.2 and apply the above procedure over them. As the only difference, this first solution does not use the stochastic zeroing in the similarity matrix, as there is no need to encourage diversity (X ′ and Z ′ are only used once), and the threshold for vocabulary cutoff is set to k"
P18-1073,P16-1024,0,0.119415,"Missing"
P18-1073,D13-1168,0,0.102455,"Missing"
P18-1073,N15-1104,0,0.294358,"ervised, and use a bilingual dictionary of a few thousand entries to learn the mapping. Existing approaches can be classified into regression methods, which map the embeddings in one language using a leastsquares objective (Mikolov et al., 2013; Shigeto et al., 2015; Dinu et al., 2015), canonical methods, which map the embeddings in both languages to a shared space using canonical correlation analysis and extensions of it (Faruqui and Dyer, 2014; Lu et al., 2015), orthogonal methods, which map the embeddings in one or both languages under the constraint of the transformation being orthogonal (Xing et al., 2015; Artetxe et al., 2016; Zhang et al., 2016; Smith et al., 2017), and margin methods, which map the embeddings in one language to maximize the margin between the correct translations and the rest of the candidates (Lazaridou et al., 2015). Artetxe et al. (2018a) showed that many of them could be generalized as part of a multi-step framework of linear transformations. A related research line is to adapt these methods to the semi-supervised scenario, where the training dictionary is much smaller and used as part of a bootstrapping process. While similar ideas where already explored for traditiona"
P18-1073,P17-1179,0,0.541326,"methods rely on adversarial training. This was first proposed by Miceli Barone (2016), who combine an encoder that maps source language embeddings into the target language, a decoder that reconstructs the source language embeddings from the mapped embeddings, and a discriminator that discriminates between the mapped embeddings and the true target language embed790 and directly related to their Euclidean distance1 , and can be taken as a measure of their similarity. dings. Despite promising, they conclude that their model “is not competitive with other cross-lingual representation approaches”. Zhang et al. (2017a) use a very similar architecture, but incorporate additional techniques like noise injection to aid training and report competitive results on bilingual lexicon extraction. Conneau et al. (2018) drop the reconstruction component, regularize the mapping to be orthogonal, and incorporate an iterative refinement process akin to self-learning, reporting very strong results on a large bilingual lexicon extraction dataset. Finally, Zhang et al. (2017b) adopt the earth mover’s distance for training, optimized through a Wasserstein generative adversarial network followed by an alternating optimizati"
P18-1073,D17-1207,0,0.39139,"methods rely on adversarial training. This was first proposed by Miceli Barone (2016), who combine an encoder that maps source language embeddings into the target language, a decoder that reconstructs the source language embeddings from the mapped embeddings, and a discriminator that discriminates between the mapped embeddings and the true target language embed790 and directly related to their Euclidean distance1 , and can be taken as a measure of their similarity. dings. Despite promising, they conclude that their model “is not competitive with other cross-lingual representation approaches”. Zhang et al. (2017a) use a very similar architecture, but incorporate additional techniques like noise injection to aid training and report competitive results on bilingual lexicon extraction. Conneau et al. (2018) drop the reconstruction component, regularize the mapping to be orthogonal, and incorporate an iterative refinement process akin to self-learning, reporting very strong results on a large bilingual lexicon extraction dataset. Finally, Zhang et al. (2017b) adopt the earth mover’s distance for training, optimized through a Wasserstein generative adversarial network followed by an alternating optimizati"
P18-1073,N16-1156,0,0.0613836,"f a few thousand entries to learn the mapping. Existing approaches can be classified into regression methods, which map the embeddings in one language using a leastsquares objective (Mikolov et al., 2013; Shigeto et al., 2015; Dinu et al., 2015), canonical methods, which map the embeddings in both languages to a shared space using canonical correlation analysis and extensions of it (Faruqui and Dyer, 2014; Lu et al., 2015), orthogonal methods, which map the embeddings in one or both languages under the constraint of the transformation being orthogonal (Xing et al., 2015; Artetxe et al., 2016; Zhang et al., 2016; Smith et al., 2017), and margin methods, which map the embeddings in one language to maximize the margin between the correct translations and the rest of the candidates (Lazaridou et al., 2015). Artetxe et al. (2018a) showed that many of them could be generalized as part of a multi-step framework of linear transformations. A related research line is to adapt these methods to the semi-supervised scenario, where the training dictionary is much smaller and used as part of a bootstrapping process. While similar ideas where already explored for traditional count-based vector space models (Peirsma"
P19-1019,P15-1081,0,0.0131111,"ems with monolingual corpora go back to statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012). These methods see the source language as ciphertext produced by a noisy channel model that first generates the original English text and then probabilistically replaces the words in it. The English generative process is modeled using an n-gram language model, and the channel model parameters are estimated using either expectation maximization or Bayesian inference. This basic approach was later improved by incorporating syntactic knowledge (Dou and Knight, 2013) and word embeddings (Dou et al., 2015). Nevertheless, these methods were only shown to work in limited settings, being most often evaluated in word-level translation. More recently, the task got a renewed interest after the concurrent work of Artetxe et al. (2018c) and Lample et al. (2018a) on unsupervised NMT which, for the first time, obtained promising results in standard machine translation benchmarks using monolingual corpora only. Both methods build upon the recent work on unsupervised cross-lingual embedding mappings, which independently train word embeddings in two languages and learn a linear transformation to map them to"
P19-1019,N13-1073,0,0.060691,"749 million tokens in French, 1,606 millions in German, and 2,109 millions in English, from which we take a random subset of 2,000 sentences for tuning (Section 3.3). Preprocessing is done using standard Moses tools, and involves punctuation normalization, tokenization with aggressive hyphen splitting, and truecasing. Our SMT implementation is based on Moses10 , and we use the KenLM (Heafield et al., 2013) tool included in it to estimate our 5-gram language model with modified Kneser-Ney smoothing. Our unsupervised tuning implementation is based on Z-MERT (Zaidan, 2009), and we use FastAlign (Dyer et al., 2013) for word alignment within the joint refinement procedure. Finally, we use the big transformer implementation from fairseq11 for our NMT system, training with a total batch size of 20,000 tokens across 8 GPUs with the exact same hyperparameters as Ott et al. (2018). We use newstest2014 as our test set for 10 11 5.1 Main results Table 1 reports the results of the proposed system in comparison to previous work. As it can be seen, our full system obtains the best published results in all cases, outperforming the previous stateof-the-art by 5-7 BLEU points in all datasets and translation direction"
P19-1019,P17-1042,1,0.837208,"shown to work in limited settings, being most often evaluated in word-level translation. More recently, the task got a renewed interest after the concurrent work of Artetxe et al. (2018c) and Lample et al. (2018a) on unsupervised NMT which, for the first time, obtained promising results in standard machine translation benchmarks using monolingual corpora only. Both methods build upon the recent work on unsupervised cross-lingual embedding mappings, which independently train word embeddings in two languages and learn a linear transformation to map them to a shared space through self-learning (Artetxe et al., 2017, 2018a) or adversarial training (Conneau et al., 2018). The resulting crosslingual embeddings are used to initialize a shared encoder for both languages, and the entire system is trained using a combination of denoising autoencoding, back-translation and, in the case of Lample et al. (2018a), adversarial training. This method was further improved by Yang et al. (2018), who use two language-specific encoders sharing only a subset of their parameters, and incorporate a local and a global generative adversarial network. Concurrent to our work, Lample and Conneau (2019) report strong results init"
P19-1019,D18-1045,0,0.283144,"f-the-art in unsupervised machine translation by 5-7 BLEU points in all these datasets and translation directions. Our system also outperforms the supervised WMT 2014 shared task winner in English-to-German, and is around 2 BLEU points behind it in the rest of translation directions, suggesting that unsupervised machine translation can be a usable alternative in practical settings. Introduction The recent advent of neural sequence-to-sequence modeling has resulted in significant progress in the field of machine translation, with large improvements in standard benchmarks (Vaswani et al., 2017; Edunov et al., 2018) and the first solid claims of human parity in certain settings (Hassan et al., 2018). Unfortunately, these systems rely on large amounts of parallel corpora, which are only available for a few combinations of major languages like English, German and French. Aiming to remove this dependency on parallel data, a recent research line has managed to train unsupervised machine translation systems using monolingual corpora only. The first such systems were based on Neural Machine Translation (NMT), and combined denoising autoencoding and back-translation to train a dual model iniThe remaining of thi"
P19-1019,P18-1073,1,0.0533936,"supervised Machine Translation Mikel Artetxe, Gorka Labaka, Eneko Agirre IXA NLP Group University of the Basque Country (UPV/EHU) {mikel.artetxe, gorka.labaka, e.agirre}@ehu.eus Abstract tialized with cross-lingual embeddings (Artetxe et al., 2018c; Lample et al., 2018a). Nevertheless, these early systems were later superseded by Statistical Machine Translation (SMT) based approaches, which induced an initial phrase-table through cross-lingual embedding mappings, combined it with an n-gram language model, and further improved the system through iterative backtranslation (Lample et al., 2018b; Artetxe et al., 2018b). While machine translation has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both Neural Machine Translation (NMT) and Statistical Machine Translation (SMT) systems using monolingual corpora only. In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. Moreover, we use our improved SMT system to initialize a dual NMT model, which is further fi"
P19-1019,D18-1399,1,0.136031,"supervised Machine Translation Mikel Artetxe, Gorka Labaka, Eneko Agirre IXA NLP Group University of the Basque Country (UPV/EHU) {mikel.artetxe, gorka.labaka, e.agirre}@ehu.eus Abstract tialized with cross-lingual embeddings (Artetxe et al., 2018c; Lample et al., 2018a). Nevertheless, these early systems were later superseded by Statistical Machine Translation (SMT) based approaches, which induced an initial phrase-table through cross-lingual embedding mappings, combined it with an n-gram language model, and further improved the system through iterative backtranslation (Lample et al., 2018b; Artetxe et al., 2018b). While machine translation has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both Neural Machine Translation (NMT) and Statistical Machine Translation (SMT) systems using monolingual corpora only. In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. Moreover, we use our improved SMT system to initialize a dual NMT model, which is further fi"
P19-1019,P13-2121,0,0.056362,"Missing"
P19-1019,D18-1549,0,0.145662,"Missing"
P19-1019,D12-1025,0,0.036531,"l corpus through backtranslation, and a new NMT model is trained on top of it from scratch, repeating the process iteratively. Ren et al. (2019) follow a similar approach, but use SMT as posterior regularization at each iteration. As shown later in our experiments, our proposed NMT hybridization obtains substantially larger absolute gains than all these previous approaches, even if our initial SMT system is stronger and thus more challenging to improve upon. Early attempts to build machine translation systems with monolingual corpora go back to statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012). These methods see the source language as ciphertext produced by a noisy channel model that first generates the original English text and then probabilistically replaces the words in it. The English generative process is modeled using an n-gram language model, and the channel model parameters are estimated using either expectation maximization or Bayesian inference. This basic approach was later improved by incorporating syntactic knowledge (Dou and Knight, 2013) and word embeddings (Dou et al., 2015). Nevertheless, these methods were only shown to work in limited settings, being most often e"
P19-1019,J82-2005,0,0.799078,"Missing"
P19-1019,P18-1005,0,0.141734,"ods build upon the recent work on unsupervised cross-lingual embedding mappings, which independently train word embeddings in two languages and learn a linear transformation to map them to a shared space through self-learning (Artetxe et al., 2017, 2018a) or adversarial training (Conneau et al., 2018). The resulting crosslingual embeddings are used to initialize a shared encoder for both languages, and the entire system is trained using a combination of denoising autoencoding, back-translation and, in the case of Lample et al. (2018a), adversarial training. This method was further improved by Yang et al. (2018), who use two language-specific encoders sharing only a subset of their parameters, and incorporate a local and a global generative adversarial network. Concurrent to our work, Lample and Conneau (2019) report strong results initializing an unsupervised NMT system with a cross-lingual language model. Following the initial work on unsupervised NMT, it was argued that the modular architecture of phrase-based SMT was more suitable for this problem, and Lample et al. (2018b) and Artetxe et al. (2018b) adapted the same principles discussed above to train an unsupervised SMT model, obtaining large i"
P19-1019,P03-1021,0,0.129273,"(McCallum et al., 2005), for future work. f where the temperature τ is estimated using maximum likelihood estimation over a dictionary induced in the reverse direction. In addition to the phrase translation probabilities in both directions, the forward and reverse lexical weightings 3.3 Unsupervised tuning Having trained the underlying statistical models independently, SMT tuning aims to adjust the weights of their resulting log-linear combination to optimize some evaluation metric like BLEU in a parallel validation corpus, which is typically done through Minimum Error Rate Training or MERT (Och, 2003). Needless to say, this cannot be done in strictly unsupervised settings, but we argue that 1 https://github.com/artetxem/ phrase2vec 2 So as to keep the model size within a reasonable limit, we restrict the vocabulary to the most frequent 200,000 unigrams, 400,000 bigrams and 400,000 trigrams. 3 https://github.com/artetxem/vecmap 196 where the length penalty LP = LP(E) · LP(F ) penalizes excessively long translations:5   len(TF →E (TE→F (E))) LP(E) = max 1, len(E) it would still be desirable to optimize some unsupervised criterion that is expected to correlate well with test performance. Un"
P19-1019,W18-6301,0,0.0247339,"ion with aggressive hyphen splitting, and truecasing. Our SMT implementation is based on Moses10 , and we use the KenLM (Heafield et al., 2013) tool included in it to estimate our 5-gram language model with modified Kneser-Ney smoothing. Our unsupervised tuning implementation is based on Z-MERT (Zaidan, 2009), and we use FastAlign (Dyer et al., 2013) for word alignment within the joint refinement procedure. Finally, we use the big transformer implementation from fairseq11 for our NMT system, training with a total batch size of 20,000 tokens across 8 GPUs with the exact same hyperparameters as Ott et al. (2018). We use newstest2014 as our test set for 10 11 5.1 Main results Table 1 reports the results of the proposed system in comparison to previous work. As it can be seen, our full system obtains the best published results in all cases, outperforming the previous stateof-the-art by 5-7 BLEU points in all datasets and translation directions. A substantial part of this improvement comes from our more principled unsupervised SMT ap12 Note that it is only the test set that is from WMT 2016. All the training data comes from WMT 2014 News Crawl, so it is likely that our results could be further improved"
P19-1019,W18-6319,0,0.0256025,"26.9 26.4 Table 1: Results of the proposed method in comparison to previous work (BLEU). Overall best results are in bold, the best ones in each group are underlined. ∗ Detokenized BLEU equivalent to the official mteval-v13a.pl script. The rest use tokenized BLEU with multi-bleu.perl (or similar). French-English, and both newstest2014 and newstest2016 (from WMT 201612 ) for GermanEnglish. Following common practice, we report tokenized BLEU scores as computed by the multi-bleu.perl script included in Moses. In addition to that, we also report detokenized BLEU scores as computed by SacreBLEU13 (Post, 2018), which is equivalent to the official mteval-v13a.pl script. We next present the results of our proposed system in comparison to previous work in Section 5.1. Section 5.2 then compares the obtained results to those of different supervised systems. Finally, Section 5.3 presents some translation examples from our system. points from every 10 iterations. 5 Experiments and results In order to make our experiments comparable to previous work, we use the French-English and German-English datasets from the WMT 2014 shared task. More concretely, our training data consists of the concatenation of all N"
P19-1019,P11-1002,0,0.172675,"t the synthetic parallel corpus through backtranslation, and a new NMT model is trained on top of it from scratch, repeating the process iteratively. Ren et al. (2019) follow a similar approach, but use SMT as posterior regularization at each iteration. As shown later in our experiments, our proposed NMT hybridization obtains substantially larger absolute gains than all these previous approaches, even if our initial SMT system is stronger and thus more challenging to improve upon. Early attempts to build machine translation systems with monolingual corpora go back to statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012). These methods see the source language as ciphertext produced by a noisy channel model that first generates the original English text and then probabilistically replaces the words in it. The English generative process is modeled using an n-gram language model, and the channel model parameters are estimated using either expectation maximization or Bayesian inference. This basic approach was later improved by incorporating syntactic knowledge (Dou and Knight, 2013) and word embeddings (Dou et al., 2015). Nevertheless, these methods were only shown to work in limited setti"
P19-1019,P16-1009,0,0.800056,"ion 6 concludes the paper. 194 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 194–203 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics 2 Related work unsupervised NMT systems. More concretely, both approaches learn cross-lingual n-gram embeddings from monolingual corpora based on the mapping method discussed earlier, and use them to induce an initial phrase-table that is combined with an n-gram language model and a distortion model. This initial system is then refined through iterative back-translation (Sennrich et al., 2016) which, in the case of Artetxe et al. (2018b), is preceded by an unsupervised tuning step. Our work identifies some deficiencies in these previous systems, and proposes a more principled approach to unsupervised SMT that incorporates subword information, uses a theoretically better founded unsupervised tuning method, and applies a joint refinement procedure, outperforming these previous systems by a substantial margin. Very recently, some authors have tried to combine both SMT and NMT to build hybrid unsupervised machine translation systems. This idea was already explored by Lample et al. (201"
P19-1019,D13-1173,0,\N,Missing
P19-1492,P17-1042,1,0.901941,"rable corpora (Vuli´c and Moens, 2016) or large bilingual dictionaries (Duong et al., 2016) have also been proposed. For a more detailed survey, the reader is referred to Ruder et al. (2017). In contrast, offline mapping approaches work by aligning separately trained word embeddings in different languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a common space (Mikolov et al., 2013a; Artetxe et al., 2018a). The amount of required supervision was later reduced through selflearning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). There are several authors that have discussed the potential limitations of these mapping approaches. For instance, Søgaard et al. (2018) observe that the assumption that separately trained embeddings are approximately isomorphic is not true in general, showing that the performance of mapping methods is conditioned by the language pair, the comparability of the training"
P19-1492,D18-1043,0,0.254107,"aches work by aligning separately trained word embeddings in different languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a common space (Mikolov et al., 2013a; Artetxe et al., 2018a). The amount of required supervision was later reduced through selflearning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). There are several authors that have discussed the potential limitations of these mapping approaches. For instance, Søgaard et al. (2018) observe that the assumption that separately trained embeddings are approximately isomorphic is not true in general, showing that the performance of mapping methods is conditioned by the language pair, the comparability of the training corpora, and the parameters of the word embedding algorithms. Similarly, Patra et al. (2019) show that the isomorphism assumption weakens as the languages involved become increasingly etymologically distant. Finally, Nakashole"
P19-1492,W15-1521,0,0.255871,"clear whether this mismatch is a consequence of separately training both embedding spaces, and thus an inherent limitation of mapping approaches, or an insurmountable obstacle that arises from the linguistic divergences across languages, and hence a more general issue when learning cross-lingual word embeddings. Introduction Cross-lingual word embeddings have attracted a lot of attention in recent times. Existing methods can be broadly classified into two categories: joint methods, which simultaneously learn word representations for multiple languages on parallel corpora (Gouws et al., 2015; Luong et al., 2015), and mapping methods, which independently train word embeddings in different languages and map them to a shared space through linear transformations (Mikolov et al., 2013a; Artetxe et al., 2018a). While early work in cross-lingual word embeddings was dominated by joint approaches, recent research has almost exclusively focused on mapping methods, which have the advantage of requirThe goal of this paper is to shed light on this matter so as to better understand the nature and extension of these limitations. For that purpose, we experiment with parallel corpora, which allows us to compare mappi"
P19-1492,P18-1073,1,0.905812,"the linguistic divergences across languages, and hence a more general issue when learning cross-lingual word embeddings. Introduction Cross-lingual word embeddings have attracted a lot of attention in recent times. Existing methods can be broadly classified into two categories: joint methods, which simultaneously learn word representations for multiple languages on parallel corpora (Gouws et al., 2015; Luong et al., 2015), and mapping methods, which independently train word embeddings in different languages and map them to a shared space through linear transformations (Mikolov et al., 2013a; Artetxe et al., 2018a). While early work in cross-lingual word embeddings was dominated by joint approaches, recent research has almost exclusively focused on mapping methods, which have the advantage of requirThe goal of this paper is to shed light on this matter so as to better understand the nature and extension of these limitations. For that purpose, we experiment with parallel corpora, which allows us to compare mapping methods and joint methods under the exact same conditions, and analyze the properties of the resulting embeddings. Our results show that, under these conditions, joint learning yields to more"
P19-1492,P18-2036,0,0.195788,"lf, 2018). There are several authors that have discussed the potential limitations of these mapping approaches. For instance, Søgaard et al. (2018) observe that the assumption that separately trained embeddings are approximately isomorphic is not true in general, showing that the performance of mapping methods is conditioned by the language pair, the comparability of the training corpora, and the parameters of the word embedding algorithms. Similarly, Patra et al. (2019) show that the isomorphism assumption weakens as the languages involved become increasingly etymologically distant. Finally, Nakashole and Flauger (2018) argue that embedding spaces in different languages are linearly equivalent only at local regions, but their global structure is different. Nevertheless, neither of these works does systematically analyze the extent to which these limitations are inherent to mapping approaches. To the best of our knowledge, ours is the first work comparing joint and mapping methods in the exact same conditions, characterizing the nature and impact of such limitations. Experimental design We next describe the cross-lingual embedding methods, evaluation measures and datasets used in our experiments. 3.1 Cross-li"
P19-1492,D16-1136,0,0.101565,"2019 Association for Computational Linguistics 2 3 Related work Cross-lingual word embeddings represent words from multiple languages in a common vector space. So as to train them, joint methods simultaneously learn the embeddings in the different languages, which requires some form of cross-lingual supervision. This supervision usually comes from parallel corpora, which can be aligned at the word level (Luong et al., 2015), or only at the sentence level (Gouws et al., 2015). In addition to that, methods that rely on comparable corpora (Vuli´c and Moens, 2016) or large bilingual dictionaries (Duong et al., 2016) have also been proposed. For a more detailed survey, the reader is referred to Ruder et al. (2017). In contrast, offline mapping approaches work by aligning separately trained word embeddings in different languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a common space (Mikolov et al., 2013a; Artetxe et al., 2018a). The amount of required supervision was later reduced through selflearning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang e"
P19-1492,N13-1073,0,0.0179014,"ld of 1e-5 and 5 training iterations. Having done that, we map the resulting monolingual embeddings to a cross-lingual space using the unsupervised mode in VecMap1 (Artetxe et al., 2018b), which builds an initial solution based on heuristics and iteratively improves it through self-learning. Joint learning: We use the BiVec2 tool proposed by Luong et al. (2015), an extension of skip-gram that, given a word aligned parallel corpus, learns to predict the context of both the source word and the target word aligned with it. For that purpose, we first word align our training corpus using FastText (Dyer et al., 2013). Given that BiVec is a natural extension of skip-gram, we use the exact same hyperparameters as for the mapping method. In both cases, we restrict the vocabulary to the most frequent 200,000 words. 3.2 Evaluation measures We use the following measures to characterize cross-lingual embeddings: Isomorphism. Intuitively, the notion of isomorphism captures the idea of how well the embeddings in both languages fit together (i.e. the degree of their structural similarity). So as to measure it, we use the eigenvalue similarity metric proposed by Søgaard et al. (2018). For that purpose, we first cent"
P19-1492,W18-6488,0,0.0156138,"etrieval. Note that, in addition to having a practical application, BLI performance is an informative measure of the quality of the embeddings, as a good cross-lingual representation should place equivalent words close to each other. 3.3 Datasets We experiment with 4 language pairs with English as the target language, covering 3 relatively close languages (German, Spanish and Italian) and a non-indoeuropean agglutinative language (Finnish). All embeddings were trained on the BiCleaner v3.0 version of the ParaCrawl corpus,4 a parallel corpus collected through crawling and filtered according to Sánchez-Cartagena et al. (2018). The size of this corpus changes from one language to another: German and Spanish are the largest (503 and 492 million tokens in the English side, respectively), followed by Italian (308 million tokens), and Finnish (55 million tokens). As for the evaluation dictionaries for BLI, we use two datasets that have been widely used in the literature. The first one, which we call Eparl, was first introduced by Dinu et al. (2015) and subsequently extended by Artetxe et al. (2017) and Artetxe et al. (2018a), and consists of 1,500 test entries extracted from Europarl word alignments 4992 4 https://para"
P19-1492,P18-1072,0,0.113707,"Missing"
P19-1492,P17-1179,0,0.143559,", 2016) have also been proposed. For a more detailed survey, the reader is referred to Ruder et al. (2017). In contrast, offline mapping approaches work by aligning separately trained word embeddings in different languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a common space (Mikolov et al., 2013a; Artetxe et al., 2018a). The amount of required supervision was later reduced through selflearning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). There are several authors that have discussed the potential limitations of these mapping approaches. For instance, Søgaard et al. (2018) observe that the assumption that separately trained embeddings are approximately isomorphic is not true in general, showing that the performance of mapping methods is conditioned by the language pair, the comparability of the training corpora, and the parameters of the word embedding algorithms. Similarly, Patra e"
P19-1494,D18-1214,0,0.0377093,"ons of words that were missing in the training dictionary by taking their nearest neighbor in the target language. The amount of required supervision was later reduced through self-learning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017a; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). At the same time, several recent methods have formulated embedding mappings as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2018; Alvarez-Melis and Jaakkola, 2018). In addition to that, a large body of work has focused on addressing the hubness problem that arises when directly inducing bilingual dictionaries from cross-lingual embeddings, either through the retrieval method (Dinu et al., 2015; Smith et al., 2017; Conneau et al., 2018) or the mapping itself (Lazaridou et al., 2015; Shigeto et al., 2015; Joulin et al., 2018). While all these previous methods directly induce bilingual dictionaries from cross-lingually mapped embeddings, our proposed method combines them with unsupervised machine translation techniques, outperforming them all by a substant"
P19-1494,P17-1042,1,0.854883,"mbedding mappings, which work by aligning independently trained word embeddings in different languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a shared crosslingual space (Mikolov et al., 2013; Artetxe et al., 2018a). The resulting cross-lingual embeddings are then used to induce the translations of words that were missing in the training dictionary by taking their nearest neighbor in the target language. The amount of required supervision was later reduced through self-learning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017a; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). At the same time, several recent methods have formulated embedding mappings as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2018; Alvarez-Melis and Jaakkola, 2018). In addition to that, a large body of work has focused on addressing the hubness problem that arises when directly inducing bilingual dictionaries from cross-lingual embeddings, either t"
P19-1494,P18-1073,1,0.912865,"oints over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset. 1 Introduction Cross-lingual word embedding mappings have attracted a lot of attention in recent times. These methods work by independently training word embeddings in different languages, and mapping them to a shared space through linear transformations. While early methods required a training dictionary to find the initial alignment (Mikolov et al., 2013), fully unsupervised methods have managed to obtain comparable results based on either adversarial training (Conneau et al., 2018) or selflearning (Artetxe et al., 2018b). A prominent application of these methods is Bilingual Lexicon Induction (BLI), that is, using In this paper, we go one step further and, rather than directly inducing the bilingual dictionary from the cross-lingual word embeddings, we use them to build an unsupervised machine translation system, and extract a bilingual dictionary from a synthetic parallel corpus generated with it. This allows us to take advantage of a strong language model and naturally extract translation equivalences through statistical word alignment. At the same time, our method can be used as a drop-in replacement of"
P19-1494,D18-1399,1,0.920694,"oints over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset. 1 Introduction Cross-lingual word embedding mappings have attracted a lot of attention in recent times. These methods work by independently training word embeddings in different languages, and mapping them to a shared space through linear transformations. While early methods required a training dictionary to find the initial alignment (Mikolov et al., 2013), fully unsupervised methods have managed to obtain comparable results based on either adversarial training (Conneau et al., 2018) or selflearning (Artetxe et al., 2018b). A prominent application of these methods is Bilingual Lexicon Induction (BLI), that is, using In this paper, we go one step further and, rather than directly inducing the bilingual dictionary from the cross-lingual word embeddings, we use them to build an unsupervised machine translation system, and extract a bilingual dictionary from a synthetic parallel corpus generated with it. This allows us to take advantage of a strong language model and naturally extract translation equivalences through statistical word alignment. At the same time, our method can be used as a drop-in replacement of"
P19-1494,P19-1019,1,0.856747,"In addition to the phrase translation probabilities in both directions, we also estimate the forward and reverse lexical weightings by aligning each word in the target phrase with the one in the source phrase most likely generating it, and taking the product of their respective translation probabilities. We then combine this phrase-table with a distortion model and a 5-gram language model estimated in the target language corpus, which results in a phrase-based machine translation system. So as to optimize the weights of the resulting model, we use the unsupervised tuning procedure proposed by Artetxe et al. (2019), which combines a cyclic consistency loss and a language modeling loss over a subset of 2,000 sentences from each monolingual corpora. Having done that, we generate a synthetic parallel corpus by translating the source language monolingual corpus with the resulting machine translation system.3 We then word align this corpus using FastAlign (Dyer et al., 2013) with default hyperparameters and the grow-diag-finaland symmetrization heuristic. Finally, we build a phrase-table from the word aligned corpus, and extract a bilingual dictionary from it by discarding all non-unigram entries. For words"
P19-1494,Q17-1010,0,0.378654,"any other points in high-dimensional spaces, which has been reported to severely affect cross-lingual embedding mappings (Dinu et al., 2015). 2 The original paper refers to this method as globally corrected retrieval. 5002 Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5002–5007 c Florence, Italy, July 28 - August 2, 2019. 2019 Association for Computational Linguistics 2 Proposed method The input of our method is a set of cross-lingual word embeddings and the monolingual corpora used to train them. In our experiments, we use fastText embeddings (Bojanowski et al., 2017) mapped through VecMap (Artetxe et al., 2018b), but the algorithm described next can also work with any other word embedding and cross-lingual mapping method. The general idea of our method is to to build an unsupervised phrase-based statistical machine translation system (Lample et al., 2018; Artetxe et al., 2018c, 2019), and use it to generate a synthetic parallel corpus from which to extract a bilingual dictionary. For that purpose, we first derive phrase embeddings from the input word embeddings by taking the 400,000 most frequent bigrams and and the 400,000 most frequent trigrams in each"
P19-1494,D12-1025,0,0.0581822,"ngs trained on Wikipedia with the same hyperparameters. retrieval over mapped embeddings, obtains substantially better results without requiring any additional resource. As such, we argue that 1) future work in cross-lingual word embeddings should consider other evaluation tasks in addition to BLI, and 2) future work in BLI should consider other alternatives in addition to direct retrieval over crosslingual embedding mappings. 5 Related work While BLI has been previously tackled using count-based vector space models (Vuli´c and Moens, 2013) and statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012), these methods have recently been superseded by crosslingual embedding mappings, which work by aligning independently trained word embeddings in different languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a shared crosslingual space (Mikolov et al., 2013; Artetxe et al., 2018a). The resulting cross-lingual embeddings are then used to induce the translations of words that were missing in the training dictionary by taking their nearest neighbor in the target language. The amount of require"
P19-1494,N13-1073,0,0.0639365,"nd a 5-gram language model estimated in the target language corpus, which results in a phrase-based machine translation system. So as to optimize the weights of the resulting model, we use the unsupervised tuning procedure proposed by Artetxe et al. (2019), which combines a cyclic consistency loss and a language modeling loss over a subset of 2,000 sentences from each monolingual corpora. Having done that, we generate a synthetic parallel corpus by translating the source language monolingual corpus with the resulting machine translation system.3 We then word align this corpus using FastAlign (Dyer et al., 2013) with default hyperparameters and the grow-diag-finaland symmetrization heuristic. Finally, we build a phrase-table from the word aligned corpus, and extract a bilingual dictionary from it by discarding all non-unigram entries. For words with more than one entry, we rank translation candidates according to their direct translation probability. 3 Experimental settings In order to compare our proposed method headto-head with other BLI methods, the experimental setting needs to fix the monolingual embedding training method, as well as the cross-lingual mapping algorithm and the evaluation diction"
P19-1494,P19-1070,0,0.216208,"Missing"
P19-1494,D18-1043,0,0.0623802,"these embeddings into a shared crosslingual space (Mikolov et al., 2013; Artetxe et al., 2018a). The resulting cross-lingual embeddings are then used to induce the translations of words that were missing in the training dictionary by taking their nearest neighbor in the target language. The amount of required supervision was later reduced through self-learning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017a; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). At the same time, several recent methods have formulated embedding mappings as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2018; Alvarez-Melis and Jaakkola, 2018). In addition to that, a large body of work has focused on addressing the hubness problem that arises when directly inducing bilingual dictionaries from cross-lingual embeddings, either through the retrieval method (Dinu et al., 2015; Smith et al., 2017; Conneau et al., 2018) or the mapping itself (Lazaridou et al., 2015; Shigeto et al., 2015; Joulin et al., 2018). While all these previous methods directly induc"
P19-1494,D18-1330,0,0.0240602,"tialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). At the same time, several recent methods have formulated embedding mappings as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2018; Alvarez-Melis and Jaakkola, 2018). In addition to that, a large body of work has focused on addressing the hubness problem that arises when directly inducing bilingual dictionaries from cross-lingual embeddings, either through the retrieval method (Dinu et al., 2015; Smith et al., 2017; Conneau et al., 2018) or the mapping itself (Lazaridou et al., 2015; Shigeto et al., 2015; Joulin et al., 2018). While all these previous methods directly induce bilingual dictionaries from cross-lingually mapped embeddings, our proposed method combines them with unsupervised machine translation techniques, outperforming them all by a substantial margin. 6 Conclusions and future work We propose a new approach to BLI which, instead of directly inducing bilingual dictionaries from cross-lingual embedding mappings, uses them to build an unsupervised machine translation system, which is then used to generate a synthetic parallel corpus from which to extract bilingual lexica. Our approach does not require a"
P19-1494,P07-2045,0,0.00496398,"2018) but, instead of using the pre-trained Wikipedia embeddings distributed with it, we extract monolingual corpora from Wikipedia ourselves and train our own embeddings trying to be as faithful as possible to the original settings. This allows us to compare our proposed method to previous retrieval techniques in the exact same conditions, while keeping our results as comparable as possible to previous work reporting results for the MUSE dataset. More concretely, we use WikiExtractor4 to extract plain text from Wikipedia dumps, and preprocess the resulting corpus using standard Moses tools (Koehn et al., 2007) by applying sentence splitting, punctuation normalization, tokenization with aggressive hyphen splitting, and lowercasing. We then train word embeddings for each language using the skip-gram implementation of fastText (Bojanowski et al., 2017) with default hyperparameters, restricting the vocabulary to the 200,000 most frequent tokens. The official embeddings in 3 For efficiency purposes, we restricted the size of the synthetic parallel corpus to a maximum of 10 million sentences, and use cube-pruning for faster decoding. As such, our results could likely be improved by translating the full m"
P19-1494,J82-2005,0,0.727459,"Missing"
P19-1494,P15-1027,0,0.0246216,"robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). At the same time, several recent methods have formulated embedding mappings as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2018; Alvarez-Melis and Jaakkola, 2018). In addition to that, a large body of work has focused on addressing the hubness problem that arises when directly inducing bilingual dictionaries from cross-lingual embeddings, either through the retrieval method (Dinu et al., 2015; Smith et al., 2017; Conneau et al., 2018) or the mapping itself (Lazaridou et al., 2015; Shigeto et al., 2015; Joulin et al., 2018). While all these previous methods directly induce bilingual dictionaries from cross-lingually mapped embeddings, our proposed method combines them with unsupervised machine translation techniques, outperforming them all by a substantial margin. 6 Conclusions and future work We propose a new approach to BLI which, instead of directly inducing bilingual dictionaries from cross-lingual embedding mappings, uses them to build an unsupervised machine translation system, which is then used to generate a synthetic parallel corpus from which to extract bilin"
P19-1494,D13-1168,0,0.0760126,"Missing"
P19-1494,D18-1268,0,0.104777,"Missing"
P19-1494,P17-1179,0,0.0826342,"ifferent languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a shared crosslingual space (Mikolov et al., 2013; Artetxe et al., 2018a). The resulting cross-lingual embeddings are then used to induce the translations of words that were missing in the training dictionary by taking their nearest neighbor in the target language. The amount of required supervision was later reduced through self-learning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017a; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). At the same time, several recent methods have formulated embedding mappings as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2018; Alvarez-Melis and Jaakkola, 2018). In addition to that, a large body of work has focused on addressing the hubness problem that arises when directly inducing bilingual dictionaries from cross-lingual embeddings, either through the retrieval method (Dinu et al., 2015; Smith et al., 2017; Conneau et al"
P19-1494,D18-1063,0,0.0822933,"Missing"
P19-1494,D17-1207,0,0.0779351,"ifferent languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a shared crosslingual space (Mikolov et al., 2013; Artetxe et al., 2018a). The resulting cross-lingual embeddings are then used to induce the translations of words that were missing in the training dictionary by taking their nearest neighbor in the target language. The amount of required supervision was later reduced through self-learning methods (Artetxe et al., 2017), and then completely eliminated through adversarial training (Zhang et al., 2017a; Conneau et al., 2018) or more robust iterative approaches combined with initialization heuristics (Artetxe et al., 2018b; Hoshen and Wolf, 2018). At the same time, several recent methods have formulated embedding mappings as an optimal transport problem (Zhang et al., 2017b; Grave et al., 2018; Alvarez-Melis and Jaakkola, 2018). In addition to that, a large body of work has focused on addressing the hubness problem that arises when directly inducing bilingual dictionaries from cross-lingual embeddings, either through the retrieval method (Dinu et al., 2015; Smith et al., 2017; Conneau et al"
P19-1494,P11-1002,0,0.0605316,"nd use fastText embeddings trained on Wikipedia with the same hyperparameters. retrieval over mapped embeddings, obtains substantially better results without requiring any additional resource. As such, we argue that 1) future work in cross-lingual word embeddings should consider other evaluation tasks in addition to BLI, and 2) future work in BLI should consider other alternatives in addition to direct retrieval over crosslingual embedding mappings. 5 Related work While BLI has been previously tackled using count-based vector space models (Vuli´c and Moens, 2013) and statistical decipherment (Ravi and Knight, 2011; Dou and Knight, 2012), these methods have recently been superseded by crosslingual embedding mappings, which work by aligning independently trained word embeddings in different languages. For that purpose, early methods required a training dictionary, which was used to learn a linear transformation that mapped these embeddings into a shared crosslingual space (Mikolov et al., 2013; Artetxe et al., 2018a). The resulting cross-lingual embeddings are then used to induce the translations of words that were missing in the training dictionary by taking their nearest neighbor in the target language"
W12-6212,atserias-etal-2006-freeling,0,0.0452885,"Missing"
W12-6212,E09-2008,1,0.831125,"r inside or between chunks. Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 65–69, c Donostia–San Sebasti´an, July 23–25, 2012. 2012 Association for Computational Linguistics fer at the verb chunk level is carried out. The verbal chunk transfer is a very complex module because of the nature of Spanish and Basque auxiliary verb constructions, and is the main subject of this paper. This verb chain transfer module is implemented as a series of ordered replacement rules (Beesley and Karttunen, 2003) using the foma finite-state toolkit (Hulden, 2009). In total, the system consists of 166 separate replacement rules that together perform the verb chunk translation. In practice, the input is given to the first transducer, after which its output is passed to the second, and so forth, in a cascade. Each rule in the system is unambiguous in its output; that is, for each input in a particular step along the verb chain transfer, the transducers never produce multiple outputs (i.e. the transducers in question are functional). Some of the rules are joined together with composition, yielding a total of 55 separate transducers. In principle, all the"
W15-1007,agerri-etal-2014-ixa,0,0.0257674,"Missing"
W15-1007,P08-1045,0,0.0890747,"Missing"
W15-1007,P07-2045,0,0.00394272,"Missing"
W15-1007,W10-3707,0,0.0578954,"Missing"
W15-1007,P13-1059,0,\N,Missing
W15-4901,de-marneffe-etal-2006-generating,0,0.0452984,"Missing"
W15-4901,W12-6212,1,0.848256,"forms, relative clauses, completives, conditionals and a number of adverbial clauses (time, place and reason). I drive my car to university every morning input pattern to verb transfer drive[VBP]+[subj1s][dObj3s][iObj00]+[paradigm2]+gidatu target pattern assigned by grammar gidatu{Asp}{Mod+Asp}{Aux}{Tense}{Subj}{dObj}{iObj} transformed pattern gidatu{IMPERF}{}{edun}{A1}{subj1s}{dObj3s} Nik nire autoa gidatzen dut unibertsitatera goizero. Figure 6: Dummy example of verb transfer steps. Verb transfer in the Matxin architecture is carried out using ﬁnite-state transducers (Alegria et al., 2005; Mayor et al., 2012). In short, the transducers take the source verb phrase as input, perform a number of replacements and create the ﬁnal output which is ready for the syntactic and morphological generators to interpret. We kept the three-step organization of the grammar used in the original language pair. 1. Identiﬁcation of the Basque verbal schema corresponding to the source verbal chunk. We use 21 patterns that we then unify into 5 general schemes corresponding to simple tenses (works, worked), compound tenses (have worked, will work), continuous tenses (is working, had been working), simple tenses preceded"
W15-4901,2009.eamt-1.9,1,0.898692,"Missing"
W15-4901,2011.eamt-1.22,0,0.0622998,"Missing"
W15-4901,E06-1032,0,0.031794,"re that the second verb is treated differently to how main verbs are treated. This needs to be noted before the verbs arrive in the verb transfer component. In order to do that, a special attribute needs to be passed on to the verb phrase. We tested these two cases and saw that Matxin’s design can be appropriate for language-speciﬁc structures. 3.4 human evaluation even when it is known that automatic scores tend to favor SMT systems over RBMT systems because they do not consider the correctness of the output but rather compare the difference between the output and the reference translations (Callison-Burch et al., 2006). And the use of a single reference accentuates this. To get a perspective on the overall performance, we ran the evaluation for two additional systems, an in-house statistical system, SMTs, and Google Translate, as well as Matxin ENEUS. Our SMT system was trained on a parallel corpus of 12 million Basque words and 14 million English words comprising user manuals, academic books and web data. We implemented a phrase-based system using Moses (Koehn et al., 2007). To better deal with the agglutinative nature of Basque, we trained the system on morpheme-level segmented data (Labaka, 2010). As a r"
W15-4901,C02-1014,1,0.747375,"Missing"
W15-4901,W07-0704,0,\N,Missing
W15-4901,sangodkar-damani-2012-ordering,0,\N,Missing
W15-4902,2011.eamt-1.28,0,0.0195959,"ut it has been progressively replaced by Statistical Machine Translation (SMT) since the 1990s (Hutchins, 2007). Example-Based Machine Translation (EBMT), the other main MT paradigm, has never attracted that much attention: even though it gives excellent results with repetitive text for which accurate matches are found in the parallel corpus, its quality quickly degrades as more generalization is needed. Nevertheless, it has been argued that, along with the raise of hybrid systems that try to combine multiple paradigms, EBMT can help to overcome some of the weaknesses of the other approaches (Dandapat et al., 2011)1 . c 2015 The authors. This article is licensed under a Creative � Commons 3.0 licence, no derivative works, attribution, CCBY-ND. 1 This paper refers to as hybridization to any combination of MT paradigms, no matter if they are integrated in a single 11 In this paper, we propose one such system based on a multi-pass system combination: an EBMT preprocessor translates those fragments of the input text for which accurate matches are found in the parallel corpus, generating a high-quality partial translation that is then completed by the main translator, which can be either rule-based or statis"
W15-4902,W12-0106,0,0.0428936,"Missing"
W15-4902,P07-1003,0,0.0226498,"sh, whereas we used Moses (Koehn et al., 2007) as our SMT engine for both language pairs. 4 Results and discussion This section presents the outcomes of the experiments described in Section 3. The results for the quality and coverage experiment are discussed in Section 4.1, and the RBMT and SMT hybridization in Sections 4.2 and 4.3. 4.1 Quality and coverage of EBMT Table 3 shows the number of tokens translated by the EBMT preprocessor according to each generalization mechanism. In the case of chunk generalization, we tried both GIZA++ and Berkeley aligner with and without syntactic tailoring (DeNero and Klein, 2007), which could presumably generate more chunk alignments that meet the restrictions of our translation process. However, contrary to our expectations syntactic tailoring gave the worst results by far both in terms of coverage and translation quality, apparently because it is still an experimental feature, and it was the default HMM mode of Berkeley Aligner which clearly outperformed the rest. We will consequently refer to the results obtained by this aligner in the remaining of this section. As we expected, Table 3 reﬂects that the cover15 age of the EBMT preprocessing clearly depends on the si"
W15-4902,P98-1062,0,0.152584,"essor. Two steps are required for this: the analysis step, presented in Section 2.1.1, and the alignment step, presented in Section 2.1.2. The resulting data is encoded in a custom binary format based on sufﬁx arrays (Manber and Myers, 1990) for its efﬁcient retrieval by the EBMT preprocessor. 2.1.1 Analysis The analysis step involves the tokenization, NE recognition and classiﬁcation, lemmatization and parsing of each side of the parallel corpus. We have used Freeling (Padr´o and Stanilovsky, 2012) as our analyzer for Spanish, Stanford CoreNLP (Socher et al., 2013) for English and Eustagger (Ezeiza et al., 1998) for Basque, with a custom regex-based handling for numerals. The resulting constituency-based parse tree is simpliﬁed by removing inner nodes that correspond to part-ofspeech tags and representing NEs as single leaves. In the case of Basque, our analyzer is only capable of shallow parsing, so we have generated a dummy tree in which chunks are the only inner nodes. 2.1.2 Alignment The alignment step involves establishing the translation relationships among the tokens2 and NEs of the parallel corpus. This is done separately because the latter serves as the basis for NE generalization as discuss"
W15-4902,W05-0833,0,0.0306647,"that do not. • Chunk generalization, giving the option to reuse examples in a subsentential level. Several other methods that combine EBMT and TM with other MT paradigms have been proposed in the literature. Koehn and Senellart (2010) use an SMT system to ﬁll the mismatched parts from a fuzzy search in a TM. Similarly, Shirai et al. (1997) use a RBMT engine to complete the mismatched fragments from an EBMT system and smooth the resulting output using linguistic rules. On the other hand, Dandapat et al. (2012) integrate SMT phrase tables into an EBMT framework. Following the opposite approach, Groves and Way (2005) feed an SMT system with alignments obtained using EBMT techniques. S´anchez-Mart´ınez et al. (2009) use EBMT techniques to obtain bilingual chunks that are then integrated into a RBMT system. Lastly, Alegria et al. (2008) propose a multi-engine system that selects the best translation created by a RBMT, an SMT and an EBMT engine. However, to the best of our knowledge, the use of a generic multi-pass hybridization method for EBMT that works with both SMT and RBMT has never been reported so far. The remaining of this paper is structured as follows. The proposed method is presented in Section 2."
W15-4902,2010.jec-1.4,0,0.0267762,"milar to those used by second and third generation TM systems (Gotti et al., 2005): • Named-entity (NE) generalization, giving the option to replace NEs like proper names and numerals in the parallel corpus with any other found in the text to translate. engine or not. However, some authors distinguish between hybridization for systems that meet this requirement and combination for systems that do not. • Chunk generalization, giving the option to reuse examples in a subsentential level. Several other methods that combine EBMT and TM with other MT paradigms have been proposed in the literature. Koehn and Senellart (2010) use an SMT system to ﬁll the mismatched parts from a fuzzy search in a TM. Similarly, Shirai et al. (1997) use a RBMT engine to complete the mismatched fragments from an EBMT system and smooth the resulting output using linguistic rules. On the other hand, Dandapat et al. (2012) integrate SMT phrase tables into an EBMT framework. Following the opposite approach, Groves and Way (2005) feed an SMT system with alignments obtained using EBMT techniques. S´anchez-Mart´ınez et al. (2009) use EBMT techniques to obtain bilingual chunks that are then integrated into a RBMT system. Lastly, Alegria et a"
W15-4902,P07-2045,0,0.011652,"Missing"
W15-4902,N06-1014,0,0.0354926,"not enough evidence to do so. This way, word-alignment produces a set An for each nth sentence pair where (i, j) ∈ An if and only if there is a translation relationship between the ith token in the source language and the jth token in the target language, as well as the lexical weightings or translation probabilities in both directions, that is, a set of p(e|f ) and p(f |e) probabilities that express the likelihood of the f token to be translated as e and the e token to be translated as f , respectively. Our system has been integrated both with GIZA++ (Och and Ney, 2003) and Berkeley Aligner (Liang et al., 2006). As for NE alignment, we align NEs if and only if they have the same written form, are equivalent 2 We refer as tokens to the leaves of the parse tree obtained in the analysis phase, which implies that NEs are considered (multiword) tokens. numerals or are found in either of the following dictionaries: • A manually built dictionary, mostly consisting of translation relationships between proper names like countries. • An automatically generated dictionary from Wikipedia article titles with support for redirections. • An automatically generated dictionary from word-alignment, consisting of ever"
W15-4902,J03-1002,0,0.00442246,"t aligning NEs in this level if there is not enough evidence to do so. This way, word-alignment produces a set An for each nth sentence pair where (i, j) ∈ An if and only if there is a translation relationship between the ith token in the source language and the jth token in the target language, as well as the lexical weightings or translation probabilities in both directions, that is, a set of p(e|f ) and p(f |e) probabilities that express the likelihood of the f token to be translated as e and the e token to be translated as f , respectively. Our system has been integrated both with GIZA++ (Och and Ney, 2003) and Berkeley Aligner (Liang et al., 2006). As for NE alignment, we align NEs if and only if they have the same written form, are equivalent 2 We refer as tokens to the leaves of the parse tree obtained in the analysis phase, which implies that NEs are considered (multiword) tokens. numerals or are found in either of the following dictionaries: • A manually built dictionary, mostly consisting of translation relationships between proper names like countries. • An automatically generated dictionary from Wikipedia article titles with support for redirections. • An automatically generated dictiona"
W15-4902,padro-stanilovsky-2012-freeling,0,0.0206728,"Missing"
W15-4902,P02-1040,0,0.09238,"Missing"
W15-4902,P13-1045,0,0.0509124,"d parallel corpus to be used by the EBMT preprocessor. Two steps are required for this: the analysis step, presented in Section 2.1.1, and the alignment step, presented in Section 2.1.2. The resulting data is encoded in a custom binary format based on sufﬁx arrays (Manber and Myers, 1990) for its efﬁcient retrieval by the EBMT preprocessor. 2.1.1 Analysis The analysis step involves the tokenization, NE recognition and classiﬁcation, lemmatization and parsing of each side of the parallel corpus. We have used Freeling (Padr´o and Stanilovsky, 2012) as our analyzer for Spanish, Stanford CoreNLP (Socher et al., 2013) for English and Eustagger (Ezeiza et al., 1998) for Basque, with a custom regex-based handling for numerals. The resulting constituency-based parse tree is simpliﬁed by removing inner nodes that correspond to part-ofspeech tags and representing NEs as single leaves. In the case of Basque, our analyzer is only capable of shallow parsing, so we have generated a dummy tree in which chunks are the only inner nodes. 2.1.2 Alignment The alignment step involves establishing the translation relationships among the tokens2 and NEs of the parallel corpus. This is done separately because the latter serv"
W15-5707,P13-3023,0,0.0471446,"Missing"
W15-5707,W12-3132,0,0.0582104,"Missing"
W15-5707,W10-1730,0,0.0332396,"Missing"
W15-5707,P09-2037,0,0.0133725,"Lingua/Interset/ Tagset/ES/Conll2009.pm 5 https://github.com/ufal/treex/blob/master/lib/Treex/Block/HamleDT/ES/Harmonize.pm 58 Figure 3: a-level and t-level English analysis. variant given the source t-lemma and formeme, and other contextual information, and it is calculated as a linear combination of two main components: • The discriminative TM (Mareˇcek et al., 2010) is a set of maximum entropy (MaxEnt) models (Berger et al., 1996) trained for each specific source t-lemma and formeme, where the prediction is ˇ based on features extracted from the source tree (Crouse et al., 1998; Zabokrtsk´ y and Popel, 2009). • The dictionary TM is a bilingual dictionary that contains a list of possible translation equivalents based on relative frequencies and no contextual features. Both components are trained on the parallel corpora at the t-level. The final score assigned to each tlemma and formeme in the TMs is calculated through interpolation. For the t-lemmas, weights of 0.5 and 1 are assigned to the dictionary TM and the discriminative TM, respectively. In the case of formemes, the values are reversed. Using these two TMs, we obtain a weighted n-best list of translation variants for each t-lemma and each f"
W15-5707,W08-0325,0,0.0337859,"ucture often move the level of linguistic abstraction a step deeper into semantic roles and relations, which should entail a simpler transfer step because of the greater structural similarity between the deep structures of the source and target languages as compared to the surface realizations; better generalization of the language as it operates on lemmas of content words and grammatical constructions are abstracted with their meaning captured by language-independent attributes; and improved grammaticality of the output given the explicit representation of target-side sentence structure. ˇ ˇ y et al., 2008; Popel and Zabokrtsk´ y, 2010) has emerged as a potential archiTectoMT (Zabokrtsk´ tecture to develop such an approach, together with other deep-transfer systems such as Matxin (Mayor et al., 2011) and the one proposed by Gasser (2012). In contrast to those systems, TectoMT combines linguistic knowledge and statistical techniques, particularly during transfer, and it aims at transfer on the so-called tectogrammatical layer (Hajiˇcov´a, 2000), a layer of deep syntactic dependency trees. In this paper we present a description of the work done to develop a TectoMT system for both directions of E"
W15-5707,zeman-2008-reusable,0,0.0118352,"word forms and term elements) via standard input and output NAF through standard output. The NAF format is a linguistic annotation format designed for complex NLP pipelines (Fokkens et al., 2014). The analyses generated by the ixa-pipes tools follow the AnCora guidelines both for morphological tags and dependency tree structures. This mostly equates to the a-layer in the TectoMT stratification. Therefore, to fully integrate the analyses into Treex and generate the expected a-tree, the analyses had to be mapped to a universal PoS and dependency tags. TectoMT currently uses the Interset tagset (Zeman, 2008) and HamleDT guidelines (Zeman et al., 2014). To implement this mapping, we used existing modules such as the Interset driver for Spanish AnCora Treebank tagset4 by Dan Zeman and Zdenek Zabokrtsky, and the Harmonization Treex block for Spanish AnCora-style dependencies5 by Dan Zeman, Zdenek Zabokrtsky and Martin Popel. On top of these, and in order to form the t-level tree, we used 16 additional blocks: 1. Language-independent blocks. 11 of the blocks were simply reused from the languageindependent set already available in Treex. These mainly re-arrange nodes, mark heads (coordinations, clause"
W16-2332,N03-1017,0,0.00891535,"provide several translation options for each node along with their estimated probability. The best options are then selected using a Hidden Markov Tree Model (HMTM) ˇ with a target-language tree model (Zabokrtsk´ y and Popel, 2009). For this specific task, where we need to work on a specific domain, an extended version of TectoMT was used allowing interpolation of multiple TMs (Rosa et al., 2015). Moses All the systems submitted that were based on Moses have been trained on a phrase-based model by Giza++ or mGiza with “grow-diag-finaland” symmetrization and “msd-bidirectional-fe” reordering (Koehn et al., 2003). For the language pairs where big quantities of domain-specific monolingual data were available along with the generic domain data, separate language models (domain-specific and generic) were interpolated against our ICT domain-specific development set. For LM training and interpolation, the SRILM toolkit (Stolcke, 2002) was used. The method of truecasing has been adopted for several language pairs where it proved useful. 3 TectoMT The deep translation is based on the TectoMT system, an open-source MT system based on the Treex platform for general natural-language processing. TectoMT uses a c"
W16-2332,C10-3009,0,0.0136209,"obabilities in both directions, lexical weightings in both directions, a phrase length penalty, a ”phrase-mslr-fe” lexicalized reordering model and a target language model. As for the language model, a 5-gram model was trained. The weights for the different components were adjusted to optimize BLEU using MERT tuning over the Batch1 development set, with an n-best list of size 100. For the TectoMT system, EU-Treex existing tools were used in order to get the a-layer. Eustagger is a robust and wide coverage morphological analyzer and POS tagger. The dependency parser is based on the MATE-tools (Bjrkelund et al., 2010). Basque models have been trained using the Basque Dependency Treebank (BDT) corpus (Aduriz et al., 2003). Transformation from the a-level analysis into t-level is partially performed with language-independent blocks thanks to the support of Interset (Zeman, 2008). The English-to-Basque TectoMT system uses the PaCo2 and the Batch1 corpora to train two separate translation models, and they are used to create an interpolated list of translation candidates. In addition to that, the terminological equivalences extracted from the localization PO files (VLC, LO and KDE) as well as the domain terms e"
W16-2332,W16-2334,1,0.789389,"Missing"
W16-2332,2005.mtsummit-papers.11,0,0.0123228,"PO files (VLC, LO and KDE) as well as the domain terms extracted from Wikipedia are used to identify domain terms before syntactic analysis and to ensure domain translation on transfer. Finally, an extra module to treat non linguistic elements (URLs, shell commands, ...) has been used to identify the elements that should be maintained untranslated on the output. Both systems were trained using the same training corpora: the 7th version of the Europarl corpus was used for both translation and language modDutch The Moses system for Dutch was trained on the third version of the Europarl corpus (Koehn, 2005) and the in-domain KDE4 Localization data (Tiedemann, 2012). Words are aligned with GIZA++ and tuning was done with MERT. The applied heuristics for the Dutch baselines were set to “grow-diag-final-and” alignment and “msdbidirectional-fe” reordering. For the creation of the language models, IRSTLM was used to train a 5-gram language model with Kneser-Ney smoothing on the monolingual part of the training corpora. For the TectoMT system, the analysis of Dutch input uses the Alpino system (Noord, 2006), a 438 of tectogrammatical trees. Two separate models were trained and interpolated, the first"
W16-2332,P14-5010,0,0.00318097,"ed Moses with the following factors: ENWordForm-BGLemma|Lemma|BGPOStag, where ENWordForm-BGLemma is an English word form when there is no appropriate Bulgarian one, or the Bulgarian lemma; BGPOStag is the appropriate Bulgarian tag representing grammatical features like number, tense, etc. adaptation and MERT training. Batch2 domain corpus was used for testing during development. The Moses system, EU-Moses, uses factored models to allow lemma-based word-alignment. After word alignment, the rest of the training process is based on lowercased word-forms and standard parameters: Stanford CoreNLP (Manning et al., 2014) and Eustagger (Alegria et al., 2002) tools are used for tokenization and lemmatization, MGIZA for word alignment with the ”growdiag-final-and” symmetrization heuristic, a maximum length of 75 tokens per sentence and 5 tokens per phrase, translation probabilities in both directions, lexical weightings in both directions, a phrase length penalty, a ”phrase-mslr-fe” lexicalized reordering model and a target language model. As for the language model, a 5-gram model was trained. The weights for the different components were adjusted to optimize BLEU using MERT tuning over the Batch1 development se"
W16-2332,W15-4101,1,0.800257,"was performed by the Moses tokenizer. No lemmatization or compound splitting was used and the casing was obtained with the Moses truecaser. For the training, a phrase-based model was used with a language model order of 5, with Kneser-Ney smoothing, which was interpolated using the SRILM tool. The word alignment was done with Giza++ on full forms and the final tuning was done using MERT. The Europarl corpus was used for the training data, both as monolingual data for training language models and as parallel data for training the phrase-table. Regarding the English-to-Portuguese TectoMT system (Silva et al., 2015)(Rodrigues et al., 2016a), PT-Treex, in order to get the a-layer the Portuguese system resorted to LX-Suite (Branco and Silva, 2006), a set of pre-existing shallow processing tools for Portuguese that include a sentence segmenter, a tokenizer, a POS tagger, a morphological analyser and a dependency parser, all with state-of-the-art performance. Treex blocks were created to be called and interfaced with these tools. After running the shallow processing tools, the dependency output of the parser is converted into Universal Dependencies (UD) (de Marneffe et al., 2014). These dependencies are then"
W16-2332,W10-1730,1,0.894585,"Missing"
W16-2332,W15-5712,1,0.718195,"ansfer, and synthesis 4 Basque Both English-Basque submissions are trained on the same training corpora. That is, the PaCO2eneu corpus for translation and language modeling, and the in-domain Batch1 corpus for domain 436 tors retrieved from POS tagged, lemmatized parallel corpora; and BG-DeepMoses — a system that also is based on standard factored Moses but the translation is done in two steps: (1) semanticsbased translation of the source language text to a mixed source-target language text which is then (2) translated to the target language via Moses. The latter system builds on Simov et al. (2015). As training data for both systems the following corpora were used: the Setimes parallel corpus, the Europarl parallel corpus and a corpus created on the basis of the documentation of LibreOffice. The corpora are linguistically processed with the IXA2 pipeline for the English part and the BTB pipeline for the Bulgarian. The analyses include POS tagging, lemmatization and WSD, using the UKB system,3 which provides graph-based methods for Word Sense Disambiguation and lexical similarity measurements. For the BG-Moses system, the following factors have been constructed: WordForm|Lemma|POStag. Fo"
W16-2332,H05-1066,0,0.184414,"Missing"
W16-2332,P14-5003,0,0.0466518,"Missing"
W16-2332,2006.jeptalnrecital-invite.2,1,0.754357,"Missing"
W16-2332,tiedemann-2012-parallel,0,0.0377489,"extracted from Wikipedia are used to identify domain terms before syntactic analysis and to ensure domain translation on transfer. Finally, an extra module to treat non linguistic elements (URLs, shell commands, ...) has been used to identify the elements that should be maintained untranslated on the output. Both systems were trained using the same training corpora: the 7th version of the Europarl corpus was used for both translation and language modDutch The Moses system for Dutch was trained on the third version of the Europarl corpus (Koehn, 2005) and the in-domain KDE4 Localization data (Tiedemann, 2012). Words are aligned with GIZA++ and tuning was done with MERT. The applied heuristics for the Dutch baselines were set to “grow-diag-final-and” alignment and “msdbidirectional-fe” reordering. For the creation of the language models, IRSTLM was used to train a 5-gram language model with Kneser-Ney smoothing on the monolingual part of the training corpora. For the TectoMT system, the analysis of Dutch input uses the Alpino system (Noord, 2006), a 438 of tectogrammatical trees. Two separate models were trained and interpolated, the first model with over 1.9 million sentences from Europarl (Koehn,"
W16-2332,L16-1094,1,0.833385,"ag-final-and” alignment and “msdbidirectional-fe” reordering. For the creation of the language models, IRSTLM was used to train a 5-gram language model with Kneser-Ney smoothing on the monolingual part of the training corpora. For the TectoMT system, the analysis of Dutch input uses the Alpino system (Noord, 2006), a 438 of tectogrammatical trees. Two separate models were trained and interpolated, the first model with over 1.9 million sentences from Europarl (Koehn, 2005) and the second model composed of the Batch1, the Microsoft Terminology Collection and ˇ the LibreOffice localization data (Stajner et al., 2016). Each pair of parallel sentences, one in English and one in Portuguese, are analyzed by Treex up to the t-layer level, where each pair of trees are fed into the model. The TectoMT synthesis (Rodrigues et al., 2016b) included other two lexical-semanticsrelated modules, the HideIT and gazetteers. The HideIT module handles entities that do not require translation such as URLs and shell commands. The gazetteers are specialized lexicons that handle the translation of named entities from the ITdomain such as menu items and button names. Finally, synset IDs were used as additional contextual feature"
W16-2332,P09-2037,1,0.925288,"uage-specific additions and distinguishes two levels of syntactic description: and Spanish, Charles University in Prague for Czech, by University of Groningen for Dutch, by University of Lisbon for Portuguese and by IICTBAS of the Bulgarian Academy of Sciences for Bulgarian. For each language two different systems were submitted, corresponding to different phases of the project, namely a phrase-based MT system built using Moses (Koehn et al., 2007), and a system exploiting deep language engineering approaches, that in all the languages but Bulgarian was imˇ plemented using TectoMT (Zabokrtsk´ y and Popel, 2009). For Bulgarian, its second MT system is not based on TectoMT, but on exploiting deep factors in Moses. All 12 systems are constrained, that is trained only on the data provided by the WMT16 IT-task organizers. We present briefly the Moses common setting and the TectoMT structure and then more detailed information for each language system are provided. In the last Section, results based on BLEU and TrueSkill are given and discussed. 2 • Surface dependency syntax (a-layer) – surface dependency trees containing all the tokens in the sentence. • Deep syntax (t-layer) – dependency trees that conta"
W16-2332,W08-0325,0,0.300026,"Missing"
W16-2332,L16-1438,1,0.826183,"Missing"
W16-2332,zeman-2008-reusable,0,0.0263149,"djusted to optimize BLEU using MERT tuning over the Batch1 development set, with an n-best list of size 100. For the TectoMT system, EU-Treex existing tools were used in order to get the a-layer. Eustagger is a robust and wide coverage morphological analyzer and POS tagger. The dependency parser is based on the MATE-tools (Bjrkelund et al., 2010). Basque models have been trained using the Basque Dependency Treebank (BDT) corpus (Aduriz et al., 2003). Transformation from the a-level analysis into t-level is partially performed with language-independent blocks thanks to the support of Interset (Zeman, 2008). The English-to-Basque TectoMT system uses the PaCo2 and the Batch1 corpora to train two separate translation models, and they are used to create an interpolated list of translation candidates. In addition to that, the terminological equivalences extracted from the localization PO files (VLC, LO and KDE) as well as the domain terms extracted from Wikipedia are used to identify domain terms before syntactical analysis and to ensure domain translation on transfer. Finally, an extra module to treat non linguistic elements (URLs, shell commands, ...) has been used, to identify the elements that s"
W16-2332,W15-5711,1,0.91741,"Missing"
W16-2332,de-marneffe-etal-2014-universal,0,\N,Missing
W16-2332,E06-2024,1,\N,Missing
W16-2332,P07-2045,0,\N,Missing
W16-2332,W13-2208,0,\N,Missing
W16-2332,bojar-etal-2012-joy,1,\N,Missing
W16-2332,L16-1441,1,\N,Missing
W16-2338,W09-0438,0,0.0359821,"versa, and 3 runs for each of the health test sets. We submitted the Systems 1, 2 and 3, and, therefore, the System 0 remained out of the evaluation. Table 4 shows the BLEU results of the three systems we submitted for the four test sets. The results of the remaining systems have not been published yet, so we can not compare our systems to the others. In any case, we can compare them with the average of all the runs submitted for the language pair for each sub-domain. State-of-the-art shows many approaches for transliteration in machine translation, most of them based on statistical methods (Deselaers et al., 2009; Habash, 2008; Hermjakob et al., 2008; Rama and Gali, 2009). In a previous work, we developed a system to automatically translate English medical neoclassical compounds such as “glaucoma” or “meningitis” into Basque (Perez-de Vi˜naspre and Oronoz, 2015). This translation system is based on affix translation and a transliteration module was also implemented. In this case, we adapted the transliteration module for the English-Spanish and Spanish-English pair for the neoclassical medical words as well as for the substances and pharmaceutical products. System System 1 System 2 System 3 Average Th"
W16-2338,P08-2015,0,0.180573,"le statistical machine translation system. In contrast, the Spanish morphology made the process more complex, as in addition to the number variability, we must also take into consideration the gender of the words, and even the combination of both (feminine and plural). With respect to transliteration, (Callison-Burch et al., 2006) exposes that state-of-the-art systems usually apply two strategies to cope with OOV words, neither of them satisfactory. In the first strategy the unknown word is omitted and in the second one it is not translated. The first strategy is even excluded as solution in (Habash, 2008), because the author considers it a trick to score better precision in evaluation metrics. Nevertheless, the second approach can be a good strategy whenever the OOV word is a Named Entity, such as a proper name or an organization name. Otherwise some action is needed. 4 Results In this section we provide the results given by the organizers that measures the BLEU score of the systems submitted as the test sets are not publicly available yet. Each team was allowed to submit up to 3 runs per test file, in our case, 3 runs for the biological test sets from English to Spanish and vice versa, and 3"
W16-2338,P08-1045,0,0.0668059,"Missing"
W16-2338,E09-2008,0,0.0226015,"utomatically translate English medical neoclassical compounds such as “glaucoma” or “meningitis” into Basque (Perez-de Vi˜naspre and Oronoz, 2015). This translation system is based on affix translation and a transliteration module was also implemented. In this case, we adapted the transliteration module for the English-Spanish and Spanish-English pair for the neoclassical medical words as well as for the substances and pharmaceutical products. System System 1 System 2 System 3 Average The module was implemented using Foma, a free software tool to specify finite-state automata and transducers (Hulden, 2009). Biological en-es es-en 31.57 30.66 31.32 30.59 29.61 29.51 31.34 30.17 Health en-es es-en 28.09 27.96 28.06 27.97 28.13 28.12 28.3 27.79 Table 3: BLEU results of our systems. The results obtained do not show any signifi480 cant improvement of the different systems and in general we are close to the average. We obtained a small improvement from the average in three of the sets and we are very close to it in the fourth one (English to Spanish translation on the Health domain). If we consider each System on its own, we can conclude that the System 2 does not give any advantage on what BLEU resu"
W16-2338,P07-2045,0,0.00683273,"ent the system developed at the IXA NLP Group from the University of the Basque Country for the Biomedical Translation Task in the First Conference on Machine Translation (WMT16). This is the first shared task organized for the biomedical domain inside WMT. The Biomedical Translation Task consists of translating scientific abstracts in health and biological domains for languages such as English, Spanish, French and Portuguese. In our case, we developed a system for English-Spanish and Spanish-English pairs. We present a system that takes a general Moses statistical machine translation system (Koehn et al., 2007) and adapts it to the biomedical domain. The adaptation of a MT system to a specific domain comes with two main issues: i) a bigger set of out-of-vocabulary (OOV) words and ii) the variation of the prominent sense of the words. Corpora The corpora pertains to two different sub-domains: health and biology. Thus, the corpus extracted from Scielo is separated by the domain the abstracts pertains. In the case of the Medline corpus there is a unique corpus for both sub-domains. Although the corpora is in general bilingual and aligned at sentence level, in some cases sentences from the parallel corp"
W16-2338,2005.mtsummit-papers.11,0,0.046039,"escriptions in SNOMED CT: Fully Specified Names (FSN) and Synonyms. Fully Specified Names are the descriptions used to identify the concepts and they have a semantic tag in parenthesis that indicates its semantic type and, consequently, its hierarchy. Those are descriptions to unambiguously identify the concept, and they are not proper terms you can find in texts. Spanish 1,248 5,163 2,227 Table 2: Monolingual corpora In addition to the in-domain corpora, we also included some other corpora available in other machine translation tasks inside the WMT challenge. • Parallel Corpora: – Europarl2 (Koehn, 2005): it is a corpus of parallel texts in 11 languages from the proceedings of the European Parliament. The version we used for this task has 2,218,201 English sentences and 2,123,835 Spanish sentences. For a direct alignment we excluded some of the sentences, obtaining 1,965,734 parallel sentences. 2 Terminological Resources 3 https://www.project-syndicate.org/ http://commoncrawl.org/ 5 http://www.ihtsdo.org/snomed-ct/ whysnomedct/snomedfeatures/ 4 http://www.statmt.org/europarl/ 478 corpora. That is, we grouped all the News corpora together, the Scielo Health bilingual and monolingual together,"
W16-2338,W09-3528,0,\N,Missing
W16-2338,N06-1003,0,\N,Missing
W16-6405,W12-3132,0,0.045366,"Missing"
W16-6405,W15-3009,0,0.0248943,"Missing"
W16-6405,W08-0325,0,0.0248875,"sults with simple techniques, e.g. force-translating domain-specific expressions. In such approaches, multiword entries are translated as if they were a single token-with-spaces, failing to represent the internal structure which makes TectoMT a powerful translation engine. In this work we enrich source and target multiword terms with syntactic structure, and seamlessly integrate them in the tree-based transfer phase of TectoMT. Our experiments on the IT domain using the Microsoft terminological resource show improvement in Spanish, Basque and Portuguese. 1 Introduction ˇ ˇ TectoMT (Zabokrtsk´ y et al., 2008; Popel and Zabokrtsk´ y, 2010) has emerged as an architecture to develop deep-transfer systems, where the translation step is done a deep level of analysis, in contrast to methods based on surface sequences of words. TectoMT combines linguistic knowledge and statistical techniques, particularly during transfer, and it aims at transfer on the so-called tectogrammatical layer (Hajiˇcov´a, 2000), a layer of deep syntactic dependency trees. In domain adaptation of machine translation, a typical scenario is as follows: there is an MT system trained on large general-domain data, and there is a bili"
W16-6405,zesch-etal-2008-extracting,0,0.0608747,"Missing"
W17-1720,bouamor-etal-2012-identifying,0,0.020018,"work (Section 2), a brief explanation about Matxin and the way it handles MWEs will be given (Section 3). Then, the experimental setup will be presented (Section 4), and results will be shown (Section 5). 1 Whereas Spanish is a romance language, Basque is a non-indoeuropean language which belongs to no known family. More details about the main differences between both languages are given in Section 3. 149 Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017), pages 149–154, c Valencia, Spain, April 4. 2017 Association for Computational Linguistics 3.1 corpora (Ren et al., 2009; Bouamor et al., 2012; Kordoni and Simova, 2014), rule-based systems often get bad results when MWEs are involved, as they tend to translate each word separately. Thus, this kind of expression being so frequent in natural language, MT systems benefit greatly from including phraseological knowledge, and several studies have shown that even the simplest method to process MWEs makes a difference in the system’s translation quality (Wehrli et al., 2009; Seretan, 2014). 3 Current MWE handling At the moment, Matxin uses a very simple method to process MWEs. When an entry in the system’s bilingual dictionary is formed by"
W17-1720,W11-0802,0,0.376259,"@ehu.eus, itziar.aduriz@ub.edu a.diazdeilarraza|gorka.labaka|kepa.sarasola@ehu.eus 2 Abstract MWEs are word combinations that need to be treated as a whole in order to get good results in lexically-sensitive NLP tasks (Sag et al., 2002). Not all MWEs are morphosyntactically fixed –there are also semi-fixed and flexible combinations–, which makes their processing a complex task. Some kinds of MWEs, like VNCs, are specially tricky, as they are more likely to have multiple morphosyntactic variants. Over the last decades, quite a lot of research has been done on MWE identification and extraction (Gurrutxaga and Alegria, 2011; Ramisch, 2015), which is relevant not only for NLP applications but also for other disciplines like Lexicography (Vincze et al., 2011). MWE-specific resources are being developed in a number of languages, as reported by Losnegaard et al. (2016) in a survey carried out within the PARSEME COST Action (IC1207). However, not so much work has been undertaken concerning the multilingual aspects of this phraseological phenomenon, although challenges get bigger when multiple languages are involved. One of the reasons why this happens is that MWEs are not usually translated word for word from one lan"
W17-1720,2006.amta-papers.25,0,0.03479,".28 7.50 NIST 3.88 3.90 TER 84.36 84.27 Table 1: BLEU, NIST and TER scores obtained by Matxin with and without VNC-specific information In example (9), for instance, the Basque NP needs a postposition other than the one automatically given as a translation of the Spanish preposition. Furthermore, it needs to be indefinite, but it would be translated as definite if no special rule was applied. (9) Results After integrating all the linguistic information into Matxin, the system was evaluated using three automatic evaluation metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and TER (Snover et al., 2006). Evaluation was carried out without casing, and two systems were compared: (a) the original one, Matxin, and (b) the same system with VNC-specific information. On the other hand, for the VNCs needing special grammatical treatment, the features that need to be taken into account are specified. For those cases, exceptional rules are added within the Transfer phase, so that the specified feature(s) is/are not translated regularly. The features specified in the database are: • • • • • ’They miss him.’ ES: Lo echan en falta. him.IndObj throw in lack MT: Faltan botatzen dute. lack.ine throw AuxV CT"
W17-1720,kordoni-simova-2014-multiword,0,0.255648,"ief explanation about Matxin and the way it handles MWEs will be given (Section 3). Then, the experimental setup will be presented (Section 4), and results will be shown (Section 5). 1 Whereas Spanish is a romance language, Basque is a non-indoeuropean language which belongs to no known family. More details about the main differences between both languages are given in Section 3. 149 Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017), pages 149–154, c Valencia, Spain, April 4. 2017 Association for Computational Linguistics 3.1 corpora (Ren et al., 2009; Bouamor et al., 2012; Kordoni and Simova, 2014), rule-based systems often get bad results when MWEs are involved, as they tend to translate each word separately. Thus, this kind of expression being so frequent in natural language, MT systems benefit greatly from including phraseological knowledge, and several studies have shown that even the simplest method to process MWEs makes a difference in the system’s translation quality (Wehrli et al., 2009; Seretan, 2014). 3 Current MWE handling At the moment, Matxin uses a very simple method to process MWEs. When an entry in the system’s bilingual dictionary is formed by more than one word, the wh"
W17-1720,L16-1364,0,0.168592,"Missing"
W17-1720,2009.eamt-1.18,0,0.0284224,"Workshop on Multiword Expressions (MWE 2017), pages 149–154, c Valencia, Spain, April 4. 2017 Association for Computational Linguistics 3.1 corpora (Ren et al., 2009; Bouamor et al., 2012; Kordoni and Simova, 2014), rule-based systems often get bad results when MWEs are involved, as they tend to translate each word separately. Thus, this kind of expression being so frequent in natural language, MT systems benefit greatly from including phraseological knowledge, and several studies have shown that even the simplest method to process MWEs makes a difference in the system’s translation quality (Wehrli et al., 2009; Seretan, 2014). 3 Current MWE handling At the moment, Matxin uses a very simple method to process MWEs. When an entry in the system’s bilingual dictionary is formed by more than one word, the whole expression is treated as a fixed sequence, that is, as if it was a single word. During the transfer phase, the Spanish MWE is replaced by its corresponding Basque word(s), as shown in example (1)2 . (1) Matxin: Rule-based MT from Spanish into Basque Matxin (Mayor et al., 2011) is an MT system which translates Spanish into Basque, two longdistance families. As opposed to Spanish, which uses preposi"
W17-1720,padro-stanilovsky-2012-freeling,0,0.0989717,"Missing"
W17-1720,P02-1040,0,0.106894,"the verbs and the NPs Postpositions of open slots BLEU 7.28 7.50 NIST 3.88 3.90 TER 84.36 84.27 Table 1: BLEU, NIST and TER scores obtained by Matxin with and without VNC-specific information In example (9), for instance, the Basque NP needs a postposition other than the one automatically given as a translation of the Spanish preposition. Furthermore, it needs to be indefinite, but it would be translated as definite if no special rule was applied. (9) Results After integrating all the linguistic information into Matxin, the system was evaluated using three automatic evaluation metrics: BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and TER (Snover et al., 2006). Evaluation was carried out without casing, and two systems were compared: (a) the original one, Matxin, and (b) the same system with VNC-specific information. On the other hand, for the VNCs needing special grammatical treatment, the features that need to be taken into account are specified. For those cases, exceptional rules are added within the Transfer phase, so that the specified feature(s) is/are not translated regularly. The features specified in the database are: • • • • • ’They miss him.’ ES: Lo echan en falta. him.IndObj throw i"
W17-1720,W09-2907,0,0.0782785,"Missing"
W19-7102,N19-1191,0,0.0117281,"nd the adaptation of a RBMT system for the medical domain as backup. With respect to the translation of EHRs, the bibliography is scarce, and nowadays we can only refer to a preliminary study for translating clinical notes from English to Spanish (Liu and Cai, 2015). Another approach for the task of translation of clinical texts is domain adaptation. Usually, when low resources for the desired domain are available, a bigger corpus from another domain is used to first train the system, which is then fine-tuned with the available in-domain corpus (Zoph et al., 2016). From another point of view, Bapna and Firat (2019) try to combine non-parametric or retrieval based approaches with NMT, looking for similarities between n-grams in the sentence to be translated and part of previously translated sentences, and then using this information for producing more accurate translations. Concerning backtranslation, we have considered the analysis performed by Poncelas et al. (2018), where different sizes of backtranslated corpora were added to the human translated corpora used as training corpus; and regarding the techniques used for backtranslation, we follow the work by Burlot and Yvon (2019) in which they compare t"
W19-7102,D18-1045,0,0.0124211,"tificial sentences and the copied monolingual corpus, and the performance of the systems is tested in the clinical domain. 5 In this section we show and discuss the automatic evaluation results of the experiments carried out with different architectures and backtranslation systems. In both cases, we calculate BLEU (Papineni et al., 2002) in development and test sets using the multi-bleu script included in Moses.5 5.1 Transformer: We train the Transformer system in the Spanish-to-Basque translation direction with the same hyperparameters specified in the previous section. Following the work by Edunov et al. (2018), we perform the translation by unrestricted random sampling, which is proved to obtain better results than restricted random sampling or traditional beam search when applied to backtranslation. SMT: Finally, we try Moses (Koehn et al., 2007) as a statistical system, adapted to the MomenT-2019 Architectures Table 5 shows the results of the tested architectures in two variants: 1) trained only with out-of-domain corpora, and 2) including all the clinical domain resources. We observe large and consistent improvements when adding in-domain data to each of the tested architectures. Surprisingly, t"
W19-7102,W11-2123,0,0.0264163,"implementation in Pytorch by OpenNMT (Klein et al., 2017). We use the recommended hyperparameters,4 except for the number of GPUs and batch-size, that were 3 https://github.com/Avmb/deep-nmtarchitectures/blob/master/configs/ bideep-bideep-rGRU-large/config.sh (Accessed on April 11, 2019.) 4 http://opennmt.net/OpenNMT-py/FAQ.html# how-do-i-use-the-transformer-model-doyou-support-multi-gpu (Accessed on April 11, 2019.) Dublin, Aug. 19-23, 2019 |p. 13 biomedical domain. We use default parametrisation with MGIZA for word alignment, a ”msdbidirectional-fe” lexicalised reordering model and a KenLM (Heafield, 2011) 5-gram target language model. The weights for the different components were adjusted to optimise BLEU using Minimum Error Rate Training (MERT) with an n-best list of size 100. halved to meet our hardware capabilities. 4.2 Backtranslation systems After trying different architectures, we select the one that obtains the best automatic evaluation results in the clinical domain and change the way the backtranslation is performed. For that, we compare the shallow RNN architecture with the one that gets the best results in the clinical domain, and also try RBMT and SMT systems to translate the EHRs"
W19-7102,N03-1017,0,0.0553735,"years the prevailing technology for machine translation, especially in the research community. Several architectures have been proposed for NMT, ranging from the initial Convolutional Neural Networks (CNN) (Kalchbrenner and Blunsom, 2013) and Recurrent Neural Networks (RNN) (Sutskever et al., 2014), to the most advanced Transformer (Vaswani et al., 2017). However, it is known that NMT systems require a large amount of training data to obtain optimal results (Koehn and Knowles, 2017), so traditional techniques as Rule-Based Machine Translation (RBMT) and Statistical Machine Translation (SMT) (Koehn et al., 2003) can be considered when the available resources are low. One of the techniques that has become a standard to increase the available resources for NMT systems is backtranslation (Sennrich et al., 2015a), consisting in automatically translating a monolingual corpus from the target language into the Dublin, Aug. 19-23, 2019 |p. 8 source language, and then adding both original and translated corpora to the training corpus. In our case, the availability of EHRs in Spanish enables us to improve the results for the translation of clinical texts from Basque to Spanish, also serving us as a resource fo"
W19-7102,W17-3204,0,0.0225806,"sh, conditioned by the current lack of clinical domain corpora in Basque. Neural Machine Translation (NMT) has become in the past recent years the prevailing technology for machine translation, especially in the research community. Several architectures have been proposed for NMT, ranging from the initial Convolutional Neural Networks (CNN) (Kalchbrenner and Blunsom, 2013) and Recurrent Neural Networks (RNN) (Sutskever et al., 2014), to the most advanced Transformer (Vaswani et al., 2017). However, it is known that NMT systems require a large amount of training data to obtain optimal results (Koehn and Knowles, 2017), so traditional techniques as Rule-Based Machine Translation (RBMT) and Statistical Machine Translation (SMT) (Koehn et al., 2003) can be considered when the available resources are low. One of the techniques that has become a standard to increase the available resources for NMT systems is backtranslation (Sennrich et al., 2015a), consisting in automatically translating a monolingual corpus from the target language into the Dublin, Aug. 19-23, 2019 |p. 8 source language, and then adding both original and translated corpora to the training corpus. In our case, the availability of EHRs in Spani"
W19-7102,P16-1160,0,0.0186106,"em for NMT between Basque and Spanish is already available online.1 In the NMT approach for Basque by Etchegoyhen et al. (2018), diverse morphological segmentation techniques are tested, including the afore1 https://www.modela.eus/eu/itzultzailea (Accessed on April 11, 2019.) MomenT-2019 mentioned Byte Pair Encoding (BPE) (Sennrich et al., 2015b), the linguistically motivated vocabulary reduction originally proposed for Turkish (Ataman et al., 2017) and the ixaKat morphological analyser for Basque (Alegria et al., 1996; Otegi et al., 2016). They also tried character-based Machine Translation (Lee et al., 2016), obtaining the best results for translating from Basque to Spanish when applying the morphological analyser for Basque followed by BPE word segmentation to the source language corpus, and only BPE word segmentation to the target language corpus. Regarding the clinical domain, Perez-deVinaspre (2017) developed a system for automatically translating the clinical terminology included in SNOMED CT (IHTSDO, 2014) into Basque. Perez-de-Vinaspre (2017) combined the use of lexical resources, transliteration of neoclassic terms, generation of nested terms and the adaptation of a RBMT system for the me"
W19-7102,W15-3816,0,0.0196422,"segmentation to the target language corpus. Regarding the clinical domain, Perez-deVinaspre (2017) developed a system for automatically translating the clinical terminology included in SNOMED CT (IHTSDO, 2014) into Basque. Perez-de-Vinaspre (2017) combined the use of lexical resources, transliteration of neoclassic terms, generation of nested terms and the adaptation of a RBMT system for the medical domain as backup. With respect to the translation of EHRs, the bibliography is scarce, and nowadays we can only refer to a preliminary study for translating clinical notes from English to Spanish (Liu and Cai, 2015). Another approach for the task of translation of clinical texts is domain adaptation. Usually, when low resources for the desired domain are available, a bigger corpus from another domain is used to first train the system, which is then fine-tuned with the available in-domain corpus (Zoph et al., 2016). From another point of view, Bapna and Firat (2019) try to combine non-parametric or retrieval based approaches with NMT, looking for similarities between n-grams in the sentence to be translated and part of previously translated sentences, and then using this information for producing more acc"
