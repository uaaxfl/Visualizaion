1999.mtsummit-1.79,J93-1001,0,0.0418335,"Missing"
1999.mtsummit-1.79,H91-1026,0,0.141918,"Missing"
1999.mtsummit-1.79,P91-1023,0,0.0511309,"Missing"
1999.mtsummit-1.79,W96-0201,0,0.0868358,"Missing"
1999.mtsummit-1.79,W97-0311,0,0.048186,"Missing"
1999.mtsummit-1.79,A97-1050,0,0.0331323,"Missing"
1999.mtsummit-1.79,J93-1004,0,\N,Missing
1999.mtsummit-1.79,J90-2002,0,\N,Missing
2020.cllrd-1.1,strotgen-gertz-2012-temporal,0,0.0544082,"Missing"
2020.lrec-1.423,W15-1409,0,0.0195902,"Missing"
2020.lrec-1.423,K19-2001,0,0.0577783,"Missing"
2020.lrec-1.423,strassel-etal-2010-darpa,1,0.705151,"though the types have been diversifying over time. Annotation often includes entities, events, relations and coreference and may be normalized or linked within or across documents, sometimes across languages and increasingly to knowledgebases. • Committed Belief Annotation of discussion forums in Chinese (LDC2019T03), English (LDC2019T16) and Spanish (LDC2019T09) developed by LDC for the DARPA DEFT program described in §4.5 • A collection (LDC2019T14) of 110 source documents from English newswire manually annotated for instances of categories defined with respect to the NFL Scoring ontology (Strassel et al. 2010) to support the DARPA Machine Reading program 7 8 3451 https://dirha.fbk.eu https://librivox.org • • 3.7 Multiple datasets from the NIST TAC KBP task including: source data for 2009-2014 (LDC2018T03) and 2016-2017 (LDC2019T12); training and evaluation data for the Slot Filling task in English for 2009-2014 (LDC2018T22) and in Chinese for 2014 (LDC2019T08); evaluation data for the 2012-2017 Cold Start task (LDC2019T17); training and evaluation data for the Entity Discovery and Linking task for 20092013 (LDC2018T16), 2014-2015, (LDC2019T02) and 2016-2017 (LDC2019T19), the Relation Extraction tas"
2020.lrec-1.423,wright-etal-2012-annotation,1,0.779908,"o supplement current approaches that use paid experts and paid crowd workers. They demonstrate the nearly boundless power of organizing willing contributors and offering as incentives: challenge, entertainment, competition, opportunities to contribute to technological advancement and by extension the betterment of one’s own community and the broader society. For example, Zooniverse has recruited nearly two million citizen scientists who have contributed more than 250 million judgements to researchers in astronomy, biology and other fields. LDC&apos;s internal web based annotation platform, webann (Wright et al. 2012), continues to support the majority of our workload, adding support for video and image annotation as these media gained importance in LDC projects. With the support of the NSF NIEUW project, we have created a new platform, Universal Annotator (UA), a reboot of the webann code base with portability as an explicit design goal. NIEUW has used UA to build the NameThatLanguage 14 language identification game and the Citizen Linguist portal LanguageARC15 (see §7) along with the 9 projects currently deployed on that portal and the LanguageARC, built upon LDC’s UA framework (see §6), hosts LR develop"
bird-etal-2000-atlas,A97-1051,1,\N,Missing
bird-etal-2000-atlas,bird-etal-2000-towards,1,\N,Missing
bird-etal-2000-atlas,cunningham-etal-2000-software,0,\N,Missing
C90-3049,C69-0101,0,0.534797,"Missing"
C90-3049,C88-1069,0,\N,Missing
cieri-etal-2000-large,wayne-2000-multilingual,0,\N,Missing
cieri-etal-2000-large,strassel-etal-2000-quality,1,\N,Missing
cieri-etal-2000-large,graff-bird-2000-many,1,\N,Missing
cieri-etal-2006-mixer,cieri-etal-2004-fisher,1,\N,Missing
cieri-etal-2012-twenty,N10-1024,0,\N,Missing
cieri-etal-2012-twenty,walker-etal-2010-large,1,\N,Missing
cieri-etal-2012-twenty,ahtaridis-etal-2012-ldc,1,\N,Missing
cieri-etal-2014-new,cieri-etal-2008-bridging,1,\N,Missing
cieri-etal-2014-new,P11-2122,0,\N,Missing
cieri-etal-2014-new,ide-etal-2014-language,1,\N,Missing
cieri-etal-2014-new,wright-2014-restful,1,\N,Missing
cieri-liberman-2000-issues,wayne-2000-multilingual,0,\N,Missing
cieri-liberman-2000-issues,strassel-etal-2000-quality,1,\N,Missing
cieri-liberman-2000-issues,graff-bird-2000-many,0,\N,Missing
cieri-liberman-2000-issues,geoffrois-etal-2000-transcribing,0,\N,Missing
cieri-liberman-2000-issues,bird-etal-2000-towards,0,\N,Missing
cieri-liberman-2000-issues,cieri-etal-2000-large,1,\N,Missing
cieri-liberman-2002-language,bird-etal-2002-open,0,\N,Missing
cieri-liberman-2002-language,strassel-etal-2000-quality,1,\N,Missing
cieri-liberman-2002-language,saggion-etal-2002-developing,0,\N,Missing
cieri-liberman-2002-language,graff-bird-2000-many,0,\N,Missing
cieri-liberman-2002-language,H01-1059,0,\N,Missing
cieri-liberman-2002-language,wayne-2000-multilingual,0,\N,Missing
cieri-liberman-2002-language,cieri-etal-2000-large,1,\N,Missing
cieri-liberman-2002-tides,bird-etal-2002-open,0,\N,Missing
cieri-liberman-2002-tides,saggion-etal-2002-developing,0,\N,Missing
cieri-liberman-2002-tides,H01-1059,0,\N,Missing
cieri-liberman-2002-tides,P99-1068,0,\N,Missing
cieri-liberman-2002-tides,wayne-2000-multilingual,0,\N,Missing
cieri-liberman-2002-tides,cieri-etal-2000-large,1,\N,Missing
cieri-liberman-2004-progress,bird-etal-2002-open,0,\N,Missing
cieri-liberman-2004-progress,strassel-etal-2000-quality,1,\N,Missing
cieri-liberman-2004-progress,wayne-2000-multilingual,0,\N,Missing
cieri-liberman-2006-data,maeda-strassel-2004-annotation,0,\N,Missing
cieri-liberman-2006-data,strassel-2004-linguistic,0,\N,Missing
cieri-liberman-2006-data,cieri-liberman-2004-progress,1,\N,Missing
cieri-liberman-2006-data,doddington-etal-2004-automatic,0,\N,Missing
cieri-liberman-2008-15,cieri-liberman-2006-data,1,\N,Missing
cieri-liberman-2010-adapting,mapelli-etal-2008-latest,0,\N,Missing
cieri-liberman-2010-adapting,cieri-liberman-2008-15,1,\N,Missing
D10-1071,P06-1084,0,0.048861,"Missing"
D10-1071,2008.eamt-1.3,0,0.0560375,"Missing"
D10-1071,N04-4038,0,0.100647,"Missing"
D10-1071,W09-0805,0,0.0501513,"Missing"
D10-1071,R09-1018,0,0.0352063,"Missing"
D10-1071,P08-1085,0,0.0364335,"Missing"
D10-1071,P05-1071,0,0.0769356,"Missing"
D10-1071,A00-2013,0,0.01337,"lly, we also consider a context-less approach, i.e. using only “unigram” features for labels as well as LEs. We call this feature set Zuni , and the corresponding SVM model Muni . The results of these various models, along with those of Mf ull are summarized in Table 5. Model Mbaseline Mind Muni Mcheat Mf ull E1 13.6 18.7 11.6 8.2 9.4 E2 9.1 6.0 6.4 2.8 3.8 Table 5: Percent error rates of alternative approaches. Note: The results reported are 10 fold cross validation test accuracies and no parameters have been tuned on them. We used same train-test splits for all the datasets. 5 Related Work (Hajic, 2000) show that for highly inflectional languages, the use of a morphological analyzer 1 A new version of MADA was released very close to the submission deadline for this conference. improves accuracy of disambiguation. (Diab et al., 2004) perform tokenization, POS tagging and base phrase chunking using an SVM based learner. (Ahmed and N¨urnberger, 2008) perform word-sense disambiguation using a Naive Bayesian model and rely on parallel corpora and matching schemes instead of a morphological analyzer. (Kulick, 2010) perform simultaneous tokenization and part-of-speech tagging for Arabic by separati"
D10-1071,C08-2011,0,0.0587293,"Missing"
D10-1071,P10-2063,0,0.0213625,"Missing"
D10-1071,mohamed-kubler-2010-arabic,0,0.024886,"Missing"
D10-1071,P08-2030,0,0.0268738,"Missing"
D10-1071,H05-1060,0,0.0542564,"Missing"
D10-1071,P09-1055,0,0.0233945,"Missing"
D10-1071,W02-1001,0,\N,Missing
L16-1333,W13-1701,0,0.0603584,"Missing"
L16-1333,W11-0610,0,0.045776,"Missing"
L18-1516,W01-0513,0,0.175699,"countries with common research infrastructure, especially HLTs, with additional support in the form of training, travel grants, workshops, help-desks and other outreach. At the same time, clinical groups and the medical field are beginning to recognize the promise of LRs and HLTs not only in the mining and management of vast stores of text and speech data but also in the diagnosis and tracking of disorders and therapies. These shifts in emphasis should not, and generally are not, seen as proof that our communities have fully solved traditional problems such as multiword expression extraction (Schone & Jurafsky, 2001), language identification from text (da Silva & Lopes, 2006), speech synthesis (Sproat, 2010, p. 206) or speech recognition (Schwartz et al., 2011, p. 399) even in well-studied English. However, in a world with limited resources, they do suggest that sponsors recognize the growing need to address a wider range of new languages and technologies and the growing power of the commercial sector to improve performance in market products. 2. Data Centers as Global Networks LDC is a consortium of educational, research and technology development groups in the academic, government and commercial sectors"
L18-1516,L16-1674,1,0.89746,"Missing"
N13-1083,W10-4343,0,0.0303867,"sist of spoken words and phrases that represent self-correction, hesitation, and floor-grabbing behaviors, but do not add semantic information; removing them yields the intended, fluent utterance. The presence of disfluencies in conversational speech data can cause problems for both downstream processing (parsing and other natural language processing tasks) and human readability of speech transcripts. There has been much research effort on automatic disfluency detection in recent years (Shriberg and Stolcke, 1997; Snover et al., 2004; Liu et al., 2006; Lin and Lee, 2009; Schuler et al., 2010; Georgila et al., 2010; Zwarts and Johnson, 2011), particularly from the DARPA EARS (Effective, Affordable, Reusable Speech-toText) MDE (MetaData Extraction) (DARPA Information Processing Technology Office, 2003) program, which focused on the automatic transcription of sizable amounts of speech data and rendering such transcripts in readable form, for both conversational telephone speech (CTS) and broadcast news (BN). However, the EARS MDE effort was focused on English only, and there hasn’t been much research on the effectiveness of similar automatic disfluency detection approaches for multiple languages. This pap"
N13-1083,W03-0430,0,0.0866272,"Missing"
N13-1083,J10-1001,0,0.0279547,"neous speech. They consist of spoken words and phrases that represent self-correction, hesitation, and floor-grabbing behaviors, but do not add semantic information; removing them yields the intended, fluent utterance. The presence of disfluencies in conversational speech data can cause problems for both downstream processing (parsing and other natural language processing tasks) and human readability of speech transcripts. There has been much research effort on automatic disfluency detection in recent years (Shriberg and Stolcke, 1997; Snover et al., 2004; Liu et al., 2006; Lin and Lee, 2009; Schuler et al., 2010; Georgila et al., 2010; Zwarts and Johnson, 2011), particularly from the DARPA EARS (Effective, Affordable, Reusable Speech-toText) MDE (MetaData Extraction) (DARPA Information Processing Technology Office, 2003) program, which focused on the automatic transcription of sizable amounts of speech data and rendering such transcripts in readable form, for both conversational telephone speech (CTS) and broadcast news (BN). However, the EARS MDE effort was focused on English only, and there hasn’t been much research on the effectiveness of similar automatic disfluency detection approaches for multi"
N13-1083,N04-4040,0,0.0372801,"duction Speech disfluencies are common phenomena in spontaneous speech. They consist of spoken words and phrases that represent self-correction, hesitation, and floor-grabbing behaviors, but do not add semantic information; removing them yields the intended, fluent utterance. The presence of disfluencies in conversational speech data can cause problems for both downstream processing (parsing and other natural language processing tasks) and human readability of speech transcripts. There has been much research effort on automatic disfluency detection in recent years (Shriberg and Stolcke, 1997; Snover et al., 2004; Liu et al., 2006; Lin and Lee, 2009; Schuler et al., 2010; Georgila et al., 2010; Zwarts and Johnson, 2011), particularly from the DARPA EARS (Effective, Affordable, Reusable Speech-toText) MDE (MetaData Extraction) (DARPA Information Processing Technology Office, 2003) program, which focused on the automatic transcription of sizable amounts of speech data and rendering such transcripts in readable form, for both conversational telephone speech (CTS) and broadcast news (BN). However, the EARS MDE effort was focused on English only, and there hasn’t been much research on the effectiveness of"
N13-1083,P11-1071,0,0.367378,"d phrases that represent self-correction, hesitation, and floor-grabbing behaviors, but do not add semantic information; removing them yields the intended, fluent utterance. The presence of disfluencies in conversational speech data can cause problems for both downstream processing (parsing and other natural language processing tasks) and human readability of speech transcripts. There has been much research effort on automatic disfluency detection in recent years (Shriberg and Stolcke, 1997; Snover et al., 2004; Liu et al., 2006; Lin and Lee, 2009; Schuler et al., 2010; Georgila et al., 2010; Zwarts and Johnson, 2011), particularly from the DARPA EARS (Effective, Affordable, Reusable Speech-toText) MDE (MetaData Extraction) (DARPA Information Processing Technology Office, 2003) program, which focused on the automatic transcription of sizable amounts of speech data and rendering such transcripts in readable form, for both conversational telephone speech (CTS) and broadcast news (BN). However, the EARS MDE effort was focused on English only, and there hasn’t been much research on the effectiveness of similar automatic disfluency detection approaches for multiple languages. This paper presents three main inno"
P14-2109,D08-1052,0,0.02555,"ow does the parser do on non-recursive NPs, separate from NPs resulting from modification? On PP attachment?” etc. Answering such questions is the goal of this work, which combines two strands of research. First, inspired by the tradition of Tree Adjoining Grammar-based research (Joshi and Schabes, 1997; Bangalore and Joshi, 2010), we use a decomposition of the full trees into “elementary trees” (henceforth “etrees”), with a derivation tree that records how the etrees relate to each other, as in Kulick et al. (2011). In particular, we use the “spinal” structure approach of (Shen et al., 2008; Shen and Joshi, 2008), where etrees are constrained to be unary-branching. 2 Framework for analyzing parsing performance We first describe the use of the regexes in tree decomposition, and then give some examples of in1 We refer only to the WSJ treebank portion of OntoNotes, which is roughly a subset of the Penn Treebank (Marcus et al., 1999) with annotation revisions including the addition of NML nodes. 2 We parse (c) while training on (a) to follow the procedure in Petrov and McDonald (2012) 668 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 668–673,"
P14-2109,N12-1031,1,0.896225,"Missing"
P14-2109,N13-1061,1,0.836283,"as well. For example, “make” is a match for VP-t in Figures 2 and 3, and is also a match for the span as well, since in both derivation trees it includes the words “make. . .Florida”. It is this matching for span as well as head that allows us to compare our results to evalb. We call the match just for the head the “Fh” score and the match that also includes the span information the “F-s” score. The F-s score roughly corresponds to the evalb score. However, the F2.4 Comparison with previous work This work is in the same basic line of research as the inter-annotator agreement analysis work in Kulick et al. (2013). However, that work did not utilize regexes, and focused on comparing sequences of identical strings. The current work scores on general categories of structures, without 6 A regex intermediate in a etree, such as VP-t above, is considered to have a default null attachment. Also, the attachment score is not relevant for regexes that already express a recursive structure, such as NP-modr. In Figure 2, NP-t in etree #a5 is considered as having the attachment to #a3. 670 regex NP-t VP-t PP-t S-vp NP-modr VP-aux SBAR-s ADVP-t NML-t ADJP-t QP-t NP-crd VP-crd S-crd SQ-v FRAG-nt Sections 2-21 (Onton"
P14-2109,D12-1096,0,0.0613251,"Missing"
P14-2109,J03-4003,0,\N,Missing
P14-2109,P11-2122,1,\N,Missing
strassel-etal-2006-integrated,W04-1602,1,\N,Missing
strassel-etal-2006-integrated,maeda-etal-2006-new,1,\N,Missing
W04-3111,kingsbury-palmer-2002-treebank,1,\N,Missing
W04-3111,P03-1002,0,\N,Missing
W04-3111,N03-1028,0,\N,Missing
W04-3111,P96-1008,0,\N,Missing
W04-3111,tateisi-tsujii-2004-part,0,\N,Missing
W06-2919,P05-1001,0,0.0144376,"Missing"
W06-2919,W03-0425,0,0.0139299,"Missing"
W06-2919,N04-1043,0,0.142536,"Missing"
W06-2919,W02-1028,0,0.106868,"d with these large corpora, the recent availability of entity lists in those domains has opened up interesting opportunities and challenges. Such lists are never complete and suffer from sampling biases, but we would like to exploit them, in combination with large unlabeled corpora, to speed up the creation of information extraction systems for different domains and languages. In this paper, we concentrate on exploring utility of such resources for named entity extraction. Previous approaches to context pattern induction were described by Riloff and Jones (1999), Agichtein and Gravano (2000), Thelen and Riloff (2002), Lin et al. (2003), and Etzioni et al. (2005), among others. The main advance in the present method is the combination of grammatical induction and statistical techniques to create high-precision patterns. The paper is organized as follows. Section 2 describes our pattern induction algorithm. Section 3 shows how to extend seed sets with entities extracted by the patterns from unlabeled data. Section 4 gives experimental results, and Section 5 compares our method with previous work. 1 For example, based on approximate matching, there is an overlap of only 22 organizations between the 2403 orga"
W06-2919,W03-0434,0,0.0325757,"Missing"
W16-0308,W10-4346,0,0.397733,"Missing"
W16-0308,P15-2035,0,0.35866,"Missing"
W16-0308,N13-1084,0,0.0689651,"Missing"
W99-0301,J93-2004,0,0.0476757,"]. ToBI is an acronym for &quot;Tones and Break Indices&quot;, and correspondingly provides two types of information: Tones, which are taken from a fixed vocabulary of categories of (stress-linked) &quot;pitch accents&quot; and (juncture-linked) &quot;boundary tones&quot;; and Break Indices, which are integers characterizing the strength and nature of interword disjunctures. We have added four additional annotations: coreference annotation and named entity annotation in the style of MUC-7 [wWW.muc. saic. com/proceedings/muc_7_toc. html] provided by Lynette Hirschman; syntactic structures in the style of the Penn TreeBank (Marcus et al., 1993) provided by Ann Taylor; and an alternative annotation for the F0 aspects of prosody, known as Tilt (Taylor, 1998) and provided by its inventor, Paul Taylor. Taylor has done Tilt annotations for much of the BU corpus, and will soon b e publishing them as a point of comparison with the ToBI tonal annotation. Tilt differs from ToBI in providing a quantitative rather than qualitative characterization of F0 obtrusions: where ToBI might say &quot;this is a L+H* pitch accent,&quot; Tilt would say &quot;This is an Fo obtrusion that starts at time to, lasts for duration d seconds, involves a Hz total F0 change, and"
