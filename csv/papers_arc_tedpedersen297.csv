2021.semeval-1.44,{S}em{E}val-2021 Task 11: {NLPC}ontribution{G}raph - Structuring Scholarly {NLP} Contributions for a Research Knowledge Graph,2021,-1,-1,3,0,1752,jennifer dsouza,Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),0,"There is currently a gap between the natural language expression of scholarly publications and their structured semantic content modeling to enable intelligent content search. With the volume of research growing exponentially every year, a search feature operating over semantically structured content is compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. {`}the NCG task{'}) tasks participants to develop automated systems that structure contributions from NLP scholarly articles in the English language. Being the first-of-its-kind in the SemEval series, the task released structured data from NLP scholarly articles at three levels of information granularity, i.e. at sentence-level, phrase-level, and phrases organized as triples toward Knowledge Graph (KG) building. The sentence-level annotations comprised the few sentences about the article{'}s contribution. The phrase-level annotations were scientific term and predicate phrases from the contribution sentences. Finally, the triples constituted the research overview KG. For the Shared Task, participating systems were then expected to automatically classify contribution sentences, extract scientific terms and relations from the sentences, and organize them as KG triples. Overall, the task drew a strong participation demographic of seven teams and 27 participants. The best end-to-end task system classified contribution sentences at 57.27{\%} F1, phrases at 46.41{\%} F1, and triples at 22.28{\%} F1. While the absolute performance to generate triples remains low, as conclusion to the article, the difficulty of producing such data and as a consequence of modeling it is highlighted."
2021.semeval-1.60,{D}uluth at {S}em{E}val-2021 Task 11: Applying {D}e{BERT}a to Contributing Sentence Selection and Dependency Parsing for Entity Extraction,2021,-1,-1,2,0,1802,anna martin,Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021),0,"This paper describes the Duluth system that participated in SemEval-2021 Task 11, NLP Contribution Graph. It details the extraction of contribution sentences and scientific entities and their relations from scholarly articles in the domain of Natural Language Processing. Our solution uses deBERTa for multi-class sentence classification to extract the contributing sentences and their type, and dependency parsing to outline each sentence and extract subject-predicate-object triples. Our system ranked fifth of seven for Phase 1: end-to-end pipeline, sixth of eight for Phase 2 Part 1: phrases and triples, and fifth of eight for Phase 2 Part 2: triples extraction."
2020.semeval-1.128,{D}uluth at {S}em{E}val-2020 Task 7: Using Surprise as a Key to Unlock Humorous Headlines,2020,-1,-1,4,1,15169,shuning jin,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"We use pretrained transformer-based language models in SemEval-2020 Task 7: Assessing the Funniness of Edited News Headlines. Inspired by the incongruity theory of humor, we use a contrastive approach to capture the surprise in the edited headlines. In the official evaluation, our system gets 0.531 RMSE in Subtask 1, 11th among 49 submissions. In Subtask 2, our system gets 0.632 accuracy, 9th among 32 submissions."
2020.semeval-1.255,{D}uluth at {S}em{E}val-2020 Task 12: Offensive Tweet Identification in {E}nglish with Logistic Regression,2020,-1,-1,1,1,1754,ted pedersen,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"This paper describes the Duluth systems that participated in SemEval{--}2020 Task 12, Multilingual Offensive Language Identification in Social Media (OffensEval{--}2020). We participated in the three English language tasks. Our systems provide a simple machine learning baseline using logistic regression. We trained our models on the distantly supervised training data made available by the task organizers and used no other resources. As might be expected we did not rank highly in the comparative evaluation: 79th of 85 in task A, 34th of 43 in task B, and 24th of 39 in task C. We carried out a qualitative analysis of our results and found that the class labels in the gold standard data are somewhat noisy. We hypothesize that the extremely high accuracy ({\textgreater}{\$} 90{\%}) of the top ranked systems may reflect methods that learn the training data very well but may not generalize to the task of identifying offensive language in English. This analysis includes examples of tweets that despite being mildly redacted are still offensive."
S19-2106,{D}uluth at {S}em{E}val-2019 Task 6: Lexical Approaches to Identify and Categorize Offensive Tweets,2019,0,1,1,1,1754,ted pedersen,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"This paper describes the Duluth systems that participated in SemEval{--}2019 Task 6, Identifying and Categorizing Offensive Language in Social Media (OffensEval). For the most part these systems took traditional Machine Learning approaches that built classifiers from lexical features found in manually labeled training data. However, our most successful system for classifying a tweet as offensive (or not) was a rule-based black{--}list approach, and we also experimented with combining the training data from two different but related SemEval tasks. Our best systems in each of the three OffensEval tasks placed in the middle of the comparative evaluation, ranking 57th of 103 in task A, 39th of 75 in task B, and 44th of 65 in task C."
S19-2162,{D}uluth at {S}em{E}val-2019 Task 4: The Pioquinto Manterola Hyperpartisan News Detector,2019,0,0,2,0,25138,saptarshi sengupta,Proceedings of the 13th International Workshop on Semantic Evaluation,0,"This paper describes the Pioquinto Manterola Hyperpartisan News Detector, which participated in SemEval-2019 Task 4. Hyperpartisan news is highly polarized and takes a very biased or one{--}sided view of a particular story. We developed two variants of our system, the more successful was a Logistic Regression classifier based on unigram features. This was our official entry in the task, and it placed 23rd of 42 participating teams. Our second variant was a Convolutional Neural Network that did not perform as well."
S18-1060,{UMDS}ub at {S}em{E}val-2018 Task 2: Multilingual Emoji Prediction Multi-channel Convolutional Neural Network on Subword Embedding,2018,9,0,2,0,28792,zhenduo wang,Proceedings of The 12th International Workshop on Semantic Evaluation,0,This paper describes the UMDSub system that participated in Task 2 of SemEval-2018. We developed a system that predicts an emoji given the raw text in a English tweet. The system is a Multi-channel Convolutional Neural Network based on subword embeddings for the representation of tweets. This model improves on character or word based methods by about 2{\%}. Our system placed 21st of 48 participating systems in the official evaluation.
S18-1077,{D}uluth {UROP} at {S}em{E}val-2018 Task 2: Multilingual Emoji Prediction with Ensemble Learning and Oversampling,2018,3,0,2,1,15169,shuning jin,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes the Duluth UROP systems that participated in SemEval{--}2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of ensembles made up of classifiers using Naive Bayes, Logistic Regression, and Random Forests. We used unigram and bigram features and tried to offset the skewness of the data through the use of oversampling. Our task evaluation results place us 19th of 48 systems in the English evaluation, and 5th of 21 in the Spanish. After the evaluation we realized that some simple changes to our pre-processing could significantly improve our results. After making these changes we attained results that would have placed us sixth in the English evaluation, and second in the Spanish."
S18-1082,{ALANIS} at {S}em{E}val-2018 Task 3: A Feature Engineering Approach to Irony Detection in {E}nglish Tweets,2018,0,0,3,0,28820,kevin swanberg,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes the ALANIS system that participated in Task 3 of SemEval-2018. We develop a system for detection of irony, as well as the detection of three types of irony: verbal polar irony, other verbal irony, and situational irony. The system uses a logistic regression model in subtask A and a voted classifier system with manually developed features to identify ironic tweets. This model improves on a naive bayes baseline by about 8 percent on training set."
S18-1149,"{UMD}uluth-{CS}8761 at {S}em{E}val-2018 Task9: Hypernym Discovery using Hearst Patterns, Co-occurrence frequencies and Word Embeddings",2018,5,0,3,0,28890,arshia hassan,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"Hypernym Discovery is the task of identifying potential hypernyms for a given term. A hypernym is a more generalized word that is super-ordinate to more specific words. This paper explores several approaches that rely on co-occurrence frequencies of word pairs, Hearst Patterns based on regular expressions, and word embeddings created from the UMBC corpus. Our system Babbage participated in Subtask 1A for English and placed 6th of 19 systems when identifying concept hypernyms, and 12th of 18 systems for entity hypernyms."
W17-2313,Improving Correlation with Human Judgments by Integrating Semantic Similarity with Second{--}Order Vectors,2017,29,1,2,0.925992,14659,bridget mcinnes,{B}io{NLP} 2017,0,"Vector space methods that measure semantic similarity and relatedness often rely on distributional information such as co{--}occurrence frequencies or statistical measures of association to weight the importance of particular co{--}occurrences. In this paper, we extend these methods by incorporating a measure of semantic similarity based on a human curated taxonomy into a second{--}order vector representation. This results in a measure of semantic relatedness that combines both the contextual information available in a corpus{--}based vector space representation with the semantic knowledge found in a biomedical ontology. Our results show that incorporating semantic similarity into a second order co-occurrence matrices improves correlation with human judgments for both similarity and relatedness, and that our method compares favorably to various different word embedding methods that have recently been evaluated on the same reference standards we have used."
S17-2064,{D}uluth at {S}em{E}val-2017 Task 6: Language Models in Humor Detection,2017,5,0,2,0,10527,xinru yan,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes the Duluth system that participated in SemEval-2017 Task 6 {\#}HashtagWars: Learning a Sense of Humor. The system participated in Subtasks A and B using N-gram language models, ranking highly in the task evaluation. This paper discusses the results of our system in the development and evaluation stages and from two post-evaluation runs."
S17-2070,"{D}uluth at {S}em{E}val-2017 Task 7 : Puns Upon a Midnight Dreary, Lexical Semantics for the Weak and Weary",2017,5,2,1,1,1754,ted pedersen,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes the Duluth systems that participated in SemEval-2017 Task 7 : Detection and Interpretation of English Puns. The Duluth systems participated in all three subtasks, and relied on methods that included word sense disambiguation and measures of semantic relatedness."
W16-6203,Why Do They Leave: Modeling Participation in Online Depression Forums,2016,14,7,2,1,22246,farig sadeque,Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media,0,None
W16-6105,Analysis of Anxious Word Usage on Online Health Forums,2016,16,2,5,0,33400,nicolas reyvillamizar,Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis,0,None
W16-0322,Semi-supervised {CLP}sych 2016 Shared Task System Submission,2016,2,1,6,0,33400,nicolas reyvillamizar,Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology,0,None
S16-1207,{D}uluth at {S}em{E}val 2016 Task 14: Extending Gloss Overlaps to Enrich Semantic Taxonomies,2016,0,0,1,1,1754,ted pedersen,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
S16-1211,{UMND}uluth at {S}em{E}val-2016 Task 14: {W}ord{N}et{'}s Missing Lemmas,2016,2,0,2,0,34343,jon rusert,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper presents a solution to Semeval 2016 Task 14 which asks for a system that is able to insert new lemmas into WordNet. Our system aims to do this by overlapping words in the definitions of the to-be-inserted lemma and all senses in WordNet. This paper includes the results of our system and also includes the baseline provided by Task 14, with our system scoring higher than the random baseline, and lower than the first word baseline."
L16-1541,Age and Gender Prediction on Health Forum Data,2016,6,3,4,0,11296,prasha shrestha,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Health support forums have become a rich source of data that can be used to improve health care outcomes. A user profile, including information such as age and gender, can support targeted analysis of forum data. But users might not always disclose their age and gender. It is desirable then to be able to automatically extract this information from users{'} content. However, to the best of our knowledge there is no such resource for author profiling of health forum data. Here we present a large corpus, with close to 85,000 users, for profiling and also outline our approach and benchmark results to automatically detect a user{'}s age and gender from their forum posts. We use a mix of features from a user{'}s text as well as forum specific features to obtain accuracy well above the baseline, thus showing that both our dataset and our method are useful and valid."
W15-2602,Predicting Continued Participation in Online Health Forums,2015,14,4,3,1,22246,farig sadeque,Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis,0,"Online health forums provide advice and emotional solace to their users from a social network of people who have faced similar conditions. Continued participation of users is thus critical to their success. In this paper, we develop machine learning models for predicting whether or not a user will continue to participate in an online health forum. The prediction models are trained and tested over a large dataset collected from the support group based social networking site dailystrength.org. We find that our models can predict continued participation with over 83% accuracy after as little as 1 month observing the userxe2x80x99s activities, and that performance increases rapidly up to 1 year of observation. We also show that features such as the time since a userxe2x80x99s last activity are consistently predictive regardless of the length of the observation period, while other features, such as the number of times a user replies to others, decrease in predictiveness as the observation period grows."
W15-1206,Screening {T}witter Users for Depression and {PTSD} with Lexical Decision Lists,2015,6,24,1,1,1754,ted pedersen,Proceedings of the 2nd Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality,0,"This paper describes various systems from the University of Minnesota, Duluth that participated in the CLPsych 2015 shared task. These systems learned decision lists based on lexical features found in training data. These systems typically had average precision in the range of .70 xe2x80x90 .76, whereas a random baseline attained .47 xe2x80x90 .49."
S15-2076,{D}uluth: Word Sense Discrimination in the Service of Lexicography,2015,11,5,1,1,1754,ted pedersen,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes the Duluth systems that participated in Task 15 of SemEval 2015. The goal of the task was to automatically construct dictionary entries (via a series of three subtasks). Our systems participated in subtask 2, which involved automatically clustering the contexts in which a target word occurs into its different senses. Our results are consistent with previous word sense induction and discrimination findings, where it proves difficult to beat a baseline algorithm that assigns all instances of a target word to a single sense. However, our method of predicting the number of senses automatically fared quite well."
S14-2040,{D}uluth : Measuring Cross-Level Semantic Similarity with First and Second Order Dictionary Overlaps,2014,13,0,1,1,1754,ted pedersen,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper describes the Duluth systems that participated in the Crossxe2x80x90Level Semantic Similarity task of SemEvalxe2x80x902014. These three systems were all unsupervised and relied on a dictionary melded together from various sources, and used firstxe2x80x90order (Lesk) and secondxe2x80x90order (Vector) overlaps to measure similarity. The firstxe2x80x90order overlaps fared well according to Spearmanxe2x80x99s correlation (top 5) but less so relative to Pearsonxe2x80x99s. Most systems performed at comparable levels for both Spearmanxe2x80x99s and Pearsonxe2x80x99s measure, which suggests the Duluth approach is potentially unique among the participating systems."
S13-2036,{D}uluth : Word Sense Induction Applied to Web Page Clustering,2013,14,6,1,1,1754,ted pedersen,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"The Duluth systems that participated in task 11 of SemEvalxe2x80x902013 carried out word sense induction (WSI) in order to cluster Web search results. They relied on an approach that represented Web snippets using secondxe2x80x90order coxe2x80x90 occurrences. These systems were all implemented using SenseClusters, a freely available open source software package."
P13-1166,Offspring from Reproduction Problems: What Replication Failure Teaches Us,2013,35,45,4,0,2845,antske fokkens,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Repeating experiments is an important instrument in the scientific toolbox to validate previous work and build upon existing work. We present two concrete use cases involving key techniques in the NLP domain for which we show that reproducing results is still difficult. We show that the deviation that can be found in reproduction efforts leads to questions about how our results should be interpreted. Moreover, investigating these deviations provides new insights and a deeper understanding of the examined techniques. We identify five aspects that can influence the outcomes of experiments that are typically not addressed in research papers. Our use cases show that these aspects may change the answer to research questions leading us to conclude that more care should be taken in interpreting our results and more research involving systematic testing of methods is required in our field."
N13-3007,{UMLS}::{S}imilarity: Measuring the Relatedness and Similarity of Biomedical Concepts,2013,18,7,2,1,14659,bridget mcinnes,Proceedings of the 2013 {NAACL} {HLT} Demonstration Session,0,"UMLS::Similarity is freely available open source software that allows a user to measure the semantic similarity or relatedness of biomedical terms found in the Unified Medical Language System (UMLS). It is written in Perl and can be used via a command line interface, an API, or a Web interface."
S12-1070,{D}uluth : Measuring Degrees of Relational Similarity with the Gloss Vector Measure of Semantic Relatedness,2012,9,8,1,1,1754,ted pedersen,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"This paper describes the Duluth systems that participated in Task 2 of SemEval-2012. These systems were unsupervised and relied on variations of the Gloss Vector measure found in the freely available software package WordNet:: Similarity. This method was moderately successful for the Class-Inclusion, Similar, Contrast, and Non-Attribute categories of semantic relations, but mimicked a random baseline for the other six categories."
W11-1306,Identifying Collocations to Measure Compositionality: Shared Task System Description,2011,9,7,1,1,1754,ted pedersen,Proceedings of the Workshop on Distributional Semantics and Compositionality,0,"This paper describes three systems from the University of Minnesota, Duluth that participated in the DiSCo 2011 shared task that evaluated distributional methods of measuring semantic compositionality. All three systems approached this as a problem of collocation identification, where strong collocates are assumed to be minimally compositional. duluth-1 relies on the t-score, whereas duluth-2 and duluth-3 rely on Pointwise Mutual Information (pmi). duluth-1 was the top ranked system overall in coarse--grained scoring, which was a 3-way category assignment where pairs were assigned values of high, medium, or low compositionality."
W11-0821,"The Ngram Statistics Package (Text::{NSP}) : A Flexible Tool for Identifying Ngrams, Collocations, and Word Associations",2011,11,18,1,1,1754,ted pedersen,Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,0,"The Ngram Statistics Package (Text::NSP) is freely available open-source software that identifies ngrams, collocations and word associations in text. It is implemented in Perl and takes advantage of regular expressions to provide very flexible tokenization and to allow for the identification of non-adjacent ngrams. It includes a wide range of measures of association that can be used to identify collocations."
W11-0317,Using Second-order Vectors in a Knowledge-based Method for Acronym Disambiguation,2011,25,12,2,1,14659,bridget mcinnes,Proceedings of the Fifteenth Conference on Computational Natural Language Learning,0,"In this paper, we introduce a knowledge-based method to disambiguate biomedical acronyms using second-order co-occurrence vectors. We create these vectors using information about a long-form obtained from the Unified Medical Language System and Medline. We evaluate this method on a dataset of 18 acronyms found in biomedical text. Our method achieves an overall accuracy of 89%. The results show that using second-order features provide a distinct representation of the long-form and potentially enhances automated disambiguation."
S10-1081,{D}uluth-{WSI}: {S}ense{C}lusters Applied to the Sense Induction Task of {S}em{E}val-2,2010,7,26,1,1,1754,ted pedersen,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"The Duluth-WSI systems in SemEval-2 built word co--occurrence matrices from the task test data to create a second order co--occurrence representation of those test instances. The senses of words were induced by clustering these instances, where the number of clusters was automatically predicted. The Duluth-Mix system was a variation of WSI that used the combination of training and test data to create the co-occurrence matrix. The Duluth-R system was a series of random baselines."
N10-1047,Information Content Measures of Semantic Similarity Perform Better Without Sense-Tagged Text,2010,10,53,1,1,1754,ted pedersen,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,This paper presents an empirical comparison of similarity measures for pairs of concepts based on Information Content. It shows that using modest amounts of untagged text to derive Information Content results in higher correlation with human similarity judgments than using the largest available corpus of manually annotated sense--tagged text.
N09-5005,{W}ord{N}et::{S}ense{R}elate::{A}ll{W}ords - A Broad Coverage Word Sense Tagger that Maximizes Semantic Relatedness,2009,2,76,1,1,1754,ted pedersen,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Demonstration Session",0,"WordNet::SenseRelate::AllWords is a freely available open source Perl package that assigns a sense to every content word (known to WordNet) in a text. It finds the sense of each word that is most related to the senses of surrounding words, based on measures found in WordNet::Similarity. This method is shown to be competitive with results from recent evaluations including Senseval-2 and Senseval-3."
J08-3010,Last Words: Empiricism Is Not a Matter of Faith,2008,3,54,1,1,1754,ted pedersen,Computational Linguistics,0,"xe2x80x9cHurrah, this is it!xe2x80x9d you exclaim as you set down the most recent issue of Computational Linguistics. xe2x80x9cThis Zigglebottom Tagger is exactly what I need!xe2x80x9d A gleeful smile crosses your face as you imagine how your system will improve once you replace your tagger from graduate school with the clearly superior Zigglebottom method. You rub your hands together and page through the article looking for a way to obtain the tagger, but nothing is mentioned. That doesnxe2x80x99t dampen your enthusiasm, so you search the Web, but still nothing turns up. You persist though; those 17 pages of statistically significant results really are impressive. So you e-mail Zigglebottom asking for the tagger. Some days, or perhaps weeks, later, you get a hesitant reply saying: xe2x80x9cWexe2x80x99re planning to release a demo version soon, stay tuned . . . xe2x80x9d Or perhaps: xe2x80x9cWe donxe2x80x99t normally do this, but we can send you a copy (informally) once we clean it up a bit . . . xe2x80x9d Or maybe: xe2x80x9cWe canxe2x80x99t actually give you the tagger, but you should be able to re-implement it from the article. Just let us know if you have any questions . . . xe2x80x9d Still having faith, and lacking any better alternative, you decide to re-implement the Zigglebottom Tagger. Despite three months of on-and-off effort, the end result provides just the same accuracy as your old tagger, which is nowhere near that reported in the article. Feeling sheepish, you conclude you must have misunderstood something, or maybe therexe2x80x99s a small detail missing from the article. So you contact Zigglebottom again and explain your predicament. He eventually responds: xe2x80x9cWexe2x80x99ll look into this right away and get back to you . . . xe2x80x9d A year passes. You have the good fortune to bump into Zigglebottom at the Annual Meeting of the Association for Computational Linguistics (ACL). You angle for a seat next to him during a night out, and you buy him a few beers before you politely resume your quest for the tagger. Finally, he confesses rather glumly: xe2x80x9cMy student Pifflewhap was the one who did the implementation and ran the experiments, and if hexe2x80x99d only respond to my e-mail I could ask him to tell you how to get it working, but hexe2x80x99s graduated now and is apparently too busy to reply.xe2x80x9d After a fewmore beers, Zigglebottom finally agrees to give you the tagger: xe2x80x9cIxe2x80x99ll send you the version of the code I have, no promises though!xe2x80x9d And true to his word, what he sends is incomplete and undocumented. It doesnxe2x80x99t compile easily, and itxe2x80x99s engineered so that a jumble of programs must be run in an undisclosed kabalistic sequence known only to (perhaps) the elusive Pifflewhap. You try your best to make it work every now"
W07-1002,Determining the Syntactic Structure of Medical Terms in Clinical Notes,2007,25,4,2,1,14659,bridget mcinnes,"Biological, translational, and clinical language processing",0,This paper demonstrates a method for determining the syntactic structure of medical terms. We use a model-fitting method based on the Log Likelihood Ratio to classify three-word medical terms as right or left-branching. We validate this method by computing the agreement between the classification produced by the method and manually annotated classifications. The results show an agreement of 75%--83%. This method may be used effectively to enable a wide range of applications that depend on the semantic interpretation of medical terms including automatic mapping of terms to standardized vocabularies and induction of terminologies from unstructured medical text.
S07-1086,{UMND}1: Unsupervised Word Sense Disambiguation Using Contextual Semantic Relatedness,2007,7,38,3,0.909091,34497,siddharth patwardhan,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"In this paper we describe an unsupervised WordNet-based Word Sense Disambiguation system, which participated (as UMND1) in the SemEval-2007 Coarse-grained English Lexical Sample task. The system disambiguates a target word by using WordNet-based measures of semantic relatedness to find the sense of the word that is semantically most strongly related to the senses of the words in the context of the target word. We briefly describe this system, the configuration options used for the task, and present some analysis of the results."
S07-1087,{UMND}2 : {S}ense{C}lusters Applied to the Sense Induction Task of Senseval-4,2007,10,15,1,1,1754,ted pedersen,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"SenseClusters is a freely--available open--source system that served as the University of Minnesota, Duluth entry in the Senseval-4 sense induction task. For this task SenseClusters was configured to construct representations of the instances to be clustered using the centroid of word cooccurrence vectors that replace the words in an instance. These instances are then clustered using k--means where the number of clusters is discovered automatically using the Adapted Gap Statistic. In these experiments SenseClusters did not use any information outside of the raw untagged text that was to be clustered, and no tuning of the system was performed using external corpora."
W06-2501,Using {W}ord{N}et-based Context Vectors to Estimate the Semantic Relatedness of Concepts,2006,20,326,2,0.952381,34497,siddharth patwardhan,Proceedings of the Workshop on Making Sense of Sense: Bringing Psycholinguistics and Computational Linguistics Together,0,"In this paper, we introduce a WordNetbased measure of semantic relatedness by combining the structure and content of WordNet with coxe2x80x93occurrence information derived from raw text. We use the coxe2x80x93occurrence information along with the WordNet definitions to build gloss vectors corresponding to each concept in WordNet. Numeric scores of relatedness are assigned to a pair of concepts by measuring the cosine of the angle between their respective gloss vectors. We show that this measure compares favorably to other measures with respect to human judgments of semantic relatedness, and that it performs well when used in a word sense disambiguation algorithm that relies on semantic relatedness. This measure is flexible in that it can make comparisons between any two concepts without regard to their part of speech. In addition, it can be adapted to different domains, since any plain text corpus can be used to derive the coxe2x80x93occurrence information."
W06-2004,Improving Name Discrimination: A Language Salad Approach,2006,9,4,1,1,1754,ted pedersen,Proceedings of the Cross-Language Knowledge Induction Workshop,0,"This paper describes a method of discriminating ambiguous names that relies upon features found in corpora of a more abundant language. In particular, we discriminate ambiguous names in Bulgarian, Romanian, and Spanish corpora using information derived from much larger quantities of English data. We also mix together occurrences of the ambiguous name found in English with the occurrences of the name in the language in which we are trying to discriminate. We refer to this as a language salad, and find that it often results in even better performance than when only using English or the language itself as the source of information for discrimination."
N06-4007,Automatic Cluster Stopping with Criterion Functions and the Gap Statistic,2006,6,38,1,1,1754,ted pedersen,"Proceedings of the Human Language Technology Conference of the {NAACL}, Companion Volume: Demonstrations",0,"SenseClusters is a freely available system that clusters similar contexts. It can be applied to a wide range of problems, although here we focus on word sense and name discrimination. It supports several different measures for automatically determining the number of clusters in which a collection of contexts should be grouped. These can be used to discover the number of senses in which a word is used in a large corpus of text, or the number of entities that share the same name. There are three measures based on clustering criterion functions, and another on the Gap Statistic."
E06-2007,Selecting the {``}Right{''} Number of Senses Based on Clustering Criterion Functions,2006,6,19,1,1,1754,ted pedersen,Demonstrations,0,This paper describes an unsupervised knowledge-lean methodology for automatically determining the number of senses in which an ambiguous word is used in a large corpus. It is based on the use of global criterion functions that assess the quality of a clustering solution.
W05-0809,Word Alignment for Languages with Scarce Resources,2005,18,68,3,0,38645,joel martin,Proceedings of the {ACL} Workshop on Building and Using Parallel Texts,0,"This paper presents the task definition, resources, participating systems, and comparative results for the shared task on word alignment, which was organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts. The shared task included English-Inuktitut, Romanian-English, and English-Hindi sub-tasks, and drew the participation of ten teams from around the world with a total of 50 systems."
P05-3019,{S}ense{R}elate::{T}arget{W}ord{---}{A} Generalized Framework for Word Sense Disambiguation,2005,7,63,3,0.952381,34497,siddharth patwardhan,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,Many words in natural language have different meanings when used in different contexts. Sense Relate: Target Word is a Perl package that disambiguates a target word in context by finding the sense that is most related to its neighbors according to a WordNet: Similarity measure of relatedness.
P05-3027,{S}ense{C}lusters: Unsupervised Clustering and Labeling of Similar Contexts,2005,5,27,2,0,47881,anagha kulkarni,Proceedings of the {ACL} Interactive Poster and Demonstration Sessions,0,"SenseClusters is a freely available system that identifies similar contexts in text. It relies on lexical features to build first and second order representations of contexts, which are then clustered using unsupervised methods. It was originally developed to discriminate among contexts centered around a given target word, but can now be applied more generally. It also supports methods that create descriptive and discriminating labels for the discovered clusters."
W04-2404,Combining Lexical and Syntactic Features for Supervised Word Sense Disambiguation,2004,11,27,2,0,13005,saif mohammad,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,"The success of supervised learning approaches to word sense disambiguation is largely dependent on the features used to represent the context in which an ambiguous word occurs. Previous work has reached mixed conclusions; some suggest that combinations of syntactic and lexical features will perform most effectively. However, others have shown that simple lexical features perform well on their own. This paper evaluates the effect of using different lexical and syntactic features both individually and in combination. We show that it is possible for a very simple ensemble that utilizes a single lexical feature and a sequence of part of speech features to result in disambiguation accuracy that is near state of the art."
W04-2406,Word Sense Discrimination by Clustering Contexts in Vector and Similarity Spaces,2004,10,135,2,0,48036,amruta purandare,Proceedings of the Eighth Conference on Computational Natural Language Learning ({C}o{NLL}-2004) at {HLT}-{NAACL} 2004,0,"This paper systematically compares unsupervised word sense discrimination techniques that cluster instances of a target word that occur in raw text using both vector and similarity spaces. The context of each instance is represented as a vector in a high dimensional feature space. Discrimination is achieved by clustering these context vectors directly in vector space and also by finding pairwise similarities among the vectors and then clustering in similarity space. We employ two different representations of the context in which a target word occurs. First order context vectors represent the context of each instance of a target word as a vector of features that occur in that context. Second order context vectors are an indirect representation of the context based on the average of vectors that represent the words that occur in the context. We evaluate the discriminated clusters by carrying out experiments using sensexe2x80x93tagged instances of 24 SENSEVAL2 words and the well known Line, Hard and Serve sensexe2x80x93tagged corpora."
W04-0802,The Senseval-3 Multilingual {E}nglish-{H}indi lexical sample task,2004,4,18,3,0,49341,timothy chklovski,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"This paper describes the Englishxe2x80x90Hindi Multilingual lexical sample task in SENSEVALxe2x80x903. Rather than tagging an English word with a sense from an English dictionary, this task seeks to assign the most appropriate Hindi translation to an ambiguous target word. Training data was solicited via the Open Mind Word Expert (OMWE) from Web users who are fluent in English and Hindi."
W04-0839,Complementarity of lexical and simple syntactic features: The {S}ynta{L}ex approach to Senseval-3,2004,11,11,2,0,13005,saif mohammad,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,None
W04-0850,The {D}uluth lexical sample systems in Senseval-3,2004,14,2,1,1,1754,ted pedersen,"Proceedings of {SENSEVAL}-3, the Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text",0,"Two systems from the University of Minnesota, Duluth participated in various SENSEVAL-3 lexical sample tasks. The supervised learning system is based on lexical features and bagged decision trees. It participated in lexical sample tasks for the English, Spanish, Catalan, Basque, Romanian and MultiLingual English-Hindi data. The unsupervised system uses measures of semantic relatedness to find the sense of the target word that is most related to the senses of its neighbors. It participated in the English lexical sample task."
N04-3008,{S}ense{C}lusters - Finding Clusters that Represent Word Senses,2004,9,3,2,0,48036,amruta purandare,Demonstration Papers at {HLT}-{NAACL} 2004,0,"SenseClusters is a freely available word sense discrimination system that takes a purely unsu-pervised clustering approach. It uses no knowledge other than what is available in a raw unstructured corpus, and clusters instances of a given target word based only on their mutual contextual similarities. It is a complete system that provides support for feature selection from large corpora, several different context representation schemes, various clustering algorithms, and evaluation of the discovered clusters."
N04-3012,{W}ord{N}et::{S}imilarity - Measuring the Relatedness of Concepts,2004,14,652,1,1,1754,ted pedersen,Demonstration Papers at {HLT}-{NAACL} 2004,0,"WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity and relatedness between a pair of concepts (or synsets). It provides six measures of similarity, and three measures of relatedness, all of which are based on the lexical database WordNet. These measures are implemented as Perl modules which take as input two concepts, and return a numeric value that represents the degree to which they are similar or related."
W03-0301,An Evaluation Exercise for Word Alignment,2003,13,165,2,0.211644,1124,rada mihalcea,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,"This paper presents the task definition, resources, participating systems, and comparative results for the shared task on word alignment, which was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts. The shared task included Romanian-English and English-French sub-tasks, and drew the participation of seven teams from around the world."
W03-0309,The {D}uluth Word Alignment System,2003,6,4,2,1,14659,bridget mcinnes,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond,0,"The Duluth Word Alignment System participated in the 2003 HLT-NAACL Workshop on Parallel Text shared task on word alignment for both English--French and Romanian--English. It is a Perl implementation of IBM Model 2. We used approximately 50,000 aligned sentences as training data for each language pair, and found the results for Romanian--English to be somewhat better. We also varied the Model 2 distortion parameters among the values 2, 4, and 6, but did not observe any significant differences in performance as a result."
W02-0806,Assessing System Agreement and Instance Difficulty in the Lexical,2002,4,13,1,1,1754,ted pedersen,Proceedings of the {ACL}-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,0,"This paper presents a comparative evaluation among the systems that participated in the Spanish and English lexical sample tasks of SENSEVAL-2. The focus is on pairwise comparisons among systems to assess the degree to which they agree, and on measuring the difficulty of the test instances included in these tasks."
W02-0812,Evaluating the Effectiveness of Ensembles of Decision Trees,2002,10,5,1,1,1754,ted pedersen,Proceedings of the {ACL}-02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,0,"This paper presents an evaluation of an ensemble-based system that participated in the English and Spanish lexical sample tasks of SENSEVAL-2. The system combines decision trees of unigrams, bigrams, and co---occurrences into a single classifier. The analysis is extended to include the SENSEVAL-1 data."
S01-1034,Machine Learning with Lexical Features: {T}he {D}uluth Approach to {SENSEVAL}-2,2001,2,25,1,1,1754,ted pedersen,Proceedings of {SENSEVAL}-2 Second International Workshop on Evaluating Word Sense Disambiguation Systems,0,"This paper describes the sixteen Duluth entries in the Senseval-2 comparative exercise among word sense disambiguation systems. There were eight pairs of Duluth systems entered in the Spanish and English lexical sample tasks. These are all based on standard machine learning algorithms that induce classifiers from sense-tagged training text where the context in which ambiguous words occur are represented by simple lexical features. These are highly portable, robust methods that can serve as a foundation for more tailored approaches."
N01-1011,A Decision Tree of Bigrams is an Accurate Predictor of Word Sense,2001,18,117,1,1,1754,ted pedersen,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper presents a corpus-based approach to word sense disambiguation where a decision tree assigns a sense to an ambiguous word based on the bigrams that occur nearby. This approach is evaluated using the sense-tagged corpora from the 1998 SENSEVAL word sense disambiguation exercise. It is more accurate than the average results reported for 30 of 36 words, and is more accurate than the best results for 19 of 36 words."
A00-2009,A Simple Approach to Building Ensembles of Naive {B}ayesian Classifiers for Word Sense Disambiguation,2000,16,132,1,1,1754,ted pedersen,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"This paper presents a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co-occurring words in varying sized windows of context. Despite the simplicity of this approach, empirical results disambiguating the widely studied nouns line and interest show that such an ensemble achieves accuracy rivaling the best previously published results."
W97-1005,A Statistical Decision Making Method: A Case Study on Prepositional Phrase Attachment,1997,20,3,2,0,55524,mehmet kayaalp,{C}o{NLL}97: Computational Natural Language Learning,0,"Statistical classification methods usually rely on a single best model to make accurate predictions. Such a model aims to maximize accuracy by balancing precision and recall. The Model Switching method as presented in this paper performs with higher predictive accuracy and 100% recall by using a set of decomposable models instead of a single one. The implemented system, MS1, is tested on a case study, predicting Prepositional Phrase Attachment (PPA). The results show that iV is more accurate than other statistical techniques that select single models for classification and competitive with other successful NLP approaches in PPA disambiguation. The Model Switching method may be preferable to other methods because of its generality (i.e., wide range of applicability), and its competitive accuracy in prediction. It may also be used as an analytical tool to investigate the nature of the domain and the characteristics of the data with the help of generated models."
W97-0322,Distinguishing Word Senses in Untagged Text,1997,37,131,1,1,1754,ted pedersen,Second Conference on Empirical Methods in Natural Language Processing,0,"This paper describes an experimental comparison of three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text. The methods described in this paper, McQuitty's similarity analysis, Ward's minimum-variance method, and the EM algorithm, assign each instance of an ambiguous word to a known sense definition based solely on the values of automatically identifiable features in text. These methods and feature sets are found to be more successful in disambiguating nouns rather than adjectives or verbs. Overall, the most accurate of these procedures is McQuitty's similarity analysis in combination with a high dimensional feature set. 1 I n t r o d u c t i o n Statistical methods for natural language processing are often dependent on the availability of costly knowledge sources such as manually annotated text or semantic networks. This limits the applicability of such approaches to domains where this hard to acquire knowledge is already available. This paper presents three unsupervised learning algorithms that are able to distinguish among the known senses (i.e., as defined in some dictionary) of a word, based only on features that can be automatically extracted from untagged text. The object of unsupervised learning is to determine the class membership of each observation (i.e. each object to be classified), in a sample without using training examples of correct classifications. We discuss three algorithms, McQuitty's similarity analysis (McQuitty, 1966), Ward's minimum-variance method (Ward, 1963) and the EM algorithm (Dempster, Laird, and Rubin, 1977), that can be used to distinguish among the known senses of an ambiguous word without the aid of disambiguated examples. The EM algorithm produces maximum likelihood estimates of the parameters of a probabilistic model, where that model has been specified in advance. Both Ward's and McQuitty's methods are agglomerative clustering algorithms that form classes of unlabeled observations that minimize their respective distance measures between class members. The rest of this paper is organized as follows. First, we present introductions to Ward's and McQuitty 's methods (Section 2) and the EM algorithm (Section 3). We discuss the thirteen words (Section 4) and the three feature sets (Section 5) used in our experiments. We present our experimental results (Section 6) and close with a discussion of related work (Section 7). 2 Agglomerat ive Clustering In general, clustering methods rely on the assumption that classes occupy distinct regions in the feature space. The distance between two points in a multi-dimensional space can be measured using any of a wide variety of metrics (see, e.g. (Devijver and Kittler, 1982)). Observations are grouped in the manner that minimizes the distance between the members of each class. Ward's and McQuitty's method are agglomerative clustering algorithms that differ primarily in how they compute the distance between clusters. All such algorithms begin by placing each observation in a unique cluster, i.e. a cluster of one. The two closest clusters are merged to form a new cluster that replaces the two merged clusters. Merging of the two closest clusters continues until only some specified number of clusters remain. However, our data does not immediately lend itself to a distance-based interpretation. Our features represent part-of-speech (POS) tags, morphological characteristics, and word co-occurrence; such features are nominal and their values do not have scale. Given a POS feature, for example, we could choose noun = 1, verb = 2, adjective = 3, and adverb = 4. That adverb is represented by a larger number than noun is purely coincidental and implies nothing about the relationship between nouns and adverbs. Thus, before we employ either clustering algo-"
A97-1056,Sequential Model Selection for Word Sense Disambiguation,1997,20,25,1,1,1754,ted pedersen,Fifth Conference on Applied Natural Language Processing,0,"Statistical models of word-sense disambiguation are often based on a small number of contextual features or on a model that is assumed to characterize the interactions among a set of features. Model selection is presented as an alternative to these approaches, where a sequential search of possible models is conducted in order to find the model that best characterizes the interactions among features. This paper expands existing model selection methodology and presents the first comparative study of model selection search strategies and evaluation criteria when applied to the problem of building probabilistic classifiers for word-sense disambiguation."
W96-0210,The Measure of a Model,1996,0,14,3,0,51650,rebecca bruce,Conference on Empirical Methods in Natural Language Processing,0,None
