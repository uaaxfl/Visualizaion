W14-2214,Time to Change the {``}{D}{''} in {``}{DEL}{''},2014,9,1,1,1,38698,stephen beale,Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages,0,"The xe2x80x9cDxe2x80x9d in xe2x80x9cDELxe2x80x9d stands for xe2x80x9cdocumentingxe2x80x9d xe2x80x90 a code word for linguists that means the collection of linguistic data in audio and written form. The DEL (Documenting Endangered Languages) program run by the NSF and NEH is thus centered around building and archiving data resources for endangered languages. This paper is an argument for extending the xe2x80x98Dxe2x80x99 to include xe2x80x9cdescribingxe2x80x9d languages in terms of lexical, semantic, morphological and grammatical knowledge. We present an overview of descriptive computational tools aimed at endangered languages along with a longer summary of two particular computer programs: Linguistxe2x80x99s Assistant and Boas. These two programs, respectively, represent research in the areas of: A) computational systems capable of representing lexical, morphological and grammatical structures and using the resulting computational models for translation in a minority language context, and B) tools for efficiently and accurately acquiring linguistic knowledge. A hoped-for side effect of this paper is to promote cooperation between these areas of research in order to provide a total solution to describing endangered languages."
2014.lilt-10.1,Nominal Compound Interpretation by Intelligent Agents,2014,-1,-1,2,1,33676,marjorie mcshane,"Linguistic Issues in Language Technology, Volume 10, 2014",0,"This paper presents a cognitively-inspired algorithm for the semantic analysis of nominal compounds by intelligent agents. The agents, modeled within the OntoAgent environment, are tasked to compute a full context-sensitive semantic interpretation of each compound using a battery of engines that rely on a high-quality computational lexicon and ontology. Rather than being treated as an isolated {``}task{''}, as in many NLP approaches, nominal compound analysis in OntoAgent represents a minimal extension to the core process of semantic analysis. We hypothesize that seeking similarities across language analysis tasks reflects the spirit of how people approach language interpretation, and that this approach will make feasible the long-term development of truly sophisticated, human-like intelligent agents. The initial evaluation of our approach to nominal compounds are fixed expressions, requiring individual semantic specification at the lexical level."
W12-1510,"Linguist{'}s Assistant: A Multi-Lingual Natural Language Generator based on Linguistic Universals, Typologies, and Primitives",2012,9,1,2,0,33273,tod allman,{INLG} 2012 Proceedings of the Seventh International Natural Language Generation Conference,0,"Linguist's Assistant (LA) is a large scale semantic analyzer and multi-lingual natural language generator designed and developed entirely from a linguist's perspective. The system incorporates extensive typological, semantic, syntactic, and discourse research into its semantic representational system and its transfer and synthesizing grammars. LA has been tested with English, Korean, Kewa (Papua New Guinea), Jula (Cote d'Ivoure), and North Tanna (Vanuatu), and proof-of-concept lexicons and grammars have been developed for Spanish, Urdu, Tagalog, Chinantec (Mexico), and Angas (Nigeria). This paper will summarize the major components of the NLG system, and then present the results of experiments that were performed to determine the quality of the generated texts. The experiments indicate that when experienced mother-tongue translators use the drafts generated by LA, their productivity is typically quadrupled without any loss of quality."
W11-3408,Linguist{'}s Assistant: A Resource For Linguists,2011,8,2,1,1,38698,stephen beale,Proceedings of the 9th Workshop on {A}sian Language Resources,0,"The Linguistxe2x80x99s Assistant (LA) is a practical computational paradigm for describing languages. In this paper we describe how to use LA with naturally occurring texts that exemplify interesting target-language linguistic phenomena. We will describe how such texts can be semantically analyzed using a convenient semi-automatic document authoring interface, in effect adding them to LAxe2x80x99s standard semantic-based elicitation corpus. We then exemplify t h e n a g d e s c r i p i o process using a phenomenon that is prevalent in our research: alienable vs. inalienable nominal possession."
I11-2002,Using Linguist{'}s Assistant for Language Description and Translation,2011,5,3,1,1,38698,stephen beale,Proceedings of the {IJCNLP} 2011 System Demonstrations,0,The Linguistxe2x80x99s Assistant (LA) is a practical computational paradigm for describing languages. LA seeks to specify in semantic representations a large subset of possible written communication. These semantic representations then become the starting point and organizing principle from which a linguist describes the linguistic surface forms of a language using LA's visual lexicon and grammatical rule development interface. The resulting computational description can then be used in our document authoring and translation applications.
W08-2215,Resolving Paraphrases to Support Modeling Language Perception in an Intelligent Agent,2008,15,9,3,0,32552,sergei nirenburg,Semantics in Text Processing. {STEP} 2008 Conference Proceedings,0,"When interacting with humans, intelligent agents must be able not only to understand natural language inputs but also to remember them and link their content with the contents of their memory of event and object instances. As inputs can come in a variety of forms, linking to memory can be successful only when paraphrasing relations are established between the meaning of new input and the content of the agent's memory. This paper discusses a variety of types of paraphrases relevant to this task and describes the way we implement this capability in a virtual patient application."
W08-2225,Baseline Evaluation of {WSD} and Semantic Dependency in {O}nto{S}em,2008,6,9,2,0,32552,sergei nirenburg,Semantics in Text Processing. {STEP} 2008 Conference Proceedings,0,"This paper presents the evaluation of a subset of the capabilities of the On-toSem semantic analyzer conducted in the framework of the Shared Task for the STEP 2008 workshop. We very briefly describe OntoSem's components and knowledge resources, describe the work preparatory to the evaluation (the creation of gold standard basic text meaning representations) and present OntoSem's performance on word sense disambiguation and determination of semantic dependencies. The paper also contains elements of a methodological discussion."
W08-1507,Language Understanding in {M}aryland Virtual Patient,2008,2,2,2,0,32552,sergei nirenburg,Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications,0,"This paper discusses language understanding in the Maryland Virtual Patient environment. Language understanding is just one of many cognitive functions of the virtual patients in MVP, others including decision making about healthcare and lifestyle, and the experiencing and remembering of interoceptive events."
W05-0310,Semantically Rich Human-Aided Machine Annotation,2005,9,20,3,1,33676,marjorie mcshane,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"This paper describes a semantically rich, human-aided machine annotation system created within the Ontological Semantics (OntoSem) environment using the DEKADE toolset. In contrast to mainstream annotation efforts, this method of annotation provides more information at a lower cost and, for the most part, shifts the maintenance of consistency to the system itself. In addition, each tagging effort not only produces knowledge resources for that corpus, but also leads to improvements in the knowledge environment that will better support subsequent tagging efforts."
I05-7007,Increasing Understanding: Interpreting Events of Change,2005,0,1,3,0,32552,sergei nirenburg,Proceedings of {O}nto{L}ex 2005 - Ontologies and Lexical Resources,0,None
2005.mtsummit-papers.9,Document Authoring the {B}ible for Minority Language Translation,2005,5,5,1,1,38698,stephen beale,Proceedings of Machine Translation Summit X: Papers,0,"This paper describes one approach to document authoring and natural language generation being pursued by the Summer Institute of Linguistics in cooperation with the University of Maryland, Baltimore County. We will describe the tools provided for document authoring, including a glimpse at the underlying controlled language and the semantic representation of the textual meaning. We will also introduce The Bible Translator{'}s Assistant{\copyright} (TBTA), which is used to elicit and enter target language data as well as perform the actual text generation process. We conclude with a discussion of the usefulness of this paradigm from a Bible translation perspective and suggest several ways in which this work will benefit the field of computational linguistics."
W04-2601,{O}nto{S}em Methods for Processing Semantic Ellipsis,2004,9,8,2,1,33676,marjorie mcshane,Proceedings of the Computational Lexical Semantics Workshop at {HLT}-{NAACL} 2004,0,"This paper describes various types of semantic ellipsis and underspecification in natural language, and the ways in which the meaning of semantically elided elements is reconstructed in the Ontological Semantics (OntoSem) text processing environment. The description covers phenomena whose treatment in OntoSem has reached various levels of advancement: fully implemented, partially implemented, and described algorithmically outside of implementation. We present these research results at this point -- prior to full implementation and extensive evaluation -- for two reasons: first, new descriptive material is being reported; second, some subclasses of the phenomena in question will require a truly long-term effort whose results are best reported in installments."
W04-0904,{O}nto{S}em and {SIMPLE}: Two multi-lingual world views,2004,4,7,4,1,33676,marjorie mcshane,Proceedings of the 2nd Workshop on Text Meaning and Interpretation,0,"In this paper we compare programs of work that aim to develop broad coverage cross-linguistic resources for NLP: Ontological Semantics (OntoSem) and SIMPLE. The approaches taken in these projects differ in three notable respects: the use of an ontology versus a word net as the semantic substrate; the development of knowledge resources inside of as opposed to outside of a processing environment; and the development of lexicons for multiple languages based on a single core lexicon or without such a core (i.e., in parallel fashion). In large part, these differences derive from project-driven, real-world requirements and available resources -- a reflection of their being practical rather than theoretical projects. However, that being said, we will suggest certain preferences regarding the content and development of NLP resources with a view toward both short- and long-term, high-level language processing goals."
W04-0905,Evaluating the performance of the {O}nto{S}em semantic analyzer,2004,3,16,2,0,32552,sergei nirenburg,Proceedings of the 2nd Workshop on Text Meaning and Interpretation,0,"This paper describes an innovative evaluation regimen developed for the text meaning representations (TMRs) produced by the Ontological Semantic (OntoSem) general purpose syntactic-semantic analyzer. The goal of evaluation is not only to determine the quality of TMRs for given texts, but also to assign blame for various classes of errors, thus suggesting directions for continued work on both knowledge resources and processors. The paper includes descriptions of the OntoSem processing environment, the evaluation regime itself and results from our first evaluation effort."
W04-0906,Question answering using ontological semantics,2004,8,26,1,1,38698,stephen beale,Proceedings of the 2nd Workshop on Text Meaning and Interpretation,0,"This paper describes the initial results of an experiment in integrating knowledge-based text processing with real-world reasoning in a question answering system. Our MOQA meaning-oriented question answering system seeks answers to questions not in open text but rather in a structured fact repository whose elements are instances of ontological concepts extracted from the text meaning representations (TMRs) produced by the OntoSem text analyzer. The query interpretation and answer content formulation modules of MOQA use the same knowledge representation substrate and the same static knowledge resources as the ontological semantic (OntoSem) semantic text analyzer. The same analyzer is used for deriving the meaning of questions and of texts from which the fact repository content is extracted. Inference processes in question answering rely on ontological scripts (complex events) that also support reasoning for purely NLP-related purposes, such as ambiguity resolution in its many guises."
nirenburg-etal-2004-rationale,The Rationale for Building an Ontology Expressly for {NLP},2004,11,12,3,0,32552,sergei nirenburg,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,None
mcshane-etal-2004-meaning,Some Meaning Procedures of Ontological Semantics,2004,1,13,2,1,33676,marjorie mcshane,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents implemented algorithms for interpreting the meaning of certain context-dependent lexical items within the Ontological Semantic text processing environment. We discuss the form, function and rationale behind three meaning procedures, all of which are, in a certain sense, numerically oriented. We show that only a knowledge-rich processing system can fully interpret such entities, and that an integrated combination of static resources and processors provides sufficient foundation for high-quality text interpretation."
W03-0904,Operative strategies in ontological semantics,2003,2,7,3,0,32552,sergei nirenburg,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Text Meaning,0,"In this paper, we briefly and informally illustrate, using a few annotated examples, the static and dynamic knowledge resources of ontological semantics. We then present the main motivations and desiderata of our approach and then discuss issues related to making ontological-semantic applications feasible through the judicious stepwise enhancement of static and dynamic knowledge sources while at all times maintaining a working system."
1999.tmi-1.2,Long time no see: overt semantics for Machine Translation,1999,9,2,3,0.846625,45501,evelyne viegas,Proceedings of the 8th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,"In this paper, we show how a computational semantic approach is best fitted to address the translation of highly isolating languages. We use Chinese as an example and present the overall process of translation from Chinese to English, within the framework of Knowledge-Based Machine Translation (KBMT), using an overt semantics while de-emphasizing syntax. We focus here on two particular tasks: Word Sense Disambiguation (WSD) and compound translation."
1999.mtsummit-1.77,Using computational semantics for {C}hinese translations,1999,-1,-1,3,0.846625,45501,evelyne viegas,Proceedings of Machine Translation Summit VII,0,None
W98-1406,De-Constraining Text Generation,1998,12,11,1,1,38698,stephen beale,Natural Language Generation,0,"We argue that the current, predominantly task-oriented, approaz~hes to modularizing text xe2x80xa2 generation, while plausible and useful conceptually, set up spurious conceptual and operational constraints. We propose a data-driven approach to modularization and illustrate how it eliminates xe2x80xa2 xe2x80xa2the previously ubiquitous constraints on combination of evidence across modules and on xe2x80xa2 control. We also briefly overview the constraint-based control architecture that enables such an approach and facilitates near linear-time processing with realistic texts."
W98-0603,Representation and Processing of {C}hinese Nominals and Compounds,1998,8,1,4,0.846625,45501,evelyne viegas,The Computational Treatment of Nominals,0,"Abstract : In this paper, we address representation issues of Chinese nominals. In particular, we look at lexical rules as a conceptual tool to link forms with the same semantics as is the case between nominalizations and the forms they are derived from. We also address Chinese compounds, illustrating how to recover implicit semantic relations in nominal compounds. Finally, we show how to translate Chinese nominals within a knowledge-based framework."
P98-2216,The Computational Lexical Semantics of Syntagmatic Expressions,1998,15,4,2,0.846625,45501,evelyne viegas,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"In this paper, we address the issue of syntagmatic expressions from a computational lexical semantic perspective. From a representational viewpoint, we argue for a hybrid approach combining linguistic and conceptual paradigms, in order to account for the continuum we find in natural languages from free combining words to frozen expressions. In particular, we focus on the place of lexical and semantic restricted co-occurrences. From a processing viewpoint, we show how to generate/analyze syntagmatic expressions by using an efficient constraintbased processor, well fitted for a knowledge-driven approach."
C98-2211,The Computational Lexical Semantics of Syntagmatic Relations,1998,15,4,2,0.846625,45501,evelyne viegas,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"In this paper, we address the issue of syntagmatic expressions from a computational lexical semantic perspective. From a representational viewpoint, we argue for a hybrid approach combining linguistic and conceptual paradigms, in order to account for the continuum we find in natural languages from free combining words to frozen expressions. In particular, we focus on the place of lexical and semantic restricted co-occurrences. From a processing viewpoint, we show how to generate/analyze syntagmatic expressions by using an efficient constraintbased processor, well fitted for a knowledge-driven approach."
1997.tmi-1.1,"If you have it, flaunt it: using full ontological knowledge for word sense disambiguation",1997,-1,-1,3,1,33381,kavi mahesh,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
1997.tmi-1.18,Word sense disambiguation: why statistics when we have these numbers?,1997,-1,-1,3,1,33381,kavi mahesh,Proceedings of the 7th Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,0,None
W96-0506,{PICARD}: The Next Generator,1996,3,1,1,1,38698,stephen beale,Eighth International Natural Language Generation Workshop (Posters and Demonstrations),0,None
W96-0513,Multilinguality and Reversibility in Computational Semantic Lexicons,1996,2,4,2,0.717638,45501,evelyne viegas,Eighth International Natural Language Generation Workshop (Posters and Demonstrations),0,None
C96-1016,Measuring Semantic Coverage,1996,6,4,3,0,32552,sergei nirenburg,{COLING} 1996 Volume 1: The 16th International Conference on Computational Linguistics,0,"The development of natural language processing systems is currently driven to a large extent by measures of knowledge-base size and coverage of individual phenomena relative to a corpus. While these measures have led to significant advances for knowledge-lean applications, they do not adequately motivate progress in computational semantics leading to the development of large-scale, general purpose NLP systems. In this article, we argue that depth of semantic representation is essential for covering a broad range of phenomena in the computational treatment of language and propose depth as an important additional dimension for measuring the semantic coverage of NLP systems. We propose an operationalization of this measure and show how to characterize an NLP system along the dimensions of size, corpus coverage, and depth. The proposed framework is illustrated using several prominent NLP systems. We hope the preliminary proposals made in this article will lead to prolonged debates in the field and will continue to be refined."
1996.amta-1.10,Two principles and six techniques for rapid {MT} development,1996,-1,-1,2,0,32552,sergei nirenburg,Conference of the Association for Machine Translation in the Americas,0,None
1994.amta-1.10,Integrating Translations from Multiple Sources within the {PANGLOSS} Mark {III} Machine Translation System,1994,-1,-1,7,0,39652,robert frederking,Proceedings of the First Conference of the Association for Machine Translation in the Americas,0,None
