2005.mtsummit-papers.40,P93-1001,0,0.0606651,"ncompass not only genetic cognates (e.g. name/nom), but also borrowings (e.g. computer/komputer) and proper names. Even nonlexical types, such as numbers and punctuation, are 305 sometimes included as well. While genetic cognates occur only between related languages, other kinds of cognates can be found in virtually any bitext. If languages use different scripts, the identification of cognates must be preceded by a transliteration or transcription process. In the context of bitexts, cognates have been employed in several bitext-related tasks, including sentence alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), inducing translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2001), and improving statistical machine translation models (Al-Onaizan et al., 1999; Kondrak et al., 2003). All those applications depend on an effective method of identifying cognates, which performs a well-defined task: given two words from different languages, compute a numerical score reflecting the likelihood that the words are cognates. In this paper, we focus on identifying cognates on the basis of their orthographic similarity in the context of word alignment. So far, f"
2005.mtsummit-papers.40,C04-1136,0,0.146675,"Missing"
2005.mtsummit-papers.40,E95-1009,0,0.047549,"common subsequence is “c-o-l-u-r”. Brew and McKelvie (1996) propose a variation in which the denominator is the average of both word lengths. The orthographic measures described in this section disregard the fact that alphabetic symbols express actual sounds, instead employing a binary identity function on the level of character comparison. While such measures seem to be preferred in practice, a number of more complex approaches have been proposed, including phonetic-based methods, which take advantage of the phonetic characteristics of individual sounds in order to estimate their similarity (Kessler, 1995; Nerbonne and Heeringa, 1997; Kondrak, 2000), and HMM-based methods, which build a similarity model on the basis of training data (Mann and Yarowsky, 2001; Mackay and Kondrak, 2005). Although such methods fall outside the scope of this paper, the problem of length normalization applies to them as well. 3 Normalization In this section, we investigate the relationship between the similarity score and the word length, focusing on the methods based on the length of the longest common subsequence. We chose LCSR not only because it’s a method of choice in several bitext-oriented papers (Melamed, 19"
2005.mtsummit-papers.40,W01-0504,0,0.023412,"es. Even nonlexical types, such as numbers and punctuation, are 305 sometimes included as well. While genetic cognates occur only between related languages, other kinds of cognates can be found in virtually any bitext. If languages use different scripts, the identification of cognates must be preceded by a transliteration or transcription process. In the context of bitexts, cognates have been employed in several bitext-related tasks, including sentence alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), inducing translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2001), and improving statistical machine translation models (Al-Onaizan et al., 1999; Kondrak et al., 2003). All those applications depend on an effective method of identifying cognates, which performs a well-defined task: given two words from different languages, compute a numerical score reflecting the likelihood that the words are cognates. In this paper, we focus on identifying cognates on the basis of their orthographic similarity in the context of word alignment. So far, few comparisons of similarity measures have been published (Brew and McKelvie, 1996; McEnery and Oakes, 1996), We evaluate"
2005.mtsummit-papers.40,N03-2016,1,0.92844,"of the words and the length of their longest common subsequence. We present an alternative to the longest common subsequence ratio (LCSR), a widely-used orthographic word similarity measure. Experiments involving identification of cognates in bitexts suggest that the alternative method outperforms LCSR. Our results also indicate that alignment links can be used as a substitute for cognates for the purpose of evaluating word similarity measures. 1 Introduction It has been shown that the quality of word alignment in bitexts can be improved if the actual orthographic form of words is considered (Kondrak et al., 2003). Words that look or sound similar are more likely to be mutual translations than words that exhibit no similarity. The explanation of of this phenomenon lies in the fact that orthographic similarity is a hallmark of cognates. Because of their common origin, cognates normally coincide both in form and meaning. The concept of cognates is largely languageindependent. In the context of machine translation, cognates encompass not only genetic cognates (e.g. name/nom), but also borrowings (e.g. computer/komputer) and proper names. Even nonlexical types, such as numbers and punctuation, are 305 some"
2005.mtsummit-papers.40,A00-2038,1,0.780166,"McKelvie (1996) propose a variation in which the denominator is the average of both word lengths. The orthographic measures described in this section disregard the fact that alphabetic symbols express actual sounds, instead employing a binary identity function on the level of character comparison. While such measures seem to be preferred in practice, a number of more complex approaches have been proposed, including phonetic-based methods, which take advantage of the phonetic characteristics of individual sounds in order to estimate their similarity (Kessler, 1995; Nerbonne and Heeringa, 1997; Kondrak, 2000), and HMM-based methods, which build a similarity model on the basis of training data (Mann and Yarowsky, 2001; Mackay and Kondrak, 2005). Although such methods fall outside the scope of this paper, the problem of length normalization applies to them as well. 3 Normalization In this section, we investigate the relationship between the similarity score and the word length, focusing on the methods based on the length of the longest common subsequence. We chose LCSR not only because it’s a method of choice in several bitext-oriented papers (Melamed, 1999; Brew and McKelvie, 1996; Tiedemann, 1999)"
2005.mtsummit-papers.40,W05-0606,1,0.818188,"scribed in this section disregard the fact that alphabetic symbols express actual sounds, instead employing a binary identity function on the level of character comparison. While such measures seem to be preferred in practice, a number of more complex approaches have been proposed, including phonetic-based methods, which take advantage of the phonetic characteristics of individual sounds in order to estimate their similarity (Kessler, 1995; Nerbonne and Heeringa, 1997; Kondrak, 2000), and HMM-based methods, which build a similarity model on the basis of training data (Mann and Yarowsky, 2001; Mackay and Kondrak, 2005). Although such methods fall outside the scope of this paper, the problem of length normalization applies to them as well. 3 Normalization In this section, we investigate the relationship between the similarity score and the word length, focusing on the methods based on the length of the longest common subsequence. We chose LCSR not only because it’s a method of choice in several bitext-oriented papers (Melamed, 1999; Brew and McKelvie, 1996; Tiedemann, 1999), but also because of its particularly transparent way of computing the similarity score. The reason for dividing the LCS length by the w"
2005.mtsummit-papers.40,N01-1020,0,0.406958,"/komputer) and proper names. Even nonlexical types, such as numbers and punctuation, are 305 sometimes included as well. While genetic cognates occur only between related languages, other kinds of cognates can be found in virtually any bitext. If languages use different scripts, the identification of cognates must be preceded by a transliteration or transcription process. In the context of bitexts, cognates have been employed in several bitext-related tasks, including sentence alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), inducing translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2001), and improving statistical machine translation models (Al-Onaizan et al., 1999; Kondrak et al., 2003). All those applications depend on an effective method of identifying cognates, which performs a well-defined task: given two words from different languages, compute a numerical score reflecting the likelihood that the words are cognates. In this paper, we focus on identifying cognates on the basis of their orthographic similarity in the context of word alignment. So far, few comparisons of similarity measures have been published (Brew and McKelvie, 1996; McEnery and O"
2005.mtsummit-papers.40,J99-1003,0,0.725422,". name/nom), but also borrowings (e.g. computer/komputer) and proper names. Even nonlexical types, such as numbers and punctuation, are 305 sometimes included as well. While genetic cognates occur only between related languages, other kinds of cognates can be found in virtually any bitext. If languages use different scripts, the identification of cognates must be preceded by a transliteration or transcription process. In the context of bitexts, cognates have been employed in several bitext-related tasks, including sentence alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), inducing translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2001), and improving statistical machine translation models (Al-Onaizan et al., 1999; Kondrak et al., 2003). All those applications depend on an effective method of identifying cognates, which performs a well-defined task: given two words from different languages, compute a numerical score reflecting the likelihood that the words are cognates. In this paper, we focus on identifying cognates on the basis of their orthographic similarity in the context of word alignment. So far, few comparisons of similarity measures hav"
2005.mtsummit-papers.40,W03-0301,0,0.0299564,"n Interpolated precision 0.9 ""LCSF"" ""LCSR"" ""DICE"" ""PREFIX"" ""IDENT"" 0.6 0.5 0.4 0.6 0.5 0.4 0.3 0.3 0.2 0.2 0.1 0.1 0 0 0 0.1 0.2 0.3 0.4 0.5 Recall 0.6 0.7 0.8 0.9 1 0 100 200 300 400 500 600 Cutoff 700 800 900 1000 Figure 1: Performance of various similarity measures on the Blinker bitext evaluated against actual cognate pairs (left), and manually annotated word alignment links (right). text was estimated by counting all cognate pairs in 25 randomly selected sentences, and extrapolating the result. The third bitext is a manually aligned RomanianEnglish corpus containing newspaper-style text (Mihalcea and Pedersen, 2003). The estimate of the number of cognates in the bitext was based on 31 randomly selected sentences. 4.4 Results Figures 1, 2, and 3 contain plots that compare the interpolated precision values corresponding to various measures on the Blinker, Hansards, and the Romanian-English bitexts, respectively. In all three cases, we calculated the precision against a list of manually identified word alignment links. In addition, we also calculated the precision against a complete list of cognate pairs in the Blinker bitext, and against a list of machine-generated links obtained with the Giza statistical"
2005.mtsummit-papers.40,W97-1102,0,0.138318,"milarity measures have been published (Brew and McKelvie, 1996; McEnery and Oakes, 1996), We evaluate several measures of orthographic similarity, with the emphasis on the measures based on computing the longest common subsequence length. Many word similarity/distance measures (including the ones based on letter n-grams, the longest common subsequence, edit distance, and Hidden Markov Models) compute an overall score that is biased towards shorter or longer words. A solution that is often adopted is to normalize the score by the average or the maximum of word lengths (Brew and McKelvie, 1996; Nerbonne and Heeringa, 1997; Melamed, 1999). Although such a straightforward normalization method is preferable to using an unnormalized score, it is not necessarily optimal. In this paper, we investigate the possibility of deriving an alternative normalization formula by analyzing the behaviour of randomly generated strings. We present the results of experiments involving identification of cognates in bitexts that suggest that the alternative normalization method performs better than the straightforward normalization. Although our focus is on LCS-based measures, a similar approach could be applicable to other types of"
2005.mtsummit-papers.40,C00-2163,0,0.0233607,"of cognates in the bitext was based on 31 randomly selected sentences. 4.4 Results Figures 1, 2, and 3 contain plots that compare the interpolated precision values corresponding to various measures on the Blinker, Hansards, and the Romanian-English bitexts, respectively. In all three cases, we calculated the precision against a list of manually identified word alignment links. In addition, we also calculated the precision against a complete list of cognate pairs in the Blinker bitext, and against a list of machine-generated links obtained with the Giza statistical machine translation package (Och and Ney, 2000a) in the Hansards sample. Since orthographic similarity by itself can only identify a fraction of word alignment links, we used fixed cutoff levels instead of recall in all plots except the first one. The cutoff levels correspond to absolute numbers of correctly identified alignment links. We performed statistical significance tests for all pairs of similarity measures at various cutoff levels. 310 Following the method proposed by Evert (2004), we applied Fisher’s exact test to counts of word pairs that are accepted by only one of two similarity measures. The results of the significance tests"
2005.mtsummit-papers.40,P00-1056,0,0.0733526,"of cognates in the bitext was based on 31 randomly selected sentences. 4.4 Results Figures 1, 2, and 3 contain plots that compare the interpolated precision values corresponding to various measures on the Blinker, Hansards, and the Romanian-English bitexts, respectively. In all three cases, we calculated the precision against a list of manually identified word alignment links. In addition, we also calculated the precision against a complete list of cognate pairs in the Blinker bitext, and against a list of machine-generated links obtained with the Giza statistical machine translation package (Och and Ney, 2000a) in the Hansards sample. Since orthographic similarity by itself can only identify a fraction of word alignment links, we used fixed cutoff levels instead of recall in all plots except the first one. The cutoff levels correspond to absolute numbers of correctly identified alignment links. We performed statistical significance tests for all pairs of similarity measures at various cutoff levels. 310 Following the method proposed by Evert (2004), we applied Fisher’s exact test to counts of word pairs that are accepted by only one of two similarity measures. The results of the significance tests"
2005.mtsummit-papers.40,P02-1038,0,0.105254,"Missing"
2005.mtsummit-papers.40,1992.tmi-1.7,0,0.123924,"anslation, cognates encompass not only genetic cognates (e.g. name/nom), but also borrowings (e.g. computer/komputer) and proper names. Even nonlexical types, such as numbers and punctuation, are 305 sometimes included as well. While genetic cognates occur only between related languages, other kinds of cognates can be found in virtually any bitext. If languages use different scripts, the identification of cognates must be preceded by a transliteration or transcription process. In the context of bitexts, cognates have been employed in several bitext-related tasks, including sentence alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), inducing translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2001), and improving statistical machine translation models (Al-Onaizan et al., 1999; Kondrak et al., 2003). All those applications depend on an effective method of identifying cognates, which performs a well-defined task: given two words from different languages, compute a numerical score reflecting the likelihood that the words are cognates. In this paper, we focus on identifying cognates on the basis of their orthographic similarity in the context of word alignm"
2005.mtsummit-papers.40,W99-0626,0,0.307088,"; Kondrak, 2000), and HMM-based methods, which build a similarity model on the basis of training data (Mann and Yarowsky, 2001; Mackay and Kondrak, 2005). Although such methods fall outside the scope of this paper, the problem of length normalization applies to them as well. 3 Normalization In this section, we investigate the relationship between the similarity score and the word length, focusing on the methods based on the length of the longest common subsequence. We chose LCSR not only because it’s a method of choice in several bitext-oriented papers (Melamed, 1999; Brew and McKelvie, 1996; Tiedemann, 1999), but also because of its particularly transparent way of computing the similarity score. The reason for dividing the LCS length by the word length is to avoid bias towards longer words. For example, the length of the LCS is 4 in both ideas/id´ees and vegetables/victimes. Obviously the former is more orthographically similar. However, the division by word length introduces an opposite bias, albeit less pronounced, towards shorter words. For example, the LCSR of both saw/osa and jacinth/hyacinthe is 23 . Moreover, when the words being compared are completely identical, the LCSR score is always"
2020.emnlp-main.332,N13-1073,0,0.0612266,"TRAINT and S OFT C ONSTRAINT rely on the proper alignment between the source focus word and its translation, which may be composed of multiple word tokens. Although attention weights in some NMT systems may be used to derive word alignment, such an approach is not necessarily more accurate than off-the-shelf alignment tools (Li et al., 2019). Therefore, our approach is to instead identify the word-level translations by performing a bitext-based alignment between the source focus words and their translations. During development, we found that the accuracy of alignment tools such as FASTA LIGN (Dyer et al., 2013) is limited by the size of the aligned bitext, as well as the lack of access to the translation information which is present in BabelNet. To mitigate these issues, we introduce a knowledge-based word alignment algorithm BABA LIGN1 that leverages translation information in BabelNet by post-processing the output of an off-the-shelf word aligner. BA 1 Implementation is available at: https://github. com/YixingLuan/BabAlign 4058 BA LIGN is shown to be more effective than existing word aligners in downstream tasks such as crosslingual lexical entailment (Hauer et al., 2020). We first append our tran"
2020.emnlp-main.332,W18-2505,0,0.0247408,"Missing"
2020.emnlp-main.332,2020.semeval-1.32,1,0.589037,"tools such as FASTA LIGN (Dyer et al., 2013) is limited by the size of the aligned bitext, as well as the lack of access to the translation information which is present in BabelNet. To mitigate these issues, we introduce a knowledge-based word alignment algorithm BABA LIGN1 that leverages translation information in BabelNet by post-processing the output of an off-the-shelf word aligner. BA 1 Implementation is available at: https://github. com/YixingLuan/BabAlign 4058 BA LIGN is shown to be more effective than existing word aligners in downstream tasks such as crosslingual lexical entailment (Hauer et al., 2020). We first append our translated WSD data to a large lemmatized bitext. We further augment the bitext with the BabelNet translations for all WSD focus words. We then run the base aligner in both translation directions, and take the intersection of the two sets of alignment links. In its final stage, BABA LIGN leverages the BabelNet translation pairs again, to post-process the generated alignment. Algorithm 1 summarizes BABA LIGN. The algorithm takes as input a source-language sentence and a target-language sentence, as well as the set of translations for each content word in the source sentenc"
2020.emnlp-main.332,E09-1010,0,0.0335033,"y (1999) observe that highly distinct senses can translate differently. Diab and Resnik (2002) propose a WSD system based on translation information extracted from a bitext, but it fails to outperform systems that rely on monolingual information only. Word sense induction (WSI) and cross-lingual WSD (CLWSD) are related tasks. WSI aims for automatically inducing word senses from corpora by clustering similar instances of words. Several prior works perform WSI based on bitexts to create bilingual sense inventory on word samples, where translations are treated as sense tags (Specia et al., 2007; Apidianaki, 2009). CLWSD is a task to predict a set of translations for a given ambiguous word in context. Attempts have been made to integrate translations as bag-of-words feature vectors to enhance CLWSD (Lefever et al., 2011). Since the goals of WSI and CLWSD differ from standard WSD with predefined senses, our approach is not directly comparable. Navigli and Ponzetto (2012b) incorporate translations in BabelNet synsets as a feature in a graphbased WSD system. However, rather than apply translations of the focus word token as constraints, they simply consider all possible translations of the focus word type"
2020.emnlp-main.332,S15-2050,0,0.195321,"f the history of WSD has been determined by the availability of manually created lexical resources in English, including SemCor (Miller et al., 1994) and WordNet (Miller, 1995). The situation changed with the introduction of BabelNet (Navigli and Ponzetto, 2012a), a massive multilingual semantic network, created by automatically integrating WordNet, Wikipedia, and other resources. In particular, BabelNet synsets contain translations in multiple languages for each individual word sense. Methods have been proposed to use multilingual information in BabelNet for WSD (Navigli and Ponzetto, 2012b; Apidianaki and Gong, 2015), but they do not directly exploit the mapping between senses and translations in multiple languages. While there have been many attempts to apply WSD to machine translation (MT) (Liu et al., 2018; Pu et al., 2018), our goal instead is to harness advances in MT to improve WSD. Rather than develop a new WSD system, we propose a general method that can make existing and future systems more accurate by leveraging translations. We evaluate our methods with several supervised and knowledge-based WSD systems. Our approach is based on the assumption of absolute synonymy between the senses of mutual t"
2020.emnlp-main.332,W11-0104,0,0.0662218,"Missing"
2020.emnlp-main.332,W09-2404,0,0.0431728,"ranslation information, we also propose BABA LIGN, an precise bitext alignment algorithm which is guided by multilingual lexical correspondences from BabelNet. 1 Figure 1: An overview of our approach to leverage translations to improve a base WSD system. Introduction Word sense disambiguation (WSD) is one of the core tasks in natural language processing. Given a predefined sense inventory, a WSD system aims to identify the correct sense of a content word in context. Although WSD is a monolingual task, it has been conjectured that multilingual information could help (Resnik and Yarowsky, 1999; Carpuat, 2009). Attempts have been made to leverage parallel corpora for sense tagging (Diab and Resnik, 2002), but no effective method for improving WSD with translations has been proposed to date. Much of the history of WSD has been determined by the availability of manually created lexical resources in English, including SemCor (Miller et al., 1994) and WordNet (Miller, 1995). The situation changed with the introduction of BabelNet (Navigli and Ponzetto, 2012a), a massive multilingual semantic network, created by automatically integrating WordNet, Wikipedia, and other resources. In particular, BabelNet s"
2020.emnlp-main.332,N19-1423,0,0.00646474,"rmation for a given lemma and part-of-speech (POS). This information is also used by most WSD systems. For English, we obtain sense frequencies from WordNet, which derives such information from SemCor, a sense-annotated corpus. To handle senses with zero frequency in SemCor, we also apply additive smoothing. To obtain pfreq for languages other than English, which lack large, highquality sense annotated corpora, we use CluBERT (Pasini et al., 2020), the state-of-the-art system for unsupervised sense distribution learning, which applies a clustering algorithm to contextual embeddings from BERT (Devlin et al., 2019). Like our methods, CluBERT is language independent, has no additional training data requirements, and has been successfully integrated into WSD systems to improve their performance. Figure 2 illustrates how S OFT C ONSTRAINT combines the three probability distributions to correct an incorrect sense prediction produced by a base system. 3.3 Contextual Word Embeddings Recent work has demonstrated the utility of contextual word embeddings for NLP tasks (Peters et al., 2018; Devlin et al., 2019). Accordingly, WSD systems such as S ENS E M BERT (Scarlini et al., 2020) take a contextual embedding o"
2020.emnlp-main.332,P02-1033,0,0.599251,"which is guided by multilingual lexical correspondences from BabelNet. 1 Figure 1: An overview of our approach to leverage translations to improve a base WSD system. Introduction Word sense disambiguation (WSD) is one of the core tasks in natural language processing. Given a predefined sense inventory, a WSD system aims to identify the correct sense of a content word in context. Although WSD is a monolingual task, it has been conjectured that multilingual information could help (Resnik and Yarowsky, 1999; Carpuat, 2009). Attempts have been made to leverage parallel corpora for sense tagging (Diab and Resnik, 2002), but no effective method for improving WSD with translations has been proposed to date. Much of the history of WSD has been determined by the availability of manually created lexical resources in English, including SemCor (Miller et al., 1994) and WordNet (Miller, 1995). The situation changed with the introduction of BabelNet (Navigli and Ponzetto, 2012a), a massive multilingual semantic network, created by automatically integrating WordNet, Wikipedia, and other resources. In particular, BabelNet synsets contain translations in multiple languages for each individual word sense. Methods have b"
2020.emnlp-main.332,P16-1085,0,0.0526173,"Missing"
2020.emnlp-main.332,P11-2055,0,0.0596471,"Missing"
2020.emnlp-main.332,P19-1124,0,0.014373,"4 Translation Alignment The effectiveness of our approach for improving WSD depends on the correct identification of the word-level translations in each language. Even when the sentential context of the focus word is correctly rendered in another language, both H ARD C ONSTRAINT and S OFT C ONSTRAINT rely on the proper alignment between the source focus word and its translation, which may be composed of multiple word tokens. Although attention weights in some NMT systems may be used to derive word alignment, such an approach is not necessarily more accurate than off-the-shelf alignment tools (Li et al., 2019). Therefore, our approach is to instead identify the word-level translations by performing a bitext-based alignment between the source focus words and their translations. During development, we found that the accuracy of alignment tools such as FASTA LIGN (Dyer et al., 2013) is limited by the size of the aligned bitext, as well as the lack of access to the translation information which is present in BabelNet. To mitigate these issues, we introduce a knowledge-based word alignment algorithm BABA LIGN1 that leverages translation information in BabelNet by post-processing the output of an off-the"
2020.emnlp-main.332,L16-1147,0,0.0583091,"e is to obtain proper translations for test words in the WSD setting. For SemCor, we continue to use the included tokenization, lemma, and POS information. For MSC and JSC, we do not use the tokenization, lemma, and POS information provided in the data to emulate the setting where we generate translations for monolingual WSD datasets. Instead, for MSC, JSC, and the additional bitexts, we employ morphological taggers to perform pre-processing: TreeTagger (Schmid, 1994) for Italian and MeCab (Kudo, 2005) for Japanese. The additional bitexts that we append to the data are from OpenSubtitles2018 (Lison and Tiedemann, 2016): English-Italian (37.8M sentences) and English-Japanese (2.2M sentences). We evaluate alignment performance in terms of 2 We use SemCor 3.0 in the Natural Language Toolkit (NLTK) to keep the compatible file format with MSC and JSC. 4059 Method FASTA LIGN BABA LIGN Data test data only +OpenSub +OpenSub +pairs +OpenSub +pairs En-It 80.4 93.3 93.6 94.0 En-Ja 36.0 75.6 81.9 91.6 Table 1: Alignment F-score on English-Italian and English-Japanese bitexts. whether the lemma of the aligned translation corresponds to the lemma of the manually aligned translation in MSC or JSC. Table 1 compares the ali"
2020.emnlp-main.332,N18-1121,0,0.0192027,"he introduction of BabelNet (Navigli and Ponzetto, 2012a), a massive multilingual semantic network, created by automatically integrating WordNet, Wikipedia, and other resources. In particular, BabelNet synsets contain translations in multiple languages for each individual word sense. Methods have been proposed to use multilingual information in BabelNet for WSD (Navigli and Ponzetto, 2012b; Apidianaki and Gong, 2015), but they do not directly exploit the mapping between senses and translations in multiple languages. While there have been many attempts to apply WSD to machine translation (MT) (Liu et al., 2018; Pu et al., 2018), our goal instead is to harness advances in MT to improve WSD. Rather than develop a new WSD system, we propose a general method that can make existing and future systems more accurate by leveraging translations. We evaluate our methods with several supervised and knowledge-based WSD systems. Our approach is based on the assumption of absolute synonymy between the senses of mutual translations in context (Hauer and Kondrak, 2020). The principal method S OFT C ONSTRAINT refines sense 4055 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing,"
2020.emnlp-main.332,P19-1569,0,0.386427,"Missing"
2020.emnlp-main.332,H94-1046,0,0.10656,"l language processing. Given a predefined sense inventory, a WSD system aims to identify the correct sense of a content word in context. Although WSD is a monolingual task, it has been conjectured that multilingual information could help (Resnik and Yarowsky, 1999; Carpuat, 2009). Attempts have been made to leverage parallel corpora for sense tagging (Diab and Resnik, 2002), but no effective method for improving WSD with translations has been proposed to date. Much of the history of WSD has been determined by the availability of manually created lexical resources in English, including SemCor (Miller et al., 1994) and WordNet (Miller, 1995). The situation changed with the introduction of BabelNet (Navigli and Ponzetto, 2012a), a massive multilingual semantic network, created by automatically integrating WordNet, Wikipedia, and other resources. In particular, BabelNet synsets contain translations in multiple languages for each individual word sense. Methods have been proposed to use multilingual information in BabelNet for WSD (Navigli and Ponzetto, 2012b; Apidianaki and Gong, 2015), but they do not directly exploit the mapping between senses and translations in multiple languages. While there have been"
2020.emnlp-main.332,S15-2049,0,0.0491682,"Missing"
2020.emnlp-main.332,Q14-1019,0,0.0901998,"Missing"
2020.emnlp-main.332,S13-2040,0,0.0401211,"Missing"
2020.emnlp-main.332,D12-1128,0,0.119113,"Missing"
2020.emnlp-main.332,W19-5333,0,0.0407665,"Missing"
2020.emnlp-main.332,N19-4009,0,0.0211633,"Missing"
2020.emnlp-main.332,W18-6301,0,0.0575121,"Missing"
2020.emnlp-main.332,N18-1202,0,0.011559,"stem for unsupervised sense distribution learning, which applies a clustering algorithm to contextual embeddings from BERT (Devlin et al., 2019). Like our methods, CluBERT is language independent, has no additional training data requirements, and has been successfully integrated into WSD systems to improve their performance. Figure 2 illustrates how S OFT C ONSTRAINT combines the three probability distributions to correct an incorrect sense prediction produced by a base system. 3.3 Contextual Word Embeddings Recent work has demonstrated the utility of contextual word embeddings for NLP tasks (Peters et al., 2018; Devlin et al., 2019). Accordingly, WSD systems such as S ENS E M BERT (Scarlini et al., 2020) take a contextual embedding of the focus word as input, in order to leverage its dense encoding of relevant local information, which may be used to determine the correct sense. In this section, we propose a method of adding translation information to the input of a WSD system by modifying the contextual embedding of the focus word to reflect its translation. We refer to this method as t emb. Note that this method can be combined with either the H ARD C ONSTRAINT or S OFTC ONSTRAINT methods. Unlike t"
2020.emnlp-main.332,Q18-1044,0,0.0207152,"BabelNet (Navigli and Ponzetto, 2012a), a massive multilingual semantic network, created by automatically integrating WordNet, Wikipedia, and other resources. In particular, BabelNet synsets contain translations in multiple languages for each individual word sense. Methods have been proposed to use multilingual information in BabelNet for WSD (Navigli and Ponzetto, 2012b; Apidianaki and Gong, 2015), but they do not directly exploit the mapping between senses and translations in multiple languages. While there have been many attempts to apply WSD to machine translation (MT) (Liu et al., 2018; Pu et al., 2018), our goal instead is to harness advances in MT to improve WSD. Rather than develop a new WSD system, we propose a general method that can make existing and future systems more accurate by leveraging translations. We evaluate our methods with several supervised and knowledge-based WSD systems. Our approach is based on the assumption of absolute synonymy between the senses of mutual translations in context (Hauer and Kondrak, 2020). The principal method S OFT C ONSTRAINT refines sense 4055 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, pages 4055–4065, c"
2020.emnlp-main.332,E17-1010,0,0.0279815,"Missing"
2020.emnlp-main.332,P19-1069,0,0.0411143,"Missing"
2020.emnlp-main.332,P10-4014,0,0.0877494,"Missing"
2020.emnlp-main.332,2020.acl-main.369,0,0.117756,"e set of senses. To avoid zero values, we perform smoothing by adding a small positive value (a tunable parameter). Probability pfreq represents the sense frequency information for a given lemma and part-of-speech (POS). This information is also used by most WSD systems. For English, we obtain sense frequencies from WordNet, which derives such information from SemCor, a sense-annotated corpus. To handle senses with zero frequency in SemCor, we also apply additive smoothing. To obtain pfreq for languages other than English, which lack large, highquality sense annotated corpora, we use CluBERT (Pasini et al., 2020), the state-of-the-art system for unsupervised sense distribution learning, which applies a clustering algorithm to contextual embeddings from BERT (Devlin et al., 2019). Like our methods, CluBERT is language independent, has no additional training data requirements, and has been successfully integrated into WSD systems to improve their performance. Figure 2 illustrates how S OFT C ONSTRAINT combines the three probability distributions to correct an incorrect sense prediction produced by a base system. 3.3 Contextual Word Embeddings Recent work has demonstrated the utility of contextual word e"
2020.semeval-1.32,N13-1073,0,0.100457,"e threshold, the words are deemed to be semantically similar. Note that the search for similar words is performed only with respect to the first of the words in a given instance, which may entail the second word. Figure 1 shows an example of applying the V ECTORS method. Although jug is not translated as contenitore in the bitext, the method is still able to detect the entailment, based on the semantic similarity between jug and bottle. 2.3 Knowledge-Based Alignment Both of our methods are dependent upon accurate alignment. Therefore, in addition to an off-theshelf alignment tool, FASTA LIGN (Dyer et al., 2013), we also apply a new knowledge-based alignment algorithm, BABA LIGN (Luan, 2020). We first obtain all possible translations for all content words in the trial, development, and test sets from a multilingual lexical resource, such as BabelNet (Navigli and Ponzetto, 2012). To bias FASTA LIGN, we append the obtained translation pairs to the lemmatized bitext. We then use the sets of translation pairs again to post-process the generated alignment: if FASTA LIGN failed to link a source content word to a target content word, we attempt to align the word to its translation. We apply this process in"
2020.semeval-1.32,2020.semeval-1.2,0,0.257474,"Missing"
2020.semeval-1.32,E17-2098,1,0.833072,"ts entailed by the translated concept. For example, from the English phrase “you gave me the bottle”, and its Italian translation “mi hai dato il contenitore”, it can be inferred that bottle entails contenitore (“container”).1 We are interested in leveraging this phenomenon to perform unsupervised LE prediction. Our use of bitexts, word embeddings, and multilingual wordnets builds upon prior work. Qiu et al. (2018) observe that similar words share entailments, and so semantic similarity can be used to detect additional entailment pairs. Cross-lingual word embedding similarity has been used by Hauer et al. (2017) to identify translations, and by Hauer et al. (2019) to detect frequent word senses. Mehdad et al. (2011) leverage bitext alignment for textual entailment. The principal contribution of this paper is the presentation and evaluation of LE prediction methods that leverage: (1) translation mining for entailment classification; (2) monolingual word embeddings for expanding the set of entailment pairs; and (3) multilingual lexical resources for improving translation alignment. To the best of our knowledge, we are the first to apply these ideas to cross-lingual LE prediction, and demonstrate that e"
2020.semeval-1.32,L16-1147,0,0.406555,"improves LE prediction performance, especially in a low-resource setting. 2 Methods In this section, we outline our bitext-based approach to predicting cross-lingual entailment. Section 2.1 describes our base method, B ITEXT, which mines entailment pairs from word alignments in a bilingual parallel corpus. Section 2.2 describes an enhanced method, V ECTORS, which identifies additional This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/. 1 This is an actual translation from the OpenSubtitles corpus (Lison and Tiedemann, 2016). 263 Proceedings of the 14th International Workshop on Semantic Evaluation, pages 263–269 Barcelona, Spain (Online), December 12, 2020. Figure 1: Two methods for identifying cross-lingual entailment. entailment pairs based on estimates of semantic similarity. Section 2.3 outlines our use of a knowledgebased alignment method, BABA LIGN, to further improve entailment coverage. 2.1 Entailment via Alignment Our basic method, which we call B ITEXT, represents the key idea of our approach: lexical translation captures entailment relations. The method uses automatic word alignment of bitexts to mine"
2020.semeval-1.32,L16-1676,0,0.0132765,"ols, setup, results, and implications. At the end, we discuss an additional experiment in which we use the hypernymy relation in BabelNet as a proxy for lexical entailment. 3.1 Tools and Resources Our bitexts are from the OpenSubtitles2 project (Lison and Tiedemann, 2016; Tiedemann, 2016). Table 1 shows the corpus size for each language pair. We lower-case all text, and tokenize by white space and punctuation. To improve coverage, we experiment with performing lemmatization prior to alignment. We employ TreeTagger (Schmid, 1999; Schmid, 2013) for English, German and Italian, and reldi-tagger (Ljubesic et al., 2016) for Croatian. No lemmatization was done for Turkish and Albanian, due to the unavailability of lemmatizers. Languages de-en lines bytes de-hr de-it en-it 22.5M 13.8M 13.6M 35.2M 2.7G 1.0G 1.1G 2.6G Table 1: The bitext size in the high-resource setting. For the purpose of computing word similarity in the V ECTORS method, we generate word embeddings using the skip-gram model of word2vec (Mikolov et al., 2013). We set the vector dimensions to 200, the context window size to 10, and run word2vec for 25 iterations. All other parameters affecting the vectors are left at their default values. 3.2 Ex"
2020.semeval-1.32,P11-1134,0,0.037907,"its Italian translation “mi hai dato il contenitore”, it can be inferred that bottle entails contenitore (“container”).1 We are interested in leveraging this phenomenon to perform unsupervised LE prediction. Our use of bitexts, word embeddings, and multilingual wordnets builds upon prior work. Qiu et al. (2018) observe that similar words share entailments, and so semantic similarity can be used to detect additional entailment pairs. Cross-lingual word embedding similarity has been used by Hauer et al. (2017) to identify translations, and by Hauer et al. (2019) to detect frequent word senses. Mehdad et al. (2011) leverage bitext alignment for textual entailment. The principal contribution of this paper is the presentation and evaluation of LE prediction methods that leverage: (1) translation mining for entailment classification; (2) monolingual word embeddings for expanding the set of entailment pairs; and (3) multilingual lexical resources for improving translation alignment. To the best of our knowledge, we are the first to apply these ideas to cross-lingual LE prediction, and demonstrate that each of them improves LE prediction performance, especially in a low-resource setting. 2 Methods In this se"
2020.semeval-1.32,S18-1148,0,0.0197345,"oss-lingual lexical semantics that translations may be broader in meaning than the original text (Bentivogli and Pianta, 2000; Rudnicka et al., 2012). In particular, translations may represent concepts entailed by the translated concept. For example, from the English phrase “you gave me the bottle”, and its Italian translation “mi hai dato il contenitore”, it can be inferred that bottle entails contenitore (“container”).1 We are interested in leveraging this phenomenon to perform unsupervised LE prediction. Our use of bitexts, word embeddings, and multilingual wordnets builds upon prior work. Qiu et al. (2018) observe that similar words share entailments, and so semantic similarity can be used to detect additional entailment pairs. Cross-lingual word embedding similarity has been used by Hauer et al. (2017) to identify translations, and by Hauer et al. (2019) to detect frequent word senses. Mehdad et al. (2011) leverage bitext alignment for textual entailment. The principal contribution of this paper is the presentation and evaluation of LE prediction methods that leverage: (1) translation mining for entailment classification; (2) monolingual word embeddings for expanding the set of entailment pair"
2020.semeval-1.32,C12-2101,0,0.0169254,"be inferred from the meaning of a word in another language.” They note its potential applications to machine translation, question answering, as well as to cross-lingual inference and entity linking. LE is related to hypernym detection, with the former being more general (Upadhyay et al., 2018). Our principal objective is to provide evidence for the hypothesis that translations are useful in predicting cross-lingual entailment. It has been observed in prior work on cross-lingual lexical semantics that translations may be broader in meaning than the original text (Bentivogli and Pianta, 2000; Rudnicka et al., 2012). In particular, translations may represent concepts entailed by the translated concept. For example, from the English phrase “you gave me the bottle”, and its Italian translation “mi hai dato il contenitore”, it can be inferred that bottle entails contenitore (“container”).1 We are interested in leveraging this phenomenon to perform unsupervised LE prediction. Our use of bitexts, word embeddings, and multilingual wordnets builds upon prior work. Qiu et al. (2018) observe that similar words share entailments, and so semantic similarity can be used to detect additional entailment pairs. Cross-l"
2020.semeval-1.32,L16-1559,0,0.104945,"E prediction performance, especially in a low-resource setting. 2 Methods In this section, we outline our bitext-based approach to predicting cross-lingual entailment. Section 2.1 describes our base method, B ITEXT, which mines entailment pairs from word alignments in a bilingual parallel corpus. Section 2.2 describes an enhanced method, V ECTORS, which identifies additional This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/. 1 This is an actual translation from the OpenSubtitles corpus (Lison and Tiedemann, 2016). 263 Proceedings of the 14th International Workshop on Semantic Evaluation, pages 263–269 Barcelona, Spain (Online), December 12, 2020. Figure 1: Two methods for identifying cross-lingual entailment. entailment pairs based on estimates of semantic similarity. Section 2.3 outlines our use of a knowledgebased alignment method, BABA LIGN, to further improve entailment coverage. 2.1 Entailment via Alignment Our basic method, which we call B ITEXT, represents the key idea of our approach: lexical translation captures entailment relations. The method uses automatic word alignment of bitexts to mine"
2020.semeval-1.32,N18-1056,0,0.0161867,"versity of Alberta systems for SemEval-2020 Task 2: Predicting Multilingual and Cross-Lingual Lexical Entailment (Glavaˇs et al., 2020). We focus on the subtask of cross-lingual binary lexical entailment (LE). Vyas and Carpuat (2016) define this task as “the task of detecting whether the meaning of a word in one language can be inferred from the meaning of a word in another language.” They note its potential applications to machine translation, question answering, as well as to cross-lingual inference and entity linking. LE is related to hypernym detection, with the former being more general (Upadhyay et al., 2018). Our principal objective is to provide evidence for the hypothesis that translations are useful in predicting cross-lingual entailment. It has been observed in prior work on cross-lingual lexical semantics that translations may be broader in meaning than the original text (Bentivogli and Pianta, 2000; Rudnicka et al., 2012). In particular, translations may represent concepts entailed by the translated concept. For example, from the English phrase “you gave me the bottle”, and its Italian translation “mi hai dato il contenitore”, it can be inferred that bottle entails contenitore (“container”)"
2020.semeval-1.32,P19-1490,0,0.0393793,"Missing"
2020.semeval-1.32,N16-1142,0,0.0240863,"ta.ca Abstract We investigate the hypothesis that translations can be used to identify cross-lingual lexical entailment. We propose novel methods that leverage parallel corpora, word embeddings, and multilingual lexical resources. Our results demonstrate that the implementation of these ideas leads to improvements in predicting entailment. 1 Introduction In this paper, we discuss the University of Alberta systems for SemEval-2020 Task 2: Predicting Multilingual and Cross-Lingual Lexical Entailment (Glavaˇs et al., 2020). We focus on the subtask of cross-lingual binary lexical entailment (LE). Vyas and Carpuat (2016) define this task as “the task of detecting whether the meaning of a word in one language can be inferred from the meaning of a word in another language.” They note its potential applications to machine translation, question answering, as well as to cross-lingual inference and entity linking. LE is related to hypernym detection, with the former being more general (Upadhyay et al., 2018). Our principal objective is to provide evidence for the hypothesis that translations are useful in predicting cross-lingual entailment. It has been observed in prior work on cross-lingual lexical semantics that"
2020.sigmorphon-1.12,D19-1091,0,0.0193077,"lgorithm which uses a set of feature templates to transduce multiple characters in a single operation. The feature set includes context features (n-grams on the source side), transition features (target side bigrams), linear-chain features (conjunction of context and transition features), and joint n-gram features (on both source and target). The transduction quality of DTLM depends on a high precision one-to-many alignment, which is performed with M2M+ aligner (Jiampojamarn 3.2 Data Augmentation Inspired by the data hallucination technique for neural model training (Silfverberg et al., 2017; Anastasopoulos and Neubig, 2019), we introduce a method to synthesize additional training instances from unannotated texts. For each language under consideration, we train base transduction models on the available training data, and extract a list of words from a text corpus. A naive self-training approach would be to simply apply a base G2P model to the words in the list to produce new training instances. However, without some mechanism to filter out incorrect predictions, a model trained on the augmented data would learn to replicate many of the errors made by the base model. Instead, we 118 reduce the noise by cross-check"
2020.sigmorphon-1.12,W19-4202,1,0.841939,"ure set was augmented with 117 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 117–122 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Figure 1: Our approach to synthesizing additional G2P training data. joint n-grams defined on both source and target substrings. The system was applied to related tasks such as transliteration (Jiampojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (Nicolai and Kondrak, 2016), and cognate projection (Hauer et al., 2019), proving to be particularly competitive in low-resource settings. DTLM (Nicolai et al., 2018), our principal tool in this work, is a successor of DirecTL+, which incorporates target-side language models and a highprecision alignment. DTLM achieved state-of-theart results on several tasks in which plain word types constitute the transduction target strings. Finally, our data augmentation approach is inspired by the self-training approach of Hauer et al. (2017). 3 et al., 2007) in a two-step process. In the first step, M2M+ induces a one-to-one alignment in which null symbols may be inserted on"
2020.sigmorphon-1.12,E17-2098,1,0.833744,"mpojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (Nicolai and Kondrak, 2016), and cognate projection (Hauer et al., 2019), proving to be particularly competitive in low-resource settings. DTLM (Nicolai et al., 2018), our principal tool in this work, is a successor of DirecTL+, which incorporates target-side language models and a highprecision alignment. DTLM achieved state-of-theart results on several tasks in which plain word types constitute the transduction target strings. Finally, our data augmentation approach is inspired by the self-training approach of Hauer et al. (2017). 3 et al., 2007) in a two-step process. In the first step, M2M+ induces a one-to-one alignment in which null symbols may be inserted on either side. In the second step, the null links on the source side are removed by merging adjacent target symbols. The accuracy of DTLM can be enhanced by leveraging target character and word language models. A 4-gram character languages model, which is induced from a set of word types extracted from a text corpus, encourages the prediction of high-probability letter sequences. A unigram word language model (which we also refer to as word counts) biases DTLM"
2020.sigmorphon-1.12,W09-3504,1,0.727728,"inative transducer, was originally designed for the G2P task (Jiampojamarn et al., 2008). In DirecTL+ (Jiampojamarn et al., 2010), the feature set was augmented with 117 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 117–122 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Figure 1: Our approach to synthesizing additional G2P training data. joint n-grams defined on both source and target substrings. The system was applied to related tasks such as transliteration (Jiampojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (Nicolai and Kondrak, 2016), and cognate projection (Hauer et al., 2019), proving to be particularly competitive in low-resource settings. DTLM (Nicolai et al., 2018), our principal tool in this work, is a successor of DirecTL+, which incorporates target-side language models and a highprecision alignment. DTLM achieved state-of-theart results on several tasks in which plain word types constitute the transduction target strings. Finally, our data augmentation approach is inspired by the self-training approach of Hauer et al. (2017). 3"
2020.sigmorphon-1.12,P08-1103,1,0.687222,"2P model input. The precision of this approach is further improved by comparing predictions of different systems. Figure 1 illustrates this idea. The principal contributions of this paper include a novel G2P data augmentation method that leverages multiple systems and text corpora, as well as a thorough comparison of several G2P and P2G systems in both low-resource and high-resource settings. 2 Prior Work Our methods build upon the prior work of the University of Alberta teams on string transduction. DirecTL, a feature-based discriminative transducer, was originally designed for the G2P task (Jiampojamarn et al., 2008). In DirecTL+ (Jiampojamarn et al., 2010), the feature set was augmented with 117 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 117–122 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Figure 1: Our approach to synthesizing additional G2P training data. joint n-grams defined on both source and target substrings. The system was applied to related tasks such as transliteration (Jiampojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (N"
2020.sigmorphon-1.12,W10-2405,1,0.746904,"roach is further improved by comparing predictions of different systems. Figure 1 illustrates this idea. The principal contributions of this paper include a novel G2P data augmentation method that leverages multiple systems and text corpora, as well as a thorough comparison of several G2P and P2G systems in both low-resource and high-resource settings. 2 Prior Work Our methods build upon the prior work of the University of Alberta teams on string transduction. DirecTL, a feature-based discriminative transducer, was originally designed for the G2P task (Jiampojamarn et al., 2008). In DirecTL+ (Jiampojamarn et al., 2010), the feature set was augmented with 117 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 117–122 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Figure 1: Our approach to synthesizing additional G2P training data. joint n-grams defined on both source and target substrings. The system was applied to related tasks such as transliteration (Jiampojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (Nicolai and Kondrak, 2016), and cognate pr"
2020.sigmorphon-1.12,N07-1047,1,0.677154,"Missing"
2020.sigmorphon-1.12,2020.lrec-1.521,0,0.426487,"output the original orthographic word. If both G2P models predict the same phoneme sequence, and both P2G models recover the original grapheme sequence, that grapheme–phoneme pair is added to the synthetic training data. The final augmented model is trained on the combined original and synthetic data. 4 Development In this section, we describe our development experiments on both G2P and P2G with three different transduction systems and the synthetic training data. 4.1 Datasets We created low-resource datasets of 100 instances from each standard (high-resource) training set of 3600 instances (Lee et al., 2020). We extracted every 36th instance, starting from the first instance, in a deterministic manner, to ensure replicability. The P2G datasets were created by swapping the grapheme and phoneme strings in the task datasets. The official development sets of 450 instances were used for model tuning only. 4.2 Task Baselines The task organizers provided implementations of three baseline systems, which are referred to as FST, LSTM, and T RANSFORMER. These are not baselines in the traditional sense of “the simplest possible algorithm” (Manning and Schutze, 2001, page 234), but rather sophisticated system"
2020.sigmorphon-1.12,N15-1093,1,0.820202,"P task (Jiampojamarn et al., 2008). In DirecTL+ (Jiampojamarn et al., 2010), the feature set was augmented with 117 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 117–122 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Figure 1: Our approach to synthesizing additional G2P training data. joint n-grams defined on both source and target substrings. The system was applied to related tasks such as transliteration (Jiampojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (Nicolai and Kondrak, 2016), and cognate projection (Hauer et al., 2019), proving to be particularly competitive in low-resource settings. DTLM (Nicolai et al., 2018), our principal tool in this work, is a successor of DirecTL+, which incorporates target-side language models and a highprecision alignment. DTLM achieved state-of-theart results on several tasks in which plain word types constitute the transduction target strings. Finally, our data augmentation approach is inspired by the self-training approach of Hauer et al. (2017). 3 et al., 2007) in a two-step process. In the first"
2020.sigmorphon-1.12,P16-1108,1,0.848935,"). In DirecTL+ (Jiampojamarn et al., 2010), the feature set was augmented with 117 Proceedings of the Seventeenth SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 117–122 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Figure 1: Our approach to synthesizing additional G2P training data. joint n-grams defined on both source and target substrings. The system was applied to related tasks such as transliteration (Jiampojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (Nicolai and Kondrak, 2016), and cognate projection (Hauer et al., 2019), proving to be particularly competitive in low-resource settings. DTLM (Nicolai et al., 2018), our principal tool in this work, is a successor of DirecTL+, which incorporates target-side language models and a highprecision alignment. DTLM achieved state-of-theart results on several tasks in which plain word types constitute the transduction target strings. Finally, our data augmentation approach is inspired by the self-training approach of Hauer et al. (2017). 3 et al., 2007) in a two-step process. In the first step, M2M+ induces a one-to-one align"
2020.sigmorphon-1.12,W18-5805,1,0.82078,"tional Research in Phonetics, Phonology, and Morphology, pages 117–122 c Online, July 10, 2020. 2020 Association for Computational Linguistics https://doi.org/10.18653/v1/P17 Figure 1: Our approach to synthesizing additional G2P training data. joint n-grams defined on both source and target substrings. The system was applied to related tasks such as transliteration (Jiampojamarn et al., 2009), morphological inflection (Nicolai et al., 2015), stemming (Nicolai and Kondrak, 2016), and cognate projection (Hauer et al., 2019), proving to be particularly competitive in low-resource settings. DTLM (Nicolai et al., 2018), our principal tool in this work, is a successor of DirecTL+, which incorporates target-side language models and a highprecision alignment. DTLM achieved state-of-theart results on several tasks in which plain word types constitute the transduction target strings. Finally, our data augmentation approach is inspired by the self-training approach of Hauer et al. (2017). 3 et al., 2007) in a two-step process. In the first step, M2M+ induces a one-to-one alignment in which null symbols may be inserted on either side. In the second step, the null links on the source side are removed by merging adj"
2020.sigmorphon-1.12,N19-4009,0,0.0607675,"Missing"
2020.sigmorphon-1.12,J96-3003,0,0.0874429,"ausible scenario of working with a low-resource language for which only a small quantity of reliable phonological data is available. For example, a typical IPA description of the phonological inventory of a single language contains about a hundred phonetic transcriptions of individual words (IPA, 1999). We analyze the relative performance of different systems depending on the size of the training data. The task of phoneme-to-grapheme (P2G) conversion is the inverse of grapheme-to-phoneme Conversion (G2P), in which the goal is to predict the spelling of a word given its phonetic transcription (Rentzepopoulos and Kokkinakis, 1996). While G2P reflects the difficulty of reading, P2G may indicate the complexity of writing in a given language. Training instances for one of the two tasks can easily be applied to the other one by simply reversing the input and output. We use the shared task datasets to investigate how systems designed for G2P perform on P2G. We also leverage raw text corpora to improve the accuracy on P2G, which indirectly leads to improvements on G2P as well. We develop a novel method of mitigating resource limitations by synthesizing additional training data using a combination of multiple G2P and P2G mode"
2020.sigmorphon-1.12,K17-2010,0,0.0284427,"is a dynamic programming algorithm which uses a set of feature templates to transduce multiple characters in a single operation. The feature set includes context features (n-grams on the source side), transition features (target side bigrams), linear-chain features (conjunction of context and transition features), and joint n-gram features (on both source and target). The transduction quality of DTLM depends on a high precision one-to-many alignment, which is performed with M2M+ aligner (Jiampojamarn 3.2 Data Augmentation Inspired by the data hallucination technique for neural model training (Silfverberg et al., 2017; Anastasopoulos and Neubig, 2019), we introduce a method to synthesize additional training instances from unannotated texts. For each language under consideration, we train base transduction models on the available training data, and extract a list of words from a text corpus. A naive self-training approach would be to simply apply a base G2P model to the words in the list to produce new training instances. However, without some mechanism to filter out incorrect predictions, a model trained on the augmented data would learn to replicate many of the errors made by the base model. Instead, we 1"
2021.gwc-1.1,P13-1133,0,0.0261104,", OmegaWiki, and various other resources, supplemented by machine translation, to cover nearly 300 distinct languages. Each of the multisynsets in BN corresponds to a unique concept, with a unique eight-digit identifier, and an associated part of speech (noun, verb, adjective, or adverb), and contains one or more words which can express that concept in various languages. For instance, the nominal concept TREE is represented by synset bn:00078131n which includes the English words tree and arbor, as well as French arbre and Italian albero. We use BabelNet version 4.0. Open Multilingual WordNet (Bond and Foster, 2013) is another multilingual wordnet, constructed by linking wordnets in 29 languages to WordNet version 3.0. Like BN, OMWN consists of multisynsets, each containing one or more words from Resource CLICS BN OMWN Colexified Concept Pair LEG - FOOT WOOD - TREE MOON - MONTH town.n.01 - city.n.01 painting.n.01 - image.n.01 house.n.01 - dwelling.n.01 book.n.02 (work) - book.n.01 (object) wing.n.02 (airplane) - wing.n.01 (animal) shout.v.02 (cry) - shout.v.01 (with loud voice) COL 336 335 313 100 89 88 23 22 22 LEX 1038 1036 538 121 93 117 25 22 24 Ratio 0.324 0.323 0.582 0.826 0.957 0.752 0.920 1.000 0"
2021.gwc-1.1,W13-0208,0,0.0236571,"guages. Their experiments show that 12 diverse languages are sufficient to build a stable semantic map. Our hypothesis relates this statement to entire lexicons of core concepts. Franc¸ois (2008) also uses colexification data to build a semantic map for studying the world’s lexicons across languages. He observes that the more languages are considered, the more distinctions between senses need to be made. This finding is consistent with our hypothesis, and also raises another open question: is a given pair of colexified concepts colexified universally? The graph-based approach is introduced by List and Terhalle (2013), who analyze cross-linguistic polysemy. They build a weighted colexification graph using data from 195 languages representing 44 language families, and find that clusters 4 Resources In this section, we describe our three resources: BabelNet (BN), Open Multilingual WordNet (OMWN), and CLICS. Table 2 contains the number of concepts and languages that we consider in each of these resources. For instance, CLICS contains approximately one million words in 3050 languages, which express 2919 concepts. The other two resources have fewer languages, but a higher average number of words per language. B"
2021.gwc-1.1,L16-1379,0,0.0522072,"Missing"
2021.gwc-1.1,W97-0213,0,0.679607,"ample, the English word right colexifies the concepts of RIGHT (side) and CORRECT (Figure 1). The term covers both polysemy and homonymy (Pericliev, 2015). In this paper, we posit and investigate the hypothesis that there are no universal colexifications, or more precisely, that no two distinct concepts are colexified in every language. The universal colexification hypothesis is relevant for the task of word sense disambiguation because it would imply that any sense distinction in any language could be disambiguated by translation into some language. It is also related to a famous proposal of Resnik and Yarowsky (1997) “to restrict a word sense inventory to those distinctions that are typically lexicalized crosslinguistically”. If there are no universal colexifications, then a sense inventory based on crosslingual translation pairs would also include all core concepts in existing lexical resources, which would cast doubt on the commonly expressed opinion that WordNet is too fine-grained (Pasini and Navigli, 2018). Figure 1: Three concepts (RIGHT, TRUE, CORRECT) that are colexified in Persian, English, and Chinese. We test our hypothesis by analyzing the colexification data from three different lexical resou"
2021.gwc-1.4,P08-2063,0,0.107013,"Missing"
2021.gwc-1.4,N06-2015,0,0.39287,"Missing"
2021.gwc-1.4,N18-1121,0,0.0281046,"Missing"
2021.gwc-1.4,P06-1014,0,0.190834,"Missing"
2021.gwc-1.4,W11-0128,0,0.0408635,"Missing"
2021.gwc-1.4,W18-6242,0,0.0540692,"Missing"
2021.gwc-1.4,P06-2111,0,0.188874,"Missing"
2021.semeval-1.101,2020.semeval-1.3,0,0.0515095,"Missing"
2021.semeval-1.101,2021.gwc-1.1,1,0.880578,"ask can only be applied if t1 and t2 have the same POS but different lemmas. A complete theoretical solution can be obtained by considering translations in multiple languages. If the focus word s is not used in the same sense in S1 and S2 , we would expect that in some language, the translations t1 and t2 will be different and not mutually replaceable in both sentences. This expectation is consistent with the speculation of Palmer et al. (2007) that translation into a sufficiently large set of language will eventually lexicalize every sense distinction. It is also supported by the findings of Bao et al. (2021) who found no evidence for the existence of universal colexifications, that is, pairs of concepts that are expressed by the same word in every natural language. 3.3 Multi-Synset Intersection For each language Fi in the set of all natural languages L, let ti1 and ti2 be the lexical translations of the focus word s in the first and second input sentences, respectively. Let T be the set consisting of the focus word, and all its lexical translations; that is W = {s} ∪Fi {ti1 , ti2 }. Assuming access to a perfect universal multi-wordnet, we define the set C to be the set of multi-synsets that conta"
2021.semeval-1.101,N19-1423,0,0.00474108,"t to create synthetic training data and post-process the alignment produced using a base unsupervised alignment method. Specifically, we use FastAlign (Dyer et al., 2013) as the base aligner. When aligning input sentences with translations, we concatenate the sentences and their translations with the OpenSubtitles bitext (Lison and Tiedemann, 2016) for the corresponding language pair. For each language pair, we use the first 1M sentences of the OpenSubtitles bitext. 5.3 Contextual Embeddings To obtain contextual representations for the purposes of deciding the substitution check, we use BERT (Devlin et al., 2019), a deep neural architecture trained with the masked language model. We chose BERT because it has been proven to capture the semantics of a word in context (Coenen et al., 2019). The context is the sentence containing the focus word. Specifically, we use cased multilingual BERT to generate contextualized embedding of focus words by summing up the last four hidden layers of the BERT model. This choice was based on the results achieved by Devlin et al. (2019) in the named entity recognition task, and by Soler et al. (2019) in the SemDeep-5 WiC shared task.1 We use cased multilingual BERT embeddi"
2021.semeval-1.101,N13-1073,0,0.0480434,", identify the word or phrase in the translated sentence corresponding to the source focus word. Once each input sentence is aligned with its translation, we extract the lemmas aligned with each focus word token. These are the lexical translations of the focus word for this language. To carry out the alignment, we use BabAlign (Luan et al., 2020), a state-of-the-art knowledgebased aligner. BabAlign leverages translation information from BabelNet to create synthetic training data and post-process the alignment produced using a base unsupervised alignment method. Specifically, we use FastAlign (Dyer et al., 2013) as the base aligner. When aligning input sentences with translations, we concatenate the sentences and their translations with the OpenSubtitles bitext (Lison and Tiedemann, 2016) for the corresponding language pair. For each language pair, we use the first 1M sentences of the OpenSubtitles bitext. 5.3 Contextual Embeddings To obtain contextual representations for the purposes of deciding the substitution check, we use BERT (Devlin et al., 2019), a deep neural architecture trained with the masked language model. We chose BERT because it has been proven to capture the semantics of a word in co"
2021.semeval-1.101,2020.semeval-1.2,0,0.0415048,"Missing"
2021.semeval-1.101,2020.semeval-1.32,1,0.797175,"stinctions in translation. We have previously presented methods leveraging translation information to improve word sense disambiguation (Luan et al., 2020), and most frequent sense detection (Hauer et al., 2019), and have demonstrated that word senses which share translations are, in general, semantically related (Hauer and Kondrak, 2020a). We have also presented theoretical formalizations of lexico-semantic phenomena which view synonymy and translation as two aspects of semantic equivalence (Hauer and Kondrak, 2020b). Our team additionally presented a method based on translation information (Hauer et al., 2020) for the SemEval2020 Task 2 on Predicting Multilingual and CrossLingual Lexical Entailment (Glavaˇs et al., 2020). In this task, we investigate whether translation can be used to detect semantic equivalence in context, just as in the aforementioned prior task we investigated whether translation can be used to detect lexical entailment between word types. Our focus is on developing principled theoretical approaches which are grounded in linguistic phenomena, leading to more explainable models. Our more complex methods depend upon a mapping between word senses and translations, as different sens"
2021.semeval-1.101,L16-1147,0,0.0194844,"mmas aligned with each focus word token. These are the lexical translations of the focus word for this language. To carry out the alignment, we use BabAlign (Luan et al., 2020), a state-of-the-art knowledgebased aligner. BabAlign leverages translation information from BabelNet to create synthetic training data and post-process the alignment produced using a base unsupervised alignment method. Specifically, we use FastAlign (Dyer et al., 2013) as the base aligner. When aligning input sentences with translations, we concatenate the sentences and their translations with the OpenSubtitles bitext (Lison and Tiedemann, 2016) for the corresponding language pair. For each language pair, we use the first 1M sentences of the OpenSubtitles bitext. 5.3 Contextual Embeddings To obtain contextual representations for the purposes of deciding the substitution check, we use BERT (Devlin et al., 2019), a deep neural architecture trained with the masked language model. We chose BERT because it has been proven to capture the semantics of a word in context (Coenen et al., 2019). The context is the sentence containing the focus word. Specifically, we use cased multilingual BERT to generate contextualized embedding of focus words"
2021.semeval-1.101,2020.emnlp-main.333,0,0.0204728,"ant prior literature. Section 3 discusses the theoretical model underlying our work. Section 4 outlines our methods. Section 5 describes our experiments and results. 2 Related Work Methods for WiC task can be roughly divided into two paradigms: contextualized-embedding-based systems, and word sense disambiguation-based systems. Pilehvar and Camacho-Collados (2018) introduce the WiC dataset as a benchmark for evaluating context sensitive word representations. Soler et al. (2019) achieve improvements by combining similarity scores from different types of contextual word and sentence embeddings. Liu et al. (2020) propose a method to enhance contextual representations by leveraging other pre-trained contextual or static embeddings. Another approach to WiC task is to employ a word sense disambiguation (WSD) system to tag the target words with senses from a pre-defined sense inventory and subsequently make a decision based on the predicted synsets of the target words. Loureiro and Jorge (2019b) use the LMMS sense embeddings (Loureiro and Jorge, 2019a) to disambiguate the target words. A simple approach of checking if the disambiguated senses are equal lead to competitive performance in the SemDeep-5 WiC"
2021.semeval-1.101,P19-1569,0,0.0212729,"the WiC dataset as a benchmark for evaluating context sensitive word representations. Soler et al. (2019) achieve improvements by combining similarity scores from different types of contextual word and sentence embeddings. Liu et al. (2020) propose a method to enhance contextual representations by leveraging other pre-trained contextual or static embeddings. Another approach to WiC task is to employ a word sense disambiguation (WSD) system to tag the target words with senses from a pre-defined sense inventory and subsequently make a decision based on the predicted synsets of the target words. Loureiro and Jorge (2019b) use the LMMS sense embeddings (Loureiro and Jorge, 2019a) to disambiguate the target words. A simple approach of checking if the disambiguated senses are equal lead to competitive performance in the SemDeep-5 WiC challenge (Anke et al., 2019). SENSEMBERT (Scarlini et al., 2020a) and ARES (Scarlini et al., 2020b) embeddings, when used as features in a BERT-based model, also achieve competitive results on the WiC task. Our methods combine elements of both paradigms. We employ contextual embeddings in our proposed translation-based methods. However, we take the embeddings of the translations o"
2021.semeval-1.101,2020.emnlp-main.332,1,0.892859,"ompared in terms of their accuracy, the percentage of test instances correctly identified as T RUE (same meaning) or FALSE (different meaning). The dataset includes training, development, and testing splits; as our methods are unsupervised, we do not use the training data. The goal of this paper is an exploration of the use of translation information for the WiC task. The intuition underlying our work is that distinctions in meaning tend to be reflected in distinctions in translation. We have previously presented methods leveraging translation information to improve word sense disambiguation (Luan et al., 2020), and most frequent sense detection (Hauer et al., 2019), and have demonstrated that word senses which share translations are, in general, semantically related (Hauer and Kondrak, 2020a). We have also presented theoretical formalizations of lexico-semantic phenomena which view synonymy and translation as two aspects of semantic equivalence (Hauer and Kondrak, 2020b). Our team additionally presented a method based on translation information (Hauer et al., 2020) for the SemEval2020 Task 2 on Predicting Multilingual and CrossLingual Lexical Entailment (Glavaˇs et al., 2020). In this task, we inve"
2021.semeval-1.101,2021.semeval-1.3,0,0.0269521,"ord-in-Context (MCL-WiC) disambiguation task. We explore the use of translation information for deciding whether two different tokens of the same word correspond to the same sense of the word. Our focus is on developing principled theoretical approaches which are grounded in linguistic phenomena, leading to more explainable models. We show that translations from multiple languages can be leveraged to improve the accuracy on the WiC task. 1 Introduction This paper describes the University of Alberta systems for SemEval-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (Martelli et al., 2021). We focus on the monolingual (English) variant of the task, which is the same as the original WiC task (Pilehvar and Camacho-Collados, 2018). An instance of the WiC task consists of two sentences that share a focus word in common; the word may be inflected differently in each sentence (e.g. “they had searched his flat a few days before” and “the production of lithium from salt flats”) but will share the same lemma and part of speech. A WiC task system must decide, given such a pair of sentences, whether the focus tokens have the same meaning in both sentences. Systems are compared in terms of"
2021.semeval-1.101,P10-1023,0,0.0374528,"uch embeddings is that semantically S UB and CS UB Experiments In this section, we describe the application of our methods to the English development and test sets. We begin by specifying various implementation details. Next, we describe our development experiments, including results and error analysis. Finally, we present our results on the test set. While our 766 method is, in theory, applicable to any language, and even to cross-lingual subtasks, we focus exclusively on the English monolingual substask due to time and resource constraints. 5.1 Translation and Lemmatization We use BabelNet (Navigli and Ponzetto, 2010, 2012) as our multi-wordnet; in particular, we make use of the BabelNet multi-synsets which are linked to Princeton Wordnet synsets. This allows us to exclude synsets that refer to named entities, rather than lexicalized concepts, to limit the impact of noise in BabelNet. For translation, we use Google Translate, as it is fast and publicly available. In our analysis, we found the lexical translations obtained using Google Translate to be of generally high quality, which is important given our method’s dependence on machine translation. We use French, Italian, and Russian as our languages of t"
2021.semeval-1.101,2020.semeval-1.5,0,0.0576697,"Missing"
2021.semeval-1.101,2020.emnlp-main.285,0,0.0351124,"resentations by leveraging other pre-trained contextual or static embeddings. Another approach to WiC task is to employ a word sense disambiguation (WSD) system to tag the target words with senses from a pre-defined sense inventory and subsequently make a decision based on the predicted synsets of the target words. Loureiro and Jorge (2019b) use the LMMS sense embeddings (Loureiro and Jorge, 2019a) to disambiguate the target words. A simple approach of checking if the disambiguated senses are equal lead to competitive performance in the SemDeep-5 WiC challenge (Anke et al., 2019). SENSEMBERT (Scarlini et al., 2020a) and ARES (Scarlini et al., 2020b) embeddings, when used as features in a BERT-based model, also achieve competitive results on the WiC task. Our methods combine elements of both paradigms. We employ contextual embeddings in our proposed translation-based methods. However, we take the embeddings of the translations of the target words instead of the target words themselves. Similarly to WSD based approaches, our methods also analyze the common synsets of the focus tokens and their translations, with the goal of identifying a probable shared synset. The most similar prior work to our approach"
2021.semeval-1.101,W19-5802,0,0.107919,"strong lead for future work on contextual semantic analysis. This paper is structured as follows: Section 2 provides an overview of relevant prior literature. Section 3 discusses the theoretical model underlying our work. Section 4 outlines our methods. Section 5 describes our experiments and results. 2 Related Work Methods for WiC task can be roughly divided into two paradigms: contextualized-embedding-based systems, and word sense disambiguation-based systems. Pilehvar and Camacho-Collados (2018) introduce the WiC dataset as a benchmark for evaluating context sensitive word representations. Soler et al. (2019) achieve improvements by combining similarity scores from different types of contextual word and sentence embeddings. Liu et al. (2020) propose a method to enhance contextual representations by leveraging other pre-trained contextual or static embeddings. Another approach to WiC task is to employ a word sense disambiguation (WSD) system to tag the target words with senses from a pre-defined sense inventory and subsequently make a decision based on the predicted synsets of the target words. Loureiro and Jorge (2019b) use the LMMS sense embeddings (Loureiro and Jorge, 2019a) to disambiguate the"
A00-2038,J96-4002,0,0.461531,"asis of phonological features that encode certain properties of phones. An obvious candidate for the latter is a well-known dynamic programming (DP) algorithm for string alignment (Wagner and Fischer, 1974), although other algorithms can used as well. The task of finding the optimal alignment is closely linked to the task of calculating the distance between two sequences. The basic DP algorithm 288 accomplishes both tasks. Depending on the application, either of the results, or both, can be used. Within the last few years, several different approaches to phonetic alignment have been reported. Covington (1996) used depth-first search and a special distance function to align words for historical comparison. In a follow-up paper (Covington, 1998), he extended the algorithm to align words from more than two languages. Somers (1998) proposed a special algorithm for aligning children&apos;s articulation data with the adult model. Gildea and Jurafsky (1996) applied the DP algorithm to pre-align input and output phonetic strings in order to improve the performance of their transducer induction system. Nerbonne and Heeringa (1997) employed a similar procedure to compute relative distance between words from vari"
A00-2038,P98-1043,0,0.308786,"amming (DP) algorithm for string alignment (Wagner and Fischer, 1974), although other algorithms can used as well. The task of finding the optimal alignment is closely linked to the task of calculating the distance between two sequences. The basic DP algorithm 288 accomplishes both tasks. Depending on the application, either of the results, or both, can be used. Within the last few years, several different approaches to phonetic alignment have been reported. Covington (1996) used depth-first search and a special distance function to align words for historical comparison. In a follow-up paper (Covington, 1998), he extended the algorithm to align words from more than two languages. Somers (1998) proposed a special algorithm for aligning children&apos;s articulation data with the adult model. Gildea and Jurafsky (1996) applied the DP algorithm to pre-align input and output phonetic strings in order to improve the performance of their transducer induction system. Nerbonne and Heeringa (1997) employed a similar procedure to compute relative distance between words from various Dutch dialects. Some characteristics of these implementations are juxtaposed in Table 1. In this paper, I present a new algorithm for"
A00-2038,J96-4003,0,0.133628,"ating the distance between two sequences. The basic DP algorithm 288 accomplishes both tasks. Depending on the application, either of the results, or both, can be used. Within the last few years, several different approaches to phonetic alignment have been reported. Covington (1996) used depth-first search and a special distance function to align words for historical comparison. In a follow-up paper (Covington, 1998), he extended the algorithm to align words from more than two languages. Somers (1998) proposed a special algorithm for aligning children&apos;s articulation data with the adult model. Gildea and Jurafsky (1996) applied the DP algorithm to pre-align input and output phonetic strings in order to improve the performance of their transducer induction system. Nerbonne and Heeringa (1997) employed a similar procedure to compute relative distance between words from various Dutch dialects. Some characteristics of these implementations are juxtaposed in Table 1. In this paper, I present a new algorithm for the alignment of cognates. It combines various techniques developed for sequence comparison with an appropriate scoring scheme for computing phonetic similarity on the basis of multivalued features. The ne"
A00-2038,W97-1102,0,0.589617,"in the last few years, several different approaches to phonetic alignment have been reported. Covington (1996) used depth-first search and a special distance function to align words for historical comparison. In a follow-up paper (Covington, 1998), he extended the algorithm to align words from more than two languages. Somers (1998) proposed a special algorithm for aligning children&apos;s articulation data with the adult model. Gildea and Jurafsky (1996) applied the DP algorithm to pre-align input and output phonetic strings in order to improve the performance of their transducer induction system. Nerbonne and Heeringa (1997) employed a similar procedure to compute relative distance between words from various Dutch dialects. Some characteristics of these implementations are juxtaposed in Table 1. In this paper, I present a new algorithm for the alignment of cognates. It combines various techniques developed for sequence comparison with an appropriate scoring scheme for computing phonetic similarity on the basis of multivalued features. The new algorithm performs better, in terms of accuracy and efficiency, than comparable algorithms reported by Covington (1996) and Somers (1999). Although the main focus of this pa"
A00-2038,P98-2200,0,0.117486,"orithms can used as well. The task of finding the optimal alignment is closely linked to the task of calculating the distance between two sequences. The basic DP algorithm 288 accomplishes both tasks. Depending on the application, either of the results, or both, can be used. Within the last few years, several different approaches to phonetic alignment have been reported. Covington (1996) used depth-first search and a special distance function to align words for historical comparison. In a follow-up paper (Covington, 1998), he extended the algorithm to align words from more than two languages. Somers (1998) proposed a special algorithm for aligning children&apos;s articulation data with the adult model. Gildea and Jurafsky (1996) applied the DP algorithm to pre-align input and output phonetic strings in order to improve the performance of their transducer induction system. Nerbonne and Heeringa (1997) employed a similar procedure to compute relative distance between words from various Dutch dialects. Some characteristics of these implementations are juxtaposed in Table 1. In this paper, I present a new algorithm for the alignment of cognates. It combines various techniques developed for sequence comp"
A00-2038,J99-2005,0,0.258799,"er induction system. Nerbonne and Heeringa (1997) employed a similar procedure to compute relative distance between words from various Dutch dialects. Some characteristics of these implementations are juxtaposed in Table 1. In this paper, I present a new algorithm for the alignment of cognates. It combines various techniques developed for sequence comparison with an appropriate scoring scheme for computing phonetic similarity on the basis of multivalued features. The new algorithm performs better, in terms of accuracy and efficiency, than comparable algorithms reported by Covington (1996) and Somers (1999). Although the main focus of this paper is diachronic phonology, the techniques proposed here can also be applied in other contexts where it is necessary to align phonetic sequences. 2 Comparing Phones To align phonetic sequences, we first need a function for calculating the distance between individual phones. The numerical value assigned by the function to a pair of segments is referred to as the cost, or penalty, of substitution. The function is often extended to cover pairs consisting of a segment and the null character, which correspond to the operaAlgorithm Covington (1996) Somers (1998)"
A00-2038,C98-1043,0,\N,Missing
A00-2038,C98-2195,0,\N,Missing
C02-1016,J93-1003,0,0.0321228,", and proposes an algorithm for inducing models of translational equivalence that outperform the models that are based solely on co-occurrence counts. His models employ the one-to-one assumption, which formalizes the observation that most words in bitexts are translated to a single word in the corresponding sentence. The algorithm, which is related to the expectation-maximization (EM) algorithm, iteratively re-estimates the likelihood scores which represent the probability that two word types are mutual translations. In the first step, the scores are initialized according to the G2 statistic (Dunning, 1993). Next, the likelihood scores are used to induce a set of one-to-one links between word tokens in the bitext. The links are determined by a greedy competitive linking algorithm, which proceeds to link pairs that have the highest likelihood scores. After the linking is completed, the link counts are used to re-estimate the likelihood scores, which in turn are applied to find a new set of links. The process is repeated until the translation model converges to the desired degree. Melamed presents three translation-model estimation methods. Method A re-estimates the likelihood scores as the logari"
C02-1016,W01-0504,0,0.0273549,"assistance to historical linguists. The Reconstruction Engine (Lowe and Mazaudon, 1994), a set of programs designed to be an aid in language reconstruction, requires a set of correspondences to be provided beforehand. The determination of correspondences is closely related to another task that has been much studied in computational linguistics, the identification of cognates. Cognates have been employed for sentence and word alignment in bitexts (Simard et al., 1992; Melamed, 1999), improving statistical machine translation models (Al-Onaizan et al., 1999), and inducing translation lexicons (Koehn and Knight, 2001). Some of the proposed cognate identification algorithms implicitly determine and employ correspondences (Tiedemann, 1999; Mann and Yarowsky, 2001). Although it may not be immediately apparent, there is a strong similarity between the task of matching phonetic segments in a pair of cognate words, and the task of matching words in two sentences that are mutual translations (Figure 1). The Snow lies on the Nix iacet in terra w u l l u p ground f Figure 1: The similarity of word alignment in bitexts and phoneme alignment between cognates. consistency with which a word in one language is translate"
C02-1016,A00-2038,1,0.817417,"sponding sequences. In sentence translation, the alignment links frequently cross and it is not unusual for two words in different parts of sentences to correspond. In contrast, the processes that lead to link intersection in diachronic phonology, such as metathesis, are quite sporadic. The introduction of the no-crossing-links constraint on alignments not only leads to a dramatic reduction of the search space, but also makes it possible to replace the approximate competitive-linking algorithm of Melamed with a variant of the well-known dynamic programming algorithm (Wagner and Fischer, 1974; Kondrak, 2000), which computes the optimal alignment between two strings in polynomial time. Null links in statistical machine translation are induced for words on one side of the bitext that have no clear counterparts on the other side of the bitext. Melamed’s algorithm explicitly calculates the likelihood scores of null links for every word type occurring in a bitext. In diachronic phonology, phonological processes that lead to insertion or deletion of segments usually operate on individual words rather than on particular sounds across the language. Therefore, I model insertion and deletion by employing a"
C02-1016,N01-1014,1,0.871197,"Missing"
C02-1016,J94-3004,0,0.0300767,"ermination of correspondences is the principal step of the comparative method of language reconstruction. Not only does it provide evidence for the relatedness of languages, but it also makes it possible to distinguish cognates from loan words and chance resemblances. However, because manual determination of correspondences is an extremely time-consuming process, it has yet to be accomplished for many proposed language families. A system able to perform this task automatically from unprocessed bilingual wordlists could be of great assistance to historical linguists. The Reconstruction Engine (Lowe and Mazaudon, 1994), a set of programs designed to be an aid in language reconstruction, requires a set of correspondences to be provided beforehand. The determination of correspondences is closely related to another task that has been much studied in computational linguistics, the identification of cognates. Cognates have been employed for sentence and word alignment in bitexts (Simard et al., 1992; Melamed, 1999), improving statistical machine translation models (Al-Onaizan et al., 1999), and inducing translation lexicons (Koehn and Knight, 2001). Some of the proposed cognate identification algorithms implicit"
C02-1016,N01-1020,0,0.0476947,"nstruction, requires a set of correspondences to be provided beforehand. The determination of correspondences is closely related to another task that has been much studied in computational linguistics, the identification of cognates. Cognates have been employed for sentence and word alignment in bitexts (Simard et al., 1992; Melamed, 1999), improving statistical machine translation models (Al-Onaizan et al., 1999), and inducing translation lexicons (Koehn and Knight, 2001). Some of the proposed cognate identification algorithms implicitly determine and employ correspondences (Tiedemann, 1999; Mann and Yarowsky, 2001). Although it may not be immediately apparent, there is a strong similarity between the task of matching phonetic segments in a pair of cognate words, and the task of matching words in two sentences that are mutual translations (Figure 1). The Snow lies on the Nix iacet in terra w u l l u p ground f Figure 1: The similarity of word alignment in bitexts and phoneme alignment between cognates. consistency with which a word in one language is translated into a word in another language is mirrored by the consistency of sound correspondences. The former is due to the semantic relation of synonymy,"
C02-1016,W97-0311,0,0.221581,"Missing"
C02-1016,J99-1003,0,0.0148205,"osed language families. A system able to perform this task automatically from unprocessed bilingual wordlists could be of great assistance to historical linguists. The Reconstruction Engine (Lowe and Mazaudon, 1994), a set of programs designed to be an aid in language reconstruction, requires a set of correspondences to be provided beforehand. The determination of correspondences is closely related to another task that has been much studied in computational linguistics, the identification of cognates. Cognates have been employed for sentence and word alignment in bitexts (Simard et al., 1992; Melamed, 1999), improving statistical machine translation models (Al-Onaizan et al., 1999), and inducing translation lexicons (Koehn and Knight, 2001). Some of the proposed cognate identification algorithms implicitly determine and employ correspondences (Tiedemann, 1999; Mann and Yarowsky, 2001). Although it may not be immediately apparent, there is a strong similarity between the task of matching phonetic segments in a pair of cognate words, and the task of matching words in two sentences that are mutual translations (Figure 1). The Snow lies on the Nix iacet in terra w u l l u p ground f Figure 1: The si"
C02-1016,J00-2004,0,0.068389,"ies can be induced from bitexts. The difficulty lies in the fact that the mapping, or alignment, of words between two parts of a bitext is not known in advance. Algorithms for word alignment in bitexts aim at discovering word pairs that are mutual translations. A straightforward approach is to estimate the likelihood that words are mutual translations by computing a similarity function based on a co-occurrence statistic, such as mutual information, Dice coefficient, or the χ2 test. The underlying assumption is that the association scores for different word pairs are independent of each other. Melamed (2000) shows that the assumption of independence leads to invalid word associations, and proposes an algorithm for inducing models of translational equivalence that outperform the models that are based solely on co-occurrence counts. His models employ the one-to-one assumption, which formalizes the observation that most words in bitexts are translated to a single word in the corresponding sentence. The algorithm, which is related to the expectation-maximization (EM) algorithm, iteratively re-estimates the likelihood scores which represent the probability that two word types are mutual translations."
C02-1016,1992.tmi-1.7,0,0.0569222,"plished for many proposed language families. A system able to perform this task automatically from unprocessed bilingual wordlists could be of great assistance to historical linguists. The Reconstruction Engine (Lowe and Mazaudon, 1994), a set of programs designed to be an aid in language reconstruction, requires a set of correspondences to be provided beforehand. The determination of correspondences is closely related to another task that has been much studied in computational linguistics, the identification of cognates. Cognates have been employed for sentence and word alignment in bitexts (Simard et al., 1992; Melamed, 1999), improving statistical machine translation models (Al-Onaizan et al., 1999), and inducing translation lexicons (Koehn and Knight, 2001). Some of the proposed cognate identification algorithms implicitly determine and employ correspondences (Tiedemann, 1999; Mann and Yarowsky, 2001). Although it may not be immediately apparent, there is a strong similarity between the task of matching phonetic segments in a pair of cognate words, and the task of matching words in two sentences that are mutual translations (Figure 1). The Snow lies on the Nix iacet in terra w u l l u p ground f"
C02-1016,W99-0626,0,0.0127683,"in language reconstruction, requires a set of correspondences to be provided beforehand. The determination of correspondences is closely related to another task that has been much studied in computational linguistics, the identification of cognates. Cognates have been employed for sentence and word alignment in bitexts (Simard et al., 1992; Melamed, 1999), improving statistical machine translation models (Al-Onaizan et al., 1999), and inducing translation lexicons (Koehn and Knight, 2001). Some of the proposed cognate identification algorithms implicitly determine and employ correspondences (Tiedemann, 1999; Mann and Yarowsky, 2001). Although it may not be immediately apparent, there is a strong similarity between the task of matching phonetic segments in a pair of cognate words, and the task of matching words in two sentences that are mutual translations (Figure 1). The Snow lies on the Nix iacet in terra w u l l u p ground f Figure 1: The similarity of word alignment in bitexts and phoneme alignment between cognates. consistency with which a word in one language is translated into a word in another language is mirrored by the consistency of sound correspondences. The former is due to the seman"
C02-1016,J01-4008,1,\N,Missing
C04-1137,A00-2038,1,0.857804,"ns’ Desk Reference (PDR) warns may be “mistaken for each other ... lead[ing]  Orthographic Phonetic Distance EDIT NED SOUNDEX EDITEX Similarity -GRAM LCSR ALINE Measure EDIT NED LCSR BIGRAM TRIGRAM-2B SOUNDEX EDITEX ALINE BI-SIM TRI-SIM PREFIX Table 1: Classification of word distance and similarity measures. to serious medication errors” (24th Ed., 2003). The phonetic transcription of the two names, [zænæks] and [zæntæk], reveals their sound-alike similarity that is not apparent in their orthographic form. For the detection of sound-alike confusion pairs, we apply the ALINE phonetic aligner (Kondrak, 2000), which estimates the similarity between two phonetically-transcribed words. We demonstrate that ALINE outperforms orthographic approaches on a test set containing sound-alike confusion pairs. The next section describes several commonlyused measures of word similarity. After this, we present two new methods for identifying look-alike and sound-alike drug names. We then compare the effectiveness of various measures using our recallbased evaluation methodology on a U.S. pharmacopeial gold standard and on another test set containing sound-alike confusion pairs. We conclude with a discussion of ou"
C04-1137,J99-1003,0,0.492233,"section, we describe a number of measures that have been applied to the problem of identifying confusable drug names. Specific examples of values obtained by the measures are provided in Table 2. String-edit distance (Wagner and Fischer, 1974) (EDIT) (also known as Levenshtein distance) counts up the number of steps it takes to transform one string into another, where the cost of substitution is the same as the cost of insertion or deletion. A normalized edit distance (NED) is calculated by dividing the total edit cost by the length of the longer string. The longest common subsequence ratio (Melamed, 1999) (LCSR) is computed by dividing Zantac/ Xanax 3 0.500 0.500 0.222 0.000 3 5 9.542 0.417 0.333 0.000 Zantac/ Contac 2 0.333 0.667 0.600 0.333 1 2 9.333 0.583 0.500 0.000 Xanax/ Contac 4 0.667 0.333 0.000 0.000 3 7 8.958 0.250 0.167 0.000 Table 2: Examples of values returned by various measures. the length of the longest common subsequence by the length of the longer string. LCSR is closely related to normalized edit distance. If the cost of substitution is at least twice the cost of insertion/deletion and the strings are of equal length, LCSR is equivalent to the normalized edit distance. In -g"
C14-1218,D11-1029,0,0.0545959,"thout the key, given only a corpus representing the language of the plaintext. The key is a 1-1 mapping between plaintext and ciphertext alphabets, which are assumed to be of equal length. Without loss of generality, we assume that both alphabets are composed of the same set of symbols, so that the key is equivalent to a permutation of the alphabet. Accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition (Nagy et al., 1987), decoding web pages that utilize an unknown encoding scheme (Corlett and Penn, 2010), cognate identification (Berg-Kirkpatrick and Klein, 2011), bilingual lexicon induction (Nuhn et al., 2012), machine translation without parallel training data (Ravi and Knight, 2011), and archaeological decipherment of lost languages (Snyder et al., 2010). Our contribution is a novel approach to the problem that combines both character-level and word-level language models. We formulate decipherment as a tree search problem, and find solutions with beam search, which has previously been applied to decipherment by Nuhn et al. (2013), or Monte Carlo Tree Search (MCTS), an algorithm originally designed for games, which can provide accurate solutions in"
C14-1218,A00-1031,0,0.180409,"d language model that incorporates both character-level and word-level information. With unigram, bigram, and trigram language models over both words and characters trained on a large corpus, n-gram models of different orders are combined by deleted interpolation (Jelinek and Mercer, 1980). The smoothed word trigram probability Pˆ is: Pˆ (wk |wk−2 wk−1 ) = λ1 P (wk ) + λ2 P (wk |wk−1 ) + λ3 P (wk |wk−2 wk−1 ), such that the λs sum to 1. The linear coefficients are determined by successively deleting each trigram from the training corpus and maximizing the likelihood of the rest of the corpus (Brants, 2000). The probability of text s = w1 , w2 , . . . , wn according to the smoothed word language model is: PW (s) = P (w1n ) = n Y Pˆ (wk |wk−2 wk−1 ). k=1 The unigram, bigram, and trigram character language models are combined in a similar manner to yield PC (s). The final score is then computed as a linear combination of the log probabilities returned by both character and word components: score(s) = χ log PC (s) + (1 − χ) log PW (s), with the value of χ optimized on a development set. The score of a key is taken to be the score of the decipherment that it produces. The handling of the OOV words i"
C14-1218,P10-1106,0,0.732724,"). The method is elegant and easy to use, requiring only the knowledge of a key whose length is no longer than the size of the alphabet. There are over 1026 possible 26-letter keys, so brute-force decryption is infeasible. Manual decipherment of substitution ciphers typically starts with frequency analysis, provided that the ciphertext is sufficiently long, followed by various heuristics (Singh, 1999). In this paper, we investigate the task of automatically solving substitution ciphers. Complete automation of the key discovery process remains an active area of research (Ravi and Knight, 2008; Corlett and Penn, 2010; Nuhn et al., 2013). The task is to recover the plaintext from the ciphertext without the key, given only a corpus representing the language of the plaintext. The key is a 1-1 mapping between plaintext and ciphertext alphabets, which are assumed to be of equal length. Without loss of generality, we assume that both alphabets are composed of the same set of symbols, so that the key is equivalent to a permutation of the alphabet. Accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition (Nagy et al., 1987), decoding web pages that util"
C14-1218,W99-0906,0,0.707207,"Missing"
C14-1218,P06-2065,0,0.639528,"Missing"
C14-1218,W11-1202,0,0.440295,"Missing"
C14-1218,P13-1060,0,0.0296388,"candidates are ranked according to their Hamming distance to the current decipherment, with score used only to break ties. This two-stage approach is designed to exploit the fact that the solver typically gets closer to the correct decipherment as the search progresses. 2317 1: 2: 3: 4: 5: 6: 7: 8: Root contains InitialKey for m iterations do recursively select optimal Path from Root Leaf = last node of Path BestLeaf = E XPAND(Leaf, CipherText) append BestLeaf to Path Max = Path node with the highest score assign score of Max to all nodes in Path Figure 2: MCTS for decipherment. 5 Tree Search Nuhn and Ney (2013) show that finding the optimal decipherment with respect to a character bigram model is NP-hard. Since our scoring function incorporates a language model score, choosing an appropriate tree search technique is crucial in order to minimize the number of search errors, where the score of the returned solution is lower than the score of the actual plaintext. In this section we describe two search algorithms: an adaptation of Monte Carlo Tree Search (MCTS), and a version of beam search. 5.1 Monte Carlo Tree Search MCTS is a search algorithm for heuristic decision making. Starting from an initial s"
C14-1218,P12-1017,0,0.0149492,"the plaintext. The key is a 1-1 mapping between plaintext and ciphertext alphabets, which are assumed to be of equal length. Without loss of generality, we assume that both alphabets are composed of the same set of symbols, so that the key is equivalent to a permutation of the alphabet. Accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition (Nagy et al., 1987), decoding web pages that utilize an unknown encoding scheme (Corlett and Penn, 2010), cognate identification (Berg-Kirkpatrick and Klein, 2011), bilingual lexicon induction (Nuhn et al., 2012), machine translation without parallel training data (Ravi and Knight, 2011), and archaeological decipherment of lost languages (Snyder et al., 2010). Our contribution is a novel approach to the problem that combines both character-level and word-level language models. We formulate decipherment as a tree search problem, and find solutions with beam search, which has previously been applied to decipherment by Nuhn et al. (2013), or Monte Carlo Tree Search (MCTS), an algorithm originally designed for games, which can provide accurate solutions in less time. We compare the speed and accuracy of b"
C14-1218,P13-1154,0,0.529001,"and easy to use, requiring only the knowledge of a key whose length is no longer than the size of the alphabet. There are over 1026 possible 26-letter keys, so brute-force decryption is infeasible. Manual decipherment of substitution ciphers typically starts with frequency analysis, provided that the ciphertext is sufficiently long, followed by various heuristics (Singh, 1999). In this paper, we investigate the task of automatically solving substitution ciphers. Complete automation of the key discovery process remains an active area of research (Ravi and Knight, 2008; Corlett and Penn, 2010; Nuhn et al., 2013). The task is to recover the plaintext from the ciphertext without the key, given only a corpus representing the language of the plaintext. The key is a 1-1 mapping between plaintext and ciphertext alphabets, which are assumed to be of equal length. Without loss of generality, we assume that both alphabets are composed of the same set of symbols, so that the key is equivalent to a permutation of the alphabet. Accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition (Nagy et al., 1987), decoding web pages that utilize an unknown encod"
C14-1218,D08-1085,0,0.39599,"the alphabet (Figure 1). The method is elegant and easy to use, requiring only the knowledge of a key whose length is no longer than the size of the alphabet. There are over 1026 possible 26-letter keys, so brute-force decryption is infeasible. Manual decipherment of substitution ciphers typically starts with frequency analysis, provided that the ciphertext is sufficiently long, followed by various heuristics (Singh, 1999). In this paper, we investigate the task of automatically solving substitution ciphers. Complete automation of the key discovery process remains an active area of research (Ravi and Knight, 2008; Corlett and Penn, 2010; Nuhn et al., 2013). The task is to recover the plaintext from the ciphertext without the key, given only a corpus representing the language of the plaintext. The key is a 1-1 mapping between plaintext and ciphertext alphabets, which are assumed to be of equal length. Without loss of generality, we assume that both alphabets are composed of the same set of symbols, so that the key is equivalent to a permutation of the alphabet. Accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition (Nagy et al., 1987), deco"
C14-1218,N09-1005,0,0.376042,"Missing"
C14-1218,P11-1002,0,0.0368259,"alphabets, which are assumed to be of equal length. Without loss of generality, we assume that both alphabets are composed of the same set of symbols, so that the key is equivalent to a permutation of the alphabet. Accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition (Nagy et al., 1987), decoding web pages that utilize an unknown encoding scheme (Corlett and Penn, 2010), cognate identification (Berg-Kirkpatrick and Klein, 2011), bilingual lexicon induction (Nuhn et al., 2012), machine translation without parallel training data (Ravi and Knight, 2011), and archaeological decipherment of lost languages (Snyder et al., 2010). Our contribution is a novel approach to the problem that combines both character-level and word-level language models. We formulate decipherment as a tree search problem, and find solutions with beam search, which has previously been applied to decipherment by Nuhn et al. (2013), or Monte Carlo Tree Search (MCTS), an algorithm originally designed for games, which can provide accurate solutions in less time. We compare the speed and accuracy of both approaches. On a benchmark set of variable-length ciphers, we achieve si"
C14-1218,W11-1511,0,0.329751,"Missing"
C14-1218,P10-1107,0,0.0814185,"lity, we assume that both alphabets are composed of the same set of symbols, so that the key is equivalent to a permutation of the alphabet. Accurate and efficient automated decipherment can be applied to other problems, such as optical character recognition (Nagy et al., 1987), decoding web pages that utilize an unknown encoding scheme (Corlett and Penn, 2010), cognate identification (Berg-Kirkpatrick and Klein, 2011), bilingual lexicon induction (Nuhn et al., 2012), machine translation without parallel training data (Ravi and Knight, 2011), and archaeological decipherment of lost languages (Snyder et al., 2010). Our contribution is a novel approach to the problem that combines both character-level and word-level language models. We formulate decipherment as a tree search problem, and find solutions with beam search, which has previously been applied to decipherment by Nuhn et al. (2013), or Monte Carlo Tree Search (MCTS), an algorithm originally designed for games, which can provide accurate solutions in less time. We compare the speed and accuracy of both approaches. On a benchmark set of variable-length ciphers, we achieve significant improvement in terms of accuracy over the state of the art. Add"
D10-1029,atserias-etal-2006-freeling,0,0.0609957,"Missing"
D10-1029,J96-2001,0,0.0666403,"above the 0.80 level considered to indicate good reliability. For our experiments, the 1718 annotated examples are randomly divided into 1000 training, 359 development, and 359 held-out test examples. 4.3 Classifier Settings We train a linear support vector machine classifier using the efficient LIBLINEAR package (Fan et al., 2008). We use L2-loss and L2-regularization. We 4 We found that the majority of single-occurrence verbs in the Gigaword data were typos. We would expect true hapax legomena to be largely compositional, and we could potentially derive better statistics if we include them (Baayen and Sproat, 1996). One possible option, employed in previous work, is to ensure words of interest are “manually corrected for typing errors before further analysis” (Baayen and Renouf, 1996). optimize the choice of features and regularization hyperparameter on development data, attaining a maximum when C = 0.1. 4.4 Evaluation We compare the following systems: 1. Base1: always choose compositional (the majority class). 2. Base2: for each prefix, choose the majority class over the verbs having that prefix in training data. 3. Morf: the unsupervised Morfessor system (Creutz and Lagus, 2007) (CategoriesML, from 11"
D10-1029,W03-1812,0,0.0168956,"an include arbitrary and interdependent features of the type proposed in our work. We see potential in combining the best elements of both approaches to obtain a system that 301 does not need annotated training data, but can make use of powerful web-scale features. Our approach follows previous systems for morphological analysis that leverage semantic as well as orthographic information (Yarowsky and Wicentowski, 2000; Schone and Jurafsky, 2001; Baroni et al., 2002). Similar problems also arise in core semantics, such as how to detect the compositionality of multi-word expressions (Lin, 1999; Baldwin et al., 2003; Fazly et al., 2009). Our problem is similar to the analysis of verb-particle constructions or VPCs (e.g., round up, sell off, etc.) (Bannard et al., 2003). Web-scale data can be used for a variety of problems in semantics (Lin et al., 2010), including classifying VPCs (Kummerfeld and Curran, 2008). We motivated our work by describing applications in information retrieval, and here Google is clearly the elephant in the room. It is widely reported that Google has been using stemming since 2003; for example, a search today for Porter stemming returns pages describing the Porter stemmer, and the"
D10-1029,W03-1809,0,0.152894,"of precision, but the results depend on the morphological complexity of the text’s language (Hollink et al., 2004). Introduction Many verbs are formed by adding prefixes to existing verbs. For example, remarry is composed of a prefix, re-, and a stem, marry. We present an approach to predicting the compositionality of prefix verbs. The verb remarry is compositional; it means to marry again. On the other hand, retire is generally non-compositional; it rarely means to tire again. There is a continuum of compositionality in prefix verbs, as in other complex word forms and multiword expressions (Bannard et al., 2003; Creutz and Lagus, 2005; Fazly et al., 2009; Xu et al., 2009). We adopt a definition of compositionality specifically designed to support downstream applications that might benefit from knowledge of verb stems. The lack of success in applying morphological analysis in IR is unsurprising given that most previous systems are not designed with applications in mind. For example, the objective of the influential Linguistica program is “to produce an output that matches as closely as possible the analysis that would be given by a human morphologist” (Goldsmith, 2001). Unsupervised systems achieve t"
D10-1029,W02-0606,0,0.364441,"ventional standards, we present an algorithm whose objective is to find only those prefix verbs that exhibit semantic compositionality; i.e., prefix verbs that are fully meaningpreserving, sums-of-their-parts. We produce a new corpus, annotated according to this definition. We use these annotated examples to learn a discriminative model of semantic compositionality. Our classifier relies on a variety of features that exploit the distributional patterns of verbs and stems. We build on previous work that applies semantics to morphology (Yarowsky and Wicentowski, 2000; Schone and Jurafsky, 2001; Baroni et al., 2002), and also on work that exploits web-scale data for semantic analysis (Turney, 2001; Nakov, 2007; Kummerfeld and Curran, 2008). For example, we measure how often a prefix verb appears with a hyphen between the prefix and stem. We also look at the distribution of the stem as a separate word: we calculate the probability of the prefix verb and the separated stem’s co-occurrence in a segment of discourse; we also calculate the distributional similarity between the verb and the separated stem. High scores for these measures indicate compositionality. We extract counts from a web-scale N-gram corpu"
D10-1029,H05-1013,0,0.0294595,"Missing"
D10-1029,P96-1044,0,0.0613204,"Missing"
D10-1029,D08-1113,0,0.0273355,"inistically stripping prefixes in some languages, but not English (e.g., only semi- and re- can be stripped when analyzing OOV Spanish verbs). A number of modern morphological analyzers use supervised machine learning. These systems could all potentially benefit from the novel distributional features used in our model. Van den Bosch and Daelemans (1999) use memory-based learning to analyze Dutch. Wicentowski (2004)’s supervised WordFrame model includes a prefixation component. Results are presented on over 30 languages. Erjavec and D˘zeroski (2004) present a supervised lemmatizer for Slovene. Dreyer et al. (2008) perform supervised lemmatization on Basque, English, Irish and Tagalog; like us they include results when the set of lemmas is given. Toutanova and Cherry (2009) present a discriminative lemmatizer for English, Bulgarian, Czech and Slovene, but only handle suffix morphology. Poon et al. (2009) present an unsupervised segmenter, but one that is based on a log-linear model that can include arbitrary and interdependent features of the type proposed in our work. We see potential in combining the best elements of both approaches to obtain a system that 301 does not need annotated training data, bu"
D10-1029,J09-1005,0,0.0493937,"orphological complexity of the text’s language (Hollink et al., 2004). Introduction Many verbs are formed by adding prefixes to existing verbs. For example, remarry is composed of a prefix, re-, and a stem, marry. We present an approach to predicting the compositionality of prefix verbs. The verb remarry is compositional; it means to marry again. On the other hand, retire is generally non-compositional; it rarely means to tire again. There is a continuum of compositionality in prefix verbs, as in other complex word forms and multiword expressions (Bannard et al., 2003; Creutz and Lagus, 2005; Fazly et al., 2009; Xu et al., 2009). We adopt a definition of compositionality specifically designed to support downstream applications that might benefit from knowledge of verb stems. The lack of success in applying morphological analysis in IR is unsurprising given that most previous systems are not designed with applications in mind. For example, the objective of the influential Linguistica program is “to produce an output that matches as closely as possible the analysis that would be given by a human morphologist” (Goldsmith, 2001). Unsupervised systems achieve this aim by exploiting learning biases such a"
D10-1029,J01-2001,0,0.0102835,"and multiword expressions (Bannard et al., 2003; Creutz and Lagus, 2005; Fazly et al., 2009; Xu et al., 2009). We adopt a definition of compositionality specifically designed to support downstream applications that might benefit from knowledge of verb stems. The lack of success in applying morphological analysis in IR is unsurprising given that most previous systems are not designed with applications in mind. For example, the objective of the influential Linguistica program is “to produce an output that matches as closely as possible the analysis that would be given by a human morphologist” (Goldsmith, 2001). Unsupervised systems achieve this aim by exploiting learning biases such as minimum description length for lexicons (Goldsmith, 2001; Creutz and Lagus, 2007) and high entropy across morpheme boundaries (Keshava and Pitler, 2006). Supervised approaches learn directly from words annotated by morphologists (Van den Bosch and Daelemans, 1999; Toutanova and Cherry, 2009), often using CELEX, a lexical database that includes 293 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 293–303, c MIT, Massachusetts, USA, 9-11 October 2010. 2010 Association for Co"
D10-1029,C92-3145,0,0.16832,"g systems according to conventional morphology may not be optimal for downstream applications. Furthermore, accuracy is substantially lower in this setting than in our main results. Targeting conventional segmentations may be both more challenging and less useful than focusing on semantic compositionality. 6 Related Work There is a large body of work on morphological analysis of English, but most of this work does not handle prefixes. Porter’s stemmer is a well-known suffix-stripping algorithm (Porter, 1980), while publicly-available lemmatizers like morpha (Minnen et al., 2001) and PC-KIMMO (Karp et al., 1992) only process inflectional morphology. FreeLing (Atserias et al., 2006) comes with a few simple rules for deterministically stripping prefixes in some languages, but not English (e.g., only semi- and re- can be stripped when analyzing OOV Spanish verbs). A number of modern morphological analyzers use supervised machine learning. These systems could all potentially benefit from the novel distributional features used in our model. Van den Bosch and Daelemans (1999) use memory-based learning to analyze Dutch. Wicentowski (2004)’s supervised WordFrame model includes a prefixation component. Result"
D10-1029,U08-1008,0,0.0138957,"ous systems for morphological analysis that leverage semantic as well as orthographic information (Yarowsky and Wicentowski, 2000; Schone and Jurafsky, 2001; Baroni et al., 2002). Similar problems also arise in core semantics, such as how to detect the compositionality of multi-word expressions (Lin, 1999; Baldwin et al., 2003; Fazly et al., 2009). Our problem is similar to the analysis of verb-particle constructions or VPCs (e.g., round up, sell off, etc.) (Bannard et al., 2003). Web-scale data can be used for a variety of problems in semantics (Lin et al., 2010), including classifying VPCs (Kummerfeld and Curran, 2008). We motivated our work by describing applications in information retrieval, and here Google is clearly the elephant in the room. It is widely reported that Google has been using stemming since 2003; for example, a search today for Porter stemming returns pages describing the Porter stemmer, and the returned snippets have words like stemming, stemmer, and stem in bold text. Google can of course develop high-quality lists of morphological variants by paying attention to how users reformulate their queries. User query sessions have previously been used to expand queries using similar terms, such"
D10-1029,lin-etal-2010-new,1,0.878978,"unlabeled text. If a frequency or similarity is undefined in our corpus, we indicate this with a separate feature; weights on these features act as a kind of smoothing. 3.1 Features based on Web-Scale N-gram Data We use web-scale N-gram data to extract distributional features. The most widely-used N-gram corpus is the Google 5-gram Corpus (Brants and Franz, 2006). We use Google V2: a new N-gram corpus (also with N-grams of length one-to-five) created from the same one-trillion-word snapshot of the web as the Google 5-gram Corpus, but with enhanced filtering and processing of the source text (Lin et al., 2010). For Google V2, the source text was also partof-speech tagged, and the resulting part-of-speech tag distribution is included for each N-gram. There are 4.1 billion N-grams in the corpus. The part-of-speech tag distributions are particularly useful, as they allow us to collect verb-specific counts. For example, while a string like reuse occurs 1.1 million times in the web corpus, it is only tagged as a verb 270 thousand times. Conflating the noun/verb senses can lead to misleading scores for certain features. E.g., the hyphenation frequency of re-use would appear relatively low, even though re"
D10-1029,P98-2127,0,0.139567,"n N-gram. For the PMI, we regard occurrence in an N-gram as an event, and calculate the probability that a verb and separated stem jointly occur in an N-gram, divided by the probability of their occurring in an N-gram independently. 3.1.3 SIM features If a prefix verb is compositional, it should occur in similar contexts to its stem. The idea that a stem and stem+affix should be semantically similar has been exploited previously for morphological analysis (Schone and Jurafsky, 2000). We include a real-valued feature for the distributional similarity of the verb and stem using Lin’s thesaurus (Lin, 1998). The coverage of this measure was low: it was non-zero for only 93 of the 1000 prefix verbs in our training set. We therefore also include distributional similarity calculated using the web-scale 10million-phrase clustering as described above. Using this data, similarity is defined for 615 of the 1000 training verbs. We also explored a variety of WordNet-based similarity measures, but these ultimately did not prove helpful on development data. 3.1.4 FRQ features We include real-valued features for the raw frequencies of the verb and the stem on the web. If these frequencies are widely differe"
D10-1029,P99-1041,0,0.0397357,"odel that can include arbitrary and interdependent features of the type proposed in our work. We see potential in combining the best elements of both approaches to obtain a system that 301 does not need annotated training data, but can make use of powerful web-scale features. Our approach follows previous systems for morphological analysis that leverage semantic as well as orthographic information (Yarowsky and Wicentowski, 2000; Schone and Jurafsky, 2001; Baroni et al., 2002). Similar problems also arise in core semantics, such as how to detect the compositionality of multi-word expressions (Lin, 1999; Baldwin et al., 2003; Fazly et al., 2009). Our problem is similar to the analysis of verb-particle constructions or VPCs (e.g., round up, sell off, etc.) (Bannard et al., 2003). Web-scale data can be used for a variety of problems in semantics (Lin et al., 2010), including classifying VPCs (Kummerfeld and Curran, 2008). We motivated our work by describing applications in information retrieval, and here Google is clearly the elephant in the room. It is widely reported that Google has been using stemming since 2003; for example, a search today for Porter stemming returns pages describing the P"
D10-1029,W05-0603,0,0.0195206,"ge corpus, compositional prefix verbs tend to occur in a hyphenated form more often than do non-compositional prefix verbs. We therefore provide real-valued features for how often the verb was hyphenated and unhyphenated on the web. For example, we collect counts for the frequencies of re-elect (33K) and reelect (9K) in our web corpus, and we convert the frequencies to logcounts. We also give real-valued features for the hyphenated/unhyphenated log-counts using only those occurrences of the verb that were tagged as a verb, exploiting the tag distributions in our web corpus as described above. Nakov and Hearst (2005) previously used hyphenation counts as an indication of a syntactic relationship between nouns. In contrast, we leverage hyphenation counts as an indication of a semantic property of verbs. 3.1.2 COOC features COOC features, and also the SIM (Section 3.1.3) and YAH (Section 3.2.2) features, concern the association in text between the prefix verb and its stem, where the stem occurs as a separate word. We call this the separated stem. If a prefix verb is compositional, it is more likely to occur near its separated stem in text. We often see agree and disagree, read and reread, etc. occurring in"
D10-1029,N09-1024,0,0.118371,"o force,” (non-compositional) while a computer program can “resort a linked list” (compositional). We therefore define prefix-verb compositionality as a context-specific property of verb tokens rather than a global property of verb types. However, it is worth noting that we ultimately found the compositionality of types to be very consistent across contexts (Section 5.1.2), and we were unable to leverage contextual information to improve classification accuracy; our final system is essentially type-based. Other recent morphological analyzers have also been typebased (Keshava and Pitler, 2006; Poon et al., 2009). Our system takes as input a verb token in uninflected form along with its sentence as context. The verb must be divisible into an initial string and a following remainder such that the initial string is on our list of prefixes and the remainder is on our list of stems. Hyphenation is allowed, e.g., both re-enter and reenter are acceptable inputs. The system determines whether the prefix/stem combination is compositional in the current context. For example, the verb unionize in, “The workers must unionize,” can be divided into a prefix un- and a stem ionize. The system should determine that h"
D10-1029,W00-0712,0,0.2625,"cy threshold. We also include a real-valued pointwise mutual information (PMI) feature for the verb and separated stem’s co-occurrence in an N-gram. For the PMI, we regard occurrence in an N-gram as an event, and calculate the probability that a verb and separated stem jointly occur in an N-gram, divided by the probability of their occurring in an N-gram independently. 3.1.3 SIM features If a prefix verb is compositional, it should occur in similar contexts to its stem. The idea that a stem and stem+affix should be semantically similar has been exploited previously for morphological analysis (Schone and Jurafsky, 2000). We include a real-valued feature for the distributional similarity of the verb and stem using Lin’s thesaurus (Lin, 1998). The coverage of this measure was low: it was non-zero for only 93 of the 1000 prefix verbs in our training set. We therefore also include distributional similarity calculated using the web-scale 10million-phrase clustering as described above. Using this data, similarity is defined for 615 of the 1000 training verbs. We also explored a variety of WordNet-based similarity measures, but these ultimately did not prove helpful on development data. 3.1.4 FRQ features We includ"
D10-1029,N01-1024,0,0.0708245,"Rather than relying on conventional standards, we present an algorithm whose objective is to find only those prefix verbs that exhibit semantic compositionality; i.e., prefix verbs that are fully meaningpreserving, sums-of-their-parts. We produce a new corpus, annotated according to this definition. We use these annotated examples to learn a discriminative model of semantic compositionality. Our classifier relies on a variety of features that exploit the distributional patterns of verbs and stems. We build on previous work that applies semantics to morphology (Yarowsky and Wicentowski, 2000; Schone and Jurafsky, 2001; Baroni et al., 2002), and also on work that exploits web-scale data for semantic analysis (Turney, 2001; Nakov, 2007; Kummerfeld and Curran, 2008). For example, we measure how often a prefix verb appears with a hyphen between the prefix and stem. We also look at the distribution of the stem as a separate word: we calculate the probability of the prefix verb and the separated stem’s co-occurrence in a segment of discourse; we also calculate the distributional similarity between the verb and the separated stem. High scores for these measures indicate compositionality. We extract counts from a"
D10-1029,P09-1055,0,0.065781,"us systems are not designed with applications in mind. For example, the objective of the influential Linguistica program is “to produce an output that matches as closely as possible the analysis that would be given by a human morphologist” (Goldsmith, 2001). Unsupervised systems achieve this aim by exploiting learning biases such as minimum description length for lexicons (Goldsmith, 2001; Creutz and Lagus, 2007) and high entropy across morpheme boundaries (Keshava and Pitler, 2006). Supervised approaches learn directly from words annotated by morphologists (Van den Bosch and Daelemans, 1999; Toutanova and Cherry, 2009), often using CELEX, a lexical database that includes 293 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 293–303, c MIT, Massachusetts, USA, 9-11 October 2010. 2010 Association for Computational Linguistics morphological information (Baayen et al., 1996). The conventional approach in morphology is to segment words into separate morphemes even when the words are not entirely compositional combinations of their parts (Creutz and Lagus, 2005). For example, while co- is considered a separate morpheme in the verb cooperate, the meaning of cooperate is"
D10-1029,P99-1037,0,0.0665249,"Missing"
D10-1029,W04-0109,0,0.0194869,"available lemmatizers like morpha (Minnen et al., 2001) and PC-KIMMO (Karp et al., 1992) only process inflectional morphology. FreeLing (Atserias et al., 2006) comes with a few simple rules for deterministically stripping prefixes in some languages, but not English (e.g., only semi- and re- can be stripped when analyzing OOV Spanish verbs). A number of modern morphological analyzers use supervised machine learning. These systems could all potentially benefit from the novel distributional features used in our model. Van den Bosch and Daelemans (1999) use memory-based learning to analyze Dutch. Wicentowski (2004)’s supervised WordFrame model includes a prefixation component. Results are presented on over 30 languages. Erjavec and D˘zeroski (2004) present a supervised lemmatizer for Slovene. Dreyer et al. (2008) perform supervised lemmatization on Basque, English, Irish and Tagalog; like us they include results when the set of lemmas is given. Toutanova and Cherry (2009) present a discriminative lemmatizer for English, Bulgarian, Czech and Slovene, but only handle suffix morphology. Poon et al. (2009) present an unsupervised segmenter, but one that is based on a log-linear model that can include arbitr"
D10-1029,Y09-2015,0,0.0126761,"ity of the text’s language (Hollink et al., 2004). Introduction Many verbs are formed by adding prefixes to existing verbs. For example, remarry is composed of a prefix, re-, and a stem, marry. We present an approach to predicting the compositionality of prefix verbs. The verb remarry is compositional; it means to marry again. On the other hand, retire is generally non-compositional; it rarely means to tire again. There is a continuum of compositionality in prefix verbs, as in other complex word forms and multiword expressions (Bannard et al., 2003; Creutz and Lagus, 2005; Fazly et al., 2009; Xu et al., 2009). We adopt a definition of compositionality specifically designed to support downstream applications that might benefit from knowledge of verb stems. The lack of success in applying morphological analysis in IR is unsurprising given that most previous systems are not designed with applications in mind. For example, the objective of the influential Linguistica program is “to produce an output that matches as closely as possible the analysis that would be given by a human morphologist” (Goldsmith, 2001). Unsupervised systems achieve this aim by exploiting learning biases such as minimum descript"
D10-1029,P00-1027,0,0.233899,"y have undesirable consequences. Rather than relying on conventional standards, we present an algorithm whose objective is to find only those prefix verbs that exhibit semantic compositionality; i.e., prefix verbs that are fully meaningpreserving, sums-of-their-parts. We produce a new corpus, annotated according to this definition. We use these annotated examples to learn a discriminative model of semantic compositionality. Our classifier relies on a variety of features that exploit the distributional patterns of verbs and stems. We build on previous work that applies semantics to morphology (Yarowsky and Wicentowski, 2000; Schone and Jurafsky, 2001; Baroni et al., 2002), and also on work that exploits web-scale data for semantic analysis (Turney, 2001; Nakov, 2007; Kummerfeld and Curran, 2008). For example, we measure how often a prefix verb appears with a hyphen between the prefix and stem. We also look at the distribution of the stem as a separate word: we calculate the probability of the prefix verb and the separated stem’s co-occurrence in a segment of discourse; we also calculate the distributional similarity between the verb and the separated stem. High scores for these measures indicate compositionality"
D10-1029,C98-2122,0,\N,Missing
D17-1267,P07-1083,1,0.790942,"dences The features described in the previous section are language-independent, but we would also like to take into account cognate information that is specific to pairs of languages, namely regular sound correspondences. For example, th/d is a sound correspondence between English and German, occurring in words such as think/denken and leather/Leder. A model trained on another language family would not be able to learn that a corresponding th and d is an important indicator of cognation in English/German pairs. For each language pair, we derive a specific model by implementing the approach of Bergsma and Kondrak (2007). As features, we extract pairs of substrings, up to length 3, that are consistent with the alignment induced by the minimum edit distance algorithm. The models are able to learn when a certain substring in one language corresponds to a certain substring in another language. In order to train the specific models, we need a substantial number of cognate pairs, which are not initially available in our unsupervised setting. We use a heuristic method to overcome this limitation. We create sets of words that satisfy the following two constraints: (1) identical dictionary definition, and (2) identic"
D17-1267,R13-1019,0,0.061475,"tem code is publicly available.1 2 Related Work Most previous work in automatic cognate identification only consider words as cognates if they have identical definitions. As such, they make limited or no use of semantic information. The simplest variant of this task is to make pairwise cognate classifications based on orthographic or pho1 https://github.com/ajstarna/SemaPhoR netic forms. Turchin et al. (2010) apply a heuristic based on consonant classes to identify the ratio of cognate pairs to non-cognate pairs between languages in an effort to determine the likelihood that they are related. Ciobanu and Dinu (2013) find cognate pairs by referring to dictionaries containing etymological information. Rama (2015) experiments with features motivated by string kernels for pairwise cognate classification. A more challenging version of the task is to cluster cognates within lists of words that have identical definitions. Hauer and Kondrak (2011) use confidence scores from a binary classifier that incorporates a variety of string similarity features to guide an average score clustering algorithm. Hall and Klein (2010, 2011) define generative models that model the evolution of words along a phylogeny according t"
D17-1267,P10-1105,0,0.0900341,"nate pairs between languages in an effort to determine the likelihood that they are related. Ciobanu and Dinu (2013) find cognate pairs by referring to dictionaries containing etymological information. Rama (2015) experiments with features motivated by string kernels for pairwise cognate classification. A more challenging version of the task is to cluster cognates within lists of words that have identical definitions. Hauer and Kondrak (2011) use confidence scores from a binary classifier that incorporates a variety of string similarity features to guide an average score clustering algorithm. Hall and Klein (2010, 2011) define generative models that model the evolution of words along a phylogeny according to automatically learned sound laws in the form of parametric edit distances. List and Moran (2013) propose an approach based on sound class alignments and an average score clustering algorithm. List et al. (2016) extend the approach to include partial cognates within word lists. Cognate identification that considers semantic information is a less-studied problem. Again, the task can be framed as either a pairwise classification or multi-lingual clustering. In a pairwise context, Kondrak (2004) descr"
D17-1267,D11-1032,0,0.356793,"Missing"
D17-1267,I11-1097,1,0.856745,"hic or pho1 https://github.com/ajstarna/SemaPhoR netic forms. Turchin et al. (2010) apply a heuristic based on consonant classes to identify the ratio of cognate pairs to non-cognate pairs between languages in an effort to determine the likelihood that they are related. Ciobanu and Dinu (2013) find cognate pairs by referring to dictionaries containing etymological information. Rama (2015) experiments with features motivated by string kernels for pairwise cognate classification. A more challenging version of the task is to cluster cognates within lists of words that have identical definitions. Hauer and Kondrak (2011) use confidence scores from a binary classifier that incorporates a variety of string similarity features to guide an average score clustering algorithm. Hall and Klein (2010, 2011) define generative models that model the evolution of words along a phylogeny according to automatically learned sound laws in the form of parametric edit distances. List and Moran (2013) propose an approach based on sound class alignments and an average score clustering algorithm. List et al. (2016) extend the approach to include partial cognates within word lists. Cognate identification that considers semantic inf"
D17-1267,W07-1317,1,0.700493,"ulti-lingual clustering. In a pairwise context, Kondrak (2004) describes a system for identifying cognates between language dictionaries which is based on phonetic similarity, complex multi-phoneme correspondences, and seman2520 tic information. The method of Wang and Sitbon (2014) employs word sense disambiguation combined with classic string similarity measures for finding cognate pairs in parallel texts to aid language learners. Finally, very little has been published on creating cognate sets based on both phonetic and semantic information, which is the task that we focus on in this paper. Kondrak et al. (2007) combine phonetic and sound correspondence scores with a simple semantic heuristic, and create cognate sets by using graph-based algorithms on connected components. Steiner et al. (2011) aim at a fully automated approach to the comparative method, including cognate set identification and language phylogeny construction. Neither of those systems and datasets are publicly available for the purpose of direct comparison to our method. 3 Methods In this section, we describe the design of our language-independent general model, as well as the language-specific models. Given a pair of words from rela"
D17-1267,M95-1005,0,0.108959,"Missing"
D17-1267,U14-1003,0,0.024372,"3) propose an approach based on sound class alignments and an average score clustering algorithm. List et al. (2016) extend the approach to include partial cognates within word lists. Cognate identification that considers semantic information is a less-studied problem. Again, the task can be framed as either a pairwise classification or multi-lingual clustering. In a pairwise context, Kondrak (2004) describes a system for identifying cognates between language dictionaries which is based on phonetic similarity, complex multi-phoneme correspondences, and seman2520 tic information. The method of Wang and Sitbon (2014) employs word sense disambiguation combined with classic string similarity measures for finding cognate pairs in parallel texts to aid language learners. Finally, very little has been published on creating cognate sets based on both phonetic and semantic information, which is the task that we focus on in this paper. Kondrak et al. (2007) combine phonetic and sound correspondence scores with a simple semantic heuristic, and create cognate sets by using graph-based algorithms on connected components. Steiner et al. (2011) aim at a fully automated approach to the comparative method, including cog"
D17-1267,P16-2097,0,0.231743,"e challenging version of the task is to cluster cognates within lists of words that have identical definitions. Hauer and Kondrak (2011) use confidence scores from a binary classifier that incorporates a variety of string similarity features to guide an average score clustering algorithm. Hall and Klein (2010, 2011) define generative models that model the evolution of words along a phylogeny according to automatically learned sound laws in the form of parametric edit distances. List and Moran (2013) propose an approach based on sound class alignments and an average score clustering algorithm. List et al. (2016) extend the approach to include partial cognates within word lists. Cognate identification that considers semantic information is a less-studied problem. Again, the task can be framed as either a pairwise classification or multi-lingual clustering. In a pairwise context, Kondrak (2004) describes a system for identifying cognates between language dictionaries which is based on phonetic similarity, complex multi-phoneme correspondences, and seman2520 tic information. The method of Wang and Sitbon (2014) employs word sense disambiguation combined with classic string similarity measures for findin"
D17-1267,P13-4003,0,0.020959,"rmation. Rama (2015) experiments with features motivated by string kernels for pairwise cognate classification. A more challenging version of the task is to cluster cognates within lists of words that have identical definitions. Hauer and Kondrak (2011) use confidence scores from a binary classifier that incorporates a variety of string similarity features to guide an average score clustering algorithm. Hall and Klein (2010, 2011) define generative models that model the evolution of words along a phylogeny according to automatically learned sound laws in the form of parametric edit distances. List and Moran (2013) propose an approach based on sound class alignments and an average score clustering algorithm. List et al. (2016) extend the approach to include partial cognates within word lists. Cognate identification that considers semantic information is a less-studied problem. Again, the task can be framed as either a pairwise classification or multi-lingual clustering. In a pairwise context, Kondrak (2004) describes a system for identifying cognates between language dictionaries which is based on phonetic similarity, complex multi-phoneme correspondences, and seman2520 tic information. The method of Wa"
D17-1267,P12-2059,0,0.120566,"Missing"
D17-1267,N15-1130,0,0.239389,"onsider words as cognates if they have identical definitions. As such, they make limited or no use of semantic information. The simplest variant of this task is to make pairwise cognate classifications based on orthographic or pho1 https://github.com/ajstarna/SemaPhoR netic forms. Turchin et al. (2010) apply a heuristic based on consonant classes to identify the ratio of cognate pairs to non-cognate pairs between languages in an effort to determine the likelihood that they are related. Ciobanu and Dinu (2013) find cognate pairs by referring to dictionaries containing etymological information. Rama (2015) experiments with features motivated by string kernels for pairwise cognate classification. A more challenging version of the task is to cluster cognates within lists of words that have identical definitions. Hauer and Kondrak (2011) use confidence scores from a binary classifier that incorporates a variety of string similarity features to guide an average score clustering algorithm. Hall and Klein (2010, 2011) define generative models that model the evolution of words along a phylogeny according to automatically learned sound laws in the form of parametric edit distances. List and Moran (2013"
D17-1267,P07-3005,0,\N,Missing
D17-1267,I13-1112,0,\N,Missing
D17-1267,W12-0216,0,\N,Missing
E17-2034,N07-1047,1,0.798716,"rd-form l¨ufte. 2.1 c c c c c c We say that a lemma+tag analysis generated from a word-form satisfies the affix-match constraint if and only if the resulting affix-tag pair occurs in the alignment of the training data. Table 2 shows the alignments of five possible analyses to the corresponding word-form schreibet, of which three satisfy the affix-match constraint. Only analysis #2 (in bold) is correct. Alignment For the training of the string transduction models, we need aligned source-target pairs. Monotonic alignments are inferred with a modified version of the M2M (many-to-many) aligner of Jiampojamarn et al. (2007), which maximizes the joint likelihood of the aligned source and target substring pairs using the Expectation-Maximization algorithm. A transduction from a word-form which happens to be shorter than its lemma (e.g. l¨ufte/l¨uften) could be achieved by including an insertion operation (e.g.  → n). However, in order to avoid a prohibitively expensive transduction model, we model insertion as a many-to-many alignment, which bounds the transduction operation to its context. We modify the M2M aligner by allowing the alignment to learn the likelihood of a generalized identity alignment (i.e., i → i"
E17-2034,N10-1103,1,0.83254,"t, which is typically aligned to a substring in the word-form that involves the corresponding affix.2 We allow the maximum length of the alignment substring to be longer for the tag alignment than for the individual characters in the lemma. After aligning the training data we record all substring alignments that involve affixes and tags. At test time, the source-target alignment is implied by the substring transduction sequence. 2.2 Transduction We train transduction models for transforming the word-forms into analyses on the aligned sourcetarget pairs using a modified version of D I REC TL+ (Jiampojamarn et al., 2010). D IREC TL+ is a feature-rich, discriminative character transducer, which searches for a model-optimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation, also known as a semi-Markov model. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. D IREC TL+ uses a number of feature template"
E17-2034,P05-1012,0,0.108293,"ring transduction sequence. 2.2 Transduction We train transduction models for transforming the word-forms into analyses on the aligned sourcetarget pairs using a modified version of D I REC TL+ (Jiampojamarn et al., 2010). D IREC TL+ is a feature-rich, discriminative character transducer, which searches for a model-optimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation, also known as a semi-Markov model. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. D IREC TL+ uses a number of feature templates to assess the quality of a rule: source context, target n-gram, and joint n-gram features. Context features conjoin the rule with indicators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indicators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoined with our source"
E17-2034,D13-1032,0,0.0672395,"Missing"
E17-2034,D15-1272,0,0.038454,"Missing"
E17-2034,W15-1844,0,0.0627562,"Missing"
E17-2034,chrupala-etal-2008-learning,0,0.0935092,"Missing"
E17-2034,P09-1055,0,0.0361397,"present the word-forms of the languages that we consider in this paper. The only exception is the circumfix of the German past participle. 212 Source schreiben + 2PKA schreiben + 2PKE schreiben + 3SIA schrieben + 2PKE schreiben + 2PIA Target schriebet schreibet schrieb schriebet schriebt × X × × × 1 2 3 4 5 6 7 8 9 Table 3: Example source-target pairs of the inflector model. The check marks indicate which of the analyses of the German word-form schreibet satisfy the mirror constraint. Type binary real real binary binary binary binary binary binary Table 4: Features of the re-ranker. Following Toutanova and Cherry (2009), we modify the out-of-the-box version of D IREC TL+ by augmenting it with an abstract copy feature that indicates when a rule simply copies its source characters into the target, e.g. b → b. The copy feature has the effect of biasing the transducer towards preserving the source characters during transduction. In addition to training an analyzer model that transforms a word-form into an analysis, we also train an inflector model that converts an analysis back into a word-form. This opposite transformation corresponds to the task of morphological inflection (Cotterell et al., 2016). By deriving"
E17-2098,D13-1173,0,0.0134931,"me that the languages are sufficiently closely related to allow some translation pairs to be identified on the basis of orthographic similarity. Our setting is completely unsupervised: we extract the bilingual lexicons from non-parallel monolingual corpora representing the same domain. By contrast, most of the prior work depend on parallel data in the form of a small bitext (Genzel, 2005), a gold seed lexicon (Mikolov et al., 2013b), or document-aligned comparable corpora (Vuli´c and Moens, 2015). Other prior work assumes access to additional resources or features, such as dependency parsers (Dou and Knight, 2013; Dou et al., 2014), temporal and web-based features (Irvine and Callison-Burch, 2013), or BabelNet (Wang and Sitbon, 2014). Our approach consists of two stages: we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping 2 Methods In this section, we describe the two components of our approach: seed lexicon extraction, and lexicon expansion via bootstrapping. 2.1 Seed Lexicon Extraction Our seed extraction algorithm is aimed at identifying cross-lingual word pairs that exhibit high orthographic similarity, and have comparable frequency, both f"
E17-2098,D14-1061,0,0.0465802,"Missing"
E17-2098,H05-1110,0,0.0139885,"ctive of bilingual lexicon induction is to find translation pairs between two languages. Specifically, we aim to pair each word in the source vocabulary with its translation in the target vocabulary. In this paper, we assume that the languages are sufficiently closely related to allow some translation pairs to be identified on the basis of orthographic similarity. Our setting is completely unsupervised: we extract the bilingual lexicons from non-parallel monolingual corpora representing the same domain. By contrast, most of the prior work depend on parallel data in the form of a small bitext (Genzel, 2005), a gold seed lexicon (Mikolov et al., 2013b), or document-aligned comparable corpora (Vuli´c and Moens, 2015). Other prior work assumes access to additional resources or features, such as dependency parsers (Dou and Knight, 2013; Dou et al., 2014), temporal and web-based features (Irvine and Callison-Burch, 2013), or BabelNet (Wang and Sitbon, 2014). Our approach consists of two stages: we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping 2 Methods In this section, we describe the two components of our approach: seed lexicon extraction,"
E17-2098,P08-1088,0,0.287045,"fy a certain number of correct translation pairs. Adding the high-confidence pairs to the seed lexicon allows us to refine the cross-lingual transformation matrix. We proceed to iteratively expand our lexicon by alternating the two steps of translation pair identification, and transformation induction. We conduct a series of experiments on English, French, and Spanish. The results demonstrate a substantial error reduction with respect to a word-vector-based method of Mikolov et al. (2013b), when using the same word vectors on six source-target pairs. We also improve on the results reported by Haghighi et al. (2008) with both automatically-extracted and gold seed lexicons. The task of unsupervised lexicon induction is to find translation pairs across monolingual corpora. We develop a novel method that creates seed lexicons by identifying cognates in the vocabularies of related languages on the basis of their frequency and lexical similarity. We apply bidirectional bootstrapping to a method which learns a linear mapping between context-based vector spaces. Experimental results on three language pairs show consistent improvement over prior work. 1 Introduction The objective of bilingual lexicon induction i"
E17-2098,W13-2233,0,0.0249413,"lation pairs to be identified on the basis of orthographic similarity. Our setting is completely unsupervised: we extract the bilingual lexicons from non-parallel monolingual corpora representing the same domain. By contrast, most of the prior work depend on parallel data in the form of a small bitext (Genzel, 2005), a gold seed lexicon (Mikolov et al., 2013b), or document-aligned comparable corpora (Vuli´c and Moens, 2015). Other prior work assumes access to additional resources or features, such as dependency parsers (Dou and Knight, 2013; Dou et al., 2014), temporal and web-based features (Irvine and Callison-Burch, 2013), or BabelNet (Wang and Sitbon, 2014). Our approach consists of two stages: we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping 2 Methods In this section, we describe the two components of our approach: seed lexicon extraction, and lexicon expansion via bootstrapping. 2.1 Seed Lexicon Extraction Our seed extraction algorithm is aimed at identifying cross-lingual word pairs that exhibit high orthographic similarity, and have comparable frequency, both factors being indicators of translations (Kondrak, 2013). For each language, represente"
E17-2098,2005.mtsummit-papers.11,0,0.212768,"Missing"
E17-2098,J03-1002,0,0.029112,"Missing"
E17-2098,C94-1027,0,0.656183,"Missing"
E17-2098,tiedemann-2012-parallel,0,0.119449,"Missing"
E17-2098,P15-2118,0,0.141656,"Missing"
E17-2098,U14-1003,0,0.0299604,"rthographic similarity. Our setting is completely unsupervised: we extract the bilingual lexicons from non-parallel monolingual corpora representing the same domain. By contrast, most of the prior work depend on parallel data in the form of a small bitext (Genzel, 2005), a gold seed lexicon (Mikolov et al., 2013b), or document-aligned comparable corpora (Vuli´c and Moens, 2015). Other prior work assumes access to additional resources or features, such as dependency parsers (Dou and Knight, 2013; Dou et al., 2014), temporal and web-based features (Irvine and Callison-Burch, 2013), or BabelNet (Wang and Sitbon, 2014). Our approach consists of two stages: we first create a seed set of translation pairs, and then iteratively expand the lexicon with a bootstrapping 2 Methods In this section, we describe the two components of our approach: seed lexicon extraction, and lexicon expansion via bootstrapping. 2.1 Seed Lexicon Extraction Our seed extraction algorithm is aimed at identifying cross-lingual word pairs that exhibit high orthographic similarity, and have comparable frequency, both factors being indicators of translations (Kondrak, 2013). For each language, represented by a raw monolingual corpus, we fir"
H05-1120,W04-3238,0,0.383731,"bability of edit operations is learned from a corpus of pairs of misspelled words and corrections. 955 Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language c Processing (HLT/EMNLP), pages 955–962, Vancouver, October 2005. 2005 Association for Computational Linguistics Search query correction is an interesting branch of spelling correction. Due to the wide variety of search queries, dictionary based spelling correction is not adequate for correcting search terms. The concept of using query logs to aid in spelling correction is explored in (Brill and Cucerzan, 2004). It is noted that using traditional Levenshtein distance as an error model can lead to inappropriate corrections, so a weighted distance measure is used instead. This paper focuses on deriving a language model and probabilistic error model directly from search query logs without requiring a corpus of misspelled words paired with their corrections. The task of search query spelling correction is analyzed, and an implementation of the Expectation Maximization (EM) algorithm to learn an error model is described, with reference to similar approaches. In Section 2, the make-up of search queries is"
H05-1120,P00-1037,0,0.619412,"Missing"
H05-1120,C90-2036,0,0.83441,"st typos, but often misspelled words are off by more than one character. A method of quantifying string-to-string distance is introduced in (Wagner and Fischer, 1974), allowing the consideration of multiple edit operations when determining candidate corrections. Each edit operation is assigned a fixed cost. Edit operations, though, can be more accurately modelled by considering every possible insertion, deletion, and substitution operation individually instead of having a fixed cost for each operation. For example, the application of probabilistic models to spelling correction is explored in (Kernighan, Church, and Gale, 1990), in which a confusion matrix describes the probability of each letter being substituted for another. The Bayesian noisy channel model is used to determine the the error probabilities, with the simplifying assumption that each word has at most one spelling error. In (Ristad and Yianilos, 1997), a probabilistic model of edit distance is learned from pairs of misspelled words and their corrections. This extends Kernighan’s approach by allowing multiple edit operations rather than assuming a single edit. The probability of edit operations is learned from a corpus of pairs of misspelled words and"
H05-1120,P02-1019,0,0.339845,"Missing"
I11-1097,D07-1093,0,0.0155261,"Missing"
I11-1097,gimenez-marquez-2004-svmtool,0,0.0324917,"Missing"
I11-1097,P10-1105,0,0.223972,"Missing"
I11-1097,C04-1137,1,0.671929,"{bmhauer,gkondrak}@ualberta.ca Abstract world’s languages (Wichmann et al., 2011). However, only a fraction of such lists contain cognate information. Methods proposed for pairwise cognate identification are of limited utility for such data because they fail to consider the transitivity property of the cognation relationship. Cognate groups are also more useful than cognate pairs as the input to algorithms for reconstructing phylogenetic trees (Bouchard-Cˆot´e et al., 2007). A number of word similarity measures have been applied to the problem of cognate identification (Frunza et al., 2005). Kondrak and Dorr (2004) report that a simple average of various measures outperforms any individual measure of phonetic similarity. We propose to combine measures using a machine-learning approach based on support vector machines (SVMs). The SVMs are trained on both positive and negative examples, and allow for a seamless combination of a number of diverse similarity measures. In addition to word similarity features, we include a set of language-pair features that incorporate information regarding the degree of relatedness between languages. We develop a way to self-train these features in the absence of preexisting"
I11-1097,N03-2016,1,0.518124,"rs of languages. The output of the classification algorithm is then used to generate cognate groups. The results of the experiments on word lists representing several language families demonstrate the utility of the proposed approach. 1 Introduction Cognates are words with a shared linguistic origin, such as English father and French p`ere. Identification of cognates is essential in historical linguistics, and cognate information has been successfully applied to natural language processing tasks, such as sentence alignment in bitexts (Simard et al., 1993), and statistical machine translation (Kondrak et al., 2003). The problem of automatically identifying pairs of cognates has been addressed previously (Frunza and Inkpen, 2009; Kondrak, 2009). The process of identification is usually based on the combination of the following three types of evidence: phonetic similarity, semantic similarity, and recurrent sound correspondences. The input data include dictionaries, multilingual word lists, and bitexts. The objective can be finding pairs of cognates among two related languages, or finding groups of cognates among multiple languages. In this paper, we focus on the task of identifying cognate groups (cluste"
I11-1097,P07-3005,0,0.477405,"Missing"
K17-2008,P05-1012,0,0.154648,"r each language: a discriminative transduction system, an ensemble of neural encoder-decoder mod2.1 String transduction We perform string transduction with a modified version of D IREC TL+, a tool originally designed for grapheme-to-phoneme conversion.1 D IREC TL+ is a feature-rich, discriminative character string transducer that searches for a modeloptimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. From aligned source-target pairs, our version of D IREC TL+ extracts statistically-supported feature templates: source context, target n-gram, and joint 1 https://github.com/GarrettNicolai/DTL 79 Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection, pages 79–84, c Vancouver, Canada, August 3–4, 2017. 2017 Association for Computational Linguistics n-gram features. Context features conjoin the rule with in"
K17-2008,N15-1093,1,0.882714,"n SVM reranker. The results demonstrate that our transduction approach is strongly competitive in the low-resource setting. Further gains can be obtained via tag reordering heuristics and system combination. We describe our approach and experiments in the context of the CoNLLSIGMORPHON 2017 Shared Task on Universal Morphological Reinflection. We combine a discriminative transduction system with neural models. The results on five languages show that our approach works well in the low-resource setting. We also investigate adaptations designed to handle small training sets. 1 2 Methods We follow Nicolai et al. (2015, 2016) in approaching inflection generation as discriminative string transduction. After aligning source lemmas to target word forms, conversion operations are extracted and applied to transform a lemma-tag sequence into an inflected form. In this section, we describe several novel adaptations to the lowresource setting, as well as the system combination methods. Introduction In this paper, we describe our system as participants in the CoNLL-SIGMORPHON 2017 Shared Task on Universal Morphological Reinflection (Cotterell et al., 2017). Our focus is on the sub-task of inflection generation under"
K17-2008,W16-2005,1,0.600658,"set, and select the one that results in the highest accuracy on the development set. Training instances in the inflection generation task consist of a lemma and a tag sequence which specifies the inflection slot. Tag sequences consist of smaller units, which we refer to as subtags, that determine specific aspects of the inflection. For example, the tag sequence “V;PTCP;PST;FEM;SG” indicates that the target form is a verbal (V) feminine (FEM) singular (SG) past (PST) participle (PTCP). In the small training data scenario, it is not practical to treat tag sequences as atomic units, as we did in Nicolai et al. (2016), because many tag sequences may be represented by only a single training instance, or not at all. We follow Kann and Sch¨utze (2016) in separating each tag sequence into its component subtags, in order to share information across inflection slots. Our system treats each subtag as an indivisible atomic symbol. An example is shown in Figure 1. From the linguistic point of view, tag splitting may seem counter-intuitive, as composite inflectional affixes in fusional languages can rarely be separated into individual morphemes. However, on the character level, many affixes share letter substrings a"
K17-2008,E17-2034,1,0.880038,"Missing"
K17-2008,Q16-1006,1,0.793015,"d subtags that correspond to different parts of speech (e.g., V:SG vs. N:SG). 2.3 Tag splitting Subtag reordering Because our alignment and transduction systems are monotonic, tag splitting introduces the issue of subtag ordering. The provided data files are not always consistent in terms of the relative order in which subtags appear in sequence. We enforce the consistency by establishing a global ordering of all subtags in a given language. Our objective is to make as few changes as possible with respect to the original tag sequences. We achieve this by adapting the set ordering algorithm of Hauer and Kondrak (2016), which uses a beam search to minimize the number of subtag swaps within the tag sequences. We then reorder all tag sequences that are inconsistent with the resulting ordering. Our development experiments suggest that the consistent ordering never leads to a decrease in accuracy with respect to the original ordering. We also investigate ways of optimizing the subtag order. For example, it would make sense for the gender subtag to precede the number subtag in Spanish past participles (e.g., cortadas). Since the number of possible orderings is exponential, testing a separate transduction model f"
K17-2008,P08-1103,1,0.867487,"ovel adaptations to the lowresource setting, as well as the system combination methods. Introduction In this paper, we describe our system as participants in the CoNLL-SIGMORPHON 2017 Shared Task on Universal Morphological Reinflection (Cotterell et al., 2017). Our focus is on the sub-task of inflection generation under the lowresource scenario, in which the training data is limited to 100 labeled examples, with and without monolingual corpora. Our principal approach follows Nicolai et al. (2015), performing discriminative string transduction with a modified version of the D IREC TL+ program (Jiampojamarn et al., 2008). Taking into account the results of the SIGMORPHON 2016 Shared Task on Morphological Reinflection (Cotterell et al., 2016), we investigate ways to combine the strengths of D IREC TL+ with those of neural models. In addition, we experiment with various adaptations designed to handle small training sets, such as splitting and reordering morphological tags, and synthetic training data. We derive inflection models for five languages: English, German, Persian, Polish, and Spanish. These languages display varying degrees of inflectional complexity, but are mostly suffixing, fusional languages. We c"
K17-2008,N07-1047,1,0.783989,"ators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indicators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoined with our source context features. Joint n-grams build indicators on rule sequences, combining source and target context, and memorizing frequently-used rule patterns. We also add an abstract copy feature that corresponds to preserving the source characters unchanged. We perform source-target pair alignment with a modified version of the M2M aligner (Jiampojamarn et al., 2007). The program applies the Expectation-Maximization algorithm with the objective to maximize the conditional likelihood of its aligned source and target pairs. In order to encourage alignments between identical characters, we modify the aligner to generalize all identity transformations into a single match operation, which corresponds to the transduction copy feature. 2.2 desperdiciar + V;COND;3;SG = desperdiciaría desperdiciar + V + COND + 3 + SG = desperdiciaría Figure 1: Splitting a tag into subtags to mitigate data sparsity. lav+e+mos, where the three substrings correspond to the stem, the"
K18-3015,W18-2412,1,0.727525,"Missing"
K18-3015,K17-2002,0,0.167031,"Missing"
K18-3015,K17-2008,1,0.858914,"Missing"
K18-3015,W18-5805,1,0.841221,"transduction models trained on small amounts of source-target pairs. Many of the target forms are observed in raw text corpora. In addition, character-level language models derived from monolingual corpora can reduce the number of output forms that violate the phonotactic constraints of a language. Target language modelling is particularly important in low-data scenarios, where the limited transduction models often produce many ill-formed output candidates. In this section, we describe the sources of the text corpora, and two novel methods that attempt to leverage the additional information. Nicolai et al. (2018) present DTLM, a new system that combines discriminative transduction with character and word language models derived from large unannotated corpora. DTLM is an extension of D IREC TL+ (Section 2.3), whose target language modeling is limited to a set of binary ngram features, which are based exclusively on the target sequences from the parallel training data. DTLM avoids the error propagation problem that is inherent in pipeline approaches by incorporating the language-model features directly into the transducer. In addition, DTLM bolsters the quality of transduction by employing a novel align"
K18-3015,K18-3001,0,0.276525,"Missing"
K18-3015,P08-1103,1,0.878088,"Missing"
K18-3015,N07-1047,1,0.763852,"Missing"
K18-3015,L18-1293,0,0.035119,"The neural network is trained with each of these external words as both input and output. We pre-train AC-RNN with this copying procedure for 50 epochs. (Bergmanis et al. (2017) use a similar technique with randomly-generated sequences.) We then fine-tune the model on the actual low-resource dataset. This approach is helpful in a several different ways: it biases the network towards copying input characters in the output, guides the attention parameters towards learning a monotonic alignment, and improves the randomly The monolingual corpora come from one of two sources. The UniMorph project (Kirov et al., 2018) contains corpora for 46 out of 103 languages.7 For 42 languages that are not represented in Unimorph, we instead use the target side of the high-resource training data in this shared task. For the 15 remaining languages that lack either of these resources, we simply back off to the standard version of each system. Note that we use only the target-side forms of the high-resource training data (if applicable), so that there is no overlap between the training and testing sets. The principal use of the additional data is to 8 6 http://www.speech.cs.cmu.edu/SLM/toolkit.html DTLM was also succesful"
K18-3015,K17-2004,0,0.117236,"Missing"
K18-3015,P05-1012,0,0.362026,"Missing"
N01-1014,J95-4004,0,0.0161376,"Missing"
N01-1014,P93-1001,0,0.0584225,"more loosely, denoting words in different languages that are similar in form and meaning, without making a distinction between borrowed and genetically related words; for example, English sprint and the Japanese borrowing supurinto are considered cognate, even though these two languages are unrelated. In historical linguistics, the identification of cognates is a component of two principal tasks of the field: establishing the relatedness of languages and reconstructing the histories of language families. In corpus linguistics, cognates have been used for bitext alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), and for extracting lexicographically interesting wordpairs from multilingual corpora (Brew and McKelvie, 1996). The task addressed in this paper can be formulated in two ways. On the word level, given two words (lexemes) from different languages, the goal is to compute a value that reflects the likelihood of the pair being cognate. I assume that each lexeme is given in a phonetic notation, and that it is accompanied by one or more glosses that specify its meaning in a metalanguage for which a lexical resource is available (for example, English). On th"
N01-1014,A00-2038,1,0.852266,"verified during the evaluation of my system (Section 6). However, in the case of very remotely related languages, the difference may no longer be statistically significant (Ringe, 1998). 3 Phonetic similarity DICE x  y  2  bigrams x bigrams y   bigrams x  bigrams y where bigrams(x) is a multi-set of character bigrams in x. Church (1993) uses 4-grams at the level of character sequences. Melamed (1999) uses the Longest Common Subsequence Ratio (LCSR) defined as LCSR x  y  LCS x  y max  x    y  where LCS(x,y) is the longest common subsequence of x and y. ALINE (Kondrak, 2000), is an example of the “phonetic” approach. ALINE was originally developed for aligning phonetic sequences, but since it chooses the optimal alignment on the basis of a similarity score, it can also be used for computing similarity. Each phoneme is represented as a vector of phonetically-based feature values. The number of distinct values for each feature is not constrained.2 The features have salience coefficients that express their relative importance. ALINE uses dynamic programming to compute similarity scores. Because it uses similarity rather than distance, the score assigned to two ident"
N01-1014,J94-3004,0,0.732414,"ed. The algorithm has no semantic component, as the words are assumed to have already been matched by their meanings. Such an approach by definition cannot detect cognates that have undergone a semantic shift. Hewson (1974; 1993) employed a simple strategy of generating proto-projections to produce a dictionary of over 4000 Proto-Algonquian etyma from vocabularies of several contemporary Algonquian languages. The proto-projections, generated using long-established systematic sound correspondences, were then examined individually in order to select true cognates. The “Reconstruction Engine” of Lowe and Mazaudon (1994) uses a similar strategy of generating proto-projections to establish cognate sets. Both 1 The assumption was verified during the evaluation of my system (Section 6). However, in the case of very remotely related languages, the difference may no longer be statistically significant (Ringe, 1998). 3 Phonetic similarity DICE x  y  2  bigrams x bigrams y   bigrams x  bigrams y where bigrams(x) is a multi-set of character bigrams in x. Church (1993) uses 4-grams at the level of character sequences. Melamed (1999) uses the Longest Common Subsequence Ratio (LCSR) defined as LCSR x"
N01-1014,J99-1003,0,0.256016,"nt languages that are similar in form and meaning, without making a distinction between borrowed and genetically related words; for example, English sprint and the Japanese borrowing supurinto are considered cognate, even though these two languages are unrelated. In historical linguistics, the identification of cognates is a component of two principal tasks of the field: establishing the relatedness of languages and reconstructing the histories of language families. In corpus linguistics, cognates have been used for bitext alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), and for extracting lexicographically interesting wordpairs from multilingual corpora (Brew and McKelvie, 1996). The task addressed in this paper can be formulated in two ways. On the word level, given two words (lexemes) from different languages, the goal is to compute a value that reflects the likelihood of the pair being cognate. I assume that each lexeme is given in a phonetic notation, and that it is accompanied by one or more glosses that specify its meaning in a metalanguage for which a lexical resource is available (for example, English). On the language level, given two vocabulary li"
N01-1014,W97-1102,0,0.0125279,"¯ıwin ‘fear, alarm’ in Tables 1 and 2 are correctly associated by this method. However, in many cases, the similarity of semantically related glosses is not recognized. The most common reasons are listed below. 1. Spelling errors or variants: ‘vermilion’ and ‘vermillion’, ‘sweet grass’ and ‘sweetgrass’, ‘plow’ and ‘plough’; 2. Morphological differences: ‘ash’ and ‘ashes’; 3. Determiners: ‘a mark’ and ‘mark’, ‘my finger’ and ‘finger’, ‘fish’ and ‘kind of fish’; 4. Adjectival modifiers: ‘small stone’ and ‘stone’; 2 For a different “phonetic” approach, based on binary articulatory features, see (Nerbonne and Heeringa, 1997). 5. Nominal modifiers: ‘goose’ and ‘snow goose’; 6. Complements and adjuncts: ‘stone’ and ‘stone of peach’, ‘island’ and ‘island in a river’; 7. Synonymy: ‘grave’ and ‘tomb’; 8. Small semantic changes: ‘fowl’ and ‘turkey’; 9. Radical semantic changes: ‘grease’. ‘broth’ and Spelling errors, which may be especially frequent in data that have been acquired through optical character recognition, are easy to detect but have to be corrected manually. Morphological differences (category 2) can be removed by lemmatization. Many of the cases belonging to categories 3 and 4 can be handled by adopting a"
N01-1014,1992.tmi-1.7,0,0.741856,"e term is often used more loosely, denoting words in different languages that are similar in form and meaning, without making a distinction between borrowed and genetically related words; for example, English sprint and the Japanese borrowing supurinto are considered cognate, even though these two languages are unrelated. In historical linguistics, the identification of cognates is a component of two principal tasks of the field: establishing the relatedness of languages and reconstructing the histories of language families. In corpus linguistics, cognates have been used for bitext alignment (Simard et al., 1992; Church, 1993; McEnery and Oakes, 1996; Melamed, 1999), and for extracting lexicographically interesting wordpairs from multilingual corpora (Brew and McKelvie, 1996). The task addressed in this paper can be formulated in two ways. On the word level, given two words (lexemes) from different languages, the goal is to compute a value that reflects the likelihood of the pair being cognate. I assume that each lexeme is given in a phonetic notation, and that it is accompanied by one or more glosses that specify its meaning in a metalanguage for which a lexical resource is available (for example, E"
N03-2016,P01-1030,1,0.457519,"s split into words, and all possible word pairings are stored in a file. Numbers and punctuation are not considered, since we feel that they warrant a more specific approach. After sorting and removing duplicates, the file represents all possible one-to-one word alignments of the bitext. Also removed are the pairs that include English 3 Experiments We induced translation models using IBM Model 4 (Brown et al., 1990) with the GIZA toolkit (Al-Onaizan et al., 1999). The maximum sentence length in the training data was set at 30 words. The actual translations were produced with a greedy decoder (Germann et al., 2001). For the evaluation of translation quality, we used the BLEU metric (Papineni et al., 2002), which measures the n-gram overlap between the translated output and one or more reference translations. In our experiments, we used only one reference translation. 3.1 Word alignment quality In order to directly measure the influence of the added cognate information on the word alignment quality, we performed a single experiment using a set of 500 manually aligned sentences from Hansards (Och and Ney, 2000). Giza was first trained on 50,000 sentences from Hansards, and then on the same training set au"
N03-2016,N01-1020,0,0.323315,"uage to another (e.g. English sprint and Japanese supurinto). In a broad sense, cognates include not only genetically related words and borrowings but also names, numbers, and punctuation. Practically all bitexts (bilingual parallel corpora) contain some kind of cognates. If the languages are represented in different scripts, a phonetic transcription or transliteration of one or both parts of the bitext is a pre-requisite for identifying cognates. Cognates have been employed for a number of bitextrelated tasks, including sentence alignment (Simard et al., 1992), inducing translation lexicons (Mann and Yarowsky, 2001), and improving statistical machine translation models (Al-Onaizan et al., 1999). Cognates are particularly useful when machine-readable bilingual dictionaries are not available. Al-Onaizan et al. (1999) experimented with using bilingual dictionaries and cognates in the training of Czech–English translation models. They found that appending probable cognates to the training bitext significantly lowered the perplexity score on the test bitext (in some cases more than when using a bilingual dictionary), and observed improvement in word alignments of test sentences. In this paper, we investigate"
N03-2016,P00-1056,0,0.17161,"Missing"
N03-2016,P02-1040,0,0.0821725,"ation are not considered, since we feel that they warrant a more specific approach. After sorting and removing duplicates, the file represents all possible one-to-one word alignments of the bitext. Also removed are the pairs that include English 3 Experiments We induced translation models using IBM Model 4 (Brown et al., 1990) with the GIZA toolkit (Al-Onaizan et al., 1999). The maximum sentence length in the training data was set at 30 words. The actual translations were produced with a greedy decoder (Germann et al., 2001). For the evaluation of translation quality, we used the BLEU metric (Papineni et al., 2002), which measures the n-gram overlap between the translated output and one or more reference translations. In our experiments, we used only one reference translation. 3.1 Word alignment quality In order to directly measure the influence of the added cognate information on the word alignment quality, we performed a single experiment using a set of 500 manually aligned sentences from Hansards (Och and Ney, 2000). Giza was first trained on 50,000 sentences from Hansards, and then on the same training set augmented with a set of cognates. The set consisted of two copies of a list produced by applyi"
N03-2016,1992.tmi-1.7,0,0.578863,"sh night and German nacht) or borrowing from one language to another (e.g. English sprint and Japanese supurinto). In a broad sense, cognates include not only genetically related words and borrowings but also names, numbers, and punctuation. Practically all bitexts (bilingual parallel corpora) contain some kind of cognates. If the languages are represented in different scripts, a phonetic transcription or transliteration of one or both parts of the bitext is a pre-requisite for identifying cognates. Cognates have been employed for a number of bitextrelated tasks, including sentence alignment (Simard et al., 1992), inducing translation lexicons (Mann and Yarowsky, 2001), and improving statistical machine translation models (Al-Onaizan et al., 1999). Cognates are particularly useful when machine-readable bilingual dictionaries are not available. Al-Onaizan et al. (1999) experimented with using bilingual dictionaries and cognates in the training of Czech–English translation models. They found that appending probable cognates to the training bitext significantly lowered the perplexity score on the test bitext (in some cases more than when using a bilingual dictionary), and observed improvement in word ali"
N03-2016,J93-2003,0,\N,Missing
N07-1047,J00-2003,0,0.0278611,"any alignments. A letter chunking bigram prediction manages double letters and double phonemes automatically as opposed to preprocessing with fixed lists. We also apply an HMM method in conjunction with a local classification model to predict a global phoneme sequence given a word. The many-to-many alignments result in significant improvements over the traditional one-to-one approach. Our system achieves state-of-the-art performance on several languages and data sets. 1 Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including pronunciation by analogy (Marchand and Damper, 2000), constraint satisfaction (Van Den Bosch and Canisius, 2006), Hidden Markov Model (Taylor, 2005), decision trees (Black et al., 1998), and neural networks (Sejnowski and Rosenberg, 1987). The training data usually consists of written words and their corresponding phonemes, which are not aligned; there is no explicit information indicating individual letter and phoneme relationships. These relationships must be postulated before a prediction model can be trained. Introduction Letter-to-phoneme (L2P) conversion requires a system to produce phonemes that correspond to a given written word. Phonem"
N07-1047,W06-3206,0,0.109454,"Missing"
N07-1047,W02-1001,0,\N,Missing
N07-1047,P02-1019,0,\N,Missing
N07-2008,P02-1033,0,0.0256362,"inappropriate for testing parallel document identification systems in general. 1 Introduction Parallel documents are documents that are mutual translations. There are a number of reasons one might want to either identify parallel documents, or confirm that a pair of documents are in fact parallel. Most prominently, one could use pairs of automatically detected parallel documents to build parallel corpora. Parallel corpora have many uses in natural language processing, and their dearth has been identified as a major bottleneck (Diab, 2004). They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al., 2002), and inducing statistical machine translation models (Koehn et al., 2003). In addition to building parallel corpora, one can envision other uses for parallel document identification, such as cross-language information retrieval (Chen and Nie, 2000). Much work on identifying pairs of parallel documents focuses on the use of external features of the documents, rather than content. Chen and Nie (2000) describe PTMiner, a cross-language information retrieval system. They consider a number of factors in determining if a pair o"
N07-2008,P04-1039,0,0.0158565,"his paper furnishes evidence that parliamentary proceedings may be inappropriate for testing parallel document identification systems in general. 1 Introduction Parallel documents are documents that are mutual translations. There are a number of reasons one might want to either identify parallel documents, or confirm that a pair of documents are in fact parallel. Most prominently, one could use pairs of automatically detected parallel documents to build parallel corpora. Parallel corpora have many uses in natural language processing, and their dearth has been identified as a major bottleneck (Diab, 2004). They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al., 2002), and inducing statistical machine translation models (Koehn et al., 2003). In addition to building parallel corpora, one can envision other uses for parallel document identification, such as cross-language information retrieval (Chen and Nie, 2000). Much work on identifying pairs of parallel documents focuses on the use of external features of the documents, rather than content. Chen and Nie (2000) describe PTMiner, a cross-language information"
N07-2008,N03-1017,0,0.00254301,"ations. There are a number of reasons one might want to either identify parallel documents, or confirm that a pair of documents are in fact parallel. Most prominently, one could use pairs of automatically detected parallel documents to build parallel corpora. Parallel corpora have many uses in natural language processing, and their dearth has been identified as a major bottleneck (Diab, 2004). They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al., 2002), and inducing statistical machine translation models (Koehn et al., 2003). In addition to building parallel corpora, one can envision other uses for parallel document identification, such as cross-language information retrieval (Chen and Nie, 2000). Much work on identifying pairs of parallel documents focuses on the use of external features of the documents, rather than content. Chen and Nie (2000) describe PTMiner, a cross-language information retrieval system. They consider a number of factors in determining if a pair of documents are parallel, including document size, date, URL, and language flag. For example, if a document is available in both French and Englis"
N07-2008,J03-3002,0,0.115213,"cument’s URL to contain .f r and the English to contain .en In addition to these measures, they consider website structure. McEwan et al. (2002) find parallel documents which they then use to automatically build a bilingual dictionary. In their system, they first generate a set of candidate pairs based on manual selection, or advanced search engine use. They then filter the pairs to remove non-parallel pairs. First, they confirm that one of each pair is in each of the desired languages using tuned lists of stop-words, then they compare the documents based on length in tokens, and HTML markup. Resnik and Smith (2003) use a similar idea of candidates and filters in their STRAND system. STRAND filters the documents based on aligning them by length in tokens and location of HTML markup in the documents. Apart form the work done on external metrics, Patry and Langlais (2005) investigated a number of content-based metrics. They consider several docu29 Proceedings of NAACL HLT 2007, Companion Volume, pages 29–32, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics ment features, including the numbers, proper names and punctuation contained within, as well as document length, and alignmen"
N09-1035,P08-1065,1,0.750599,"Missing"
N09-1035,W05-0615,0,0.0660334,"based methods. M¨uller (2001) presents a hybrid of a categorical and data-driven approach. First, she manually constructs a context-free grammar of possible syllables. This grammar is then made probabilistic using counts obtained from training data. M¨uller (2006) attempts to make her method language-independent. Rather than hand-crafting her context-free grammar, she automatically generates all possible onsets, nuclei, and codas, based on the phonemes existing in the language. The results are somewhat lower than in (M¨uller, 2001), but the approach can be more easily ported across languages. Goldwater and Johnson (2005) also explore using EM to learn the structure of English and German phonemes in an unsupervised setting, following M¨uller in modeling syllable structure with PCFGs. They initialize their parameters using a deterministic 310 parser implementing the sonority principle and estimate the parameters for their maximum likelihood approach using EM. Marchand et al. (2007) apply their Syllabification by Analogy (SbA) technique, originally developed for orthographic forms, to the pronunciation domain. For each input word, SbA finds the most similar substrings in a lexicon of syllabified phoneme strings"
N09-1035,P00-1029,0,0.0648972,"Missing"
N09-1035,P01-1053,0,0.0592242,"Missing"
N09-1035,W02-0608,0,0.0416667,"Missing"
N09-1035,W06-3202,0,0.0247676,"Missing"
N09-3008,W02-1022,0,0.02399,"related task of matching words to established cognate sets, useful for a situation where it is not immediately obvious to which cognate set a word should be matched. The accuracy on the latter task exceeds the accuracy of a method based on edit distance. Profile HMMs could also potentially be used for the computation of word similarity when a word must be compared not to another word but to another set of words, taking into account properties of all constituent words. The use of Profile HMMs for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries (Barzilay and Lee, 2002) and sentence-level paraphrasing (Barzilay and Lee, 2003). This paper is organized as follows: we first describe the uses of Profile HMMs in computational biology, their structure, and then discuss their applications to word-related tasks. We then discuss our data set and describe the tasks that we test and their experimental setups and results. We conclude with a summary of the results and a brief discussion of potential future work. 2 Profile hidden Markov models In computational biology, it is often necessary to deal with multiple sequences, including DNA and protein sequences. For such bio"
N09-3008,N03-1003,0,0.0411844,"s, useful for a situation where it is not immediately obvious to which cognate set a word should be matched. The accuracy on the latter task exceeds the accuracy of a method based on edit distance. Profile HMMs could also potentially be used for the computation of word similarity when a word must be compared not to another word but to another set of words, taking into account properties of all constituent words. The use of Profile HMMs for multiple sequence alignment also presents applications to the acquisition of mapping dictionaries (Barzilay and Lee, 2002) and sentence-level paraphrasing (Barzilay and Lee, 2003). This paper is organized as follows: we first describe the uses of Profile HMMs in computational biology, their structure, and then discuss their applications to word-related tasks. We then discuss our data set and describe the tasks that we test and their experimental setups and results. We conclude with a summary of the results and a brief discussion of potential future work. 2 Profile hidden Markov models In computational biology, it is often necessary to deal with multiple sequences, including DNA and protein sequences. For such biological sequence analysis, Profile HMMs are applied to th"
N09-3008,J96-4002,0,0.10351,"els used in biological sequence analysis. We propose the use of Profile HMMs for word-related tasks. We test their applicability to the tasks of multiple cognate alignment and cognate set matching, and find that they work well in general for both tasks. On the latter task, the Profile HMM method outperforms average and minimum edit distance. Given the success for these two tasks, we further discuss the potential applications of Profile HMMs to any task where consideration of a set of words is necessary. 1 Introduction In linguistics, it is often necessary to align words or phonetic sequences. Covington (1996) uses alignments of cognate pairs for the historical linguistics task of comparative reconstruction and Nerbonne and Heeringa (1997) use alignments to compute relative distances between words from various Dutch dialects. Algorithms for aligning pairs of words have been proposed by Covington (1996) and Kondrak (2000). However, it is often necessary to align multiple words. Covington (1998) proposed a method to align multiple words based on a handcrafted scale of similarity between various classes of phonemes, again for the purpose of comparative reconstruction of languages. Profile hidden Marko"
N09-3008,P98-1043,0,0.753623,"er discuss the potential applications of Profile HMMs to any task where consideration of a set of words is necessary. 1 Introduction In linguistics, it is often necessary to align words or phonetic sequences. Covington (1996) uses alignments of cognate pairs for the historical linguistics task of comparative reconstruction and Nerbonne and Heeringa (1997) use alignments to compute relative distances between words from various Dutch dialects. Algorithms for aligning pairs of words have been proposed by Covington (1996) and Kondrak (2000). However, it is often necessary to align multiple words. Covington (1998) proposed a method to align multiple words based on a handcrafted scale of similarity between various classes of phonemes, again for the purpose of comparative reconstruction of languages. Profile hidden Markov models (Profile HMMs) are specific types of hidden Markov models used in biological sequence analysis, where they have yielded success for the matching of given sequences to sequence families as well as to multiple sequence 43 alignment (Durbin et al., 1998). In this paper, we show that Profile HMMs can be adapted to the task of aligning multiple words. We apply them to sets of multilin"
N09-3008,A00-2038,1,0.872365,"d minimum edit distance. Given the success for these two tasks, we further discuss the potential applications of Profile HMMs to any task where consideration of a set of words is necessary. 1 Introduction In linguistics, it is often necessary to align words or phonetic sequences. Covington (1996) uses alignments of cognate pairs for the historical linguistics task of comparative reconstruction and Nerbonne and Heeringa (1997) use alignments to compute relative distances between words from various Dutch dialects. Algorithms for aligning pairs of words have been proposed by Covington (1996) and Kondrak (2000). However, it is often necessary to align multiple words. Covington (1998) proposed a method to align multiple words based on a handcrafted scale of similarity between various classes of phonemes, again for the purpose of comparative reconstruction of languages. Profile hidden Markov models (Profile HMMs) are specific types of hidden Markov models used in biological sequence analysis, where they have yielded success for the matching of given sequences to sequence families as well as to multiple sequence 43 alignment (Durbin et al., 1998). In this paper, we show that Profile HMMs can be adapted"
N09-3008,W05-0606,1,0.909187,"it can be used to evaluate a given sequence for membership in the family. This is done via a straightforward application of the forward algorithm (to get the full probability of the given sequence) or the Viterbi algorithm (to get the alignment of the sequence to the family). For the alignment of multiple unaligned sequences, a Profile HMM is constructed and trained as described above and then each sequence can be aligned using the Viterbi algorithm. It should also be noted that Profile HMMs are generalizations of Pair HMMs, which have been used for cognate identification and word similarity (Mackay and Kondrak, 2005) between pairs of words. Unlike Pair HMMs, Profile HMMs are position-specific; this is what allows their application to multiple sequences but also means that each Profile HMM must be trained to a given set of sequences, whereas Pair HMMs can be trained over a very large data set of pairs of words. 3 potential applications to similar tasks for cognate sets. We apply Profile HMMs to the multiple alignment of cognate sets, which is done in the same manner as multiple sequence alignment for biological sequences described above. We also test Profile HMMs for determining the correct cognate set to"
N09-3008,W97-1102,0,0.251684,"cability to the tasks of multiple cognate alignment and cognate set matching, and find that they work well in general for both tasks. On the latter task, the Profile HMM method outperforms average and minimum edit distance. Given the success for these two tasks, we further discuss the potential applications of Profile HMMs to any task where consideration of a set of words is necessary. 1 Introduction In linguistics, it is often necessary to align words or phonetic sequences. Covington (1996) uses alignments of cognate pairs for the historical linguistics task of comparative reconstruction and Nerbonne and Heeringa (1997) use alignments to compute relative distances between words from various Dutch dialects. Algorithms for aligning pairs of words have been proposed by Covington (1996) and Kondrak (2000). However, it is often necessary to align multiple words. Covington (1998) proposed a method to align multiple words based on a handcrafted scale of similarity between various classes of phonemes, again for the purpose of comparative reconstruction of languages. Profile hidden Markov models (Profile HMMs) are specific types of hidden Markov models used in biological sequence analysis, where they have yielded suc"
N09-3008,C98-1043,0,\N,Missing
N10-1102,H05-1055,0,0.0712087,"Missing"
N10-1102,W09-3504,1,0.874876,"Missing"
N10-1102,P07-1016,0,0.0356623,"Missing"
N10-1102,W09-3501,0,\N,Missing
N10-1103,P07-1013,0,0.0271278,"oviding their respective models with different information. To combine the strengths of these two systems, we include joint n-gram features inside a state-of-the-art discriminative sequence model. We evaluate our approach on several letter-to-phoneme and transliteration data sets. Our results indicate an improvement in overall performance with respect to both the joint n-gram approach and traditional feature sets for discriminative models. 1 ‡ Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use only source or target information, nor can they consider arbitrary sequences within their context window, as they are limited by th"
N10-1103,W09-3505,0,0.0423609,"ve models with different information. To combine the strengths of these two systems, we include joint n-gram features inside a state-of-the-art discriminative sequence model. We evaluate our approach on several letter-to-phoneme and transliteration data sets. Our results indicate an improvement in overall performance with respect to both the joint n-gram approach and traditional feature sets for discriminative models. 1 ‡ Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use only source or target information, nor can they consider arbitrary sequences within their context window, as they are limited by their back-off schedule. Intr"
N10-1103,N07-1047,1,0.360301,"ever, since sounds are often represented by multicharacter units, the relationship between the input and output characters is often complex. This prevents the straightforward application of standard tagging techniques, but can be addressed by substring decoders or semi-Markov models. Because the relationship between x and y is hidden, alignments between the input and output characters (or substrings) are often provided in a preprocessing step. These are usually generated in an unsupervised fashion using a variant of the EM algorithm. Our system employs the many-to-many alignment described in (Jiampojamarn et al., 2007). We trained our system on these aligned examples by using the online discriminative training of (Jiampojamarn et al., 2009). At each step, the parameter update is provided by MIRA. 3 Features Jiampojamarn et al. (2009) describe a set of indicator feature templates that include (1) context features (2) transition features and (3) linear-chain features. 698 transition linear-chain xi−c yi ... xi+c yi xi−c xi−c+1 yi ... xi+c−1 xi+c yi ...... xi−c . . . xi+c yi yi−1 yi xi−c yi−1 yi ... xi+c yi−1 yi xi−c xi−c+1 yi−1 yi ... xi+c−1 xi+c yi−1 yi ...... xi−c . . . xi+c , yi−1 yi xi+1−n yi+1−n xi yi .."
N10-1103,P08-1103,1,0.889131,"e begin with a Hidden Markov Model architecture, augmented with substring operations and discriminative training. The primary strength of these systems is their ability to include rich indicator features representing long sequences of source context. We will assume a specific instance of discriminative sequence modeling, D I REC TL (Jiampojamarn et al., 2009), which achieved the best results on several language pairs in the NEWS Machine Transliteration Shared Task (Li et al., 2009). The same system matches or exceeds the performance of the joint n-gram approach on letterto-phoneme conversion (Jiampojamarn et al., 2008). Its features are optimized by an online, margin697 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697–700, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics based learning algorithm, specifically, the Margin Infused Relaxed Algorithm, MIRA (Crammer and Singer, 2003). In this paper, we propose an approach that combines these two different paradigms by formulating the joint n-gram model as a new set of features in the discriminative model. This leverages an advantage of discriminative training, in that"
N10-1103,W09-3504,1,0.929033,"pronunciation of orthography complicate conversion. Transliteration suffers from the same ambiguities, but the transformation is further complicated Discriminative sequence models have also been shown to perform extremely well on string transduction problems. These begin with a Hidden Markov Model architecture, augmented with substring operations and discriminative training. The primary strength of these systems is their ability to include rich indicator features representing long sequences of source context. We will assume a specific instance of discriminative sequence modeling, D I REC TL (Jiampojamarn et al., 2009), which achieved the best results on several language pairs in the NEWS Machine Transliteration Shared Task (Li et al., 2009). The same system matches or exceeds the performance of the joint n-gram approach on letterto-phoneme conversion (Jiampojamarn et al., 2008). Its features are optimized by an online, margin697 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697–700, c Los Angeles, California, June 2010. 2010 Association for Computational Linguistics based learning algorithm, specifically, the Margin Infused Relaxed Algorithm, MIRA ("
N10-1103,P04-1021,0,0.251494,"ifferent ways, providing their respective models with different information. To combine the strengths of these two systems, we include joint n-gram features inside a state-of-the-art discriminative sequence model. We evaluate our approach on several letter-to-phoneme and transliteration data sets. Our results indicate an improvement in overall performance with respect to both the joint n-gram approach and traditional feature sets for discriminative models. 1 ‡ Joint n-gram models (Bisani and Ney, 2002; Chen, 2003; Bisani and Ney, 2008) have been widely applied to string transduction problems (Li et al., 2004; Demberg et al., 2007; Jansche and Sproat, 2009). The power of the approach lies in building a language model over the operations used in the conversion from source to target. Crucially, this allows the inclusion of source context in the generative story. Smoothing techniques play an important role in joint n-gram models, greatly affecting their performance. Although joint n-gram models are capable of capturing context information in both source and target, they cannot selectively use only source or target information, nor can they consider arbitrary sequences within their context window, as"
N10-1103,W09-3501,0,\N,Missing
N12-1044,W02-0505,0,0.259213,"gins, but the pronunciation depends on its degree of assimilation to English phonology. This type of information is often difficult to determine even for humans, and we posit that it may be inferred from other transliterations. Similarly, phonetic transcriptions more directly encode the pronunciation and thus present an important resource for exploitation. In fact, some transliteration systems use a phonetic transcription as an intermediate representation (Knight and Graehl, 1998), although these methods do not generally fare as well as those that perform the transliteration process directly (Al-Onaizan and Knight, 2002; Li et al., 2009). Transcriptions are often available; larger pronunciation dictionaries contain tens of thousands of entries, including some proper names (for which machine transliteration is most relevant), and many names in Wikipedia are accompanied by an IPA transcription. Our first experiment aims at improving the transliteration accuracy from English to Japanese Katakana. The English-Japanese corpus has one of the largest overlaps (number of entries with a common input) 3 A stub article is a skeleton article with little content. BASE R ERANKED O RACLE S EQUITUR D IREC TL+ S EQUITUR D IR"
N12-1044,P11-1041,1,0.901507,"umita (2010) developed an MTL approach that combined the output input word Sudan n-best outputs base system sud@n sud{n ⁞ sud#n re-ranked n-best list re-ranker sudAn S UW D AE N スーダン सूडान Судан ⁞ supplemental representations sud#n sUd#n ⁞ sud@n Figure 2: An overview of our approach on an example from the G2P task. The correct output is shown in bold. of two systems using a linear combination of system scores and a manually-tuned weight. 3.1 Task definition On the G2P side, Loots and Niesler (2009) investigate the problem of leveraging transcriptions from a different dialect of English, while Bhargava and Kondrak (2011) focus on leveraging transliterations from multiple writing scripts. Bhargava et al. (2011) show that the reranking method proposed by Bhargava and Kondrak (2011) can increase the accuracy of MTL as well. In this paper, we aim to confirm the generality of the same method by testing it on a broad range of tasks: a) leveraging transcriptions for both G2P and MTL; b) utilizing supplemental transcriptions and transliterations simultaneously; c) improving G2P in general, rather than just G2P of names; and d) combining different transduction systems. The task is to convert an input string s into a t"
N12-1044,W11-3206,1,0.798148,"base system sud@n sud{n ⁞ sud#n re-ranked n-best list re-ranker sudAn S UW D AE N スーダン सूडान Судан ⁞ supplemental representations sud#n sUd#n ⁞ sud@n Figure 2: An overview of our approach on an example from the G2P task. The correct output is shown in bold. of two systems using a linear combination of system scores and a manually-tuned weight. 3.1 Task definition On the G2P side, Loots and Niesler (2009) investigate the problem of leveraging transcriptions from a different dialect of English, while Bhargava and Kondrak (2011) focus on leveraging transliterations from multiple writing scripts. Bhargava et al. (2011) show that the reranking method proposed by Bhargava and Kondrak (2011) can increase the accuracy of MTL as well. In this paper, we aim to confirm the generality of the same method by testing it on a broad range of tasks: a) leveraging transcriptions for both G2P and MTL; b) utilizing supplemental transcriptions and transliterations simultaneously; c) improving G2P in general, rather than just G2P of names; and d) combining different transduction systems. The task is to convert an input string s into a target string t, where both strings are representations of a word w. In G2P, s is a string o"
N12-1044,P07-1092,0,0.0282563,"nd Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relatively small drop in accuracy. Zhang et al. (2010) and Kumaran et al. (2010a) report that combinations of pivot systems A → C → B with direct systems A → B produce better results than using the direct systems only. The models, which are composed"
N12-1044,W10-2406,0,0.238942,"sented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot languag"
N12-1044,N07-1047,1,0.771767,"for each candidate output in the n-best list, as well as each pairing of a candidate output with a supplemental representation. The features used for reranking may or may not overlap with the features used by the base system. While we focus on the G2P and MTL tasks in this paper, this method is general enough as to potentially be applied to other sequence prediction tasks. 3.3 Alignment In order to construct the feature vectors, we need the alignments between the alternative representations of the same word. For the alignment of supplemental data with candidate outputs, we apply M2MA LIGNER (Jiampojamarn et al., 2007). We use the same method for the alignment between the input and the candidate outputs, unless the base system already provides this information. M2M-A LIGNER is a generalization of the learned edit distance algorithm of Ristad and Yianilos (1998). It iteratively refines the alignment of a set of string pairs in an unsupervised manner using the expectation-maximization (EM) approach. In addition to the alignment, M2M-A LIGNER produces an alignment probability, which reflects the similarity between two strings. Intuitively, if two strings contain symbols or n-grams that often co-occur in the tr"
N12-1044,P08-1103,1,0.908782,"g languages with highly transparent orthographies, the number of letter-to-sound rules appears to grow geometrically with the lexicon size, with no asymptotic limit 397 (Kominek and Black, 2006). A number of machine learning approaches have been proposed for G2P, including neural networks (Sejnowski and Rosenberg, 1987), instance-based learning (van den Bosch and Daelemans, 1998), pronunciation by analogy (Marchand and Damper, 2000), decision trees (Kienappel and Kneser, 2001), hidden Markov models (Taylor, 2005), joint n-gram models (Bisani and Ney, 2008), and online discriminative learning (Jiampojamarn et al., 2008). The current state-of-the-art is represented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems,"
N12-1044,W09-3504,1,0.897953,"on examining other potential supplemental resources. Given the success of our approach in the face of sometimes-noisy transliteration data7 , other noisy data may be applicable as well. For example, IPA transcriptions could be mined from Wikipedia despite the fact that different transcriptions may have been written by different people. Similarly, difficult-to-pronounce names or words are often accompanied by ad hoc approximately-phonetic re-spellings, which may also prove useful. 6 Conclusion In this paper, we examined the relevance of alternative, supplemental representations for the tasks 7 Jiampojamarn et al. (2009) found a significant increase in English-to-Hindi transliteration performance after applying a simple rule-based cleaning script. 404 of grapheme-to-phoneme conversion and machine transliteration, both of which have pronunciation as an important underlying influence. We applied an SVM reranking approach that leverages the supplemental data using features constructed from ngrams as well as from similarity and system scores. The approach yielded excellent improvements when used with both the S EQUITUR and D IREC TL+ base systems. Over the state-of-the-art D IREC TL+, we achieved significant erro"
N12-1044,N10-1103,1,0.937928,"approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relativel"
N12-1044,W10-2405,1,0.951121,"approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relativel"
N12-1044,N10-1065,0,0.0618032,"data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relatively small drop in accuracy. Zhang et al. (2010) and Kumaran et al. (2010a) report that combinations of pivot systems A → C → B with direct systems A → B produce better results than using the direct systems only. The models, which are composed using a linear combination of scores, utilize a single pivot language C, and require training data between all three languages A, B, and C. However, such a pivot-based f"
N12-1044,N06-1011,0,0.0171051,"ki and Rosenberg, 1987), instance-based learning (van den Bosch and Daelemans, 1998), pronunciation by analogy (Marchand and Damper, 2000), decision trees (Kienappel and Kneser, 2001), hidden Markov models (Taylor, 2005), joint n-gram models (Bisani and Ney, 2008), and online discriminative learning (Jiampojamarn et al., 2008). The current state-of-the-art is represented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isah"
N12-1044,N06-1030,0,0.0504155,"tasks when augmented with various supplemental representations. We then further test the effectiveness of the same approach for combining the results of two independent base systems. 2 Related work Because of its crucial role in speech synthesis, grapheme-to-phoneme conversion has been researched extensively. Most out-of-vocabulary words are names, which often exhibit idiosyncratic pronunciation (Black et al., 1998). Excepting languages with highly transparent orthographies, the number of letter-to-sound rules appears to grow geometrically with the lexicon size, with no asymptotic limit 397 (Kominek and Black, 2006). A number of machine learning approaches have been proposed for G2P, including neural networks (Sejnowski and Rosenberg, 1987), instance-based learning (van den Bosch and Daelemans, 1998), pronunciation by analogy (Marchand and Damper, 2000), decision trees (Kienappel and Kneser, 2001), hidden Markov models (Taylor, 2005), joint n-gram models (Bisani and Ney, 2008), and online discriminative learning (Jiampojamarn et al., 2008). The current state-of-the-art is represented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine translite"
N12-1044,W10-2403,0,0.0281356,"Missing"
N12-1044,P04-1021,0,0.0709535,"2P, including neural networks (Sejnowski and Rosenberg, 1987), instance-based learning (van den Bosch and Daelemans, 1998), pronunciation by analogy (Marchand and Damper, 2000), decision trees (Kienappel and Kneser, 2001), hidden Markov models (Taylor, 2005), joint n-gram models (Bisani and Ney, 2008), and online discriminative learning (Jiampojamarn et al., 2008). The current state-of-the-art is represented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches d"
N12-1044,J00-2003,0,0.0147691,"thesis, grapheme-to-phoneme conversion has been researched extensively. Most out-of-vocabulary words are names, which often exhibit idiosyncratic pronunciation (Black et al., 1998). Excepting languages with highly transparent orthographies, the number of letter-to-sound rules appears to grow geometrically with the lexicon size, with no asymptotic limit 397 (Kominek and Black, 2006). A number of machine learning approaches have been proposed for G2P, including neural networks (Sejnowski and Rosenberg, 1987), instance-based learning (van den Bosch and Daelemans, 1998), pronunciation by analogy (Marchand and Damper, 2000), decision trees (Kienappel and Kneser, 2001), hidden Markov models (Taylor, 2005), joint n-gram models (Bisani and Ney, 2008), and online discriminative learning (Jiampojamarn et al., 2008). The current state-of-the-art is represented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliterat"
N12-1044,N09-1010,0,0.0139027,"Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relatively small drop in accuracy. Zhang et al. (2010) and Kumaran et al. (2010a) report that combinations of pivot systems A → C → B with direct systems A → B produce better results than using the direct systems only. The models, which are composed using a linear combination of scores, uti"
N12-1044,P06-1010,0,0.0305961,"ral networks (Sejnowski and Rosenberg, 1987), instance-based learning (van den Bosch and Daelemans, 1998), pronunciation by analogy (Marchand and Damper, 2000), decision trees (Kienappel and Kneser, 2001), hidden Markov models (Taylor, 2005), joint n-gram models (Bisani and Ney, 2008), and online discriminative learning (Jiampojamarn et al., 2008). The current state-of-the-art is represented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other are"
N12-1044,N07-1061,0,0.0118461,"v and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relatively small drop in accuracy. Zhang et al. (2010) and Kumaran et al. (2010a) report that combinations of pivot systems A → C → B with direct systems A → B produce better results than using the direct systems only. The mode"
N12-1044,W98-1224,0,0.0315614,"Missing"
N12-1044,P09-1018,0,0.0235441,"last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relatively small drop in accuracy. Zhang et al. (2010) and Kumaran et al. (2010a) report that combinations of pivot systems A → C → B with direct systems A → B produce better results than using the direct systems only. The models, which are composed using a linear comb"
N12-1044,W06-1672,0,0.0223354,"stance-based learning (van den Bosch and Daelemans, 1998), pronunciation by analogy (Marchand and Damper, 2000), decision trees (Kienappel and Kneser, 2001), hidden Markov models (Taylor, 2005), joint n-gram models (Bisani and Ney, 2008), and online discriminative learning (Jiampojamarn et al., 2008). The current state-of-the-art is represented by the latter two approaches, which are available as the S EQUITUR and D IREC TL+ systems, respectively. Machine transliteration has also received much attention (Knight and Graehl, 1998; Li et al., 2004; Sproat et al., 2006; Klementiev and Roth, 2006; Zelenko and Aone, 2006). In the last few years, the Named Entities Workshop (NEWS) Shared Tasks on Transliteration have been the forum for validating diverse approaches on common data sets (Li et al., 2009; Li et al., 2010; Zhang et al., 2011). Both S E QUITUR and D IREC TL+, originally G2P systems, have been successfully adapted to MTL (Finch and Sumita, 2010; Jiampojamarn et al., 2010b). Most of the research on both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapat"
N12-1044,C10-2165,0,0.127874,"n both G2P and MTL assumes the existence of a homogeneous training set of input-output pairs. However, following the pivot approaches developed in other areas of NLP (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009; Snyder et al., 2009), the idea of taking advantage of other-language data has recently been applied to machine transliteration. Khapra et al. (2010) construct a transliteration system between languages A and B by composing two transliteration systems A → C and C → B, where C is called a bridge or pivot language, resulting in a relatively small drop in accuracy. Zhang et al. (2010) and Kumaran et al. (2010a) report that combinations of pivot systems A → C → B with direct systems A → B produce better results than using the direct systems only. The models, which are composed using a linear combination of scores, utilize a single pivot language C, and require training data between all three languages A, B, and C. However, such a pivot-based framework makes it difficult to incorporate multiple pivot languages, and has shown most promising results for cases in which data for the original A → B task are limited. Lastly, Finch and Sumita (2010) developed an MTL approach that c"
N12-1044,W09-3501,0,\N,Missing
N12-1044,W10-2401,0,\N,Missing
N12-1044,J98-4003,0,\N,Missing
N12-1044,W11-3201,0,\N,Missing
N13-1072,N09-1035,1,0.840535,"trig-onal. We adopt an overgenerate-and-rank approach, whereby instead of committing to a specific word segmentation at the start of the process, we process multiple syllabification alternatives in parallel, one of which is ultimately selected at the respelling evaluation stage. Ideally, syllabification should conform to the phonotactic constraints of English, so that the resulting respellings are easy to pronounce. The consonant sonority should be rising in onsets, and falling in codas (Kenstowicz, 1994). We verify that syllables follow the sonority principle by following the formulation of Bartlett et al. (2009). The sonority constraints are not tested at the boundaries of the word, which are independent of the syllabification choice. We also incorporate another important principle of English phonotactics that asserts that lax vowels do not occur in open syllables (Rogers, 2000). In our implementation, each candidate syllable is tested with respect to the following sequence of four violable constraints, ordered from the strongest to the weakest: (1) the syllable contains exactly one vowel phoneme; (2) the onset satisfies the sonority principle; (3) if the nucleus contains a lax vowel (except @), the"
N13-1072,N09-2033,0,0.0292417,"1997) describes an experiment in which 15 human subjects were asked to pronounce uncommon words after being shown a representation of their pronunciation. The respellings designed by the author were much more effective for that purpose than either the IPA phonetic transcription or phonemic respelling (Section 4.3). However, the creation of respellings was described as labour-intensive, and at least one of them was found to be sub-optimal during the experiment. Williams and Jones (2008) propose respellings as a way of extending pronunciation lexicons by informants who lack linguistic training. Galescu (2009) reports that the addition of respellings of medical terms from an on-line dictionary improves the accuracy of an L2P system. The author identifies an automatic pronunciation-to-respelling system as future work. 636 Manual Design Dictionary Lookup Pronunciation dictionaries can be helpful in generating respellings. Assuming that we have a method of dividing pronunciations into syllables, a complete respelling of an out-of-dictionary word can in some cases be automatically derived from the list of syllable pronunciations. For example, hyphy can be respelled as ‘high-fee’ by following such a pro"
N13-1072,P10-1080,1,0.827092,"e preprocessing of the training data, and the letter-to-phoneme alignment. As with the P2L model, the training data consists of a set of monosyllabic words from the Combilex dictionary. However, in order to make our correctness filter more conservative, we also remove all words that contain diacritics (e.g., crêpe), non-English phonemes (e.g., avant), or silent consonants (e.g., limn). The alignment is restricted to matching each letter symbol to at most one phoneme, and is derived with the ALINE phonetic aligner (Kondrak, 2000), which has been shown to outperform other 1-1 alignment methods (Jiampojamarn and Kondrak, 2010). 6.2 Vowel Counter Syllables that contain multiple vowel groups may be confusing to readers even if they correctly represent the intended pronunciation. For example, readers might be unsure whether takess represents one or two syllables. A simple vowel counter is provided to filter out such syllables. The vowel filter accepts a syllable only if (a) it contains exactly one vowel group (e.g., moe), or (b) the second vowel group consists of a single e at the end of the syllable (e.g., zake). 639 SVM Ambiguity Classifier This module is designed to compute a score that reflects the ambiguity of an"
N13-1072,N07-1047,1,0.754171,"s. However, if this results in rejection of all possible syllabifications, the constraints are gradually relaxed starting from the weakest. As an example, consider the word abandonment [@bænd@nm@nt], which has 18 different syllabifications satisfying the VOWEL constraint (Table 1). 8 of the 18 satisfy the ONSET constraint as well, but only two syllabifications satisfy all four constraints: [@b-æn-d@n-m@nt] and [@-bæn-d@n-m@nt]. 5.2 P2L Generator ing step, we replace the letter x with ks, and we convert digraphs, such as ch and th, to single symbols. The alignment is performed by M2M-A LIGNER (Jiampojamarn et al., 2007), under the restriction that each phoneme is matched to either one or two letter symbols. 5.3 The respelling problem can be viewed as a string transduction problem, with the transduction occurring between phonemes and letters. As such, it is directly related to the well-studied letter-to-phoneme conversion task. The difference is that the letters may not conform to the standard orthography of English. If we had a sufficiently large training set of pronunciation-respelling pairs, we could train a machine learning algorithm to directly generate respellings for any strings of English phonemes. Ho"
N13-1072,P08-1103,1,0.844629,"nd in electronic pronunciation dictionaries. In addition, the quality of Web respellings vary greatly. In place of a direct pronunciation-to-respelling model, we aim to model the orthographic intuitions of readers by deriving a phoneme-to-letter (P2L) transduction model from an English pronunciation dictionary. A possible criticism of such an approach is that our model may create ambiguous respellings, which abound in English orthography. However, we rely on a separate evaluation module to identify and filter ambiguous respellings at a later stage. Our systems utilizes the D IREC TL+ program (Jiampojamarn et al., 2008), which was originally designed for L2P conversion. Since our basic unit is the syllable, rather than the word, we train our P2L model on a set of of 4215 pairs of monosyllabic words and their pronunciations extracted from the Combilex dictionary. We exclude syllables in multisyllabic words from training because their pronunciation is often affected by context. This is consistent with our expectation that the reader will pronounce each hyphen-delimited segment of the respelling as if it was an individual word. Since the P2L training data consists of a relatively small set of syllables, we ensu"
N13-1072,N06-1030,0,0.0310131,"ng. In this paper, we conduct two kinds of evaluations: an automated verification with an independent L2P system, and an experiment with human participants that pass judgments on different respellings of the same word. We interpret the results as evidence that the output of our system compares favourably with typical respellings found on the Web. 634 Proceedings of NAACL-HLT 2013, pages 634–643, c Atlanta, Georgia, 9–14 June 2013. 2013 Association for Computational Linguistics 2 Definitions and Conventions Although Chomsky and Halle (1968) characterize English orthography as close to optimal, Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. There is no consensus on how to best convey the pronunciation of an uncommon word in English. Most dictionaries employ either the International Phonetic Alphabet (IPA), or their own transcription schemes that inco"
N13-1072,A00-2038,1,0.606289,"rated with other methods. Other differences between the two models pertain to the preprocessing of the training data, and the letter-to-phoneme alignment. As with the P2L model, the training data consists of a set of monosyllabic words from the Combilex dictionary. However, in order to make our correctness filter more conservative, we also remove all words that contain diacritics (e.g., crêpe), non-English phonemes (e.g., avant), or silent consonants (e.g., limn). The alignment is restricted to matching each letter symbol to at most one phoneme, and is derived with the ALINE phonetic aligner (Kondrak, 2000), which has been shown to outperform other 1-1 alignment methods (Jiampojamarn and Kondrak, 2010). 6.2 Vowel Counter Syllables that contain multiple vowel groups may be confusing to readers even if they correctly represent the intended pronunciation. For example, readers might be unsure whether takess represents one or two syllables. A simple vowel counter is provided to filter out such syllables. The vowel filter accepts a syllable only if (a) it contains exactly one vowel group (e.g., moe), or (b) the second vowel group consists of a single e at the end of the syllable (e.g., zake). 639 SVM"
N13-1072,williams-jones-2008-acquiring,0,0.0293245,"llings are often used for names and foreign words, no lexicon can be expected to provide a complete coverage. 4.2 Related Work Fraser (1997) describes an experiment in which 15 human subjects were asked to pronounce uncommon words after being shown a representation of their pronunciation. The respellings designed by the author were much more effective for that purpose than either the IPA phonetic transcription or phonemic respelling (Section 4.3). However, the creation of respellings was described as labour-intensive, and at least one of them was found to be sub-optimal during the experiment. Williams and Jones (2008) propose respellings as a way of extending pronunciation lexicons by informants who lack linguistic training. Galescu (2009) reports that the addition of respellings of medical terms from an on-line dictionary improves the accuracy of an L2P system. The author identifies an automatic pronunciation-to-respelling system as future work. 636 Manual Design Dictionary Lookup Pronunciation dictionaries can be helpful in generating respellings. Assuming that we have a method of dividing pronunciations into syllables, a complete respelling of an out-of-dictionary word can in some cases be automatically"
N13-2007,P08-2039,0,0.354486,"ent, rule extraction and decoding. When translating from Arabic into English, the tokenization is a form of preprocessing, and the output translation is readable, space-separated English. However, when translating from English to Arabic, the output will be in a tokenized form, which cannot be compared to the original reference without detokenization. Simply concatenating the tokenized morphemes cannot fully reverse this process, because of character transformations that occurred during tokenization. The techniques that have been proposed for the detokenization task fall into three categories (Badr et al., 2008). The simplest detokenization approach concatenates morphemes based on token markers without any adjustment. Table-based detokenization maps tokenized words into their surface form with a look-up table built by observing the tokenizer’s inProceedings of the NAACL HLT 2013 Student Research Workshop, pages 47–53, c Atlanta, Georgia, 13 June 2013. 2013 Association for Computational Linguistics 2 Arabic Morphology Figure 1: Alignment between tokenized form of ð and its English translation. “wsymnςhm” ÑêªJÒJ put and output on large amounts of text. Rule-based detokenization relies on hand-built ru"
N13-2007,W12-5611,0,0.0357877,"Missing"
N13-2007,P07-2045,0,0.00583703,"T+R) Disambig (T+LM) Disambig (T+R+LM) D IREC TL+ WER 1.710 0.590 0.192 0.122 0.164 0.094 0.087 SER 34.3 14.0 4.9 3.2 4.1 2.4 2.1 BLEU 26.30 28.32 28.54 28.55 28.53 28.54 28.55 Table 3: Word and sentence error rate of detokenization schemes on the Arabic reference text of NIST MT05. BLEU score refers to English-Arabic SMT output. effectively memorize many words. We found these settings using grid search on the development set, NIST MT04. For the SMT experiment, we use GIZA++ for the alignment between English and tokenized Arabic, and perform the translation using Moses phrasebased SMT system (Hoang et al., 2007), with a maximum phrase length of 5. We apply each detokenization scheme on the SMT tokenized Arabic output test set, and evaluate using the BLEU score (Papineni et al., 2002). 5.3 Results Table 3 shows the performance of several detokenization schemes. For evaluation, we use the sentence and word error rates on naturally occurring Arabic text, and BLEU score on tokenized Arabic output of the SMT system. The baseline scheme, which is a simple concatenation of morphemes, introduces errors in over a third of all sentences. The table-based approach outperforms the rule-based approach, indicating"
N13-2007,N07-1047,1,0.86606,"s. The set of pairs is initially aligned on the character level, and the alignment pairs become the operations that are applied during transduction. For detokenization, most operations simply copy over characters, but more complex rules such as l+ Al → ll are learned from the training data as well. The tool that we use to perform the transduction is D IREC TL+, a discriminative, character-level string transducer, which was originally designed for letterto-phoneme conversion (Jiampojamarn et al., 2008). To align the characters in each training example. D IREC TL+ uses an EM-based M2M-A LIGNER (Jiampojamarn et al., 2007). After alignment is complete, MIRA training repeatedly decodes the training set to tune the features that determine when each operation should be applied. The features include both n-gram source context and HMM-style target transitions. D IREC TL+ employs a fully discriminative decoder to learn character transformations and when they should be applied. The decoder resembles a monotone phrase-based SMT decoder, but is built to allow for hundreds of thousands of features. The following example illustrates how string transduction applies to detokenization. The seg Q.K. mented and surface forms"
N13-2007,P08-1103,1,0.848711,"nization as a string transduction task. We train a discriminative transducer on a set of tokenized-detokenized word pairs. The set of pairs is initially aligned on the character level, and the alignment pairs become the operations that are applied during transduction. For detokenization, most operations simply copy over characters, but more complex rules such as l+ Al → ll are learned from the training data as well. The tool that we use to perform the transduction is D IREC TL+, a discriminative, character-level string transducer, which was originally designed for letterto-phoneme conversion (Jiampojamarn et al., 2008). To align the characters in each training example. D IREC TL+ uses an EM-based M2M-A LIGNER (Jiampojamarn et al., 2007). After alignment is complete, MIRA training repeatedly decodes the training set to tune the features that determine when each operation should be applied. The features include both n-gram source context and HMM-style target transitions. D IREC TL+ employs a fully discriminative decoder to learn character transformations and when they should be applied. The decoder resembles a monotone phrase-based SMT decoder, but is built to allow for hundreds of thousands of features. The"
N13-2007,P02-1040,0,0.0867771,"8.55 Table 3: Word and sentence error rate of detokenization schemes on the Arabic reference text of NIST MT05. BLEU score refers to English-Arabic SMT output. effectively memorize many words. We found these settings using grid search on the development set, NIST MT04. For the SMT experiment, we use GIZA++ for the alignment between English and tokenized Arabic, and perform the translation using Moses phrasebased SMT system (Hoang et al., 2007), with a maximum phrase length of 5. We apply each detokenization scheme on the SMT tokenized Arabic output test set, and evaluate using the BLEU score (Papineni et al., 2002). 5.3 Results Table 3 shows the performance of several detokenization schemes. For evaluation, we use the sentence and word error rates on naturally occurring Arabic text, and BLEU score on tokenized Arabic output of the SMT system. The baseline scheme, which is a simple concatenation of morphemes, introduces errors in over a third of all sentences. The table-based approach outperforms the rule-based approach, indicating that there are frequent exceptions to the rules in Table 1 that require memorization. Their combination (T+R) fares better, leveraging the strengths of both approaches. The ad"
N13-2007,P06-1001,0,0.0186785,"fferent forms of Hamzated Alif “ @ @” are usually written without the Hamza “ Z”. Likewise, when the letter Ya ’Y’ ø is present at the end of the word, it is sometimes written in the form of “Alif Maqsura” letter ’ý’ ø. Also, short vowels in Arabic are represented using diacritics, which are usually absent in written text. In order to deal with these ambiguities in SMT, normalization is often performed as a preprocessing step, which usually involves converting different forms of Alif and Ya to a single form. This decreases Arabic’s lexical sparsity and improves SMT performance. 3 Related Work Sadat and Habash (2006) address the issue of lexical sparsity by presenting different preprocessing schemes for Arabic-to-English SMT. The schemes include simple tokenization, orthographic normalization, and decliticization. The combination of these schemes results in improved translation out2 We use Habash-Soudi-Buckwalter transliteration scheme (Habash, 2007) for all Arabic examples. put. This is one of many studies on normalization and tokenization for translation from Arabic, which we will not attempt to review completely here. Badr et al. (2008) show that tokenizing Arabic also has a positive influence on Engli"
N15-1056,P09-1015,1,0.81394,"en et al., 1995), which includes morphological analysis of words, and the Combilex speech lexicon (Richmond et al., 2009), which contains high-quality phonemic transcriptions. After intersecting the lexicons, and pruning it of proper nouns, function words, duplicate forms, and multi-word entries, we are left with approximately 51,000 word-forms that are annotated both morphologically and phonemically. In order to segment phonemic representations into constituent morphemes, we apply a high-precision phonetic aligner (Kondrak, 2000) to link letters and phonemes using the procedure described in (Dwyer and Kondrak, 2009). In rare cases where the phonetic aligner fails to produce an alignment, we backoff to alignment generated with m2m-aligner (Jiampojamarn et al., 2007), an unsupervised EMbased algorithm. We found that this approach worked better for our purposes than relying on the alignments provided in Combilex. We use the same approach to align variant phonemic representations of morphemes as described in Section 3.1. The morphological information contained in CELEX is incomplete for our purposes, and requires further processing. For example, the word amputate is listed as monomorphemic, but in fact conta"
N15-1056,N07-1047,1,0.64397,"phonemic transcriptions. After intersecting the lexicons, and pruning it of proper nouns, function words, duplicate forms, and multi-word entries, we are left with approximately 51,000 word-forms that are annotated both morphologically and phonemically. In order to segment phonemic representations into constituent morphemes, we apply a high-precision phonetic aligner (Kondrak, 2000) to link letters and phonemes using the procedure described in (Dwyer and Kondrak, 2009). In rare cases where the phonetic aligner fails to produce an alignment, we backoff to alignment generated with m2m-aligner (Jiampojamarn et al., 2007), an unsupervised EMbased algorithm. We found that this approach worked better for our purposes than relying on the alignments provided in Combilex. We use the same approach to align variant phonemic representations of morphemes as described in Section 3.1. The morphological information contained in CELEX is incomplete for our purposes, and requires further processing. For example, the word amputate is listed as monomorphemic, but in fact contains the suffix -ate. However, amputee is analyzed as This allows us to identify the stem as amput, which in turn implies the segmentations amput·ee, amp"
N15-1056,N10-1103,1,0.827919,"tains the suffix -ate. However, amputee is analyzed as This allows us to identify the stem as amput, which in turn implies the segmentations amput·ee, amput·ate, and amput·at·ion. Another issue that requires special handling in CELEX involves recovering reduced geminate consonants. For example, the word interrelate is pronounced with a single [r] phoneme at the morpheme boundary. However, when segmenting the phoneme sequence, we need to include [r] both at the end of inter- and at the beginning of relate. Predictor The role of the predictor mentioned in Section 3.2 is performed by D IREC TL+ (Jiampojamarn et al., 2010), a publicly available discriminative string transducer. It takes as input a sequence of common morpheme representations, determined using the method described above, and produces the predicted word pronunciation. Since D IREC TL+ tends to make mistakes related to the unstressed vowel reduction phenomenon in English, we refrain from replacing the “underlying” phonemes with either [@] or [I]. An example derivation is shown in Table 3, where the Underlying string represents the input to D I REC TL+, Predicted is its output, Surface is the actual pronunciation, and Respelling is the spelling gene"
N15-1056,N06-1030,0,0.185247,"ng Science University of Alberta {nicolai,gkondrak}@ualberta.ca Abstract In spite of the apparent irregularity of the English spelling system, Chomsky and Halle (1968) characterize it as “near optimal”. We investigate this assertion using computational techniques and resources. We design an algorithm to generate word spellings that maximize both phonemic transparency and morphological consistency. Experimental results demonstrate that the constructed system is much closer to optimality than the traditional English orthography. 1 Introduction English spelling is notorious for its irregularity. Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. Numerous proposals have been put forward for spelling reforms over the years, ranging from small changes affecting a limited set of words to complete overhauls based on novel writing scripts (Venezky, 1970). In sp"
N15-1056,A00-2038,1,0.586723,"ary information from two different resources: the CELEX lexical database (Baayen et al., 1995), which includes morphological analysis of words, and the Combilex speech lexicon (Richmond et al., 2009), which contains high-quality phonemic transcriptions. After intersecting the lexicons, and pruning it of proper nouns, function words, duplicate forms, and multi-word entries, we are left with approximately 51,000 word-forms that are annotated both morphologically and phonemically. In order to segment phonemic representations into constituent morphemes, we apply a high-precision phonetic aligner (Kondrak, 2000) to link letters and phonemes using the procedure described in (Dwyer and Kondrak, 2009). In rare cases where the phonetic aligner fails to produce an alignment, we backoff to alignment generated with m2m-aligner (Jiampojamarn et al., 2007), an unsupervised EMbased algorithm. We found that this approach worked better for our purposes than relying on the alignments provided in Combilex. We use the same approach to align variant phonemic representations of morphemes as described in Section 3.1. The morphological information contained in CELEX is incomplete for our purposes, and requires further"
N15-1093,E14-1060,0,0.208948,"ing levels of morphological complexity. In each experiment we either match or improve over the state of the art reported in previous work. In addition to providing a detailed comparison of the available inflection prediction systems, we also contribute four new inflection datasets composed of Dutch and French verbs, and Czech verbs and nouns, which are made available for future research. 923 2 Inflection generation Durrett and DeNero (2013) formulate the specific task of supervised generation of inflected forms for a given base-form based on a large number of training inflection tables, while Ahlberg et al. (2014) test their alternative method on the same Wiktionary dataset. In this section, we compare their work to our approach with respect to the following three subtasks: 1. character-wise alignment of the word-forms in an inflection table (Section 2.1), 2. extraction of rules from aligned forms (2.2), 3. matching of rules to new base-forms (2.3). 2.1 Table alignment The first step in supervised paradigm learning is the alignment of related inflected forms in a table. Though technically a multiple-alignment problem, this can also be addressed by aligning each inflected form to a base-form. Durrett &"
N15-1093,P11-1004,0,0.0483563,"depending on their role in a sentence, and adjectives agree with the nouns that they modify. For such languages, many forms will not be attested even in a large corpus. However, different lemmas often exhibit the same inflectional patterns, called paradigms, which are based on phonological, semantic, or morphological criteria. The paradigm of a given lemma can be identified and used to generate unseen forms. Inflection prediction has the potential to improve Statistical Machine Translation (SMT) into morphologically complex languages. In order to address data sparsity in the training bitext, Clifton and Sarkar (2011) and Fraser et al. (2012) reduce diverse inflected forms in the target language into the corresponding base forms, or lemmas. At test time, they predict an abstract inflection tag for each translated lemma, which is then transformed into a proper word-form. Unfortunately, hand-crafted morphological generators such as the ones that they use for this purpose are available only for a small number of languages, and are expensive to create from scratch. The supervised inflection generation models that we investigate in this paper can instead be trained on publicly available inflection tables. The t"
N15-1093,D11-1057,0,0.0194676,"Missing"
N15-1093,N13-1138,0,0.573516,"n publicly available inflection tables. The task of an inflection generator is to produce an inflected form given a base-form (e.g., an infinitive) and desired inflection, which can be specified as an abstract inflectional tag. The generator is trained on a number of inflection tables, such as the one in Figure 1, which enumerate inflection forms for a given lemma. At test time, the generator predicts inflections for previously unseen base-forms. For example, given the input atmen + 1SIA, where the tag stands for “first person singular indicative preterite,” it should output atmete. Recently, Durrett and DeNero (2013) and Ahlberg 922 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 922–931, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics et al. (2014) have proposed to model inflection generation as a two-stage process: an input base-form is first matched with rules corresponding to a paradigm seen during training, which is then used to generate all inflections for that base-form simultaneously. Although their methods are quite different, both systems account for paradigm-wide regularities by creating rules that"
N15-1093,E12-1068,0,0.0159665,"sentence, and adjectives agree with the nouns that they modify. For such languages, many forms will not be attested even in a large corpus. However, different lemmas often exhibit the same inflectional patterns, called paradigms, which are based on phonological, semantic, or morphological criteria. The paradigm of a given lemma can be identified and used to generate unseen forms. Inflection prediction has the potential to improve Statistical Machine Translation (SMT) into morphologically complex languages. In order to address data sparsity in the training bitext, Clifton and Sarkar (2011) and Fraser et al. (2012) reduce diverse inflected forms in the target language into the corresponding base forms, or lemmas. At test time, they predict an abstract inflection tag for each translated lemma, which is then transformed into a proper word-form. Unfortunately, hand-crafted morphological generators such as the ones that they use for this purpose are available only for a small number of languages, and are expensive to create from scratch. The supervised inflection generation models that we investigate in this paper can instead be trained on publicly available inflection tables. The task of an inflection gene"
N15-1093,N07-1047,1,0.80485,"ed on all inflected word-forms, we derive tag-specific models for each type of inflection. Development experiments showed the general model to be slightly more accurate overall, but we use both types of models in our reranker. 3.3 String alignment D IREC TL+ training requires a set of aligned pairs of source and target strings. The alignments account for every input and output character without the use of insertion. Derivations that transform the input substrings into the desired output substrings are then extracted from the alignments. We induce the alignments by adapting the M2M aligner of (Jiampojamarn et al., 2007), which uses Expectation-Maximization to maximize the joint likelihood of its input under a pairwise alignment scheme. Previous work creates alignments based upon entire inflection tables, while ours considers each inflection paired with its base form independently. M2M goes beyond linking single characters by aligning entire substrings instead. In practice, the base-form serves as a pivot for the entire inflection table, leading to consistent multiple alignments. We modify the M2M aligner to differentiate between stems and affixes. The alignments between stem letters rarely require more than"
N15-1093,N10-1103,1,0.404007,"es into empty strings. During development, we experimented with an alternative method, in which affixes are represented by a default allomorph. Allomorphic representations have the potential advantage of reducing the complexity of transductions by the virtue of being similar to the correct form of the affix. However, we found that allomorphic affixes tend to obfuscate differences between distinct inflections, so we decided to employ abstract tags instead. 3.2 String transduction We perform string transduction adapting the tool D IREC TL+, originally designed for grapheme-tophoneme conversion (Jiampojamarn et al., 2010). D IREC TL+ is a feature-rich, discriminative character transducer, which searches for a model-optimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation, also known as a semi-Markov model. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. D IREC TL+ uses a number of feature template"
N15-1093,P05-1012,0,0.0152706,"ctions, so we decided to employ abstract tags instead. 3.2 String transduction We perform string transduction adapting the tool D IREC TL+, originally designed for grapheme-tophoneme conversion (Jiampojamarn et al., 2010). D IREC TL+ is a feature-rich, discriminative character transducer, which searches for a model-optimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation, also known as a semi-Markov model. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. D IREC TL+ uses a number of feature templates to assess the quality of a rule: source context, target n-gram, and joint n-gram features. Context features conjoin the rule with indicators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indi925 cators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoined with our sou"
N15-1093,P09-1055,1,0.358775,"he rule with indicators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indi925 cators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoined with our source context features. Joint n-grams build indicators on rule sequences, combining source and target context, and memorizing frequently-used rule patterns. Durrett & DeNero also use source context features, but we are the first group to account for features that consider rule sequences or target word shape. Following Toutanova and Cherry (2009), we modify the out-of-the-box version of D IREC TL+ by implementing an abstract copy feature that indicates when a rule simply copies its source characters into the target, e.g. p → p. The copy feature has the effect of biasing the transducer towards preserving the base-form within the inflected form. In addition to the general model that is trained on all inflected word-forms, we derive tag-specific models for each type of inflection. Development experiments showed the general model to be slightly more accurate overall, but we use both types of models in our reranker. 3.3 String alignment D"
N15-1093,N04-1033,0,0.0594358,"than those of our predecessors, which makes it easy to get statistical support for these additional features. Finally, since our rules are not bound by paradigm structure, we employ a reranking step to account for intra-paradigm regularities. 3 Discriminative Transduction In this section, we describe the details of our approach, including the affix representation, the string alignment and transduction, and the paradigm reranking. 3.1 Affix representation Our inflection generation engine is a discriminative semi-Markov model, similar to a monotonic phrasebased decoder from machine translation (Zens and Ney, 2004). This system cannot insert characters, except as a part of a phrasal substitution, so when inflecting a base form, we add an abstract affix representation to both provide an insertion site and to indicate the desired inflection. Abstract tags are separated from their lemmas with a single ‘+’ character. Marking the morpheme boundary in such a way allows the transducer to generalize the context of a morpheme boundary. For example, the third person singular indicative present of the verb atmen is represented as atmen+3SIE. We use readable tags throughout this paper, but they are presented to the"
N15-1095,W02-0505,0,0.482825,"p in establishing the correct pronunciation (Bhargava and Kondrak, 2012). Transliteration is often defined as phonetic translation (Zhang et al., 2012). In the idealized model of Knight and Graehl (1997), a bilingual expert pronounces a name in the source language, modifies the pronunciation to fit the target language phonology, and writes it down using the orthographic rules of the target script. In practice, however, it may be difficult to guess the correct pronunciation of an unfamiliar name from the spelling. Phonetic-based models of transliteration tend to achieve suboptimal performance. Al-Onaizan and Knight (2002) report that a spelling-based model outperforms a phonetic-based model even when pronunciations are extracted from a pronunciation dictionary. This can be attributed to the importance of the source orthography in the transliteration process. For example, the initial letters of the Russian transliterations of the names Chicano ([tSIkAno]) and Chicago ([SIkAgo]) are identical, but different from Shilo ([SIlo]). The contrast is likely due to the idiosyncratic spelling of Chicago. Typical transliteration systems learn direct orthographic mapping between the source and the target languages from par"
N15-1095,N09-3008,1,0.777472,"st scoring target string, which can be recovered through backtracking. Figure 2: Three pairwise alignments between the English word abbey, its transcription [abi], and the Japanese transliteration アベイ (A-BE-I). 3.2 Figure 3: Obtaining a triple alignment by pivoting on the source word. only requires more time, but also results in less accurate transliterations. Multi-alignment M2M-A LIGNER applies the EM algorithm to align sets of string pairs. For the purpose of joint generation, we need to align triples S, P and T prior to training. The alignment of multiple strings is a challenging problem (Bhargava and Kondrak, 2009). In general, there is no obvious way of merging three pairwise alignments. Figure 2 shows an example of three pairwise alignments that are mutually inconsistent: the English letter e is aligned to the phoneme [i] and to the grapheme ベ(BE), which are not aligned to each other Our solution is to select one of the input strings as the pivot for aligning the remaining two strings. Specifically, we align the pivot string to each of the other two strings through one-to-many alignments, where the maximum length of aligned substrings in the pivot string is set to one. Then we merge these two pairwise"
N15-1095,P11-1041,1,0.918917,"the generation process. Khapra et al. (2010) propose a bridge approach of transliterating low-resource language pair (X, Y ) by pivoting on an high-resource language Z, with the assumption that the pairwise data between (X, Z) and (Y, Z) is relatively large. Their experiments show that pivoting on Z results in lower accuracy than directly transliterating X into Y . Zhang et al. (2010) and Kumaran et al. (2010) combine the pivot model with a grapheme-based model, which works better than either of the two approaches alone. However, their model is not able to incorporate more than two languages. Bhargava and Kondrak (2011) propose a reranking approach that uses supplemental transliterations to improve grapheme-to-phoneme conversion of names. Bhargava and Kondrak (2012) generalize this idea to improve transliteration accuracy by utilizing either transliterations from other languages, or phonetic transcriptions in the source language. Specifically, they apply an SVM reranker to the topn outputs of a base spelling-based model. However, the post-hoc property of reranking is a limiting factor; it can identify the correct transliteration only if the base model includes it in its output candidate list. 3 Joint Generat"
N15-1095,N12-1044,1,0.924625,"ration is the conversion of a text from one script to another. When a new name like Eyjafjallaj¨okull appears in the news, it needs to be promptly transliterated into dozens of languages. Computer-generated transliterations can be more accurate than those created by humans (Sherif and Kondrak, 2007). When the names in question originate from languages that use the same writing script as the target language, they are likely to be copied verbatim; however, their pronunciation may still be ambiguous. Existing transliterations and transcriptions can help in establishing the correct pronunciation (Bhargava and Kondrak, 2012). Transliteration is often defined as phonetic translation (Zhang et al., 2012). In the idealized model of Knight and Graehl (1997), a bilingual expert pronounces a name in the source language, modifies the pronunciation to fit the target language phonology, and writes it down using the orthographic rules of the target script. In practice, however, it may be difficult to guess the correct pronunciation of an unfamiliar name from the spelling. Phonetic-based models of transliteration tend to achieve suboptimal performance. Al-Onaizan and Knight (2002) report that a spelling-based model outperfo"
N15-1095,C04-1086,0,0.246213,"nins, Jeltoqsan, and Jecheon all differ in their initial letters. In addition, because of inconsistent correspondences between letters and phonemes in some languages, the pronunciation of a word may be difficult to derive from its orthographic form. We believe that transliteration is not simply phonetic translation, but rather a process that combines both phonetic and orthographic information. This observation prompted the development of several hybrid approaches that take advantage of both types of information, and improvements were reported on some test corpora (Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004; Oh and Choi, 2005). These models, which we discuss in more detail in Section 2.1, are well behind the current state of the art in machine transliteration. 943 Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 943–952, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics In this paper, we conduct experiments that show the relative importance of spelling and pronunciation. We propose a new hybrid approach of joint transliteration generation from both orthography and pronunciation, which is based on a dis"
N15-1095,D09-1111,0,0.0188723,"king. In order to ensure fair comparison, the held-out sets for training the rerankers are subtracted from the original training sets. Another observation that we aim to exploit is that a substantial number of the outputs generated by our joint model are very close to gold-standard transliterations. In fact, news writers often use slightly different transliterations of the same name, which makes the model’s task more difficult. Therefore, we rerank the model outputs using a target-language lexicon, which is a list of words together with their frequencies collected from a raw corpus. We follow Cherry and Suzuki (2009) in extracting lexicon features for a given word according to coarse bins, i.e., [< 2000], [< 200], [< 20], [< 2], [< 1]. For 950 example, a word with the frequency 194 will cause the features [< 2000] and [< 200] to fire. We conduct our final experiment on forward and backward transliteration. We utilize supplemental transliterations from all eight languages in the NEWS 2010 dataset. The English-Japanese and English-Hindi datasets contain 33,540 and 13,483 entries, of which 23,613 and 12,131 have at least one supplemental transliteration, respectively. These sets are split into training/devel"
N15-1095,N07-1047,1,0.870211,"roach by modifying the D IREC TL+ system of Jiampojamarn et al. (2010), which we describe in Section 3.1. In the following sections, we discuss other components of our approach, namely alignment (3.2), scoring (3.3), and search (3.4). In Section 3.5 we generalize the joint model to accept multiple input strings. 3.1 DirecTL+ D IREC TL+ (Jiampojamarn et al., 2010) is a discriminative string transducer which learns to convert source strings into target strings from a set of parallel training data. It requires pairs of strings to be aligned at the character level prior to training. M2M-A LIGNER (Jiampojamarn et al., 2007), an unsupervised EM-based aligner, is often used to generate such alignments. The output is a ranked list of candidate target strings with their confidence scores. Below, we briefly describe the scoring model, the training process, and the search algorithm. The scoring model assigns a score to an aligned pair of source and target strings (S, T ). Assuming there are m aligned substrings, such that the ith source substring generates the ith target substring, the score is computed with the following formula: m X α · Φ(i, S, T ) (1) i where α is the weight vector, and Φ is the feature vector. The"
N15-1095,N10-1103,1,0.940051,"ver the two component models on some, but not all, of their test corpora. Oh and Choi (2005) replace the fixed linear interpolation approach with a more flexible model that 944 takes into account the correspondence between the phonemes and graphemes during the transliteration generation process. They report superior performance of their hybrid model over both component models. However, their model does not consider the coherence of the target word during the generation process, nor other important features that have been shown to significantly improve machine transliteration (Li et al., 2004; Jiampojamarn et al., 2010). Oh et al. (2009) report that their hybrid models improve the accuracy of English-to-Chinese transliteration. However, since their focus is on investigating the influence of Chinese phonemes, their hybrid model is again a simple linear combination of basic models. 2.2 Leveraging supplemental transliterations Previous work that explore the idea of taking advantage of data from additional languages tend to employ supplemental transliterations indirectly, rather than to incorporate them directly into the generation process. Khapra et al. (2010) propose a bridge approach of transliterating low-re"
N15-1095,N10-1065,0,0.022596,"ove machine transliteration (Li et al., 2004; Jiampojamarn et al., 2010). Oh et al. (2009) report that their hybrid models improve the accuracy of English-to-Chinese transliteration. However, since their focus is on investigating the influence of Chinese phonemes, their hybrid model is again a simple linear combination of basic models. 2.2 Leveraging supplemental transliterations Previous work that explore the idea of taking advantage of data from additional languages tend to employ supplemental transliterations indirectly, rather than to incorporate them directly into the generation process. Khapra et al. (2010) propose a bridge approach of transliterating low-resource language pair (X, Y ) by pivoting on an high-resource language Z, with the assumption that the pairwise data between (X, Z) and (Y, Z) is relatively large. Their experiments show that pivoting on Z results in lower accuracy than directly transliterating X into Y . Zhang et al. (2010) and Kumaran et al. (2010) combine the pivot model with a grapheme-based model, which works better than either of the two approaches alone. However, their model is not able to incorporate more than two languages. Bhargava and Kondrak (2011) propose a rerank"
N15-1095,P97-1017,0,0.554006,"be promptly transliterated into dozens of languages. Computer-generated transliterations can be more accurate than those created by humans (Sherif and Kondrak, 2007). When the names in question originate from languages that use the same writing script as the target language, they are likely to be copied verbatim; however, their pronunciation may still be ambiguous. Existing transliterations and transcriptions can help in establishing the correct pronunciation (Bhargava and Kondrak, 2012). Transliteration is often defined as phonetic translation (Zhang et al., 2012). In the idealized model of Knight and Graehl (1997), a bilingual expert pronounces a name in the source language, modifies the pronunciation to fit the target language phonology, and writes it down using the orthographic rules of the target script. In practice, however, it may be difficult to guess the correct pronunciation of an unfamiliar name from the spelling. Phonetic-based models of transliteration tend to achieve suboptimal performance. Al-Onaizan and Knight (2002) report that a spelling-based model outperforms a phonetic-based model even when pronunciations are extracted from a pronunciation dictionary. This can be attributed to the im"
N15-1095,P04-1021,0,0.0612201,"ort improvement over the two component models on some, but not all, of their test corpora. Oh and Choi (2005) replace the fixed linear interpolation approach with a more flexible model that 944 takes into account the correspondence between the phonemes and graphemes during the transliteration generation process. They report superior performance of their hybrid model over both component models. However, their model does not consider the coherence of the target word during the generation process, nor other important features that have been shown to significantly improve machine transliteration (Li et al., 2004; Jiampojamarn et al., 2010). Oh et al. (2009) report that their hybrid models improve the accuracy of English-to-Chinese transliteration. However, since their focus is on investigating the influence of Chinese phonemes, their hybrid model is again a simple linear combination of basic models. 2.2 Leveraging supplemental transliterations Previous work that explore the idea of taking advantage of data from additional languages tend to employ supplemental transliterations indirectly, rather than to incorporate them directly into the generation process. Khapra et al. (2010) propose a bridge approa"
N15-1095,D09-1069,0,0.0234693,"on some, but not all, of their test corpora. Oh and Choi (2005) replace the fixed linear interpolation approach with a more flexible model that 944 takes into account the correspondence between the phonemes and graphemes during the transliteration generation process. They report superior performance of their hybrid model over both component models. However, their model does not consider the coherence of the target word during the generation process, nor other important features that have been shown to significantly improve machine transliteration (Li et al., 2004; Jiampojamarn et al., 2010). Oh et al. (2009) report that their hybrid models improve the accuracy of English-to-Chinese transliteration. However, since their focus is on investigating the influence of Chinese phonemes, their hybrid model is again a simple linear combination of basic models. 2.2 Leveraging supplemental transliterations Previous work that explore the idea of taking advantage of data from additional languages tend to employ supplemental transliterations indirectly, rather than to incorporate them directly into the generation process. Khapra et al. (2010) propose a bridge approach of transliterating low-resource language pa"
N15-1095,P07-1119,1,0.891089,"ective model for joint transliteration generation from both representations. We further generalize this model to include transliterations from other languages, and enhance it with reranking and lexicon features. We demonstrate significant improvements in transliteration accuracy on several datasets. 1 Introduction Transliteration is the conversion of a text from one script to another. When a new name like Eyjafjallaj¨okull appears in the news, it needs to be promptly transliterated into dozens of languages. Computer-generated transliterations can be more accurate than those created by humans (Sherif and Kondrak, 2007). When the names in question originate from languages that use the same writing script as the target language, they are likely to be copied verbatim; however, their pronunciation may still be ambiguous. Existing transliterations and transcriptions can help in establishing the correct pronunciation (Bhargava and Kondrak, 2012). Transliteration is often defined as phonetic translation (Zhang et al., 2012). In the idealized model of Knight and Graehl (1997), a bilingual expert pronounces a name in the source language, modifies the pronunciation to fit the target language phonology, and writes it"
N15-1095,C10-2165,0,0.0148721,"veraging supplemental transliterations Previous work that explore the idea of taking advantage of data from additional languages tend to employ supplemental transliterations indirectly, rather than to incorporate them directly into the generation process. Khapra et al. (2010) propose a bridge approach of transliterating low-resource language pair (X, Y ) by pivoting on an high-resource language Z, with the assumption that the pairwise data between (X, Z) and (Y, Z) is relatively large. Their experiments show that pivoting on Z results in lower accuracy than directly transliterating X into Y . Zhang et al. (2010) and Kumaran et al. (2010) combine the pivot model with a grapheme-based model, which works better than either of the two approaches alone. However, their model is not able to incorporate more than two languages. Bhargava and Kondrak (2011) propose a reranking approach that uses supplemental transliterations to improve grapheme-to-phoneme conversion of names. Bhargava and Kondrak (2012) generalize this idea to improve transliteration accuracy by utilizing either transliterations from other languages, or phonetic transcriptions in the source language. Specifically, they apply an SVM reranker to"
N15-1095,W10-2401,0,\N,Missing
N15-1095,W12-4401,0,\N,Missing
N16-1140,P08-2039,0,0.0239392,"that the target side of the parallel corpus has been segmented into morphemes with prefixes and suffixes marked.2 This allows us to define a complete word as a maximal morpheme sequence consisting of 0 or more prefixes, followed by at most one stem, and then 0 or more suffixes. We also assume access to a desegmentation function that takes as input a morpheme sequence matching the above definition, and returns the corresponding word as output. Depending on the complexity of the segmentation, desegmentation can be achieved through simple concatenation, a small set of rules, a statistical table (Badr et al., 2008), or a statis1 The ideas presented here could also be applied to hierarchical decoding, which would require generalizing them to account for right context as well as left. 2 Throughout this paper, we use a token-final “+” to denote a prefix, and a token-initial “+” for a suffix. 1176 tical transducer (Salameh et al., 2013). El Kholy and Habash (2012) provide an extensive study on the influence of segmentation and desegmentation on English-to-Arabic SMT. In this work, we adopt the Table+Rules technique of El Kholy and Habash (2012) for English-Arabic SMT. The technique relies on a look-up table"
N16-1140,P11-2031,0,0.0181231,"rget side of the parallel data. We experiment with word penalties based on either morphemes or desegmented words. The decoder uses Moses’ default search parameters, except for the maximum phrase length, which is set to 8, and the translation table limit, which is set to 40. The decoder’s log-linear model is tuned with MERT (Och, 2003) using unsegmented Arabic reference translations. When necessary, we desegment our 100-best-lists before MERT evaluates each hypothesis. We evaluate with BLEU (Papineni et al., 2002) measured on unsegmented Arabic, and test statistical significance with multeval (Clark et al., 2011) over 3 tuning replications. We test four systems that differ in their desegmentation approach. The NoSegm. baseline involves no segmentation. The One-best baseline translates into segmented Arabic and desegments the decoder’s 1-best output. The Lattice system is the lattice-desegmentation approach of Salameh et al. (2014). We implement our in-Decoder desegmentaSystem NoSegm. One-best Lattice Delayed Optimistic WP word morph. morph. morph. word morph. word mt05 33.2 33.8 34.4 34.1 34.1 34.2 34.5 mt08 18.6 19.1 19.7 19.4 19.5 19.6 19.7 mt09 25.6 26.8 27.4 27.0 26.8 27.2 27.2 Table 1: Evaluation"
N16-1140,P07-2045,0,0.0857459,"nd considered throughout the entire search space. We achieve this by augmenting the decoder to desegment hypotheses on the fly, allowing the inclusion of an unsegmented language model and other features. Our results on a large-scale, NIST-data English to Arabic translation task show significant improvements over the 1best desegmentation baseline, and match the performance of the state-of-the-art lattice desegmentation approach of Salameh et al. (2014), while eliminating the complication and cost of its rescoring step. Our approach is implemented as a single stateful feature function in Moses (Koehn et al., 2007), which we will submit back to the community. 2 Method Our approach extends the multi-stack phrase-based decoding paradigm to enable the extraction of wordlevel features inside morpheme-segmented models.1 We assume that the target side of the parallel corpus has been segmented into morphemes with prefixes and suffixes marked.2 This allows us to define a complete word as a maximal morpheme sequence consisting of 0 or more prefixes, followed by at most one stem, and then 0 or more suffixes. We also assume access to a desegmentation function that takes as input a morpheme sequence matching the ab"
N16-1140,D10-1015,0,0.0426598,"Missing"
N16-1140,J03-1002,0,0.016086,"n of NIST 2008 (813 pairs) and NIST 2009 (586 pairs). As there are multiple English reference translations provided for these evaluation sets, we use the first reference as our source text. The Arabic part of the training set is morphologically segmented and tokenized by MADA 3.2 (Habash et al., 2009) using the Penn Arabic Treebank (PATB) segmentation scheme. Variants of Alif and Ya characters are uniformly normalized. We generate a desegmentation table from the Arabic side of the training data by collecting mappings of segmented forms to surface forms. We align the parallel data with GIZA++ (Och et al., 2003), and decode with Moses (Koehn et al., 2007). The decoder’s log-linear model uses a standard feature set, including four phrase table scores, six features from a lexicalized distortion model, along with a phrase penalty and a distance-based distortion penalty. KN-smoothed 5-gram language models are trained on both the segmented and unsegmented views of the target side of the parallel data. We experiment with word penalties based on either morphemes or desegmented words. The decoder uses Moses’ default search parameters, except for the maximum phrase length, which is set to 8, and the translati"
N16-1140,P03-1021,0,0.0256788,"ndard feature set, including four phrase table scores, six features from a lexicalized distortion model, along with a phrase penalty and a distance-based distortion penalty. KN-smoothed 5-gram language models are trained on both the segmented and unsegmented views of the target side of the parallel data. We experiment with word penalties based on either morphemes or desegmented words. The decoder uses Moses’ default search parameters, except for the maximum phrase length, which is set to 8, and the translation table limit, which is set to 40. The decoder’s log-linear model is tuned with MERT (Och, 2003) using unsegmented Arabic reference translations. When necessary, we desegment our 100-best-lists before MERT evaluates each hypothesis. We evaluate with BLEU (Papineni et al., 2002) measured on unsegmented Arabic, and test statistical significance with multeval (Clark et al., 2011) over 3 tuning replications. We test four systems that differ in their desegmentation approach. The NoSegm. baseline involves no segmentation. The One-best baseline translates into segmented Arabic and desegments the decoder’s 1-best output. The Lattice system is the lattice-desegmentation approach of Salameh et al."
N16-1140,W07-0704,0,0.0807303,"Missing"
N16-1140,P02-1040,0,0.0952456,"ty. KN-smoothed 5-gram language models are trained on both the segmented and unsegmented views of the target side of the parallel data. We experiment with word penalties based on either morphemes or desegmented words. The decoder uses Moses’ default search parameters, except for the maximum phrase length, which is set to 8, and the translation table limit, which is set to 40. The decoder’s log-linear model is tuned with MERT (Och, 2003) using unsegmented Arabic reference translations. When necessary, we desegment our 100-best-lists before MERT evaluates each hypothesis. We evaluate with BLEU (Papineni et al., 2002) measured on unsegmented Arabic, and test statistical significance with multeval (Clark et al., 2011) over 3 tuning replications. We test four systems that differ in their desegmentation approach. The NoSegm. baseline involves no segmentation. The One-best baseline translates into segmented Arabic and desegments the decoder’s 1-best output. The Lattice system is the lattice-desegmentation approach of Salameh et al. (2014). We implement our in-Decoder desegmentaSystem NoSegm. One-best Lattice Delayed Optimistic WP word morph. morph. morph. word morph. word mt05 33.2 33.8 34.4 34.1 34.1 34.2 34."
N16-1140,N13-2007,1,0.839267,"function that takes as input a morpheme sequence matching the above definition, and returns the corresponding word as output. Depending on the complexity of the segmentation, desegmentation can be achieved through simple concatenation, a small set of rules, a statistical table (Badr et al., 2008), or a statis1 The ideas presented here could also be applied to hierarchical decoding, which would require generalizing them to account for right context as well as left. 2 Throughout this paper, we use a token-final “+” to denote a prefix, and a token-initial “+” for a suffix. 1176 tical transducer (Salameh et al., 2013). El Kholy and Habash (2012) provide an extensive study on the influence of segmentation and desegmentation on English-to-Arabic SMT. In this work, we adopt the Table+Rules technique of El Kholy and Habash (2012) for English-Arabic SMT. The technique relies on a look-up table that stores mappings of segmented-unsegmented forms, and falls back on manually crafted rules for segmented sequences not found in the table. When a segmented form has multiple desegmentation options available in the table, we select the most frequent option. The output of a phrase-based decoder is built from left to righ"
N16-1140,P14-1010,1,0.668945,"phic normalizations, such as transforming the stem-final t to p. The result is not only a reduction in the number of word types, but also better token-to-token correspondence with the source language. Morphological segmentation is typically performed as a pre-processing step before the training phase, which results in a model that translates the source language into segmented target language. Desegmentation is the process of transforming the segmented output into a readable word sequence, The rescoring approach desegments either an n-best list (Oflazer and Durgar El-Kahlout, 2007) or lattice (Salameh et al., 2014), and then re-ranks with features that consider the desegmented word sequence of each hypothesis. Rescoring features include the score from an unsegmented target language model and contiguity indicators that flag target words that were translated from contiguous source tokens. Rescoring widens the desegmentation pipeline, allowing desegmentation features to reduce the number of translation errors. However, these features are calculated for only a subset of the search space, and the extra rescoring step complicates the training and translation processes. Phrase-table desegmentation (Luong et al"
N16-1140,W15-1011,1,0.711888,"-aware phrase extraction. The extracted phrases are constrained to contain only complete target words, without any dangling affixes. With this restriction in place, the phrase table can be desegmented before decoding begins, allowing the decoder to track features over both the segmented and desegmented target. This ensures that desegmentation features are integrated into the complete search space, and 1175 Proceedings of NAACL-HLT 2016, pages 1175–1180, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics side-steps the complications of rescoring. However, Salameh et al. (2015) show experimentally that these benefits are not worth giving up phrase-pairs with dangling affixes, which are eliminated by wordboundary-aware phrase extraction. We present a method for decoder-integrated desegmentation that combines the strengths of these two approaches. Like a rescoring approach, it places no restrictions on what morpheme sequences can appear in the target side of a phrase pair. Like phrasetable desegmentation, its desegmentation features are integrated directly into decoding and considered throughout the entire search space. We achieve this by augmenting the decoder to des"
N16-1140,D08-1076,0,\N,Missing
P07-1083,N06-1011,0,0.3652,"ognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words. Strube et al. (2002) use Edit Distance as a feature for determining if two words are coreferent. Taskar et al. (2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts. Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similari- 2 Related Work ties for spelling correction. In each of these examples, a similarity measure can"
P07-1083,W02-0902,0,0.17601,"tic similarity functions. 1 Introduction words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanese). Knowledge of cognates is useful for a number of applications, including sentence alignment (Melamed, 1999) and learning translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2002). We propose an alignment-based, discriminative approach to string similarity and evaluate this approach on cognate identification. Section 2 describes previous approaches and their limitations. In Section 3, we explain our technique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six"
P07-1083,W06-3114,0,0.0183515,"of the longer word) and Tiedemann (1999)’s highest performing system (Approach #3). Both use only the positive examples in our training set. Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by Kondrak and Sherif (2006)). 2 The cognate data sets used in our experiments are available at http://www.cs.ualberta.ca/˜bergsma/Cognates/ 5.1 Bitext Experiments For the bitext-based annotation, we use publiclyavailable word alignments from the Europarl corpus, automatically generated by GIZA++ for FrenchEnglish (Fr), Spanish-English (Es) and GermanEnglish (De) (Koehn and Monz, 2006). Initial cleaning of these noisy word pairs is necessary. We thus remove all pairs with numbers, punctuation, a capitalized English word, and all words that occur fewer than ten times. We also remove many incorrectly aligned words by filtering pairs where the pairwise Mutual Information between the words is less than 7.5. This processing leaves vocabulary sizes of 39K for French, 31K for Spanish, and 60K for German. Our labelled set is then generated from pairs with LCSR ≥ 0.58 (using the cutoff from Melamed (1999)). Each labelled set entry is a triple of a) the foreign word f , b) the cognat"
P07-1083,N03-1017,0,0.00241583,"ghlight correspondences at those positions. The pair (sutoresu, stress) can be aligned: For the feature representation, we only extract substring pairs that are consistent with this alignment. 1 That is, the letters in our pairs can only be aligned to each other and not to letters outside the pairing: { ˆ-ˆ,ˆs-ˆs, s-s, su-s, ut-t, t-t,... es-es, s-s, su-ss...} We define phrase pairs to be the pairs of substrings consistent with the alignment. A similar use of the term “phrase” exists in machine translation, where phrases are often pairs of word sequences consistent with word-based alignments (Koehn et al., 2003). By limiting the substrings to only those pairs that are consistent with the alignment, we generate fewer, more-informative features. Using more precise features allows a larger maximum substring size L than is feasible with the positional approach. Larger substrings allow us to capture important recurring deletions like the “u” in sut-st. Tiedemann (1999) and others have shown the importance of using the mismatching portions of cognate pairs to learn the recurrent spelling changes between two languages. In order to capture mismatching segments longer than our maximum substring size will allo"
P07-1083,W06-1107,1,0.574718,"Missing"
P07-1083,2005.mtsummit-papers.40,1,0.968689,"tically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words. Strube et al. (2002) use Edit Distance as a feature for determining if two words are coreferent. Taskar et al. (2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts. Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similari- 2 Related Work ties for spelling correction. In each of these ex"
P07-1083,N01-1020,0,0.784029,"discriminative and heuristic similarity functions. 1 Introduction words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanese). Knowledge of cognates is useful for a number of applications, including sentence alignment (Melamed, 1999) and learning translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2002). We propose an alignment-based, discriminative approach to string similarity and evaluate this approach on cognate identification. Section 2 describes previous approaches and their limitations. In Section 3, we explain our technique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-"
P07-1083,J99-1003,0,0.775697,"e also show strong improvements over other recent discriminative and heuristic similarity functions. 1 Introduction words having the same meaning. Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages. Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanese). Knowledge of cognates is useful for a number of applications, including sentence alignment (Melamed, 1999) and learning translation lexicons (Mann and Yarowsky, 2001; Koehn and Knight, 2002). We propose an alignment-based, discriminative approach to string similarity and evaluate this approach on cognate identification. Section 2 describes previous approaches and their limitations. In Section 3, we explain our technique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of st"
P07-1083,mulloni-pekar-2006-automatic,0,0.139568,"from a set of known cognate pairs. Ristad and Yianilos (1998) developed a stochastic transducer version of Edit Distance learned from unaligned string pairs. Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer’s probabilities into different weight classes to better approximate Edit Distance. Tiedemann (1999) used various measures to learn the recurrent spelling changes between English and Swedish, and used these changes to re-weight LCSR to identify more cognates, with modest performance improvements. Mulloni and Pekar (2006) developed a similar technique to improve NED for English/German. Essentially, all these techniques improve on the baseline approaches by using a set of positive (true) cognate pairs to re-weight the costs of edit operations or the score of sequence matches. Ideally, we would prefer a more flexible approach that can learn positive or negative weights on substring pairings in order to better identify related strings. One system that can potentially provide this flexibility is a discriminative string-similarity approach 657 to named-entity transliteration by Klementiev and Roth (2006). Although"
P07-1083,W06-2003,0,0.0572106,"7 to named-entity transliteration by Klementiev and Roth (2006). Although not compared to other similarity measures in the original paper, we show that this discriminative technique can strongly outperform traditional methods on cognate identification. Unlike many recent generative systems, the Klementiev and Roth approach does not exploit the known positions in the strings where the characters match. For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction. Rappoport and Levent-Levi (2006) apply this approach to learn substring correspondences for cognates. Zelenko and Aone (2006) recently showed a Klementiev and Roth (2006)-style discriminative approach to be superior to alignment-based generative techniques for name transliteration. Our work successfully uses the alignment-based methodology of the generative approaches to enhance the feature set for discriminative string similarity. 3 The Cognate Identification Task Given two string lists, E and F , the task of cognate identification is to find all pairs of strings (e, f ) that are cognate. In other similarity-driven applicat"
P07-1083,W02-2026,0,0.121161,"Missing"
P07-1083,W02-1040,0,0.0309944,"Missing"
P07-1083,P00-1037,0,0.148917,"traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words. Strube et al. (2002) use Edit Distance as a feature for determining if two words are coreferent. Taskar et al. (2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts. Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similari- 2 Related Work ties for spelling correction. In each of these examples, a similarity measure can make use of the recur- String similarity is a fundamental concept in a varent substring pairings that reliably occur between riety of fields and hence a range of techniques 656 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics have been developed. We focus on approaches that have been applied to words, i.e"
P07-1083,H05-1010,0,0.0249605,"xperiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words. Strube et al. (2002) use Edit Distance as a feature for determining if two words are coreferent. Taskar et al. (2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts. Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similari- 2 Related Work ties for spelling correction. In each of these examples, a similarity measure can make use of the recur- String similarity is a fundamental concept in a varent substring pairings that reliably occur between riety of fields and hence a range of techniques 656 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, c Prague, Czech Republic, June"
P07-1083,C04-1136,0,0.0265857,"data size and performance in our bitext-based French-English data. Note again that the Tiedemann and Ristad & Yanilos systems only use the positive examples in the training data. Our alignment-based similarity function outperforms all the other systems across nearly the entire range of training data. Note also that the discriminative learning curves show no signs of slowing down: performance grows logarithmically from 1K to 846K word pairs. For insight into the power of our discriminative approach, we provide some of our classifiers’ highest and lowest-weighted features (Table 4). 6 Following Evert (2004), significance was computed using Fisher’s exact test (at p = 0.05) to compare the n-best word pairs from the scored test sets, where n was taken as the number of positive pairs in the set. Gr-En (Dict.) alkali:alkali makaroni:macaroni adrenalini:adrenaline flamingko:flamingo spasmodikos:spasmodic amvrosia:ambrosia 0.7 11-pt Average Precision 0.6 0.5 0.4 Es-En (Bitext) agenda:agenda natural:natural m´argenes:margins hormonal:hormonal rad´on:radon higi´enico:hygienic 0.3 0.2 0.1 Table 5: Highest scored pairs by Alignment-Based Discriminative classifier (negative pairs in italics). NED Tiedemann"
P07-1083,W99-0626,0,0.58151,"chnique for automatically creating a cognate-identification training set. A novel aspect of this set is the inclusion of competitive counter-examples for learning. Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings. In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets. In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by Ristad and Yianilos (1998), Tiedemann (1999), Kondrak (2005), and Klementiev and Roth (2006). String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words. Strube et al. (2002) use Edit Distance as a feature for determining if two words are coreferent. Taskar et al. (2005) use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts. Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similari- 2 Related Work ties for spelling correction. In"
P07-1083,W06-1672,0,0.0444782,"rity measures in the original paper, we show that this discriminative technique can strongly outperform traditional methods on cognate identification. Unlike many recent generative systems, the Klementiev and Roth approach does not exploit the known positions in the strings where the characters match. For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction. Rappoport and Levent-Levi (2006) apply this approach to learn substring correspondences for cognates. Zelenko and Aone (2006) recently showed a Klementiev and Roth (2006)-style discriminative approach to be superior to alignment-based generative techniques for name transliteration. Our work successfully uses the alignment-based methodology of the generative approaches to enhance the feature set for discriminative string similarity. 3 The Cognate Identification Task Given two string lists, E and F , the task of cognate identification is to find all pairs of strings (e, f ) that are cognate. In other similarity-driven applications, E and F could be misspelled and correctly spelled words, or the orthographic and the ph"
P07-1109,N06-1060,0,0.128437,"rmance without making the algorithms language-specific. Many word-similarity metrics require that the strings being compared be Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 864–871, c Prague, Czech Republic, June 2007. 2007 Association for Computational Linguistics written in the same script. Levenshtein edit distance, for example, does not produce a meaningful score in the absence of character identities. Thus, if these metrics are to be used for transliteration extraction, modifications must be made to allow them to compare different scripts. Freeman et al. (2006) take the approach of manually encoding a great deal of language knowledge directly into their Arabic-English fuzzy matching algorithm. They define equivalence classes between letters in the two scripts and perform several rule-based transformations to make word pairs more comparable. This approach is unattractive for two reasons. Firstly, predicting all possible relationships between letters in English and Arabic is difficult. For example, allowances have to be made for unusual pronunciations in foreign words such as the ch in clich´e or the c in Milosevic. Secondly, the algorithm becomes com"
P07-1109,N06-1011,0,0.227792,"her, however, they cannot be considered transliterations. Error 9 is a case of two words of common origin taking on language-specific derivational endings that corrupt the phonetic match. Finally, error 10 shows a mapping ( /c) that is often correct in transliteration, but is inappropriate in this particular case. à ñJ á J  5.2 Experiment 2: Document-Aligned Named Entity Recognition The second experiment provides a more challenging task for the evaluation of the models. It is structured as a cross-language named entity recognition task similar to those outlined in (Lee and Chang, 2003) and (Klementiev and Roth, 2006). Essentially, the goal is to use a language for which named entity recognition software is readily available as a reference for tagging named entities in a language for which such software is not available. For this task, the sentence alignment of the bitext is ignored. For each named entity in an English document, the models must select a transliteration from within the document’s entire Arabic translation. This is meant to be a loose approximation of the “comparable” corpora used in (Klementiev and Roth, 2006). The comparable corpora are related documents in different languages that are not"
P07-1109,A00-2038,1,0.816531,"used Levenshtein edit distance. The algorithm simply counts the minimum number of insertions, deletions and substitutions required to convert one string into another. Levenshtein distance depends on finding identical letters, so both words must use the same alphabet. Prior to comparison, we convert the Arabic words into the Latin alphabet using the intuitive mappings for each letter shown in Table 3. The distances are also normalized by the length of the longer of the two words to avoid excessively penalizing longer words. 4.2 ALINE Unlike other algorithms presented here, the ALINE algorithm (Kondrak, 2000) operates in the phonetic, rather than the orthographic, domain. It was originally designed to identify cognates in related languages, but it can be used to compute similarity between any pair of words, provided that they are expressed in a standard phonetic notation. Individual 867 H .  H →g →k →n P   →r → sh ¬ È ð →b → th → kh p à In this section, we present two models of word similarity used for purposes of comparison. Levenshtein distance and ALINE are not language-specific per se, but require that the words being compared be written in a common script. Thus, they require some language"
P07-1109,W03-0317,0,0.220497,"to be derived from the other, however, they cannot be considered transliterations. Error 9 is a case of two words of common origin taking on language-specific derivational endings that corrupt the phonetic match. Finally, error 10 shows a mapping ( /c) that is often correct in transliteration, but is inappropriate in this particular case. à ñJ á J  5.2 Experiment 2: Document-Aligned Named Entity Recognition The second experiment provides a more challenging task for the evaluation of the models. It is structured as a cross-language named entity recognition task similar to those outlined in (Lee and Chang, 2003) and (Klementiev and Roth, 2006). Essentially, the goal is to use a language for which named entity recognition software is readily available as a reference for tagging named entities in a language for which such software is not available. For this task, the sentence alignment of the bitext is ignored. For each named entity in an English document, the models must select a transliteration from within the document’s entire Arabic translation. This is meant to be a loose approximation of the “comparable” corpora used in (Klementiev and Roth, 2006). The comparable corpora are related documents in"
P07-1109,P95-1026,0,0.298901,"tionships directly from the bitext containing the transliterations. Our model is based on the memoriless stochastic transducer proposed by Ristad and Yianilos (1998), which derives a probabilistic wordsimilarity function from a set of examples. The transducer is able to learn edit distance costs between disjoint sets of characters representing different writing scripts without any language-specific knowledge. The transducer approach, however, requires a large set of training examples, which is a limitation not present in the fuzzy matching algorithm. Thus, we propose a bootstrapping approach (Yarowsky, 1995) to train the stochastic transducer iteratively as it extracts transliterations from a bitext. The bootstrapped stochastic transducer is completely language-independent, and we show that it is able to perform at least as well as the Arabic-English specific fuzzy matching algorithm. The remainder of this paper is organized as follows. Section 2 presents our bootstrapping method to train a stochastic transducer. Section 3 outlines the Arabic-English fuzzy matching algorithm. Section 4 discusses other word-similarity models used for comparison. Section 5 describes the results of two experiments p"
P07-1109,W02-0505,0,\N,Missing
P07-1109,J98-4003,0,\N,Missing
P07-1119,P06-2025,0,0.00876202,"to several English letters, and consider these n-grams as single letters for the purpose of training. The English transliterations are produced using probabilities, learned from the training data, for the mappings between Arabic letters and English letters/n-grams. Li et al. (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. The model isolates individual mapping operations between training pairs, and then learns n-gram probabilities for sequences of these mapping operations. Ekbal et al. (2006) adapt this model to the transliteration of names from Bengali to English. 3 Letter-based Transliteration The main point of comparison for the evaluation of our substring-based models of transliteration is the letter-based transducer proposed by (Al-Onaizan and Knight, 2002). Their model is a composition of a transliteration transducer and a language transducer. Mappings in the transliteration transducer are defined between 1-3 English letters and 0-2 Arabic letters, and their probabilities are learned by EM. The transliteration transducer is split into three states to allow mapping probabilit"
P07-1119,N03-1017,0,0.0581472,"ns to go through state q, then this optimal path must include the best path up to and including q. Thus, once an optimal path to state q is found, all other paths to q can be eliminated from the search. The validity of this assumption depends on the state space used to define the model. Typically, for problems related to word comparison, a dynamic programming approach will define states as positions in the source and target words. As will be shown later, however, not all models can be represented with such a state space. The phrase-based approach developed for statistical machine translation (Koehn et al., 2003) is designed to overcome the restrictions on many-tomany mappings in word-based translation models. This approach is based on learning correspondences between phrases, rather than words. Phrases are generated on the basis of a word-to-word alignment, with the constraint that no words within the phrase pair are linked to words outside the phrase pair. In this paper, we propose to apply phrase-based translation methods to the task of machine transliteration, in an approach we refer to as substringbased transliteration. We consider two implementations of these models. The first is an adaptation o"
P07-1119,P04-1021,0,0.616644,"o Arabic letters outperforms the phoneme-toletter model. AbdulJaleel and Larkey (2003) model forward transliteration from Arabic to English by treating the words as sentences and using a statistical word alignment model to align the letters. They select common English n-grams based on cases when the alignment links an Arabic letter to several English letters, and consider these n-grams as single letters for the purpose of training. The English transliterations are produced using probabilities, learned from the training data, for the mappings between Arabic letters and English letters/n-grams. Li et al. (2004) propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more contextual information. The model isolates individual mapping operations between training pairs, and then learns n-gram probabilities for sequences of these mapping operations. Ekbal et al. (2006) adapt this model to the transliteration of names from Bengali to English. 3 Letter-based Transliteration The main point of comparison for the evaluation of our substring-based models of transliteration is the letter-based transducer proposed by (Al-Onaizan and K"
P07-1119,P02-1038,0,0.0421293,"Missing"
P07-1119,W98-1005,0,0.784462,"l net and expert systems. Their main task was to vowelize the Arabic names as a preprocessing step for transliteration. Their method is Arabic-specific and requires that the Arabic names have a regular pattern of vowelization. Knight and Graehl (1998) model the transliteration of Japanese syllabic katakana script into English with a sequence of finite-state transducers. After performing a conversion of the English and katakana sequences to their phonetic representations, the correspondences between the English and Japanese phonemes are learned with the expectation maximization (EM) algorithm. Stalls and Knight (1998) adapt this approach to Arabic, with the modification that the English phonemes are mapped directly to Arabic letters. Al-Onaizan and Knight (2002) find that a model mapping directly from English to Arabic letters outperforms the phoneme-toletter model. AbdulJaleel and Larkey (2003) model forward transliteration from Arabic to English by treating the words as sentences and using a statistical word alignment model to align the letters. They select common English n-grams based on cases when the alignment links an Arabic letter to several English letters, and consider these n-grams as single lett"
P07-1119,N04-1033,0,0.514346,"many-tomany mappings in word-based translation models. This approach is based on learning correspondences between phrases, rather than words. Phrases are generated on the basis of a word-to-word alignment, with the constraint that no words within the phrase pair are linked to words outside the phrase pair. In this paper, we propose to apply phrase-based translation methods to the task of machine transliteration, in an approach we refer to as substringbased transliteration. We consider two implementations of these models. The first is an adaptation of the monotone search algorithm outlined in (Zens and Ney, 2004).The second encodes the substringbased transliteration model as a transducer. The results of experiments on Arabic-to-English transliteration show that the substring-based transducer outperforms a state-of-the-art letter-based transducer, while at the same time being orders of magnitude smaller and faster. The remainder of the paper is organized as follows. Section 2 discusses previous approaches 945  to machine transliteration. Section 3 presents the letter-based transducer approach to Arabic-English transliteration proposed in (Al-Onaizan and Knight, 2002), which we use as the main point of"
P07-1119,W02-0505,0,\N,Missing
P07-1119,J98-4003,0,\N,Missing
P08-1065,P07-1013,0,0.364566,"Missing"
P08-1065,N07-1047,1,0.73259,"pear in both the training and test sets. This makes the problem much easier with large training sets, where the chance of this sort of overlap becomes high. Therefore, any large data results may be slightly inflated as a prediction of actual out-of-dictionary performance. 6 L2P Performance As we stated from the outset, one of our primary motivations for exploring orthographic syllabification is the improvements it can produce in L2P systems. To explore this, we tested our model in conjunction with a recent L2P system that has been shown to predict phonemes with state-of-the-art word accuracy (Jiampojamarn et al., 2007). Using a model derived from training data, this L2P system first divides a word into letter chunks, each containing one or two letters. A local classifier then predicts a number of likely phonemes for each chunk, with confidence values. A phoneme-sequence Markov model is then used to select the most likely sequence from the phonemes proposed by the local classifier. Syllabification None Numbered NB Break ONC Dictionary English 84.67 85.55 85.59 86.29 Dutch 91.56 92.60 N/A 93.03 German 90.18 90.59 N/A 90.57 Table 3: Word accuracy percentage on the letter-tophoneme task with and without the syl"
P08-1065,P01-1053,0,0.172004,"Missing"
P08-1103,W06-3206,0,0.159283,"Missing"
P08-1103,W98-1224,0,0.596528,"Missing"
P08-1103,W02-1001,0,0.537739,"sequence can propagate forward and throw off later processing. Second, each module is trained independently, and the training methods are not aware of the tasks performed later in the pipeline. For example, optimal parameters for a phoneme prediction module may vary depending on whether or not the module will be used in conjunction with a phoneme sequence model. We propose a joint approach to L2P conversion, grounded in dynamic programming and online discriminative training. We view L2P as a tagging task that can be performed with a discriminative learning method, such as the Perceptron HMM (Collins, 2002). The Perceptron HMM naturally handles phoneme prediction (#1) and sequence modeling (#3) simultaneously, as shown in Figure 1b. Furthermore, unlike a generative HMM, it can incorporate many overlapping source n-gram features to represent context. In order to complete the conversion from a pipeline approach to a joint approach, we fold our input segmentation step into the exact search framework by replacing a separate segmentation module (#2) with a monotone phrasal decoder (Zens and Ney, 2004). At this point all three of our desiderata are incorporated into a single module, 907 as shown in Fi"
P08-1103,P07-1013,0,0.269044,"Missing"
P08-1103,2005.iwslt-1.22,0,0.0906111,"Missing"
P08-1103,N07-1047,1,0.927132,"ks, called letter-to-phoneme alignment, is not always straightforward. For example, consider the word “phoenix” and its corresponding phoneme sequence [f i n I k s], where we encounter cases of two letters generating a single phoneme (ph→f), and a single letter generating two phonemes (x→k s). Fortunately, alignments between letters and phonemes can be discovered reliably with unsupervised generative models. Originally, L2P systems assumed one-to-one alignment (Black et al., 1998; Damper et al., 2005), but recently many-to-many alignment has been shown to perform better (Bisani and Ney, 2002; Jiampojamarn et al., 2007). Given such an alignment, L2P can be viewed either as a sequence of classification problems, or as a sequence modeling problem. In the classification approach, each phoneme is predicted independently using a multi-class classifier such as decision trees (Daelemans and Bosch, 1997; Black et al., 1998) or instance-based learning (Bosch and Daelemans, 1998). These systems predict a phoneme for each input letter, using the letter and its context as features. They leverage the structure of the input but ignore any structure in the output. L2P can also be viewed as a sequence modeling, or tagging p"
P08-1103,N06-1030,0,0.23683,"Missing"
P08-1103,J00-2003,0,0.326833,"for each input letter, using the letter and its context as features. They leverage the structure of the input but ignore any structure in the output. L2P can also be viewed as a sequence modeling, or tagging problem. These approaches model the structure of the output, allowing previously predicted phonemes to inform future decisions. The supervised Hidden Markov Model (HMM) applied by Taylor (2005) achieved poor results, mostly because its maximum-likelihood emission probabilities cannot be informed by the emitted letter’s context. Other approaches, such as those of Bisani and Ney (2002) and Marchand and Damper (2000), have shown that better performance can be achieved by pairing letter substrings with phoneme substrings, allowing context to be captured implicitly by these groupings. Recently, two hybrid methods have attempted to capture the flexible context handling of classification-based methods, while also modeling the sequential nature of the output. The 906 constraint satisfaction inference (CSInf) approach (Bosch and Canisius, 2006) improves the performance of instance-based classification (Bosch and Daelemans, 1998) by predicting for each letter a trigram of phonemes consisting of the previous, cur"
P08-1103,N04-1033,0,0.119611,"s a tagging task that can be performed with a discriminative learning method, such as the Perceptron HMM (Collins, 2002). The Perceptron HMM naturally handles phoneme prediction (#1) and sequence modeling (#3) simultaneously, as shown in Figure 1b. Furthermore, unlike a generative HMM, it can incorporate many overlapping source n-gram features to represent context. In order to complete the conversion from a pipeline approach to a joint approach, we fold our input segmentation step into the exact search framework by replacing a separate segmentation module (#2) with a monotone phrasal decoder (Zens and Ney, 2004). At this point all three of our desiderata are incorporated into a single module, 907 as shown in Figure 1c. Our joint approach to L2P lends itself to several refinements. We address an underfitting problem of the perceptron by replacing it with a more robust Margin Infused Relaxed Algorithm (MIRA), which adds an explicit notion of margin and takes into account the system’s current n-best outputs. In addition, with all of our features collected under a unified framework, we are free to conjoin context features with sequence features to create a powerful linearchain model (Sutton and McCallum,"
P08-1103,P02-1019,0,\N,Missing
P09-1014,P09-1015,1,0.885144,"Missing"
P09-1014,N07-1047,1,0.859949,"sed in our experiments. Finally, we provide the results. 5.1 The L2P system We combine stress prediction with a state-of-theart L2P system (Jiampojamarn et al., 2008). Like our stress ranker, their system is a data-driven sequence predictor that is trained with supervised learning. The score for each output sequence is a weighted combination of features. The feature weights are trained using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003), a powerful online discriminative training framework. Like other recent L2P systems (Bisani and Ney, 2002; Marchand and Damper, 2007; Jiampojamarn et al., 2007), this approach does not generate stress, nor does it consider stress when it generates phonemes. For L2P experiments, we use the same training, testing, and development data as was used in Section 4. For all experiments, we use the development set to determine at which iteration to stop training in the online algorithm. 5.2 1) J OINT : The L2P system’s input sequence is letters, the output sequence is phonemes+stress. 2) J OINT +C ONSTR : Same as J OINT , except it selects the highest scoring output that obeys the stress pattern constraint. 3) P OST P ROCESS : The L2P system’s input is letter"
P09-1014,P08-1103,1,0.85482,"idance for the assignment of secondary stress. Inspired by the aforementioned strategies, we evaluate the following approaches: 5 Lexical stress and L2P conversion In this section, we evaluate various methods of combining stress prediction with phoneme generation. We first describe the specific system that we use for letter-to-phoneme (L2P) conversion. We then discuss the different ways stress prediction can be integrated with L2P, and define the systems used in our experiments. Finally, we provide the results. 5.1 The L2P system We combine stress prediction with a state-of-theart L2P system (Jiampojamarn et al., 2008). Like our stress ranker, their system is a data-driven sequence predictor that is trained with supervised learning. The score for each output sequence is a weighted combination of features. The feature weights are trained using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003), a powerful online discriminative training framework. Like other recent L2P systems (Bisani and Ney, 2002; Marchand and Damper, 2007; Jiampojamarn et al., 2007), this approach does not generate stress, nor does it consider stress when it generates phonemes. For L2P experiments, we use the same train"
P09-1014,P08-1065,1,0.841252,"first and the third syllable are stressed, with the former receiving weaker emphasis than the latter. In this case, the initial syllable is said to carry a secondary stress. Although each word has only one primary stress, it may have any number of secondary stresses. Predicting the full stress pattern is therefore inherently more difficult than predicting the location of primary stress only. Our objective is to automatically assign primary and, where possible, secondary stress to out-ofvocabulary words. Stress is an attribute of syllables, but syllabification is a non-trivial task in itself (Bartlett et al., 2008). Rather than assuming correct syllabification of the input word, we instead follow Webster (2004) in placing the stress on the vowel which constitutes the nucleus of the stressed syllable. If the syllable boundaries are known, the mapping from the vowel to the corresponding syllable is straightforward. We investigate the assignment of stress to two related but different entities: the spoken word (represented by its phonetic transcription), and the written word (represented by its orthographic form). Although stress is a prosodic feature, assigning stress to written words (“stressed orthograph"
P09-1014,P85-1030,0,0.864481,"boundaries, or whether a vowel letter sequence represents one or more spoken vowels (e.g., beating vs. be-at-i-fy). There is a long history of research into the principles governing lexical stress placement. Zipf (1929) showed that stressed syllables are often those with low frequency in speech, while unstressed syllables are usually very common. Chomsky and Halle (1968) proposed a set of context-sensitive rules for producing English stress from underlying word forms. Due to its importance in text-to-speech, there is also a long history of computational stress prediction systems (Fudge, 1984; Church, 1985; Williams, 1987). While these early approaches depend on human definitions of vowel tensity, syllable weight, word etymology, etc., our work follows a recent trend of purely data-driven approaches to stress prediction (Black et al., 1998; Pearson et al., 2000; Webster, 2004; Demberg et al., 2007). In many languages, only two levels of stress are distinguished: stressed and unstressed. However, some languages exhibit more than two levels of stress. For example, in the English word economic, the first and the third syllable are stressed, with the former receiving weaker emphasis than the latter"
P09-1014,J05-1003,0,0.0592415,"mes will always generate the correct number of syllables. For letters, splitting may result in a different number of units than the true syllabification, e.g., pronounce → ron-no-un-ce. This does not prevent the system from producing the correct stress assignment after the pattern-to-vowel mapping stage (Section 3.3) is complete. 1 120 See (Dou, 2009) for more details. Substring needed here, we can exploit longer-range features. Choosing the highest-scoring output from a fixed set is a ranking problem, and we provide the full ranking formulation below. Unlike previous ranking approaches (e.g. Collins and Koo (2005)), we do not rely on a generative model to produce a list of candidates. Candidates are chosen in advance from observed training patterns. 3.2.1 Context Stress Pattern Table 2: Feature Template Ranking Formulation For a substring sequence, s, of length N , our task is to select the correct output pattern from the set of all length-N patterns observed in our training data, a set we denote as TN . We score each possible input-output combination using a linear model. Each substring sequence and possible output pattern, (s, t), is represented with a set of features, Φ(s, t). The score for a partic"
P09-1014,W02-1001,0,0.0126056,"sequence the stress pattern for a word. Table 1 gives examples of words, substrings, and stress patterns. We use supervised learning to train a system to predict the stress pattern. We generate training (s, t) pairs in the obvious way from our stressmarked training words, w. ¯ That is, we first extract the letter/phoneme portion, w, and use it to create the substrings, s. We then create the stress pattern, t, using w’s ¯ stress markers. Given the training pairs, any sequence predictor can be used, for example a Conditional Random Field (CRF) (Lafferty et al., 2001) or a structured perceptron (Collins, 2002). However, we can take advantage of a unique property of our problem to use a more expressive framework than is typically used in sequence prediction. The key observation is that the output space of possible stress patterns is actually fairly limited. Clopper (2002) shows that people have strong preferences for particular sequences of stress, and this is confirmed by our training data (Section 4.1). In English, for example, we find that for each set of spoken words with the same number of syllables, there are no more than fifteen different stress patterns. In total, among 55K English training"
P09-1014,P07-1013,0,0.214572,"Missing"
P09-1015,P08-1103,1,0.868195,"ion is to produce a correct sequence of phonemes, given the letters that comprise a word. An accurate L2P converter is an important component of a text-to-speech system. In general, a lookup table does not suffice for L2P conversion, since out-of-vocabulary words (e.g., proper names) are inevitably encountered. This motivates the need for classification techniques that can predict the phonemes for an unseen word. Numerous studies have contributed to the development of increasingly accurate L2P systems (Black et al., 1998; Kienappel and Kneser, 2001; Bisani and Ney, 2002; Demberg et al., 2007; Jiampojamarn et al., 2008). A common assumption made in these works is that ample amounts of labelled data are available for training a classifier. Yet, in practice, this is the case for only a small number of languages. In order to train an L2P classifier for a new language, we must first annotate words in that language with their correct phoneme sequences. As annotation is expensive, we would 127 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 127–135, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP Sections 7 and 8, respectively. Finally, Section 9 offers some conclu"
P09-1015,J92-4003,0,0.00958218,"nd employs a variety of different pruning strategies; the portion of the gains attributable to letter clustering are not evident. In addition to exploring the effect of letter clustering on a wider range of languages, we are particularly concerned with the impact that clustering has on decision tree performance when the training set is small. The addition of letter class features to the data may enable the active learner to better evaluate candidate words in the pool, and therefore make more informed selections. To group the letters into classes, we employ a hierarchical clustering algorithm (Brown et al., 1992). One advantage of inducing a hierarchy is that we need not commit to a particular level of granularity; in other words, we are not required to specify the number of classes beforehand, as is the case with some other clustering algorithms.1 The clustering algorithm is initialized by placing each letter in its own class, and then proceeds in a bottom-up manner. At each step, the pair of classes is merged that leads to the smallest loss in the average mutual information (Manning and Schütze, 1999) between adjacent classes. The merging process repeats until a single class remains that contains al"
P09-1015,W09-3504,1,0.897586,"Missing"
P09-1015,N06-1030,0,0.20637,"apping technique that iteratively requests the labels of the n most frequent words in a corpus. A classifier is trained on the words that have been annotated thus far, and then predicts the phonemes for each of the n words being considered. Words for which the prediction confidence is above a certain threshold are immediately added to the lexicon, while the remaining words must be verified (and corrected, if necessary) by a human annotator. The main drawback of such an approach lies in the risk of adding erroneous entries to the lexicon when the classifier is overly confident in a prediction. Kominek and Black (2006) devise a word selection strategy based on letter n-gram coverage and word length. Their method slightly outperforms random selection, thereby establishing passive learning as a strong baseline. However, only a single Italian dataset was used, and the results do not necessarily generalize to other languages. In this paper, we propose to apply an active learning technique known as Query-byBagging (Abe and Mamitsuka, 1998). We consider a pool-based active learning setting, whereby the learner has access to a pool of unlabelled examples (words), and may obtain labels (phoneme sequences) at a cost"
P09-1015,A00-2038,1,0.842738,"terested in mapping each letter to either a single phoneme or the “null” phoneme. The standard approach to L2P alignment is described by Damper et al. (2005). It performs an Expectation-Maximization (EM) procedure that takes a (preferably large) collection of words as input and computes alignments for them simultaneously. However, since in our active learning setting the data is acquired incrementally, we cannot count on the initial availability of a substantial set of words accompanied by their phonemic transcriptions. In this paper, we apply the ALINE algorithm to the task of L2P alignment (Kondrak, 2000; Inkpen et al., 2007). ALINE, which performs phonetically-informed alignment of two strings of phonemes, requires no training data, and so is ideal for our purposes. Since our task requires the alignment of phonemes with letters, we wish to replace every letter with a phoneme that is the most likely to be produced by that letter. On the other hand, we would like our approach to be languageindependent. Our solution is to simply treat every letter as an IPA symbol (International Phonetic Association, 1999). The IPA is based on the Roman alphabet, but also includes a number of other symbols. The"
P09-1015,N04-4028,0,0.0130526,"l that maximizes the disagreement among the predictions of the committee members is selected. A crucial question is how to calculate the disagreement among the predicted phoneme sequences for a word in the pool. In the L2P domain, we assume that a human annotator specifies the phonemes for an entire word, and that the active learner cannot query individual letters. We require a measure of confidence at the word level; yet, our classifiers make predictions at the letter level. This is analogous to the task of estimating record confidence using field confidence scores in information extraction (Culotta and McCallum, 2004). Our solution is as follows. Let w be a word in the pool. Each classifier Ci predicts the phoneme for each letter l ∈ w. These “votes” are aggregated to produce a vector vl for letter l that indicates the distribution of the |C |predictions over its possible phonemes. We then compute the margin for each letter: If {p, p0 } ∈ vl are the two highest vote totals, then the margin is M (vl ) = |p − p0 |. A small margin indicates disagreement among the constituent classifiers. We define the disagreement score for the entire word as the minimum margin: Whereas a passive supervised learning algorithm"
P09-1015,N04-1043,0,0.20416,"rst bit distinguishes vowels from consonants, meaning that these were the last two groups that were merged by the clustering algorithm. Note also that the beginning/end of word marker (#) is included in the hierarchy, and is the last character to be absorbed into a larger cluster. This indicates that # carries more information than most letters, as is to be expected, in light of its distinct status. We also experimented with a manually-constructed letter hierarchy, but observed no significant differences in accuracy visà-vis the automatic clustering. 1 This approach is inspired by the work of Miller et al. (2004), who clustered words for a named-entity tagging task. 129 5 Active learning set, the classifier is re-trained, and the process repeats until some stopping criterion is met (e.g., annotation resources are exhausted). Query-by-Bagging (QBB) is an instance of the Query-by-Committee algorithm (Freund et al., 1997), which selects examples that have high classification variance. At each iteration, QBB employs the bagging procedure (Breiman, 1996) to create a committee of classifiers C. Given a training set T containing k examples (in our setting, k is the total number of letters that have been labe"
P09-1015,D08-1112,0,0.0176582,"ly demonstrate that unlabelled data can be used more efficiently, resulting in greater accuracy for a given training set size, without any additional tuning for the different languages. The experiments also show that a phonetically-based aligner may be preferable to the widely-used EM alignment technique, a discovery that could lead to the improvement of L2P accuracy in general. While this work represents an important step in reducing the cost of constructing an L2P training set, we intend to explore other active learners and classification algorithms, including sequence labelling strategies (Settles and Craven, 2008). We also plan to incorporate user-centric enhancements (Davel and Barnard, 2004; Culotta and McCallum, 2005) with the aim of reducing both the effort and expertise that is required to annotate words with their phoneme sequences. 60 50 40 30 20 Complete System Baseline 10 5 Spanish 15 10 Number of training words (x100) Italian + 0 French Dutch + German 20 English Figure 2: Performance of the complete system 8.5 Complete system The complete system consists of context ordering, clustering, Query-by-Bagging, and ALINE; the baseline represents random sampling with EM alignment and no additional en"
P09-1015,P07-1013,0,0.0630884,"-phoneme (L2P) conversion is to produce a correct sequence of phonemes, given the letters that comprise a word. An accurate L2P converter is an important component of a text-to-speech system. In general, a lookup table does not suffice for L2P conversion, since out-of-vocabulary words (e.g., proper names) are inevitably encountered. This motivates the need for classification techniques that can predict the phonemes for an unseen word. Numerous studies have contributed to the development of increasingly accurate L2P systems (Black et al., 1998; Kienappel and Kneser, 2001; Bisani and Ney, 2002; Demberg et al., 2007; Jiampojamarn et al., 2008). A common assumption made in these works is that ample amounts of labelled data are available for training a classifier. Yet, in practice, this is the case for only a small number of languages. In order to train an L2P classifier for a new language, we must first annotate words in that language with their correct phoneme sequences. As annotation is expensive, we would 127 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 127–135, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP Sections 7 and 8, respectively. Finally,"
P10-1080,W06-3206,0,0.0505112,"Missing"
P10-1080,P07-1013,0,0.0328331,"Missing"
P10-1080,2005.iwslt-1.22,0,0.0207123,"algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets. 1 Introduction Letter-to-phoneme (L2P) conversion (also called grapheme-to-phoneme conversion) is the task of predicting the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phone"
P10-1080,N07-1047,1,0.61603,"d 780 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 780–788, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics 2 Background example, a double phoneme U would replace a sequence of the phonemes j and u in Figure 1. This solution requires a manual extension of the set of phonemes present in the data. By convention, we regard the models that include a restricted set of 1-2 mappings as 1-1 models. Advanced L2P approaches, including the joint n-gram models (Bisani and Ney, 2008) and the joint discriminative approach (Jiampojamarn et al., 2007) eliminate the one-to-one constraint entirely, allowing for linking of multiple letters to multiple phonemes. We refer to such models as many-to-many (M-M) models. We define the letter-phoneme alignment task as the problem of inducing links between units that are related by pronunciation. Each link is an instance of a specific mapping between letters and phonemes. The leftmost example alignment of the word accuse [@kjuz] below includes 1-1, 1-0, 12, and 2-1 links. The letter e is considered to be linked to special null phoneme. 3 EM Alignment Figure 1: Two alignments of accuse. Early EM-based"
P10-1080,N04-1033,0,0.0169701,"roach tends to create relatively large models, it generates more intuitive alignments and leads to improvement in the L2P accuracy (Jiampojamarn et al., 2007). However, since many links involve multiple letters, it also introduces additional complexity in the phoneme prediction phase. One possible solution is to apply a letter segmentation algorithm at test time to cluster letters according to the alignments in the training data. This is problematic because of error propagation inherent in such a process. A better solution is to combine segmentation and decoding using a phrasal decoder (e.g. (Zens and Ney, 2004)). 1 2 ALINE can also be applied to non-Latin scripts by replacing every grapheme with the IPA symbol that is phonetically closest to it. http://code.google.com/p/m2m-aligner/ 782 s | S h | - e | i a | - t | T h | - randomly choose one of them. Furthermore, we extend this idea also to many-to-many alignments. In addition to lists of phonemes for each letter (11 mappings), we also construct lists of many-tomany mappings, such as ee:i, sch:S, and ew:ju. In total, the English set contains 377 mappings, of which more than half are of the 2-1 type. Since ALINE is designed to align phonemes with pho"
P10-1080,P08-1103,1,0.861377,"Missing"
P10-1080,A00-2038,1,0.796377,"mid-high rounded vowel in Classical Latin and is still generally used to represent similar vowels. The following simple heuristic works well for a number of languages: treat every letter as if it were a symbol in the International Phonetic Alphabet (IPA). The set of symbols employed by the IPA includes the 26 letters of the Latin alphabet, which tend to correspond to the phonemes that they represent in the Latin script. For example, the IPA symbol [m] denotes a voiced bilabial nasal consonant, which is the phoneme represented by the letter m in most languages that utilize Latin script. ALINE (Kondrak, 2000) performs phonetic alignment of two strings of phonemes. It combines a dynamic programming alignment algorithm with an appropriate scoring scheme for computing phonetic similarity on the basis of multivalued features. The example below shows the alignment of the word sheath to its phonetic transcription [SiT]. ALINE correctly links the most similar pairs of phonemes (s:S, e:i, t:T).2 ,ǫ)βt,v γ(xtt−i+1 , ǫ) + = t−i,v αt−i+1 T ,V for i = 1..maxX st t − i ≥ 0 do for j = 1..maxY st v − j ≥ 0 do 8 9 10 t v 11 γ(xt−i+1 , yv−j+1 ) += v αt−i,v−j δ(xtt−i+1 ,yv−j+1 )βt,v αT ,V maxX and maxY parameters."
P10-1080,J00-2003,0,0.0366562,"the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phonemes, these must be inferred 780 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 780–788, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics 2 Background example"
P10-1080,P09-1016,0,0.0405001,"r e z - 6.1 Combining IP with EM p h r a s e - f r e z - Figure 3: Two alignments of phrase. The set of allowable letter-phoneme mappings can also be used as an input to the EM alignment algorithm. We call this approach IP-EM. After inducing the minimal set of letter-phoneme mappings, we constrain EM to use only those mappings with In order to generate the list of best alignments, we use Algorithm 2, which is an adaptation of the standard Viterbi algorithm. Each cell Qt,v contains a list of n-best scores that correspond to al784 Alignment entropy is a measure of alignment quality proposed by Pervouchine et al. (2009) in the context of transliteration. The entropy indicates the uncertainty of mapping between letter l and phoneme p resulting from the alignment: We compute the alignment entropy for each of the methods using the following formula: Algorithm 2: Extracting n-best alignments Input: x, y, δ Output: QT,V 1 2 3 4 5 6 7 8 9 10 11 T = |x |+ 1 , V = |y |+ 1 for t = 1..T do Qt,v = ∅ for v = 1..V do for q ∈ Qt−1,v do append q · δ(xt , ǫ) to Qt,v for j = 1..maxY st v − j ≥ 0 do for q ∈ Qt−1,v−j do v append q · δ(xt , yv−j+1 ) to Qt,v sort Qt,v Qt,v = Qt,v [1 : n] H=− P (l, p) log P (l|p) (7) l,p Table 1"
P10-1080,P02-1019,0,\N,Missing
P11-1041,P07-1092,0,0.0465206,"eographical names. However, it is unclear whether such an approach would be able to improve the performance of the current state-of-the-art G2P systems. In addition, the P2P approach works only on single outputs, whereas our re-ranking approach is designed to handle n-best output lists. Although our approach is (to the best of our knowledge) the first to use different tasks (G2P and transliteration) to inform each other, this is conceptually similar to model and system combination approaches. In statistical machine translation (SMT), methods that incorporate translations from other languages (Cohn and Lapata, 2007) have proven effective in low-resource situations: when phrase translations are unavailable for a certain language, one can look at other languages where the translation is available and then translate from that language. A similar pivoting approach has also been applied to machine transliteration (Zhang et al., 2010). Notably, the focus of these works have been on cases in which there are less data available; they also modify the generation process directly, rather than operating on existing outputs as we do. Ultimately, a combination of the two approaches is likely to give the best results."
P11-1041,W10-2406,0,0.219192,"ne obvious problem with this method is that it ignores the relative ordering of the n-best lists and their corresponding scores produced by the base system. A better approach is to combine the similarity score with the output score from the base system, allowing it to contribute an estimate of confidence in its output. For this purpose, we apply a linear combination of the two scores, where a single parameter λ, ranging between zero and one, determines the relative weight of the scores. The exact value of λ can be optimized on a training set. This approach is similar 400 to the method used by Finch and Sumita (2010) to combine the scores of two different machine transliteration systems. 2.3 Measuring similarity The approaches presented in the previous section crucially depend on a method for computing the similarity between various symbol sequences that represent the same word. If we have a method of converting transliterations to phonetic representations, the similarity between two sequences of phonemes can be computed with a simple method such as normalized edit distance or the longest common subsequence ratio, which take into account the number and position of identical phonemes. Alternatively, we cou"
P11-1041,P10-1080,1,0.850035,"duction for three very different G2P base systems. 2 Improving G2P with transliterations 2.1 Problem definition In both G2P and machine transliteration, we are interested in learning a function that, given an input sequence x, produces an output sequence y. In the G2P task, x is composed of graphemes and y is composed of phonemes; in transliteration, both sequences consist of graphemes but they represent different writing scripts. Unlike in machine translation, the monotonicity constraint is enforced; i.e., we assume that x and y can be aligned without the alignment links crossing each other (Jiampojamarn and Kondrak, 2010). We assume that we have available a base G2P system that produces an n-best list of outputs with a corresponding list of confidence scores. The goal is to improve the base system’s performance by applying existing transliterations of the input x to re-rank the system’s n-best output list. 2.2 Similarity-based methods A simple and intuitive approach to improving G2P with transliterations is to select from the n-best list the output sequence that is most similar to the corresponding transliteration. For example, the Hindi transliteration in Figure 1 is arguably closest in perceptual terms to th"
P11-1041,N07-1047,1,0.848942,"dentical phonemes. Alternatively, we could apply a more complex approach, such as ALINE (Kondrak, 2000), which computes the distance between pairs of phonemes. However, the implementation of a conversion program would require ample training data or language-specific expertise. A more general approach is to skip the transcription step and compute the similarity between phonemes and graphemes directly. For example, the edit distance function can be learned from a training set of transliterations and their phonetic transcriptions (Ristad and Yianilos, 1998). In this paper, we apply M2M-A LIGNER (Jiampojamarn et al., 2007), an unsupervised aligner, which is a many-to-many generalization of the learned edit distance algorithm. M2M-A LIGNER was originally designed to align graphemes and phonemes, but can be applied to discover the alignment between any sets of symbols (given training data). The logarithm of the probability assigned to the optimal alignment can then be interpreted as a similarity measure between the two sequences. 2.4 Discriminative re-ranking The methods described in Section 2.2, which are based on the similarity between outputs and transliterations, are difficult to generalize when multiple tran"
P11-1041,W09-3504,1,0.925287,"Missing"
P11-1041,N10-1103,1,0.931836,"transliteration-transcription pairs and system output scores for input-output pairs. One feature vector is constructed for each system output. to the problem. Our re-ranking system is informed by a large number of features, which are based on scores and n-grams. The scores are of three types: 1. The scores produced by the base system for each output in the n-best list. 2. The similarity scores between the outputs and each available transliteration. 3. The differences between scores in the n-best lists for both (1) and (2). Our set of binary n-gram features includes those used for D IREC TL+ (Jiampojamarn et al., 2010). They can be divided into four types: 1. The context features combine output symbols (phonemes) with n-grams of varying sizes in a window of size c centred around a corresponding position on the input side. 2. The transition features are bigrams on the output (phoneme) side. 3. The linear chain features combine the context features with the bigram transition features. 4. The joint n-gram features are n-grams containing both input and output symbols. We apply the features in a new way: instead of being applied strictly to a given input-output set, we expand their use across many languages and"
P11-1041,A00-2038,1,0.690537,"ransliteration systems. 2.3 Measuring similarity The approaches presented in the previous section crucially depend on a method for computing the similarity between various symbol sequences that represent the same word. If we have a method of converting transliterations to phonetic representations, the similarity between two sequences of phonemes can be computed with a simple method such as normalized edit distance or the longest common subsequence ratio, which take into account the number and position of identical phonemes. Alternatively, we could apply a more complex approach, such as ALINE (Kondrak, 2000), which computes the distance between pairs of phonemes. However, the implementation of a conversion program would require ample training data or language-specific expertise. A more general approach is to skip the transcription step and compute the similarity between phonemes and graphemes directly. For example, the edit distance function can be learned from a training set of transliterations and their phonetic transcriptions (Ristad and Yianilos, 1998). In this paper, we apply M2M-A LIGNER (Jiampojamarn et al., 2007), an unsupervised aligner, which is a many-to-many generalization of the lear"
P11-1041,yang-etal-2006-development,0,0.0313588,"Missing"
P11-1041,C10-2165,0,0.220832,"est of our knowledge) the first to use different tasks (G2P and transliteration) to inform each other, this is conceptually similar to model and system combination approaches. In statistical machine translation (SMT), methods that incorporate translations from other languages (Cohn and Lapata, 2007) have proven effective in low-resource situations: when phrase translations are unavailable for a certain language, one can look at other languages where the translation is available and then translate from that language. A similar pivoting approach has also been applied to machine transliteration (Zhang et al., 2010). Notably, the focus of these works have been on cases in which there are less data available; they also modify the generation process directly, rather than operating on existing outputs as we do. Ultimately, a combination of the two approaches is likely to give the best results. Finch and Sumita (2010) combine two very different approaches to transliteration using simple linear interpolation: they use S EQUITUR’s n-best outputs and re-rank them using a linear combination of the original S EQUITUR score and the score for that output of a phrased-based SMT system. The linear weights are hand-tu"
P11-1041,W09-3501,0,\N,Missing
P11-1041,W10-2401,0,\N,Missing
P11-1041,W09-3502,0,\N,Missing
P13-1129,P10-1015,0,0.536872,"Missing"
P13-1129,P05-1045,0,0.007312,"ters, and can be compiled with the help of web resources, such as Wikipedia, or study guides, such as CliffsNotesT M . This preprocessing step could also be performed automatically using a canonicalization method (Andrews et al., 2012); however, since our focus is on speaker identification, we decided to avoid introducing annotation errors at this stage. Other preprocessing steps that are required for processing a new novel include standarizing the typographical conventions, and performing POS tagging, NER tagging, and dependency parsing. We utilize the Stanford tools (Toutanova et al., 2003; Finkel et al., 2005; Marneffe et al., 2006). 7 Evaluation In this section, we describe experiments conducted to evaluate our speaker identification approach. We refer to our main model as N EIGHBORS, because it incorporates features from the neighboring utterances, as described in Section 4.3. In contrast, the I NDIVIDUAL model relies only on features from the current utterance. In an attempt to reproduce the evaluation methodology of EM2010, we also test the O RACLE model, which has access to the gold-standard information about the speakers of eight neighboring utterances in the Pride & P. 42.0 77.8 82.5 86.5 E"
P13-1129,krestel-etal-2008-minding,0,0.0131767,"iven utterance, they assume that all previous utterances are already correctly assigned to their speakers. Our approach differs in considering the utterances in a sequence, rather than independently from each other, and in removing the unrealistic assumption that the previous utterances are correctly identified. The speaker identification task has also been investigated in other domains. Bethard et al. (2004) identify opinion holders by using semantic parsing techniques with additional linguistic features. Pouliquen et al. (2007) aim at detecting direct speech quotations in multilingual news. Krestel et al. (2008) automatically tag speech sentences in newspaper articles. Finally, Ruppenhofer et al. (2010) implement a rule-based system to enrich German cabinet protocols with automatic speaker attribution. 3 Definitions and Conventions In this section, we introduce the terminology used in the remainder of the paper. Our definitions are different from those of EM2010 partly because we developed our method independently, and partly because we disagree with some of their choices. The examples are from Jane Austen’s Pride and Prejudice, which was the source of our development set. An utterance is a connected"
P13-1129,de-marneffe-etal-2006-generating,0,0.00413514,"Missing"
P13-1129,D12-1032,0,0.0155865,"d to produce a list of characters in the novel and their aliases. For example, Elizabeth Bennet may be referred to as Liz, Lizzy, Miss Lizzy, Miss Bennet, Miss Eliza, and Miss Elizabeth Bennet. We apply a name entity tagger, and then group the names into sets of character aliases, together with their gender information. The sets of aliases are typically small, except for major characters, and can be compiled with the help of web resources, such as Wikipedia, or study guides, such as CliffsNotesT M . This preprocessing step could also be performed automatically using a canonicalization method (Andrews et al., 2012); however, since our focus is on speaker identification, we decided to avoid introducing annotation errors at this stage. Other preprocessing steps that are required for processing a new novel include standarizing the typographical conventions, and performing POS tagging, NER tagging, and dependency parsing. We utilize the Stanford tools (Toutanova et al., 2003; Finkel et al., 2005; Marneffe et al., 2006). 7 Evaluation In this section, we describe experiments conducted to evaluate our speaker identification approach. We refer to our main model as N EIGHBORS, because it incorporates features fr"
P13-1129,ruppenhofer-etal-2010-speaker,0,0.132859,"o their speakers. Our approach differs in considering the utterances in a sequence, rather than independently from each other, and in removing the unrealistic assumption that the previous utterances are correctly identified. The speaker identification task has also been investigated in other domains. Bethard et al. (2004) identify opinion holders by using semantic parsing techniques with additional linguistic features. Pouliquen et al. (2007) aim at detecting direct speech quotations in multilingual news. Krestel et al. (2008) automatically tag speech sentences in newspaper articles. Finally, Ruppenhofer et al. (2010) implement a rule-based system to enrich German cabinet protocols with automatic speaker attribution. 3 Definitions and Conventions In this section, we introduce the terminology used in the remainder of the paper. Our definitions are different from those of EM2010 partly because we developed our method independently, and partly because we disagree with some of their choices. The examples are from Jane Austen’s Pride and Prejudice, which was the source of our development set. An utterance is a connected text that can be attributed to a single speaker. Our task is to associate each utterance wit"
P13-1129,N03-1033,0,0.00321527,"except for major characters, and can be compiled with the help of web resources, such as Wikipedia, or study guides, such as CliffsNotesT M . This preprocessing step could also be performed automatically using a canonicalization method (Andrews et al., 2012); however, since our focus is on speaker identification, we decided to avoid introducing annotation errors at this stage. Other preprocessing steps that are required for processing a new novel include standarizing the typographical conventions, and performing POS tagging, NER tagging, and dependency parsing. We utilize the Stanford tools (Toutanova et al., 2003; Finkel et al., 2005; Marneffe et al., 2006). 7 Evaluation In this section, we describe experiments conducted to evaluate our speaker identification approach. We refer to our main model as N EIGHBORS, because it incorporates features from the neighboring utterances, as described in Section 4.3. In contrast, the I NDIVIDUAL model relies only on features from the current utterance. In an attempt to reproduce the evaluation methodology of EM2010, we also test the O RACLE model, which has access to the gold-standard information about the speakers of eight neighboring utterances in the Pride & P."
P14-1010,P08-2039,0,0.532592,"gmentation strategies recommended by previous work: the Penn Arabic Treebank scheme for English-Arabic (El Kholy and Habash, 2012a), and an unsupervised scheme for EnglishFinnish (Clifton and Sarkar, 2011). Desegmentation is the process of converting segmented words into their original surface form. For many segmentations, especially unsupervised ones, this amounts to simple concatenation. However, more complex segmentations, such as the Arabic tokenization provided by MADA (Habash et al., 2009), require further orthographic adjustments to reverse normalizations performed during segmentation. Badr et al. (2008) present two Arabic desegmentation schemes: table-based and rule-based. El Kholy and Habash (2012a) provide an extensive study on the influence of segmentation and desegmentation on English-toArabic SMT. They introduce an additional desegmentation technique that augments the table-based approach with an unsegmented language model. Salameh et al. (2013) replace rule-based desegmentation with a discriminatively-trained character transducer. In this work, we adopt the Table+Rules approach of El Kholy and Habash (2012a) for English-Arabic, while concatenation is sufficient for English-Finnish. Wor"
P14-1010,P07-1019,0,0.027739,"nodes that lie on the boundary between words, and for each node on this list, it launches a depth first search Programmatic Desegmentation Lattice desegmentation is a non-local lattice transformation. That is, the morphemes forming a word might span several edges, making desegmentation non-trivial. Luong et al. (2010) address this problem by forcing the decoder’s phrase table to respect word boundaries, guaranteeing that each desegmentable token sequence is local to an edge. 4 5 Or the LM composition can be done dynamically, effectively decoding the lattice with a beam or cube-pruned search (Huang and Chiang, 2007). Sentence-initial suffix morphemes and sentence-final prefix morphemes represent a special case that we omit for the sake of brevity. Lacking stems, they are left segmented. 104 3.4 Algorithm 1 Desegment a lattice hns , N , Ei {Initialize output lattice and work list WL} n0s = ns , N 0 = ∅, E 0 = ∅, WL = [ns ] while n = WL.pop() do {Work on each node only once} if n ∈ N 0 then continue N 0 = N 0 ∪ {n} {Initialize the chain stack C} C=∅ for e ∈ n.out do if [e] is valid then C.push([e]) {Depth-first search for complete chains} while [e1 , . . . , el ] = C.pop() do {Attempt to extend chain} for"
P14-1010,W07-0735,0,0.0238566,"r work, they replace the segmented language model with the unsegmented one, allowing them to tune the linear model parameters by hand. We use both segmented and unsegmented language models, and tune automatically to optimize BLEU. Like us, Luong et al. (2010) tune on unsegmented references,1 and translate with both segmented and unsegmented language models for English-to-Finnish translation. However, they adopt a scheme of word-boundary-aware Morphological Analysis Many languages have access to morphological analyzers, which annotate surface forms with their lemmas and morphological features. Bojar (2007) incorporates such analyses into a factored model, to either include a language model over target morphological tags, or model the generation of morphological features. Other approaches train an SMT system to predict lemmas instead of surface forms, and then inflect the SMT output as a postprocessing step (Minkov et al., 2007; Clifton and Sarkar, 2011; Fraser et al., 2012; El Kholy and Habash, 2012b). Alternatively, one can reparameterize existing phrase tables as exponential models, so that translation probabilities account for source context and morphological features (Jeong et al., 2010; Su"
P14-1010,P08-1067,0,0.0370348,"cceptor over morphemes. We compose this acceptor with a desegmenting transducer, and then with an unsegmented LM acceptor, producing a fully annotated, desegmented lattice. Instead of using a tool kit such as OpenFst (Allauzen et al., 2007), we implement both the desegmenting transducer and the LM acceptor programmatically. This eliminates the need to construct intermediate machines, such as the lattice-specific desegmenter in Figure 1b, and facilitates working with edges annotated with feature vectors as opposed to single weights. Inspired by the use of non-local features in forest decoding (Huang, 2008), we present an algorithm to find chains of edges that correspond to desegmentable token sequences, allowing lattice desegmentation with no phrase-table restrictions. This algorithm can be seen as implicitly constructing a customized desegmenting transducer and composing it with the input lattice on the fly. Before describing the algorithm, we define some notation. An input morpheme lattice is a triple hns , N , Ei, where N is a set of nodes, E is a set of edges, and ns ∈ N is the start node that begins each path through the lattice. Each edge e ∈ E is a 4-tuple hfrom, to, lex , wi, where from"
P14-1010,N12-1047,1,0.838563,"about 40 million Arabic tokens before 6 Allowing the re-ranker to choose between multiple Y s is a natural avenue for future work. 7 We also experimented on log p(X|Y ) as an additional feature, but observed no improvement in translation quality. 105 maximum phrase length is set to 8. For Englishto-Finnish, we follow Clifton and Sarkar (2011) in setting the hypothesis stack size to 100, distortion limit to 6, and maximum phrase length to 20. The decoder’s log-linear model is tuned with MERT (Och, 2003). Re-ranking models are tuned using a batch variant of hope-fear MIRA (Chiang et al., 2008; Cherry and Foster, 2012), using the n-best variant for n-best desegmentation, and the lattice variant for lattice desegmentation. MIRA was selected over MERT because we have an in-house implementation that can tune on lattices very quickly. During development, we confirmed that MERT and MIRA perform similarly, as is expected with fewer than 20 features. Both the decoder’s log-linear model and the re-ranking models are trained on the same development set. Historically, we have not seen improvements from using different tuning sets for decoding and reranking. Lattices are pruned to a density of 50 edges per word before"
P14-1010,D08-1024,0,0.0241362,"training set contains about 40 million Arabic tokens before 6 Allowing the re-ranker to choose between multiple Y s is a natural avenue for future work. 7 We also experimented on log p(X|Y ) as an additional feature, but observed no improvement in translation quality. 105 maximum phrase length is set to 8. For Englishto-Finnish, we follow Clifton and Sarkar (2011) in setting the hypothesis stack size to 100, distortion limit to 6, and maximum phrase length to 20. The decoder’s log-linear model is tuned with MERT (Och, 2003). Re-ranking models are tuned using a batch variant of hope-fear MIRA (Chiang et al., 2008; Cherry and Foster, 2012), using the n-best variant for n-best desegmentation, and the lattice variant for lattice desegmentation. MIRA was selected over MERT because we have an in-house implementation that can tune on lattices very quickly. During development, we confirmed that MERT and MIRA perform similarly, as is expected with fewer than 20 features. Both the decoder’s log-linear model and the re-ranking models are trained on the same development set. Historically, we have not seen improvements from using different tuning sets for decoding and reranking. Lattices are pruned to a density o"
P14-1010,2010.amta-papers.33,0,0.0179071,"features. Bojar (2007) incorporates such analyses into a factored model, to either include a language model over target morphological tags, or model the generation of morphological features. Other approaches train an SMT system to predict lemmas instead of surface forms, and then inflect the SMT output as a postprocessing step (Minkov et al., 2007; Clifton and Sarkar, 2011; Fraser et al., 2012; El Kholy and Habash, 2012b). Alternatively, one can reparameterize existing phrase tables as exponential models, so that translation probabilities account for source context and morphological features (Jeong et al., 2010; Subotin, 2011). Of these approaches, ours is most similar to the translate-then-inflect approach, except we translate and then desegment. In particular, Toutanova et al. (2008) inflect and re-rank n-best lists in a similar manner to how we desegment and re-rank n-best lists or lattices. 2.2 Morphological Segmentation Instead of producing an abstract feature layer, morphological segmentation transforms the target sentence by segmenting relevant morphemes, which are then handled as regular tokens during alignment and translation. This is done to reduce sparsity and to improve correspondence wi"
P14-1010,P11-2031,0,0.033925,"ntation step. Our second baseline is 1-best Deseg, where we train on segmented target text and desegment the decoder’s 1-best output. Starting from the system that produced 1-best Deseg, we then output either 1000-best lists or lattices to create our two experimental systems. The 1000-best Deseg system desegments, augments and re-ranks the decoder’s 1000-best list, while Lattice Deseg does the same in the lattice. We augment n-best lists and lattices using the features described in Section 3.4.8 We evaluate our system using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). Following Clark et al. (2011), we report average scores over five random tuning replications to account for optimizer instability. For the baselines, this means 5 runs of decoder tuning. For the desegmenting re-rankers, this means 5 runs of reranker tuning, each working on n-best lists or lattices produced by the same (representative) decoder weights. We measure statistical significance using MultEval (Clark et al., 2011), which implements a stratified approximate randomization test to account for multiple tuning replications. segmentation, and 47 million after segmentation. We tune on the NIST 2004 evaluation set (1353 s"
P14-1010,D07-1091,0,0.123681,"Missing"
P14-1010,P11-1004,0,0.0694546,"es is a challenging and interesting task that has received much recent attention. Most techniques approach the problem by transforming the target language in some manner before training the translation model. They differ in what transformations are performed and at what stage they are reversed. The transformation might take the form of a morphological analysis or a morphological segmentation. 100 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 100–110, c Baltimore, Maryland, USA, June 23-25 2014. 2014 Association for Computational Linguistics 2.1 Clifton and Sarkar, 2011; El Kholy and Habash, 2012a). Since our focus here is on integrating segmentation into the decoding process, we simply adopt the segmentation strategies recommended by previous work: the Penn Arabic Treebank scheme for English-Arabic (El Kholy and Habash, 2012a), and an unsupervised scheme for EnglishFinnish (Clifton and Sarkar, 2011). Desegmentation is the process of converting segmented words into their original surface form. For many segmentations, especially unsupervised ones, this amounts to simple concatenation. However, more complex segmentations, such as the Arabic tokenization provid"
P14-1010,N03-1017,0,0.00445976,"can be constructed by first encoding our desegmenter as a table that maps morpheme sequences to words. Regardless of whether the original desegmenter was based on concatenation, rules or table-lookup, it can be encoded as a lattice-specific table by applying it to an enumeration of all words found in the lattice. We can then transform that table into a finite state transducer with one path per table entry. Finally, we take the closure of this transducer, so that the resulting machine can transduce any sequence of words. The desegmenting transtil each source word has been covered exactly once (Koehn et al., 2003). The search graph of a phrase-based decoder can be interpreted as a lattice, which can be interpreted as a finite state acceptor over target strings. In its most natural form, such an acceptor emits target phrases on each edge, but it can easily be transformed into a form with one edge per token, as shown in Figure 1a. This is sometimes referred to as a word graph (Ueffing et al., 2002), although in our case the segmented phrase table also produces tokens that correspond to morphemes. Our goal is to desegment the decoder’s output lattice, and in doing so, gain access to a compact, desegmented"
P14-1010,P07-2045,0,0.0638514,"enting an SMT system built over target segments with features that reflect the desegmented target words. In this section, we describe our various strategies for desegmenting the SMT system’s output space, along with the features that we add to take advantage of this desegmented view. 3.1 3.3 Lattice Desegmentation An n-best list reflects a tiny portion of a decoder’s search space, typically fixed at 1000 hypotheses. Lattices2 can represent an exponential number of hypotheses in a compact structure. In this section, we discuss how a lattice from a multi-stack phrasebased decoder such as Moses (Koehn et al., 2007) can be desegmented to enable word-level features. Baselines The two obvious baseline approaches each decode using one view of the target language. The unsegmented approach translates without segmenting the target. This trivially allows for an unsegmented language model and never makes desegmentation errors. However, it suffers from data sparsity and poor token-to-token correspondence with the source language. The one-best desegmentation approach segments the target language at training time and Finite State Analogy A phrase-based decoder produces its output from left to right, with each opera"
P14-1010,2012.eamt-1.6,0,0.0247451,"Missing"
P14-1010,D10-1015,0,0.151014,"concatenation is sufficient for English-Finnish. Work on integration attempts to improve SMT performance for morphologically complex target languages by going beyond simple pre- and postprocessing. Oflazer and Durgar El-Kahlout (2007) desegment 1000-best lists for English-to-Turkish translation to enable scoring with an unsegmented language model. Unlike our work, they replace the segmented language model with the unsegmented one, allowing them to tune the linear model parameters by hand. We use both segmented and unsegmented language models, and tune automatically to optimize BLEU. Like us, Luong et al. (2010) tune on unsegmented references,1 and translate with both segmented and unsegmented language models for English-to-Finnish translation. However, they adopt a scheme of word-boundary-aware Morphological Analysis Many languages have access to morphological analyzers, which annotate surface forms with their lemmas and morphological features. Bojar (2007) incorporates such analyses into a factored model, to either include a language model over target morphological tags, or model the generation of morphological features. Other approaches train an SMT system to predict lemmas instead of surface form"
P14-1010,E12-1068,0,0.0124372,"ish-to-Finnish translation. However, they adopt a scheme of word-boundary-aware Morphological Analysis Many languages have access to morphological analyzers, which annotate surface forms with their lemmas and morphological features. Bojar (2007) incorporates such analyses into a factored model, to either include a language model over target morphological tags, or model the generation of morphological features. Other approaches train an SMT system to predict lemmas instead of surface forms, and then inflect the SMT output as a postprocessing step (Minkov et al., 2007; Clifton and Sarkar, 2011; Fraser et al., 2012; El Kholy and Habash, 2012b). Alternatively, one can reparameterize existing phrase tables as exponential models, so that translation probabilities account for source context and morphological features (Jeong et al., 2010; Subotin, 2011). Of these approaches, ours is most similar to the translate-then-inflect approach, except we translate and then desegment. In particular, Toutanova et al. (2008) inflect and re-rank n-best lists in a similar manner to how we desegment and re-rank n-best lists or lattices. 2.2 Morphological Segmentation Instead of producing an abstract feature layer, morpholog"
P14-1010,J03-1002,0,0.00599847,"ces to surface forms. For Finnish, we adopt the Unsup L-match segmentation technique of Clifton and Sarkar (2011), which uses Morfessor (Creutz and Lagus, 2005) to analyze the 5,000 most frequent Finnish words. The analysis is then applied to the Finnish side of the parallel text, and a list of segmented suffixes is collected. To improve coverage, words are further segmented according to their longest matching suffix from the list. As Morfessor does not perform any orthographic normalizations, it can be desegmented with simple concatenation. 4.2 Systems We align the parallel data with GIZA++ (Och et al., 2003) and decode using Moses (Koehn et al., 2007). The decoder’s log-linear model includes a standard feature set. Four translation model features encode phrase translation probabilities and lexical scores in both directions. Seven distortion features encode a standard distortion penalty as well as a bidirectional lexicalized reordering model. A KN-smoothed 5-gram language model is trained on the target side of the parallel data with SRILM (Stolcke, 2002). Finally, we include word and phrase penalties. The decoder uses the default parameters for English-to-Arabic, except that the 8 Development expe"
P14-1010,P03-1021,0,0.087911,"entence pairs drawn from the NIST 2012 training set, excluding the UN data. This training set contains about 40 million Arabic tokens before 6 Allowing the re-ranker to choose between multiple Y s is a natural avenue for future work. 7 We also experimented on log p(X|Y ) as an additional feature, but observed no improvement in translation quality. 105 maximum phrase length is set to 8. For Englishto-Finnish, we follow Clifton and Sarkar (2011) in setting the hypothesis stack size to 100, distortion limit to 6, and maximum phrase length to 20. The decoder’s log-linear model is tuned with MERT (Och, 2003). Re-ranking models are tuned using a batch variant of hope-fear MIRA (Chiang et al., 2008; Cherry and Foster, 2012), using the n-best variant for n-best desegmentation, and the lattice variant for lattice desegmentation. MIRA was selected over MERT because we have an in-house implementation that can tune on lattices very quickly. During development, we confirmed that MERT and MIRA perform similarly, as is expected with fewer than 20 features. Both the decoder’s log-linear model and the re-ranking models are trained on the same development set. Historically, we have not seen improvements from"
P14-1010,W07-0704,0,0.66386,"Missing"
P14-1010,P02-1040,0,0.0911867,"where we train on unsegmented target text, requiring no desegmentation step. Our second baseline is 1-best Deseg, where we train on segmented target text and desegment the decoder’s 1-best output. Starting from the system that produced 1-best Deseg, we then output either 1000-best lists or lattices to create our two experimental systems. The 1000-best Deseg system desegments, augments and re-ranks the decoder’s 1000-best list, while Lattice Deseg does the same in the lattice. We augment n-best lists and lattices using the features described in Section 3.4.8 We evaluate our system using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). Following Clark et al. (2011), we report average scores over five random tuning replications to account for optimizer instability. For the baselines, this means 5 runs of decoder tuning. For the desegmenting re-rankers, this means 5 runs of reranker tuning, each working on n-best lists or lattices produced by the same (representative) decoder weights. We measure statistical significance using MultEval (Clark et al., 2011), which implements a stratified approximate randomization test to account for multiple tuning replications. segmentation, and 47 million after"
P14-1010,P11-2001,0,0.0202286,"s with an n-gram LM, every path coming into a node must end with the same sequence of (n−1) tokens. If this property does not hold, then nodes must be split until it does.4 This property is maintained by the decoder’s recombination rules for the segmented LM, but it is not guaranteed for the desegmented LM. Indeed, the expanded word-level context is one of the main benefits of incorporating a word-level LM. Fortunately, LM annotation as well as any necessary lattice modifications can be performed simultaneously by composing the desegmented lattice with a finite state acceptor encoding the LM (Roark et al., 2011). In summary, we are given a segmented lattice, which encodes the decoder’s translation space as an acceptor over morphemes. We compose this acceptor with a desegmenting transducer, and then with an unsegmented LM acceptor, producing a fully annotated, desegmented lattice. Instead of using a tool kit such as OpenFst (Allauzen et al., 2007), we implement both the desegmenting transducer and the LM acceptor programmatically. This eliminates the need to construct intermediate machines, such as the lattice-specific desegmenter in Figure 1b, and facilitates working with edges annotated with feature"
P14-1010,N13-2007,1,0.660172,"es, this amounts to simple concatenation. However, more complex segmentations, such as the Arabic tokenization provided by MADA (Habash et al., 2009), require further orthographic adjustments to reverse normalizations performed during segmentation. Badr et al. (2008) present two Arabic desegmentation schemes: table-based and rule-based. El Kholy and Habash (2012a) provide an extensive study on the influence of segmentation and desegmentation on English-toArabic SMT. They introduce an additional desegmentation technique that augments the table-based approach with an unsegmented language model. Salameh et al. (2013) replace rule-based desegmentation with a discriminatively-trained character transducer. In this work, we adopt the Table+Rules approach of El Kholy and Habash (2012a) for English-Arabic, while concatenation is sufficient for English-Finnish. Work on integration attempts to improve SMT performance for morphologically complex target languages by going beyond simple pre- and postprocessing. Oflazer and Durgar El-Kahlout (2007) desegment 1000-best lists for English-to-Turkish translation to enable scoring with an unsegmented language model. Unlike our work, they replace the segmented language mod"
P14-1010,2006.amta-papers.25,0,0.00976777,"arget text, requiring no desegmentation step. Our second baseline is 1-best Deseg, where we train on segmented target text and desegment the decoder’s 1-best output. Starting from the system that produced 1-best Deseg, we then output either 1000-best lists or lattices to create our two experimental systems. The 1000-best Deseg system desegments, augments and re-ranks the decoder’s 1000-best list, while Lattice Deseg does the same in the lattice. We augment n-best lists and lattices using the features described in Section 3.4.8 We evaluate our system using BLEU (Papineni et al., 2002) and TER (Snover et al., 2006). Following Clark et al. (2011), we report average scores over five random tuning replications to account for optimizer instability. For the baselines, this means 5 runs of decoder tuning. For the desegmenting re-rankers, this means 5 runs of reranker tuning, each working on n-best lists or lattices produced by the same (representative) decoder weights. We measure statistical significance using MultEval (Clark et al., 2011), which implements a stratified approximate randomization test to account for multiple tuning replications. segmentation, and 47 million after segmentation. We tune on the N"
P14-1010,P11-1024,0,0.0132681,"7) incorporates such analyses into a factored model, to either include a language model over target morphological tags, or model the generation of morphological features. Other approaches train an SMT system to predict lemmas instead of surface forms, and then inflect the SMT output as a postprocessing step (Minkov et al., 2007; Clifton and Sarkar, 2011; Fraser et al., 2012; El Kholy and Habash, 2012b). Alternatively, one can reparameterize existing phrase tables as exponential models, so that translation probabilities account for source context and morphological features (Jeong et al., 2010; Subotin, 2011). Of these approaches, ours is most similar to the translate-then-inflect approach, except we translate and then desegment. In particular, Toutanova et al. (2008) inflect and re-rank n-best lists in a similar manner to how we desegment and re-rank n-best lists or lattices. 2.2 Morphological Segmentation Instead of producing an abstract feature layer, morphological segmentation transforms the target sentence by segmenting relevant morphemes, which are then handled as regular tokens during alignment and translation. This is done to reduce sparsity and to improve correspondence with the source la"
P14-1010,P08-1059,0,0.0173145,"logical features. Other approaches train an SMT system to predict lemmas instead of surface forms, and then inflect the SMT output as a postprocessing step (Minkov et al., 2007; Clifton and Sarkar, 2011; Fraser et al., 2012; El Kholy and Habash, 2012b). Alternatively, one can reparameterize existing phrase tables as exponential models, so that translation probabilities account for source context and morphological features (Jeong et al., 2010; Subotin, 2011). Of these approaches, ours is most similar to the translate-then-inflect approach, except we translate and then desegment. In particular, Toutanova et al. (2008) inflect and re-rank n-best lists in a similar manner to how we desegment and re-rank n-best lists or lattices. 2.2 Morphological Segmentation Instead of producing an abstract feature layer, morphological segmentation transforms the target sentence by segmenting relevant morphemes, which are then handled as regular tokens during alignment and translation. This is done to reduce sparsity and to improve correspondence with the source language (usually English). Such a segmentation can be produced as a byproduct of analysis (Oflazer and Durgar El-Kahlout, 2007; Badr et al., 2008; El Kholy and Hab"
P14-1010,W02-1021,0,0.0335071,"path per table entry. Finally, we take the closure of this transducer, so that the resulting machine can transduce any sequence of words. The desegmenting transtil each source word has been covered exactly once (Koehn et al., 2003). The search graph of a phrase-based decoder can be interpreted as a lattice, which can be interpreted as a finite state acceptor over target strings. In its most natural form, such an acceptor emits target phrases on each edge, but it can easily be transformed into a form with one edge per token, as shown in Figure 1a. This is sometimes referred to as a word graph (Ueffing et al., 2002), although in our case the segmented phrase table also produces tokens that correspond to morphemes. Our goal is to desegment the decoder’s output lattice, and in doing so, gain access to a compact, desegmented view of a large portion of the translation search space. This can be accomplished by composing the lattice with a desegmenting transducer that consumes morphemes and outputs desegmented words. This transducer must be able to consume every word in our lattice’s output vocabulary. We define a word using the following regular expression: 3 Throughout this paper, we use “+” to mark morpheme"
P14-1010,P07-1017,0,\N,Missing
P14-1010,D08-1076,0,\N,Missing
P14-2138,W13-1726,0,0.0339334,"Missing"
P14-2138,W13-1727,0,0.0325771,"Missing"
P14-2138,W13-1711,0,0.0343355,"Missing"
P14-2138,W13-1728,0,0.0234327,"Missing"
P14-2138,W13-1712,0,0.033807,"Missing"
P14-2138,W13-1713,0,0.178783,"Missing"
P14-2138,W13-1719,0,0.0430528,"Missing"
P14-2138,W13-1730,0,0.112684,"Missing"
P14-2138,W13-1706,0,0.117366,"Missing"
P14-2138,W13-1714,0,0.096944,"Missing"
P14-2138,W07-0602,0,0.630036,"s by BigramScore and perform two experiments to quantify their impact on the NLI task. The results of the first experiment demonstrate that the removal of a relatively small set of discriminative words from the training data significantly impairs the accuracy of a bigram-based classifier. The results of the second experiment reveal that the most indicative bigrams are quite similar across different language sets. We conclude that character bigrams are effective in determining L1 of the author because they reflect differences in L2 word usage that are unrelated to the phonology of L1. 2 Method Tsur and Rappoport (2007) report that character bigrams are more effective for the NLI task than either unigrams or trigrams. We are interested in identifying the character bigrams that are indicative of the most discriminative words in order to quantify their impact on the bigram-based classifier. We follow both Koppel et al. (2005) and Tsur and Rappoport (2007) in using a multi-class SVM classifier for the NLI task. The classifier computes a weight for each feature coupled with each L1 language by attempting to maximize the overall accuracy on the training set. For example, if we train the classifier using words as"
P14-2138,W13-1736,0,0.0464777,"Missing"
P14-2138,W13-1732,0,0.0543384,"Missing"
P14-2138,W13-1715,0,0.0463684,"Missing"
P14-2138,W13-1734,0,0.0384191,"Missing"
P14-2138,W13-1716,0,0.102272,"Missing"
P14-2138,W13-1717,0,0.0218954,"Missing"
P14-2138,W13-1718,1,0.88466,"Missing"
P14-2138,W13-1735,0,0.0547663,"Missing"
P14-2138,W13-1710,0,\N,Missing
P14-2138,W13-1725,0,\N,Missing
P15-2046,D11-1096,0,0.0298796,"e 2(a) shows the unlexicalized dependency tree for our example sentence. Our lexicalized tree representation is derived from the unlexicalized representation by attaching words as terminal nodes. In order to reduce the number of nodes, we collapse the relation and entity tags with their corresponding POS tags. Figure 2(b) shows the resulting tree for the example sentence. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimen"
P15-2046,P14-5010,0,0.00392353,"consists of three modules: entity extraction, relation candidate extraction, and tree 279 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 279–284, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics Figure 1: Our Open IE system structure. kernel filtering. The system structure is outlined in Figure 1. We identify named entities, parse sentences, and convert constituency trees into dependency structures using the Stanford tools (Manning et al., 2014). Entities within a fixed token distance (set to 20 according to development results) are extracted as pairs {&lt; E1 , E2 >}. We then identify relation candidates R for each entity pair in a sentence, using dependency paths. Finally, the candidate triples {&lt; E1 , R, E2 >} are paired with their corresponding tree structures, and provided as input to the SVM tree kernel. Our Open IE system outputs the triples that are classified as positive. In the following sections, we describe the components of the system in more detail. 3 The relation candidates are manually annotated as correct/incorrect in t"
P15-2046,D12-1048,0,0.0381022,"the results of the candidate extraction module. For semantic tasks, the design of input structures to tree kernels is as important as the design of the tree kernels themselves. In this section, we introduce our tree structure, describe the prior basic tree kernel, and finally present our lexicalized tree kernel function. Relation Candidates 4.1 Tree Structure Relation candidates are words that may represent a relation between two entities. We consider only lemmatized nouns, verbs and adjectives that are within two dependency links from either of the entities. Following Wu and Weld (2010) and Mausam et al. (2012), we use dependency patterns rather than POS patterns, which allows us to identify relation candidates which are farther away from entities in terms of token distance. We extract the first two content words along the dependency path between E1 and E2 . In the following example, the path is E1 → encounter → build → E2 , and the two relation word candidates between “Mr. Wathen” and “Plant Security Service” are encounter and build, of which the latter is the correct one. In order to formulate the input for tree kernel models, we need to convert the dependency path to a tree-like structure with un"
P15-2046,D13-1043,0,0.0168662,"(n1 , n2 ) = 0 if the productions (contextfree rules) of n1 and n2 are different. 2. Otherwise, ∆(n1 , n2 ) = 1 if n1 and n2 are matching pre-terminals (POS tags). 3. Otherwise, ∏ ∆(n1 , n2 ) = j (1 + ∆(c(n1 , j), c(n2 , j)), where c(n, j) is the jth child of n. 281 5 Smoothing none (Xu13) none Brown (PM13) Brown (PM13) Brown (PM13) embedding embedding embedding Experiments Here we evaluate alternative tree kernel configurations, and compare our Open IE system to previous work. We perform experiments on three datasets (Table 1): the Penn Treebank set (Xu et al., 2013), the New York Times set (Mesquita et al., 2013), and the ClueWeb set which we created for this project from a large collection of web pages.1 The models are trained on the Penn Treebank training set and tested on the three test sets, of which the Penn Treebank set is in-domain, and the other two sets are out-of-domain. For word embedding and Brown clustering representations, we use the data provided by Turian et al. (2010). The SVM parameters, as well as the Brown cluster size and code length, are tuned on the development set. Set Penn Treebank New York Times ClueWeb train 750 — — dev 100 300 450 Lexical info none all words relation only a"
P15-2046,P13-1147,0,0.0837377,"zed representation by attaching words as terminal nodes. In order to reduce the number of nodes, we collapse the relation and entity tags with their corresponding POS tags. Figure 2(b) shows the resulting tree for the example sentence. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimensional real valued vectors. Each dimension represents a latent feature of the word that reflects its semantic and syntactic properties. Next, we d"
P15-2046,N13-1008,0,0.186228,"Missing"
P15-2046,D13-1144,0,0.018378,"the resulting tree for the example sentence. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimensional real valued vectors. Each dimension represents a latent feature of the word that reflects its semantic and syntactic properties. Next, we describe how we embed these vectors into tree kernels. Our lexicalized tree kernel model is the same as SST, except in the following case: if n1 and n2 are matching pre-terminals (POS tags),"
P15-2046,P10-1040,0,0.0377711,"we evaluate alternative tree kernel configurations, and compare our Open IE system to previous work. We perform experiments on three datasets (Table 1): the Penn Treebank set (Xu et al., 2013), the New York Times set (Mesquita et al., 2013), and the ClueWeb set which we created for this project from a large collection of web pages.1 The models are trained on the Penn Treebank training set and tested on the three test sets, of which the Penn Treebank set is in-domain, and the other two sets are out-of-domain. For word embedding and Brown clustering representations, we use the data provided by Turian et al. (2010). The SVM parameters, as well as the Brown cluster size and code length, are tuned on the development set. Set Penn Treebank New York Times ClueWeb train 750 — — dev 100 300 450 Lexical info none all words relation only all words excl. entities relation only all words excl. entities P 85.7 89.8 88.7 84.5 86.2 93.9 93.8 95.9 R 72.7 66.7 71.2 74.2 75.8 69.7 68.2 71.2 F1 78.7 76.5 79.0 79.0 80.7 80.0 79.0 81.7 Table 2: The results of relation extraction with alternative smoothing and lexicalization techniques on the Penn Treebank set (with our relation candidate extraction and tree structure). la"
P15-2046,P10-1013,0,0.0249908,"elation candidates from the results of the candidate extraction module. For semantic tasks, the design of input structures to tree kernels is as important as the design of the tree kernels themselves. In this section, we introduce our tree structure, describe the prior basic tree kernel, and finally present our lexicalized tree kernel function. Relation Candidates 4.1 Tree Structure Relation candidates are words that may represent a relation between two entities. We consider only lemmatized nouns, verbs and adjectives that are within two dependency links from either of the entities. Following Wu and Weld (2010) and Mausam et al. (2012), we use dependency patterns rather than POS patterns, which allows us to identify relation candidates which are farther away from entities in terms of token distance. We extract the first two content words along the dependency path between E1 and E2 . In the following example, the path is E1 → encounter → build → E2 , and the two relation word candidates between “Mr. Wathen” and “Plant Security Service” are encounter and build, of which the latter is the correct one. In order to formulate the input for tree kernel models, we need to convert the dependency path to a tr"
P15-2046,N13-1107,1,0.921102,"path to a tree-like structure with unlabelled edges. The target dependency path is the shortest path that includes the triple and other content words along the path. Consider the following example, which is a simplified representation of the sentence “Georgia-Pacific Corp.’s unsolicited $3.9 billion bid for Great Northern Nekoosa Corp. was hailed by Wall Street.” The candidate triple identified by the relation candidate extraction module is &lt;Georgia-Pacific Corp., bid, Great Northern Nekoosa Corp.>. Our unlexicalized tree representation model is similar to the unlexicalized representations of Xu et al. (2013), except that instead of using the POS tag of the path’s head word as the root, we create an abstract Root node. We preserve the dependency labels, POS tags, and entity information as tree nodes: (a) the top dependency labels are inIf there are no content words on the dependency path between the two entities, we instead consider words that are directly linked to either of them. In the following example, the only relation candidate is the word battle, which is directly linked to “Edelman.” 280 (a) An un-lexicalized dependency tree. (b) A lexicalized dependency tree. Figure 2: An unlexicalized t"
P15-2046,J92-4003,0,\N,Missing
P15-2046,P02-1034,0,\N,Missing
P16-1108,chrupala-etal-2008-learning,0,0.314797,"Missing"
P16-1108,K15-1017,0,0.0445668,"Missing"
P16-1108,W02-0603,0,0.186419,"mmatization. 2.1 Present Imperfect Preterite Future Stemming and Segmentation Stemming is a sub-task of the larger problem of morphological segmentation. Because of the scarcity of morphologically-annotated data, many segmentation algorithms are unsupervised or rulebased. The Porter stemmer (Porter, 1980) and its derivatives, such as Snowball, apply hand-crafted context rules to strip affixes from a word. Creation of such rule-based programs requires significant effort and expert knowledge. We use structured inflection tables to create training data for a discriminative transducer. Morfessor (Creutz and Lagus, 2002) and Linguistica (Goldsmith, 2001) are unsupervised word segmenters, which divide words into regularly occurring sub-sequences by applying the minimum description length (MDL) principle. While these methods are good at identifying common morphemes, they make no distinction between stems and affixes, and thus cannot be used for stemming. Morfessor Categories-MAP (Creutz and Lagus, 2004; Creutz and Lagus, 2005) distinguishes between stems and affixes, but not between derivational and inflectional affixes. We adapt a more recent version (Gr¨onroos et al., 2014) to be used as an approximate stemme"
P16-1108,W04-0106,0,0.109265,"Missing"
P16-1108,N13-1138,0,0.0973036,"rform a precise comparison between the supervised and unsupervised systems, we extract the inflection tables from CELEX, disregarding the segmentation information. Each system is represented by a single stemming model that works on nouns, verbs, and adjectives. Due to differences in representation, the number of training instances vary slightly between models, but the number of words is constant (Table 5). In order to demonstrate that our unsupervised methods require no segmentation information, we create additional German training sets using the inflection tables extracted from Wiktionary by Durrett and DeNero (2013). The sets contain 18,912 noun forms and 43,929 verb forms. We derive separate models for verbs and nouns in order to compare the difficulty of stemming different parts of speech. The test sets for both CELEX and Wiktionary data come from CELEX, and consist of 5252, 6155, and 9817 unique forms for English, Dutch, and German, respectively. The German test set contains 2620 nouns, 3837 verbs, and 3360 adjectives. Chipmunk3 requires training data in which ev2 Morfessor is applied to the union of the training and test data. 3 http://cistern.cis.lmu.de/chipmunk EN 98.5 82.3 94.6 50.0 65.2 NL 96.0 8"
P16-1108,P09-1055,0,0.465531,"l tags in inflection tables, but segmentation and tag alignment are performed in an unsupervised way. 2.2 Lemmatization Unlike stemmers, which can be unsupervised, lemmatizers typically require annotated training data. In addition, some lemmatizers assume access to the morphological tag of the word, and/or the surrounding words in the text. Our focus is on context-free lemmatization, which could later be combined with a contextual disambiguation module. Lemmatization is often part of the morphological analysis task, which aims at annotating each word-form with its lemma and morphological tag. Toutanova and Cherry (2009) learn a joint model for contextual lemmatization and part-of-speech prediction from a morphologically annotated lexicon. Their transduction model is tightly integrated with the POS information, which makes comparison difficult. However, in Section 6, we evaluate our approach against two other fully-supervised morphological analyzers: Morfette (Chrupała et al., 2008) and Lemming (M¨uller et al., 2015). Both of these systems perform lemmatization and morphological analysis in context, but can be trained to learn non-contextual models. Morfette requires morphological tags during training, while"
P16-1108,J01-2001,0,0.0215349,"ite Future Stemming and Segmentation Stemming is a sub-task of the larger problem of morphological segmentation. Because of the scarcity of morphologically-annotated data, many segmentation algorithms are unsupervised or rulebased. The Porter stemmer (Porter, 1980) and its derivatives, such as Snowball, apply hand-crafted context rules to strip affixes from a word. Creation of such rule-based programs requires significant effort and expert knowledge. We use structured inflection tables to create training data for a discriminative transducer. Morfessor (Creutz and Lagus, 2002) and Linguistica (Goldsmith, 2001) are unsupervised word segmenters, which divide words into regularly occurring sub-sequences by applying the minimum description length (MDL) principle. While these methods are good at identifying common morphemes, they make no distinction between stems and affixes, and thus cannot be used for stemming. Morfessor Categories-MAP (Creutz and Lagus, 2004; Creutz and Lagus, 2005) distinguishes between stems and affixes, but not between derivational and inflectional affixes. We adapt a more recent version (Gr¨onroos et al., 2014) to be used as an approximate stemmer. Poon et al. (2009) abandons the"
P16-1108,C14-1111,0,0.0393432,"Missing"
P16-1108,N07-1047,1,0.849813,"M|2SIE PP|STEM|PP geb|en gab|gib|st ge|geb|en setz|en setz|te setz|t ge|setz|t tu|n tat|tu|st ge|ta|n Table 3: Stemming of the training data based on the patterns of regularity in inflectional tables. Stemmas are shown in bold. Character Alignment The training of a transduction model requires a set of aligned pairs of source and target strings. The alignment involves every input and output character; the insertion and deletion operations are disallowed. Atomic character transformations are then extracted from the alignments. We infer the alignment with a modified version of the M2M aligner of Jiampojamarn et al. (2007). The program applies the ExpectationMaximization algorithm with the objective to maximize the joint likelihood of its aligned source and target pairs. For our task, the source and target strings are nearly identical, except that the target includes stem-affix boundary markers. In order to account for every character in the target, which is usually longer than the source, we allow one-tomany alignment. This has the effect of tying the markers to the edge of a stem or affix. In order to encourage alignments between identical characters, we modify the aligner to generalize all identity transform"
P16-1108,N10-1103,1,0.876225,"alignments between identical characters, we modify the aligner to generalize all identity transformations into a single match operation. 3.2 STEM|1SIA Supervised Transduction Once we have aligned the source and target pairs, we proceed to train a word-to-stem transduction model for stemming unseen test instances. The word-to-stem model learns where to insert boundary markers. We refer to a model that is trained on annotated morphological segmentations as our supervised method. We perform string transduction by adapting D I REC TL+, a tool originally designed for graphemeto-phoneme conversion (Jiampojamarn et al., 2010). D IREC TL+ is a feature-rich, discriminative character transducer that searches for a modeloptimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. D IREC TL+ uses a number of feature templates to assess the quality of a rule: sou"
P16-1108,P05-1012,0,0.100568,"ry markers. We refer to a model that is trained on annotated morphological segmentations as our supervised method. We perform string transduction by adapting D I REC TL+, a tool originally designed for graphemeto-phoneme conversion (Jiampojamarn et al., 2010). D IREC TL+ is a feature-rich, discriminative character transducer that searches for a modeloptimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. D IREC TL+ uses a number of feature templates to assess the quality of a rule: source context, target n-gram, and joint n-gram features. Context features conjoin the rule with indicators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indicators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoined with our source"
P16-1108,D13-1032,0,0.0629347,"Missing"
P16-1108,D15-1272,0,0.0703143,"Missing"
P16-1108,N09-1024,0,0.0162847,"d Linguistica (Goldsmith, 2001) are unsupervised word segmenters, which divide words into regularly occurring sub-sequences by applying the minimum description length (MDL) principle. While these methods are good at identifying common morphemes, they make no distinction between stems and affixes, and thus cannot be used for stemming. Morfessor Categories-MAP (Creutz and Lagus, 2004; Creutz and Lagus, 2005) distinguishes between stems and affixes, but not between derivational and inflectional affixes. We adapt a more recent version (Gr¨onroos et al., 2014) to be used as an approximate stemmer. Poon et al. (2009) abandons the generative model of Morfessor for a log-linear model that predicts segmentations in sequence. The discriminative approach allows for the incorporation of several priors that minimize over-segmentation. Their unsupervised model outperforms Morfessor, and they are also able to report semi- and fullysupervised results. We also approach the problem using a discriminative method, but by aligning structured inflection tables, we can take advantage of linguistic knowledge, without requiring costly annotation. Ruokolainen et al. (2014) obtain further improvements by combining a structure"
P16-1108,E14-4017,0,0.0188254,"¨onroos et al., 2014) to be used as an approximate stemmer. Poon et al. (2009) abandons the generative model of Morfessor for a log-linear model that predicts segmentations in sequence. The discriminative approach allows for the incorporation of several priors that minimize over-segmentation. Their unsupervised model outperforms Morfessor, and they are also able to report semi- and fullysupervised results. We also approach the problem using a discriminative method, but by aligning structured inflection tables, we can take advantage of linguistic knowledge, without requiring costly annotation. Ruokolainen et al. (2014) obtain further improvements by combining a structured perceptron CRF with letter successor variety (LSV), and the unsupervised features of Creutz and Lagus (2004). Their system is inherently supervised, while our stem annotations are derived in an unsupervised manner. Cotterell et al. (2015) introduce Chipmunk, a Singular 1st 2nd doy das daba dabas di diste dar´e dar´as 3rd da daba dio dar´a Plural 1st damos d´abamos dimos daramos Table 2: A partial inflection table for the Spanish verb dar “to give”. fully-supervised system for labeled morphological segmentation. Extending the sequence-predi"
P16-1108,W16-2002,0,\N,Missing
Q16-1006,W14-2211,0,0.0223758,"Missing"
Q16-1006,C14-1218,1,0.940194,"ge model. A solution is found by optimally solving an integer linear program. Knight et al. (2011) describe a successful decipherment of an eighteenth century text known as the Copiale Cipher. Language identification was the first step of the process. The EM-based method of Knight et al. (2006) identified German as the most likely candidate among over 40 candidate character language models. The more accurate method of Ravi and Knight (2008) was presumably either too slow or too brittle for this purpose. The cipher was eventually broken using a combination of manual and algorithmic techniques. Hauer et al. (2014) present an approach to solving monoalphabetic substitution ciphers which is more accurate than other algorithms proposed for this task, including Knight et al. (2006), Ravi and Knight (2008), and Norvig (2009). We provide a detailed description of the method in Section 4.1. 3 Source Language Identification In this section, we propose and evaluate three methods for determining the source language of a document enciphered with a monoalphabetic substitution cipher. We frame it as a classification task, with the classes corresponding to the candidate languages, 77 which are represented by short s"
Q16-1006,P06-2065,0,0.607518,"ny undeciphered scripts, such as Linear A, the Indus script, and the Phaistos Disc, remain unknown (Robinson, 2002). Even the order of characters within text may be in doubt; in Egyptian hieroglyphic inscriptions, for instance, the symbols were sometimes rearranged within a word in order to create a more elegant inscription (Singh, 2011). Another complicating factor is the omission of vowels in some writing systems. Applications of ciphertext language identification extend beyond secret ciphers and ancient scripts. Nagy et al. (1987) frame optical character recognition as a decipherment task. Knight et al. (2006) note that for some languages, such as Hindi, there exist many different and incompatible encoding schemes for digital storage of text; the task of analyzing such an arbitrary encoding scheme can be viewed as a decipherment of a substitution cipher in an unknown language. Similarly, the unsupervised derivation of transliteration mappings between different writing scripts lends itself to a cipher formulation (Ravi and Knight, 2009). The Voynich manuscript is written in an unknown script that encodes an unknown language, which is the most challenging type of a decipherment problem (Robinson, 200"
Q16-1006,W11-1202,0,0.715414,"Missing"
Q16-1006,2005.mtsummit-papers.11,0,0.0634339,"mplete in-vocabulary words from sequences of anagrams containing only consonants. At test time, we remove the vowels from the input to the decipherment step of the pipeline. In contrast with Knight et al. (2006), our approach is able not only to attack abjad ciphers, but also to restore the vowels, producing fully readable text. 4.4 Evaluation In order to test our anagram decryption pipeline on out-of-domain ciphertexts, the corpora for deriving language models need to be much larger than the UDHR samples used in the previous section. We selected five diverse European languages from Europarl (Koehn, 2005): English, Bulgarian, German, Greek, and Spanish. The corresponding corpora contain about 50 million words each, with the exception of Bulgarian which has only 9 million words. We remove punctuation and numbers, and lowercase all text. We test on texts extracted from Wikipedia articles on art, Earth, Europe, film, history, language, music, science, technology, and Wikipedia. The texts are first enciphered using a substitution cipher, and then anagrammed (Figure 3a-c). Each of the five languages is represented by 10 ciphertexts, which are decrypted independently. In order to keep the running ti"
Q16-1006,D14-1185,0,0.0377848,"Missing"
Q16-1006,D08-1085,0,0.180071,"s worth noting that this method requires word separators to be preserved in the ciphertext. In fact, the effectiveness of the method comes partly from capturing the distribution of word lengths in a text. On the other hand, the decomposition patterns are independent of the ordering of characters within words. We will take advantage of this property in Section 4. 3.3 Trial Decipherment The final method that we present involves deciphering the document in question into each candidate language. The decipherment is performed with a fast greedy-swap algorithm, which is related to the algorithms of Ravi and Knight (2008) and Norvig (2009). It attempts to find the key that maximizes the probability of the decipherment according to a bigram character language model derived from a sample document in a given language. The decipherment with the highest probability indicates the most likely plaintext language of the document. The greedy-swap algorithm is shown in Figure 2. The initial key is created by pairing the ciphertext and plaintext symbols in the order of decreasing frequency, with null symbols appended to the shorter of the two alphabets. The algorithm repeatedly attempts to improve the current key k by con"
Q16-1006,N09-1005,0,0.0249979,"of ciphertext language identification extend beyond secret ciphers and ancient scripts. Nagy et al. (1987) frame optical character recognition as a decipherment task. Knight et al. (2006) note that for some languages, such as Hindi, there exist many different and incompatible encoding schemes for digital storage of text; the task of analyzing such an arbitrary encoding scheme can be viewed as a decipherment of a substitution cipher in an unknown language. Similarly, the unsupervised derivation of transliteration mappings between different writing scripts lends itself to a cipher formulation (Ravi and Knight, 2009). The Voynich manuscript is written in an unknown script that encodes an unknown language, which is the most challenging type of a decipherment problem (Robinson, 2002, p. 46). Inspired by the mystery of both the Voynich manuscript and the undeciphered ancient scripts, we develop a series of 75 Transactions of the Association for Computational Linguistics, vol. 4, pp. 75–86, 2016. Action Editor: Regina Barzilay. Submission batch: 12/2015; Published 4/2016. c 2016 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. algorithms for the purpose of decrypting unknown a"
Q16-1006,W11-1511,0,0.419708,"Other claimed decipherments by Feely (1943) and Strong (1945) have also been refuted (Tiltman, 1968). A detailed study of the manuscript by d’Imperio (1978) details various other proposed solutions and the arguments against them. 76 Figure 1: A sample from the Voynich manuscript. Numerous languages have been proposed to underlie the VMS. The properties and the dating of the manuscript imply Latin and Italian as potential candidates. On the basis of the analysis of the character frequency distribution, Jaskiewicz (2011) identifies five most probable languages, which include Moldavian and Thai. Reddy and Knight (2011) discover an excellent match between the VMS and Quranic Arabic in the distribution of word lengths, as well as a similarity to Chinese Pinyin in the predictability of letters given the preceding letter. It has been suggested previously that some anagramming scheme may alter the sequence order of characters within words in the VMS. Tiltman (1968) observes that each symbol behaves as if it had its own place in an “order of precedence” within words. Rugg (2004) notes the apparent similarity of the VMS to a text in which each word has been replaced by an alphabetically ordered anagram (alphagram)"
W05-0606,P98-1043,0,0.205136,"ability of a genuine correspondence between a pair of symbols (the similarity model) by the probability of them co-occurring by chance (the random model). These individual scores are combined to produce an overall score for the pair of sequences in the same way as individual symbol probabilities are combined in other algorithms. Figure 2: The random Pair Hidden Markov Model. sponding algorithms. The modified model is shown in Figure 3. First, the original model’s assumption that an insertion followed by a deletion is the same as a substitution is problematic in the context of word similarity. Covington (1998) illustrates the problem with an example of Italian “due” and the Spanish “dos”, both of which mean “two”. While there is no doubt that the first two pairs of symbols should be aligned, there is no historical connection between the Italian “e” and the Spanish “s”. In this case, a sequence of an insertion and a deletion is more appropriate than a substitution. In order to remedy this problem, we decided to a add a pair of transitions between states “X” and “Y”, which is denoted by λ in Figure 3. The second modification involves splitting the parameter τ into two separate values: τM for the matc"
W05-0606,C04-1136,0,0.112484,"Missing"
W05-0606,W01-0504,0,0.247403,"onsists of word pairs known to be similar. Our tests focus on the identification of cognates — words of common origin in related languages. The results show that our system outperforms previously proposed techniques. 1 Introduction The computation of surface similarity between pairs of words is an important task in many areas of natural language processing. In historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share a common origin (Oakes, 2000). In statistical machine translation, cognates are helpful in inducing translation lexicons (Koehn and Knight, 2001; Mann and Yarowsky, 2001), sentence alignment (Melamed, 1999), and word alignment (Tiedemann, 2003). In dialectology, similarity is used for estimating distance between dialects (Nerbonne, 2003). Other applications include cross-lingual information retrieval (Pirkola et al., 2003), detection of confusable drug names (Kondrak and Dorr, 2004), and lexicography (Brew and McKelvie, 1996). Methods that are normally used for computing word similarity can be divided into orthographic and phonetic. The former includes string edit distance (Wagner and Fischer, 1974), longest common subsequence ratio ("
W05-0606,C04-1137,1,0.775889,"guage processing. In historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share a common origin (Oakes, 2000). In statistical machine translation, cognates are helpful in inducing translation lexicons (Koehn and Knight, 2001; Mann and Yarowsky, 2001), sentence alignment (Melamed, 1999), and word alignment (Tiedemann, 2003). In dialectology, similarity is used for estimating distance between dialects (Nerbonne, 2003). Other applications include cross-lingual information retrieval (Pirkola et al., 2003), detection of confusable drug names (Kondrak and Dorr, 2004), and lexicography (Brew and McKelvie, 1996). Methods that are normally used for computing word similarity can be divided into orthographic and phonetic. The former includes string edit distance (Wagner and Fischer, 1974), longest common subsequence ratio (Melamed, 1999), and measures based on shared character n-grams (Brew and McKelvie, 1996). These usually employ a binary identity function on the level of character comparison. The phonetic approaches, such as Soundex (Hall and Dowling, 1980) and Editex (Zobel and Dart, 1996), attempt to take advantage of the phonetic characteristics of indiv"
W05-0606,A00-2038,1,0.744595,"ds for comparison. The results are separated into individual language pairs from the test set. For the baseline method, we selected the Longest Common Subsequence Ratio (LCSR), a measure of orthographic word similarity often used for cognate identification (Brew and McKelvie, 1996; Melamed, 1999; Koehn and Knight, 2001). The LCSR of two words is computed by dividing the length of their longest common subsequence by the length of the longer word. LLW stands for “Levenshtein with learned weights”, which is described in Section 4.4. We also include the results obtained by the ALINE word aligner (Kondrak, 2000) on phonetically-transcribed word lists. Because of the relatively small size of the lists, the differences among results for individual language pairs are not statistically significant in many cases. However, when the average over all language pairs is considered, the Viterbi-based log odds algorithm (LOG) is significantly better than all other algorithms in Table 2. The differences between the remaining algorithms are not statistically significant, except that they all significantly outperform the LCSR baseline. The fact that LOG is significantly better than ALINE demonstrates that given a s"
W05-0606,N01-1020,0,0.742974,"own to be similar. Our tests focus on the identification of cognates — words of common origin in related languages. The results show that our system outperforms previously proposed techniques. 1 Introduction The computation of surface similarity between pairs of words is an important task in many areas of natural language processing. In historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share a common origin (Oakes, 2000). In statistical machine translation, cognates are helpful in inducing translation lexicons (Koehn and Knight, 2001; Mann and Yarowsky, 2001), sentence alignment (Melamed, 1999), and word alignment (Tiedemann, 2003). In dialectology, similarity is used for estimating distance between dialects (Nerbonne, 2003). Other applications include cross-lingual information retrieval (Pirkola et al., 2003), detection of confusable drug names (Kondrak and Dorr, 2004), and lexicography (Brew and McKelvie, 1996). Methods that are normally used for computing word similarity can be divided into orthographic and phonetic. The former includes string edit distance (Wagner and Fischer, 1974), longest common subsequence ratio (Melamed, 1999), and measur"
W05-0606,J99-1003,0,0.160227,"tification of cognates — words of common origin in related languages. The results show that our system outperforms previously proposed techniques. 1 Introduction The computation of surface similarity between pairs of words is an important task in many areas of natural language processing. In historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share a common origin (Oakes, 2000). In statistical machine translation, cognates are helpful in inducing translation lexicons (Koehn and Knight, 2001; Mann and Yarowsky, 2001), sentence alignment (Melamed, 1999), and word alignment (Tiedemann, 2003). In dialectology, similarity is used for estimating distance between dialects (Nerbonne, 2003). Other applications include cross-lingual information retrieval (Pirkola et al., 2003), detection of confusable drug names (Kondrak and Dorr, 2004), and lexicography (Brew and McKelvie, 1996). Methods that are normally used for computing word similarity can be divided into orthographic and phonetic. The former includes string edit distance (Wagner and Fischer, 1974), longest common subsequence ratio (Melamed, 1999), and measures based on shared character n-grams"
W05-0606,P00-1056,0,0.0882775,"ed from limited-size training data. If there is a many-to-one correspondence that is consistent between languages, it would be beneficial to change the word representation so that the many symbols are considered as a single symbol instead. For example, a group of characters in the orthographic representation may correspond to a single phoneme if the word is written phonetically. 3 Pair Hidden Markov Models Hidden Markov Models have been applied successfully to a number of problems in natural language processing, including speech recognition (Jelinek, 1999) and statistical machine translation (Och and Ney, 2000). One of the more intangible aspects of a Hidden Markov Model is the choice of the model itself. While algorithms exist to train the parameters of the model so that the model better describes its data, there is no formulaic way to create the model. We decided to adopt as a starting point a model developed in a different field of study. Durbin et al. (1998) created a new type of Hidden Markov Model that has been used for the task of aligning biological sequences (Figure 1). Called a Pair Hidden Markov Model, it uses two output streams in parallel, each corresponding to a sequence that is being"
W05-0606,W99-0626,0,0.0692964,"mon subsequence ratio (Melamed, 1999), and measures based on shared character n-grams (Brew and McKelvie, 1996). These usually employ a binary identity function on the level of character comparison. The phonetic approaches, such as Soundex (Hall and Dowling, 1980) and Editex (Zobel and Dart, 1996), attempt to take advantage of the phonetic characteristics of individual characters in order to estimate their similarity. All of the above methods are static, in the sense of having a fixed definition that leaves little room for adaptation to a specific context. In contrast, the methods proposed by Tiedemann (1999) automatically construct weighted string similarity measures on the basis of string segmentation and bitext co-occurrence statistics. We have created a system for determining word similarity based on a Pair Hidden Markov Model. The parameters of the model are automatically learned from training data that consists of word 40 Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL), c pages 40–47, Ann Arbor, June 2005. 2005 Association for Computational Linguistics pairs that are known to be similar. The model is trained using the Baum-Welch algorithm (Baum et al., 19"
W05-0606,E03-1026,0,0.0165318,"mmon origin in related languages. The results show that our system outperforms previously proposed techniques. 1 Introduction The computation of surface similarity between pairs of words is an important task in many areas of natural language processing. In historical linguistics phonetic similarity is one of the clues for identifying cognates, that is, words that share a common origin (Oakes, 2000). In statistical machine translation, cognates are helpful in inducing translation lexicons (Koehn and Knight, 2001; Mann and Yarowsky, 2001), sentence alignment (Melamed, 1999), and word alignment (Tiedemann, 2003). In dialectology, similarity is used for estimating distance between dialects (Nerbonne, 2003). Other applications include cross-lingual information retrieval (Pirkola et al., 2003), detection of confusable drug names (Kondrak and Dorr, 2004), and lexicography (Brew and McKelvie, 1996). Methods that are normally used for computing word similarity can be divided into orthographic and phonetic. The former includes string edit distance (Wagner and Fischer, 1974), longest common subsequence ratio (Melamed, 1999), and measures based on shared character n-grams (Brew and McKelvie, 1996). These usua"
W05-0606,C98-1043,0,\N,Missing
W05-0606,J01-4008,1,\N,Missing
W06-1107,P05-1042,0,0.317503,"nment exists, links are assigned the weight averaged over the entire set of best alignments. Finally, the score is normalized by dividing it by the average of the lengths of the two words. 46 A Bayesian Net is a directed acyclic graph in which each of the nodes represents a random variable. The random variable can be either deterministic, in which case the node can only take on one value for a given configuration of its parents, or stochastic, in which case the configuration of the parents determines the probability distribution of the node. Arcs in the net represent dependency relationships. Filali and Bilmes (2005) proposed to use Dynamic Bayesian Nets (DBNs) for computing word similarity. A DBN is a Bayesian Net where a set of arcs and nodes are maintained for each point in time in a dynamic process. This involves set of prologue frames denoting the beginning of the process, chunk frames which are repeated for the middle of the process, and epilogue frames to end the process. The conditional probability relationships are timeindependent. DBNs can encode quite complex interdependencies between states. We tested four different DBN models on the task of cognate identification. In the following description"
W06-1107,A00-2038,1,0.931909,"sing multidimensional scaling. The three dimensions can be interpreted roughly as (a) sonorous vs. sibilant, (b) grave vs. acute, and (c) low vs. high formant density. The articulatory dimensions were based on ultrasound images of the tongue and palate, video images of the face, and oral and nasal airflow measurements. The four articulatory dimensions were: oral constriction location, oral constriction size, lip constriction size, and nasal/oral airflow ratio. In this section, we first describe two different constructed schemes and then compare their properties. 2.1 ALINE The ALINE algorithm (Kondrak, 2000) assigns a similarity score to pairs of phonetically-transcribed words on the basis of the decomposition of phonemes into elementary phonetic features. The algorithm was originally designed to identify and align cognates in vocabularies of related languages. Nevertheless, thanks to its grounding in universal phonetic principles, the algorithm can be used for estimating the similarity of any pair of words. The principal component of ALINE is a function that calculates the similarity of two phonemes that are expressed in terms of about a dozen multi-valued phonetic features (Place, Manner, Voice"
W06-1107,C02-1016,1,0.898441,"Missing"
W06-1107,W05-0606,1,0.95334,"able to various tasks, but they crucially require training data sets of reasonable size. In general, the more complex the underlying model, the larger the data sets needed for parameter estimation. In this paper, we focus on a few representatives of both approaches, and compare their performance on the specific task of cognate identification. Cognate identification is a problem of finding, in distinct languages, words that can be traced back to a common word in a proto-language. Beyond historical linguistics, cognate identification has applications in other areas of computational linguistics (Mackay and Kondrak, 2005). Because the likelihood that two words across different languages are cognates is highly correlated with their phonetic similarity, cognate identification provides an objective test of the quality of phonetic similarity schemes. The remainder of this paper is organized as fol43 Proceedings of the Workshop on Linguistic Distances, pages 43–50, c Sydney, July 2006. 2006 Association for Computational Linguistics lows. Section 2 discusses the two manually designed schemes: the ALINE algorithm and a linguisticallymotivated metric. Section 3 discusses various learning approaches. In Section 4, we d"
W06-1107,N01-1020,0,0.765375,"d on either the most probable sequence of operations that could produce the two words (Viterbi scoring), or the sum of the scores of all possible paths that could have produced the two words (stochastic scoring). The score of an individual path here is simply the product of the probabilities of the edit operations in the path. The algorithm was evaluated on the task of matching surface pronunciations in the Switchboard data to their canonical pronunciations in a lexicon, yielding a significant improvement in accuracy over Levenshtein distance. 3.2 Levenshtein with learned weights 3.4 Pair HMM Mann and Yarowsky (2001) applied the stochastic transducer of Ristad and Yianilos (1998) for inducing translation lexicons between two languages, but found that in some cases it offered no improvement over Levenshtein distance. In order to remedy this problem, they they proposed to filter the probabilities learned by EM into a few discrete cost classes, which are then used in the standard edit distance algorithm. The LLW approach yielded improvement over both regular Levenshtein and the stochastic transducer. Mackay and Kondrak (2005) propose to computing similarity between pairs of words with a technique adapted fro"
W06-1107,J00-2004,0,0.0602697,"Missing"
W06-1107,J01-4008,1,\N,Missing
W06-3319,W04-1213,0,0.0878962,"Missing"
W06-3319,W02-1001,0,\N,Missing
W07-1301,P06-1035,1,0.772823,"documents. There is a substantial and growing body of work applying computational techniques of various sorts to problems in historical phonology. We mention a few here to give the flavor of the sort of work we hoped to attract for presentation in a coherent SIGMORPHON workshop. Kessler (2001) estimates the likelihood of chance phonemic correspondences using permutation statistics; Kondrak (2002) develops algorithms to detect cognates and sound correspondences; McMahon and McMahon (2005) and also Nakhleh, Ringe and Warnow (2005) apply phylogenetic techniques to comparative reconstruction; and Ellison and Kirby (2006) suggest means of detecting relationships which do not depend on word by word comparisons. But we likewise wished to draw on the creativity of the computational linguistics (CL) community to see which other important problems in historical phonology might also be addressed computationally (see below). There has recently been a good deal of computational work in historical linguistics involving phylogenetic inference, i.e., the inference to the genealogical tree which best explains the historical developments (Gray and Atkinson, 2003; Dunn et al., 2005). While the application of phylogenetic an"
W07-1301,W05-0606,1,0.817712,"Most research has proceeded from the assumption that lists of word pairs be available, as indeed they normally are in the case of dialect atlas data or as they often may be obtained by constructing lexicalizations of the concepts in the so-called “Swadesh” list. But such data is not always available, nor is it straightforward to construct. Singh and Surana construct n-gram models of order five (5), and compare Indo-Iranian and Dravidian languages based on symmetric cross-entropy. Martijn Wieling, Therese Leinonen and John Nerbonne apply PAIR H IDDEN M ARKOV M ODELS (PHMM), introduced to CL by Mackay and Kondrak (2005), to a large collection of Dutch dialect pronunciations in an effort to learn the degree of segment differentiation. Essentially the PHMM regards frequently aligned segments as more similar, and Wieling et al. show that the induced similarity indeed corresponds to phonetic similarity in the case of vowels, whose acoustic properties facilitate the assessment of similarity. 3.3 Views from other Perspectives Several papers examined diachronic change from well-developed perspectives outside of historical linguistics, including evolution and genetic algorithms, language learning, biological cladist"
W07-1301,J01-4008,1,\N,Missing
W07-1317,J94-3004,0,0.0551635,"nguage families. 1 Philip Dilts Department of Linguistics University of Alberta pdilts@ualberta.ca Introduction Identification of cognates and recurrent sound correspondences is a component of two principal tasks of historical linguistics: demonstrating the relatedness of languages, and reconstructing the histories of language families. Manually compiling the list of cognates is an error-prone and time-consuming task. Several methods for constructing comparative dictionaries have been proposed and applied to specific language families: Algonquian (Hewson, 1974), Yuman (Johnson, 1985), Tamang (Lowe and Mazaudon, 1994), and Malayo-Javanic (Oakes, 2000). Most of those methods crucially depend on previously determined regular sound correspondences; each of them was both developed and tested on a single language family. Kondrak (2002) proposes a number of algorithms for automatically detecting and quantifying three characteristics of cognates: recurrent sound correspondences, phonetic similarity, and semantic affinThe experiments reported in this paper were performed in the context of the Upper Necaxa Totonac Project (Beck, 2005), of which one of the authors is the principal investigator. Upper Necaxa is a ser"
W07-1317,J00-2004,0,0.016634,"Missing"
W07-1317,W06-1108,0,0.0685796,"Missing"
W09-3504,N07-1047,1,0.591584,"language-specific regularities in the training data. 2 Transliteration alignment In the transliteration task, training data consist of word pairs that map source language words to words in the target language. The matching between character substrings in the source word and target word is not explicitly provided. These hidden relationships are generally known as alignments. In this section, we describe an EM-based many-to-many alignment algorithm employed by D IREC TL. In Section 4, we discuss an alternative phonetic alignment method. We apply an unsupervised many-to-many alignment algorithm (Jiampojamarn et al., 2007) to the transliteration task. The algorithm follows the expectation maximization (EM) paradigm. In the expectation step shown in Algorithm 1, partial counts γ of the possible substring alignments are collected from each word pair (xT , y V ) in the training data; T and V represent the lengths of words x and y, respectively. The forward probability α is estimated by summing the probabilities of all possible sequences of substring pairings from left to right. The F ORWARD - M 2 M procedure is similar to lines 5 through 12 of Algorithm 1, except that it uses Equation 1 on line 8, Equation 2 on li"
W09-3504,P08-1103,1,0.7541,"amming problem in Equation 3. We utilize a function from the SVMlight package (Joachims, 1999) to solve this optimization problem. v αt−i,v−j δ(xtt−i+1 ,yv−j+1 )βt,v αT ,V In the maximization step, we normalize the partial counts γ to the alignment probability δ using the conditional probability distribution. The EM steps are repeated until the alignment probability δ converges. Finally, the most likely alignment for each word pair in the training data is computed with the standard Viterbi algorithm. 3 Discriminative training We adapt the online discriminative training framework described in (Jiampojamarn et al., 2008) to the transliteration task. Once the training data has been aligned, we can hypothesize that the ith letter substring xi ∈ x in a source language word is transliterated into the ith substring yi ∈ y in the target language word. Each word pair is represented as a feature vector Φ(x, y). Our feature vector consists of (1) n-gram context features, (2) HMM-like transition features, and (3) linear-chain features. The n-gram context features relate the letter evidence that surrounds each letter xi to its output yi . We include all n-grams that fit within a context window of size c. The c value is"
W09-3504,A00-2038,1,0.776093,"rameters by training on the training portion of the provided data and measuring performance on the development portion. For the final testing, we trained the models on all the available labeled data (training plus development data). For each data set, we converted any uppercase letters to lowercase. Our system outputs the top 10 candidate answers for each input word. Table 1 reports the performance of our system on the development and final test sets, measured in terms of top-1 word accuracy (ACC). For certain language pairs, we tested variants of the base Phonetic alignment with ALINE ALINE (Kondrak, 2000) is an algorithm that performs phonetically-informed alignment of two strings of phonemes. Since our task requires the alignment of characters representing different writing scripts, we need to first replace every character with a phoneme that is the most likely to be produced by that character. We applied slightly different methods to the test languages. In converting the Cyrillic script into phonemes, we take advantage of the fact that the Russian orthography is largely phonemic, which makes it a relatively straightforward task. 1 2 For example, http://www.chinesetopinyin.com/ 30 http://www."
W09-3504,P04-1021,0,0.488334,"vidual systems according to their top-1 accuracy on the development set. To obtain the top-1 prediction for each input word, we use simple voting, with ties broken according to the ranking of the systems. We generalize this approach to handle nbest lists by first ordering the candidate transliterations according to the highest rank assigned by any of the systems, and then similarly breaking ties by voting and system ranking. 5 Evaluation In the context of the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009), we tested our system on six data sets: from English to Chinese (EnCh) (Li et al., 2004), Hindi (EnHi), Russian (EnRu) (Kumaran and Kellner, 2007), Japanese Katakana (EnJa), and Korean Hangul (EnKo); and from Japanese Name to Japanese Kanji (JnJk)2 . We optimized the models’ parameters by training on the training portion of the provided data and measuring performance on the development portion. For the final testing, we trained the models on all the available labeled data (training plus development data). For each data set, we converted any uppercase letters to lowercase. Our system outputs the top 10 candidate answers for each input word. Table 1 reports the performance of our s"
W09-3504,N04-1033,0,0.0168432,"(yi−1 , yi ). The linear-chain features are identical to the context features, except that yi is replaced with a bi-gram (yi−1 , yi ). Algorithm 2 trains a linear model in this feature space. The procedure makes k passes over the aligned training data. During each iteration, the model produces the n most likely output words Yˆj in the target language for each input word xj in the source language, based on the current paminψn k ψn − ψo k subject to ∀ˆ y ∈ Yˆ : ˆ )) ≥ ℓ(y, y ˆ) ψn · (Φ(x, y) − Φ(x, y (3) The arg max operation is performed by an exact search algorithm based on a phrasal decoder (Zens and Ney, 2004). This decoder simultaneously finds the l most likely substrings of letters x that generate the most probable output y, given the feature weight vector ψ and the input word xT . The search algorithm is based on the following dynamic programming recurrence: Q(0, $) = 0 Q(t, p) = max {ψ · φ(xtt′ +1 , p′ , p) + Q(t′ , p′ )} ′ p ,p, t−maxX≤t′ &lt;t {ψ · φ($, p′ , $) + Q(T, p′ )} Q(T +1, $) = max ′ p To find the n-best predicted outputs, the table Q records the top n scores for each output substring that has the suffix p substring and is generated by the input letter substring xt1 ; here, p′ is 29 In"
W09-3504,W09-3502,0,\N,Missing
W10-2405,P08-1103,1,0.413264,"Section 3.1), or 3) either word contains a digit. Due to the fact that names transliterated into Chinese consist of multiple Chinese characters and that the Chinese text provided in this shared task is not segmented, we have to adopt a different approach to the English-Chinese mining task (Unlike many other languages, there are no clear boundaries between Chinese words). We first train a generation model using the seed data and then apply a greedy string matching algorithm to extract transliteration pairs. The generation model is built using the discriminative training framework described in (Jiampojamarn et al., 2008). Two models are learned: one is trained using English and Chinese characters, while the other is trained on English and Pinyin (a standard phonetic representation of Chinese characters). In order to mine transliteration pairs from Wikipedia titles, we first use the generation model to produce transliterations for each English token on the source side as both Chinese characters and Pinyin. The generated Chinese characters are ultimately converted to Pinyin during string matching. We also convert all the Chinese characters on the target side to their Pinyin representations when performing strin"
W10-2405,W09-3504,1,0.91083,"language-independent approaches to transliteration mining, which range from simple to sophisticated. 1 Introduction Many out-of-vocabulary words in statistical machine translation and cross-language information retrieval are named entities. If the languages in question use different writing scripts, such names must be transliterated. Transliteration can be defined as the conversion of a word from one writing script to another, which is usually based on the phonetics of the original word. D IREC TL+ is our current approach to name transliteration which is an extension of the D I REC TL system (Jiampojamarn et al., 2009). We augmented the feature set with joint n-gram features which allow the discriminative model to utilize long dependencies of joint information of source and target substrings (Jiampojamarn et al., 2010). Experimental results suggest an improvement over the results achieved by D IREC TL in 2009. Transliteration mining aims at automatically obtaining bilingual lists of names written in different scripts. We explore a number of different approaches to transliteration mining in the context of the NEWS 2010 Shared Task.1 The sole resource that is provided for each language pair is a “seed” 2 Tran"
W10-2405,N10-1103,1,0.548255,"mation retrieval are named entities. If the languages in question use different writing scripts, such names must be transliterated. Transliteration can be defined as the conversion of a word from one writing script to another, which is usually based on the phonetics of the original word. D IREC TL+ is our current approach to name transliteration which is an extension of the D I REC TL system (Jiampojamarn et al., 2009). We augmented the feature set with joint n-gram features which allow the discriminative model to utilize long dependencies of joint information of source and target substrings (Jiampojamarn et al., 2010). Experimental results suggest an improvement over the results achieved by D IREC TL in 2009. Transliteration mining aims at automatically obtaining bilingual lists of names written in different scripts. We explore a number of different approaches to transliteration mining in the context of the NEWS 2010 Shared Task.1 The sole resource that is provided for each language pair is a “seed” 2 Transliteration generation The structure of this section is as follows. In Section 2.1, we describe the pre-processing steps that were applied to all datasets. Section 2.2 reviews two methods for aligning the"
W10-2405,N06-1011,0,0.366309,"the negative examples. We adopt two approaches for selecting negatives. First, we generate all possible source-target pairs in the seed data, and take as negatives those pairs which are not transliterations but have a longest common subsequence ratio (LCSR) above 0.58; this mirrors the approach used by Bergsma and Kondrak (2007). The method assumes that the source and target words are written in the same script (e.g., the foreign word has been romanized). A second possibility is to generate all seed pairings as above, but then randomly select negative examples, thus mirroring the approach in Klementiev and Roth (2006). In this case, the source and target scripts do not need to be the same. Compared with the LCSR technique, random sampling in this manner has the potential to produce negative examples that are very “easy” (i.e., clearly not transliterations), and which may be of limited utility when training a classifier. On the other hand, at test time, the set of candidates extracted from the Wikipedia data will include pairs that have very low LCSR scores; hence, it can be argued that dissimilar pairs should also appear as negative examples in the training set. 3.3.2 Normalized edit distance Normalized ed"
W10-2405,A00-2038,1,0.451066,"atching with its Chinese targets. During testing, we pre-process test data in the same manner, except that we do not remove nonalphabetic characters. After the pre-processing steps, our system proposes 10-best lists for single word titles in the test data. For multi-word titles, we construct 10-best lists by ranking the combination scores of single words that make up the test titles. r | - c | k | u l | r a | - y | i Figure 1: An alignment example. similarity between phonemes. The main advantage of the phonetic alignment is that it requires no training data. We use the ALINE phonetic aligner (Kondrak, 2000), which aligns two strings of phonemes. The example in Figure 1 shows the alignment of the word Barclay to its Katakana transliteration ba-ku-ri. The one-to-one alignment can then be converted to a many-to-many alignment by grouping the Japanese phonemes that correspond to individual Katakana symbols. 2.3 D IREC TL+ We refer to our present approach to transliteration as D IREC TL+. It is an extension of our D IREC TL system (Jiampojamarn et al., 2009). It includes additional “joint n-gram” features that allow the discriminative model to correlate longer source and target substrings. The additi"
W10-2405,J00-2004,0,0.0126423,"The generated Chinese characters are ultimately converted to Pinyin during string matching. We also convert all the Chinese characters on the target side to their Pinyin representations when performing string matching. The transliteration pairs are then mined by combining two different strategies. First of all, we observe that most of the titles that contain a separation symbol “ · ” on the target side are transliterations. In this case, the number of tokens on both sides is often equal. Therefore, the mining task can be formulated as a matching problem. We use a competitive linking approach (Melamed, 2000) to find the best match. First, we select links between all possible pairs if similarity of strings on both sides is above a threshold (0.6 ∗ length(P inyin)). We then greedily extract the pairs with highest similarity until the number of unextracted segments on either side becomes zero. The problem becomes harder when there is no indication of word segmentation for Chinese. Instead of trying to segment the Chinese characters first, we use an incremental string matching strat3.3.5 Generation-based approach In the mining tasks, we are interested in whether a candidate pair (x, y) is a translite"
W10-2405,P07-1083,1,0.931923,"applying a supervised learning approach to the NEWS 2010 Shared Task is that annotated task-specific data is not available to train the system. However, the seed pairs do provide example transliterations, and these can be used as positive training examples. The remaining issue is how to select the negative examples. We adopt two approaches for selecting negatives. First, we generate all possible source-target pairs in the seed data, and take as negatives those pairs which are not transliterations but have a longest common subsequence ratio (LCSR) above 0.58; this mirrors the approach used by Bergsma and Kondrak (2007). The method assumes that the source and target words are written in the same script (e.g., the foreign word has been romanized). A second possibility is to generate all seed pairings as above, but then randomly select negative examples, thus mirroring the approach in Klementiev and Roth (2006). In this case, the source and target scripts do not need to be the same. Compared with the LCSR technique, random sampling in this manner has the potential to produce negative examples that are very “easy” (i.e., clearly not transliterations), and which may be of limited utility when training a classifi"
W10-2405,N10-1102,1,0.773087,"Sequences of letters that cannot be converted into Katakana are removed from the output m-best lists and replaced by lower scoring sequences that pass the back-conversion filter. Otherwise, there is usually a single valid mapping because most Katakana symbols are represented by single vowels or a consonant-vowel pair. The only apparent ambiguity involves the letter n, which can either stand by itself or cluster with the following vowel letter. We resolve the ambiguity by always assuming the latter case unless the letter n occurs at the end of the word. 2.4.4 Language identification for Hindi Bhargava and Kondrak (2010) apply support vector machines (SVMs) to the task of identifying the language of names. The intuition here is that language information can inform transliteration. Bhargava and Kondrak (2010) test this hypothesis on the NEWS 2009 English-Hindi transliteration data by training language identification on data manually tagged as being of either Indian or non-Indian origin. It was found that splitting the data disjointly into two sets and training separate transliteration models yields no performance increase due to the decreased size of the data for the models. We adopt this approach for the NEWS"
W10-2405,D08-1037,0,0.0250091,"andomly select 10K of the successfully aligned pairs to use as negative examples in the training set. Each aligned pair is converted into an “alignment string” by placing the letters that appear in One particularly successful approach is by Bergsma and Kondrak (2007), who use discriminative learning with an improved feature representation. The features are substring pairs that are consistent with a character-level alignment of the two strings. This approach strongly improved performance on cognate identification, while variations of it have also proven successful in transliteration discovery (Goldwasser and Roth, 2008). We therefore adopted this approach for the transliteration mining task. We produce negative training examples using the LCSR threshold approach described in Section 3.2. For features, we extract from the aligned word pairs all substring pairs up to a maximum length of three. We also append characters marking the beginning and end of words, as described in Bergsma and Kondrak (2007). For our classifier, we use a Support Vector Machine (SVM) training with the very efficient LIBLINEAR package (Fan et al., 2008). We optimize the SVM’s regularization parameter using 10-fold cross validation on th"
W10-2405,N07-1047,1,0.491226,"glishHindi (EnHi). These special cases are described in the next section. 2.2 Alignment In the transliteration tasks, training data consist of pairs of names written in source and target scripts without explicit character-level alignment. In our experiments, we applied two different algorithms to automatically generate alignments in the training data. The generated alignments provide hypotheses of substring mappings in the training data. Given aligned training data, a transliteration model is trained to generate names in the target language given names in the source language. The M2M-aligner (Jiampojamarn et al., 2007) is based on the expectation maximization (EM) algorithm. It allows us to create alignments between substrings of various lengths. We optimized the maximum substring sizes for the source and target based on the performance of the end task on the development sets. We allowed empty strings (nulls) only on the target side. We used the M2M-aligner for all alignment tasks, except for English-Pinyin alignment. The source code of the M2M-aligner is publicly available.2 An alternative alignment algorithm is based on the phonetic similarity of graphemes. The key idea of this approach is to represent ea"
W10-3708,W08-0336,0,0.0651969,"Missing"
W10-3708,P08-1102,0,0.0338408,"Missing"
W10-3708,D08-1111,0,0.444346,"of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section 4 describes the integration of the semantic tightness measure into an IR system. Section 5 discusses the available data for Chinese IR evaluation, as well as an approach to acquire new data. Section 6 presents the results of our method on word segmentation and IR. A short conclusion wraps up and gives directions for future work. 2 et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003; Liu et al., 2008; Shi and Nie, 2009). For example, Foo and Li (2004) tested the effects of manual segmentation and various character-based segmentations. In contrast with most related work that only reports the overall performance, they provide an in-depth analysis of query results. They note that a small test collection diminishes the significance of the results. In a series of papers on Chinese IR, Peng and Huang compared various segmentation methods in IR, and proposed a new segmentation method (Peng et al., 2002a; Peng et al., 2002b; Huang et al., 2000; Huang et al., 2003). Their experiments suggest that"
W10-3708,W03-1810,0,0.273307,"s Chinese Information Retrieval from information retrieval (IR) in other languages is the challenge of segmenting the queries and the documents, created by the lack of word delimiters. In general, there are two categories of segmenters: character-based methods and word-based methods. Despite the superior performance of bigram segmenters (Nie et al., 2000; Huang et al., 2000; Foo and Li, 2004), word-based approaches continue to be investigated because of their applica1 This issue is also present to a certain degree in languages that do use explicit delimiters, including English (Halpern, 2000; McCarthy et al., 2003; Guenthner and Blanco, 2004). 55 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 55–63, Beijing, August 2010 compositional semantic units, such as “d d d d” (match maker), and at the other end are sequences of consecutive words with no dependency relationship, such as “dddd” (Shanghai where). In the middle of the spectrum are compositional compounds such as “d d d d” (machine learning) and phrases such as “ddd d” (legitimate income). In this paper, we propose a method to apply the concept of semantic tightness to Chinese IR, which refines the output of"
W10-3708,Y09-2015,1,0.821583,"will lead to better IR performance. For example, keeping “d d d d” (Pinatubo) as a unit should lead to better results than segmenting it into “d(skin)|d(include)|d(picture)|d(large)”. On the other hand, segmenting the compositional phrase “dddd” (Kuwait country) into “dd d(Kuwait)|d(country)” can improve recall. We revise an initial segmentation in two steps: first, we combine components that should not have been separated, such as “dddd” (Pinatubo); second, we split units which are compositional, such as “dddd” (Kuwait country). Semantic Tightness Continuum We adopt the method developed by (Xu et al., 2009) for Chinese semantic unit tightness measure, which was shown to outperform the pointwise mutual information method. For the sake of completeness we briefly describe the basic approach here. The input of the measure is the probability distribution of a unit’s segmentation patterns, i.e., potential segmentation candidates. The output is a tightness value; the greater the value, the tighter the unit. In this paper, we focus on 4gram sequences because 4-character compounds are the most prominent in Chinese. There are eight possible segmentations of any 4-character sequence: “ABCD,” “A|BCD,” “A|B|"
W10-3708,W03-1730,0,0.037714,"n wordbased Chinese information retrieval, with the aim of establishing which segmenter is best for CIR, while pursuing the best segmentation performance in terms of segmented corpus is not the main crux. In this section, we first present the accuracy of different segmentation methods, and then discuss the results of IR systems. 6.1 Chinese Word Segmentation ICTCLAS is a Chinese segmentation tool built by the Institute of Computing Technology, Chinese Academy of Sciences. Its segmentation model is a 59 ICTCLAS Tight Combine Tight Split Online Tight class-based hidden Markov model (HMM) model (Zhang et al., 2003). The segmenter is trained from manually segmented corpus, which makes it ignore both the tightness of units and unknown words such as “dddd” (Pinatubo), which are difficult to identify. In this experiment, we segmented the Chinese Treebank using ICTCLAS and our three methods that employ the tightness measure. The evaluation is based on the manual segmentation of the corpus. We evaluated the methods on the entire Treebank corpus, employing 10-cross validation for result significance verification. In order to measure the tightness of Chinese semantic units, pattern distributions of every 4gram"
W10-3708,C02-1148,0,0.163016,"emantic tightness to Chinese IR, which refines the output of a general Chinese word segmenter using tightness information. In the first phase, we re-combine multiple units that are considered semantically tight into single terms. In the second phase, we break single units that are not sufficiently tight. The experiments involving two different IR systems demonstrate that the new method improves IR performance as compared to the general segmenter. Most Chinese IR systems are evaluated on the data from the TREC 5 and TREC 6 competitions (Huang et al., 2000; Huang et al., 2003; Nie et al., 2000; Peng et al., 2002a; Peng et al., 2002b; Shi and Nie, 2009). That data contains only 54 queries, which are linked to relevancyjudged documents. During our experiments, we found the TREC query data is ill-suited for analyzing the effects of compound segmentation on Chinese IR. For this reason, we created an additional set of queries based on the TREC corpus, which includes a wide variety of semantic compounds. This paper is organized as follows. After summarizing related work on Chinese IR and word segmentation studies, we introduce the measure of semantic tightness. Section 4 describes the integration of the se"
W10-3708,J96-3004,0,0.458679,"Missing"
W10-3708,P09-1118,0,0.0302048,"and ICTCLAS, as it segments queries such as “d d d d” (chain reaction). However, in other instances, it is better than 5 We also experimented with replacing β with the tightness value, but the results were not substantially different. 61 helps the in-depth analysis for the performance of different IR systems on different queries. We also plan to gather more queries and more judged documents in order to further analyze the influence of the proper treatment of semantic units in Chinese information retrieval. A large query set could also make it possible to employ machine learning models for IR (Song et al., 2009). Tight Combine and ICTCLAS since it segments queries such as “dddd” (international chess). The result suggests that the setting of the threshold for non-compositional terms should be below 10. In the range of [1, 0), the result is also mixed. One reason for the low performance of Tight Split is that the tightness measure is not precise for those queries, which affects the segmentation. For example, splitting the queries “dddd” (labor movement) and “dddd” (Zhongshan University) decreases the IR performance dramatically. In future work, we would like to investigate this problem by segmenting qu"
W11-3206,P11-1041,1,0.846753,"present a significant quantity of potentially useful data that is being ignored. In this NEWS 2011 Shared Task submission, we present a method which beneficially applies supplemental transliterations from other languages to English-to-Hindi transliteration. In practice, this is a realistic situation in which transliterations from other languages can help. For example, Wikipedia contains articles on guitarist John Petrucci in English and Japanese, but not in Hindi. If we wanted to automatically generate a stub (skeleton) article in Hindi, we would need to 2 Leveraging multiple transliterations Bhargava and Kondrak (2011) present a method for applying transliterations to grapheme-to-phoneme conversion. Here, we apply this method verbatim to machine transliteration. The method is based on SVM re-ranking applied over n-best output lists generated by a base system. Intuitively, we have 36 Proceedings of the 2011 Named Entities Workshop, IJCNLP 2011, pages 36–40, Chiang Mai, Thailand, November 12, 2011. an existing base transliteration system that, for a given input, provides a set of n scored outputs, with the correct output not always appearing in the top position. In order to help bring the correct output to th"
W11-3206,P07-1092,0,0.0510135,"very good overall accuracy in the English-to-Japanese results (which also only use base D IREC TL+), which further confirm the effectiveness of D IREC TL+ when applied to machine transliteration. 7 ing approach to machine transliteration, and similarly Khapra et al. (2010) propose to transliterate through “bridge” languages. Along similar lines, Kumaran et al. (2010a) find increases in accuracy using a linear-combination-of-scores system that combined the outputs of a direct transliteration system with a system that transliterated through a third language. For statistical machine translation, Cohn and Lapata (2007) also explore the use of a third language. Finally, we also touched briefly on system combination: we applied the SVM re-ranking method to combining the outputs of both D IREC TL+ and S EQUITUR , in particular treating D IREC TL+ as the base system and using S EQUITUR ’s best outputs to re-rank D IREC TL+’s output lists. Finch and Sumita (2010), in contrast, combine S EQUITUR ’s output with that of a phrase-based statistical machine translation system, achieving excellent results. Where our approach is based on SVM reranking, theirs merged the outputs of the two systems together and then used"
W11-3206,W10-2406,0,0.0638967,"s, Kumaran et al. (2010a) find increases in accuracy using a linear-combination-of-scores system that combined the outputs of a direct transliteration system with a system that transliterated through a third language. For statistical machine translation, Cohn and Lapata (2007) also explore the use of a third language. Finally, we also touched briefly on system combination: we applied the SVM re-ranking method to combining the outputs of both D IREC TL+ and S EQUITUR , in particular treating D IREC TL+ as the base system and using S EQUITUR ’s best outputs to re-rank D IREC TL+’s output lists. Finch and Sumita (2010), in contrast, combine S EQUITUR ’s output with that of a phrase-based statistical machine translation system, achieving excellent results. Where our approach is based on SVM reranking, theirs merged the outputs of the two systems together and then used a linear combination of the system scores to re-rank the combined list. Previous work 8 There are three lines of research that are relevant to the work we have presented in this paper: (1) D I REC TL+ and S EQUITUR for machine transliteration; (2) applying multiple languages; and (3) system combination. For the NEWS 2009 and 2010 Shared Tasks,"
W11-3206,C10-2165,0,0.165073,"Missing"
W11-3206,N07-1047,1,0.813778,"ons of the input from other languages. In order to leverage a variety of features and transliterations from all available languages, SVM re-ranking is applied to this task. drak (2011) show the effectiveness of the granular n-gram features vs. the score features as well as the importance of applying multiple transliteration languages. 3 Alignment of training data Practically, we must consider how to generate the alignments between the candidate output transliterations and the supplemental transliterations for the n-gram features, as well as how to generate the similarity scores. M2M-A LIGNER (Jiampojamarn et al., 2007) addresses both of these. M2M-A LIGNER is an unsupervised character alignment system, meaning that it can learn to align data given sufficient training data consisting of unaligned inputoutput pairs. Once trained, M2M-A LIGNER will then produce an alignment for a new pair as well as an alignment score. Because the algorithm is a many-to-many extension of the unsupervised edit distance algorithm, we can see that the alignment score should represent some notion of scriptagnostic similarity. Since we will be applying M2M-A LIGNER between candidate output transliterations and supplemental translit"
W11-3206,W09-3504,1,0.817772,"binations between the candidate output and supplemental transliterations; this provides very fine-grained features that can explicitly use certain characters in supplemental transliterations to help determine the quality of a candidate output. There are, however, some practicalities that must be considered. Bhargava and Kondrak (2011) note the importance of applying multiple languages; they found it difficult to achieve significant improvements using transliterations from one language only. This is due in part to noise in the data (which has been observed in some of the NEWS Shared Task data (Jiampojamarn et al., 2009)) as well as differing conventions for various transliteration “schemes”. These issues are handled implicitly in two ways: (1) the granularity of the n-gram features allows certain character combinations in the transliteration to be learned as being positive or negative indicators of a candidate output’s quality, or that they should be ignored altogether; and (2) the use of multiple transliterations helps smooth out some of the noise. While we do not examine these methods here for brevity’s sake, Bhargava and Kon37 Language EnBa EnCh EnHe EnHi EnJa EnKa EnKo EnPe EnTa EnTh Test set Overlap 1,0"
W11-3206,N10-1103,1,0.941473,"enables us to more closely examine the outputs based on our own linguistic familiarities. The use of other corpora here requires that these results be submitted as a nonstandard run. Note that, because there is not complete coverage for the English-to-Hindi test data, we simply submit the base system’s results as-is in cases where there is no transliteration available from other languages. For each output, a feature vector is constructed. Given alignments between the input and output, for example, binary indicator features based on grouping input and output n-grams in the style of D IREC TL+ (Jiampojamarn et al., 2010a) are constructed. The base system’s score for the output would be included as well, along with differences between the given output’s score and the scores for the other outputs in the list. This feature construction process is then repeated, replacing the input with an available transliteration, for each available transliteration language. The score in this latter case is used as a measure of how “similar” a candidate output is to a “reference” transliteration from another language. We refer to these other transliterations as supplemental transliterations. While the score features provide a"
W11-3206,W10-2405,1,0.822667,"enables us to more closely examine the outputs based on our own linguistic familiarities. The use of other corpora here requires that these results be submitted as a nonstandard run. Note that, because there is not complete coverage for the English-to-Hindi test data, we simply submit the base system’s results as-is in cases where there is no transliteration available from other languages. For each output, a feature vector is constructed. Given alignments between the input and output, for example, binary indicator features based on grouping input and output n-grams in the style of D IREC TL+ (Jiampojamarn et al., 2010a) are constructed. The base system’s score for the output would be included as well, along with differences between the given output’s score and the scores for the other outputs in the list. This feature construction process is then repeated, replacing the input with an available transliteration, for each available transliteration language. The score in this latter case is used as a measure of how “similar” a candidate output is to a “reference” transliteration from another language. We refer to these other transliterations as supplemental transliterations. While the score features provide a"
W11-3206,N10-1065,0,0.0690716,"sibilities. In the final results, we see a substantial difference between the two alignment settings. We hypothesize that the complexity of English-to-Chinese mappings is better captured by the alignments that map longer sequences of English letters to single Chinese characters. making it difficult to generalize to new data. Finally, we observe very good overall accuracy in the English-to-Japanese results (which also only use base D IREC TL+), which further confirm the effectiveness of D IREC TL+ when applied to machine transliteration. 7 ing approach to machine transliteration, and similarly Khapra et al. (2010) propose to transliterate through “bridge” languages. Along similar lines, Kumaran et al. (2010a) find increases in accuracy using a linear-combination-of-scores system that combined the outputs of a direct transliteration system with a system that transliterated through a third language. For statistical machine translation, Cohn and Lapata (2007) also explore the use of a third language. Finally, we also touched briefly on system combination: we applied the SVM re-ranking method to combining the outputs of both D IREC TL+ and S EQUITUR , in particular treating D IREC TL+ as the base system an"
W11-3206,W10-2403,0,\N,Missing
W11-3206,W09-3501,0,\N,Missing
W12-0208,P08-1065,1,0.792288,"its orthographic form. They find A LINE to be an excellent substitute for the expectation-maximization (EM) algorithm when the quantity of the training data is small. Jiampojamarn and Kondrak (2010) confirm that A LINE is highly accurate on the task of letterphoneme alignment. When evaluated on a manually aligned lexicon, its precision was very close to the theoretical upper bound, with the number of incorrect links less than one in a thousand. Lastly, A LINE has also been used for the mapping of annotations, including syllable breaks and stress marks, from the phonetic to orthographic forms (Bartlett et al., 2008; Dou et al., 2009). 4 Conclusion The problems involved in language reconstruction are easy to state but surprisingly hard to solve. As such, they lead to the development of new methods and insights that are not restricted in application to historical linguistics. Although the goal of developing a program that performs a fully automatic reconstruction of a proto-language has yet to been attained, the research conducted towards this goal has been, and is likely to continue to influence other areas of NLP. Acknowledgments This paper refers to research projects that were conducted jointly with th"
W12-0208,P07-1083,1,0.933366,"incipal approaches to computing phonetic similarity on the task of identifying cognates among Indoeuropean languages, both in the supervised and unsupervised context. Their results suggest that given a sufficiently large training set of positive examples, the learning algorithms achieve higher accuracy than manuallydesigned metrics. Techniques such as Pair HMMs improve on the baseline approaches by using a set of similar words to re-weight the costs of edit operations or the score of sequence matches. A more flexible approach is to learn from both positive and negative examples of word pairs. Bergsma and Kondrak (2007a) propose such a discriminative algorithm, which achieves exceptional performance on the task of cognate identification. 2.2 2.3 Phonetic Similarity Recurrent Sound Correspondences An important phenomenon that allows us to distinguish between cognates and borrowings or chance resemblances is the regularity of sound change. The regularity principle states that a change in pronunciation applies to sounds in a given phonological context across all words in the language. Regular sound changes tend to produce recurrent sound correspondences of phonemes in corresponding cognates. Although it may no"
W12-0208,N09-3008,1,0.856044,"UNCLH, pages 49–53, c Avignon, France, April 23 - 24 2012. 2012 Association for Computational Linguistics 2.1 Alignment Identification of the corresponding segments in sequences of phonemes is a necessary step in many applications in both diachronic and synchronic phonology. A LINE (Kondrak, 2000) was originally developed for aligning corresponding phonemes in cognate pairs. It combines a dynamic programming alignment algorithm with a scoring scheme based on multi-valued phonetic features. A LINE has been shown to generate more accurate alignments than comparable algorithms (Kondrak, 2003b). Bhargava and Kondrak (2009) propose a different method of alignment, which is an adaptation of Profile Hidden Markov Models developed for biological sequence analysis. They find that Profile HMMs work well on the tasks of multiple cognate alignment and cognate set matching. Kondrak and Sherif (2006) test representatives of the two principal approaches to computing phonetic similarity on the task of identifying cognates among Indoeuropean languages, both in the supervised and unsupervised context. Their results suggest that given a sufficiently large training set of positive examples, the learning algorithms achieve high"
W12-0208,P09-1015,1,0.837229,"cognates, Sherif and Kondrak (2007) applies several methods, including A LINE, to the task of extracting transliterations from an English-Arabic bitext, and show that it performs better than edit distance, but not as well as a bootstrapping approach to training a memoriless stochastic transducer. Jiampojamarn et al. (2009) employ A LINE for aligning transliterations from distinct scripts by mapping every character to a phoneme that is the most likely to be produced by that character. They observe that even such an imprecise mapping is sufficient for A LINE to produce high quality alignments. Dwyer and Kondrak (2009) apply the A LINE algorithm to the task of grapheme-to-phoneme conversion, which is the process of producing the correct phoneme sequence for a word given its orthographic form. They find A LINE to be an excellent substitute for the expectation-maximization (EM) algorithm when the quantity of the training data is small. Jiampojamarn and Kondrak (2010) confirm that A LINE is highly accurate on the task of letterphoneme alignment. When evaluated on a manually aligned lexicon, its precision was very close to the theoretical upper bound, with the number of incorrect links less than one in a thousa"
W12-0208,I11-1061,1,0.834427,"nd synechdoche. Kondrak (2004) presents a method of combining distinct types of cognation evidence, including the phonetic and semantic similarity, as well as simple and complex recurrent sound correspondences. The method requires no manual parameter tuning, and performs well when tested on cognate identification in the Indoeuropean word lists and Algonquian dictionaries. 2.5 2.6 Phylogenetic Trees Phylogenetic methods are used to build evolutionary trees of languages given data that may include lexical, phonological, and morphological information. Such data rarely admits a perfect phylogeny. Enright and Kondrak (2011) explore the use of the more permissive conservative Dollo phylogeny as an alternative approach that produces an output tree minimizing the number of borrowing events directly from the data. The approach which is significantly faster than the more commonly known perfect phylogeny, is shown to produce plausible phylogenetic trees on three different datasets. 3 NLP Applications In this section, I mention several NLP projects which directly benefitted from insights gained in my research on diachronic linguistics. Statistical machine translation in its original formulation disregarded the actual f"
W12-0208,I11-1097,1,0.899855,"Missing"
W12-0208,P10-1080,1,0.842726,"igning transliterations from distinct scripts by mapping every character to a phoneme that is the most likely to be produced by that character. They observe that even such an imprecise mapping is sufficient for A LINE to produce high quality alignments. Dwyer and Kondrak (2009) apply the A LINE algorithm to the task of grapheme-to-phoneme conversion, which is the process of producing the correct phoneme sequence for a word given its orthographic form. They find A LINE to be an excellent substitute for the expectation-maximization (EM) algorithm when the quantity of the training data is small. Jiampojamarn and Kondrak (2010) confirm that A LINE is highly accurate on the task of letterphoneme alignment. When evaluated on a manually aligned lexicon, its precision was very close to the theoretical upper bound, with the number of incorrect links less than one in a thousand. Lastly, A LINE has also been used for the mapping of annotations, including syllable breaks and stress marks, from the phonetic to orthographic forms (Bartlett et al., 2008; Dou et al., 2009). 4 Conclusion The problems involved in language reconstruction are easy to state but surprisingly hard to solve. As such, they lead to the development of new"
W12-0208,W09-3504,1,0.739855,"words from one writing script to another. Transliteration mining aims at automatically constructing bilingual lists of names for the purpose of training transliteration programs. The task of detecting phonetically-similar words across different writing scripts is quite similar to that of identifying cognates, Sherif and Kondrak (2007) applies several methods, including A LINE, to the task of extracting transliterations from an English-Arabic bitext, and show that it performs better than edit distance, but not as well as a bootstrapping approach to training a memoriless stochastic transducer. Jiampojamarn et al. (2009) employ A LINE for aligning transliterations from distinct scripts by mapping every character to a phoneme that is the most likely to be produced by that character. They observe that even such an imprecise mapping is sufficient for A LINE to produce high quality alignments. Dwyer and Kondrak (2009) apply the A LINE algorithm to the task of grapheme-to-phoneme conversion, which is the process of producing the correct phoneme sequence for a word given its orthographic form. They find A LINE to be an excellent substitute for the expectation-maximization (EM) algorithm when the quantity of the tra"
W12-0208,C04-1137,1,0.811096,"knowledge with computational analysis, it is possible to quickly identify a large number of cognate sets within the family, resulting in a basic comparative dictionary. The dictionary subsequently served as a starting point for generating lists of putative cognates between the Totonacan and MixeZoquean families. The project eventually culminated in a proposal for establishing a super-family dubbed Totozoquean (Brown et al., 2011). Bergsma and Kondrak (2007b) present a method for identifying sets of cognates across groups of languages using the global inference 51 injure or even kill patients. Kondrak and Dorr (2004) apply anumber of similarity measures to the task of identifying confusable drug names. They find that a combination of several measures outperforms all individual measures. Cognate lists can also assist in secondlanguage learning, especially in vocabulary expansion and reading comprehension. On the other hand, the learner needs to pay attention to false friends, which are pairs of similar-looking words that have different meanings. Inkpen et al. (2005) propose a method to automatically classify pairs of words as cognates or false friends, with focus on French and English. The results show tha"
W12-0208,W06-1107,1,0.840807,". A LINE (Kondrak, 2000) was originally developed for aligning corresponding phonemes in cognate pairs. It combines a dynamic programming alignment algorithm with a scoring scheme based on multi-valued phonetic features. A LINE has been shown to generate more accurate alignments than comparable algorithms (Kondrak, 2003b). Bhargava and Kondrak (2009) propose a different method of alignment, which is an adaptation of Profile Hidden Markov Models developed for biological sequence analysis. They find that Profile HMMs work well on the tasks of multiple cognate alignment and cognate set matching. Kondrak and Sherif (2006) test representatives of the two principal approaches to computing phonetic similarity on the task of identifying cognates among Indoeuropean languages, both in the supervised and unsupervised context. Their results suggest that given a sufficiently large training set of positive examples, the learning algorithms achieve higher accuracy than manuallydesigned metrics. Techniques such as Pair HMMs improve on the baseline approaches by using a set of similar words to re-weight the costs of edit operations or the score of sequence matches. A more flexible approach is to learn from both positive an"
W12-0208,N03-2016,1,0.765982,"proach that produces an output tree minimizing the number of borrowing events directly from the data. The approach which is significantly faster than the more commonly known perfect phylogeny, is shown to produce plausible phylogenetic trees on three different datasets. 3 NLP Applications In this section, I mention several NLP projects which directly benefitted from insights gained in my research on diachronic linguistics. Statistical machine translation in its original formulation disregarded the actual forms of words, focusing instead exclusively on their cooccurrence patterns. In contrast, Kondrak et al. (2003) show that automatically identifying orthographically similar words in bitexts can improve the quality of word alignment, which is an important step in statistical machine translation. The improved alignment leads to better translation models, and, consequently, translations of higher quality. Kondrak (2005a) further investigates word alignment in bitexts, focusing on on identifying cognates on the basis of their orthographic similarity. He concludes that word alignment links can be used as a substitute for cognates for the purpose of evaluating word similarity measures. Many hundreds of drugs"
W12-0208,W07-1317,1,0.751345,"in bitexts, focusing on on identifying cognates on the basis of their orthographic similarity. He concludes that word alignment links can be used as a substitute for cognates for the purpose of evaluating word similarity measures. Many hundreds of drugs have names that either look or sound so much alike that doctors, nurses and pharmacists sometimes get them confused, dispensing the wrong one in errors that may Cognate Sets When data from several related languages is available, it is preferable to identify cognate sets simultaneously across all languages rather than perform pairwise analysis. Kondrak et al. (2007) apply several of the algorithms described above to a set of diverse dictionaries of languages belonging to the Totonac-Tepehua family in Mexico. They show that by combining expert linguistic knowledge with computational analysis, it is possible to quickly identify a large number of cognate sets within the family, resulting in a basic comparative dictionary. The dictionary subsequently served as a starting point for generating lists of putative cognates between the Totonacan and MixeZoquean families. The project eventually culminated in a proposal for establishing a super-family dubbed Totozoq"
W12-0208,A00-2038,1,0.689151,"be performed by a computer program. In this section, I discuss methods for implementing several steps of the comparative method that are outlined above. The ordering of projects is roughly chronological. For an article-length summary see (Kondrak, 2009). 49 Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 49–53, c Avignon, France, April 23 - 24 2012. 2012 Association for Computational Linguistics 2.1 Alignment Identification of the corresponding segments in sequences of phonemes is a necessary step in many applications in both diachronic and synchronic phonology. A LINE (Kondrak, 2000) was originally developed for aligning corresponding phonemes in cognate pairs. It combines a dynamic programming alignment algorithm with a scoring scheme based on multi-valued phonetic features. A LINE has been shown to generate more accurate alignments than comparable algorithms (Kondrak, 2003b). Bhargava and Kondrak (2009) propose a different method of alignment, which is an adaptation of Profile Hidden Markov Models developed for biological sequence analysis. They find that Profile HMMs work well on the tasks of multiple cognate alignment and cognate set matching. Kondrak and Sherif (2006"
W12-0208,N01-1014,1,0.73903,"lingual word lists into cognate sets. The method incorporates a number of diverse word similarity measures and features that encode the degree of affinity between pairs of languages. Semantic Similarity Only a fraction of all cognates can be detected by analyzing Swadesh-type word lists, which are usually limited to at most 200 basic meanings. A more challenging task is identifying cognates directly in bilingual dictionaries, which define the meanings of words in the form of glosses. The main problem is how to quantify semantic similarity of two words on the basis of their respective glosses. Kondrak (2001) proposes to compute similarity of glosses by augmenting simple string-matching with a syntactically-informed keyword extraction. In addition, the concepts mentioned in glosses are mapped to WordNet synsets in an attempt to account for various types of diachronic semantic change, such as generalization, specialization, and synechdoche. Kondrak (2004) presents a method of combining distinct types of cognation evidence, including the phonetic and semantic similarity, as well as simple and complex recurrent sound correspondences. The method requires no manual parameter tuning, and performs well w"
W12-0208,C02-1016,1,0.754044,"eply interested in words. Even though many NLP algorithms treat words as indivisible abstract atoms, I think that much can be gained by considering smaller units: morphemes, phonemes, syllables, and letters. Words that are similar at the sub-word level often exhibit similarities on the syntactic and semantic level as well. Even more important, as we move beyond written text towards speech and pronunciation, the make-up of words cannot be ignored anymore. I commenced my NLP research by investigating ways of developing computer programs for various stages of the language reconstruction process (Kondrak, 2002a). From the very start, I 2 Diachronic NLP The comparative method is the technique applied by linguists for reconstructing proto-languages. It consists of several stages, which include the identification of cognates by semantic and phonetic similarity, the alignment of cognates, the determination of recurrent sound correspondences, and finally the reconstruction of the proto-forms. The results of later steps are used to refine the judgments made in earlier ones. The comparative method is not an algorithm, but rather a collection of heuristics, which involve intuitive criteria and broad domain"
W12-0208,2005.mtsummit-papers.40,1,0.879783,"employing an algorithm designed for extracting non-compositional compounds from bitexts. In experimental evaluation against a set of correspondences manually In many applications, it is necessary to algorithmically quantify the similarity exhibited by two strings composed of symbols from a finite alphabet. Probably the most well-known measure of string similarity is the edit distance, which is the number of insertions, deletions and substitutions required to transform one string into another. Other measures include the length of the longest common subsequence, and the bigram Dice coefficient. Kondrak (2005b) introduces a notion of ngram similarity and distance, and shows that edit distance and the length of the longest common subsequence are special cases of n-gram distance and similarity, respectively. Another class of similarity measures are specifically for phonetic comparison. The A LINE algorithm chooses the optimal alignment on the basis of a similarity score, and therefore can also be used for computing phonetic similarity of words. Kondrak (2001) shows that it performs well on the task of cognate identification. The above algorithms have the important advantage of not requiring training"
W12-0208,W05-0606,1,0.829857,"Missing"
W12-0208,P07-1109,1,0.760539,"cally classify pairs of words as cognates or false friends, with focus on French and English. The results show that it is possible to achieve very good accuracy even without any training data by employing orthographic measures of word similarity. Transliteration is the task of converting words from one writing script to another. Transliteration mining aims at automatically constructing bilingual lists of names for the purpose of training transliteration programs. The task of detecting phonetically-similar words across different writing scripts is quite similar to that of identifying cognates, Sherif and Kondrak (2007) applies several methods, including A LINE, to the task of extracting transliterations from an English-Arabic bitext, and show that it performs better than edit distance, but not as well as a bootstrapping approach to training a memoriless stochastic transducer. Jiampojamarn et al. (2009) employ A LINE for aligning transliterations from distinct scripts by mapping every character to a phoneme that is the most likely to be produced by that character. They observe that even such an imprecise mapping is sufficient for A LINE to produce high quality alignments. Dwyer and Kondrak (2009) apply the A"
W12-0208,P09-1014,1,\N,Missing
W12-4411,N12-1044,1,0.826854,"hallenging because the relationship between the source and target representations is often ambiguous. The process is further complicated by restrictions in the target phonological system. D IREC TL+ (Jiampojamarn et al., 2010a) is an online discriminative training system that incorporates joint n-gram features and many-to-many alignments, which are generated by M2M-A LIGNER (Jiampojamarn et al., 2007). Our team employed variants of D IREC TL+ in the previous editions of the Shared Task on Transliteration (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011). Recently, Bhargava and Kondrak (2012) show significant improvement in accuracy for the English-to-Japanese task by leveraging supplemental transliterations from other scripts. In this edition of the Shared Task on Transliteration, we experiment with language-specific adaptations for the EnCh and ArEn data sets. The structure of the paper is as follows. In Section 2, we 71 We run D IREC TL+ with all of the features described in (Jiampojamarn et al., 2010a). System parameters were determined during development. For the EnCh experiments, we set the context feature size to 5, the transition feature size to 2, and the joint n-gram fea"
W12-4411,N07-1047,1,0.875465,"the official test results. 2 Base System 1 Introduction Transliteration transforms an orthographic form of a word in one writing script into an orthographic form of the same word in another writing script. The problem is challenging because the relationship between the source and target representations is often ambiguous. The process is further complicated by restrictions in the target phonological system. D IREC TL+ (Jiampojamarn et al., 2010a) is an online discriminative training system that incorporates joint n-gram features and many-to-many alignments, which are generated by M2M-A LIGNER (Jiampojamarn et al., 2007). Our team employed variants of D IREC TL+ in the previous editions of the Shared Task on Transliteration (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011). Recently, Bhargava and Kondrak (2012) show significant improvement in accuracy for the English-to-Japanese task by leveraging supplemental transliterations from other scripts. In this edition of the Shared Task on Transliteration, we experiment with language-specific adaptations for the EnCh and ArEn data sets. The structure of the paper is as follows. In Section 2, we 71 We run D IREC TL+ with all of the featu"
W12-4411,W09-3504,1,0.92542,"pt into an orthographic form of the same word in another writing script. The problem is challenging because the relationship between the source and target representations is often ambiguous. The process is further complicated by restrictions in the target phonological system. D IREC TL+ (Jiampojamarn et al., 2010a) is an online discriminative training system that incorporates joint n-gram features and many-to-many alignments, which are generated by M2M-A LIGNER (Jiampojamarn et al., 2007). Our team employed variants of D IREC TL+ in the previous editions of the Shared Task on Transliteration (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011). Recently, Bhargava and Kondrak (2012) show significant improvement in accuracy for the English-to-Japanese task by leveraging supplemental transliterations from other scripts. In this edition of the Shared Task on Transliteration, we experiment with language-specific adaptations for the EnCh and ArEn data sets. The structure of the paper is as follows. In Section 2, we 71 We run D IREC TL+ with all of the features described in (Jiampojamarn et al., 2010a). System parameters were determined during development. For the EnCh experiments, we se"
W12-4411,N10-1103,1,0.88039,"owledge and system combination algorithm. In Section 4 we elaborate on the difficulty of Arabic name transliteration and propose a letter mapping scheme. In Section 5 we present the official test results. 2 Base System 1 Introduction Transliteration transforms an orthographic form of a word in one writing script into an orthographic form of the same word in another writing script. The problem is challenging because the relationship between the source and target representations is often ambiguous. The process is further complicated by restrictions in the target phonological system. D IREC TL+ (Jiampojamarn et al., 2010a) is an online discriminative training system that incorporates joint n-gram features and many-to-many alignments, which are generated by M2M-A LIGNER (Jiampojamarn et al., 2007). Our team employed variants of D IREC TL+ in the previous editions of the Shared Task on Transliteration (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011). Recently, Bhargava and Kondrak (2012) show significant improvement in accuracy for the English-to-Japanese task by leveraging supplemental transliterations from other scripts. In this edition of the Shared Task on Transliteration, we e"
W12-4411,W10-2405,1,0.859094,"owledge and system combination algorithm. In Section 4 we elaborate on the difficulty of Arabic name transliteration and propose a letter mapping scheme. In Section 5 we present the official test results. 2 Base System 1 Introduction Transliteration transforms an orthographic form of a word in one writing script into an orthographic form of the same word in another writing script. The problem is challenging because the relationship between the source and target representations is often ambiguous. The process is further complicated by restrictions in the target phonological system. D IREC TL+ (Jiampojamarn et al., 2010a) is an online discriminative training system that incorporates joint n-gram features and many-to-many alignments, which are generated by M2M-A LIGNER (Jiampojamarn et al., 2007). Our team employed variants of D IREC TL+ in the previous editions of the Shared Task on Transliteration (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011). Recently, Bhargava and Kondrak (2012) show significant improvement in accuracy for the English-to-Japanese task by leveraging supplemental transliterations from other scripts. In this edition of the Shared Task on Transliteration, we e"
W12-4411,W11-3206,1,\N,Missing
W13-1718,P07-1083,1,0.940831,"-L dictionary. We use the following algorithm: 1. For each misspelled English word m found in a document, identify the most likely intended word e using a spell-checking program. 2. For each language L: (a) Look up the translation f of the intended word e in language L. (b) Compute the orthographic edit distance D between the words. (c) If D(e, f ) &lt; t then f is assumed to be a cognate of e. (d) If f is a cognate and D(m, f ) &lt; D(e, f ) then we consider it as a clue that L = L1. We use a simple method of computing orthographic distance with threshold t = 0.58 defined as the baseline method by Bergsma and Kondrak (2007). However, more accurate methods of cognate identification discussed in that paper could also be used. Misspellings can betray cognate interference even if the misspelled word has no direct cognate in language L1. For example, a Spanish speaker might spell the word quick as cuick because of the existence of numerous cognates such as question/cuesti´on. Our misspelling features can detect such phenomena at the character level; in this case, qu:cu corresponds to an individual misspelling feature. 4.7 0.3 0.4 Meta-features We included a number of document-specific metafeatures as suggested by Ber"
W13-1718,N12-1033,0,0.0480618,"Missing"
W13-1718,N07-1047,1,0.849432,"ent to distinguish the spelling characteristics of writers from 11 different languages. We extract the spelling error features from character-level alignments between the misspelled word and the intended word. For example, if the word abstract is identified as the intended spelling of a misspelling abustruct, the character alignments are as follows: a | a bu | b s | s t | t ru | ra ct | ct Only the alignments of the misspelled parts, i.e. (bu,b) and (ru,ra) in this case, are used as features. The spell-checker we use is aspell1 , and the character-level alignments are generated by m2maligner (Jiampojamarn et al., 2007). 4.6 Cognate Interference Cognates are words that share their linguistic origin. For example, English become and German bekommen have evolved from the same word in a common ancestor language. Other cognates are words that have been transfered between languages; for example, English system comes from the Greek word συστ ηµα via Latin and French. On average, pairs of cognates exhibit higher orthographic similarity than unrelated translation pairs (Kondrak, 2013). Cognate interference may cause an L1-speaker to use a cognate word instead of a correct English translation (for example, become inst"
W13-1718,P03-1054,0,0.00831794,"bigram across all training documents. Then, during feature extraction, we again determine the relative frequency of each character bigram across documents. We then use binary features to indicate if the frequency of a bigram is higher than the average frequency. Experiments conducted on the development set showed that although this modified frequency was out-performed by the original relative frequency on its own, our method performed better when further features were incorporated into the classifier. 4.3 Part-of-speech n-grams All documents are tagged with POS tags using the Stanford parser (Klein and Manning, 2003), From the documents in the training data, a list of all POS bigrams was generated, and documents were represented by binary indicators of the presence or absence of a bigram in the document. As with character bigrams, we did not simply use the most common bigrams, but rather considered all bigrams that appeared in the training data. 4.4 Syntax Production Rules After generating syntactic parse trees with the Stanford Parser. we extract all possible production rules from each document, including lexicalized rules. The features are binary; if a production rule occurs in an essay, its value is se"
W13-1718,C12-1158,0,0.0240562,"of their frequency. An early concern with token bigrams was that they were both large in number, and sparse. In an attempt to reduce the number of bigrams, we conducted experiments on the development set with different numbers of bigrams that exhibited the highest information gain. It was found that using all combinations of word bigrams improved predictive accuracy the most, and did not lead to a significant cost to the SVM. Thus, for experiments on the test set, all token bigrams that were encountered in the training set were used as features. 4.2 4 Word n-grams Character n-grams Following Tetreault et al. (2012), we utilize all character bigrams that occur in the training data, rather than only the most frequent ones. However, where the literature uses either binary indicators or relative frequency of bigrams as features, we use a modified form of the relative frequency in our classifier. In a pre-processing step, we calculate the average frequency of each character bigram across all training documents. Then, during feature extraction, we again determine the relative frequency of each character bigram across documents. We then use binary features to indicate if the frequency of a bigram is higher tha"
W13-1718,W13-1706,0,0.0629267,"ond language (L2). Speakers and writers of the same L1 can sometimes be identified by similar L2 errors. The weak Contrastive Analysis Hypothesis (Jarvis and Crossley, 2012) suggests that these errors may be a result of L1 causing linguistic interference; that is, common tendencies of a speaker’s L1 are superimposed onto their L2. Native Language Identification, or NLI, is an attempt to exploit these errors in order to identify the L1 of the speaker from texts written in L2. Our group at the University of Alberta was unfamiliar with the NLI research prior to the announcement of a shared task (Tetreault et al., 2013). However, we saw it as an opportunity to apply our expertise in character-level NLP to a new task. Our goal was to propose novel features, and to combine them with other features that have been previously shown to work well for language identification. In the end, we managed to define two feature sets that are based on spelling errors made by L2 writers. Cognate features relate a spelling mistake to cognate interference with the writer’s L1. Misspelling features identify common mistakes that may be indicative of the writer’s L1. Both feature sets are meant to exploit the Contrastive Analysis"
W13-1718,W07-0602,0,0.241271,"Missing"
W13-1718,D11-1148,0,0.0199766,"absence of a bigram in the document. As with character bigrams, we did not simply use the most common bigrams, but rather considered all bigrams that appeared in the training data. 4.4 Syntax Production Rules After generating syntactic parse trees with the Stanford Parser. we extract all possible production rules from each document, including lexicalized rules. The features are binary; if a production rule occurs in an essay, its value is set to 1, and 0 otherwise. For each language, we use information gain for feature selection to select the most informative production rules as suggested by Wong and Dras (2011). Experiments on the development set indicated that the information gain is superior to raw frequency for the purpose of syntax feature selection. Since the accuracy increased as we added more production rules, the feature set for final testing includes all production rules encountered in the training set. The majority of the rules are of the form POS ⇒ terminal. We hypothesized that most of the information contained in these rules may be already captured by the word unigram features. However, experiments on the development set suggested that the lexicalized rules contain information that is n"
W14-2808,W02-0505,0,0.0408524,"modifies the pronunciation to fit the target language phonology, and writes it down using the orthographic rules of the target script. In reality, however, the source orthography strongly influences the form of the transliteration. For example, the Russian transliteration of the name Dickens on Wikipedia back-transliterates as Dikkens, although Dykynz would be much closer to the original pronunciation. For less well-known names that first appear in English-language news, human transliterators are often in the dark because the correct pronunciation may be difficult to guess from the spelling. Al-Onaizan and Knight (2002) report that a spelling-based model outperforms a phoneticbased model even when pronunciations are extracted from a pronunciation dictionary. Bhargava and Kondrak (2012) present a re-ranking approach that is able to improve spelling-based models by consulting the supplied pronunciations. It remains an open question how to design a superior joint model that would generate transliterations directly from both spelling and pronunciation. 7 Phonetic Similarity of Translations Words that are phonetically similar across different languages tend to be transliterations, or at least share the same origi"
W14-2808,P14-2138,1,0.827816,"Missing"
W14-2808,P08-1065,1,0.762762,"entify the most discriminative words and the corresponding character bigrams. They find that the removal of such words results in a substantial drop in the accuracy of the classifier that is based exclusively on character bigrams, and that the majority of the most indicative character bigrams are common among different language sets. They conclude that the effectiveness of a bigrambased classifier in identifying the native language of a writer is primarily driven by the relative fre10 Syllabification and Morphology Orthographic syllabification of words is sometimes referred to as hyphenation. Bartlett et al. (2008) propose a sequence prediction approach to syllabify out-of-dictionary words based on letter n-gram features. Despite its high accuracy, their system suffers from the lack of awareness of compound nouns and other morphological phenomena. For example, hold-o-ver is incorrectly syllabified as hol-dov-er. Yao and Kondrak (2014) demonstrate that the accuracy of orthographic syllabification can be improved by using morphological information. In particular, incorporating oracle morphological segmentation substantially reduces the syllabification error rate on English and German. If unsupervised segm"
W14-2808,N09-1005,0,0.0309692,"oses to explain this phe6 Transliteration and Decipherment Although transliteration is typically defined as conversion between writing scripts, the proper form strongly depends on the particular target language with its phonological and orthographic constraints. For example, the name of the city that hosted the recent Winter Olympics is represented in various European languages as Sochi, Sotchi, Sotschi, Sotsji, Sotji, Sotˇsi, Soˇci, Soczi, Szocsi, etc. In order to derive language-specific transliteration models, we would need to collect training data for thousands of possible language pairs. Ravi and Knight (2009) introduce the task of unsupervised transliteration without parallel resources. They formulate the problem as decipherment, and reconstruct cross-lingual phoneme mapping tables from Japanese words of English origin, 66 nomenon by positing a chain of correlations between the following word characteristics: translatability, frequency, length, and similarity. The key observation is that translations are on average closer in terms of their length than random words. First, pairs of cross-lingual translations exhibit a correlation with respect to the logarithm of their frequencies. Intuitively, tran"
W14-2808,N12-1044,1,0.843136,"thography strongly influences the form of the transliteration. For example, the Russian transliteration of the name Dickens on Wikipedia back-transliterates as Dikkens, although Dykynz would be much closer to the original pronunciation. For less well-known names that first appear in English-language news, human transliterators are often in the dark because the correct pronunciation may be difficult to guess from the spelling. Al-Onaizan and Knight (2002) report that a spelling-based model outperforms a phoneticbased model even when pronunciations are extracted from a pronunciation dictionary. Bhargava and Kondrak (2012) present a re-ranking approach that is able to improve spelling-based models by consulting the supplied pronunciations. It remains an open question how to design a superior joint model that would generate transliterations directly from both spelling and pronunciation. 7 Phonetic Similarity of Translations Words that are phonetically similar across different languages tend to be transliterations, or at least share the same origin. For this reason, words on two sides of a bitext are more likely to correspond to each other if they exhibit phonetic similarity (Kondrak, 2005). This is true even for"
W14-2808,P14-1010,1,0.819019,"ing performed before the the translation process. Since the English words are not segmented, the output of the decoder can be directly compared to the reference translation. However, when translating in the opposite direction, the segmentation must be reversed to make the generated text readable. Desegmentation is typically performed as a postprocessing step that is independent from the decoding process. Unfortunately, the pipeline approach may prevent the desegmenter from recovering from errors made by the decoder, including output morpheme sequences that cannot be combined into valid words. Salameh et al. (2014) propose to replace the pipeline approach with a solution inspired by finite-state methods. They perform desegmentation directly on the search graph of a phrase-based 2 Inflection Generation An alternative to the morphological segmentation approach is to reduce the diverse forms in the training bitext to lemmas, and, at test time, reconstruct the wordforms in the target language directly from lemmas annotated with morphological features. Note that the wordforms that have not been seen in training pose a problem for language models, and are typically shunned by the current SMT systems. Although"
W14-2808,W13-1706,0,0.0290407,"Missing"
W14-2808,D13-1174,0,0.0211459,"raining data to a list of name pairs is the lack of the context that is required to account for morphological alterations. For example, the title of the Russian Wikipedia page that corresponds to Presidency of Barack Obama back-transliterates as Presidentstvo Baraka Obamy, where the personal 3 From Syntax to Morphology In some languages, syntactic function of phrases is mainly marked by word position and prepositions, while other languages rely on morphology to a greater degree. Similarly, verbal attributes such as tense, person, and gender, can be either encoded morphologically or lexically. Chahuneau et al. (2013) propose a discriminative model for translating into morphologically rich languages that predicts inflections of target words from sourceside annotations that include POS tags, dependency parses, and semantic clusters. In other words, they exploit the syntax of the source language to select the most likely wordforms in the target language, The open question in this case is whether instead of learning a prediction model separately for each language pair, the morphological features could be mapped directly on the source words. For example, in the phrase she would have asked, the actual morpholog"
W14-2808,W07-0602,0,0.0168987,"cond, the connection between word frequency and length is well established (Zipf, 1936). Finally, pairs of words that differ in length are less likely to be considered similar, which is reflected by word similarity measures. In summary, the reason for the greater phonetic similarity of translations lies in the similarity of their frequencies, which is reflected by the similarity of their lengths. This hypothesis remains to be verified on other languages and data sets. quency of words rather than by the influence of the phonology of L1. Although this provides evidence against the hypothesis of Tsur and Rappoport (2007), the question to what degree the L1 phonology affects L2 writing remains open. 9 English Orthography The English spelling system is notorious for its irregularity. Kominek and Black (2006) estimate that it is about 3 times more complex than German, and 40 times more complex than Spanish. This is confirmed by lower accuracy of letter-to-phoneme systems on English (Bisani and Ney, 2008). A survey of English spelling (Carney, 1994) devotes 120 pages to describe phoneme-to-letter correspondences, and lists 226 letter-to-phoneme rules, almost all of which admit exceptions. In view of this, the cla"
W14-2808,D09-1111,0,0.021823,"ental comparison, or as a misdirected effort to investigate irrelevant problems. The NEWS Shared Task on Machine Transliteration was held four times between 2009 and 2012 (Zhang et al., 2012). With the exception of the 2010 edition that included a transliteration mining task, the shared task was invariably defined in terms of learning transliteration models from the training sets of word pairs. This framework seems to ignore the fact that many of the transliteration target words can be found in monolingual corpora, in a marked contrast with the prevalent SMT practice of avoiding unseen words. Cherry and Suzuki (2009) show that the inclusion of a target lexicon dramatically improves transliteration accuracy. Unfortunately, the paper has largely been ignored by the transliteration community (perhaps because it strays from the standard task formulation), as well as the SMT community (perhaps because it shows only modest gains in terms of BLEU score). Another drawback of limiting the training data to a list of name pairs is the lack of the context that is required to account for morphological alterations. For example, the title of the Russian Wikipedia page that corresponds to Presidency of Barack Obama back-"
W14-2808,D11-1057,0,0.0268061,"with a stem. These combinations are rarely concatenative, often affecting characters at the end or even in the middle of a stem. 64 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 64–68, c Baltimore, Maryland USA, June 27 2014. 2014 Association for Computational Linguistics notation could not only help machine translation, but also provide a rich source of information in the monolingual context, which would go well beyond POS tagging. For languages without hand-built morphological analyzers and generators, automated learning of morphological paradigms is the only option. Dreyer and Eisner (2011) propose a Dirichlet process mixture model and loopy belief propagation to learn complete paradigms starting from an initial small set of seed paradigms. An unannotated corpus is utilized to guide the predictions of the model by reducing the likelihood of generating unseen wordforms. Durrett and DeNero (2013) align the lemmas with inflected forms to identify spans that change for the inflections, and learn explicit rules for applying those changes in contexts in which they appear. Their joint model is aware of complete paradigms, and is able to correct errors made on individual inflections. Ni"
W14-2808,N13-1138,0,0.0179689,"ld not only help machine translation, but also provide a rich source of information in the monolingual context, which would go well beyond POS tagging. For languages without hand-built morphological analyzers and generators, automated learning of morphological paradigms is the only option. Dreyer and Eisner (2011) propose a Dirichlet process mixture model and loopy belief propagation to learn complete paradigms starting from an initial small set of seed paradigms. An unannotated corpus is utilized to guide the predictions of the model by reducing the likelihood of generating unseen wordforms. Durrett and DeNero (2013) align the lemmas with inflected forms to identify spans that change for the inflections, and learn explicit rules for applying those changes in contexts in which they appear. Their joint model is aware of complete paradigms, and is able to correct errors made on individual inflections. Nicolai et al. (2014) train a discriminative string transducer on lemma-inflection pairs, and apply a separate re-ranking step to take advantage of the paradigmatic constraints. In spite of its relative simplicity, their string transduction approach outperforms the previous approaches to learning morphological"
W14-2808,C14-1218,1,0.871869,"Missing"
W14-2808,P97-1017,0,0.212175,"lai et al. (2014) train a discriminative string transducer on lemma-inflection pairs, and apply a separate re-ranking step to take advantage of the paradigmatic constraints. In spite of its relative simplicity, their string transduction approach outperforms the previous approaches to learning morphological paradigms on several European languages. The question remains whether the string transduction approach is also superior to more complex methods on languages with different morphological systems. 4 Transliteration and Morphology Transliteration is sometimes defined as “phonetic translation” (Knight and Graehl, 1997). In fact, it is straightforward to train a transliteration model using SMT toolkits by treating individual characters as words, and words as sentences. However, unless substantial modifications are made, the accuracy of such a system will be mediocre. Transliteration needs a dedicated approach in order to fully exploit the source-side context and other constraints. The way we define tasks in NLP is important, because the definitions (and shared tasks) tend to guide research in a particular direction. New papers are expected to show improvement over previously published results, preferably on"
W14-2808,N06-1030,0,0.0424195,"Missing"
W14-2808,2005.mtsummit-papers.40,1,0.653791,"ctionary. Bhargava and Kondrak (2012) present a re-ranking approach that is able to improve spelling-based models by consulting the supplied pronunciations. It remains an open question how to design a superior joint model that would generate transliterations directly from both spelling and pronunciation. 7 Phonetic Similarity of Translations Words that are phonetically similar across different languages tend to be transliterations, or at least share the same origin. For this reason, words on two sides of a bitext are more likely to correspond to each other if they exhibit phonetic similarity (Kondrak, 2005). This is true even for completely unrelated languages because of the prevalence of loanwords, proper names, and technical terms. Orthographic similarity, which reflects phonetic similarity, has been exploited in the past to improve word and sentence alignment in SMT, and other NLP tasks. Surprisingly, the correlation with phonetic similarity appears to hold for any translations, defined as words that express the same meaning in some context. Kondrak (2013) observes that even after all cognates and loanwords are removed from consideration, the similarity between the words from different langua"
W14-2808,W12-4402,0,\N,Missing
W15-1011,P08-2039,0,0.152648,"aluable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a growing interest in segmentation on the target side (Oflazer and Durgar El-Kahlout, 2007), which introduces a question of how to perform proper desegmentation (Badr et al., 2008). El Kholy and Habash (2012) have conducted a thorough exploration of the various segmentation and desegmentation options for English to Arabic translation, and we follow their work when designing our test bed. Method Unsegmented Desegment before: Alignment model Lexical weights Language model Tuning Flexible boundaries? Never segment Word Word Word Word No Alignment Deseg. Phrase extraction Morph Word Word Word No Phrase Table Deseg. Decoding Morph Morph Word Word No One-best Deseg. Evaluation Morph Morph Morph Morph Yes Lattice Deseg. Evaluation Morph Morph Morph + Word Morph then Word Yes T"
W15-1011,J93-2003,0,0.0425605,"s the Arabic target language before training begins, and the decoder’s output is generated in segmented form. As a post-processing step, the one-best output is desegmented using a mapping table and desegmentation rules. All of the component models used during decoding are based on morphemes instead of words. The segmented models are intended to help alleviate data sparsity and improve token correspondence. Unlike the unsegmented system, this system requires a desegmentation step, which can produce morphologically incorrect words. 3.2 Alignment Desegmentation Our unsupervised alignment models (Brown et al., 1993; Och and Ney, 2003) are sensitive both to poor word-to-word correspondence and to data sparsity issues. They are also at the very start of the SMT pipeline; they impact nearly all other downstream models. Therefore, it would be reasonable to suspect that the primary benefit of segmentation could come from improved word alignment. Alignment desegmentation allows us to test this theory by desegmenting immediately after alignment. More specifically, we segment the target side as pre-processing. After word alignment, we replace the segmented Arabic training data with its unsegmented form. Note th"
W15-1011,N12-1047,1,0.818464,"by converting different forms of Alif and Ya to bare Alif and dotless Ya. In order to generate the desegmentation table, we analyze the MADA segmentations from the Arabic side of the parallel training data to collect mappings from morpheme sequences to surface forms. 4.2 penalties. The decoder uses Moses’ default search parameters, except that the maximum phrase length is set to 8. The decoder’s log-linear model is tuned with MERT (Och, 2003). Following Salameh et al. (2014), the tuning of the re-ranking models for lattice desegmentation is performed using a lattice variant of hope-fear MIRA (Cherry and Foster, 2012); lattices are pruned to a density of 50 edges per word before re-ranking. We evaluate our system using BLEU (Papineni et al., 2002). Decoder Integration Lattice Desegmentation performs best overall, which is not entirely surprising, as it has access to all of the information present in the other systems. Notably, it outperforms Phrase Table Desegmentation; this is the first time to our knowledge that the two have been compared directly. The main disadvantage of Lattice Deseg, which is not present in Alignment and Phrase Table Deseg, is the lack of decoder integration of its unsegmented view o"
W15-1011,P08-1115,0,0.0351294,"y on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a growing interest in segmentation on the target side (Oflazer and Durgar El-Kahlout, 2007), which introduces a question of how to perform proper desegmentation (Badr et al., 2008). El Kholy and Habash (2012) have conducted a thorough exploration of the various segmentation and desegmentation options for English to Arabic translation, and we follow their work when designing our test bed. Method Unsegmented Desegment before: Alignment model Lexical weights Language model Tuning Flexible boundaries? Never segment Word Word Word Word No Alignment Deseg. Phrase extractio"
W15-1011,P12-1016,0,0.0174589,"crease BLEU score, they also reduce the system’s use of morphological affixes to well below that of a human. Finally, we present the first direct comparison between phrase table desegmentation (Luong et al., 2010) and lattice desegmentation (Salameh et al., 2014). 2 Background Our work builds on earlier studies of automatic morphological segmentation and its impact on SMT. There are many ways to segment syntactically relevant affixes from stems. Supervised techniques may either pass through an intermediate morphological analysis (Habash et al., 2009), or directly segment the character stream (Green and DeNero, 2012); recent work on supervised Arabic segmentation focuses primarily on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used"
W15-1011,N13-1044,0,0.0132258,", we present the first direct comparison between phrase table desegmentation (Luong et al., 2010) and lattice desegmentation (Salameh et al., 2014). 2 Background Our work builds on earlier studies of automatic morphological segmentation and its impact on SMT. There are many ways to segment syntactically relevant affixes from stems. Supervised techniques may either pass through an intermediate morphological analysis (Habash et al., 2009), or directly segment the character stream (Green and DeNero, 2012); recent work on supervised Arabic segmentation focuses primarily on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a g"
W15-1011,D07-1091,0,0.0234547,"ethods to combine the scores across tables. In addition, they incorporate both segmented and unsegmented language models, which is a difference that we address in the next section. 68 3.4 Segmented LM Scoring in Desegmented Models Both alignment desegmentation and phrase table desegmentation rely on an unsegmented language model, as they naturally decode directly into a desegmented target language. We experiment with augmenting both of these systems with an extra feature: a segmented language model. For each Arabic target word, we add its segmented form to the phrase table as an extra factor (Koehn and Hoang, 2007). We insert this factor after phrase extraction, so it has no impact on alignment or the calculation of translation model scores. The factor merely gives us access to the segmented morphemes during decoding. The decoder uses this factor to apply a segmented language model during each hypothesis extension. Although the segmented language model spans a shorter context, its scores benefit from the reduced data sparsity that comes from modeling morphemes. In particular, it can unveil whether attaching two hypotheses is grammatical. For example, the unsegmented language model score for the consecut"
W15-1011,P07-2045,0,0.0842681,"Word Yes Table 1: Desegmentation scenarios and their effect on the components of a typical SMT system. 3 Methods When translating into a segmented target language, such as Arabic, the segmentation will need to eventually be reversed for the output to be readable. The key insight driving our experiments is that by varying the point in the SMT pipeline where this reversal occurs, we can alter which models are based on morphemes and which are based on words, and thereby determine which components most benefit from segmentation. We assume a phrase-based SMT architecture similar to that of Moses (Koehn et al., 2007), but most of our observations hold for hierarchical and tree-based models. In all of our approaches, we desegment using a mapping table that counts the segmentations performed on the target side of our training data. The table uses counts of wordsegmentation pairs to map each morpheme sequence back to its most likely unsegmented word form. We back off to manually crafted rules in cases where the segmented form does not exist in the mapping table (El Kholy and Habash, 2012). Table 1 summarizes the effect of the desegmentation point on the components of a typical SMT system, indicating which co"
W15-1011,W11-0301,0,0.0315674,"ntation (Salameh et al., 2014). 2 Background Our work builds on earlier studies of automatic morphological segmentation and its impact on SMT. There are many ways to segment syntactically relevant affixes from stems. Supervised techniques may either pass through an intermediate morphological analysis (Habash et al., 2009), or directly segment the character stream (Green and DeNero, 2012); recent work on supervised Arabic segmentation focuses primarily on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a growing interest in segmentation on the target side (Oflazer and Durgar El-Kahlout, 2007), which introduces a quest"
W15-1011,D10-1015,0,0.372773,"Missing"
W15-1011,P14-2034,0,0.0168156,"t direct comparison between phrase table desegmentation (Luong et al., 2010) and lattice desegmentation (Salameh et al., 2014). 2 Background Our work builds on earlier studies of automatic morphological segmentation and its impact on SMT. There are many ways to segment syntactically relevant affixes from stems. Supervised techniques may either pass through an intermediate morphological analysis (Habash et al., 2009), or directly segment the character stream (Green and DeNero, 2012); recent work on supervised Arabic segmentation focuses primarily on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a growing interest in seg"
W15-1011,J03-1002,0,0.0434558,"language before training begins, and the decoder’s output is generated in segmented form. As a post-processing step, the one-best output is desegmented using a mapping table and desegmentation rules. All of the component models used during decoding are based on morphemes instead of words. The segmented models are intended to help alleviate data sparsity and improve token correspondence. Unlike the unsegmented system, this system requires a desegmentation step, which can produce morphologically incorrect words. 3.2 Alignment Desegmentation Our unsupervised alignment models (Brown et al., 1993; Och and Ney, 2003) are sensitive both to poor word-to-word correspondence and to data sparsity issues. They are also at the very start of the SMT pipeline; they impact nearly all other downstream models. Therefore, it would be reasonable to suspect that the primary benefit of segmentation could come from improved word alignment. Alignment desegmentation allows us to test this theory by desegmenting immediately after alignment. More specifically, we segment the target side as pre-processing. After word alignment, we replace the segmented Arabic training data with its unsegmented form. Note that this desegmentati"
W15-1011,P03-1021,0,0.106912,"Arabic Treebank (PATB) segmentation scheme as recommended by El Kholy and Habash (2012). For both segmented and unsegmented Arabic, we further normalize the script by converting different forms of Alif and Ya to bare Alif and dotless Ya. In order to generate the desegmentation table, we analyze the MADA segmentations from the Arabic side of the parallel training data to collect mappings from morpheme sequences to surface forms. 4.2 penalties. The decoder uses Moses’ default search parameters, except that the maximum phrase length is set to 8. The decoder’s log-linear model is tuned with MERT (Och, 2003). Following Salameh et al. (2014), the tuning of the re-ranking models for lattice desegmentation is performed using a lattice variant of hope-fear MIRA (Cherry and Foster, 2012); lattices are pruned to a density of 50 edges per word before re-ranking. We evaluate our system using BLEU (Papineni et al., 2002). Decoder Integration Lattice Desegmentation performs best overall, which is not entirely surprising, as it has access to all of the information present in the other systems. Notably, it outperforms Phrase Table Desegmentation; this is the first time to our knowledge that the two have been"
W15-1011,W07-0704,0,0.406451,"Missing"
W15-1011,P02-1040,0,0.0922354,"e MADA segmentations from the Arabic side of the parallel training data to collect mappings from morpheme sequences to surface forms. 4.2 penalties. The decoder uses Moses’ default search parameters, except that the maximum phrase length is set to 8. The decoder’s log-linear model is tuned with MERT (Och, 2003). Following Salameh et al. (2014), the tuning of the re-ranking models for lattice desegmentation is performed using a lattice variant of hope-fear MIRA (Cherry and Foster, 2012); lattices are pruned to a density of 50 edges per word before re-ranking. We evaluate our system using BLEU (Papineni et al., 2002). Decoder Integration Lattice Desegmentation performs best overall, which is not entirely surprising, as it has access to all of the information present in the other systems. Notably, it outperforms Phrase Table Desegmentation; this is the first time to our knowledge that the two have been compared directly. The main disadvantage of Lattice Deseg, which is not present in Alignment and Phrase Table Deseg, is the lack of decoder integration of its unsegmented view of the target; instead, it is handled by re-ranking a lattice in post-processing. In fact, the top two systems, Lattice Deseg and 1-B"
W15-1011,P06-1001,0,0.0286995,"h et al., 2009), or directly segment the character stream (Green and DeNero, 2012); recent work on supervised Arabic segmentation focuses primarily on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a growing interest in segmentation on the target side (Oflazer and Durgar El-Kahlout, 2007), which introduces a question of how to perform proper desegmentation (Badr et al., 2008). El Kholy and Habash (2012) have conducted a thorough exploration of the various segmentation and desegmentation options for English to Arabic translation, and we follow their work when designing our test bed. Method Unsegmented Desegment before: Ali"
W15-1011,P14-1010,1,0.912641,"rase table, allowing morphemes to reduce sparsity while words expand context, and eliminating the need for a separate desegmentation step. Their word-boundary-aware morpheme-level phrase extraction technique restricts phrase boundaries so that no target phrase can begin with a suffix or end with a prefix. This allows them to desegment each target phrase independently, enabling the use of both word- and morpheme-level language models during decoding. However, this phrase-table desegmentation approach lacks the expressive power that comes from translating morphemes independently. More recently, Salameh et al. (2014) propose a lattice desegmentation approach, which comes close to combining all the advantages of word and morpheme views. By desegmenting a lattice that compactly represents many translation options, and rescoring it with a word-level language model, they avoid restricting the phrase table. However, by delaying desegmentation until rescoring, the approach loses Luong et al. (2010)’s advantage of full decoder integration. In this paper, we present an experimental study of English-to-Arabic translation that is designed to better understand the impact of various trade-offs when translating into a"
W15-1011,Q13-1021,0,0.0258496,"t al., 2014). 2 Background Our work builds on earlier studies of automatic morphological segmentation and its impact on SMT. There are many ways to segment syntactically relevant affixes from stems. Supervised techniques may either pass through an intermediate morphological analysis (Habash et al., 2009), or directly segment the character stream (Green and DeNero, 2012); recent work on supervised Arabic segmentation focuses primarily on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a growing interest in segmentation on the target side (Oflazer and Durgar El-Kahlout, 2007), which introduces a question of how to perform proper"
W15-1011,P12-2063,0,0.0157824,"ctly segment the character stream (Green and DeNero, 2012); recent work on supervised Arabic segmentation focuses primarily on adaptation to dialects (Habash et al., 2013; Monroe et al., 2014). There are also a host of unsupervised techniques (Creutz and Lagus, 2005; Lee et al., 2011; Sirts and Goldwater, 2013), which provide valuable language portability, but which generally fall behind supervised methods when labeled data is available. There is a large body of work studying the best form of segmentation when translating from a morphologically complex source language (Sadat and Habash, 2006; Stallard et al., 2012), where the segmentation can be used as a simple preprocessing step, or to create an input lattice (Dyer et al., 2008). Recently, there has been a growing interest in segmentation on the target side (Oflazer and Durgar El-Kahlout, 2007), which introduces a question of how to perform proper desegmentation (Badr et al., 2008). El Kholy and Habash (2012) have conducted a thorough exploration of the various segmentation and desegmentation options for English to Arabic translation, and we follow their work when designing our test bed. Method Unsegmented Desegment before: Alignment model Lexical wei"
W15-1011,D08-1076,0,\N,Missing
W15-1518,W13-3520,0,0.0233018,"xity. In this paper, we replicate their syntactic experiments on four languages that are more morphologically complex than English: Dutch, French, German, and Spanish. 2 Replication Experiments In order to to validate our methodology, we first replicate the results of Mikolov et al. (2013b) on English syntactic analogies. 2.1 Training Corpus for Word Vectors The vectors of Mikolov et al. (2013b) were trained on 320M tokens of broadcast news data, as described by Mikolov et al. (2011). Since we have no access to this data, we instead train English vectors on a corpus from the Polyglot project (Al-Rfou et al., 2013), which contains tokenized Wikipedia dumps intended for the training of vector-space models. For comparison with the results of Mikolov et al. (2013b), we limit the data to the first 320M lowercased tokens of the corpus. 129 Proceedings of NAACL-HLT 2015, pages 129–134, c Denver, Colorado, May 31 – June 5, 2015. 2015 Association for Computational Linguistics Mikolov et al. (2013b) obtain their best results with vectors of size 1600 that combine several models, but do not elaborate how this composite model was constructed. Instead, we take as a point of reference their second-best model, which"
W15-1518,N13-1138,0,0.0331844,"gy for the other languages. 3.2 Test Sets In order to make results between multiple languages comparable, we made several changes to the construction of syntactic analogy questions. We follow the methodology of Mikolov et al. (2013b) in limiting analogy questions to the 100 most frequent verbs or nouns. The frequencies are obtained from corpora tagged by T REE TAGGER (Schmid, 1994). We identify inflections using manually constructed inflection tables from several sources. Spanish and German verbal inflections, as well as German nominal inflections, are from a Wiktionary data set introduced by Durrett and DeNero (2013).4 Dutch verbal inflections and English verbal and nominal inflections are from the CELEX database (Baayen et al., 1995). French verbal inflections are from Verbiste, an online French conjugation dictionary.5 Whereas Mikolov et al. create analogies from various inflectional forms, we require the analogies to always include the base dictionary form: the infinitive for verbs, and the nominative singular for nouns. In other words, all analogies are limited to 4 We exclude Finnish because of its high morphological complexity and the small size of the corresponding Polyglot corpus. 5 http://perso.b"
W15-1518,N13-1090,0,0.683358,"treal Road Ottawa, ON, K1A 0R6, Canada Colin.Cherry@nrc-cnrc.gc.ca Abstract We replicate the syntactic experiments of Mikolov et al. (2013b) on English, and expand them to include morphologically complex languages. We learn vector representations for Dutch, French, German, and Spanish with the W ORD 2V EC tool, and investigate to what extent inflectional information is preserved across vectors. We observe that the accuracy of vectors on a set of syntactic analogies is inversely correlated with the morphological complexity of the language. 1 Figure 1: An example of vector offsets. Introduction Mikolov et al. (2013b) demonstrate that vector representations of words obtained from a neural network language model provide a way of capturing both semantic and syntactic regularities in language. They observe that by manipulating vector offsets between pairs of words, it is possible to derive an approximation of vectors representing other words, such as queen ≈ king − man + woman. Similarly, an abstract relationship between the present and past tense may be computed by subtracting the base form eat from the past form ate; the result of composing such an offset with the base form cook may turn out to be similar"
W15-1518,D14-1113,0,0.0871772,"Missing"
W15-3911,N12-1044,1,0.914253,"− minScore) (maxScore − minScore) where minScore is the confidence score of the n-th best prediction, and maxScore is the confidence score of the best prediction. Predictions that do not occur in a specific system’s n-best predictions are also given a score of 0 for combination. n is set to 10 in all of our experiments. If an n-best list contains less than 10 predictions, minScore is set to the score of the last prediction in the list. Our development experiments indicated that this method of combination was more accurate than a simpler method that uses only the prediction ranks. 4.2 R ERANK Bhargava and Kondrak (2012) propose a reranking approach to transliteration to leverage supplemental representations, such as phonetic transcriptions and transliterations from other languages. The reranker utilizes many features, including the similarity of the candidate outputs to the supplemental 73 representations, several types of n-gram features, and the confidence scores of the base system itself. Once a feature vector is created for each output, weights are learned with an SVM reranker. Bhargava et al. (2011) apply the reranking approach (R ERANK) to system combination. The idea is to rerank the n-best list outpu"
W15-3911,W11-3206,1,0.901865,"ansliterations from other languages, in order to test whether this can improve the overall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bisani and Ney, 2008), whic"
W15-3911,W10-2406,0,0.117958,"and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bisani and Ney, 2008), which is also applicable to a wide 1 2 72 https://code.google.com/p/directl-p http://www-i6.informatik.rwth-aachen.de/web/Software Proceedings of the Fifth Named Entity Workshop, joint with 53rd ACL and the 7th IJCNLP, pages 72–77, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics variety of monotone translation tasks including transliteration (Finch and Sumita, 2010; Nejad et al., 2011). Unlike D IREC TL+, which requires aligned source-target pairs, S EQUITUR directly trains a joint n-gram model for transduction from unaligned data. Higher order n-gram models are trained iteratively: a unigram model is created first; this model is then used to train a bigram model, which is then in turn used to train a trigram model, and so on. The order of the model trained is a parameter tuned on a development set. An important limitation of S EQUITUR is that both the source and target character sets are limited to a maximum of 255 symbols each. This precludes a direct"
W15-3911,N07-1047,1,0.854506,"ction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bisani and Ney, 2008), which is also applicable to a wide 1 2 72 https://code.google.com/p/directl-p http://www-i6.informatik.rwth-aachen.de/web/Software Proceedings of the Fifth Named Entity Workshop, joint with 53rd ACL and the 7th IJCNLP, pages 72–77, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics variety of monotone translation"
W15-3911,P08-1103,1,0.878928,"translation toolkits (SMT). In an effort to harness the strengths of each system, we explore various techniques of combining their outputs. Furthermore, we experiment with leveraging transliterations from other languages, in order to test whether this can improve the overall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for e"
W15-3911,W09-3504,1,0.899505,"outputs. Furthermore, we experiment with leveraging transliterations from other languages, in order to test whether this can improve the overall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-t"
W15-3911,N10-1103,1,0.917539,"xperiment with leveraging transliterations from other languages, in order to test whether this can improve the overall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bis"
W15-3911,W10-2405,1,0.873324,"xperiment with leveraging transliterations from other languages, in order to test whether this can improve the overall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bis"
W15-3911,P07-2045,0,0.0218725,"meter tuned on a development set. An important limitation of S EQUITUR is that both the source and target character sets are limited to a maximum of 255 symbols each. This precludes a direct application of S EQUITUR to scripts such as Chinese, Korean, and Japanese Kanji. Ultimately, it was a factor in our decision to leave out the datasets that involve these languages. 2.3 SMT We frame the transliteration task as a machine translation task by treating individual characters as words, and sequences of characters as phrases. We align the word pairs with GIZA++ (Och and Ney, 2003), and use Moses (Koehn et al., 2007), a phrase-based SMT system, to generate transliterations. The decoder’s log-linear model includes a standard feature set. Four translation model features encode phrase translation probabilities and lexical scores in both directions. Both alignment and generation are monotonic, i.e. reordering is disabled, with distortion limit set to zero. We train a KN-smoothed 5-gram language model on the target side of the parallel training data with SRILM (Stolcke, 2002). If a source word is provided with several target transliterations, we select the first one. The decoder’s log-linear model is tuned wit"
W15-3911,W12-4411,1,0.935495,"er languages, in order to test whether this can improve the overall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bisani and Ney, 2008), which is also applicable to"
W15-3911,W11-3214,0,0.0230646,"ned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bisani and Ney, 2008), which is also applicable to a wide 1 2 72 https://code.google.com/p/directl-p http://www-i6.informatik.rwth-aachen.de/web/Software Proceedings of the Fifth Named Entity Workshop, joint with 53rd ACL and the 7th IJCNLP, pages 72–77, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics variety of monotone translation tasks including transliteration (Finch and Sumita, 2010; Nejad et al., 2011). Unlike D IREC TL+, which requires aligned source-target pairs, S EQUITUR directly trains a joint n-gram model for transduction from unaligned data. Higher order n-gram models are trained iteratively: a unigram model is created first; this model is then used to train a bigram model, which is then in turn used to train a trigram model, and so on. The order of the model trained is a parameter tuned on a development set. An important limitation of S EQUITUR is that both the source and target character sets are limited to a maximum of 255 symbols each. This precludes a direct application of S EQU"
W15-3911,J03-1002,0,0.00745369,"rder of the model trained is a parameter tuned on a development set. An important limitation of S EQUITUR is that both the source and target character sets are limited to a maximum of 255 symbols each. This precludes a direct application of S EQUITUR to scripts such as Chinese, Korean, and Japanese Kanji. Ultimately, it was a factor in our decision to leave out the datasets that involve these languages. 2.3 SMT We frame the transliteration task as a machine translation task by treating individual characters as words, and sequences of characters as phrases. We align the word pairs with GIZA++ (Och and Ney, 2003), and use Moses (Koehn et al., 2007), a phrase-based SMT system, to generate transliterations. The decoder’s log-linear model includes a standard feature set. Four translation model features encode phrase translation probabilities and lexical scores in both directions. Both alignment and generation are monotonic, i.e. reordering is disabled, with distortion limit set to zero. We train a KN-smoothed 5-gram language model on the target side of the parallel training data with SRILM (Stolcke, 2002). If a source word is provided with several target transliterations, we select the first one. The dec"
W15-3911,P03-1021,0,0.0379389,"se-based SMT system, to generate transliterations. The decoder’s log-linear model includes a standard feature set. Four translation model features encode phrase translation probabilities and lexical scores in both directions. Both alignment and generation are monotonic, i.e. reordering is disabled, with distortion limit set to zero. We train a KN-smoothed 5-gram language model on the target side of the parallel training data with SRILM (Stolcke, 2002). If a source word is provided with several target transliterations, we select the first one. The decoder’s log-linear model is tuned with MERT (Och, 2003). We use BLEU score (Papineni et al., 2002) as an evaluation metric during tuning. 3 Language-specific Preprocessing Our development experiments showed that romanization of Chinese and Japanese characters can be helpful. For the alignment of English and Chinese (EnCh) names, we convert the Chinese names in the training data into Pinyin romanization, as described in Kondrak et al. (2012). This set of training pairs is aligned using our many-tomany aligner, and the resulting alignment links are projected onto Chinese characters. In cases where alignments split individual Chinese characters, they"
W15-3911,W12-4409,0,0.0173922,"prove the overall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bisani and Ney, 2008), which is also applicable to a wide 1 2 72 https://code.google.com/p"
W15-3911,P02-1040,0,0.0922654,"e transliterations. The decoder’s log-linear model includes a standard feature set. Four translation model features encode phrase translation probabilities and lexical scores in both directions. Both alignment and generation are monotonic, i.e. reordering is disabled, with distortion limit set to zero. We train a KN-smoothed 5-gram language model on the target side of the parallel training data with SRILM (Stolcke, 2002). If a source word is provided with several target transliterations, we select the first one. The decoder’s log-linear model is tuned with MERT (Och, 2003). We use BLEU score (Papineni et al., 2002) as an evaluation metric during tuning. 3 Language-specific Preprocessing Our development experiments showed that romanization of Chinese and Japanese characters can be helpful. For the alignment of English and Chinese (EnCh) names, we convert the Chinese names in the training data into Pinyin romanization, as described in Kondrak et al. (2012). This set of training pairs is aligned using our many-tomany aligner, and the resulting alignment links are projected onto Chinese characters. In cases where alignments split individual Chinese characters, they are expanded to include the entire charact"
W15-3911,W12-4408,0,0.0147674,"rall results. We obtain state-of-the-art results on most language pairs. 2 Base Systems In this section, we describe our three base systems: D IREC TL+, S EQUITUR, and SMT. 2.1 DirecTL+ D IREC TL+ is a publicly-available1 discriminative string transduction tool, which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). D IREC TL+ was successfully applied to transliteration in the previous NEWS shared tasks by our team (Jiampojamarn et al., 2009; Jiampojamarn et al., 2010b; Bhargava et al., 2011; Kondrak et al., 2012), as well as by other teams (Okuno, 2012; Wu et al., 2012). We make use of all features described by Jiampojamarn et al. (2010a). We perform source-target pair alignment with mpaligner (Kubo et al., 2011) because it performed slightly better in our development experiments than M 2 M-aligner (Jiampojamarn et al., 2007). The parameters of the transducer and the aligner were tuned separately for each language pair. 2.2 S EQUITUR S EQUITUR is a joint n-gram-based string transduction system2 originally designed for grapheme-to-phoneme transduction (Bisani and Ney, 2008), which is also applicable to a wide 1 2 72 https://code.google.com/p/directl-p http://"
W15-3911,N15-1095,1,0.918642,"L+ and S EQUITUR as the base and supplemental system, respectively. For this shared task, we investigated two modifications of R ERANK. First, we attempted to extend the original approach to take advantage of more than one supplemental system. For this purpose, we experimented with cascaded reranking, in which the n-best list is reranked using the top outputs of both supplemental systems in turn. Second, in an attempt to emulate the effectiveness of the linear combination approach, we experimented with restricting the set of features to confidence scores from the individual systems. 4.3 JOINT Yao and Kondrak (2015) propose a JOINT generation approach that can incorporate multiple transliterations as input, and show that it outperforms the reranking approach of Bhargava and Kondrak (2012). The JOINT system is a modified version of D IREC TL+ that utilizes aligned supplemental transliterations to learn additional features. Supplemental transliterations are then provided to the system at test time, in order to generate the final output. For this shared task, we performed two sets of experiments with the JOINT system. While the JOINT system was designed to incorporate additional transliterations as suppleme"
W16-2005,N07-1047,1,0.836744,"res conjoin the rule with indicators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indicators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoined with our source context features. Joint ngrams build indicators on rule sequences, combining source and target context, and memorizing frequently-used rule patterns. We train separate models for each part of speech in the training data. We perform source-target pair alignment with a modified version of the M2M aligner (Jiampojamarn et al., 2007). The program applies the Expectation-Maximization algorithm with the obIntroduction Many languages have complex morphology with dozens of different word-forms for any given lemma. It is often beneficial to reduce the data sparsity introduced by morphological variation in order to improve the applicability of methods that rely on textual regularity. The task of inflection generation (Task 1) is to produce an inflected form given a lemma and desired inflection, which is specified as an abstract tag. The task of labelled reinflection (Task 2) replaces the input lemma with a morphologically-tagge"
W16-2005,P08-1103,1,0.911432,"roduce an inflected form given a lemma and desired inflection, which is specified as an abstract tag. The task of labelled reinflection (Task 2) replaces the input lemma with a morphologically-tagged inflected form. Finally, the task of unlabelled reinflection (Task 3) differs from Task 2 in that the input lacks the inflection tag. In this paper, we describe our system as participants in the SIGMORPHON 2016 Shared Task on Morphological Reinflection (Cotterell et al., 2016). Our approach is based on discriminative string transduction performed with a modified version of the D IREC TL+ program (Jiampojamarn et al., 2008). We perform Task 1 using the inflection generation approach of Nicolai et al. (2015), which we refer to as the lemma-to-word model. We also derive a reverse word-to-lemma (lemmatization) model from the Task 1 data. We perform Task 3 by composing the word-to-lemma and lemma-to-word models. We reduce Task 2 to Task 3 by simply ignoring the input inflection tag. 1 https://code.google.com/p/directl-p 31 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 31–35, c Berlin, Germany, August 11, 2016. 2016 Association for Computat"
W16-2005,P05-1012,0,0.118038,"rm well on typologically diverse languages. We also discuss language-specific heuristics and errors. 1 Methods 2.1 String Transduction We perform string transduction by adapting D I REC TL+, a tool originally designed for graphemeto-phoneme conversion.1 D IREC TL+ is a featurerich, discriminative character string transducer that searches for a model-optimal sequence of character transformation rules for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation. Using a structured version of the MIRA algorithm (McDonald et al., 2005), training attempts to assign weights to each feature so that its linear model separates the gold-standard derivation from all others in its search space. From aligned source-target pairs, D IREC TL+ extracts statistically-supported feature templates: source context, target n-gram, and joint n-gram features. Context features conjoin the rule with indicators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indicators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoine"
W16-2005,P16-1108,1,0.842851,"o Task 3 by simply ignoring the input inflection tag. 1 https://code.google.com/p/directl-p 31 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 31–35, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics side. In order to avoid the problem of unbounded insertions, we place a dummy null character at the boundaries of the word, effectively turning insertion into substitution. Lemmatization is not the only method of inflection simplification; we experimented with three alternative approaches (Nicolai and Kondrak, 2016): jective to maximize the joint likelihood of its aligned source and target pairs. In order to encourage alignments between identical characters, we modify the aligner to generalize all identity transformations into a single match operation. 2.2 Task 1: Inflection For Task 1, we derive a lemma-to-word model, which transforms the lemma along with an inflection tag into the inflected form. Our method models affixation with atomic morphological tags. For example, the training instance corresponding to the past participle dado of the Spanish verb dar “to give” consists of the source dar+PP and the"
W16-2005,N15-1093,1,0.752338,"stract tag. The task of labelled reinflection (Task 2) replaces the input lemma with a morphologically-tagged inflected form. Finally, the task of unlabelled reinflection (Task 3) differs from Task 2 in that the input lacks the inflection tag. In this paper, we describe our system as participants in the SIGMORPHON 2016 Shared Task on Morphological Reinflection (Cotterell et al., 2016). Our approach is based on discriminative string transduction performed with a modified version of the D IREC TL+ program (Jiampojamarn et al., 2008). We perform Task 1 using the inflection generation approach of Nicolai et al. (2015), which we refer to as the lemma-to-word model. We also derive a reverse word-to-lemma (lemmatization) model from the Task 1 data. We perform Task 3 by composing the word-to-lemma and lemma-to-word models. We reduce Task 2 to Task 3 by simply ignoring the input inflection tag. 1 https://code.google.com/p/directl-p 31 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 31–35, c Berlin, Germany, August 11, 2016. 2016 Association for Computational Linguistics side. In order to avoid the problem of unbounded insertions, we pla"
W16-2016,N13-1072,1,0.842677,"iderations we focus here on orthographic syllabification, which is also referred to as hyphenation. Some dictionaries include hyphenation information to indicate where words may be broken for end-of-line divisions, and to assist the reader in recovering the correct pronunciation. In many languages the orthographic and phonological representations of a word are closely related. Orthographic syllabification has a number of computational applications. Incorporation of the syllable boundaries between letters benefits grapheme-to-phoneme conversion (Damper et al., 2005), and respelling generation (Hauer and Kondrak, 2013). Hyphenation of out-of-dictionary words is also important in text processing (Trogkanis and Elkan, 2010). Because of the productive nature of language, a dictionary look-up process for syllabification is inadequate. Rule-based systems are generally outperformed on out-ofdictionary words by data-driven methods, such as those of Daelemans et al. (1997), Demberg (2006), Marchand and Damper (2007), and Trogkanis and Elkan (2010). 1 We denote syllable boundaries with ‘-’, and morpheme boundaries with ‘+’. 99 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics,"
W16-2016,N10-1103,1,0.819523,", while the N tags indicate the distance from the previous boundary. For example, the word syl-lab-i-fy is annotated as: N1 N2 B N1 N2 B B N1 N2. The feature vectors consist of all n-grams around the current focus character, up to size 5. These n-grams are composed of context letters, and word-boundary markers that are added at the beginning and end of each word. While supervised methods typically require large amounts of annotated training data, they can perform segmentation of unseen (out-of-dictionary) words. As our fully-supervised segmenter, we use the discriminative string transducer of Jiampojamarn et al. (2010). The transducer is trained on aligned source-target pairs, one pair per word; the target is identical to the source except that it includes characters that represent morphological breaks. Using source and target context, the transducer learns to insert these breaks into words. 2.2 2.2.3 2.2.2 Distantly-supervised Whereas morphologically-annotated lexicons are rare, websites such as Wiktionary contain crowdgenerated inflection tables for many languages. A distantly-supervised segmenter can be trained on semi-structured inflection tables to divide words into stems and affixes without explicit s"
W16-2016,P16-1108,1,0.837915,"get pairs, one pair per word; the target is identical to the source except that it includes characters that represent morphological breaks. Using source and target context, the transducer learns to insert these breaks into words. 2.2 2.2.3 2.2.2 Distantly-supervised Whereas morphologically-annotated lexicons are rare, websites such as Wiktionary contain crowdgenerated inflection tables for many languages. A distantly-supervised segmenter can be trained on semi-structured inflection tables to divide words into stems and affixes without explicit segmentation annotation. We adopt the approach of Nicolai and Kondrak (2016), which combines unsupervised alignment with a discriminative string transduction algorithm, An important limitation of this approach is that it can only identify inflectional morpheme boundaries. Morphological information Unsupervised Unsupervised methods have the advantage of requiring no training data. We investigate the applicability of two unsupervised segmenters: Morfessor (Creutz and Lagus, 2005) and Morpheme++ (Dasgupta and Ng, 2007). Morfessor uses the minimum description length (MDL) principle to predict a word as a likely sequence of morphemes. Since the baseline version of Morfesso"
W16-2016,W13-3504,0,0.0314428,"l Segmentation Can Improve Syllabification Garrett Nicolai Lei Yao Grzegorz Kondrak Department of Computing Science University of Alberta {nicolai,lyao1,gkondrak}@ualberta.ca Abstract Morphological segmentation is the task of dividing words into morphemes, the smallest meaning-bearing units in the word (Goldsmith, 2001). For example the morpheme over occurs in words like hold+over, lay+over, and skip+over.1 Roots combine with derivational (e.g. refut+able) and inflectional affixes (e.g. hold+ing). Computational segmentation approaches can be divided into rule-based (Porter, 1980), supervised (Ruokolainen et al., 2013), semi-supervised (Gr¨onroos et al., 2014), and unsupervised (Creutz and Lagus, 2002). Bartlett et al. (2008) observe that some of the errors made by their otherwise highly-accurate system, such as hol-dov-er and coad-ju-tors, can be attributed to the lack of awareness of morphological boundaries, which influence syllabification. In this paper, we demonstrate that the accuracy of orthographic syllabification can be improved by considering morphology. We augment the syllabification approach of Bartlett et al. (2008), with features encoding morphological segmentation of words. We investigate the"
W16-2016,P08-1065,1,0.908689,"nce University of Alberta {nicolai,lyao1,gkondrak}@ualberta.ca Abstract Morphological segmentation is the task of dividing words into morphemes, the smallest meaning-bearing units in the word (Goldsmith, 2001). For example the morpheme over occurs in words like hold+over, lay+over, and skip+over.1 Roots combine with derivational (e.g. refut+able) and inflectional affixes (e.g. hold+ing). Computational segmentation approaches can be divided into rule-based (Porter, 1980), supervised (Ruokolainen et al., 2013), semi-supervised (Gr¨onroos et al., 2014), and unsupervised (Creutz and Lagus, 2002). Bartlett et al. (2008) observe that some of the errors made by their otherwise highly-accurate system, such as hol-dov-er and coad-ju-tors, can be attributed to the lack of awareness of morphological boundaries, which influence syllabification. In this paper, we demonstrate that the accuracy of orthographic syllabification can be improved by considering morphology. We augment the syllabification approach of Bartlett et al. (2008), with features encoding morphological segmentation of words. We investigate the degree of overlap between the morphological and syllable boundaries. The results of our experiments on Engli"
W16-2016,P10-1038,0,0.0214047,"e dictionaries include hyphenation information to indicate where words may be broken for end-of-line divisions, and to assist the reader in recovering the correct pronunciation. In many languages the orthographic and phonological representations of a word are closely related. Orthographic syllabification has a number of computational applications. Incorporation of the syllable boundaries between letters benefits grapheme-to-phoneme conversion (Damper et al., 2005), and respelling generation (Hauer and Kondrak, 2013). Hyphenation of out-of-dictionary words is also important in text processing (Trogkanis and Elkan, 2010). Because of the productive nature of language, a dictionary look-up process for syllabification is inadequate. Rule-based systems are generally outperformed on out-ofdictionary words by data-driven methods, such as those of Daelemans et al. (1997), Demberg (2006), Marchand and Damper (2007), and Trogkanis and Elkan (2010). 1 We denote syllable boundaries with ‘-’, and morpheme boundaries with ‘+’. 99 Proceedings of the 14th Annual SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 99–103, c Berlin, Germany, August 11, 2016. 2016 Association for Comput"
W16-2016,W02-0603,0,0.100796,"artment of Computing Science University of Alberta {nicolai,lyao1,gkondrak}@ualberta.ca Abstract Morphological segmentation is the task of dividing words into morphemes, the smallest meaning-bearing units in the word (Goldsmith, 2001). For example the morpheme over occurs in words like hold+over, lay+over, and skip+over.1 Roots combine with derivational (e.g. refut+able) and inflectional affixes (e.g. hold+ing). Computational segmentation approaches can be divided into rule-based (Porter, 1980), supervised (Ruokolainen et al., 2013), semi-supervised (Gr¨onroos et al., 2014), and unsupervised (Creutz and Lagus, 2002). Bartlett et al. (2008) observe that some of the errors made by their otherwise highly-accurate system, such as hol-dov-er and coad-ju-tors, can be attributed to the lack of awareness of morphological boundaries, which influence syllabification. In this paper, we demonstrate that the accuracy of orthographic syllabification can be improved by considering morphology. We augment the syllabification approach of Bartlett et al. (2008), with features encoding morphological segmentation of words. We investigate the degree of overlap between the morphological and syllable boundaries. The results of"
W16-2016,N07-1020,0,0.0302045,"trained on semi-structured inflection tables to divide words into stems and affixes without explicit segmentation annotation. We adopt the approach of Nicolai and Kondrak (2016), which combines unsupervised alignment with a discriminative string transduction algorithm, An important limitation of this approach is that it can only identify inflectional morpheme boundaries. Morphological information Unsupervised Unsupervised methods have the advantage of requiring no training data. We investigate the applicability of two unsupervised segmenters: Morfessor (Creutz and Lagus, 2005) and Morpheme++ (Dasgupta and Ng, 2007). Morfessor uses the minimum description length (MDL) principle to predict a word as a likely sequence of morphemes. Since the baseline version of Morfessor tends to over-segment rare words, we instead apply Morfessor FlatCat (Gr¨onroos et al., 2014), which reduces over-segmentation through the use of a hidden Markov model. Morpheme++ is another system that is capable of distinguishing between prefixes, suffixes, and stems by taking advantage of the regularity of affixes. We incorporate available morphological information by adding morpheme boundary markers into the input words. The extracted"
W16-2016,J01-2001,0,0.274286,"Missing"
W18-2412,P17-4012,0,0.0422731,"string transduction tool1 , which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). Previous University of Alberta teams have successfully applied D I REC TL+ to transliteration in the previous editions 1 S EQUITUR 2 3 https://code.google.com/archive/p/directl-p http://www-i6.informatik.rwth-aachen.de/web/Software https://metacpan.org/Lingua::KO::Romanize::Hangul 84 Proceedings of the Seventh Named Entities Workshop, pages 84–88 c Melbourne, Australia, July 20, 2018. 2018 Association for Computational Linguistics 2.3 OpenNMT 2.6 We adopt the OpenNMT tool (Klein et al., 2017), specifically the PyTorch variant4 , as a baseline neural machine translation system. We apply the system “as-is” to all language pairs, with all parameters left at their default settings. Word boundaries are inserted between all characters in the input and output, resulting in translation models which view characters as words and words as sentences. 2.4 We also consider the linear combination of multiple systems. One motivation for the combination is the observation that the non-neural models often perform better on datasets with fewer training instances. We make each individual system gener"
W18-2412,W12-4411,1,0.777527,"Missing"
W18-2412,D15-1166,0,0.0590215,". Scores of each model are normalized as described in (Nicolai et al., 2015, Section 4.1). The linear coefficients are tuned separately for each language pair on the provided development sets, using grid search with a step of 0.1. Base NMT As our main neural system, we implement a character-level neural transducer (NMT) following the encoder-decoder architecture of Sutskever et al. (2014), which is widely applied to machine translation. The encoder is a bi-directional recurrent neural network (RNN) applied to randomly initialized character embeddings. We employ the soft attention mechanism of Luong et al. (2015) to learn an aligner within the model. The NMT is trained for a fixed random seed using the Adam optimizer with a learning rate of 0.0005, embeddings of 128 dimensions, and hidden units of size 256. We employ beam search using a beam size of 10 to generate the final predictions at test time. 2.5 2.7 Non-Standard DTLM DTLM is a new system that combines discriminative transduction with character and word language models derived from large unannotated corpora (Nicolai et al., 2018). DTLM is an extension of D IREC TL+, whose target language modeling is limited to a set of binary n-gram features. T"
W18-2412,W11-3206,1,0.873761,"Missing"
W18-2412,W15-3911,1,0.840893,"settings. Word boundaries are inserted between all characters in the input and output, resulting in translation models which view characters as words and words as sentences. 2.4 We also consider the linear combination of multiple systems. One motivation for the combination is the observation that the non-neural models often perform better on datasets with fewer training instances. We make each individual system generate the 10 best transliterations for each test input, and combine the lists via a linear combination of the confidence scores. Scores of each model are normalized as described in (Nicolai et al., 2015, Section 4.1). The linear coefficients are tuned separately for each language pair on the provided development sets, using grid search with a step of 0.1. Base NMT As our main neural system, we implement a character-level neural transducer (NMT) following the encoder-decoder architecture of Sutskever et al. (2014), which is widely applied to machine translation. The encoder is a bi-directional recurrent neural network (RNN) applied to randomly initialized character embeddings. We employ the soft attention mechanism of Luong et al. (2015) to learn an aligner within the model. The NMT is traine"
W18-2412,W18-5805,1,0.408623,"t neural network (RNN) applied to randomly initialized character embeddings. We employ the soft attention mechanism of Luong et al. (2015) to learn an aligner within the model. The NMT is trained for a fixed random seed using the Adam optimizer with a learning rate of 0.0005, embeddings of 128 dimensions, and hidden units of size 256. We employ beam search using a beam size of 10 to generate the final predictions at test time. 2.5 2.7 Non-Standard DTLM DTLM is a new system that combines discriminative transduction with character and word language models derived from large unannotated corpora (Nicolai et al., 2018). DTLM is an extension of D IREC TL+, whose target language modeling is limited to a set of binary n-gram features. Target language modelling is particularly important in low-data scenarios, where the limited transduction models often produce many ill-formed output candidates. We avoid the error propagation problem that is inherent in pipeline approaches by incorporating the LM feature sets directly into the transducer, which are based exclusively on the forms in the parallel training data. The weights of the new features are learned jointly with the other features of D IREC TL+. In addition,"
W18-2412,W09-3504,1,0.847651,"Missing"
W18-2412,P08-1103,1,0.905378,"nd 2-gram for T-EnPe. One limitation of S EQUITUR is that both the source and target character sets are limited to a maximum of 255 symbols. This precluded the application of S EQUITUR to Chinese and Japanese Kanji. For the English-Korean (EnKo) language pair, our work-around was to convert Korean Hangul into Latin characters using a romanization module.3 Systems In this section, we briefly describe the principal systems that we tested. 2.1 D IREC TL+ D IREC TL+ is a publicly available discriminative string transduction tool1 , which was initially developed for grapheme-to-phoneme conversion (Jiampojamarn et al., 2008). Previous University of Alberta teams have successfully applied D I REC TL+ to transliteration in the previous editions 1 S EQUITUR 2 3 https://code.google.com/archive/p/directl-p http://www-i6.informatik.rwth-aachen.de/web/Software https://metacpan.org/Lingua::KO::Romanize::Hangul 84 Proceedings of the Seventh Named Entities Workshop, pages 84–88 c Melbourne, Australia, July 20, 2018. 2018 Association for Computational Linguistics 2.3 OpenNMT 2.6 We adopt the OpenNMT tool (Klein et al., 2017), specifically the PyTorch variant4 , as a baseline neural machine translation system. We apply the s"
W18-2412,W10-2405,1,0.855905,"Missing"
W18-2412,N07-1047,1,0.830477,"Missing"
W18-5805,P17-1183,0,0.0152042,"ms by a large margin thanks to its ability to leverage a target word list. Additional results are reported by Najafi et al. (2018b). 4.3 Average 40.7 49.0 40.9 Inflection generation Inflection generation is the task of producing an inflected word-form, given a citation form and a set of morphological features. For example, given the Spanish infinitive liberar, with the tag V;IND;FUT;2;SG, the word-form liberarás should be produced. In recent years, inflection generation has attracted much interest (Dreyer and Eisner, 2011; Durrett and DeNero, 2013; Nicolai et al., 2015; Ahlberg et al., 2015). Aharoni and Goldberg (2017) propose an RNN augmented with hard attention and explicit alignments for inflection, but have difficulty consistently improving upon the results of DTL, even on larger datasets. Furthermore, their system cannot be applied to tasks where the source and target are different languages, due to shared embeddings between the encoder and decoder. Ruzsics and Samardzic (2017) incorporate a language model into the decoder of 48 System EN-DE RU-PL DTL 4.3 23.5 DTL+RR 7.1 32.8 DTLM 17.7 43.9 RNN 2.2 1.7 SEQ 9.2 22.3 with the sparse corpora that such inventories supply, we see notable gains over DTL. We"
W18-5805,N15-1107,0,0.0184167,"erforms the other systems by a large margin thanks to its ability to leverage a target word list. Additional results are reported by Najafi et al. (2018b). 4.3 Average 40.7 49.0 40.9 Inflection generation Inflection generation is the task of producing an inflected word-form, given a citation form and a set of morphological features. For example, given the Spanish infinitive liberar, with the tag V;IND;FUT;2;SG, the word-form liberarás should be produced. In recent years, inflection generation has attracted much interest (Dreyer and Eisner, 2011; Durrett and DeNero, 2013; Nicolai et al., 2015; Ahlberg et al., 2015). Aharoni and Goldberg (2017) propose an RNN augmented with hard attention and explicit alignments for inflection, but have difficulty consistently improving upon the results of DTL, even on larger datasets. Furthermore, their system cannot be applied to tasks where the source and target are different languages, due to shared embeddings between the encoder and decoder. Ruzsics and Samardzic (2017) incorporate a language model into the decoder of 48 System EN-DE RU-PL DTL 4.3 23.5 DTL+RR 7.1 32.8 DTLM 17.7 43.9 RNN 2.2 1.7 SEQ 9.2 22.3 with the sparse corpora that such inventories supply, we se"
W18-5805,D11-1057,0,0.034818,"he same as for the low-resource experiments. Table 2 shows that DTLM outperforms the other systems by a large margin thanks to its ability to leverage a target word list. Additional results are reported by Najafi et al. (2018b). 4.3 Average 40.7 49.0 40.9 Inflection generation Inflection generation is the task of producing an inflected word-form, given a citation form and a set of morphological features. For example, given the Spanish infinitive liberar, with the tag V;IND;FUT;2;SG, the word-form liberarás should be produced. In recent years, inflection generation has attracted much interest (Dreyer and Eisner, 2011; Durrett and DeNero, 2013; Nicolai et al., 2015; Ahlberg et al., 2015). Aharoni and Goldberg (2017) propose an RNN augmented with hard attention and explicit alignments for inflection, but have difficulty consistently improving upon the results of DTL, even on larger datasets. Furthermore, their system cannot be applied to tasks where the source and target are different languages, due to shared embeddings between the encoder and decoder. Ruzsics and Samardzic (2017) incorporate a language model into the decoder of 48 System EN-DE RU-PL DTL 4.3 23.5 DTL+RR 7.1 32.8 DTLM 17.7 43.9 RNN 2.2 1.7 S"
W18-5805,P86-1009,0,0.700389,"rmations. The unsupervised M2M aligner (Jiampojamarn et al., 2007) employs the Expectation-Maximization (EM) algorithm with the objective of maximizing the joint likelihood of its aligned source and target pairs. The alignment involves every source and target character. The pairs of aligned substrings may contain multiple characters on both the source and target sides, yielding many-to-many (M-M) alignment links. DTL excludes insertions from its set of edit operations because they greatly increase the complexity of the generation process, to the point of making it computationally intractable (Barton, 1986). Therefore, the M2M aligner is forced to avoid nulls on the source side by incorporating them into many-to-many links during the alignment of the training data. Although many-tomany alignment models are more flexible than 1-1 models, they also generally require larger parallel datasets to produce correct alignments. In lowdata scenarios, especially when the target strings tend to be longer than the source strings, this approach often yields sub-optimal alignments (e.g., the leftmost alignment in Figure 2). 2.3 Reranking The target language modeling of DTL is limited to a set of binary ?-gram"
W18-5805,N13-1138,0,0.0258593,"source experiments. Table 2 shows that DTLM outperforms the other systems by a large margin thanks to its ability to leverage a target word list. Additional results are reported by Najafi et al. (2018b). 4.3 Average 40.7 49.0 40.9 Inflection generation Inflection generation is the task of producing an inflected word-form, given a citation form and a set of morphological features. For example, given the Spanish infinitive liberar, with the tag V;IND;FUT;2;SG, the word-form liberarás should be produced. In recent years, inflection generation has attracted much interest (Dreyer and Eisner, 2011; Durrett and DeNero, 2013; Nicolai et al., 2015; Ahlberg et al., 2015). Aharoni and Goldberg (2017) propose an RNN augmented with hard attention and explicit alignments for inflection, but have difficulty consistently improving upon the results of DTL, even on larger datasets. Furthermore, their system cannot be applied to tasks where the source and target are different languages, due to shared embeddings between the encoder and decoder. Ruzsics and Samardzic (2017) incorporate a language model into the decoder of 48 System EN-DE RU-PL DTL 4.3 23.5 DTL+RR 7.1 32.8 DTLM 17.7 43.9 RNN 2.2 1.7 SEQ 9.2 22.3 with the spars"
W18-5805,I13-1112,0,0.168055,"Missing"
W18-5805,N10-1103,1,0.860489,"s based on discriminative string transduction, where a learning algorithm assigns weights to features defined on aligned source and target pairs. At test time, an input sequence is converted into the highest-scoring output sequence. Advantages of discriminative transduction include an aptitude to derive effective models from small training sets, as wells as the capability to incorporate diverse sets of features. Specifically, we build Figure 1: Illustration of four character-level sequenceto-sequence prediction tasks. In each case, the output is a word in the target language. upon D IREC TL+ (Jiampojamarn et al., 2010), a string transduction tool which was originally designed for grapheme-to-phoneme conversion. We present a new system, DTLM, that combines discriminative transduction with character and word language models (LMs) derived from large unannotated corpora. Target language modeling is particularly important in low-data scenarios, where the limited transduction models often produce many ill-formed output candidates. We avoid the error propagation problem which is inherent in pipeline approaches by incorporating the LM feature sets directly into the transducer. In addition, we bolster the quality of"
W18-5805,D09-1111,0,0.034292,"original features of DTL, so that the high unigram count of piece is not sufficient to make it the top prediction on the right Corpus frequency counts We also extend DTL with a feature set that can be described as a unigram word-level language model. The objective is to bias the model towards generating output sequences that correspond to words observed in a large corpus. Since an output sequence can only be matched against a word list after the generation process is complete, we propose to estimate the final frequency count for each prefix considered during the generation process. Following Cherry and Suzuki (2009) we use a prefix trie to store partial words for reference in the generation phase. We modify their solution by also storing the count of each prefix, calculated as the sum of all of the words in which the prefix occurs. As with our language model features, unigram features are binned. A unigram feature fires if the 46 source and target ?-grams (Bisani and Ney, 2008), and a character-level neural model (RNN). The neural model uses the encoder-decoder architecture typically used for NMT (Sutskever et al., 2014). The encoder is a bi-directional RNN applied to randomly initialized character embed"
W18-5805,N07-1047,1,0.853065,"py feature generalizes the identity function from source to target, which is useful if there is an overlap between the input and output symbol sets. Baseline methods In this section, we describe the baseline methods, including the alignment of the training data, the feature sets of DirecTL+ (henceforth DTL), and reranking as a way of incorporating corpus statistics. 2.1 wɔkəz Alignment Before a transduction model can be derived from the training data, the pairs of source and target strings need to be aligned, in order to identify atomic substring transformations. The unsupervised M2M aligner (Jiampojamarn et al., 2007) employs the Expectation-Maximization (EM) algorithm with the objective of maximizing the joint likelihood of its aligned source and target pairs. The alignment involves every source and target character. The pairs of aligned substrings may contain multiple characters on both the source and target sides, yielding many-to-many (M-M) alignment links. DTL excludes insertions from its set of edit operations because they greatly increase the complexity of the generation process, to the point of making it computationally intractable (Barton, 1986). Therefore, the M2M aligner is forced to avoid nulls"
W18-5805,K18-3001,1,0.867407,"Missing"
W18-5805,K17-2001,0,0.13538,"Missing"
W18-5805,P05-1012,0,0.0464658,"thods. (5) Three new datasets for cognate projection. 2 wɔ_k_əz wɔk əz walkers walkers walkers Figure 2: Examples of different alignments in phoneme-to-letter conversion. The underscore denotes a null substring. 2.2 Features DTL is a feature-rich, discriminative character transducer, which searches for a model-optimal sequence of character transformation operations for its input. The core of the engine is a dynamic programming algorithm capable of transducing many consecutive characters in a single operation, also known as a semi-Markov model. Using a structured version of the MIRA algorithm (McDonald et al., 2005), the training process assigns weights to each feature, in order to achieve maximum separation of the gold-standard output from all others in the search space. DTL uses a number of feature templates to assess the quality of an operation: source context, target ?-gram, and joint ?-gram features. Context features conjoin the rule with indicators for all source character ?-grams within a fixed window of where the rule is being applied. Target n-grams provide indicators on target character sequences, describing the shape of the target as it is being produced, and may also be conjoined with the sou"
W18-5805,K18-3015,1,0.882215,"Missing"
W18-5805,W18-2412,1,0.442669,"Missing"
W18-5805,N15-1093,1,0.953652,"they also generally require larger parallel datasets to produce correct alignments. In lowdata scenarios, especially when the target strings tend to be longer than the source strings, this approach often yields sub-optimal alignments (e.g., the leftmost alignment in Figure 2). 2.3 Reranking The target language modeling of DTL is limited to a set of binary ?-gram features, which are based exclusively on the target sequences from the parallel training data. This shortcoming can be remedied by taking advantage of large unannotated corpora that contain thousands of examples of valid target words. Nicolai et al. (2015) propose to leverage corpus statistics by reranking the ?-best list of candidates generated by the transducer. They report consistent modest gains by applying an SVM-based 44 1: 2: 3: 4: 5: 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: reranker, with features including a word unigram corpus presence indicator, a normalized character language model score, and the rank and normalized confidence score generated by DTL. However, such a pipeline approach suffers from error propagation, and is unable to produce output forms that are not already present in the ?-best list. In addition, training"
W18-5805,J96-3003,0,0.640465,"Missing"
W18-5805,K17-1020,0,0.021006,"e tag V;IND;FUT;2;SG, the word-form liberarás should be produced. In recent years, inflection generation has attracted much interest (Dreyer and Eisner, 2011; Durrett and DeNero, 2013; Nicolai et al., 2015; Ahlberg et al., 2015). Aharoni and Goldberg (2017) propose an RNN augmented with hard attention and explicit alignments for inflection, but have difficulty consistently improving upon the results of DTL, even on larger datasets. Furthermore, their system cannot be applied to tasks where the source and target are different languages, due to shared embeddings between the encoder and decoder. Ruzsics and Samardzic (2017) incorporate a language model into the decoder of 48 System EN-DE RU-PL DTL 4.3 23.5 DTL+RR 7.1 32.8 DTLM 17.7 43.9 RNN 2.2 1.7 SEQ 9.2 22.3 with the sparse corpora that such inventories supply, we see notable gains over DTL. We also see large gains for languages such as Northern Sami and Navajo that have relatively small Wikipedias (fewer than 10,000 articles). DTLM was also evaluated as a non-standard submission in the low-data track of the 2018 Shared Task on Universal Morphological Inflection (Cotterell et al., 2018). The results reported by Najafi et al. (2018a) confirm that DTLM substant"
W18-5805,P07-3005,0,\N,Missing
W18-5805,P18-1180,0,\N,Missing
W18-5805,K17-2004,0,\N,Missing
W19-1403,W14-3914,0,0.0320232,"netic spelling, ad-hoc transliterations, and abbreviations. A great deal of information is lost in the romanization process due to the difficulty of representing native phonological distinctions in the Roman script. This makes deromanization of such messages a challenging task (Irvine et al., 2012). Another phenomenon that further complicates the task of deromanization is code-mixing, which occurs when words from another language (typically English) are introduced in the messages (e.g., the word decent in Figure 1). Code-mixing is particularly common in multi-lingual areas such as South Asia (Bali et al., 2014). In many cases, the 26 Proceedings of VarDial, pages 26–34 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics 2.1 lem of word-level language identification (Chittaranjan et al., 2014; Choudhury et al., 2014). Transliteration and back-transliteration is a wellunderstood problem, which also has been the topic of several shared tasks (Duan et al., 2016; Chen et al., 2018). However, unlike romanization, transliteration is focused on names rather than dictionary words, and usually performed without considering the context of the word in a sentence. Finally, a number of"
W19-1403,W14-3908,0,0.0609476,"Missing"
W19-1403,W14-1604,0,0.0744018,"Missing"
W19-1403,W14-5152,0,0.0622543,"Missing"
W19-1403,2014.amta-researchers.25,0,0.0771866,"Missing"
W19-1403,W18-5805,1,0.848898,"is a datadriven transduction tool which derives a joint ngram model from unaligned source-target data.3 The model reflects the edit operations used in the conversion from source to target, and allows for the inclusion of source context in the generative model. Higher n-gram order models are trained iteratively from the lower order models. Sequitur was adopted as a baseline in the most recent NEWS shared task on transliteration (Chen et al., 2018). DTLM is a new system that combines discriminative transduction with character and word language models (LM) derived from large unannotated corpora (Nicolai et al., 2018).4 DTLM is an extension of DirecTL+ (Jiampojamarn et al., 2010). For target language modeling, which is particularly important in low-data scenarios, DirecTL+ uses binary n-gram features based exclusively on the forms in the parallel training data. This limitation often results in many ill-formed output candidates. DTLM avoids the error prop3 4 3.3 Sequence Prediction The transliteration systems process individual words in isolation, and thus fail to take into account the context of a word in a sentence. However, multiple native words may have the same romanized form, so the top-scoring predic"
W19-1403,W17-4002,0,0.0693755,"Missing"
W19-1403,D14-1162,0,0.0822181,"ximum 3 Latin letters. (We 5 Experiments In this section, we present the results for each of the three tasks. 5.1 Setup We tune all parameters, including the exponents pt and ps , of our sequence prediction module, on the Bengali development set, and apply them unchanged to both test sets. For the transliteration, we set the n-gram order of Sequitur to 6. We apply a grid-search to establish the parameters for the DTLM transducer and aligner. We set parameters of the OpenNMT system to the default settings. For the sequence prediction, we use pre-trained Glove word-embeddings of 100 dimensions (Pennington et al., 2014), and derive the characterembedding of 32 dimensions from the training data. The training is accomplished with Adam optimizer (Kingma and Ba, 2014), dropout regularization, and batch size of 64. 5.2 Language Identification We evaluate our encoder-decoder model against a strong general sequence tagging system (Huang et al., 2015). For this purpose, we adapt an implementation12 of a CRF-based sequence tagging model on top of RNNs to the language identification task (Bi-LSTM + CRF). In addition, we compare to a word-level language identification system13 based on word frequencies and character ng"
W19-1403,D15-1097,0,0.0411332,"Missing"
W19-1403,W12-2109,0,0.0306305,". The phenomenon is observed in informal settings, such as social media, and is due to either unavailability of a native-script keyboard, or the writer’s preference for using a Roman keyboard. Rather than following any predefined inter-script mappings, romanized texts typically constitute an idiosyncratic mixture of phonetic spelling, ad-hoc transliterations, and abbreviations. A great deal of information is lost in the romanization process due to the difficulty of representing native phonological distinctions in the Roman script. This makes deromanization of such messages a challenging task (Irvine et al., 2012). Another phenomenon that further complicates the task of deromanization is code-mixing, which occurs when words from another language (typically English) are introduced in the messages (e.g., the word decent in Figure 1). Code-mixing is particularly common in multi-lingual areas such as South Asia (Bali et al., 2014). In many cases, the 26 Proceedings of VarDial, pages 26–34 c Minneapolis, MN, June 7, 2019 2019 Association for Computational Linguistics 2.1 lem of word-level language identification (Chittaranjan et al., 2014; Choudhury et al., 2014). Transliteration and back-transliteration is"
W19-1403,N10-1103,1,0.717043,"ram model from unaligned source-target data.3 The model reflects the edit operations used in the conversion from source to target, and allows for the inclusion of source context in the generative model. Higher n-gram order models are trained iteratively from the lower order models. Sequitur was adopted as a baseline in the most recent NEWS shared task on transliteration (Chen et al., 2018). DTLM is a new system that combines discriminative transduction with character and word language models (LM) derived from large unannotated corpora (Nicolai et al., 2018).4 DTLM is an extension of DirecTL+ (Jiampojamarn et al., 2010). For target language modeling, which is particularly important in low-data scenarios, DirecTL+ uses binary n-gram features based exclusively on the forms in the parallel training data. This limitation often results in many ill-formed output candidates. DTLM avoids the error prop3 4 3.3 Sequence Prediction The transliteration systems process individual words in isolation, and thus fail to take into account the context of a word in a sentence. However, multiple native words may have the same romanized form, so the top-scoring prediction is often incorrect in the given context. To solve this pro"
W19-1403,W16-3908,0,0.0312609,"Missing"
W19-1403,N13-1131,0,0.0850456,"Missing"
W19-1403,P17-4012,0,0.0273896,"by employing a novel alignment method, which is referred to as precision alignment.5 The idea is to allow null substrings on the source side during the alignment of the training data, and then apply a separate aggregation algorithm to merge them with adjoining non-empty substrings. This method yields precise many-to-many alignment links that result in substantially higher transduction accuracy. DTLM was among the bestperforming systems at the recent NEWS shared task on transliteration (Chen et al., 2018). As our neural transliteration system, we adopt the PyTorch variant of the OpenNMT tool (Klein et al., 2017).6 The system employs an encoderdecoder architecture with an attention mechanism on top of the decoder RNN. We insert word boundaries between all characters in the input and output, resulting in translation models which view characters as words and words as sentences. We apply the default translation architecture provided by OpenNMT with the exception of using a bidirectional-LSTM in the encoder model. We optionally generate additional synthetic training data for the neural system, using a simple romanization table that maps each native script character to a set of English letters. Back-Transl"
W19-4202,K18-3001,0,0.128798,"Missing"
W19-4202,P18-4003,0,0.179513,"Missing"
W19-4202,P08-1103,1,0.803081,"urce setting, we attempt to leverage external text corpora, from which we extract target language word lists for both inflection generation and cognate projection. The results show that this strategy improves the overall results for some of the tested language pairs. Prior Work Our methods build upon the prior work of the University of Alberta teams for three previous SIGMORPHON shared tasks on type-level morphological generation (Cotterell et al., 2016, 2017, 2018). We view inflection as a string transduction task. Our discriminative transduction models stem from the D IREC TL+ transducer of Jiampojamarn et al. (2008), which was originally designed for grapheme-to-phoneme conversion. Nicolai et al. (2016) apply discriminative string transduction to morphological reinflection. They show that the approach of Nicolai et al. (2015) performs well on typologically diverse languages. They also discuss language-specific heuristics and errors. Nicolai et al. (2017) combine a discriminative transduction system with neural models. The results on five languages show that the approach works well in the low-resource setting. Additionally, they propose adaptations designed to handle small training sets, such as tag re-or"
W19-4202,I13-1112,0,0.0618009,"iteration (Najafi et al., 2018b). 3.2 4 Cognate Projection Methods Each dataset in this shared task pairs a lowresource (LR) language with a related highresource (HR) language. Genetically related languages share cognates, words with a common linguistic origin (St Arnaud et al., 2017). For example, the Latin word oculus ‘eye’ is cognate with the Romanian word ochi. Cognate pairs exhibit phonetic and semantic similarity (Kondrak, 2013). The correspondences between substrings in cognates tend to follow regular patterns (Kondrak, 2009). Cognate projection, also referred to as cognate production (Beinborn et al., 2013; Ciobanu, 2016), is the task of predicting the spelling of a hypothetical cognate in another language. For example, the projection of oculus from Latin to Romanian should generate ochi. Even if a cognate OpenNMT OpenNMT (Klein et al., 2017) is an open-source neural machine translation tool based on sequence to sequence model with attention mechanism. Klein et al. (2017) demonstrates that Open7 Language Kashubian Occitan Latin Bengali Source UniMorph Words Wikipedia 509 60286 Wikipedia 8316 318706 UniMorph 509182 357951 UniMorph 4443 2752 Pair pol↔csb spa↔oci ron↔lat hin↔ben Table 1: The size"
W19-4202,N15-1093,1,0.842257,"l results for some of the tested language pairs. Prior Work Our methods build upon the prior work of the University of Alberta teams for three previous SIGMORPHON shared tasks on type-level morphological generation (Cotterell et al., 2016, 2017, 2018). We view inflection as a string transduction task. Our discriminative transduction models stem from the D IREC TL+ transducer of Jiampojamarn et al. (2008), which was originally designed for grapheme-to-phoneme conversion. Nicolai et al. (2016) apply discriminative string transduction to morphological reinflection. They show that the approach of Nicolai et al. (2015) performs well on typologically diverse languages. They also discuss language-specific heuristics and errors. Nicolai et al. (2017) combine a discriminative transduction system with neural models. The results on five languages show that the approach works well in the low-resource setting. Additionally, they propose adaptations designed to handle small training sets, such as tag re-ordering and particle processing. Najafi et al. (2018a) make further progress on the combination of neural and non-neural models for low-resource reinflection. Their best system obtains the highest accuracy on 34 out"
W19-4202,L18-1293,0,0.0382073,"Missing"
W19-4202,K17-2008,1,0.911943,"s for three previous SIGMORPHON shared tasks on type-level morphological generation (Cotterell et al., 2016, 2017, 2018). We view inflection as a string transduction task. Our discriminative transduction models stem from the D IREC TL+ transducer of Jiampojamarn et al. (2008), which was originally designed for grapheme-to-phoneme conversion. Nicolai et al. (2016) apply discriminative string transduction to morphological reinflection. They show that the approach of Nicolai et al. (2015) performs well on typologically diverse languages. They also discuss language-specific heuristics and errors. Nicolai et al. (2017) combine a discriminative transduction system with neural models. The results on five languages show that the approach works well in the low-resource setting. Additionally, they propose adaptations designed to handle small training sets, such as tag re-ordering and particle processing. Najafi et al. (2018a) make further progress on the combination of neural and non-neural models for low-resource reinflection. Their best system obtains the highest accuracy on 34 out of 103 languages. They achieve additional improvements in accuracy by leveraging unannotated text corpora using the non-standard a"
W19-4202,W16-2005,1,0.86267,"age word lists for both inflection generation and cognate projection. The results show that this strategy improves the overall results for some of the tested language pairs. Prior Work Our methods build upon the prior work of the University of Alberta teams for three previous SIGMORPHON shared tasks on type-level morphological generation (Cotterell et al., 2016, 2017, 2018). We view inflection as a string transduction task. Our discriminative transduction models stem from the D IREC TL+ transducer of Jiampojamarn et al. (2008), which was originally designed for grapheme-to-phoneme conversion. Nicolai et al. (2016) apply discriminative string transduction to morphological reinflection. They show that the approach of Nicolai et al. (2015) performs well on typologically diverse languages. They also discuss language-specific heuristics and errors. Nicolai et al. (2017) combine a discriminative transduction system with neural models. The results on five languages show that the approach works well in the low-resource setting. Additionally, they propose adaptations designed to handle small training sets, such as tag re-ordering and particle processing. Najafi et al. (2018a) make further progress on the combin"
W19-4202,P17-4012,0,0.0763384,"Missing"
W19-4202,W18-5805,1,0.839983,"scriminative transduction system with neural models. The results on five languages show that the approach works well in the low-resource setting. Additionally, they propose adaptations designed to handle small training sets, such as tag re-ordering and particle processing. Najafi et al. (2018a) make further progress on the combination of neural and non-neural models for low-resource reinflection. Their best system obtains the highest accuracy on 34 out of 103 languages. They achieve additional improvements in accuracy by leveraging unannotated text corpora using the non-standard approaches of Nicolai et al. (2018) and Najafi et al. (2019). 1 For an unknown reason, only the inflected Latin forms in the data include vowel length diacritics. 6 Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 6–11 c Florence, Italy. August 2, 2019 2019 Association for Computational Linguistics Data Projection Low Resource Language Instance Projection High Resource Language Low Resource Language Latin dormio + V;3;SG LR words LR NMT inflect Latin DTLM HR DTLM Romanian dormio + V;3;SG HR cognate LR High Resource Language DTLM LR inflect words dormit dormit Latin Latin"
W19-4202,D17-1267,1,0.808242,"asks, including inflection generation, transliteration, phoneme-to-grapheme conversion, and cognate projection. In the CoNLL–SIGMORPHON 2018 Shared Task on Universal Morphological Reinflection (Cotterell et al., 2018), DTLM was our best performing individual system. It was also successfully used in the NEWS 2018 shared task on transliteration (Najafi et al., 2018b). 3.2 4 Cognate Projection Methods Each dataset in this shared task pairs a lowresource (LR) language with a related highresource (HR) language. Genetically related languages share cognates, words with a common linguistic origin (St Arnaud et al., 2017). For example, the Latin word oculus ‘eye’ is cognate with the Romanian word ochi. Cognate pairs exhibit phonetic and semantic similarity (Kondrak, 2013). The correspondences between substrings in cognates tend to follow regular patterns (Kondrak, 2009). Cognate projection, also referred to as cognate production (Beinborn et al., 2013; Ciobanu, 2016), is the task of predicting the spelling of a hypothetical cognate in another language. For example, the projection of oculus from Latin to Romanian should generate ochi. Even if a cognate OpenNMT OpenNMT (Klein et al., 2017) is an open-source neur"
W19-4202,tiedemann-2012-parallel,0,0.0244799,"on and cognate projection, it makes obvious sense to leverage additional resources, which are freely available for many under-resourced languages. We extract the target word lists for DTLM from UniMorph2 (Kirov et al., 2018). and Wikipedia3 , as summarized in Table 1.4 For cognate projection, we need training sets composed of cognate pairs, Finding good parallel bitexts for low-resource languages is quite challenging. Small bitexts exist in special domains, such as technical documentation or Bible translations. For Polish-Kashubian and SpanishOccitan, we use software documentation from OPUS5 (Tiedemann, 2012). For Hindi-Bengali, we use the OpenSubtitles (v2018) data, also from OPUS. For Romanian-Latin, we use a parallel corpus which contains a verse-by-verse alignment of the Bible translations in 100 languages (Christodouloupoulos and Steedman, 2015). 2 https://unimorph.github.io https://dumps.wikimedia.org 4 We are aware that the test data for the shared task may come from UniMorph. We use UniMorph solely for deriving the target word language model, without taking advantage of the morphological annotations. All our submissions that use external data are declared as non-standard. 5 http://opus.nlp"
W19-4202,P19-1148,0,0.0538257,"Missing"
W19-4202,K18-3015,1,0.848092,"for grapheme-to-phoneme conversion. Nicolai et al. (2016) apply discriminative string transduction to morphological reinflection. They show that the approach of Nicolai et al. (2015) performs well on typologically diverse languages. They also discuss language-specific heuristics and errors. Nicolai et al. (2017) combine a discriminative transduction system with neural models. The results on five languages show that the approach works well in the low-resource setting. Additionally, they propose adaptations designed to handle small training sets, such as tag re-ordering and particle processing. Najafi et al. (2018a) make further progress on the combination of neural and non-neural models for low-resource reinflection. Their best system obtains the highest accuracy on 34 out of 103 languages. They achieve additional improvements in accuracy by leveraging unannotated text corpora using the non-standard approaches of Nicolai et al. (2018) and Najafi et al. (2019). 1 For an unknown reason, only the inflected Latin forms in the data include vowel length diacritics. 6 Proceedings of the 16th Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 6–11 c Florence, Italy. August 2, 20"
W19-4202,W18-2412,1,0.888164,"Missing"
