2021.inlg-1.15,What can Neural Referential Form Selectors Learn?,2021,-1,-1,3,1,3826,guanyi chen,Proceedings of the 14th International Conference on Natural Language Generation,0,"Despite achieving encouraging results, neural Referring Expression Generation models are often thought to lack transparency. We probed neural Referential Form Selection (RFS) models to find out to what extent the linguistic features influencing the RE form are learned and captured by state-of-the-art RFS models. The results of 8 probing tasks show that all the defined features were learned to some extent. The probing tasks pertaining to referential status and syntactic position exhibited the highest performance. The lowest performance was achieved by the probing models designed to predict discourse structure properties beyond the sentence level."
2021.inlg-1.17,Using {BERT} for choosing classifiers in {M}andarin,2021,-1,-1,3,0,5947,jani jarnfors,Proceedings of the 14th International Conference on Natural Language Generation,0,"Choosing the most suitable classifier in a linguistic context is a well-known problem in the production of Mandarin and many other languages. The present paper proposes a solution based on BERT, compares this solution to previous neural and rule-based models, and argues that the BERT model performs particularly well on those difficult cases where the classifier adds information to the text."
2020.scil-1.35,"What do you mean, {BERT}?",2020,-1,-1,4,0,15538,timothee mickus,Proceedings of the Society for Computation in Linguistics 2020,0,None
2020.nl4xai-1.9,Towards Generating Effective Explanations of Logical Formulas: Challenges and Strategies,2020,-1,-1,2,0,10497,alexandra mayn,2nd Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence,0,"While the problem of natural language generation from logical formulas has a long tradition, thus far little attention has been paid to ensuring that the generated explanations are optimally effective for the user. We discuss issues related to deciding what such output should look like and strategies for addressing those issues. We stress the importance of informing generation of NL explanations of logical formulas through reader studies and findings on the comprehension of logic from Pragmatics and Cognitive Science. We then illustrate the discussed issues and potential ways of addressing them using a simple demo system{'}s output generated from a propositional logic formula."
2020.inlg-1.33,Lessons from Computational Modelling of Reference Production in {M}andarin and {E}nglish,2020,-1,-1,2,1,3826,guanyi chen,Proceedings of the 13th International Conference on Natural Language Generation,0,"Referring expression generation (REG) algorithms offer computational models of the production of referring expressions. In earlier work, a corpus of referring expressions (REs) in Mandarin was introduced. In the present paper, we annotate this corpus, evaluate classic REG algorithms on it, and compare the results with earlier results on the evaluation of REG for English referring expressions. Next, we offer an in-depth analysis of the corpus, focusing on issues that arise from the grammar of Mandarin. We discuss shortcomings of previous REG evaluations that came to light during our investigation and we highlight some surprising results. Perhaps most strikingly, we found a much higher proportion of under-specified expressions than previous studies had suggested, not just in Mandarin but in English as well."
2020.inlg-1.45,Gradations of Error Severity in Automatic Image Descriptions,2020,-1,-1,7,0,3387,emiel miltenburg,Proceedings of the 13th International Conference on Natural Language Generation,0,"Earlier research has shown that evaluation metrics based on textual similarity (e.g., BLEU, CIDEr, Meteor) do not correlate well with human evaluation scores for automatically generated text. We carried out an experiment with Chinese speakers, where we systematically manipulated image descriptions to contain different kinds of errors. Because our manipulated descriptions form minimal pairs with the reference descriptions, we are able to assess the impact of different kinds of errors on the perceived quality of the descriptions. Our results show that different kinds of errors elicit significantly different evaluation scores, even though all erroneous descriptions differ in only one character from the reference descriptions. Evaluation metrics based solely on textual similarity are unable to capture these differences, which (at least partially) explains their poor correlation with human judgments. Our work provides the foundations for future work, where we aim to understand why different errors are seen as more or less severe."
2020.coling-main.403,A Linguistic Perspective on Reference: Choosing a Feature Set for Generating Referring Expressions in Context,2020,-1,-1,2,1,5941,fahime same,Proceedings of the 28th International Conference on Computational Linguistics,0,"This paper reports on a structured evaluation of feature-based Machine Learning algorithms for selecting the form of a referring expression in discourse context. Based on this evaluation, we selected seven feature sets from the literature, amounting to 65 distinct linguistic features. The features were then grouped into 9 broad classes. After building Random Forest models, we used Feature Importance Ranking and Sequential Forward Search methods to assess the {``}importance{''} of the features. Combining the results of the two methods, we propose a consensus feature set. The 6 features in our consensus set come from 4 different classes, namely grammatical role, inherent features of the referent, antecedent form and recency."
2020.codi-1.12,Computational Interpretations of Recency for the Choice of Referring Expressions in Discourse,2020,-1,-1,2,1,5941,fahime same,Proceedings of the First Workshop on Computational Approaches to Discourse,0,"First, we discuss the most common linguistic perspectives on the concept of recency and propose a taxonomy of recency metrics employed in Machine Learning studies for choosing the form of referring expressions in discourse context. We then report on a Multi-Layer Perceptron study and a Sequential Forward Search experiment, followed by Bayes Factor analysis of the outcomes. The results suggest that recency metrics counting paragraphs and sentences contribute to referential choice prediction more than other recency-related metrics. Based on the results of our analysis, we argue that, sensitivity to discourse structure is important for recency metrics used in determining referring expression forms."
2020.ccl-1.81,{C}hinese Long and Short Form Choice Exploiting Neural Network Language Modeling Approaches,2020,-1,-1,2,1,4040,lin li,Proceedings of the 19th Chinese National Conference on Computational Linguistics,0,"This paper presents our work in long and short form choice, a significant question of lexical choice, which plays an important role in many Natural Language Understanding tasks. Long and short form sharing at least one identical word meaning but with different number of syllables is a highly frequent linguistic phenomenon in Chinese like \textit{èè-è(laohu-hu, tiger)}"
W19-8605,Choosing between Long and Short Word Forms in {M}andarin,2019,0,0,2,1,4040,lin li,Proceedings of the 12th International Conference on Natural Language Generation,0,"Between 80{\%} and 90{\%} of all Chinese words have long and short form such as èè/è (lao-hu/hu , tiger) (Duanmu:2013). Consequently, the choice between long and short forms is a key problem for lexical choice across NLP and NLG. Following an earlier work on abbreviations in English (Mahowald et al, 2013), we bring a probabilistic perspective to these questions, using both a behavioral and a corpus-based approach. We hypothesized that there is a higher probability of choosing short form in supportive context than in neutral context in Mandarin. Consistent with our prediction, our findings revealed that predictability of contexts makes effect on speakers{'} long and short form choice."
W19-8616,{QTUNA}: A Corpus for Understanding How Speakers Use Quantification,2019,0,0,2,1,3826,guanyi chen,Proceedings of the 12th International Conference on Natural Language Generation,0,"A prominent strand of work in formal semantics investigates the ways in which human languages quantify over the elements of a set, as when we say {``}\textit{All \textit{A} are \textit{B} }{''}, {``}\textit{All except two \textit{A} are \textit{B} }{''}, {``}\textit{Only a few of the \textit{A} are \textit{B} }{''} and so on. Our aim is to build Natural Language Generation algorithms that mimic humans{'} use of quantified expressions. To inform these algorithms, we conducted on a series of elicitation experiments in which human speakers were asked to perform a linguistic task that invites the use of quantified expressions. We discuss how these experiments were conducted and what corpora they gave rise to. We conduct an informal analysis of the corpora, and offer an initial assessment of the challenges that these corpora pose for Natural Language Generation. The dataset is available at: \url{https://github.com/a-quei/qtuna}."
W19-8667,Generating Quantified Descriptions of Abstract Visual Scenes,2019,0,0,2,1,3826,guanyi chen,Proceedings of the 12th International Conference on Natural Language Generation,0,"Quantified expressions have always taken up a central position in formal theories of meaning and language use. Yet quantified expressions have so far attracted far less attention from the Natural Language Generation community than, for example, referring expressions. In an attempt to start redressing the balance, we investigate a recently developed corpus in which quantified expressions play a crucial role; the corpus is the result of a carefully controlled elicitation experiment, in which human participants were asked to describe visually presented scenes. Informed by an analysis of this corpus, we propose algorithms that produce computer-generated descriptions of a wider class of visual scenes, and we evaluate the descriptions generated by these algorithms in terms of their correctness, completeness, and human-likeness. We discuss what this exercise can teach us about the nature of quantification and about the challenges posed by the generation of quantified expressions."
W18-6506,{S}imple{NLG}-{ZH}: a Linguistic Realisation Engine for {M}andarin,2018,0,1,2,1,3826,guanyi chen,Proceedings of the 11th International Conference on Natural Language Generation,0,"We introduce SimpleNLG-ZH, a realisation engine for Mandarin that follows the software design paradigm of SimpleNLG (Gatt and Reiter, 2009). We explain the core grammar (morphology and syntax) and the lexicon of SimpleNLG-ZH, which is very different from English and other languages for which SimpleNLG engines have been built. The system was evaluated by regenerating expressions from a body of test sentences and a corpus of human-authored expressions. Human evaluation was conducted to estimate the quality of regenerated sentences."
W18-6519,Modelling Pro-drop with the Rational Speech Acts Model,2018,0,0,2,1,3826,guanyi chen,Proceedings of the 11th International Conference on Natural Language Generation,0,"We extend the classic Referring Expressions Generation task by considering zero pronouns in {``}pro-drop{''} languages such as Chinese, modelling their use by means of the Bayesian Rational Speech Acts model (Frank and Goodman, 2012). By assuming that highly salient referents are most likely to be referred to by zero pronouns (i.e., pro-drop is more likely for salient referents than the less salient ones), the model offers an attractive explanation of a phenomenon not previously addressed probabilistically."
W18-6548,Generating Summaries of Sets of Consumer Products: Learning from Experiments,2018,0,0,3,0,27686,kittipitch kuptavanich,Proceedings of the 11th International Conference on Natural Language Generation,0,"We explored the task of creating a textual summary describing a large set of objects characterised by a small number of features using an e-commerce dataset. When a set of consumer products is large and varied, it can be difficult for a consumer to understand how the products in the set differ; consequently, it can be challenging to choose the most suitable product from the set. To assist consumers, we generated high-level summaries of product sets. Two generation algorithms are presented, discussed, and evaluated with human users. Our evaluation results suggest a positive contribution to consumers{'} understanding of the domain."
W18-6551,Meteorologists and Students: A resource for language grounding of geographical descriptors,2018,8,0,3,0,27652,alejandro ramossoto,Proceedings of the 11th International Conference on Natural Language Generation,0,"We present a data resource which can be useful for research purposes on language grounding tasks in the context of geographical referring expression generation. The resource is composed of two data sets that encompass 25 different geographical descriptors and a set of associated graphical representations, drawn as polygons on a map by two groups of human subjects: teenage students and expert meteorologists."
W18-6561,Statistical {NLG} for Generating the Content and Form of Referring Expressions,2018,0,0,2,1,20576,xiao li,Proceedings of the 11th International Conference on Natural Language Generation,0,"This paper argues that a new generic approach to statistical NLG can be made to perform Referring Expression Generation (REG) successfully. The model does not only select attributes and values for referring to a target referent, but also performs Linguistic Realisation, generating an actual Noun Phrase. Our evaluations suggest that the attribute selection aspect of the algorithm exceeds classic REG algorithms, while the Noun Phrases generated are as similar to those in a previously developed corpus as were Noun Phrases produced by a new set of human speakers."
W17-3532,Investigating the content and form of referring expressions in {M}andarin: introducing the Mtuna corpus,2017,7,0,1,1,5942,kees deemter,Proceedings of the 10th International Conference on Natural Language Generation,0,"East Asian languages are thought to handle reference differently from languages such as English, particularly in terms of the marking of definiteness and number. We present the first Data-Text corpus for Referring Expressions in Mandarin, and we use this corpus to test some initial hypotheses inspired by the theoretical linguistics literature. Our findings suggest that function words deserve more attention in Referring Expressions Generation than they have so far received, and they have a bearing on the debate about whether different languages make different trade-offs between clarity and brevity."
W16-6605,Designing Algorithms for Referring with Proper Names,2016,13,5,1,1,5942,kees deemter,Proceedings of the 9th International Natural Language Generation conference,0,None
W16-6618,Statistics-Based Lexical Choice for {NLG} from Quantitative Information,2016,6,2,2,1,20576,xiao li,Proceedings of the 9th International Natural Language Generation conference,0,None
W15-0402,Ontology Authoring Inspired By Dialogue,2015,12,0,4,1,34805,artemis parvizi,Proceedings of the 1st Workshop on Language and Ontologies,0,None
W13-2120,Generation of Quantified Referring Expressions: Evidence from Experimental Data,2013,6,0,2,0,40977,dale barr,Proceedings of the 14th {E}uropean Workshop on Natural Language Generation,0,"We present the results from an elicitation experiment in which human speakers were asked to produced quantified referring expressions (QREs), as in xe2x80x98The crate with 10 applesxe2x80x99, xe2x80x98The crate with many applesxe2x80x99, etc. These results suggest that some subtle contextual factors govern the choice between different types of QREs, and that numerals are highly preferred for subitizable quantities despite the availability of coarser-grained expressions."
W13-2133,Content Selection Challenge - {U}niversity of {A}berdeen Entry,2013,6,4,3,0,40984,roman kutlak,Proceedings of the 14th {E}uropean Workshop on Natural Language Generation,0,"Bouayad-Agha et al. (2012) issued a content determination challenge in which researchers were asked to create systems that can automatically select content suitable for a first paragraph in a Wikipedia article from an RDF knowledge base of information about people. This article is a description of the system built at the University of Aberdeen. Our working assumption is that the target text should contain information that is commonly known about the target person. The Wikipediaxe2x80x99s manual of style mentions that xe2x80x9cThe lead [section] serves as an introduction to the article and a summary of its most important aspects1.xe2x80x9d What is most important about a person is likely to be often mentioned in biographies and hence it is more likely to be commonly known. Our system was motivated by the notion of common ground, especially the way it was accounted for by (Clark and Marshall, 1981). Clark and Marshall (1981) introduce two categories of common ground: personal common ground shared by a small group of individuals and communal common ground shared by a community of people. We are most interested in the concept of communal common ground, which arises from the exposure to the same information within a community. For example, if there is a statue in front of your work place, you expect your colleagues to also know about this statue and so the information that there is a statue in front of you workplace becomes a part of the community knowledge (where the community are people who work at the same place). Our hypothesis is that if we take a corpus of documents produced by some large community (e.g., English speakers), we should be able to ap-"
W13-0212,A Pilot Experiment in Knowledge Authoring as Dialogue,2013,19,4,7,1,34805,artemis parvizi,Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Short Papers,0,"This project aims to build an ontology authoring interface in which the user is engaged in a dialogue with the system in controlled natural language. To investigate what such a dialogue might be like, a layered annotation scheme is being developed for interactions between ontology authors and the Protxefxbfxbdgxefxbfxbd ontology authoring environment. A pilot experiment has been conducted with ontology authors, which reveals the complexity of mapping between user-interface actions and acts that appear in natural language dialogues; it also suggests the addition of some unanticipated types of dialogue acts and points the way to some possible enhancements of the authoring interface."
N13-1137,Generating Expressions that Refer to Visible Objects,2013,52,44,2,0.555556,8841,margaret mitchell,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,Funding for this research has been provided by SICSA and ORSAS. We thank the anonymous reviewers for useful comments on this paper.
W12-1520,Blogging birds: Generating narratives about reintroduced species to promote public engagement,2012,11,6,3,0,10906,advaith siddharthan,{INLG} 2012 Proceedings of the Seventh International Natural Language Generation Conference,0,"This paper proposes the use of NLG to enhance public engagement during the course of species reintroductions. We examine whether ecological insights can be effectively communicated through blogs about satellite-tagged individuals, and whether such blogs can help create a positive perception of the species in readers' minds, a requirement for successful reintroduction. We then discuss the implications for NLG systems that generate blogs from satellite-tag data."
J12-1006,Computational Generation of Referring Expressions: A Survey,2012,0,0,2,0,3389,emiel krahmer,Computational Linguistics,0,"This article offers a survey of computational research on referring expression generation (REG). It introduces the REG problem and describes early work in this area, discussing what basic assumptio..."
W11-2808,Two Approaches for Generating Size Modifiers,2011,18,10,2,0.952381,8841,margaret mitchell,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,"This paper offers a solution to a small problem within a much larger problem. We focus on modelling how people use size in reference, words like big and tall, which is one piece within the much larger problem of how people refer to visible objects. Examining size in isolation allows us to begin untangling a few of the complex and interacting features that affect reference, and we isolate a set of features that may be used in a hand-coded algorithm or a machine learning approach to generate one of six basic size types. The hand-coded algorithm generates a modifier type with a high correspondence to those observed in human data, and achieves 81.3% accuracy in an entirely new domain. This trails oracle accuracy for this task by just 8%. Features used by the hand-coded algorithm are added to a larger set of features in the machine learning approach, and we do not find a statistically significant difference between the precision and recall of the two systems. The input and output of these systems are a novel characterization of the factors that affect referring expression generation, and the methods described here may serve as one building block in future work connecting vision to language."
W11-2846,Direction giving: an attempt to increase user engagement,2011,12,2,2,0,44162,bob duncan,Proceedings of the 13th {E}uropean Workshop on Natural Language Generation,0,These notes describe a contribution to the 2011 GIVE Challenge from the University of Aberdeen. Our contribution focuses on an attempt to increase the extent to which participants felt engaged in the direction giving/following game on which the GIVE challenge focuses.
W10-4210,Natural Reference to Objects in a Visual Domain,2010,32,37,2,0.952381,8841,margaret mitchell,Proceedings of the 6th International Natural Language Generation Conference,0,"This paper discusses the basic structures necessary for the generation of reference to objects in a visual scene. We construct a study designed to elicit naturalistic referring expressions to relatively complex objects, and find aspects of reference that have not been accounted for in work on Referring Expression Generation (REG). This includes reference to object parts, size comparisons without crisp measurements, and the use of analogies. By drawing on research in cognitive science, neurophysiology, and psycholinguistics, we begin developing the input structure and background knowledge necessary for an algorithm capable of generating the kinds of reference we observe."
W10-4212,Charting the Potential of Description Logic for the Generation of Referring Expressions,2010,17,9,2,0,37135,yuan ren,Proceedings of the 6th International Natural Language Generation Conference,0,"The generation of referring expressions (GRE), an important subtask of Natural Language Generation (NLG) is to generate phrases that uniquely identify domain entities. Until recently, many GRE algorithms were developed using only simple formalisms, which were taylor made for the task. Following the fast development of ontology-based systems, reinterpreta-tions of GRE in terms of description logic (DL) have recently started to be studied. However, the expressive power of these DL-based algorithms is still limited, not exceeding that of older GRE approaches. In this paper, we propose a DL-based approach to GRE that exploits the full power of OWL2. Unlike existing approaches, the potential of reasoning in GRE is explored."
W09-0615,A Hearer-Oriented Evaluation of Referring Expression Generation,2009,15,4,2,1,47096,imtiaz khan,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,This paper discusses the evaluation of a Generation of Referring Expressions algorithm that takes structural ambiguity into account. We describe an ongoing study with human readers.
W09-0626,What Game Theory Can Do for {NLG}: The Case of Vague Language (Invited Talk),2009,11,0,1,1,5942,kees deemter,Proceedings of the 12th {E}uropean Workshop on Natural Language Generation ({ENLG} 2009),0,None
C08-1055,Generation of Referring Expressions: Managing Structural Ambiguities,2008,17,11,2,1,47096,imtiaz khan,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Existing algorithms for the Generation of Referring Expressions tend to generate distinguishing descriptions at the semantic level, disregarding the ways in which surface issues can affect their quality. This paper considers how these algorithms should deal with surface ambiguity, focussing on structural ambiguity. We propose that not all ambiguity is worth avoiding, and suggest some ways forward that attempt to avoid unwanted interpretations. We sketch the design of an algorithm motivated by our experimental findings."
W07-2307,Evaluating algorithms for the Generation of Referring Expressions using a balanced corpus,2007,20,81,3,0.857143,6764,albert gatt,Proceedings of the Eleventh {E}uropean Workshop on Natural Language Generation ({ENLG} 07),0,"Despite being the focus of intensive research, evaluation of algorithms that generate referring expressions is still in its infancy. We describe a corpus-based evaluation methodology, applied to a number of classic algorithms in this area. The methodology focuses on balance and semantic transparency to enable comparison of human and algorithmic output. Although the Incremental Algorithm emerges as the best match, we found that its dependency on manually-set parameters makes its performance difficult to predict."
J07-2004,Generating Referring Expressions: Making Referents Easy to Identify,2007,28,60,2,1,16913,ivandre paraboni,Computational Linguistics,0,"It is often desirable that referring expressions be chosen in such a way that their referents are easy to identify. This article focuses on referring expressions in hierarchically structured domains, exploring the hypothesis that referring expressions can be improved by including logically redundant information in them if this leads to a significant reduction in the amount of search that is needed to identify the referent. Generation algorithms are presented that implement this idea by including logically redundant information into the generated expression, in certain well-circumscribed situations. To test our hypotheses, and to assess the performance of our algorithms, two controlled experiments with human subjects were conducted. The first experiment confirms that human judges have a preference for logically redundant expressions in the cases where our model predicts this to be the case. The second experiment suggests that readers benefit from the kind of logical redundancy that our algorithms produce, as measured in terms of the effort needed to identify the referent of the expression."
D07-1011,Incremental Generation of Plural Descriptions: Similarity and Partitioning,2007,21,9,2,0.857143,6764,albert gatt,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"Approaches to plural reference generation emphasise descriptive brevity, but often lack empirical backing. This paper describes a corpus-based study of plural descriptions, and proposes a psycholinguisticallymotivated algorithm for plural reference generation. The descriptive strategy is based on partitioning and incorporates corpusderived heuristics. An exhaustive evaluation shows that the output closely matches human data."
2007.mtsummit-ucnlg.21,Content determination in {GRE}: evaluating the evaluator,2007,4,3,1,1,5942,kees deemter,Proceedings of the Workshop on Using corpora for natural language generation,0,None
W06-1409,Overspecified Reference in Hierarchical Domains: Measuring the Benefits for Readers,2006,14,14,3,1,16913,ivandre paraboni,Proceedings of the Fourth International Natural Language Generation Conference,0,"It is often desirable that referring expressions be chosen in such a way that their referents are easy to identify. In this paper, we investigate to what extent identification becomes easier by the addition of logically redundant properties. We focus on hierarchically structured domains, whose content is not fully known to the reader when the referring expression is uttered."
W06-1413,The Clarity-Brevity Trade-off in Generating Referring Expressions,2006,8,5,3,1,47096,imtiaz khan,Proceedings of the Fourth International Natural Language Generation Conference,0,"Existing algorithms for the Generation of Referring Expressions (GRE) aim at generating descriptions that allow a hearer to identify its intended referent uniquely; the length of the expression is also considered, usually as a secondary issue. We explore the possibility of making the trade-off between these two factors more explicit, via a general cost function which scores these two aspects separately. We sketch some more complex phenomena which might be amenable to this treatment."
W06-1420,Building a Semantically Transparent Corpus for the Generation of Referring Expressions.,2006,6,64,1,1,5942,kees deemter,Proceedings of the Fourth International Natural Language Generation Conference,0,"This paper discusses the construction of a corpus for the evaluation of algorithms that generate referring expressions. It is argued that such an evaluation task requires a semantically transparent corpus, and controlled experiments are the best way to create such a resource. We address a number of issues that have arisen in an ongoing evaluation study, among which is the problem of judging the output of GRE algorithms against a human gold standard."
P06-2033,Conceptual Coherence in the Generation of Referring Expressions,2006,19,7,2,0.857143,6764,albert gatt,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"One of the challenges in the automatic generation of referring expressions is to identify a set of domain entities coherently, that is, from the same conceptual perspective. We describe and evaluate an algorithm that generates a conceptually coherent description of a target set. The design of the algorithm is motivated by the results of psycholinguistic experiments."
J06-2002,Generating Referring Expressions that Involve Gradable Properties,2006,49,68,1,1,5942,kees deemter,Computational Linguistics,0,"This article examines the role of gradable properties in referring expressions from the perspective of natural language generation. First, we propose a simple semantic analysis of vague descriptions (i.e., referring expressions that contain gradable adjectives) that reflects the context-dependent meaning of the adjectives in them. Second, we show how this type of analysis can inform algorithms for the generation of vague descriptions from numerical data. Third, we ask when such descriptions should be used. The article concludes with a discussion of salience and pointing, which are analyzed as if they were gradable adjectives."
J05-1002,Squibs and Discussions: Real versus Template-Based Natural Language Generation: A False Opposition?,2005,18,110,1,1,5942,kees deemter,Computational Linguistics,0,"This article challenges the received wisdom that template-based approaches to the generation of language are necessarily inferior to other approaches as regards their maintainability, linguistic well-foundedness, and quality of output. Some recent NLG systems that call themselves ''template-based'' will illustrate our claims."
W02-2115,Generating Easy References: the Case of Document Deixis,2002,12,15,2,1,16913,ivandre paraboni,Proceedings of the International Natural Language Generation Conference,0,None
J02-1003,Generating Referring Expressions: {B}oolean Extensions of the Incremental Algorithm,2002,32,107,1,1,5942,kees deemter,Computational Linguistics,0,"This paper brings a logical perspective to the generation of referring expressions, addressing the incompleteness of existing algorithms in this area. After studying references to individual objects, we discuss references to sets, including Boolean descriptions that make use of negated and disjoined properties. To guarantee that a distinguishing description is generated whenever such descriptions exist, the paper proposes generalizations and extensions of the Incremental Algorithm of Dale and Reiter (1995)."
W01-0804,Logical Form Equivalence: the Case of Referring Expressions Generation,2001,16,10,1,1,5942,kees deemter,Proceedings of the {ACL} 2001 Eighth {E}uropean Workshop on Natural Language Generation ({EWNLG}),0,"We examine the principle of co-extensivity which underlies current algorithms for the generation of referring expressions, and investigate to what extent the principle allows these algorithms to be generalized. The discussion focusses on the generation of complex Boolean descriptions and sentence aggregation."
P01-1015,From {RAGS} to {RICHES}: Exploiting the Potential of a Flexible Generation Architecture,2001,12,19,7,0,42348,lynne cahill,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"The RAGS proposals for generic specification of NLG systems includes a detailed account of data representation, but only an outline view of processing aspects. In this paper we introduce a modular processing architecture with a concrete implementation which aims to meet the RAGS goals of transparency and reusability. We illustrate the model with the RICHES system -- a generation system built from simple linguistically-motivated modules."
W00-1424,Generating Vague Descriptions,2000,9,24,1,1,5942,kees deemter,{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation,0,"This paper deals with the generation of definite (i.e., uniquely referring) descriptions containing semantically vague expressions ('large', 'small', etc.). Firstly, the paper proposes a semantic analysis of vague descriptions that does justice to the context-dependent meaning of the vague expressions in them. Secondly, the paper shows how this semantic analysis can be implemented using a modification of the Dale and Reiter (1995) algorithm for the generation of referring expressions. A notable feature of the new algorithm is that, unlike Dale and Reiter (1995), it covers plural as well as singular NPs. This algorithm has been implemented in an experimental NLG program using ProFIT. The paper concludes by formulating some pragmatic constraints that could allow a generator to choose between different semantically correct descriptions."
kibble-van-deemter-2000-coreference,Coreference Annotation: Whither?,2000,10,16,2,0,52335,rodger kibble,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The terms coreference and anaphora tend to be used inconsistently and interchangeably in much empirically-oriented work in NLP, and this threatens to lead to incoherent analyses of texts and arbitrary loss of information. This paper discusses the role of coreference annotation in Information Extraction, focussing on the coreference scheme defined for the MUC-7 evaluation exercise. We point out deficiencies in that scheme and make some suggestions towards a new annotation philosophy."
J00-4005,On Coreferring: Coreference in {MUC} and Related Annotation Schemes,2000,17,138,1,1,5942,kees deemter,Computational Linguistics,0,"In this paper, it is argued that coreference annotations, as performed in the MUC community for example, go well beyond annotation of the relation of coreference proper. As a result, it is not always clear what semantic relation these annotations are encoding. The paper discusses a number of problems with these annotations and concludes that rethinking of the coreference task is needed before the task is expanded. In particular, it suggests a division of labor whereby annotation of the coreference relation proper is separated from other tasks such as annotation of bound anaphora and of the relation between a subject and a predicative NP."
C00-1033,Authoring Multimedia Documents using {WYSIWYM} Editing,2000,15,5,1,1,5942,kees deemter,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"(1)This paper outlines a future 'ideal' multimedia document authoring system that allows authors to specify content and form of the document independently of each other and at a high level of abstraction;(2)It describes a working system that implements a small but significant part of the functionality of such an ideal system, based on semantic modeling of the pictures as well as the text of the document; and(3)It explains what needs to be done to bridge the gap between the implemented system and the ideal one."
W99-0213,"What is coreference, and what should coreference annotation be?",1999,6,20,1,1,5942,kees deemter,Coreference and Its Applications,0,"In this paper, it is argued that 'coreference annotation', as currently performed in the MUC community, goes well beyond annotation of the relation of coreference as it is commonly understood. As a result, it is not always clear what semantic relation these annotations are actually encoding. The paper discusses a number of interrelated problems with coreference annotation and concludes that rethinking of the coreference task is needed before the task can be expanded (e.g., to cover part/whole relations) as has recently been advocated. As a step towards solution of the problems with coreference annotation, one possible simplification of the annotation task is suggested. This strategy can be summed up by the phrase Coreference annotation should annotate coreference relations, and coreference relations only."
W98-0608,Coreference in Knowledge Editing,1998,-1,-1,1,1,5942,kees deemter,The Computational Treatment of Nominals,0,None
W97-0610,Context Modeling for Language and Speech Generation,1997,17,2,1,1,5942,kees deemter,Interactive Spoken Dialog Systems: Bringing Speech and {NLP} Together in Real Applications,0,"It is well known that some of the most important issues in the design of a dialogue system involve the modeling of linguistic context. The present paper highlights a number of these issues, focusing on the language and speech generation components of such systems, and discusses their implications for the way in which context has to be modeled in a spoken dialogue system. We will compare the 'dedicated' context models that have been proposed in theoretical and computational linguistics with the more general models proposed in artificial intelligence. Our main examples of a 'dedicated' context model will be the context model of the 'Dial Your Disc' (DYD) music information system (Collier and Landsbergen, 1995), (van Deemter and Odijk, 1997) and the better-known Discourse Representation Theory (e.g. (Kamp and Reyle, 1993)) of which this model is a variant. Our main example of a 'general' context model is provided by the so-called 'Ist' formalism (McCarthy, 1993)."
C90-3016,Structured Meanings in Computational Linguistics,1990,8,2,1,1,5942,kees deemter,{COLING} 1990 Volume 3: Papers presented to the 13th International Conference on Computational Linguistics,0,None
