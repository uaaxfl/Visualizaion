2020.wmt-1.63,Priming Neural Machine Translation,2020,0,28,5,0.961538,5485,minh pham,Proceedings of the Fifth Conference on Machine Translation,0,"Priming is a well known and studied psychology phenomenon based on the prior presentation of one stimulus (cue) to influence the processing of a response. In this paper, we propose a framework to mimic the process of priming in the context of neural machine translation (NMT). We evaluate the effect of using similar translations as priming cues on the NMT network. We propose a method to inject priming cues into the NMT network and compare our framework to other mechanisms that perform micro-adaptation during inference. Overall, experiments conducted in a multi-domain setting confirm that adding priming cues in the NMT decoder can go a long way towards improving the translation accuracy. Besides, we show the suitability of our framework to gather valuable information for an NMT network from monolingual resources."
2020.wmt-1.72,A Study of Residual Adapters for Multi-Domain Neural Machine Translation,2020,-1,-1,4,0.961538,5485,minh pham,Proceedings of the Fifth Conference on Machine Translation,0,"Domain adaptation is an old and vexing problem for machine translation systems. The most common approach and successful to supervised adaptation is to fine-tune a baseline system with in-domain parallel data. Standard fine-tuning however modifies all the network parameters, which makes this approach computationally costly and prone to overfitting. A recent, lightweight approach, instead augments a baseline model with supplementary (small) adapter layers, keeping the rest of the mode unchanged. This has the additional merit to leave the baseline model intact, and adaptable to multiple domains. In this paper, we conduct a thorough analysis of the adapter model in the context of a multidomain machine translation task. We contrast multiple implementations of this idea on two language pairs. Our main conclusions are that residual adapters provide a fast and cheap method for supervised multi-domain adaptation; our two variants prove as effective as the original adapter model, and open perspective to also make adapted models more robust to label domain errors."
2020.ngt-1.25,Efficient and High-Quality Neural Machine Translation with {O}pen{NMT},2020,-1,-1,5,1,16475,guillaume klein,Proceedings of the Fourth Workshop on Neural Generation and Translation,0,"This paper describes the OpenNMT submissions to the WNGT 2020 efficiency shared task. We explore training and acceleration of Transformer models with various sizes that are trained in a teacher-student setup. We also present a custom and optimized C++ inference engine that enables fast CPU and GPU decoding with few dependencies. By combining additional optimizations and parallelization techniques, we create small, efficient, and high-quality neural machine translation models."
2020.coling-main.348,Integrating Domain Terminology into Neural Machine Translation,2020,-1,-1,3,0,21441,elise michon,Proceedings of the 28th International Conference on Computational Linguistics,0,"This paper extends existing work on terminology integration into Neural Machine Translation, a common industrial practice to dynamically adapt translation to a specific domain. Our method, based on the use of placeholders complemented with morphosyntactic annotation, efficiently taps into the ability of the neural network to deal with symbolic knowledge to surpass the surface generalization shown by alternative techniques. We compare our approach to state-of-the-art systems and benchmark them through a well-defined evaluation framework, focusing on actual application of terminology and not just on the overall performance. Results indicate the suitability of our method in the use-case where terminology is used in a system trained on generic data only."
2020.amta-research.9,The {O}pen{NMT} Neural Machine Translation Toolkit: 2020 Edition,2020,-1,-1,4,1,16475,guillaume klein,Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track),0,None
2020.acl-main.144,Boosting Neural Machine Translation with Similar Translations,2020,-1,-1,3,1,9989,jitao xu,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"This paper explores data augmentation methods for training Neural Machine Translation to make use of similar translations, in a comparable way a human translator employs fuzzy matches. In particular, we show how we can simply present the neural model with information of both source and target sides of the fuzzy matches, we also extend the similarity to include semantically related translations retrieved using sentence distributed representations. We show that translations based on fuzzy matching provide the model with {``}copy{''} information while translations based on embedding similarities tend to extend the translation {``}context{''}. Results indicate that the effect from both similar sentences are adding up to further boost accuracy, combine naturally with model fine-tuning and are providing dynamic adaptation for unseen translation pairs. Tests on multiple data sets and domains show consistent accuracy improvements. To foster research around these techniques, we also release an Open-Source toolkit with efficient and flexible fuzzy-match implementation."
D19-5615,Enhanced Transformer Model for Data-to-Text Generation,2019,0,1,3,0,26548,li gong,Proceedings of the 3rd Workshop on Neural Generation and Translation,0,"Neural models have recently shown significant progress on data-to-text generation tasks in which descriptive texts are generated conditioned on database records. In this work, we present a new Transformer-based data-to-text generation model which learns content selection and summary generation in an end-to-end fashion. We introduce two extensions to the baseline transformer model: First, we modify the latent representation of the input, which helps to significantly improve the content correctness of the output summary; Second, we include an additional learning objective that accounts for content selection modelling. In addition, we propose two data augmentation methods that succeed to further improve performance of the resulting generation models. Evaluation experiments show that our final model outperforms current state-of-the-art systems as measured by different metrics: BLEU, content selection precision and content ordering. We made publicly available the transformer extension presented in this paper."
D19-5629,{SYSTRAN} @ {WNGT} 2019: {DGT} Task,2019,0,0,3,0,26548,li gong,Proceedings of the 3rd Workshop on Neural Generation and Translation,0,This paper describes SYSTRAN participation to the Document-level Generation and Trans- lation (DGT) Shared Task of the 3rd Workshop on Neural Generation and Translation (WNGT 2019). We participate for the first time using a Transformer network enhanced with modified input embeddings and optimising an additional objective function that considers content selection. The network takes in structured data of basketball games and outputs a summary of the game in natural language.
D19-5225,{SYSTRAN} @ {WAT} 2019: {R}ussian-{J}apanese News Commentary task,2019,0,0,5,1,9989,jitao xu,Proceedings of the 6th Workshop on Asian Translation,0,"This paper describes Systran{'}s submissions to WAT 2019 Russian-Japanese News Commentary task. A challenging translation task due to the extremely low resources available and the distance of the language pair. We have used the neural Transformer architecture learned over the provided resources and we carried out synthetic data generation experiments which aim at alleviating the data scarcity problem. Results indicate the suitability of the data augmentation experiments, enabling our systems to rank first according to automatic evaluations."
W18-6485,{SYSTRAN} Participation to the {WMT}2018 Shared Task on Parallel Corpus Filtering,2018,0,0,3,1,835,minhquang pham,Proceedings of the Third Conference on Machine Translation: Shared Task Papers,0,This paper describes the participation of SYSTRAN to the shared task on parallel corpus filtering at the Third Conference on Machine Translation (WMT 2018). We participate for the first time using a neural sentence similarity classifier which aims at predicting the relatedness of sentence pairs in a multilingual context. The paper describes the main characteristics of our approach and discusses the results obtained on the data sets published for the shared task.
W18-3914,Neural Network Architectures for {A}rabic Dialect Identification,2018,0,0,4,0,21441,elise michon,"Proceedings of the Fifth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial 2018)",0,"SYSTRAN competes this year for the first time to the DSL shared task, in the Arabic Dialect Identification subtask. We participate by training several Neural Network models showing that we can obtain competitive results despite the limited amount of training data available for learning. We report our experiments and detail the network architecture and parameters of our 3 runs: our best performing system consists in a Multi-Input CNN that learns separate embeddings for lexical, phonetic and acoustic input features (F1: 0.5289); we also built a CNN-biLSTM network aimed at capturing both spatial and sequential features directly from speech spectrograms (F1: 0.3894 at submission time, F1: 0.4235 with later found parameters); and finally a system relying on binary CNN-biLSTMs (F1: 0.4339)."
W18-2715,{O}pen{NMT} System Description for {WNMT} 2018: 800 words/sec on a single-core {CPU},2018,0,2,1,1,13889,jean senellart,Proceedings of the 2nd Workshop on Neural Machine Translation and Generation,0,"We present a system description of the OpenNMT Neural Machine Translation entry for the WNMT 2018 evaluation. In this work, we developed a heavily optimized NMT inference model targeting a high-performance CPU system. The final system uses a combination of four techniques, all of them lead to significant speed-ups in combination: (a) sequence distillation, (b) architecture modifications, (c) precomputation, particularly of vocabulary, and (d) CPU targeted quantization. This work achieves the fastest performance of the shared task, and led to the development of new features that have been integrated to OpenNMT and available to the community."
W18-1817,{O}pen{NMT}: Neural Machine Translation Toolkit,2018,30,2,5,1,16475,guillaume klein,Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Track),0,"OpenNMT is an open-source toolkit for neural machine translation (NMT). The system prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques. OpenNMT has been used in several production MT systems, modified for numerous research papers, and is implemented across several deep learning frameworks."
D18-1328,Fixing Translation Divergences in Parallel Corpora for Neural {MT},2018,0,2,3,1,835,minhquang pham,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"Corpus-based approaches to machine translation rely on the availability of clean parallel corpora. Such resources are scarce, and because of the automatic processes involved in their preparation, they are often noisy. This paper describes an unsupervised method for detecting translation divergences in parallel sentences. We rely on a neural network that computes cross-lingual sentence similarity scores, which are then used to effectively filter out divergent translations. Furthermore, similarity scores predicted by the network are used to identify and fix some partial divergences, yielding additional parallel segments. We evaluate these methods for English-French and English-German machine translation tasks, and show that using filtered/corrected corpora actually improves MT performance."
W17-4722,{SYSTRAN} Purely Neural {MT} Engines for {WMT}2017,2017,6,0,10,0,19900,yongchao deng,Proceedings of the Second Conference on Machine Translation,0,"This paper describes SYSTRAN's systems submitted to the WMT 2017 shared news translation task for English-German, in both translation directions. Our systems are built using OpenNMT, an open-source neural machine translation system, implementing sequence-to-sequence models with LSTM encoder/decoders and attention. We experimented using monolingual data automatically back-translated. Our resulting models are further hyper-specialised with an adaptation technique that finely tunes models according to the evaluation test sentences."
kobus-etal-2017-domain,Domain Control for Neural Machine Translation,2017,11,32,3,0,27334,catherine kobus,"Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",0,"Machine translation systems are very sensitive to the domains they were trained on. Several domain adaptation techniques have already been deeply studied. We propose a new technique for neural machine translation (NMT) that we call domain control which is performed at runtime using a unique neural network covering multiple domains. The presented approach shows quality improvements when compared to dedicated domains translating on any of the covered domains and even on out-of-domain data. In addition, model parameters do not need to be re-estimated for each domain, making this effective to real use cases. Evaluation is carried out on English-to-French translation for two different testing scenarios. We first consider the case where an end-user performs translations on a known domain. Secondly, we consider the scenario where the domain is not known and predicted at the sentence level before translating. Results show consistent accuracy improvements for both conditions."
P17-4012,{O}pen{NMT}: Open-Source Toolkit for Neural Machine Translation,2017,18,393,4,1,16475,guillaume klein,"Proceedings of {ACL} 2017, System Demonstrations",0,"We describe an open-source toolkit for neural machine translation (NMT). The toolkit prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques."
I17-2046,Boosting Neural Machine Translation,2017,0,0,4,0.99775,16476,dakun zhang,Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Training efficiency is one of the main problems for Neural Machine Translation (NMT). Deep networks need for very large data as well as many training iterations to achieve state-of-the-art performance. This results in very high computation cost, slowing down research and industrialisation. In this paper, we propose to alleviate this problem with several training methods based on data boosting and bootstrap with no modifications to the neural network. It imitates the learning process of humans, which typically spend more time when learning {``}difficult{''} concepts than easier ones. We experiment on an English-French translation task showing accuracy improvements of up to 1.63 BLEU while saving 20{\%} of training time."
2017.jeptalnrecital-demo.6,Conception d{'}une solution de d{\\'e}tection d{'}{\\'e}v{\\'e}nements bas{\\'e}e sur {T}witter (Design of a solution for event detection from Tweeter),2017,-1,-1,10,0,5281,christophe servan,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 3 - D{\\'e}monstrations,0,"Cet article pr{\'e}sente un syst{\`e}me d{'}alertes fond{\'e} sur la masse de donn{\'e}es issues de Tweeter. L{'}objectif de l{'}outil est de surveiller l{'}actualit{\'e}, autour de diff{\'e}rents domaines t{\'e}moin incluant les {\'e}v{\'e}nements sportifs ou les catastrophes naturelles. Cette surveillance est transmise {\`a} l{'}utilisateur sous forme d{'}une interface web contenant la liste d{'}{\'e}v{\'e}nements localis{\'e}s sur une carte."
2017.jeptalnrecital-court.27,Adaptation incr{\\'e}mentale de mod{\\`e}les de traduction neuronaux (Incremental adaptation of neural machine translation models),2017,-1,-1,3,0,5281,christophe servan,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 2 - Articles courts,0,"L{'}adaptation au domaine est un verrou scientifique en traduction automatique. Il englobe g{\'e}n{\'e}ralement l{'}adaptation de la terminologie et du style, en particulier pour la post-{\'e}dition humaine dans le cadre d{'}une traduction assist{\'e}e par ordinateur. Avec la traduction automatique neuronale, nous {\'e}tudions une nouvelle approche d{'}adaptation au domaine que nous appelons {``}sp{\'e}cialisation{''} et qui pr{\'e}sente des r{\'e}sultats prometteurs tant dans la vitesse d{'}apprentissage que dans les scores de traduction. Dans cet article, nous proposons d{'}explorer cette approche."
W12-3140,Joint {WMT} 2012 Submission of the {QUAERO} Project,2012,37,5,13,0.833333,3519,markus freitag,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"This paper describes the joint QUAERO submission to the WMT 2012 machine translation evaluation. Four groups (RWTH Aachen University, Karlsruhe Institute of Technology, LIMSI-CNRS, and SYSTRAN) of the QUAERO project submitted a joint translation for the WMT Germanxe2x86x92English task. Each group translated the data sets with their own systems and finally the RWTH system combination combined these translations in our final submission. Experimental results show improvements of up to 1.7 points in Bleu and 3.4 points in Ter compared to the best single system."
E12-2003,Collaborative Machine Translation Service for Scientific texts,2012,5,4,2,0,23604,patrik lambert,Proceedings of the Demonstrations at the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"French researchers are required to frequently translate into French the description of their work published in English. At the same time, the need for French people to access articles in English, or to international researchers to access theses or papers in French, is incorrectly resolved via the use of generic translation tools. We propose the demonstration of an end-to-end tool integrated in the HAL open archive for enabling efficient translation for scientific texts. This tool can give translation suggestions adapted to the scientific domain, improving by more than 10 points the BLEU score of a generic system. It also provides a post-edition service which captures user post-editing data that can be used to incrementally improve the translations engines. Thus it is helpful for users which need to translate or to access scientific texts."
2012.iwslt-papers.12,Incremental adaptation using translation information and post-editing analysis,2012,8,15,3,1,3257,frederic blain,Proceedings of the 9th International Workshop on Spoken Language Translation: Papers,0,"It is well known that statistical machine translation systems perform best when they are adapted to the task. In this paper we propose new methods to quickly perform incremental adaptation without the need to obtain word-by-word alignments from GIZA or similar tools. The main idea is to use an automatic translation as pivot to infer alignments between the source sentence and the reference translation, or user correction. We compared our approach to the standard method to perform incremental re-training. We achieve similar results in the BLEU score using less computational resources. Fast retraining is particularly interesting when we want to almost instantly integrate user feed-back, for instance in a post-editing context or machine translation assisted CAT tool. We also explore several methods to combine the translation models."
W11-2142,Joint {WMT} Submission of the {QUAERO} Project,2011,25,1,14,0.833333,3519,markus freitag,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"This paper describes the joint QUAERO submission to the WMT 2011 machine translation evaluation. Four groups (RWTH Aachen University, Karlsruhe Institute of Technology, LIMSI-CNRS, and SYSTRAN) of the QUAERO project submitted a joint translation for the WMT Germanxe2x86x92English task. Each group translated the data sets with their own systems. Then RWTH system combination combines these translations to a better one. In this paper, we describe the single systems of each group. Before we present the results of the system combination, we give a short description of the RWTH Aachen system combination approach."
2011.mtsummit-papers.17,Qualitative Analysis of Post-Editing for High Quality Machine Translation,2011,-1,-1,2,1,3257,frederic blain,Proceedings of Machine Translation Summit XIII: Papers,0,None
2011.iwslt-evaluation.15,Advances on spoken language translation in the Quaero program,2011,25,2,10,0,43221,karim boudahmane,Proceedings of the 8th International Workshop on Spoken Language Translation: Evaluation Campaign,0,"The Quaero program is an international project promoting research and industrial innovation on technologies for automatic analysis and classification of multimedia and multilingual documents. Within the program framework, research organizations and industrial partners collaborate to develop prototypes of innovating applications and services for access and usage of multimedia data. One of the topics addressed is the translation of spoken language. Each year, a project-internal evaluation is conducted by DGA to monitor the technological advances. This work describes the design and results of the 2011 evaluation campaign. The participating partners were RWTH, KIT, LIMSI and SYSTRAN. Their approaches are compared on both ASR output and reference transcripts of speech data for the translation between French and German. The results show that the developed techniques further the state of the art and improve translation quality."
2010.jec-1.4,Convergence of Translation Memory and Statistical Machine Translation,2010,15,47,2,0,4417,philipp koehn,Proceedings of the Second Joint EM+/CNGL Workshop: Bringing MT to the User: Research on Integrating MT in the Translation Industry,0,"We present two methods that merge ideas from statistical machine translation (SMT) and translation memories (TM). We use a TM to retrieve matches for source segments, and replace the mismatched parts with instructions to an SMT system to fill in the gap. We show that for fuzzy matches of over 70{\%}, one method outperforms both SMT and TM baselines."
2010.amta-papers.2,Fast Approximate String Matching with Suffix Arrays and A* Parsing,2010,-1,-1,2,0,4417,philipp koehn,Proceedings of the 9th Conference of the Association for Machine Translation in the Americas: Research Papers,0,"We present a novel exact solution to the approximate string matching problem in the context of translation memories, where a text segment has to be matched against a large corpus, while allowing for errors. We use suffix arrays to detect exact n-gram matches, A* search heuristics to discard matches and A* parsing to validate candidate segments. The method outperforms the canonical baseline by a factor of 100, with average lookup times of 4.3{--}247ms for a segment in a realistic scenario."
W09-0419,Statistical Post Editing and Dictionary Extraction: {S}ystran/{E}dinburgh Submissions for {ACL}-{WMT}2009,2009,9,16,2,1,4946,loic dugast,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,We describe here the two Systran/University of Edinburgh submissions for WMT2009. They involve a statistical post-editing model with a particular handling of named entities (English to French and German to English) and the extraction of phrasal rules (English to French).
W09-0423,{SMT} and {SPE} Machine Translation Systems for {WMT}{`}09,2009,14,19,4,0.571063,5770,holger schwenk,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,This paper describes the development of several machine translation systems for the 2009 WMT shared task evaluation. We only consider the translation between French and English. We describe a statistical system based on the Moses decoder and a statistical post-editing system using SYSTRAN's rule-based system. We also investigated techniques to automatically extract additional bilingual texts from comparable corpora.
2009.mtsummit-posters.6,Selective addition of corpus-extracted phrasal lexical rules to a rule-based machine translation system,2009,-1,-1,2,1,4946,loic dugast,Proceedings of Machine Translation Summit XII: Posters,0,None
2009.mtsummit-posters.17,Translation Model Adaptation for an {A}rabic/{F}rench News Translation System by Lightly- Supervised Training,2009,18,32,2,0.571063,5770,holger schwenk,Proceedings of Machine Translation Summit XII: Posters,0,"Published in MT Summit XII, August 2009 Most of the existing, easily available parallel texts to train a statistical machine translation system are from international organizations that use a particular jargon. In this paper, we consider the automatic adaptation of such a translation model to the news domain. The initial system was trained on more than 200M words of UN bitexts. We then explore large amounts of in-domainmonolingual texts to modify the probability distribution of the phrase-table and to learn new task-specific phrase-pairs. This procedure achieved an improvement of 3.5 points BLEU on the test set in an Arabic/French statistical machine translation system. This result compares favorably with other large state-of-the-art systems for this language pair."
W08-0313,First Steps towards a General Purpose {F}rench/{E}nglish Statistical Machine Translation System,2008,12,12,3,0.571063,5770,holger schwenk,Proceedings of the Third Workshop on Statistical Machine Translation,0,"This paper describes an initial version of a general purpose French/English statistical machine translation system. The main features of this system are the open-source Moses decoder, the integration of a bilingual dictionary and a continuous space target language model. We analyze the performance of this system on the test data of the WMT'08 evaluation."
W08-0327,Can we Relearn an {RBMT} System?,2008,7,15,2,1,4946,loic dugast,Proceedings of the Third Workshop on Statistical Machine Translation,0,"This paper describes SYSTRAN submissions for the shared task of the third Workshop on Statistical Machine Translation at ACL. Our main contribution consists in a French-English statistical model trained without the use of any human-translated parallel corpus. In substitution, we translated a monolingual corpus with SYSTRAN rule-based translation engine to produce the parallel corpus. The results are provided herein, along with a measure of error analysis."
C08-1115,Tighter Integration of Rule-Based and Statistical {MT} in Serial System Combination,2008,11,10,7,0,28492,nicola ueffing,Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008),0,"Recent papers have described machine translation (MT) based on an automatic post-editing or serial combination strategy whereby the input language is first translated into the target language by a rule-based MT (RBMT) system, then the target language output is automatically post-edited by a phrase-based statistical machine translation (SMT) system. This approach has been shown to improve MT quality over RBMT or SMT alone. In this previous work, there was a very loose coupling between the two systems: the SMT system only had access to the final 1-best translations from RBMT. Furthermore, the previous work involved European language pairs and relatively small training corpora. In this paper, we describe a more tightly integrated serial combination for the Chinese-to-English MT task. We will present experimental evaluation results on the 2008 NIST constrained data track where a significant gain in terms of both automatic and subjective metrics is achieved through the tighter coupling of the two systems."
W07-0732,Statistical Post-Editing on {SYSTRAN}{`}s Rule-Based Translation System,2007,4,98,2,1,4946,loic dugast,Proceedings of the Second Workshop on Statistical Machine Translation,0,This article describes the combination of a SYSTRAN system with a statistical post-editing (SPE) system. We document qualitative analysis on two experiments performed in the shared task of the ACL 2007 Workshop on Statistical Machine Translation. Comparative results and more integrated hybrid techniques are discussed.
2007.mtsummit-papers.59,Rapid development of new language pairs at {SYSTRAN},2007,-1,-1,3,0,49442,sylvain surcin,Proceedings of Machine Translation Summit XI: Papers,0,None
2006.amta-panels.5,First strategies for integrating hybrid approaches into established systems,2006,-1,-1,1,1,13889,jean senellart,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Panel on hybrid machine translation: why and how?,0,None
2006.amta-panels.5,The social impact of translation via {SMS},2006,-1,-1,1,1,13889,jean senellart,Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Panel on machine translation for social impact,0,None
2005.mtsummit-papers.28,Integration of {SYSTRAN} {MT} Systems in an Open Workflow,2005,-1,-1,3,0,51214,mats attnas,Proceedings of Machine Translation Summit X: Papers,0,None
W03-1729,{SYSTRAN}{'}s {C}hinese Word Segmentation,2003,1,7,2,0,48747,jin yang,Proceedings of the Second {SIGHAN} Workshop on {C}hinese Language Processing,0,"SYSTRAN's Chinese word segmentation is one important component of its Chinese-English machine translation system. The Chinese word segmentation module uses a rule-based approach, based on a large dictionary and fine-grained linguistic rules. It works on general-purpose texts from different Chinese-speaking regions, with comparable performance. SYSTRAN participated in the four open tracks in the First International Chinese Word Segmentation Bakeoff. This paper gives a general description of the segmentation module, as well as the results and analysis of its performance in the Bakeoff."
2003.mtsummit-semit.6,Inductive coding of the {A}rabic lexicon,2003,-1,-1,2,0,51536,ali farghaly,Workshop on Machine Translation for Semitic languages: issues and approaches,0,"SYSTRAN started the design and the development of Arabic, Farsi and Urdu to English machine translation systems in July 2002. This paper describes the methodology and implementation adopted for dictionary building and morphological analysis. SYSTRAN{'}s IntuitiveCodingÂ® technology (ICT) for facilitates the creation, update, and maintenance of Arabic, Farsi and Urdu lexical entries, is more modular and less costly. ICT for Arabic, Farsi, and Urdu requires the implementation of stem-based lexical entries, the authentic scripts for each language, a statistical Arabic stem-guesser, and separate declarative modules for internal and external morphology."
2003.mtsummit-papers.45,{SYSTRAN} new generation: the {XML} translation workflow,2003,2,3,1,1,13889,jean senellart,Proceedings of Machine Translation Summit IX: Papers,0,"Customization of Machine Translation (MT) is a prerequisite for corporations to adopt the technology. It is therefore important but nonetheless challenging. Ongoing implementation proves that XML is an excellent exchange device between MT modules that efficiently enables interaction between the user and the processes to reach highly granulated structure-based customization. Accomplished through an innovative approach called the SYSTRAN Translation Stylesheet, this method is coherent with the current evolution of the {``}authoring process{''}. As a natural progression, the next stage in the customization process is the integration of MT in a multilingual tool kit designed for the {``}authoring process{''}."
2003.mtsummit-papers.46,{SYSTRAN} intuitive coding technology,2003,-1,-1,1,1,13889,jean senellart,Proceedings of Machine Translation Summit IX: Papers,0,"Customizing a general-purpose MT system is an effective way to improve machine translation quality for specific usages. Building a user-specific dictionary is the first and most important step in the customization process. An intuitive dictionary-coding tool was developed and is now utilized to allow the user to build user dictionaries easily and intelligently. SYSTRAN{'}s innovative and proprietary IntuitiveCodingÂ® technology is the engine powering this tool. It is comprised of various components: massive linguistic resources, a morphological analyzer, a statistical guesser, finite-state automaton, and a context-free grammar. Methodologically, IntuitiveCodingÂ® is also a cross-application approach for high quality dictionary building in terminology import and exchange. This paper describes the various components and the issues involved in its implementation. An evaluation frame and utilization of the technology are also presented."
2001.mtsummit-papers.56,New generation Systran translation system,2001,-1,-1,1,1,13889,jean senellart,Proceedings of Machine Translation Summit VIII,0,"In this paper, we present the design of the new generation Systran translation systems, currently utilized in the development of English-Hungarian, English-Polish, English-Arabic, French-Arabic, Hungarian-French and Polish-French language pairs. The new design, based on the traditional Systran machine translation expertise and the existing linguistic resources, addresses the following aspects: efficiency, modularity, declarativity, reusability, and maintainability. Technically, the new systems rely on intensive use of state-of-the-art finite automaton and formal grammar implementation. The finite automata provide the essential lookup facilities and the natural capacity of factorizing intuitive linguistic sets. Linguistically, we have introduced a full monolingual description of linguistic information and the concept of implicit transfer. Finally, we present some by-products that are directly derived from the new architecture: intuitive coding tools, spell checker and syntactic tagger."
2001.mtsummit-papers.57,Resource alignment for machine translation or implicit transfer,2001,-1,-1,1,1,13889,jean senellart,Proceedings of Machine Translation Summit VIII,0,"In this article we present the concept of {``}implicit transfer{''} rules. We will show that they represent a valid compromise between huge direct transfer terminology lists and large sets of transfer rules, which are very complex to maintain. We present a concrete, real-life application of this concept in a customization project (TOLEDO project) concerning the automatic translation of Autodesk (ADSK) support pages. In this application, the alignment is moreover combined with a graph representation substituting linear dictionaries. We show how the concept could be extended to increase coverage of traditional translation dictionaries as well as to extract terminology from large existing multilingual corpora. We also introduce the concept of ``alignment dictionary'' which seems promising in its ability to extend the pragmatic limits of multilingual dictionary management."
1999.eamt-1.5,Semi-automatic acquisition of lexical resources for new languages or new domains,1999,-1,-1,1,1,13889,jean senellart,EAMT Workshop: EU and the new languages,0,None
W98-0611,Tools for locating noun phrases with finite state transducers,1998,1,1,1,1,13889,jean senellart,The Computational Treatment of Nominals,0,None
P98-2198,Locating Noun Phrases with Finite State Transducers,1998,1,11,1,1,13889,jean senellart,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"We present a method for constructing, maintaining and consulting a database of proper nouns. We describe noun phrases composed of a proper noun and/or a description of a human occupation. They are formalized by finite state transducers (FST) and large coverage dictionaries and are applied to a corpus of newspapers. We take into account synonymy and hyperonymy. This first stage of our parsing procedure has a high degree of accuracy. We show how we can handle requests such as: 'Find all newspaper articles in a general corpus mentioning the French prime minister', or 'How is Mr. X referred to in the corpus; what have been his different occupations through out the period over which our corpus extends?' In the first case, non trivial occurrences of noun phrases are located, that is phrases not containing words present in the request, but either synonyms, or proper nouns relevant to request. The results of the search is far better than than those obtained by a key-word based engine. Most answers are correct: except some cases of homonymy (where a human reader would also fail without more context). Also, the treatment of people having several different occupations is not fully resolved. We have built for French, a library of about one thousand such FSTs, and English FSTs are under construction. The same method can be used to locate and propose new proper nouns, simply by replacing given proper names in the same FSTs by variables."
C98-2193,Locating noun phrases with finite state transducers.,1998,1,11,1,1,13889,jean senellart,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"We present a method for constructing, maintaining and consulting a database of proper nouns. We describe noun phrases composed of a proper noun and/or a description of a human occupation. They are formalized by finite state transducers (FST) and large coverage dictionaries and are applied to a corpus of newspapers. We take into account synonymy and hyperonymy. This first stage of our parsing procedure has a high degree of accuracy. We show how we can handle requests such as: 'Find all newspaper articles in a general corpus mentioning the French prime minister', or 'How is Mr. X referred to in the corpus; what have been his different occupations through out the period over which our corpus extends?' In the first case, non trivial occurrences of noun phrases are located, that is phrases not containing words present in the request, but either synonyms, or proper nouns relevant to request. The results of the search is far better than than those obtained by a key-word based engine. Most answers are correct: except some cases of homonymy (where a human reader would also fail without more context). Also, the treatment of people having several different occupations is not fully resolved. We have built for French, a library of about one thousand such FSTs, and English FSTs are under construction. The same method can be used to locate and propose new proper nouns, simply by replacing given proper names in the same FSTs by variables."
