2020.acl-main.394,S19-2100,1,0.781489,"comes in the form of expletives, derogatory words or threats, with substantial success (Mishra et al., 2019b). However, abuse can also be expressed in more implicit and subtle ways, for instance, through the use of ambiguous terms and figurative language, which has proved more challenging to identify. The NLP community has experimented with a range of techniques for abuse detection, such as recurrent and convolutional neural networks (Pavlopoulos et al., 2017; Park and Fung, 2017; Wang, 2018), character-based models (Nobata et al., 2016) and graph-based learning methods (Mishra et al., 2018a; Aglionby et al., 2019; Mishra et al., 2019a), obtaining promising results. However, all of the existing approaches have focused on modelling the linguistic properties of the comments or the meta-data about the users. On the other hand, abusive language and behaviour are also inextricably linked to the emotional and psychological state of the speaker (Patrick, 1901), which is reflected in the affective characteristics of their language (Mabry, 1974). In this paper, we propose to model these two phenomena jointly and present the first abusive language detection method that incorporates affective features via a multi"
2020.acl-main.394,C18-1093,1,0.944357,"explicit abuse, that comes in the form of expletives, derogatory words or threats, with substantial success (Mishra et al., 2019b). However, abuse can also be expressed in more implicit and subtle ways, for instance, through the use of ambiguous terms and figurative language, which has proved more challenging to identify. The NLP community has experimented with a range of techniques for abuse detection, such as recurrent and convolutional neural networks (Pavlopoulos et al., 2017; Park and Fung, 2017; Wang, 2018), character-based models (Nobata et al., 2016) and graph-based learning methods (Mishra et al., 2018a; Aglionby et al., 2019; Mishra et al., 2019a), obtaining promising results. However, all of the existing approaches have focused on modelling the linguistic properties of the comments or the meta-data about the users. On the other hand, abusive language and behaviour are also inextricably linked to the emotional and psychological state of the speaker (Patrick, 1901), which is reflected in the affective characteristics of their language (Mabry, 1974). In this paper, we propose to model these two phenomena jointly and present the first abusive language detection method that incorporates affect"
2020.acl-main.394,N19-1221,1,0.869815,"ological consequences for its victims (Munro, 2011). This stresses the need for automated techniques for abusive language detection, a problem that has recently gained a great deal of interest in the natural language processing community. The term abuse refers collectively to all forms of expression that vilify or offend an individual or a group, including racism, sexism, personal attacks, harassment, cyber-bullying, and many others. Much of the recent research has focused on detecting explicit abuse, that comes in the form of expletives, derogatory words or threats, with substantial success (Mishra et al., 2019b). However, abuse can also be expressed in more implicit and subtle ways, for instance, through the use of ambiguous terms and figurative language, which has proved more challenging to identify. The NLP community has experimented with a range of techniques for abuse detection, such as recurrent and convolutional neural networks (Pavlopoulos et al., 2017; Park and Fung, 2017; Wang, 2018), character-based models (Nobata et al., 2016) and graph-based learning methods (Mishra et al., 2018a; Aglionby et al., 2019; Mishra et al., 2019a), obtaining promising results. However, all of the existing app"
2020.acl-main.394,W18-5101,1,0.889863,"explicit abuse, that comes in the form of expletives, derogatory words or threats, with substantial success (Mishra et al., 2019b). However, abuse can also be expressed in more implicit and subtle ways, for instance, through the use of ambiguous terms and figurative language, which has proved more challenging to identify. The NLP community has experimented with a range of techniques for abuse detection, such as recurrent and convolutional neural networks (Pavlopoulos et al., 2017; Park and Fung, 2017; Wang, 2018), character-based models (Nobata et al., 2016) and graph-based learning methods (Mishra et al., 2018a; Aglionby et al., 2019; Mishra et al., 2019a), obtaining promising results. However, all of the existing approaches have focused on modelling the linguistic properties of the comments or the meta-data about the users. On the other hand, abusive language and behaviour are also inextricably linked to the emotional and psychological state of the speaker (Patrick, 1901), which is reflected in the affective characteristics of their language (Mabry, 1974). In this paper, we propose to model these two phenomena jointly and present the first abusive language detection method that incorporates affect"
2020.acl-main.394,S18-1001,0,0.0836111,"Missing"
2020.acl-main.394,W17-3006,0,0.182203,"rsonal attacks, harassment, cyber-bullying, and many others. Much of the recent research has focused on detecting explicit abuse, that comes in the form of expletives, derogatory words or threats, with substantial success (Mishra et al., 2019b). However, abuse can also be expressed in more implicit and subtle ways, for instance, through the use of ambiguous terms and figurative language, which has proved more challenging to identify. The NLP community has experimented with a range of techniques for abuse detection, such as recurrent and convolutional neural networks (Pavlopoulos et al., 2017; Park and Fung, 2017; Wang, 2018), character-based models (Nobata et al., 2016) and graph-based learning methods (Mishra et al., 2018a; Aglionby et al., 2019; Mishra et al., 2019a), obtaining promising results. However, all of the existing approaches have focused on modelling the linguistic properties of the comments or the meta-data about the users. On the other hand, abusive language and behaviour are also inextricably linked to the emotional and psychological state of the speaker (Patrick, 1901), which is reflected in the affective characteristics of their language (Mabry, 1974). In this paper, we propose to m"
2020.acl-main.394,W17-3004,0,0.0163922,"cluding racism, sexism, personal attacks, harassment, cyber-bullying, and many others. Much of the recent research has focused on detecting explicit abuse, that comes in the form of expletives, derogatory words or threats, with substantial success (Mishra et al., 2019b). However, abuse can also be expressed in more implicit and subtle ways, for instance, through the use of ambiguous terms and figurative language, which has proved more challenging to identify. The NLP community has experimented with a range of techniques for abuse detection, such as recurrent and convolutional neural networks (Pavlopoulos et al., 2017; Park and Fung, 2017; Wang, 2018), character-based models (Nobata et al., 2016) and graph-based learning methods (Mishra et al., 2018a; Aglionby et al., 2019; Mishra et al., 2019a), obtaining promising results. However, all of the existing approaches have focused on modelling the linguistic properties of the comments or the meta-data about the users. On the other hand, abusive language and behaviour are also inextricably linked to the emotional and psychological state of the speaker (Patrick, 1901), which is reflected in the affective characteristics of their language (Mabry, 1974). In this p"
2020.acl-main.394,D14-1162,0,0.0852711,"re W l1 and W l2 are the weight matrices of the 2-layer MLP. Dropout is applied to the output m(p) of the MLP, which is then followed by a linear output layer to get the unnormalized output o(p) . For OffensEval, a sigmoid activation σ is then applied in order to make a binary prediction with respect to whether a post is offensive or not, while the network parameters are optimized to minimize the binary cross-entropy (BCE): Across the two STL baselines, we further experiment with two different input representations: 1) GloVe (G), where the input is projected through the GloVe embedding layer (Pennington et al., 2014); 2) GloVe+ELMo (G+E), where the input is first projected through the GloVe embedding layer and the ELMo embedding layer (Peters et al., 2018) separately, and then the final word representation e is obtained by concatenating the output of these two layers. Given these input representations, we have a total of 4 different baseline models for abuse detection. We use grid search to tune the hyperparameters of the baselines on the development sets of the primary task (i.e., abuse detection). 4.2 LBCE = − N 1 X yi · log(p(yi ))+ N i=1 (1 − yi ) · log(1 − p(yi )) (6) where N is the number of trainin"
2020.acl-main.394,N18-1202,0,0.0519517,"output layer to get the unnormalized output o(p) . For OffensEval, a sigmoid activation σ is then applied in order to make a binary prediction with respect to whether a post is offensive or not, while the network parameters are optimized to minimize the binary cross-entropy (BCE): Across the two STL baselines, we further experiment with two different input representations: 1) GloVe (G), where the input is projected through the GloVe embedding layer (Pennington et al., 2014); 2) GloVe+ELMo (G+E), where the input is first projected through the GloVe embedding layer and the ELMo embedding layer (Peters et al., 2018) separately, and then the final word representation e is obtained by concatenating the output of these two layers. Given these input representations, we have a total of 4 different baseline models for abuse detection. We use grid search to tune the hyperparameters of the baselines on the development sets of the primary task (i.e., abuse detection). 4.2 LBCE = − N 1 X yi · log(p(yi ))+ N i=1 (1 − yi ) · log(1 − p(yi )) (6) where N is the number of training examples, and y denotes the true and p(y) the predicted label. For Waseem&Hovy, a log sof tmax activation is applied for multiclass classifi"
2020.acl-main.394,P19-1163,0,0.0777485,"Missing"
2020.acl-main.394,W18-5111,0,0.0773734,"sment, cyber-bullying, and many others. Much of the recent research has focused on detecting explicit abuse, that comes in the form of expletives, derogatory words or threats, with substantial success (Mishra et al., 2019b). However, abuse can also be expressed in more implicit and subtle ways, for instance, through the use of ambiguous terms and figurative language, which has proved more challenging to identify. The NLP community has experimented with a range of techniques for abuse detection, such as recurrent and convolutional neural networks (Pavlopoulos et al., 2017; Park and Fung, 2017; Wang, 2018), character-based models (Nobata et al., 2016) and graph-based learning methods (Mishra et al., 2018a; Aglionby et al., 2019; Mishra et al., 2019a), obtaining promising results. However, all of the existing approaches have focused on modelling the linguistic properties of the comments or the meta-data about the users. On the other hand, abusive language and behaviour are also inextricably linked to the emotional and psychological state of the speaker (Patrick, 1901), which is reflected in the affective characteristics of their language (Mabry, 1974). In this paper, we propose to model these tw"
2020.acl-main.394,N16-2013,0,0.345304,"for abuse detection. Furthermore, we compare the performance of MTL to a transfer learning baseline and demonstrate that MTL provides significant improvements over transfer learning. 2 Related Work Techniques for abuse detection have gone through several stages of development, starting with extensive manual feature engineering and then turning to deep learning. Early approaches experimented with lexicon-based features (Gitari et al., 2015), bagof-words (BOW) or n-gram features (Sood et al., 2012; Dinakar et al., 2011), and user-specific features, such as age (Dadvar et al., 2013) and gender (Waseem and Hovy, 2016). With the advent of deep learning, the trend shifted, with abundant work focusing on neural architectures for abuse detection. In particular, the use of convolutional neural networks (CNNs) for detecting abuse has shown promising results (Park and Fung, 2017; Wang, 2018). This can be attributed to the fact that CNNs are well suited to extract local and position-invariant features (Yin et al., 2017). Character-level features have also been shown to be beneficial in tackling the issue of Out-of-Vocabulary (OOV) words (Mishra et al., 2018b), since abusive comments tend to contain obfuscated word"
2020.acl-main.394,N19-1144,0,0.0665069,"Missing"
2020.acl-main.394,S19-2010,0,0.0455156,"Missing"
2020.findings-emnlp.402,P17-1067,0,0.022945,"features. Hartmann et al. (2019) classified frames at a sentence level using bidirectional LSTMs and GRUs and recently Khanehzar et al. (2019) compared a set of classifiers on frame identification in news. Approaches predicting emotions for a given text typically adopt a categorical model of discrete, prototypical emotions, e.g. the six basic emotions of Ekman (1992). Early computational approaches employed vector space models (Danisman and Alpkocak, 2008) or shallow machine learning classifiers (Alm et al., 2005; Yang et al., 2007). Examples of deep neural methods are the recurrent model of Abdul-Mageed and Ungar (2017), who classified 24 fine-grained emotions, and the transformerbased SentiBERT architecture of Yin et al. (2020). Computational research on metaphor has mainly focused on detecting metaphorical language in text. Early research performed supervised classification with hand-engineered lexical, syntactic and psycholinguistic features (Tsvetkov et al., 2014; Beigman Klebanov et al., 2016; Turney et al., 2011; Strzalkowski et al., 2013; Bulat et al., 2017). Alternative approaches perform metaphor detection from distributional properties of words (Shutova et al., 2010; Guti´errez et al., 2016) or by"
2020.findings-emnlp.402,H05-1073,0,0.174501,"ach to identify tweet-level frames and used Probabilistic Soft Logic on language and social-based features. Hartmann et al. (2019) classified frames at a sentence level using bidirectional LSTMs and GRUs and recently Khanehzar et al. (2019) compared a set of classifiers on frame identification in news. Approaches predicting emotions for a given text typically adopt a categorical model of discrete, prototypical emotions, e.g. the six basic emotions of Ekman (1992). Early computational approaches employed vector space models (Danisman and Alpkocak, 2008) or shallow machine learning classifiers (Alm et al., 2005; Yang et al., 2007). Examples of deep neural methods are the recurrent model of Abdul-Mageed and Ungar (2017), who classified 24 fine-grained emotions, and the transformerbased SentiBERT architecture of Yin et al. (2020). Computational research on metaphor has mainly focused on detecting metaphorical language in text. Early research performed supervised classification with hand-engineered lexical, syntactic and psycholinguistic features (Tsvetkov et al., 2014; Beigman Klebanov et al., 2016; Turney et al., 2011; Strzalkowski et al., 2013; Bulat et al., 2017). Alternative approaches perform met"
2020.findings-emnlp.402,P16-2017,1,0.814269,"pproaches employed vector space models (Danisman and Alpkocak, 2008) or shallow machine learning classifiers (Alm et al., 2005; Yang et al., 2007). Examples of deep neural methods are the recurrent model of Abdul-Mageed and Ungar (2017), who classified 24 fine-grained emotions, and the transformerbased SentiBERT architecture of Yin et al. (2020). Computational research on metaphor has mainly focused on detecting metaphorical language in text. Early research performed supervised classification with hand-engineered lexical, syntactic and psycholinguistic features (Tsvetkov et al., 2014; Beigman Klebanov et al., 2016; Turney et al., 2011; Strzalkowski et al., 2013; Bulat et al., 2017). Alternative approaches perform metaphor detection from distributional properties of words (Shutova et al., 2010; Guti´errez et al., 2016) or by training deep neural models (Rei et al., 2017; Gao et al., 2018). Dankers et al. (2019) developed a joint model of metaphor and emotion by fine-tuning BERT in an MTL setting. 3 Tasks and datasets Political Perspective in News Media Political news can be biased towards the left or right side of the political spectrum. To model such biased perspectives computationally, we classify art"
2020.findings-emnlp.402,E17-2084,1,0.852918,"shallow machine learning classifiers (Alm et al., 2005; Yang et al., 2007). Examples of deep neural methods are the recurrent model of Abdul-Mageed and Ungar (2017), who classified 24 fine-grained emotions, and the transformerbased SentiBERT architecture of Yin et al. (2020). Computational research on metaphor has mainly focused on detecting metaphorical language in text. Early research performed supervised classification with hand-engineered lexical, syntactic and psycholinguistic features (Tsvetkov et al., 2014; Beigman Klebanov et al., 2016; Turney et al., 2011; Strzalkowski et al., 2013; Bulat et al., 2017). Alternative approaches perform metaphor detection from distributional properties of words (Shutova et al., 2010; Guti´errez et al., 2016) or by training deep neural models (Rei et al., 2017; Gao et al., 2018). Dankers et al. (2019) developed a joint model of metaphor and emotion by fine-tuning BERT in an MTL setting. 3 Tasks and datasets Political Perspective in News Media Political news can be biased towards the left or right side of the political spectrum. To model such biased perspectives computationally, we classify articles as left, right or centre using data from Li and Goldwasser (201"
2020.findings-emnlp.402,W13-0909,0,0.0249715,"sman and Alpkocak, 2008) or shallow machine learning classifiers (Alm et al., 2005; Yang et al., 2007). Examples of deep neural methods are the recurrent model of Abdul-Mageed and Ungar (2017), who classified 24 fine-grained emotions, and the transformerbased SentiBERT architecture of Yin et al. (2020). Computational research on metaphor has mainly focused on detecting metaphorical language in text. Early research performed supervised classification with hand-engineered lexical, syntactic and psycholinguistic features (Tsvetkov et al., 2014; Beigman Klebanov et al., 2016; Turney et al., 2011; Strzalkowski et al., 2013; Bulat et al., 2017). Alternative approaches perform metaphor detection from distributional properties of words (Shutova et al., 2010; Guti´errez et al., 2016) or by training deep neural models (Rei et al., 2017; Gao et al., 2018). Dankers et al. (2019) developed a joint model of metaphor and emotion by fine-tuning BERT in an MTL setting. 3 Tasks and datasets Political Perspective in News Media Political news can be biased towards the left or right side of the political spectrum. To model such biased perspectives computationally, we classify articles as left, right or centre using data from L"
2020.findings-emnlp.402,W06-1639,0,0.106031,"nd investigate whether incorporating metaphor or emotion-related features enhances the models of political discourse. Our results show that incorporating metaphor or emotion significantly improves performance across all tasks, emphasising the prominent role they play in political rhetoric. 4479 Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4479–4488 c November 16 - 20, 2020. 2020 Association for Computational Linguistics 2 Related work Modelling political discourse encompasses a broad spectrum of tasks, including estimating policy positions from political texts (Thomas et al., 2006; Lowe et al., 2011), identifying features that differentiate political rhetoric of opposing parties (Monroe et al., 2008) or predicting political affiliation of Twitter users (Conover et al., 2011; Pennacchiotti and Popescu, 2011; Preot¸iuc-Pietro et al., 2017). Deep neural networks have been widely used to model political perspective, bias or affiliation at document level: Iyyer et al. (2014) used a recurrent neural network (RNN) to predict political affiliation from US congressional speeches. Li and Goldwasser (2019) identified the political perspective of news articles using a hierarchical"
2020.findings-emnlp.402,P14-1024,0,0.0162379,"n (1992). Early computational approaches employed vector space models (Danisman and Alpkocak, 2008) or shallow machine learning classifiers (Alm et al., 2005; Yang et al., 2007). Examples of deep neural methods are the recurrent model of Abdul-Mageed and Ungar (2017), who classified 24 fine-grained emotions, and the transformerbased SentiBERT architecture of Yin et al. (2020). Computational research on metaphor has mainly focused on detecting metaphorical language in text. Early research performed supervised classification with hand-engineered lexical, syntactic and psycholinguistic features (Tsvetkov et al., 2014; Beigman Klebanov et al., 2016; Turney et al., 2011; Strzalkowski et al., 2013; Bulat et al., 2017). Alternative approaches perform metaphor detection from distributional properties of words (Shutova et al., 2010; Guti´errez et al., 2016) or by training deep neural models (Rei et al., 2017; Gao et al., 2018). Dankers et al. (2019) developed a joint model of metaphor and emotion by fine-tuning BERT in an MTL setting. 3 Tasks and datasets Political Perspective in News Media Political news can be biased towards the left or right side of the political spectrum. To model such biased perspectives c"
2020.findings-emnlp.402,D11-1063,0,0.0298178,"or space models (Danisman and Alpkocak, 2008) or shallow machine learning classifiers (Alm et al., 2005; Yang et al., 2007). Examples of deep neural methods are the recurrent model of Abdul-Mageed and Ungar (2017), who classified 24 fine-grained emotions, and the transformerbased SentiBERT architecture of Yin et al. (2020). Computational research on metaphor has mainly focused on detecting metaphorical language in text. Early research performed supervised classification with hand-engineered lexical, syntactic and psycholinguistic features (Tsvetkov et al., 2014; Beigman Klebanov et al., 2016; Turney et al., 2011; Strzalkowski et al., 2013; Bulat et al., 2017). Alternative approaches perform metaphor detection from distributional properties of words (Shutova et al., 2010; Guti´errez et al., 2016) or by training deep neural models (Rei et al., 2017; Gao et al., 2018). Dankers et al. (2019) developed a joint model of metaphor and emotion by fine-tuning BERT in an MTL setting. 3 Tasks and datasets Political Perspective in News Media Political news can be biased towards the left or right side of the political spectrum. To model such biased perspectives computationally, we classify articles as left, right"
2020.findings-emnlp.405,D15-1075,0,\N,Missing
2020.findings-emnlp.405,W02-1006,0,\N,Missing
2020.findings-emnlp.405,H94-1046,0,\N,Missing
2020.findings-emnlp.405,P10-4014,0,\N,Missing
2020.findings-emnlp.405,Q14-1019,0,\N,Missing
2020.findings-emnlp.405,P07-1005,0,\N,Missing
2020.findings-emnlp.405,P12-1029,0,\N,Missing
2020.findings-emnlp.405,J14-1003,0,\N,Missing
2020.findings-emnlp.405,D14-1162,0,\N,Missing
2020.findings-emnlp.405,N15-1035,0,\N,Missing
2020.findings-emnlp.405,K16-1006,0,\N,Missing
2020.findings-emnlp.405,P16-1085,0,\N,Missing
2020.findings-emnlp.405,C16-1130,0,\N,Missing
2020.findings-emnlp.405,E17-1010,0,\N,Missing
2020.findings-emnlp.405,D17-1120,0,\N,Missing
2020.findings-emnlp.405,P19-1568,0,\N,Missing
2020.findings-emnlp.405,P19-1589,0,\N,Missing
2020.findings-emnlp.405,N19-1423,0,\N,Missing
2020.findings-emnlp.405,D19-1533,0,\N,Missing
2020.findings-emnlp.405,D19-1112,0,\N,Missing
2020.findings-emnlp.405,W19-4326,0,\N,Missing
2020.findings-emnlp.405,D19-1045,0,\N,Missing
2020.findings-emnlp.405,D19-1403,0,\N,Missing
2020.findings-emnlp.405,D19-1431,0,\N,Missing
2020.tacl-1.16,D13-1202,0,0.0282557,"Missing"
2020.tacl-1.16,Q17-1002,0,0.255209,"Sentence Comprehension Using Distributional Semantic Models Vesna G. Djokic† Jean Maillard‡ Luana Bulat‡ Ekaterina Shutova† † ‡ ILLC, University of Amsterdam, The Netherlands Dept. of Computer Science & Technology, University of Cambridge, United Kingdom vesna@imsquared.eu, jean@maillard.it, ltf24@cam.ac.uk, e.shutova@uva.nl Abstract ability of distributional models to predict patterns of brain activity associated with the meaning of words, obtained via functional magnetic resonance imaging (fMRI) (Mitchell et al., 2008; Devereux et al., 2010; Pereira et al., 2013). Following in their steps, Anderson et al. (2017b) have investigated visually grounded semantic models in this context. They found that while both visual and text-based models can equally decode concrete words, textbased models show an overall advantage over visual models when decoding more abstract words. Other research has shown that data-driven semantic models can also successfully predict patterns of brain activity associated with the processing of sentences (Pereira et al., 2018) and larger narrative text passages (Wehbe et al., 2014; Huth et al., 2016). Recently, Jain and Huth (2018) investigated long short-term memory (LSTM) recurren"
2020.tacl-1.16,D17-1113,1,0.812686,"ith several kinds of semantic models: (1) 2 Related Work 2.1 Decoding Brain Activity Mitchell et al. (2008) were the first to show that distributional representations of concrete nouns 232 built from co-occurrence counts with 25 experiential verbs could predict brain activity elicited by these nouns. Later studies used the fMRI data of Mitchell et al. (2008) as a benchmark for testing a range of semantic models including topic modelbased semantic features learned from Wikipedia (Pereira et al., 2013), feature-norm based semantic features (Devereux et al., 2010), and skip-gram word embeddings (Bulat et al., 2017). Anderson et al. (2013) demonstrate that visually grounded semantic models can also decode brain activity associated with concrete words and show the best results using multimodal models. Additionally, Anderson et al. (2015) show that text-based models are superior in predicting brain activity of concrete words in brain areas related to linguistic processing, and the visual models in those related to visual processing. Lastly, Anderson et al. (2017b) use image and text-based semantic models to decode an fMRI dataset containing nouns with varying degree of concreteness. They show that text-bas"
2020.tacl-1.16,D15-1075,0,0.263036,"ing of literal and metaphoric sentences, providing support for the idea that the literal meaning is not fully accessible during familiar metaphor comprehension. 1 Introduction Distributional semantics aims to represent the meaning of linguistic fragments as high-dimensional dense vectors. It has been successfully used to model the meaning of individual words in semantic similarity and analogy tasks (Mikolov et al., 2013; Pennington et al., 2014); as well as the meaning of larger linguistic units in a variety of tasks, such as translation (Bahdanau et al., 2014) and natural language inference (Bowman et al., 2015). Recent research has also demonstrated the 231 Transactions of the Association for Computational Linguistics, vol. 8, pp. 231–246, 2020. https://doi.org/10.1162/tacl a 00307 Action Editor: Walter Daelemans. Submission batch: 11/2019; Published 4/2020. c 2020 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. word-based models, namely, word embeddings of the verb and the nominal object; (2) compositional models, namely, vector addition and an LSTM recurrent neural network; and (3) visual models, learning visual representations of the verb and its nominal object."
2020.tacl-1.16,W10-0609,0,0.0241684,"in the context of their nominal object. We experiment with several kinds of semantic models: (1) 2 Related Work 2.1 Decoding Brain Activity Mitchell et al. (2008) were the first to show that distributional representations of concrete nouns 232 built from co-occurrence counts with 25 experiential verbs could predict brain activity elicited by these nouns. Later studies used the fMRI data of Mitchell et al. (2008) as a benchmark for testing a range of semantic models including topic modelbased semantic features learned from Wikipedia (Pereira et al., 2013), feature-norm based semantic features (Devereux et al., 2010), and skip-gram word embeddings (Bulat et al., 2017). Anderson et al. (2013) demonstrate that visually grounded semantic models can also decode brain activity associated with concrete words and show the best results using multimodal models. Additionally, Anderson et al. (2015) show that text-based models are superior in predicting brain activity of concrete words in brain areas related to linguistic processing, and the visual models in those related to visual processing. Lastly, Anderson et al. (2017b) use image and text-based semantic models to decode an fMRI dataset containing nouns with var"
2020.tacl-1.16,P16-1139,0,0.022435,"sophisticated compositional model, we take the LSTM recurrent neural network architecture of Hochreiter and Schmidhuber (1997). We trained the LSTM on a natural language inference task (Bowman et al., 2015), as it is a complex semantic task where we expect rich meaning representations to play an important role. Given two sentences, the goal of natural language inference is to decide whether the first entails or contradicts the second, or whether they are unrelated. We used the LSTM to compute compositional representations for each sentence, and then used a single-layer perceptron classifier (Bowman et al., 2016) to predict the correct relationship. The inputs to the LSTM were the same 100-dim GloVe embeddings used for the other models, and were updated during training. The model was optimized using Adam (Kingma and Ba, 2014). We extracted 100-dim vector representations from the hidden state of the LSTM for the verb-object phrases in our stimulus set. 4.2 Visually Grounded Models We use the MMfeat toolkit (Kiela, 2016) to obtain visual representations in line with Anderson et al. (2017b). We retrieved 10 images for each word or phrase in our dataset using Google Image Search. We then extracted an embe"
2020.tacl-1.16,P16-4010,0,0.019912,"dicts the second, or whether they are unrelated. We used the LSTM to compute compositional representations for each sentence, and then used a single-layer perceptron classifier (Bowman et al., 2016) to predict the correct relationship. The inputs to the LSTM were the same 100-dim GloVe embeddings used for the other models, and were updated during training. The model was optimized using Adam (Kingma and Ba, 2014). We extracted 100-dim vector representations from the hidden state of the LSTM for the verb-object phrases in our stimulus set. 4.2 Visually Grounded Models We use the MMfeat toolkit (Kiela, 2016) to obtain visual representations in line with Anderson et al. (2017b). We retrieved 10 images for each word or phrase in our dataset using Google Image Search. We then extracted an embedding for each of the images from a deep convolutional neural network that was trained on the ImageNet classification task (Russakovsky et al., 2015). We used an architecture consisting of five convolutional 1 https://nlp.stanford.edu/projects/ glove/. 235 layers, followed by two fully connected rectified linear unit layers and a softmax layer for classification. To obtain an embedding for a given image we perf"
2020.tacl-1.16,P14-2135,0,0.0301138,"inct from the specific literal uses of verbs in our stimuli (which contained primarily verb predicates with inanimate objects as arguments). It is possible that verb predicates with animate objects as arguments involving social interactions may also be relevant to the metaphoric meaning. Indeed, an important embodied dimension of variance for abstract concepts is social-emotional information (Barsalou, 2009). Additionally, it is possible that differences in overall visual statistics between our images for objects versus verbs across literal and metaphorical sentences may have biased decoding. Kiela et al. (2014) show that images for concrete objects are more internally homogenous (less dispersed) than that for abstract concepts, which may have impacted the performance of the VISUAL OBJECT model in metaphor decoding. Importantly, however, differences in literal and metaphor decoding with the VISUAL VERB model should not necessarily be impacted by this as the verbs used were the same. Therefore, the fact that the visual models in action-related areas overall had higher decoding accuracies in metaphor compared to literal decoding suggests that this effect is not influenced by image dispersion. Rather th"
2020.tacl-1.16,P82-1020,0,0.780684,"Missing"
2020.tacl-1.16,D16-1017,0,0.0730432,"Missing"
2020.tacl-1.16,D14-1162,0,0.0884794,"ociated with reading of both literal and metaphoric sentences. Our results suggest that compositional models and word embeddings are able to capture differences in the processing of literal and metaphoric sentences, providing support for the idea that the literal meaning is not fully accessible during familiar metaphor comprehension. 1 Introduction Distributional semantics aims to represent the meaning of linguistic fragments as high-dimensional dense vectors. It has been successfully used to model the meaning of individual words in semantic similarity and analogy tasks (Mikolov et al., 2013; Pennington et al., 2014); as well as the meaning of larger linguistic units in a variety of tasks, such as translation (Bahdanau et al., 2014) and natural language inference (Bowman et al., 2015). Recent research has also demonstrated the 231 Transactions of the Association for Computational Linguistics, vol. 8, pp. 231–246, 2020. https://doi.org/10.1162/tacl a 00307 Action Editor: Walter Daelemans. Submission batch: 11/2019; Published 4/2020. c 2020 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license. word-based models, namely, word embeddings of the verb and the nominal object; (2) comp"
2020.tacl-1.16,S16-2003,1,\N,Missing
2021.acl-long.210,N19-1050,1,0.83103,"the first dataset of 6000 English language Reddit comments that has finegrained, real-valued scores between -1 (maximally supportive) and 1 (maximally offensive) – normative offensiveness ratings for the comments. For the first time, we use comparative annotations to detect offensive language. In its simplest form, comparative annotations involve giving the annotators two instances at a time, and asking which exhibits the property of interest to a greater extent. This alleviates several annotation biases present in standard rating scales, such as scale-region bias (Presser and Schuman, 1996; Asaadi et al., 2019), and improves annotation consistency (Kiritchenko and Mohammad, 2017). However, instead of needing to annotate N instances, one now needs to annotate N 2 instance pairs—which can be prohibitive. Thus, we annotate our dataset using an efficient form of comparative annotation called Best–Worst Scaling (BWS) (Louviere, 1991; Louviere et al., 2015; Kiritchenko and Mohammad, 2016, 2017). Surveys by Schmidt and Wiegand (2017); Fortuna and Nunes (2018); Mishra et al. (2019); Vidgen and Derczynski (2020) discuss various existing datasets and their compositions in detail. Waseem and Hovy (2016); David"
2021.acl-long.210,S19-2007,0,0.0334653,"s), the reduced-range dataset. We discuss the models’ performance on this dataset in the next section. HateBERT HateBERT (Caselli et al., 2020b) is a version of BERT pretrained for abusive language detection in English. HateBERT was trained on RAL-E, a large dataset of English language Reddit comments from communities banned for being offensive or hateful. HateBERT has been shown to outperform the general purpose BERT model on the offensive language detection task when finetuned on popular datasets such as OffensEval 2019 (Zampieri et al., 2019), AbusEval (Caselli et al., 2020a), and HatEval (Basile et al., 2019). We fine-tuned HateBERT on Ruddit and its variants. The experimental setup for this model is the same as that described for the BERT model. 6.2 6 Computational Modeling In this section, we present benchmark experiments on Ruddit and its variants by implementing some commonly used model architectures. The task of the models was to predict the offensiveness score of a given comment. We performed 5-fold crossvalidation for each of the models.6 6.1 Models Bidirectional LSTM We fed pre-trained 300 dimensional GloVe word embeddings (Pennington et al., 2014) to a 2-layered BiLSTM to obtain a sentenc"
2021.acl-long.210,S12-1047,1,0.755705,"annotation results in inequalities for 5 of the 6 item pairs. For example, a 4-tuple with items A, B, C, and D, where A is the best, and D is the worst, results in inequalities: A&gt;B, A&gt;C, A&gt;D, B&gt;D, and C&gt;D. Real-valued scores of associations are calculated between the items and the property of interest from the best–worst annotations for a set of 4-tuples (Orme, 2009; Flynn and Marley, 2014). The scores can be used to rank items by the degree of association with the property of interest. Within the NLP community, BWS has thus far been used only for creating datasets for relational similarity (Jurgens et al., 2012), word-sense disambiguation (Jurgens, 2013), word–sentiment intensity (Kiritchenko et al., 2014), phrase sentiment composition (Kiritchenko and Mohammad, 2016), and tweet-emotion intensity (Mohammad and Bravo-Marquez, 2017; Mohammad and Kiritchenko, 2018). Using BWS, we create the first dataset with degree of offensiveness scores for social media comments. 3 Data collection and sampling We extracted Reddit data from the Pushshift repository (Baumgartner et al., 2020) using Google BigQuery. Reddit is a social news aggregation, web content rating, and discussion website. It contains forums calle"
2021.acl-long.210,P17-2074,1,0.933368,"that has finegrained, real-valued scores between -1 (maximally supportive) and 1 (maximally offensive) – normative offensiveness ratings for the comments. For the first time, we use comparative annotations to detect offensive language. In its simplest form, comparative annotations involve giving the annotators two instances at a time, and asking which exhibits the property of interest to a greater extent. This alleviates several annotation biases present in standard rating scales, such as scale-region bias (Presser and Schuman, 1996; Asaadi et al., 2019), and improves annotation consistency (Kiritchenko and Mohammad, 2017). However, instead of needing to annotate N instances, one now needs to annotate N 2 instance pairs—which can be prohibitive. Thus, we annotate our dataset using an efficient form of comparative annotation called Best–Worst Scaling (BWS) (Louviere, 1991; Louviere et al., 2015; Kiritchenko and Mohammad, 2016, 2017). Surveys by Schmidt and Wiegand (2017); Fortuna and Nunes (2018); Mishra et al. (2019); Vidgen and Derczynski (2020) discuss various existing datasets and their compositions in detail. Waseem and Hovy (2016); Davidson et al. (2017); Founta et al. (2018) created datasets based on Twit"
2021.acl-long.210,N16-1095,1,0.888787,"Missing"
2021.acl-long.210,2020.alw-1.17,0,0.0310683,"ffensive nor hate-speech and Founta et al. (2018) as abusive, hateful, normal, spam. Schmidt and Wiegand (2017); Fortuna and Nunes (2018); Mishra et al. (2019); Kiritchenko and Nejadgholi (2020) summarize the different definitions. However, these categories have significant overlaps with each other, creating ill-defined boundaries, thus introducing ambiguity and annotation inconsistency (Founta et al., 2018). A further challenge is that after encountering several highly offensive comments, an annotator might find subsequent moderately offensive comments to not be offensive (de-sensitization) (Kurrek et al., 2020; Soral et al., 2018). At the same time, existing approaches do not take into account that comments can be offensive to a different degree. Knowing the degree of offensiveness of a comment has practical implications, when taking action against inappropriate behaviour online, as it allows for a more fine-grained analysis and prioritization in moderation. The representation of the offensive class in a dataset is often boosted using different strategies. The most common strategy used is key-word based sampling. This results in datasets that are rich in explicit offensive language (language that i"
2021.acl-long.210,2020.alw-1.9,0,0.0473109,"Missing"
2021.acl-long.210,P18-1017,1,0.850033,"Emotions are highly representative of one’s mental state, which in turn are associated with their behaviour (Poria et al., 2019). For example, Jay and Janschewitz (2008) show that people tend to swear when they are angry, frustrated or anxious. Studies have shown that the primary dimensions of emotion are valence, arousal, and dominance (VAD) (Osgood et al., 1957; Russell, 1980, 2702 2003). Valence is the positive–negative or pleasure– displeasure dimension. Arousal is the excited– calm or active–passive dimension. Dominance is powerful–weak or ‘have full control’–‘have no control’ dimension (Mohammad, 2018). To boost the representation of offensive and emotional comments in our dataset, we up-sampled comments that included low-valence (highly negative) words and those that included high-arousal words (as per the NRC VAD lexicon (Mohammad, 2018)). The manually constructed NRC VAD lexicon includes 20,000 English words, each with a real-valued score between 0 and 1 in the V, A, D dimensions. In order to do this upsampling, we first defined the valence score of each comment as the average valence score of the negative words within the comment (A negative word is defined as a word with a valence scor"
2021.acl-long.210,S17-1007,1,0.938177,"negative consequences for the victim’s mental health (Munro, 2011). Automated offensive language detection has thus been gaining interest in the NLP community, as a promising direction to better understand the nature and spread of such content. There are several challenges in the automatic detection of offensive language (Wiedemann et al., 2018). The NLP community has adopted various definitions for offensive language, classifying it into specific categories. For example, Waseem and ∗ Both authors contributed equally. Hovy (2016) classified comments as racist, sexist, neither; Davidson et al. (2017) as hate-speech, offensive but not hate-speech, neither offensive nor hate-speech and Founta et al. (2018) as abusive, hateful, normal, spam. Schmidt and Wiegand (2017); Fortuna and Nunes (2018); Mishra et al. (2019); Kiritchenko and Nejadgholi (2020) summarize the different definitions. However, these categories have significant overlaps with each other, creating ill-defined boundaries, thus introducing ambiguity and annotation inconsistency (Founta et al., 2018). A further challenge is that after encountering several highly offensive comments, an annotator might find subsequent moderately of"
2021.acl-long.210,L18-1030,1,0.849767,"calculated between the items and the property of interest from the best–worst annotations for a set of 4-tuples (Orme, 2009; Flynn and Marley, 2014). The scores can be used to rank items by the degree of association with the property of interest. Within the NLP community, BWS has thus far been used only for creating datasets for relational similarity (Jurgens et al., 2012), word-sense disambiguation (Jurgens, 2013), word–sentiment intensity (Kiritchenko et al., 2014), phrase sentiment composition (Kiritchenko and Mohammad, 2016), and tweet-emotion intensity (Mohammad and Bravo-Marquez, 2017; Mohammad and Kiritchenko, 2018). Using BWS, we create the first dataset with degree of offensiveness scores for social media comments. 3 Data collection and sampling We extracted Reddit data from the Pushshift repository (Baumgartner et al., 2020) using Google BigQuery. Reddit is a social news aggregation, web content rating, and discussion website. It contains forums called subreddits dedicated to specific topics. Users can make a post on the subreddit to start a discussion. Users can comment on existing posts or comments to participate in the discussion. As users can also reply to a comment, the entire discussion has a hi"
2021.acl-long.210,D18-1302,0,0.0188152,"gen and Derczynski (2020) discuss various existing datasets and their compositions in detail. Waseem and Hovy (2016); Davidson et al. (2017); Founta et al. (2018) created datasets based on Twitter data. Due to prevalence of the non-offensive class in naturallyoccurring data (Waseem, 2016; Founta et al., 2018), the authors devised techniques to boost the presence of the offensive class in the dataset. Waseem and Hovy (2016) used terms frequently occurring in offensive tweets, while Davidson et al. (2017) used a list of hate-related terms to extract offensive tweets from the Twitter search API. Park et al. (2018), Wiegand et al. (2019), and Davidson et al. (2019) show that the Waseem and Hovy (2016) dataset exhibits topic bias and author bias due to the employed sampling strategy. Founta et al. (2018) boosted the representation of offensive class in their dataset by analysing the sentiment of the tweets and checking for the presence of offensive terms. In our work, we employ a hybrid approach, selecting our data in three ways: specific topics, emotion-related key-words, and random sampling. Past work has partitioned offensive comments into explicitly offensive (those that include profanity—swear words"
2021.acl-long.210,D14-1162,0,0.0864822,"busEval (Caselli et al., 2020a), and HatEval (Basile et al., 2019). We fine-tuned HateBERT on Ruddit and its variants. The experimental setup for this model is the same as that described for the BERT model. 6.2 6 Computational Modeling In this section, we present benchmark experiments on Ruddit and its variants by implementing some commonly used model architectures. The task of the models was to predict the offensiveness score of a given comment. We performed 5-fold crossvalidation for each of the models.6 6.1 Models Bidirectional LSTM We fed pre-trained 300 dimensional GloVe word embeddings (Pennington et al., 2014) to a 2-layered BiLSTM to obtain a sentence representation (using a concatenation of the last hidden state from the forward and backward direction). This sentence representation was then passed to a linear layer with a tanh activation to produce a score between −1 and 1. We used Mean Squared Error (MSE) loss as the objective function, Adam with 0.001 learning rate as the optimizer, hidden dimension of 256, batch size of 32, and a dropout of 0.5. The model was trained for 7 epochs. BERT We fine-tuned BERTbase (Devlin et al., 2019). We added a regression head containing a linear layer to the pre"
2021.acl-long.210,P19-1163,0,0.049151,"Missing"
2021.acl-long.210,2020.acl-main.486,0,0.12141,"lysing the sentiment of the tweets and checking for the presence of offensive terms. In our work, we employ a hybrid approach, selecting our data in three ways: specific topics, emotion-related key-words, and random sampling. Past work has partitioned offensive comments into explicitly offensive (those that include profanity—swear words, taboo words, or hate terms) and implicitly offensive (those that do not include profanity) (Waseem et al., 2017; Caselli et al., 2020a; Wiegand et al., 2021). Some other past work has defined explicitly and implicitly offensive instances a little differently: Sap et al. (2020) considered factors such as obviousness, intent to offend and biased implications, Breitfeller et al. (2019) considered factors such as the context and the person annotating the instance, and Razo and K¨ubler (2020) considered the kind of lexicon used. Regardless of the exact definition, implicit offensive language, due to a lack of lexical cues, is harder to classify not only for computational models, but also for humans. In our work, we consider implicitly offensive comments as those offensive comments that do not contain any swear words. By eliminating different offensiveness categories, tr"
2021.acl-long.210,W17-1101,0,0.177044,"community, as a promising direction to better understand the nature and spread of such content. There are several challenges in the automatic detection of offensive language (Wiedemann et al., 2018). The NLP community has adopted various definitions for offensive language, classifying it into specific categories. For example, Waseem and ∗ Both authors contributed equally. Hovy (2016) classified comments as racist, sexist, neither; Davidson et al. (2017) as hate-speech, offensive but not hate-speech, neither offensive nor hate-speech and Founta et al. (2018) as abusive, hateful, normal, spam. Schmidt and Wiegand (2017); Fortuna and Nunes (2018); Mishra et al. (2019); Kiritchenko and Nejadgholi (2020) summarize the different definitions. However, these categories have significant overlaps with each other, creating ill-defined boundaries, thus introducing ambiguity and annotation inconsistency (Founta et al., 2018). A further challenge is that after encountering several highly offensive comments, an annotator might find subsequent moderately offensive comments to not be offensive (de-sensitization) (Kurrek et al., 2020; Soral et al., 2018). At the same time, existing approaches do not take into account that c"
2021.acl-long.210,W19-3509,0,0.054317,"Missing"
2021.acl-long.210,S19-2010,0,0.0352511,"ents with scores from −0.5 to 0.5. We call this subset (of 5151 comments), the reduced-range dataset. We discuss the models’ performance on this dataset in the next section. HateBERT HateBERT (Caselli et al., 2020b) is a version of BERT pretrained for abusive language detection in English. HateBERT was trained on RAL-E, a large dataset of English language Reddit comments from communities banned for being offensive or hateful. HateBERT has been shown to outperform the general purpose BERT model on the offensive language detection task when finetuned on popular datasets such as OffensEval 2019 (Zampieri et al., 2019), AbusEval (Caselli et al., 2020a), and HatEval (Basile et al., 2019). We fine-tuned HateBERT on Ruddit and its variants. The experimental setup for this model is the same as that described for the BERT model. 6.2 6 Computational Modeling In this section, we present benchmark experiments on Ruddit and its variants by implementing some commonly used model architectures. The task of the models was to predict the offensiveness score of a given comment. We performed 5-fold crossvalidation for each of the models.6 6.1 Models Bidirectional LSTM We fed pre-trained 300 dimensional GloVe word embedding"
2021.acl-long.210,W16-5618,0,0.237183,"deration. The representation of the offensive class in a dataset is often boosted using different strategies. The most common strategy used is key-word based sampling. This results in datasets that are rich in explicit offensive language (language that is unambiguous in its potential to be offensive, such as those using slurs or swear words (Waseem et al., 2017)) but lack cases of implicit offensive language (language with its true offensive nature obscured due to lack of unambiguous swear words, usage of sarcasm or offensive analogies, and others (Waseem et al., 2017; Wiegand et al., 2021)) (Waseem, 2016; Wiegand et al., 2019). Further, Wiegand et al. (2019) show that key-word based sampling often results in spurious correlations (e.g., sports-related expressions such as announcer and sport occur very frequently in offensive tweets). 2700 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2700–2717 August 1–6, 2021. ©2021 Association for Computational Linguistics Lastly, existing datasets consider offensive comments in isolation from the wider conversation of which they are a"
2021.acl-long.210,W17-3012,0,0.0837158,"comments can be offensive to a different degree. Knowing the degree of offensiveness of a comment has practical implications, when taking action against inappropriate behaviour online, as it allows for a more fine-grained analysis and prioritization in moderation. The representation of the offensive class in a dataset is often boosted using different strategies. The most common strategy used is key-word based sampling. This results in datasets that are rich in explicit offensive language (language that is unambiguous in its potential to be offensive, such as those using slurs or swear words (Waseem et al., 2017)) but lack cases of implicit offensive language (language with its true offensive nature obscured due to lack of unambiguous swear words, usage of sarcasm or offensive analogies, and others (Waseem et al., 2017; Wiegand et al., 2021)) (Waseem, 2016; Wiegand et al., 2019). Further, Wiegand et al. (2019) show that key-word based sampling often results in spurious correlations (e.g., sports-related expressions such as announcer and sport occur very frequently in offensive tweets). 2700 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th Internation"
2021.acl-long.210,N16-2013,0,0.0362638,"n, 1996; Asaadi et al., 2019), and improves annotation consistency (Kiritchenko and Mohammad, 2017). However, instead of needing to annotate N instances, one now needs to annotate N 2 instance pairs—which can be prohibitive. Thus, we annotate our dataset using an efficient form of comparative annotation called Best–Worst Scaling (BWS) (Louviere, 1991; Louviere et al., 2015; Kiritchenko and Mohammad, 2016, 2017). Surveys by Schmidt and Wiegand (2017); Fortuna and Nunes (2018); Mishra et al. (2019); Vidgen and Derczynski (2020) discuss various existing datasets and their compositions in detail. Waseem and Hovy (2016); Davidson et al. (2017); Founta et al. (2018) created datasets based on Twitter data. Due to prevalence of the non-offensive class in naturallyoccurring data (Waseem, 2016; Founta et al., 2018), the authors devised techniques to boost the presence of the offensive class in the dataset. Waseem and Hovy (2016) used terms frequently occurring in offensive tweets, while Davidson et al. (2017) used a list of hate-related terms to extract offensive tweets from the Twitter search API. Park et al. (2018), Wiegand et al. (2019), and Davidson et al. (2019) show that the Waseem and Hovy (2016) dataset e"
2021.acl-long.210,2021.eacl-main.27,0,0.372393,"and prioritization in moderation. The representation of the offensive class in a dataset is often boosted using different strategies. The most common strategy used is key-word based sampling. This results in datasets that are rich in explicit offensive language (language that is unambiguous in its potential to be offensive, such as those using slurs or swear words (Waseem et al., 2017)) but lack cases of implicit offensive language (language with its true offensive nature obscured due to lack of unambiguous swear words, usage of sarcasm or offensive analogies, and others (Waseem et al., 2017; Wiegand et al., 2021)) (Waseem, 2016; Wiegand et al., 2019). Further, Wiegand et al. (2019) show that key-word based sampling often results in spurious correlations (e.g., sports-related expressions such as announcer and sport occur very frequently in offensive tweets). 2700 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2700–2717 August 1–6, 2021. ©2021 Association for Computational Linguistics Lastly, existing datasets consider offensive comments in isolation from the wider conversation of w"
2021.acl-long.210,N19-1060,0,0.22765,"representation of the offensive class in a dataset is often boosted using different strategies. The most common strategy used is key-word based sampling. This results in datasets that are rich in explicit offensive language (language that is unambiguous in its potential to be offensive, such as those using slurs or swear words (Waseem et al., 2017)) but lack cases of implicit offensive language (language with its true offensive nature obscured due to lack of unambiguous swear words, usage of sarcasm or offensive analogies, and others (Waseem et al., 2017; Wiegand et al., 2021)) (Waseem, 2016; Wiegand et al., 2019). Further, Wiegand et al. (2019) show that key-word based sampling often results in spurious correlations (e.g., sports-related expressions such as announcer and sport occur very frequently in offensive tweets). 2700 Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2700–2717 August 1–6, 2021. ©2021 Association for Computational Linguistics Lastly, existing datasets consider offensive comments in isolation from the wider conversation of which they are a part. Offensive langua"
2021.acl-long.409,P17-2057,0,0.0172721,"ation with slow and fast weights for one-shot learning. An external memory was introduced to enhance recurrent neural network in Munkhdalai et al. (2019), in which memory is conceptualized as an adaptable function and implemented as a deep neural network. Semantic memory has recently been introduced by Zhen et al. (2020) for few-shot learning to enhance prototypical representations of objects, where memory recall is cast as a variational inference problem. In NLP, Tang et al. (2016) use content and location-based neural attention over external memory for aspect-level sentiment classification. Das et al. (2017) use key-value memory for question answering on knowledge bases. Mem2Seq (Madotto et al., 2018) is an architecture for task-oriented dialog that combines attention-based memory with pointer networks (Vinyals et al., 2015). Geng et al. (2020) propose Dynamic Memory Induction Networks for few-shot text classification, which utilizes dynamic routing (Sabour et al., 2017) over a static memory module. Episodic memory has been used in lifelong learning on language tasks, as a means to perform experience replay (d’Autume et al., 2019; Han et al., 2020; Holla et al., 2020b). 3 Task and dataset We trea"
2021.acl-long.409,2020.acl-main.102,0,0.0179296,"neural network. Semantic memory has recently been introduced by Zhen et al. (2020) for few-shot learning to enhance prototypical representations of objects, where memory recall is cast as a variational inference problem. In NLP, Tang et al. (2016) use content and location-based neural attention over external memory for aspect-level sentiment classification. Das et al. (2017) use key-value memory for question answering on knowledge bases. Mem2Seq (Madotto et al., 2018) is an architecture for task-oriented dialog that combines attention-based memory with pointer networks (Vinyals et al., 2015). Geng et al. (2020) propose Dynamic Memory Induction Networks for few-shot text classification, which utilizes dynamic routing (Sabour et al., 2017) over a static memory module. Episodic memory has been used in lifelong learning on language tasks, as a means to perform experience replay (d’Autume et al., 2019; Han et al., 2020; Holla et al., 2020b). 3 Task and dataset We treat WSD as a word-level classification problem where ambiguous words are to be classified into their senses given the context. In traditional WSD, the goal is to generalize to new contexts of word-sense pairs. Specifically, the test set consis"
2021.acl-long.409,D19-1403,0,0.0141818,"similarity with the support set examples. Model-based methods (Santoro et al., 2016b; Munkhdalai and Yu, 2017a) employ external memory and make predictions based on examples retrieved from the memory. Optimization-based methods (Ravi and Larochelle, 2017; Finn et al., 2017; Nichol et al., 2018; Antoniou et al., 2019) directly optimize for generalizability over tasks in their training objective. Meta-learning has been applied to a range of tasks in NLP, including machine translation (Gu et al., 2018), relation classification (Obamuyide and Vlachos, 2019), text classification (Yu et al., 2018; Geng et al., 2019), hypernymy detection (Yu et al., 2020), and dialog generation (Qian and Yu, 2019). It has also been used to learn across distinct NLP tasks (Dou et al., 2019; Bansal et al., 2019) as well as across different languages (Nooralahzadeh et al., 2020; Li et al., 2020). Bansal et al. (2020) show that meta-learning during self-supervised pretraining of language models leads to improved fewshot generalization on downstream tasks. Holla et al. (2020a) propose a framework for few-shot word sense disambiguation, where the goal is to disambiguate new words during metatesting. Meta-training consists of ep"
2021.acl-long.409,D19-1533,0,0.0686568,"in extremely data scarce (e.g. one-shot) scenarios and produces meaning prototypes that capture similar senses of distinct words. 1 Introduction Disambiguating word meaning in context is at the heart of any natural language understanding task or application, whether it is performed explicitly or implicitly. Traditionally, word sense disambiguation (WSD) has been defined as the task of explicitly labeling word usages in context with sense labels from a pre-defined sense inventory. The majority of approaches to WSD rely on (semi-)supervised learning (Yuan et al., 2016; Raganato et al., 2017a,b; Hadiwinoto et al., 2019; Huang et al., 2019; Scarlini et al., 2020; Bevilacqua and Navigli, 2020) and make use of training corpora manually annotated for word senses. Typically, these methods require a fairly large number of annotated training examples per word. This problem is exacerbated by the dramatic imbalances in sense frequencies, which further increase the need for annotation to capture a diversity of senses and to obtain sufficient training data for rare senses. This motivated recent research on few-shot WSD, where the objective of the model is to learn new, previously unseen word senses from only a small n"
2021.acl-long.409,2020.acl-main.573,0,0.0398929,"emory for aspect-level sentiment classification. Das et al. (2017) use key-value memory for question answering on knowledge bases. Mem2Seq (Madotto et al., 2018) is an architecture for task-oriented dialog that combines attention-based memory with pointer networks (Vinyals et al., 2015). Geng et al. (2020) propose Dynamic Memory Induction Networks for few-shot text classification, which utilizes dynamic routing (Sabour et al., 2017) over a static memory module. Episodic memory has been used in lifelong learning on language tasks, as a means to perform experience replay (d’Autume et al., 2019; Han et al., 2020; Holla et al., 2020b). 3 Task and dataset We treat WSD as a word-level classification problem where ambiguous words are to be classified into their senses given the context. In traditional WSD, the goal is to generalize to new contexts of word-sense pairs. Specifically, the test set consists of word-sense pairs that were seen during train5256 ing. On the other hand, in few-shot WSD, the goal is to generalize to new words and senses altogether. The meta-testing phase involves further adapting the models (on the small support set) to new words that were not seen during training and evaluates th"
2021.acl-long.409,P18-1136,0,0.0687506,"Missing"
2021.acl-long.409,K16-1006,0,0.0409825,"Missing"
2021.acl-long.409,H94-1046,0,0.619136,"_WSD 2014; Moro et al., 2014) rely on lexical resources such as WordNet (Miller et al., 1990) and do not require a corpus manually annotated with word senses. Alternatively, supervised learning methods treat WSD as a word-level classification task for ambiguous words and rely on sense-annotated corpora for training. Early supervised learning approaches trained classifiers with hand-crafted features (Navigli, 2009; Zhong and Ng, 2010) and word embeddings (Rothe and Sch¨utze, 2015; Iacobacci et al., 2016) as input. Raganato et al. (2017a) proposed a benchmark for WSD based on the SemCor corpus (Miller et al., 1994) and found that supervised methods outperform the knowledgebased ones. Neural models for supervised WSD include LSTM-based (Hochreiter and Schmidhuber, 1997) classifiers (K˚ageb¨ack and Salomonsson, 2016; Melamud et al., 2016; Raganato et al., 2017b), nearest neighbour classifier with ELMo embeddings (Peters et al., 2018), as well as a classifier based on pretrained BERT representations (Hadiwinoto et al., 2019). Recently, hybrid approaches incorporating information from lexical resources into neural architectures have gained traction. GlossBERT (Huang et al., 2019) fine-tunes BERT with WordNe"
2021.acl-long.409,Q14-1019,0,0.0972637,"Missing"
2021.acl-long.409,2020.emnlp-main.368,0,0.0260395,"Larochelle, 2017; Finn et al., 2017; Nichol et al., 2018; Antoniou et al., 2019) directly optimize for generalizability over tasks in their training objective. Meta-learning has been applied to a range of tasks in NLP, including machine translation (Gu et al., 2018), relation classification (Obamuyide and Vlachos, 2019), text classification (Yu et al., 2018; Geng et al., 2019), hypernymy detection (Yu et al., 2020), and dialog generation (Qian and Yu, 2019). It has also been used to learn across distinct NLP tasks (Dou et al., 2019; Bansal et al., 2019) as well as across different languages (Nooralahzadeh et al., 2020; Li et al., 2020). Bansal et al. (2020) show that meta-learning during self-supervised pretraining of language models leads to improved fewshot generalization on downstream tasks. Holla et al. (2020a) propose a framework for few-shot word sense disambiguation, where the goal is to disambiguate new words during metatesting. Meta-training consists of episodes formed from multiple words whereas meta-testing has one episode corresponding to each of the test words. They show that prototype-based methods – prototypical networks (Snell et al., 2017) and first-order ProtoMAML (Triantafillou et al., 2"
2021.acl-long.409,P19-1589,0,0.0239449,"a kernel function and make predictions on the query set based on the similarity with the support set examples. Model-based methods (Santoro et al., 2016b; Munkhdalai and Yu, 2017a) employ external memory and make predictions based on examples retrieved from the memory. Optimization-based methods (Ravi and Larochelle, 2017; Finn et al., 2017; Nichol et al., 2018; Antoniou et al., 2019) directly optimize for generalizability over tasks in their training objective. Meta-learning has been applied to a range of tasks in NLP, including machine translation (Gu et al., 2018), relation classification (Obamuyide and Vlachos, 2019), text classification (Yu et al., 2018; Geng et al., 2019), hypernymy detection (Yu et al., 2020), and dialog generation (Qian and Yu, 2019). It has also been used to learn across distinct NLP tasks (Dou et al., 2019; Bansal et al., 2019) as well as across different languages (Nooralahzadeh et al., 2020; Li et al., 2020). Bansal et al. (2020) show that meta-learning during self-supervised pretraining of language models leads to improved fewshot generalization on downstream tasks. Holla et al. (2020a) propose a framework for few-shot word sense disambiguation, where the goal is to disambiguate"
2021.acl-long.409,D14-1162,0,0.0861766,"of senses in the corpus, including class imbalance, providing a realistic evaluation setting. 4 Methods 4.1 Model architectures We experiment with the same model architectures as Holla et al. (2020a). The model fθ , with parameters θ, takes words xi as input and produces a perword representation vector fθ (xi ) for i = 1, ..., L where L is the length of the sentence. Sense predictions are only made for ambiguous words using the corresponding word representation. GloVe+GRU Single-layer bi-directional GRU (Cho et al., 2014) network followed by a single linear layer, that takes GloVe embeddings (Pennington et al., 2014) as input. GloVe embeddings capture all senses of a word. We thus evaluate a model’s ability to disambiguate from senseagnostic input. ELMo+MLP A multi-layer perception (MLP) network that receives contextualized ELMo embeddings (Peters et al., 2018) as input. Their contextualised nature makes ELMo embeddings better suited to capture meaning variation than the static ones. Since ELMo is not fine-tuned, this model has the lowest number of learnable parameters. BERT Pretrained BERTBASE (Devlin et al., 2019) model followed by a linear layer, fully finetuned on the task. BERT underlies state-of-the"
2021.acl-long.409,N18-1202,0,0.16096,"supervised learning approaches trained classifiers with hand-crafted features (Navigli, 2009; Zhong and Ng, 2010) and word embeddings (Rothe and Sch¨utze, 2015; Iacobacci et al., 2016) as input. Raganato et al. (2017a) proposed a benchmark for WSD based on the SemCor corpus (Miller et al., 1994) and found that supervised methods outperform the knowledgebased ones. Neural models for supervised WSD include LSTM-based (Hochreiter and Schmidhuber, 1997) classifiers (K˚ageb¨ack and Salomonsson, 2016; Melamud et al., 2016; Raganato et al., 2017b), nearest neighbour classifier with ELMo embeddings (Peters et al., 2018), as well as a classifier based on pretrained BERT representations (Hadiwinoto et al., 2019). Recently, hybrid approaches incorporating information from lexical resources into neural architectures have gained traction. GlossBERT (Huang et al., 2019) fine-tunes BERT with WordNet sense definitions as additional input. EWISE (Kumar et al., 2019) learns continuous sense embeddings as targets, aided by dictionary definitions and lexical knowledge bases. Scarlini et al. (2020) present a semi-supervised approach for obtaining sense embeddings with the aid of a lexical knowledge base, enabling WSD wit"
2021.acl-long.409,P19-1253,0,0.0237049,"16b; Munkhdalai and Yu, 2017a) employ external memory and make predictions based on examples retrieved from the memory. Optimization-based methods (Ravi and Larochelle, 2017; Finn et al., 2017; Nichol et al., 2018; Antoniou et al., 2019) directly optimize for generalizability over tasks in their training objective. Meta-learning has been applied to a range of tasks in NLP, including machine translation (Gu et al., 2018), relation classification (Obamuyide and Vlachos, 2019), text classification (Yu et al., 2018; Geng et al., 2019), hypernymy detection (Yu et al., 2020), and dialog generation (Qian and Yu, 2019). It has also been used to learn across distinct NLP tasks (Dou et al., 2019; Bansal et al., 2019) as well as across different languages (Nooralahzadeh et al., 2020; Li et al., 2020). Bansal et al. (2020) show that meta-learning during self-supervised pretraining of language models leads to improved fewshot generalization on downstream tasks. Holla et al. (2020a) propose a framework for few-shot word sense disambiguation, where the goal is to disambiguate new words during metatesting. Meta-training consists of episodes formed from multiple words whereas meta-testing has one episode correspondi"
2021.acl-long.409,E17-1010,0,0.0180382,"pports effective learning in extremely data scarce (e.g. one-shot) scenarios and produces meaning prototypes that capture similar senses of distinct words. 1 Introduction Disambiguating word meaning in context is at the heart of any natural language understanding task or application, whether it is performed explicitly or implicitly. Traditionally, word sense disambiguation (WSD) has been defined as the task of explicitly labeling word usages in context with sense labels from a pre-defined sense inventory. The majority of approaches to WSD rely on (semi-)supervised learning (Yuan et al., 2016; Raganato et al., 2017a,b; Hadiwinoto et al., 2019; Huang et al., 2019; Scarlini et al., 2020; Bevilacqua and Navigli, 2020) and make use of training corpora manually annotated for word senses. Typically, these methods require a fairly large number of annotated training examples per word. This problem is exacerbated by the dramatic imbalances in sense frequencies, which further increase the need for annotation to capture a diversity of senses and to obtain sufficient training data for rare senses. This motivated recent research on few-shot WSD, where the objective of the model is to learn new, previously unseen wor"
2021.acl-long.409,D17-1120,0,0.0204239,"pports effective learning in extremely data scarce (e.g. one-shot) scenarios and produces meaning prototypes that capture similar senses of distinct words. 1 Introduction Disambiguating word meaning in context is at the heart of any natural language understanding task or application, whether it is performed explicitly or implicitly. Traditionally, word sense disambiguation (WSD) has been defined as the task of explicitly labeling word usages in context with sense labels from a pre-defined sense inventory. The majority of approaches to WSD rely on (semi-)supervised learning (Yuan et al., 2016; Raganato et al., 2017a,b; Hadiwinoto et al., 2019; Huang et al., 2019; Scarlini et al., 2020; Bevilacqua and Navigli, 2020) and make use of training corpora manually annotated for word senses. Typically, these methods require a fairly large number of annotated training examples per word. This problem is exacerbated by the dramatic imbalances in sense frequencies, which further increase the need for annotation to capture a diversity of senses and to obtain sufficient training data for rare senses. This motivated recent research on few-shot WSD, where the objective of the model is to learn new, previously unseen wor"
2021.acl-long.409,P15-1173,0,0.0709827,"Missing"
2021.acl-long.409,2020.emnlp-main.285,0,0.0287903,"arios and produces meaning prototypes that capture similar senses of distinct words. 1 Introduction Disambiguating word meaning in context is at the heart of any natural language understanding task or application, whether it is performed explicitly or implicitly. Traditionally, word sense disambiguation (WSD) has been defined as the task of explicitly labeling word usages in context with sense labels from a pre-defined sense inventory. The majority of approaches to WSD rely on (semi-)supervised learning (Yuan et al., 2016; Raganato et al., 2017a,b; Hadiwinoto et al., 2019; Huang et al., 2019; Scarlini et al., 2020; Bevilacqua and Navigli, 2020) and make use of training corpora manually annotated for word senses. Typically, these methods require a fairly large number of annotated training examples per word. This problem is exacerbated by the dramatic imbalances in sense frequencies, which further increase the need for annotation to capture a diversity of senses and to obtain sufficient training data for rare senses. This motivated recent research on few-shot WSD, where the objective of the model is to learn new, previously unseen word senses from only a small number of examples. Holla et al. (2020a) pre"
2021.acl-long.409,D16-1021,0,0.0148701,"cently used access module for writes. Meta Network (Munkhdalai and Yu, 2017b) uses two memory modules: a key-value memory in combination with slow and fast weights for one-shot learning. An external memory was introduced to enhance recurrent neural network in Munkhdalai et al. (2019), in which memory is conceptualized as an adaptable function and implemented as a deep neural network. Semantic memory has recently been introduced by Zhen et al. (2020) for few-shot learning to enhance prototypical representations of objects, where memory recall is cast as a variational inference problem. In NLP, Tang et al. (2016) use content and location-based neural attention over external memory for aspect-level sentiment classification. Das et al. (2017) use key-value memory for question answering on knowledge bases. Mem2Seq (Madotto et al., 2018) is an architecture for task-oriented dialog that combines attention-based memory with pointer networks (Vinyals et al., 2015). Geng et al. (2020) propose Dynamic Memory Induction Networks for few-shot text classification, which utilizes dynamic routing (Sabour et al., 2017) over a static memory module. Episodic memory has been used in lifelong learning on language tasks,"
2021.acl-long.409,2020.acl-main.336,0,0.0313332,". Model-based methods (Santoro et al., 2016b; Munkhdalai and Yu, 2017a) employ external memory and make predictions based on examples retrieved from the memory. Optimization-based methods (Ravi and Larochelle, 2017; Finn et al., 2017; Nichol et al., 2018; Antoniou et al., 2019) directly optimize for generalizability over tasks in their training objective. Meta-learning has been applied to a range of tasks in NLP, including machine translation (Gu et al., 2018), relation classification (Obamuyide and Vlachos, 2019), text classification (Yu et al., 2018; Geng et al., 2019), hypernymy detection (Yu et al., 2020), and dialog generation (Qian and Yu, 2019). It has also been used to learn across distinct NLP tasks (Dou et al., 2019; Bansal et al., 2019) as well as across different languages (Nooralahzadeh et al., 2020; Li et al., 2020). Bansal et al. (2020) show that meta-learning during self-supervised pretraining of language models leads to improved fewshot generalization on downstream tasks. Holla et al. (2020a) propose a framework for few-shot word sense disambiguation, where the goal is to disambiguate new words during metatesting. Meta-training consists of episodes formed from multiple words where"
2021.acl-long.409,N18-1109,0,0.02193,"set based on the similarity with the support set examples. Model-based methods (Santoro et al., 2016b; Munkhdalai and Yu, 2017a) employ external memory and make predictions based on examples retrieved from the memory. Optimization-based methods (Ravi and Larochelle, 2017; Finn et al., 2017; Nichol et al., 2018; Antoniou et al., 2019) directly optimize for generalizability over tasks in their training objective. Meta-learning has been applied to a range of tasks in NLP, including machine translation (Gu et al., 2018), relation classification (Obamuyide and Vlachos, 2019), text classification (Yu et al., 2018; Geng et al., 2019), hypernymy detection (Yu et al., 2020), and dialog generation (Qian and Yu, 2019). It has also been used to learn across distinct NLP tasks (Dou et al., 2019; Bansal et al., 2019) as well as across different languages (Nooralahzadeh et al., 2020; Li et al., 2020). Bansal et al. (2020) show that meta-learning during self-supervised pretraining of language models leads to improved fewshot generalization on downstream tasks. Holla et al. (2020a) propose a framework for few-shot word sense disambiguation, where the goal is to disambiguate new words during metatesting. Meta-tra"
2021.acl-long.409,C16-1130,0,0.107912,"in few-shot WSD, supports effective learning in extremely data scarce (e.g. one-shot) scenarios and produces meaning prototypes that capture similar senses of distinct words. 1 Introduction Disambiguating word meaning in context is at the heart of any natural language understanding task or application, whether it is performed explicitly or implicitly. Traditionally, word sense disambiguation (WSD) has been defined as the task of explicitly labeling word usages in context with sense labels from a pre-defined sense inventory. The majority of approaches to WSD rely on (semi-)supervised learning (Yuan et al., 2016; Raganato et al., 2017a,b; Hadiwinoto et al., 2019; Huang et al., 2019; Scarlini et al., 2020; Bevilacqua and Navigli, 2020) and make use of training corpora manually annotated for word senses. Typically, these methods require a fairly large number of annotated training examples per word. This problem is exacerbated by the dramatic imbalances in sense frequencies, which further increase the need for annotation to capture a diversity of senses and to obtain sufficient training data for rare senses. This motivated recent research on few-shot WSD, where the objective of the model is to learn new"
2021.eacl-main.165,2020.acl-main.372,0,0.14555,"ch comment and possible answer, indicating the probability with which each option could be the gold label. Finally, Media Unit Quality score (UQS) describes the quality of annotation for each comment. We removed annotations by workers with a WQS lower than 0.1 and those with high disagreement after manually checking their responses, and recomputed the metrics. We removed comments left with only one annotator and comments with a UQS lower than 0.2. This resulted in 4278 comments with 5+ annotators, and 2564 comments with less, which constitute our final dataset. Following the same procedure as Demszky et al. (2020), we computed inter-rater correlation (Delgado and Tibau Alberdi, 2019) by using Spearman correlation. We took the average of the correlation between each annotator’s answers and all other annotators’ average answers that labelled the same items. We obtain a range between 0.5 and 0.13 per emotion. The lowest agreement is for Relief (0.13), in line with Demszky et al. (2020), where the lowest value for correlation agreement being Of course Dems are stealing the elections. They are playing by a different set of rules - being ruthless and violent. Dems take no prisoners and show no mercy to their"
2021.eacl-main.165,2020.findings-emnlp.402,1,0.651679,"iation on the Convote dataset. Li and Goldwasser (2019) detected the political perspective of news articles using a long short-term memory (LSTM) and a graph convolutional network (GCN) on user data from Twitter. Other research investigated the framing effect in news articles, which is a mechanism that promotes a particular perspective (Entman, 1993). Card et al. (2015) presented the Media Frame Corpus, which explores policy framing within news articles. Ji and Smith (2017) developed a discourse-level Tree-RNN model to identify the framing in each article, by using this corpus dataset. Huguet Cabot et al. (2020) addressed this 1922 task by leveraging emotion and metaphor detection in an MTL setup. Other works have also explored sentence-level framing (Johnson et al., 2017; Hartmann et al., 2019). Hate speech detection is not limited to the analysis of political discourses. However, it is related to exposing populist rhetoric in digital communication (Meret and Pajnik, 2017; Estelles and Castellv´ı Mata, 2020). Several NLP approaches (Mishra et al., 2020), as well as recent shared tasks (Zampieri et al., 2019, 2020) have been proposed to tackle this widespread problem. While political bias and framing"
2021.eacl-main.165,P14-1105,0,0.218331,"f multi-task learning models that leverage and demonstrate the importance of emotion and group identification as auxiliary tasks. 1 Introduction Political discourse is essential in shaping public opinion. The tasks related to modelling political rhetoric have thus been gaining interest in the natural language processing (NLP) community. Many of them focused on automatically placing a piece of text on the left-to-right political spectrum. For instance, much research has been devoted to detecting bias in news sources (Kiesel et al., 2019) and predicting the political affiliation of politicians (Iyyer et al., 2014) and social media users, more generally (Conover et al., 2011; Pennacchiotti and Popescu, 2011; Preot¸iuc-Pietro et al., 2017). Other works conducted a more fine-grained analysis, identifying the framing of political issues in news articles (Card et al., 2015; Ji and Smith, 2017). Recently, the field has also turned attention towards modelling the spread of political information in social media, such as detecting fake news or political perspectives (Li and Goldwasser, 2019; Chandra et al., 2020; Nguyen et al., 2020). Populism has taken the spotlight in political communication in recent years."
2021.eacl-main.165,P17-1092,0,0.0854151,"terest in the natural language processing (NLP) community. Many of them focused on automatically placing a piece of text on the left-to-right political spectrum. For instance, much research has been devoted to detecting bias in news sources (Kiesel et al., 2019) and predicting the political affiliation of politicians (Iyyer et al., 2014) and social media users, more generally (Conover et al., 2011; Pennacchiotti and Popescu, 2011; Preot¸iuc-Pietro et al., 2017). Other works conducted a more fine-grained analysis, identifying the framing of political issues in news articles (Card et al., 2015; Ji and Smith, 2017). Recently, the field has also turned attention towards modelling the spread of political information in social media, such as detecting fake news or political perspectives (Li and Goldwasser, 2019; Chandra et al., 2020; Nguyen et al., 2020). Populism has taken the spotlight in political communication in recent years. Various countries around the globe have experienced a surge of populist rhetoric (Inglehart and Norris, 2016) in both the public and political space. Despite this, approaches to computational modelling of populist discourse have so far been scarce. Due to the flexible nature of p"
2021.eacl-main.165,P17-1069,0,0.0605559,"Missing"
2021.eacl-main.165,P19-1247,0,0.115231,"been devoted to detecting bias in news sources (Kiesel et al., 2019) and predicting the political affiliation of politicians (Iyyer et al., 2014) and social media users, more generally (Conover et al., 2011; Pennacchiotti and Popescu, 2011; Preot¸iuc-Pietro et al., 2017). Other works conducted a more fine-grained analysis, identifying the framing of political issues in news articles (Card et al., 2015; Ji and Smith, 2017). Recently, the field has also turned attention towards modelling the spread of political information in social media, such as detecting fake news or political perspectives (Li and Goldwasser, 2019; Chandra et al., 2020; Nguyen et al., 2020). Populism has taken the spotlight in political communication in recent years. Various countries around the globe have experienced a surge of populist rhetoric (Inglehart and Norris, 2016) in both the public and political space. Despite this, approaches to computational modelling of populist discourse have so far been scarce. Due to the flexible nature of populism, annotating populist rhetoric in text is challenging, and the existing research in this area has relied on small-scale analysis by experts (Hawkins et al., 2019). In this paper, we present"
2021.eacl-main.165,P17-1068,0,0.0361255,"Missing"
2021.eacl-main.168,Q19-1038,0,0.13224,"in valid forever. With the aim of extending the global reach of Natural Language Processing (NLP) technology, much recent research has focused on the development of multilingual models and methods to efficiently transfer knowledge across languages. 1 https://www.ethnologue.com/statistics Among these advances are multilingual word vectors which aim to give word-translation pairs a similar encoding in some embedding space (Mikolov et al., 2013a; Lample et al., 2017). There has also been a lot of work on multilingual sentence and word encoders that either explicitly utilizes corpora of bi-texts (Artetxe and Schwenk, 2019; Lample and Conneau, 2019) or jointly trains language models for many languages in one encoder (Devlin et al., 2018; Conneau et al., 2019). Although great progress has been made in cross-lingual transfer learning, these methods either do not close the gap with performance in a single high-resource language (Artetxe and Schwenk, 2019; Conneau et al., 2019), e.g., because of cultural differences in languages which are not accounted for, or are impractically expensive (Lai et al., 2019). Meta-learning, or learning to learn (Schmidhuber, 1987; Bengio et al., 1990; Thrun and Pratt, 1998), is a lea"
2021.eacl-main.168,T75-2034,0,0.578202,"Missing"
2021.eacl-main.168,D19-1431,0,0.0281442,"setting and show superior performance for parameter initialization over selfsupervised pretraining and multi-task learning. Their method is an adaptation of MAML where a combination of a text-encoder, BERT (Devlin et al., 2018), is coupled with a parameter generator that learns to generate task-dependent initializations of the classification head such that metalearning can be performed across tasks with disjoint label spaces. Obamuyide and Vlachos (2019b) apply meta-learning on the task of relation extraction; Obamuyide and Vlachos (2019a) apply lifelong meta-learning for relation extraction; Chen et al. (2019) apply meta-learning for few-shot learning on missing link prediction in knowledge graphs. Multilingual Gu et al. (2018) apply metalearning to Neural Machine Translation (NMT) and show its advantage over strong baselines such as cross-lingual transfer learning. By viewing each language pair as a task, the authors apply MAML to obtain competitive NMT systems with as little as 600 parallel sentences. To our best knowledge, the only application of meta-learning for cross-lingual few-shot learning is the one by Nooralahzadeh et al. (2020). The authors study the application of X-MAML, a MAML-based"
2021.eacl-main.168,P19-4007,0,0.0480021,"Missing"
2021.eacl-main.168,D18-1269,0,0.0217194,"rediction in knowledge graphs. Multilingual Gu et al. (2018) apply metalearning to Neural Machine Translation (NMT) and show its advantage over strong baselines such as cross-lingual transfer learning. By viewing each language pair as a task, the authors apply MAML to obtain competitive NMT systems with as little as 600 parallel sentences. To our best knowledge, the only application of meta-learning for cross-lingual few-shot learning is the one by Nooralahzadeh et al. (2020). The authors study the application of X-MAML, a MAML-based variant, to crosslingual Natural Language Inference (XNLI) (Conneau et al., 2018) and Multilingual Question An1969 swering (MLQA) (Lewis et al., 2019) in both a cross-domain and cross-language setting. XMAML works by pretraining some model M on a high-resource task h to obtain initial model parameters θmono . Consecutively, a set L of one or more auxiliary languages is taken, and MAML is applied to achieve fast adaptation of θmono for l ∈ L. In their experiments, the authors use either one or two auxiliary languages and evaluate their method in both a zero- and few-shot setting. It should be noted that, in the few-shot setting, the full development set (2.5k instances) is"
2021.eacl-main.168,D19-1572,0,0.040088,"Missing"
2021.eacl-main.168,2020.emnlp-main.368,0,0.0612069,"ize to unseen tasks at test time. Meta-learning has recently emerged as a promising technique for few-shot learning for a wide array of tasks (Finn et al., 2017; Koch et al., 2015; Ravi and Larochelle, 2017) including NLP (Dou et al., 2019; Gu et al., 2018). To our best knowledge, no previous work has been done in investigating meta-learning as a framework for multilingual and cross-lingual few-shot learning. We propose such a framework and demonstrate its effectiveness in document classification tasks. The only current study on meta-learning for cross-lingual few-shot learning is the one by (Nooralahzadeh et al., 2020), focusing on natural language inference and multilingual question answering. In their work, the authors focus on applying meta-learning to learn to adapt a monolingually trained classi1966 Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics, pages 1966–1976 April 19 - 23, 2021. ©2021 Association for Computational Linguistics Algorithm 1 Meta-training procedure. Require: p(D): distribution over tasks. Require: α, β: step size hyper-parameters Initialize θ while not done do Sample batch of tasks {Dl } = {(S l , Ql )} ∼ p(D) for all (S l ,"
2021.eacl-main.168,D18-1398,0,0.118082,"pensive (Lai et al., 2019). Meta-learning, or learning to learn (Schmidhuber, 1987; Bengio et al., 1990; Thrun and Pratt, 1998), is a learning paradigm which focuses on the quick adaption of a learner to new tasks. The idea is that by training a learner to adapt quickly and from a few examples on a diverse set of training tasks, the learner can also generalize to unseen tasks at test time. Meta-learning has recently emerged as a promising technique for few-shot learning for a wide array of tasks (Finn et al., 2017; Koch et al., 2015; Ravi and Larochelle, 2017) including NLP (Dou et al., 2019; Gu et al., 2018). To our best knowledge, no previous work has been done in investigating meta-learning as a framework for multilingual and cross-lingual few-shot learning. We propose such a framework and demonstrate its effectiveness in document classification tasks. The only current study on meta-learning for cross-lingual few-shot learning is the one by (Nooralahzadeh et al., 2020), focusing on natural language inference and multilingual question answering. In their work, the authors focus on applying meta-learning to learn to adapt a monolingually trained classi1966 Proceedings of the 16th Conference of th"
2021.eacl-main.168,W19-4326,0,0.0271246,"rge amounts of unlabeled data in the target lanMeta-learning in NLP Monolingual Bansal et al. (2019) apply metalearning to a wide range of NLP tasks within a monolingual setting and show superior performance for parameter initialization over selfsupervised pretraining and multi-task learning. Their method is an adaptation of MAML where a combination of a text-encoder, BERT (Devlin et al., 2018), is coupled with a parameter generator that learns to generate task-dependent initializations of the classification head such that metalearning can be performed across tasks with disjoint label spaces. Obamuyide and Vlachos (2019b) apply meta-learning on the task of relation extraction; Obamuyide and Vlachos (2019a) apply lifelong meta-learning for relation extraction; Chen et al. (2019) apply meta-learning for few-shot learning on missing link prediction in knowledge graphs. Multilingual Gu et al. (2018) apply metalearning to Neural Machine Translation (NMT) and show its advantage over strong baselines such as cross-lingual transfer learning. By viewing each language pair as a task, the authors apply MAML to obtain competitive NMT systems with as little as 600 parallel sentences. To our best knowledge, the only appli"
2021.eacl-main.168,P19-1589,0,0.025715,"rge amounts of unlabeled data in the target lanMeta-learning in NLP Monolingual Bansal et al. (2019) apply metalearning to a wide range of NLP tasks within a monolingual setting and show superior performance for parameter initialization over selfsupervised pretraining and multi-task learning. Their method is an adaptation of MAML where a combination of a text-encoder, BERT (Devlin et al., 2018), is coupled with a parameter generator that learns to generate task-dependent initializations of the classification head such that metalearning can be performed across tasks with disjoint label spaces. Obamuyide and Vlachos (2019b) apply meta-learning on the task of relation extraction; Obamuyide and Vlachos (2019a) apply lifelong meta-learning for relation extraction; Chen et al. (2019) apply meta-learning for few-shot learning on missing link prediction in knowledge graphs. Multilingual Gu et al. (2018) apply metalearning to Neural Machine Translation (NMT) and show its advantage over strong baselines such as cross-lingual transfer learning. By viewing each language pair as a task, the authors apply MAML to obtain competitive NMT systems with as little as 600 parallel sentences. To our best knowledge, the only appli"
2021.eacl-main.168,P10-1114,0,0.29343,"ll entries of both x ˆ and µc have values between -1 and 1. The pre-softmax activation for class c is computed as x ˆT µc . Due to the size of the vectors and the scale of their respective entries, this in-product can yield a wide range of values, which in turn results in relatively high loss values, making the inner-loop optimization unstable. 3 3.1 Related work Multilingual NLP guage and domain using the MLM objective. With their method, the authors obtain state-of-the-art results on the MLDoc document classification task (Schwenk and Li, 2018) and the Amazon Sentiment Polarity Review task (Prettenhofer and Stein, 2010). A downside, however, is the high computational cost involved. For every language and domain combination: 1) a machine translation system has to be inferred on a large amount of unlabeled samples; 2) the UDA method needs to be applied to obtain a teacher model to generate pseudo-labels on the unlabeled in-domain data; 3) a language model must be finetuned, which involves forwards and backwards computation of a softmax function over a large output space (e.g., 50k tokens for mBERT and 250k tokens for XLM-RoBERTa). The final classifier is then obtained by 4) training the finetuned language mode"
2021.eacl-main.168,L18-1560,0,0.0802293,"space. Since the final activation function is the tanh activation, all entries of both x ˆ and µc have values between -1 and 1. The pre-softmax activation for class c is computed as x ˆT µc . Due to the size of the vectors and the scale of their respective entries, this in-product can yield a wide range of values, which in turn results in relatively high loss values, making the inner-loop optimization unstable. 3 3.1 Related work Multilingual NLP guage and domain using the MLM objective. With their method, the authors obtain state-of-the-art results on the MLDoc document classification task (Schwenk and Li, 2018) and the Amazon Sentiment Polarity Review task (Prettenhofer and Stein, 2010). A downside, however, is the high computational cost involved. For every language and domain combination: 1) a machine translation system has to be inferred on a large amount of unlabeled samples; 2) the UDA method needs to be applied to obtain a teacher model to generate pseudo-labels on the unlabeled in-domain data; 3) a language model must be finetuned, which involves forwards and backwards computation of a softmax function over a large output space (e.g., 50k tokens for mBERT and 250k tokens for XLM-RoBERTa). The"
2021.emnlp-main.111,2020.acl-main.703,0,0.0243409,"Missing"
2021.emnlp-main.111,2020.emnlp-main.154,0,0.200873,"spite these studies, it has remained difficult to Studies focused on measuring stereotypes in predefine what constitutes “bias”, with most work fo- trained models have thus far taken supervised apcusing on “gender bias” (Manela et al., 2021; Sun proaches, relying on human knowledge of common et al., 2019) or “racial bias” (Davidson et al., 2019; stereotypes about (a smaller set of) social groups 1477 Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 1477–1491 c November 7–11, 2021. 2021 Association for Computational Linguistics (Nadeem et al., 2020; Nangia et al., 2020). This, however, bears a few disadvantages: (1) due to the implicit nature of stereotypes, human defined examples can only expose a subset of popular stereotypes, but will omit those that human annotators are unaware of (e.g. models might encode stereotypes that are not as prevalent in the real world); (2) stereotypes vary considerably across cultures (Dong et al., 2019), meaning that the stereotypes tested for will heavily depend on the annotator’s cultural frame of reference; (3) stereotypes constantly evolve, making supervised methods difficult to maintain in practice. Therefore, similar to"
2021.emnlp-main.111,P19-1163,0,0.0290308,"rt from training data, contribute to what models learn about groups. Thus, carefully controlling training content can not fully eliminate the need to analyze models w.r.t. the stereotypes that they might propagate. 6 New Yorker 0.7 0.6 0.5 0.4 BERT-B 0.3 new_yorker-100 0.2 new_yorker-50 new_yorker-25 0.1 new_yorker-10 0.0 0 25 50 75 100 125 150 175 200 k 1.0 Stereotype shifts during fine-tuning Many debiasing studies intervene at the data level e.g., by augmenting imbalanced datasets (Manela et al., 2021; Webster et al., 2018; Dixon et al., 2018; Zhao et al., 2018) or reducing annotator bias (Sap et al., 2019). These methods are, however, dependent on the dataset, domain, or task, making new mitigation needed when transferring to a new setup (Jin et al., 2020). This raises the question of how emotion profiles and stereotypes are established through language use, and how they might shift due to new linguistic experience at the fine-tuning stage. We take U.S. news sources from across the political spectrum as a case study, as media outlets are known to be biased (Baron, 2006). By revealing stereotypes learned as an effect of fine-tuning on a specific source, we can trace the newly learned stereotypes"
2021.emnlp-main.111,P19-1159,0,0.033249,"Missing"
2021.emnlp-main.111,Q18-1042,0,0.0238203,"ciations are established and provides strong evidence that other modelling decisions, apart from training data, contribute to what models learn about groups. Thus, carefully controlling training content can not fully eliminate the need to analyze models w.r.t. the stereotypes that they might propagate. 6 New Yorker 0.7 0.6 0.5 0.4 BERT-B 0.3 new_yorker-100 0.2 new_yorker-50 new_yorker-25 0.1 new_yorker-10 0.0 0 25 50 75 100 125 150 175 200 k 1.0 Stereotype shifts during fine-tuning Many debiasing studies intervene at the data level e.g., by augmenting imbalanced datasets (Manela et al., 2021; Webster et al., 2018; Dixon et al., 2018; Zhao et al., 2018) or reducing annotator bias (Sap et al., 2019). These methods are, however, dependent on the dataset, domain, or task, making new mitigation needed when transferring to a new setup (Jin et al., 2020). This raises the question of how emotion profiles and stereotypes are established through language use, and how they might shift due to new linguistic experience at the fine-tuning stage. We take U.S. news sources from across the political spectrum as a case study, as media outlets are known to be biased (Baron, 2006). By revealing stereotypes learned as an"
2021.emnlp-main.111,2020.lrec-1.494,0,0.0110725,"is in addition trained on data from CommonCrawl News (Nagel, 2016), OpenWebTextCorpus (Gokaslan and Cohen, 2019) and STORIES (Trinh and Le, 2018); BART, a denoising autoencoder (Lewis et al., 2020) that while using a different architecture and pretraining strategy from RoBERTa, uses the same training data. Moreover, we use mBERT, that apart from being trained on Wikipedia in multiple languages, is identical to BERT. We use the uncased version that supports 102 languages. Similarly, XLM-R is the multilingual variant of RoBERTa (Conneau et al., 2020) that is trained on cleaned CommonCrawl data (Wenzek et al., 2020) and supports 100 languages. We include both versions of a model (i.e. Base and Large) if available. Appendix A provides more details on the models. Table 2: Ranking:‘why are old people so bad with’. Prior Post 1. memory 1. memory 2. math 2. alcohol 3. money 3. technology 4. children 4. dates Stereotype elicitation method For each sample in our dataset we feed the model the template sentence and replace [ATTR] with the [MASK] token. We then retrieve the top k = 200 model predictions for the MASK token, and test how many of the stereotypes found by the search engines are also encoded in the LMs"
2021.findings-emnlp.287,C18-1135,0,0.0262775,"online platform who may have posted a com- for some specific demographic (Waseem et al., ment that is to be classified as abusive or not. The 2017). Information about how a term is being community of this user comprises other users and used by other members of a user’s community, contents that they interact with on the online plat- e.g., in abusive contexts or otherwise, can help 3375 decipher linguistic variations that come up from time to time. In fact, it is usually the users with strong ties who are responsible for popularizing language variations as well as for spreading hate speech (Del Tredici and Fernández, 2018; Ribeiro et al., 2018). Therefore, having user and community information alongside linguistic features helps capture linguistic variations and their diffusion. Prevailing stereotypes. Previous research has shown that prevailing stereotypes often form the basis and justification of abuse. For example, many twitter accounts were open about their anger and hatred for Muslims in the wake of the Rochdale scandal that involved several British–Asian men getting convicted for child grooming (Awan, 2014). Stereotypes are not only explicit but implicit too (Hinton, 2017), which often show up as implici"
2021.findings-emnlp.287,D19-1477,0,0.0471978,"Missing"
2021.findings-emnlp.287,P19-1357,0,0.0632795,"unity information to enhance the detection of abusive language in comments should be preferred over those that leverage the information to classify users or communities themselves as abusive. This is because the latter can lead to unwarranted penalties, e.g., a platform may prohibit a user from engaging even in restorative conversations simply because of their past abusive behavior. • Elucidate stereotypes(s) underlying the abuse (or the absence thereof), be they explicit or be they in the form of implicit associations. Explainability is an important concept within abusive language detection. Jurgens et al. (2019) noted in their work that explainable ML techniques can promote restorative and procedural justice by surfacing the norms that have been violated and clarifying how they have been violated. That said, there has been limited discussion of the issue within the domain of abusive language detection. In this section, we first formalize the properties that an explainable detection method should aim to exhibit in order to thoroughly substantiate its decisions. We then describe how user and community information play an important role in the realization of each of the properties. Finally, we discuss w"
2021.findings-emnlp.287,gao-huang-2017-detecting,0,0.0180757,"ly, we address the topic of explainability in abusive language detection, proposing properties that an explainable detection method should aim to exhibit. We describe how user and community information can facilitate the realization of these properties and discuss the effective operationalization of explainability in view of the properties. form. In other words, community refers to the neighborhood of the user in the social graph of the platform. Conversations online are inherently contextual. Consequently, abuse on online platforms can only be effectively interpreted within a larger context (Gao and Huang, 2017) rather than in isolation. This is especially true for implicit or generalized abuse, which are harder to interpret than explicit abuse for humans and machines alike. Information of the user who posted the comment, or of the surrounding community including the targets of the comment, offers insights into several aspects of the context that are otherwise not accessible through the linguistic content of the comment alone. Here, information may refer to demographic traits like age or gender, knowledge about linguistic behavior, location details, etc. Below we categorize and discuss the aspects of"
2021.findings-emnlp.287,W16-3638,0,0.0594089,"Missing"
2021.findings-emnlp.287,C18-1093,1,0.908393,"6) constructed a dataset of 1, 900 tweets from 19 different twitter accounts with time of publication, language, and geo-position for each tweet taken from the profile of the user who created it. Waseem and Hovy (2016) released a list of 16, 907 tweet IDs along with their corresponding annotations, labeling each tweet as racist, sexist or neither. For each tweet, the dataset contains the gender of the user who created it along with their geo-location. Since Twitter APIs allow researchers to access information about a user given a tweet ID, the dataset of Waseem and Hovy (2016) was expanded by Mishra et al. (2018a) to include the follower-following information amongst users who created the tweets contained in the dataset. Ribeiro et al. (2018) collected a dataset of 100, 386 Twitter users along with up to 200 tweets for each of them. They created a graph of the users based on retweet relationship amongst them and annotated 4, 972 users as hateful or benign based on their tweets. Founta el al. (2018a) released a dataset of 80k tweet IDs with labels as normal, spam, hateful, Demographic characteristics. Previous research and abusive. Augmenting this dataset, Tredici et al. has demonstrated that some dem"
2021.findings-emnlp.287,N19-1221,1,0.861533,"Missing"
2021.findings-emnlp.287,W17-3006,0,0.0418918,"Missing"
2021.findings-emnlp.287,D17-1117,0,0.0385288,"Missing"
2021.findings-emnlp.287,W17-4209,0,0.0457469,"Missing"
2021.findings-emnlp.287,N18-2019,0,0.0354432,"Missing"
2021.findings-emnlp.287,2020.acl-main.394,1,0.848277,"Missing"
2021.findings-emnlp.287,N16-3020,0,0.0274,"ividual (i.e., directed tant for multiple reasons. Firstly, if the detection abuse) or a group (i.e., generalized abuse). method exhibits all the four properties of explain3380 ability, then the designers can easily gain insights into the factors that contributed to the decision made by the method given a comment. This can allow the designers to recognize when the method may be overly relying on a specific factor, e.g., the demographic traits. In the case of social feature engineering and user embeddings based methods, operationalization of explainability via feature attribution such as LIME (Ribeiro et al., 2016) and Integrated Gradients (Sundararajan et al., 2017) can be effective in offering such insights. For social graph based methods that employ graph neural networks, attribution techniques like GNNExplainer (Ying et al., 2019) can be used instead. The second reason why explainability is important for the designers is because it can allow them to optimize the method by removing inputs that do not contribute significantly. Here again, explainability via feature attribution can be effective. Lastly, explainability is also important for the designers to understand how their method would perform in c"
2021.findings-emnlp.287,2020.acl-main.486,0,0.13297,", as this can easily lead to scenarios of faulty generalizations where comments from a particular gender or race are always labeled abusive/benign. Moreover, relying solely on personal traits of users also comes with the risk that such information may not always be present or may not be accurate even when present (Drouin et al., 2016). On the other hand, more complex inductive biases learned from data, as in the case of social graph based methods, provide a safer and more reliable generalization from personal behaviors of users or communities to population level trends. specific demographics (Sap et al., 2020), hence diminishing the power of the methods to generalize. In fact, this bias is not only a problem for methods we discussed, but for any NLP method in general. When it comes to methods that incorporate user or community information specifically, there are two other biases that must be kept in mind when constructing datasets; we refer to them as comment distribution bias and label distribution bias. Comment distribution bias occurs when the majority of comments in the dataset come from a small number of unique users. Such datasets allow the methods to simply overfit to the linguistic or socia"
2021.findings-emnlp.287,W17-1101,0,0.0485991,"Missing"
2021.findings-emnlp.287,W18-5110,0,0.0123207,"eated a graph of the users based on retweet relationship amongst them and annotated 4, 972 users as hateful or benign based on their tweets. Founta el al. (2018a) released a dataset of 80k tweet IDs with labels as normal, spam, hateful, Demographic characteristics. Previous research and abusive. Augmenting this dataset, Tredici et al. has demonstrated that some demographic settings (2019) created a graph of users whose tweets are are inherently more abusive than others. For ex- included based on retweet relationships amongst ample, a study by Stephens et al. (2013) mapped the them. Similarly, Unsvåg and Gambäck (2018) the locations of hateful tweets across the United augmented the datasets of Fortuna (2017) and Ross States to uncover the regions where people use hate et al. (2016) which respective contain 5, 668 Porspeech the most. They observed that areas with low tuguese tweets and 13, 766 German tweets by using diversity use more derogatory slurs against racial Twitter APIs to get user information such as gender, and sexual minorities. A separate line of work by number of followers, number of status updates, etc. Savicki et al. (1996) concluded that male-only dis- Deviating from Twitter, Pavlopoulos et"
2021.findings-emnlp.287,W12-2103,0,0.137391,"Missing"
2021.findings-emnlp.287,W17-3012,0,0.0169412,"t to discuss racism and sexism. we review and analyze the state of the art methThe definitions for different types of abuse tend ods that leverage user or community information to enhance the understanding and detecto be overlapping and ambiguous. However, retion of abusive language. We then explore the gardless of the specific type, we define abuse as ethical challenges of incorporating user and any expression that is meant to denigrate or offend community information, laying out consideraa particular person or group. Taking a coursetions to guide future research. Finally, we adgrained view, Waseem et al. (2017) classify abuse dress the topic of explainability in abusive laninto broad categories based on explicitness and diguage detection, proposing properties that an rectness. Explicit abuse comes in the form of expleexplainable method should aim to exhibit. We describe how user and community information tives, derogatory words or threats, while implicit can facilitate the realization of these properties abuse has a more subtle appearance characterized and discuss the effective operationalization of by the presence of ambiguous terms and figures explainability in view of the properties. of speech su"
2021.findings-emnlp.287,N16-2013,0,0.144808,"and community In this section, we first recap the datasets in the domain of abusive language detection that contain user or community information alongside comments. We then go on to discuss the methods that have been applied to them. 3.1 Datasets Twitter has been the most common online platform from which researchers have sourced datasets with user and community information. Galán-García et al. (2016) constructed a dataset of 1, 900 tweets from 19 different twitter accounts with time of publication, language, and geo-position for each tweet taken from the profile of the user who created it. Waseem and Hovy (2016) released a list of 16, 907 tweet IDs along with their corresponding annotations, labeling each tweet as racist, sexist or neither. For each tweet, the dataset contains the gender of the user who created it along with their geo-location. Since Twitter APIs allow researchers to access information about a user given a tweet ID, the dataset of Waseem and Hovy (2016) was expanded by Mishra et al. (2018a) to include the follower-following information amongst users who created the tweets contained in the dataset. Ribeiro et al. (2018) collected a dataset of 100, 386 Twitter users along with up to 20"
2021.findings-emnlp.287,N19-1060,0,0.015137,"eralize. In fact, this bias is not only a problem for methods we discussed, but for any NLP method in general. When it comes to methods that incorporate user or community information specifically, there are two other biases that must be kept in mind when constructing datasets; we refer to them as comment distribution bias and label distribution bias. Comment distribution bias occurs when the majority of comments in the dataset come from a small number of unique users. Such datasets allow the methods to simply overfit to the linguistic or social behaviors and community roles of specific users (Wiegand et al., 2019). Label distribution bias occurs when only the abusive comments of a user are included in the dataset. Abuse is a relatively infrequent phenomenon, even at an individual level (Waseem and Hovy, 2016; Wulczyn et al., 2017). Only getting abusive comments of a user can make the methods simply associate the identity of the user to abusiveness when including user information. Moreover, datasets with this bias can also make phenomena like homophily appear overly effective in the detection of abuse by sampling only abusive comments from users who are close in the social network. Observability. The ob"
2021.findings-emnlp.287,N18-1095,0,0.0327049,"Missing"
2021.naacl-main.372,W18-0916,0,0.03028,"Missing"
2021.naacl-main.372,D14-1162,0,0.0838825,"Missing"
2021.naacl-main.372,N18-1202,0,0.0692779,"Missing"
2021.naacl-main.372,W18-0908,0,0.0339768,"Missing"
2021.naacl-main.372,D17-1162,1,0.856948,"Missing"
2021.naacl-main.372,J15-4002,1,0.831824,"ars, as well cording to corpus-linguistic research (Steen et al., as the datasets they used. We provide an analysis 2010b; Shutova, 2011). This makes accurate in- of these models from the linguistic and cognitive terpretation of metaphorical language essential for perspective and propose some future directions for many NLP tasks and applications. modelling social aspects of metaphor use (e.g. the A systematic and comprehensive survey of intent behind metaphor use, extended metaphor and metaphor processing systems was published five metaphoric framing), as well as the underaddressed years ago (Shutova, 2015). Since then, automated tasks of metaphor interpretation and generation. Fimetaphor processing has shifted focus towards neu- nally, we discuss how elements of metaphor proral approaches and there has been much activity in cessing can be integrated in the real-world applicathe area, including two shared tasks (Leong et al., tions, such as machine translation, opinion mining, 2018, 2020). The development has kept pace with dialogue modelling, and modelling argumentative the development of deep learning techniques, and discourse (e.g., political discourse). 4673 Proceedings of the 2021 Conferenc"
2021.naacl-main.372,N16-1020,1,0.929469,"d a supervised similarity network, which learns to calculate weighted coCategorial features Metaphor processing is concerned with how concepts are organised in the brain/mind, and is closely related to categorisation. It therefore makes sense to employ categorial features for metaphor identification. Tekiro˘glu 1 et al. (2015) tested the use of sensorial categories http://www.wjh.harvard.edu/~inquirer/ (the five human senses) for identifying AN synaes- homecat.htm 4677 Study Input Input features Architecture Dataset Performance (default F) Tekiro˘glu et al. (2015) AN Random Forest TSV A 0.890 Shutova et al. (2016) Bulat et al. (2017) Rei et al. (2017) AN/VN AN AN/VN 0.79/0.75 0.77 0.811/0.742 S S S Chunk skip-gram; CNN H SVM Supervised similarity H Cosine sim. H BiLSTM RoBERTa BiLSTM TSV/MOH TSV TSV/MOH Mao et al. (2018) Gao et al. (2018) Gong et al. (2020) Bizzoni and Ghanimifard (2018) Wu et al. (2018) Token, Sensorial, WordClass, Conc, Image H Token, VisualEmb H AttributeEmb H Token, AttributeEmb (AN-TSV) H Token Token (GloveElmo) Token Token MOH VUA Verbs VUA Verbs VUA All POS 0.75 0.697 0.771 0.621 VUA All POS 0.651 VUA All POS VUA All POS VUA All POS 0.715 0.718 0.730 BiLSTM + Glove Transformers"
2021.naacl-main.372,W14-2306,0,0.0396734,"and-crafted databases2 , represented as adjectives. It then selects the property that contributes the most to the semantic relatedness of the target-source pair. The resultant pair of target-domain word and property is taken as interpretation of the copula metaphor. The metaphor LOVE IS TIDE, for instance, was interpreted as The love is unstoppable. Su et al. Metaphor and emotion Motivated by the close relationship between metaphor use and the expression of emotions, Gargett and Barnden (2015) successfully used emotion features, amongst others, for metaphor identification. Kozareva (2013) and Strzalkowski et al. (2014) model the affect carried by metaphors in texts in different languages. Most recently, Dankers et al. (2019) employed multitask learning (MTL) to train models of metaphor identification and emotion prediction jointly. Models were based on BiLSTM and BERT, with a range 2 of MTL architectures. The emotion prediction For instance, the adjective taxonomy provided by Sardontask used the Valence-Arousal-Dominance model icus: http://bonnat.ucd.ie/sardonicus/. 4678 (2017) thus took into account the emergent meaning of metaphors. Note that the literal explanations they obtained can be regarded as expla"
2021.naacl-main.372,2020.figlang-1.4,0,0.0858469,"ingh, 2018). The Di-LSTM Contrast system (Swarnkar and Singh, 2018) encodes the left- and right-side context of a target word using forward and backward LSTMs. The classification is based on a concatenation of the target-word vector and its difference with the encoded context. Mao et al. (2019) combined GloVe and BiLSTM hidden states for sequence labelling, which outperformed the best model in the 2018 VUA All POS track. Most neural models treat metaphor identification as a sequence labelling task, outputing a sequence of metaphoricity labels for a sequence of input words Wu et al. (2018) and Su et al. (2020) employed (usually a sentence) (Bizzoni and Ghanimifard, separate encoding of local and long-range context. 2018; Chen et al., 2020; Dankers et al., 2019; Gao Wu et al. (2018) used a convolutional neural netet al., 2018; Gong et al., 2020; Mao et al., 2019; work (CNN) and a BiLSTM to extract local and 4676 sentence context respectively. Su et al. (2020) used separate Transformer encoder layers to encode global and local text features for each word. The two systems achieved the best performance on the VUA All POS tracks in their respective shared tasks (Leong et al., 2018, 2020). Modelling meta"
2021.naacl-main.372,W18-0914,0,0.0278202,"Missing"
2021.naacl-main.372,W15-1404,0,0.0545149,"Missing"
2021.naacl-main.372,P14-1024,0,0.0185337,"s deliberate metaphor use as the intentional introduction of a topic shift or perspective change to the discourse. Deliberate metaphor use is associated with online metaphor processing, the construction of conceptual metaphors during text comprehension (Steen, 2017). Examples of deliberate metaphors include conventional metaphors instantiated as copula metaphors and all novel metaphors. A systematic procedure for the identification of potential deliberate metaphors has also been proposed (Reijnierse et al., 2018). 3 2.4 Metaphor use in communication Metaphor datasets Metaphoricity annotations Tsvetkov et al. (2014) released a dataset (henceforth: TSV) conThe linguistic expression of emotional states often employs metaphor (Fainsilber and Ortony, 1987; sisting of an equal number (884) of metaphorical Fussell and Moss, 1998). As emotion is an ab- and non-metaphorical adjective-noun (AN) phrases collected from the web. The phrases were stated to stract domain, it goes with CMT and embodied cognition that we employ more concrete domains, be verified by multiple annotators, but the criteria such as physical or bodily experience, to concep- for metaphor annotation were not provided. tualise it. Moreover, sinc"
2021.naacl-main.372,D11-1063,0,0.10401,"Missing"
2021.naacl-main.372,W18-0913,0,0.0352296,"Missing"
C10-1113,andersen-etal-2008-bnc,0,0.0285456,"re a verb is used metaphorically. The seed phrases include e.g. stir excitement, reﬂect enthusiasm, accelerate change, grasp theory, cast doubt, suppress memory, throw remark (verb - direct object constructions) and campaign surged, factor shaped [..], tension mounted, ideology embraces, changes operated, approach focuses, example illustrates (subject verb constructions). 2.2 Corpus The search space for metaphor identiﬁcation was the British National Corpus (BNC) that was parsed using the RASP parser of Briscoe et al. (2006). We used the grammatical relations output of RASP for BNC created by Andersen et al. (2008). The system searched the corpus for the source and target domain vocabulary within a particular grammatical relation (verb-object or verbsubject). 3 Method Starting from a small seed set of metaphorical expressions, the system implicitly captures the associations that underly their production and comprehension. It generalizes over these associations by means of unsupervised verb and noun clustering. The obtained clusters then represent potential source and target concepts between which metaphorical associations hold. The knowledge of such associations is then used to annotate metaphoricity in"
C10-1113,D08-1007,0,0.110236,"ing to collect source domain vocabulary, which in turn allows us to harvest a large number of new metaphorical expressions. 3.2 Verb and Noun Clustering Since Levin (1993) published her classiﬁcation, there have been a number of attempts to automatically classify verbs into semantic classes using supervised and unsupervised approaches (Lin, 1998; Brew and Schulte im Walde, 2002; Korhonen et al., 2003; Schulte im Walde, 2006; Joanis et al., 2008; Sun and Korhonen, 2009). Similar methods were also applied to acquisition of noun classes from corpus data (Rooth et al., 1999; Pantel and Lin, 2002; Bergsma et al., 2008). We adopt a recent verb clustering approach of Sun and Korhonen (2009), who used rich syntactic and semantic features extracted using a shallow parser and a clustering method suitable for the resulting high dimensional feature space. When Sun and Korhonen evaluated their approach on 204 verbs from 17 Levin classes, they obtained 80.4 F-measure (which is high in particular for an unsupervised approach). We apply this approach to a much larger set of 1610 verbs: all the verb forms appearing in VerbNet (Kipper et al., 2006) with the exception of highly infrequent ones. In addition, we adapt the"
C10-1113,E06-1042,0,0.674756,"Missing"
C10-1113,W02-1016,0,0.271372,"Missing"
C10-1113,P06-4020,0,0.0557129,"that are single-word 1003 metaphors representing verb-subject and verbobject relations, where a verb is used metaphorically. The seed phrases include e.g. stir excitement, reﬂect enthusiasm, accelerate change, grasp theory, cast doubt, suppress memory, throw remark (verb - direct object constructions) and campaign surged, factor shaped [..], tension mounted, ideology embraces, changes operated, approach focuses, example illustrates (subject verb constructions). 2.2 Corpus The search space for metaphor identiﬁcation was the British National Corpus (BNC) that was parsed using the RASP parser of Briscoe et al. (2006). We used the grammatical relations output of RASP for BNC created by Andersen et al. (2008). The system searched the corpus for the source and target domain vocabulary within a particular grammatical relation (verb-object or verbsubject). 3 Method Starting from a small seed set of metaphorical expressions, the system implicitly captures the associations that underly their production and comprehension. It generalizes over these associations by means of unsupervised verb and noun clustering. The obtained clusters then represent potential source and target concepts between which metaphorical ass"
C10-1113,P06-2012,0,0.0560219,"for noun clustering. We employed all the argument heads and verb lemmas appearing in the subject, direct object and indirect object relations in the RASP-parsed BNC. The feature vectors were ﬁrst constructed from the corpus counts, and subsequently normalized by the sum of the feature values before applying clustering. 3.2.2 Clustering Algorithm We use spectral clustering (SPEC) for both verbs and nouns. This technique has proved to be effective in previous verb clustering works (Brew and Schulte im Walde, 2002; Sun and Korhonen, 2009) and in related NLP tasks involving high dimensional data (Chen et al., 2006). We use the MNCut algorithm for SPEC which has a wide applicability and a clear probabilistic interpretation (Meila and Shi, 2001). The task is to group a given set of words W = {wn }N n=1 into a disjoint partition of K classes. SPEC takes a similarity matrix as input. We construct it using the Jensen-Shannon divergence (JSD) as a measure. The JSD between two feature vectors w and w is djsd (w, w ) = 12 D(w||m) + 1  2 D(w ||m) where D is the Kullback-Leibler divergence, and m is the average of the w and w . The similarity matrix S is constructed where Sij = exp(−djsd (w, w )). In SPEC, t"
C10-1113,J91-1003,0,0.92557,"mputational Linguistics (Coling 2010), pages 1002–1010, Beijing, August 2010 According to Wilks, metaphors represent a violation of selectional restrictions in a given context. Consider the following example. (7) Diana and Charles did not succeed in mending their marriage. (8) The wheels of Stalin’s regime were well oiled and already turning. (5) My car drinks gasoline. (Wilks, 1978) The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may as well indicate metaphorical use of drink. This approach was automated by Fass (1991) in his met* system. However, Fass himself indicated a problem with the method: it detects any kind of non-literalness or anomaly in language (metaphors, metonymies and others), i.e., it overgenerates with respect to metaphor. The techniques met* uses to differentiate between those are mainly based on hand-coded knowledge, which implies a number of limitations. In a similar manner manually created knowledge in the form of WordNet (Fellbaum, 1998) is employed by the system of Krishnakumaran and Zhu (2007), which essentially differentiates between highly lexicalized metaphors included in WordNet"
C10-1113,P98-2127,0,0.277006,"pus. 3.1 Clustering Motivation Abstract concepts that are associated with the same source domain are often related to each other on an intuitive and rather structural level, but their meanings, however, are not necessarily synonymous or even semantically close. The results of previous research on corpus-based lexical semantics suggest that the linguistic environment in which a lexical item occurs can shed light on its meaning. A number of works have shown that it is possible to automatically induce semantic word classes from corpus data via clustering of contextual cues (Pereira et al., 1993; Lin, 1998; Schulte im Walde, 2006). The consensus is that the lexical items exposing similar behavior in a large body of text most likely have the same meaning. However, the concepts of marriage and political regime, that are also observed in similar lexico-syntactic environments, albeit having quite distinct meanings are likewise assigned by such methods to the same cluster. In contrast to concrete concepts, such as tea, water, coffee, beer, drink, liquid, that are clustered together due to meaning similarity, abstract concepts tend to be clustered together by association with the same source domain."
C10-1113,C88-1081,0,0.776717,"oes not employ any hand-crafted knowledge, other than the initial seed set, but, in contrast, captures metaphoricity by means of verb and noun clustering. Being the ﬁrst to employ unsupervised methods for metaphor identiﬁcation, our system operates with the precision of 0.79. 1 Introduction Besides enriching our thought and communication with novel imagery, the phenomenon of metaphor also plays a crucial structural role in our use of language. Metaphors arise when one concept is viewed in terms of the properties of the other. Below are some examples of metaphor. (1) How can I kill a process? (Martin, 1988) (2) Inﬂation has eaten up all my savings. (Lakoff and Johnson, 1980) (3) He shot down all of my arguments. (Lakoff and Johnson, 1980) (4) And then my heart with pleasure ﬁlls, And dances with the daffodils.1 In metaphorical expressions seemingly unrelated features of one concept are associated with another concept. In the computer science metaphor 1 “I wandered lonely as a cloud”, William Wordsworth, 1804. in (1) the computational process is viewed as something alive and, therefore, its forced termination is associated with the act of killing. Lakoff and Johnson (1980) explain metaphor as a s"
C10-1113,W06-3506,0,0.684132,"oblem with the method: it detects any kind of non-literalness or anomaly in language (metaphors, metonymies and others), i.e., it overgenerates with respect to metaphor. The techniques met* uses to differentiate between those are mainly based on hand-coded knowledge, which implies a number of limitations. In a similar manner manually created knowledge in the form of WordNet (Fellbaum, 1998) is employed by the system of Krishnakumaran and Zhu (2007), which essentially differentiates between highly lexicalized metaphors included in WordNet, and novel metaphorical senses. Alternative approaches (Gedigan et al., 2006) search for metaphors of a speciﬁc domain deﬁned a priori (e.g. MOTION metaphors) in a speciﬁc type of discourse (e.g. Wall Street Journal). In contrast, the scope of our experiments is the whole of the British National Corpus (BNC) (Burnard, 2007) and the domain of the expressions we identify is unrestricted. However, our technique is also distinguished from the systems of Fass (1991) and Krishnakumaran and Zhu (2007) in that it does not rely on any hand-crafted knowledge, but rather captures metaphoricity in an unsupervised way by means of verb and noun clustering. The motivation behind the"
C10-1113,P93-1024,0,0.220261,"oricity in a large corpus. 3.1 Clustering Motivation Abstract concepts that are associated with the same source domain are often related to each other on an intuitive and rather structural level, but their meanings, however, are not necessarily synonymous or even semantically close. The results of previous research on corpus-based lexical semantics suggest that the linguistic environment in which a lexical item occurs can shed light on its meaning. A number of works have shown that it is possible to automatically induce semantic word classes from corpus data via clustering of contextual cues (Pereira et al., 1993; Lin, 1998; Schulte im Walde, 2006). The consensus is that the lexical items exposing similar behavior in a large body of text most likely have the same meaning. However, the concepts of marriage and political regime, that are also observed in similar lexico-syntactic environments, albeit having quite distinct meanings are likewise assigned by such methods to the same cluster. In contrast to concrete concepts, such as tea, water, coffee, beer, drink, liquid, that are clustered together due to meaning similarity, abstract concepts tend to be clustered together by association with the same sour"
C10-1113,J98-1002,0,0.0506764,"Missing"
C10-1113,kingsbury-palmer-2002-treebank,0,0.181232,"Missing"
C10-1113,P07-1115,1,0.543632,"ur verb dataset is a subset of VerbNet compiled as follows. For all the verbs in VerbNet we 1004 extracted their occurrences (up to 10,000) from the raw corpus data collected originally by Korhonen et al. (2006) for construction of VALEX lexicon. Only the verbs found in this data more than 150 times were included in the experiment. For verb clustering, we adopted the best performing features of Sun and Korhonen (2009): automatically acquired verb subcategorization frames (SCFs) parameterized by their selectional preferences (SPs). We obtained these features using the SCF acquisition system of Preiss et al. (2007). The system tags and parses corpus data using the RASP parser and extracts SCFs from the resulting GRs using a rule-based classiﬁer which identiﬁes 168 SCF types for English verbs. It produces a lexical entry for each verb and SCF combination occurring in corpus data. We obtained SP s by clustering argument heads appearing in the subject and object slots of verbs in the resulting lexicon. Our noun dataset consists of 2000 most frequent nouns in the BNC. Following previous works on semantic noun classiﬁcation (Pantel and Lin, 2002; Bergsma et al., 2008), we used GRs as features for noun cluste"
C10-1113,P03-1009,1,0.889759,"Missing"
C10-1113,W97-0209,0,0.336393,"eported. Some of the clusters obtained as a result of applying the algorithm to our noun and verb datasets are demonstrated in Figures 1 and 2 respectively. The noun clusters represent target concepts that we expect to be associated with the same source concept (some suggested source concepts are given in Figure 1, although the system only captures those implicitly). 2 An eigenvector v is piecewise constant with respect to I if v(i) = v(j)∀i, j ∈ Ik and k ∈ 1, 2...K 1005 measure proposed by Resnik (1993) and successfully applied to a number of tasks in NLP including word sense disambiguation (Resnik, 1997). Resnik models selectional preference of a verb in probabilistic terms as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position regardless of the identity of the predicate. He quantiﬁes this difference using the relative entropy (or KullbackLeibler distance), deﬁning the selectional preference strength (SPS) as follows. Source: MECHANISM Target Cluster: consensus relation tradition partnership resistance foundation alliance friendship contact reserve unity link peace bond myth identity h"
C10-1113,korhonen-etal-2006-large,1,0.909373,"-word 1003 metaphors representing verb-subject and verbobject relations, where a verb is used metaphorically. The seed phrases include e.g. stir excitement, reﬂect enthusiasm, accelerate change, grasp theory, cast doubt, suppress memory, throw remark (verb - direct object constructions) and campaign surged, factor shaped [..], tension mounted, ideology embraces, changes operated, approach focuses, example illustrates (subject verb constructions). 2.2 Corpus The search space for metaphor identiﬁcation was the British National Corpus (BNC) that was parsed using the RASP parser of Briscoe et al. (2006). We used the grammatical relations output of RASP for BNC created by Andersen et al. (2008). The system searched the corpus for the source and target domain vocabulary within a particular grammatical relation (verb-object or verbsubject). 3 Method Starting from a small seed set of metaphorical expressions, the system implicitly captures the associations that underly their production and comprehension. It generalizes over these associations by means of unsupervised verb and noun clustering. The obtained clusters then represent potential source and target concepts between which metaphorical ass"
C10-1113,P99-1014,0,0.0176068,"ain. We then use unsupervised verb clustering to collect source domain vocabulary, which in turn allows us to harvest a large number of new metaphorical expressions. 3.2 Verb and Noun Clustering Since Levin (1993) published her classiﬁcation, there have been a number of attempts to automatically classify verbs into semantic classes using supervised and unsupervised approaches (Lin, 1998; Brew and Schulte im Walde, 2002; Korhonen et al., 2003; Schulte im Walde, 2006; Joanis et al., 2008; Sun and Korhonen, 2009). Similar methods were also applied to acquisition of noun classes from corpus data (Rooth et al., 1999; Pantel and Lin, 2002; Bergsma et al., 2008). We adopt a recent verb clustering approach of Sun and Korhonen (2009), who used rich syntactic and semantic features extracted using a shallow parser and a clustering method suitable for the resulting high dimensional feature space. When Sun and Korhonen evaluated their approach on 204 verbs from 17 Levin classes, they obtained 80.4 F-measure (which is high in particular for an unsupervised approach). We apply this approach to a much larger set of 1610 verbs: all the verb forms appearing in VerbNet (Kipper et al., 2006) with the exception of highl"
C10-1113,W07-0103,0,0.502837,"subject is an anomaly, which may as well indicate metaphorical use of drink. This approach was automated by Fass (1991) in his met* system. However, Fass himself indicated a problem with the method: it detects any kind of non-literalness or anomaly in language (metaphors, metonymies and others), i.e., it overgenerates with respect to metaphor. The techniques met* uses to differentiate between those are mainly based on hand-coded knowledge, which implies a number of limitations. In a similar manner manually created knowledge in the form of WordNet (Fellbaum, 1998) is employed by the system of Krishnakumaran and Zhu (2007), which essentially differentiates between highly lexicalized metaphors included in WordNet, and novel metaphorical senses. Alternative approaches (Gedigan et al., 2006) search for metaphors of a speciﬁc domain deﬁned a priori (e.g. MOTION metaphors) in a speciﬁc type of discourse (e.g. Wall Street Journal). In contrast, the scope of our experiments is the whole of the British National Corpus (BNC) (Burnard, 2007) and the domain of the expressions we identify is unrestricted. However, our technique is also distinguished from the systems of Fass (1991) and Krishnakumaran and Zhu (2007) in that"
C10-1113,J06-2001,0,0.0832386,"Missing"
C10-1113,shutova-teufel-2010-metaphor,1,0.359272,"e source and the target. The metaphor in (3) exempliﬁes a mapping of a concept of argument to that of war. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to talk about arguments using the war terminology, thus giving rise to a number of metaphors. Characteristic to all areas of human activity (from poetic to ordinary to scientiﬁc) and, thus, to all types of discourse, metaphor becomes an important problem for natural language processing (NLP). In order to estimate the frequency of the phenomenon, Shutova and Teufel (2010) conducted a corpus study on a subset of the British National Corpus (BNC) (Burnard, 2007) representing various genres. They manually annotated metaphorical expressions in this data and found that 241 out of 761 sentences contained a metaphor, whereby in 164 phrases metaphoricity was introduced by a verb. Due to such a high frequency of their use, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks:"
C10-1113,N10-1147,1,0.429452,"ain concepts using the verbs from the source domain lexicon. We tested our system starting with a collection of metaphorical expressions representing verbsubject and verb-object constructions, where the verb is used metaphorically. We evaluated the precision of metaphor identiﬁcation with the help of human judges. In addition to this we compared our system to a baseline built upon WordNet, whereby we demonstrated that our method goes far beyond synonymy and captures metaphors not directly related to any of those seen in the seed set. 2 2.1 Experimental Data Seed Phrases We used the dataset of Shutova (2010) as a seed set. Shutova (2010) annotated metaphorical expressions in a subset of the BNC sampling various genres: literature, newspaper/journal articles, essays on politics, international relations and history, radio broadcast (transcribed speech). The dataset consists of 62 phrases that are single-word 1003 metaphors representing verb-subject and verbobject relations, where a verb is used metaphorically. The seed phrases include e.g. stir excitement, reﬂect enthusiasm, accelerate change, grasp theory, cast doubt, suppress memory, throw remark (verb - direct object constructions) and campaign"
C10-1113,D09-1067,1,\N,Missing
C10-1113,C98-2122,0,\N,Missing
C12-2109,P06-4020,0,0.0159027,"e.g. speed up would select for MACHINES, or VEHICLES, rather than CHANGE (the target domain), whereas the ones used literally for the target domain, e.g. facilitate would select for PROCESSES (including CHANGE). We therefore expect that selecting the verbs whose preferences the noun in the metaphorical expression matches best should allow us to filter out non-literalness. We automatically acquired selectional preference (SP) distributions of the candidate substitutes (for subject-verb and verb-object relations) from the British National Corpus (BNC) (Burnard, 2007) parsed by the RASP parser (Briscoe et al., 2006). We obtained SP classes by clustering the 2000 most frequent nouns in the BNC into 200 clusters using the algorithm of Sun and Korhonen (2009). We quantified selectional preferences using the association measure proposed by Resnik (1993). It represents SPs as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position irrespective of the identity of the verb. This difference then defines the selectional preference strength (SPS) of the verb, quantified in terms of Kullback-Leibler divergence a"
C12-2109,E03-1034,0,0.209562,"Missing"
C12-2109,D08-1094,0,0.0272439,"restricted text. The recent metaphor paraphrasing approach of Shutova (2010) was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases. In this paper, we take the metaphor paraphrasing task a step further and present a fully unsupervised approach to this problem. In our method, candidate substitutes for the metaphorical term are generated using a vector space model. Vector space models have been previously used in the general lexical substitution task (Mitchell and Lapata, 2008; Erk and Padó, 2008, 2009; Thater et al., 2009, 2010; Erk and Padó, 2010; Van de Cruys et al., 2011). However, (to the best of our knowledge) they have not yet been deployed in tasks involving figurative meaning transfers, such as interpretation of metonymy or metaphor. In this paper, we address this problem and apply a vector space model of word meaning in context to metaphor paraphrasing, appropriately adapting it to the task. In comparison to lexical substitution, metaphor paraphrasing presents an additional challenge, namely that of discriminating between literal and metaphorical substitutes. Shutova (2010)"
C12-2109,W09-0208,0,0.178835,"Missing"
C12-2109,P10-2017,0,0.0156901,"roach of Shutova (2010) was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases. In this paper, we take the metaphor paraphrasing task a step further and present a fully unsupervised approach to this problem. In our method, candidate substitutes for the metaphorical term are generated using a vector space model. Vector space models have been previously used in the general lexical substitution task (Mitchell and Lapata, 2008; Erk and Padó, 2008, 2009; Thater et al., 2009, 2010; Erk and Padó, 2010; Van de Cruys et al., 2011). However, (to the best of our knowledge) they have not yet been deployed in tasks involving figurative meaning transfers, such as interpretation of metonymy or metaphor. In this paper, we address this problem and apply a vector space model of word meaning in context to metaphor paraphrasing, appropriately adapting it to the task. In comparison to lexical substitution, metaphor paraphrasing presents an additional challenge, namely that of discriminating between literal and metaphorical substitutes. Shutova (2010) used a selectional preference-based model for this pu"
C12-2109,J91-1003,0,0.870472,"ird sentence in general domain text contains a metaphorical expression). Due to this high frequency usage, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of many semantics-oriented NLP applications. The majority of previous computational approaches to metaphor rely on manually created knowledge and thus operate on a limited domain and are expensive to build and extend. Handcoded knowledge has proved useful for both metaphor identification, i.e. distinguishing between literal and metaphorical language in text (Fass, 1991; Martin, 1990; Krishnakumaran and Zhu, 2007; Gedigian et al., 2006) and metaphor interpretation, i.e. identifying the intended literal meaning of a metaphorical expression (Fass, 1991; Martin, 1990; Narayanan, 1997; Barnden and Lee, 2002). However, to be applicable in a real-world setting a metaphor processing system needs to be able to identify and interpret metaphorical expressions in unrestricted text. The recent metaphor paraphrasing approach of Shutova (2010) was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database"
C12-2109,W06-3506,0,0.659038,"cal expression). Due to this high frequency usage, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of many semantics-oriented NLP applications. The majority of previous computational approaches to metaphor rely on manually created knowledge and thus operate on a limited domain and are expensive to build and extend. Handcoded knowledge has proved useful for both metaphor identification, i.e. distinguishing between literal and metaphorical language in text (Fass, 1991; Martin, 1990; Krishnakumaran and Zhu, 2007; Gedigian et al., 2006) and metaphor interpretation, i.e. identifying the intended literal meaning of a metaphorical expression (Fass, 1991; Martin, 1990; Narayanan, 1997; Barnden and Lee, 2002). However, to be applicable in a real-world setting a metaphor processing system needs to be able to identify and interpret metaphorical expressions in unrestricted text. The recent metaphor paraphrasing approach of Shutova (2010) was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases. In this paper, we take"
C12-2109,W07-0103,0,0.212135,"main text contains a metaphorical expression). Due to this high frequency usage, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of many semantics-oriented NLP applications. The majority of previous computational approaches to metaphor rely on manually created knowledge and thus operate on a limited domain and are expensive to build and extend. Handcoded knowledge has proved useful for both metaphor identification, i.e. distinguishing between literal and metaphorical language in text (Fass, 1991; Martin, 1990; Krishnakumaran and Zhu, 2007; Gedigian et al., 2006) and metaphor interpretation, i.e. identifying the intended literal meaning of a metaphorical expression (Fass, 1991; Martin, 1990; Narayanan, 1997; Barnden and Lee, 2002). However, to be applicable in a real-world setting a metaphor processing system needs to be able to identify and interpret metaphorical expressions in unrestricted text. The recent metaphor paraphrasing approach of Shutova (2010) was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases."
C12-2109,nivre-etal-2006-maltparser,0,0.024482,"The model uses non-negative matrix factorization (NMF) (Lee and Seung, 2000) in order to find latent dimensions, using the minimization of the Kullback-Leibler divergence as an objective function. A more detailed description of the factorization model can be found in Van de Cruys et al. (2011). Our paraphrase generation model has been trained on part of the UKWaC corpus (Baroni et al., 2009), covering about 500M words. The corpus has been part of speech tagged and lemmatized with Stanford Part-Of-Speech Tagger (Toutanova and Manning, 2000; Toutanova et al., 2003), and parsed with MaltParser (Nivre et al., 2006), so that dependency triples could be extracted. Using the latent distributions yielded by our factorization model, it is now possible to compute the meaning vector for a particular word in context, and subsequently the most similar words to this meaning vector, which will be our candidate paraphrases. Intuitively, the contextual features of the word (i.e. the dependency-based context features) will highlight the important semantic dimensions of the particular instance, creating a probability distribution over latent factors p(z|d j ). Using this probability distribution, a new probability dis"
C12-2109,P10-1045,0,0.0249184,"Missing"
C12-2109,J07-2002,0,0.0213779,"o observe the behavior of the system, and the remaining 52 constituted the test set. 11 of them were subject-verb constructions and 41 were verb-direct object constructions. 3.2 Baseline system The baseline system is also unsupervised and incorporates two methods: that of generating most similar substitutes for the metaphorical verb regardless of its context and a method for their re-ranking based on the likelihood of their co-occurrence with the noun in the metaphorical expression. Thus a list of most similar substitutes is first generated using a standard dependencybased vector space model (Padó and Lapata, 2007). The likelihood of a paraphrase is then calculated as a joint probability of the candidate substitutes and the noun in the context as follows: f (v) f (v, n) f (v, n) L v = P(v, n)) = P(v) · P(n|v) = P · =P (5) f (v) f (v ) k k k f (vk ) where f (v, n) is the frequency of the co-occurrence of the substitute with the context and P k f (vk ) is the total number of verbs in the corpus. 3.3 Evaluation method and results We evaluated the paraphrases with the aid of human judges and against a human-created gold standard in two different experimental settings. Setting 1 Human judges were presented w"
C12-2109,N10-1147,1,0.578853,"d knowledge has proved useful for both metaphor identification, i.e. distinguishing between literal and metaphorical language in text (Fass, 1991; Martin, 1990; Krishnakumaran and Zhu, 2007; Gedigian et al., 2006) and metaphor interpretation, i.e. identifying the intended literal meaning of a metaphorical expression (Fass, 1991; Martin, 1990; Narayanan, 1997; Barnden and Lee, 2002). However, to be applicable in a real-world setting a metaphor processing system needs to be able to identify and interpret metaphorical expressions in unrestricted text. The recent metaphor paraphrasing approach of Shutova (2010) was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases. In this paper, we take the metaphor paraphrasing task a step further and present a fully unsupervised approach to this problem. In our method, candidate substitutes for the metaphorical term are generated using a vector space model. Vector space models have been previously used in the general lexical substitution task (Mitchell and Lapata, 2008; Erk and Padó, 2008, 2009; Thater et al., 2009, 2010; Erk and Padó, 2010; Van"
C12-2109,shutova-teufel-2010-metaphor,1,0.73581,"sters, pages 1121–1130, COLING 2012, Mumbai, December 2012. 1121 1 Introduction Metaphor has traditionally been viewed as an artistic device that lends vividness and distinction to its author’s style. This view was first challenged by Lakoff and Johnson (1980), who claimed that it is a productive phenomenon that operates at the level of mental processes. Humans often use metaphor to describe abstract concepts through reference to more concrete experiences. Being a characteristic property of human thought and communication, metaphor becomes an important problem for natural language processing. Shutova and Teufel (2010) have shown in an empirical study that the use of metaphor is ubiquitous in natural language text (according to their data, on average every third sentence in general domain text contains a metaphorical expression). Due to this high frequency usage, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of many semantics-oriented NLP applications. The majority of previous computational approaches to metaphor rely on manually created knowledge and thus operate on a limited domain and are expensive to build and extend."
C12-2109,D09-1067,1,0.816623,"domain, e.g. facilitate would select for PROCESSES (including CHANGE). We therefore expect that selecting the verbs whose preferences the noun in the metaphorical expression matches best should allow us to filter out non-literalness. We automatically acquired selectional preference (SP) distributions of the candidate substitutes (for subject-verb and verb-object relations) from the British National Corpus (BNC) (Burnard, 2007) parsed by the RASP parser (Briscoe et al., 2006). We obtained SP classes by clustering the 2000 most frequent nouns in the BNC into 200 clusters using the algorithm of Sun and Korhonen (2009). We quantified selectional preferences using the association measure proposed by Resnik (1993). It represents SPs as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position irrespective of the identity of the verb. This difference then defines the selectional preference strength (SPS) of the verb, quantified in terms of Kullback-Leibler divergence as follows. SR (v) = D(P(c|v)||P(c)) = X P(c|v) log c P(c|v) P(c) , (3) where P(c) is the prior probability of the noun class, P(c|v) is the pos"
C12-2109,W09-2506,0,0.0152106,"t metaphor paraphrasing approach of Shutova (2010) was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases. In this paper, we take the metaphor paraphrasing task a step further and present a fully unsupervised approach to this problem. In our method, candidate substitutes for the metaphorical term are generated using a vector space model. Vector space models have been previously used in the general lexical substitution task (Mitchell and Lapata, 2008; Erk and Padó, 2008, 2009; Thater et al., 2009, 2010; Erk and Padó, 2010; Van de Cruys et al., 2011). However, (to the best of our knowledge) they have not yet been deployed in tasks involving figurative meaning transfers, such as interpretation of metonymy or metaphor. In this paper, we address this problem and apply a vector space model of word meaning in context to metaphor paraphrasing, appropriately adapting it to the task. In comparison to lexical substitution, metaphor paraphrasing presents an additional challenge, namely that of discriminating between literal and metaphorical substitutes. Shutova (2010) used a selectional preferen"
C12-2109,P10-1097,0,0.0504015,"Missing"
C12-2109,N03-1033,0,0.00418949,"endency-based feature vector of the word accordingly. The model uses non-negative matrix factorization (NMF) (Lee and Seung, 2000) in order to find latent dimensions, using the minimization of the Kullback-Leibler divergence as an objective function. A more detailed description of the factorization model can be found in Van de Cruys et al. (2011). Our paraphrase generation model has been trained on part of the UKWaC corpus (Baroni et al., 2009), covering about 500M words. The corpus has been part of speech tagged and lemmatized with Stanford Part-Of-Speech Tagger (Toutanova and Manning, 2000; Toutanova et al., 2003), and parsed with MaltParser (Nivre et al., 2006), so that dependency triples could be extracted. Using the latent distributions yielded by our factorization model, it is now possible to compute the meaning vector for a particular word in context, and subsequently the most similar words to this meaning vector, which will be our candidate paraphrases. Intuitively, the contextual features of the word (i.e. the dependency-based context features) will highlight the important semantic dimensions of the particular instance, creating a probability distribution over latent factors p(z|d j ). Using thi"
C12-2109,W00-1308,0,0.00730431,"ar context, and adapt the dependency-based feature vector of the word accordingly. The model uses non-negative matrix factorization (NMF) (Lee and Seung, 2000) in order to find latent dimensions, using the minimization of the Kullback-Leibler divergence as an objective function. A more detailed description of the factorization model can be found in Van de Cruys et al. (2011). Our paraphrase generation model has been trained on part of the UKWaC corpus (Baroni et al., 2009), covering about 500M words. The corpus has been part of speech tagged and lemmatized with Stanford Part-Of-Speech Tagger (Toutanova and Manning, 2000; Toutanova et al., 2003), and parsed with MaltParser (Nivre et al., 2006), so that dependency triples could be extracted. Using the latent distributions yielded by our factorization model, it is now possible to compute the meaning vector for a particular word in context, and subsequently the most similar words to this meaning vector, which will be our candidate paraphrases. Intuitively, the contextual features of the word (i.e. the dependency-based context features) will highlight the important semantic dimensions of the particular instance, creating a probability distribution over latent fac"
C12-2109,D11-1094,1,0.516995,"Missing"
C12-2109,P09-2019,0,0.0790482,"Missing"
C12-2109,P08-1028,0,\N,Missing
C18-1093,K16-1017,0,0.0337369,"approach has the advantage of overcoming the absence of information that the previous approaches face. Among those that implement this idea are Yang et al. (2016), who used representations derived from a social graph to achieve better performance in entity linking tasks, and Chen and Ku (2016), who used them for stance classification. A considerable amount of literature has also been devoted to sentiment analysis with representations built from demographic factors (Yang and Eisenstein, 2017; Chen et al., 2016). Other tasks that have benefited from social representations are sarcasm detection (Amir et al., 2016) and political opinion prediction (T˘alm˘acel and Leon, 2017). 3 Dataset We experiment with the dataset of Waseem and Hovy (2016), containing tweets manually annotated for abuse. The authors retrieved around 136k tweets over a period of two months. They bootstrapped their collection process with a search for commonly used slurs and expletives related to religious, sexual, gender and ethnic minorities. From the results, they identified terms and references to entities that 1090 frequently showed up in abusive tweets. Based on this sample, they used a public Twitter API to collect the entire cor"
C18-1093,C16-1154,0,0.0307012,"ase, node representations (where nodes represent the authors in the social network) are typically induced using neural architectures. Given the graph representing the social network, such methods create low-dimensional representations for each node, which are optimized to predict the nodes close to it in the network. This approach has the advantage of overcoming the absence of information that the previous approaches face. Among those that implement this idea are Yang et al. (2016), who used representations derived from a social graph to achieve better performance in entity linking tasks, and Chen and Ku (2016), who used them for stance classification. A considerable amount of literature has also been devoted to sentiment analysis with representations built from demographic factors (Yang and Eisenstein, 2017; Chen et al., 2016). Other tasks that have benefited from social representations are sarcasm detection (Amir et al., 2016) and political opinion prediction (T˘alm˘acel and Leon, 2017). 3 Dataset We experiment with the dataset of Waseem and Hovy (2016), containing tweets manually annotated for abuse. The authors retrieved around 136k tweets over a period of two months. They bootstrapped their col"
C18-1093,D16-1171,0,0.030938,"presentations for each node, which are optimized to predict the nodes close to it in the network. This approach has the advantage of overcoming the absence of information that the previous approaches face. Among those that implement this idea are Yang et al. (2016), who used representations derived from a social graph to achieve better performance in entity linking tasks, and Chen and Ku (2016), who used them for stance classification. A considerable amount of literature has also been devoted to sentiment analysis with representations built from demographic factors (Yang and Eisenstein, 2017; Chen et al., 2016). Other tasks that have benefited from social representations are sarcasm detection (Amir et al., 2016) and political opinion prediction (T˘alm˘acel and Leon, 2017). 3 Dataset We experiment with the dataset of Waseem and Hovy (2016), containing tweets manually annotated for abuse. The authors retrieved around 136k tweets over a period of two months. They bootstrapped their collection process with a search for commonly used slurs and expletives related to religious, sexual, gender and ethnic minorities. From the results, they identified terms and references to entities that 1090 frequently show"
C18-1093,P15-1073,0,0.0506886,"s of racist tweets in response to President Obama’s re-election to show that such tweets were not uniformly distributed across the United States but formed clusters instead. In this paper, we present the first approach to abuse detection that leverages author profiling information based on properties of the authors’ social network and investigate its effectiveness. Author profiling has emerged as a powerful tool for NLP applications, leading to substantial performance improvements in several downstream tasks, such as text classification, sentiment analysis and author attribute identification (Hovy, 2015; Eisenstein, 2015; Yang and Eisenstein, 2017). The relevance of information gained from it is best explained by the idea of homophily, i.e., the phenomenon that people, both in real life as well as on the Internet, tend to associate more with those who appear similar. Here, similarity can be defined along various axes, e.g., location, age, language, etc. The strength of author profiling lies in that if we have information about members of a community c defined by some similarity criterion, and we know that the person p belongs to c, we can infer information about p. This concept has a straigh"
C18-1093,K15-1011,0,0.0227947,"r to classify the comments based on those representations. 2.2 Author profiling Author profiling has been leveraged in several ways for a variety of purposes in NLP. For instance, many studies have relied on demographic information of the authors. Amongst these are Hovy et al. (2015) and Ebrahimi et al. (2016) who extracted age and gender-related information to achieve superior performance in a text classification task. Pavalanathan and Eisenstein (2015), in their work, further showed the relevance of the same information to automatic text-based geo-location. Researching along the same lines, Johannsen et al. (2015) and Mirkin et al. (2015) utilized demographic factors to improve syntactic parsing and machine translation respectively. While demographic information has proved to be relevant for a number of tasks, it presents a significant drawback: since this information is not always available for all authors in a social network, it is not particularly reliable. Consequently, of late, a new line of research has focused on creating representations of users in a social network by leveraging the information derived from the connections that they have with other users. In this case, node representations (whe"
C18-1093,D15-1130,0,0.0233444,"ased on those representations. 2.2 Author profiling Author profiling has been leveraged in several ways for a variety of purposes in NLP. For instance, many studies have relied on demographic information of the authors. Amongst these are Hovy et al. (2015) and Ebrahimi et al. (2016) who extracted age and gender-related information to achieve superior performance in a text classification task. Pavalanathan and Eisenstein (2015), in their work, further showed the relevance of the same information to automatic text-based geo-location. Researching along the same lines, Johannsen et al. (2015) and Mirkin et al. (2015) utilized demographic factors to improve syntactic parsing and machine translation respectively. While demographic information has proved to be relevant for a number of tasks, it presents a significant drawback: since this information is not always available for all authors in a social network, it is not particularly reliable. Consequently, of late, a new line of research has focused on creating representations of users in a social network by leveraging the information derived from the connections that they have with other users. In this case, node representations (where nodes represent the au"
C18-1093,W17-3006,0,0.0925651,"GLoVe word embeddings.8 We employ Lightgbm (Ke et al., 2017) as our GDBT classifier and tune its hyper-parameters using 5-fold grid search. For the node2vec framework, we use the same parameters as in the original paper (Grover and Leskovec, 2016) except we set the dimensionality of node embeddings to 200 and increase the number of iterations to 25 for better convergence. 5.2 Results We perform 10-fold stratified cross validation (CV), as suggested by Forman and Scholz (2010), to evaluate all seven methods described in the previous section. Following previous research (Badjatiya et al., 2017; Park and Fung, 2017), we report the average weighted precision, recall, and F1 scores for all the methods. The average weighted precision is calculated as: P10 i=1 (wr · Pir + ws · Pis + wn · Pin ) 10 where Pir , Pis , Pin are precision scores on the racism, sexism, and none classes from the ith fold of the CV . The values wr , ws , and wn are the proportions of the racism, sexism, and none classes in the dataset respectively; since we use stratification, these proportions are constant (wr = 0.12, ws = 0.19, wn = 0.69) across all folds. Average weighted recall and F1 are calculated in the same manner. The results"
C18-1093,D15-1256,0,0.0183922,"017) improved the results of Wulczyn et al. by using a gated recurrent unit (GRU) model to encode the comments into dense low-dimensional representations, followed by a LR layer to classify the comments based on those representations. 2.2 Author profiling Author profiling has been leveraged in several ways for a variety of purposes in NLP. For instance, many studies have relied on demographic information of the authors. Amongst these are Hovy et al. (2015) and Ebrahimi et al. (2016) who extracted age and gender-related information to achieve superior performance in a text classification task. Pavalanathan and Eisenstein (2015), in their work, further showed the relevance of the same information to automatic text-based geo-location. Researching along the same lines, Johannsen et al. (2015) and Mirkin et al. (2015) utilized demographic factors to improve syntactic parsing and machine translation respectively. While demographic information has proved to be relevant for a number of tasks, it presents a significant drawback: since this information is not always available for all authors in a social network, it is not particularly reliable. Consequently, of late, a new line of research has focused on creating representat"
C18-1093,W17-3004,0,0.432619,"ile simultaneously being able to separate the racist and offensive ones. Their best model was a LR classifier trained using TF - IDF and POS n-gram features, as well as the count of hash tags and number of words. Wulczyn et al. (2017) prepared three different datasets of comments collected from the English Wikipedia Talk page; one was annotated for personal attacks, another for toxicity and the third one for aggression. Their best performing model was a multi-layered perceptron (MLP) classifier trained on character n-gram features. Experimenting with the personal attack and toxicity datasets, Pavlopoulos et al. (2017) improved the results of Wulczyn et al. by using a gated recurrent unit (GRU) model to encode the comments into dense low-dimensional representations, followed by a LR layer to classify the comments based on those representations. 2.2 Author profiling Author profiling has been leveraged in several ways for a variety of purposes in NLP. For instance, many studies have relied on demographic information of the authors. Amongst these are Hovy et al. (2015) and Ebrahimi et al. (2016) who extracted age and gender-related information to achieve superior performance in a text classification task. Pava"
C18-1093,D14-1162,0,0.0930946,"sults on the Wikipedia datasets released by Wulczyn et al. (2017). The method comprises a 1-layer gated recurrent unit (GRU) that takes a sequence w1 , . . . , wn of words represented as d-dimensional embeddings and encodes them into hidden states h1 , . . . , hn . This is followed by an LR layer that uses the last hidden state hn to classify the tweet. We make two minor modifications to the authors’ original architecture: we deepen the 1-layer GRU to a 2-layer GRU and use softmax instead of sigmoid in the LR layer.4 Like Pavlopoulos et al., we initialize the word embeddings to GLoVe vectors (Pennington et al., 2014). In all our methods, words not available in the GLoVe set are randomly initialized in the range ±0.05, indicating the lack of semantic information. By not mapping these words to a single random embedding, we mitigate against the errors that may arise due to their conflation (Madhyastha et al., 2015). A special OOV (out of vocabulary) token is also initialized in the same range. All the embeddings are updated during training, allowing some of the randomly-initialized ones to get task-tuned; the ones that do not get tuned lie closely clustered around the OOV token, to which unseen words in the"
C18-1093,N16-2013,0,0.406018,"bag-of-words (BOW) representations in a supervised classification setting for hate speech detection. Nobata et al. (2016) improved upon the results of Djuric et al. by training their classifier on a combination of features drawn from four different categories: linguistic (e.g., count of insult words), syntactic (e.g., POS tags), distributional semantic (e.g., word and comment embeddings) and BOW -based (word and characters n-grams). They reported that while the best results were obtained with all features combined, character n-grams contributed more to performance than all the other features. Waseem and Hovy (2016) created and experimented with a dataset of racist, sexist and clean tweets. Utilizing a logistic regression (LR) classifier to distinguish amongst them, they found that character n-grams coupled with gender information of users formed the optimal feature set; on the other hand, geographic and word-length distribution features provided little to no improvement. Working with the same dataset, Badjatiya et al. (2017) improved on their results by training a gradient-boosted decision 1 https://github.com/pushkarmishra/AuthorProfilingAbuseDetection 1089 tree (GBDT) classifier on averaged word embed"
C18-1093,W16-5618,0,0.164306,"ion (LR) classifier to distinguish amongst them, they found that character n-grams coupled with gender information of users formed the optimal feature set; on the other hand, geographic and word-length distribution features provided little to no improvement. Working with the same dataset, Badjatiya et al. (2017) improved on their results by training a gradient-boosted decision 1 https://github.com/pushkarmishra/AuthorProfilingAbuseDetection 1089 tree (GBDT) classifier on averaged word embeddings learnt using a long short-term memory (LSTM) network that they initialized with random embeddings. Waseem (2016) sampled 7k more tweets in the same manner as Waseem and Hovy (2016). They recruited expert and amateur annotators to annotate the tweets as racism, sexism, both or neither in order to study the influence of annotator knowledge on the task of hate speech detection. Combining this dataset with that of Waseem and Hovy (2016), Park et al. (2017) explored the merits of a two-step classification process. They first used a LR classifier to separate abusive and non-abusive tweets, followed by another LR classifier to distinguish between racist and sexist ones. They showed that this setup had comparab"
C18-1093,D16-1152,0,0.133695,"s of users in a social network by leveraging the information derived from the connections that they have with other users. In this case, node representations (where nodes represent the authors in the social network) are typically induced using neural architectures. Given the graph representing the social network, such methods create low-dimensional representations for each node, which are optimized to predict the nodes close to it in the network. This approach has the advantage of overcoming the absence of information that the previous approaches face. Among those that implement this idea are Yang et al. (2016), who used representations derived from a social graph to achieve better performance in entity linking tasks, and Chen and Ku (2016), who used them for stance classification. A considerable amount of literature has also been devoted to sentiment analysis with representations built from demographic factors (Yang and Eisenstein, 2017; Chen et al., 2016). Other tasks that have benefited from social representations are sarcasm detection (Amir et al., 2016) and political opinion prediction (T˘alm˘acel and Leon, 2017). 3 Dataset We experiment with the dataset of Waseem and Hovy (2016), containing tw"
D17-1113,D13-1202,0,0.404187,"enchmark for evaluating semantic model performance in terms of their ability to represent human semantic memory. Mitchell et al. (2008) were the first to demonstrate that distributional semantic models encode some of the patterns found in the fMRI data. Other researchers followed in their steps, evaluating traditional count-based distributional models (Devereux et al., 2010; Murphy et al., 2012), topic model-based semantic features (Pereira et al., 2013), psycholinguistic and behavioural features (Palatucci et al., 2009; Chang et al., 2010; Fernandino et al., 2015) and visual representations (Anderson et al., 2013, 2017). While all of these studies report correlation between the investigated semantic models and patterns found in the brain imaging data, their focus on individual models and the use of different datasets and prediction methods make their results difficult to compare and to integrate into a coherent evaluation landscape. The work of Murphy et al. (2012) is an exception, in that the authors systematically compare several distributional models with a range of parameters on the same brain imaging dataset. However, they focus on the traditional count-based distributional models only. We take i"
D17-1113,Q17-1002,1,0.767429,"s improves performance on a variety of tasks (Silberer and Lapata, 2012; Bruni et al., 2012; Kiela and Bottou, 2014; Bulat et al., 2016). Anderson et al. (2013) show that semantic models built from visual data correlate highly with fMRIbased brain activation patterns. Anderson et al. (2015) find that similarity in activity in the brain areas related to linguistic processing can be better predicted from text-based semantic representations, whilst image-based representations perform better at predicting similarity in the visual processing areas of the brain. In line with the dual coding theory, Anderson et al. (2017) demonstrate an advantage in decoding brain activity patterns of abstract words for text-based semantic models over the image-based ones. Contrary to previous findings, Anderson et al. (2017) find no advantage in decoding neural activity patterns associated with concrete words for image-based models. Murphy et al. (2012) present the first study systematically comparing several text-based semantic models on the brain activity prediction task. They focus on the traditional count-based distributional models and achieve the best performance using dependency-based features. Our study is more extens"
D17-1113,R11-1055,0,0.0453686,"as semantic features, and counts are replaced by the sum of primary, secondary and tertiary association frequencies between the target word and the responses. Counts are re-weighted using PPMI and vectors are L2normalised. The association-based representations obtained for the 60 target words in the Mitchell et al. (2008) dataset under this model are 9854-dimensional. 4.3 Image-based semantic model We also build state-of-the-art deep visual semantic representations (henceforth VISUAL) for the 60 concepts in the Mitchell et al. (2008) dataset. Following previous work in multi-modal semantics (Bergsma and Goebel, 2011; Kiela and Bottou, 2014) and the findings of a recent study of system architectures and data sources for constructing visual representations (Kiela et al., 2016), we retrieve 10 images per concept from Google Images. We use the MMFeat toolkit6 (Kiela, 2016) to build our image representations. We extract the 4096-dimensional pre-softmax layer from a for4 https://smallworldofwords.org/ Total of 9854 words (appearing as both target and responses) and 1092251 association pairs 6 https://github.com/douwekiela/mmfeat 1084 5 ward pass through a convolutional neural network (Krizhevsky et al., 2012),"
D17-1113,P12-1015,0,0.217624,"xt of natural language processing system performance. In this paper, we present a systematic evaluation and comparison of a range of widely-used, stateof-the-art semantic models in their ability to predict patterns of conceptual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in cognitive neuroscience. 1 Introduction Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the loglinear skip-gram model of Mikolov et al. (2013a) to multi-modal meaning representations (Bruni et al., 2012; Kiela and Bottou, 2014; Kiela and Clark, 2015; Kiela et al., 2015a). These models boast of a higher performance accuracy in numerous semantic tasks, including modeling semantic similarity and relatedness (Silberer and Lapata, 2012), lexical entailment (Kiela et al., 2015b), analogy (Mikolov et al., 2013b) and metaphor (Shutova et al., 2016). However, less is known about the extent to which such models correlate with and reflect human conceptual representation. Much research in the cognitive neuroscience community has been concerned with uncovering how the brain represents conceptual knowledg"
D17-1113,N16-1071,1,0.845696,"Missing"
D17-1113,J07-4004,1,0.714176,"ooccurrence based semantic vectors developed in the Mitchell et al. (2008) study. The features of this semantic space are 25 sensory-motor verbs. Co-occurrence statistics were collected using a window size of 5 words either side of the target word, on a trillion-word corpus provided by Google. 4.1 Text-based semantic models We train a variety2 of context-counting and context-predicting text-based semantic models on the January 2016 dump of Wikipedia, which was tokenised using the Stanford NLP tools3 , lemmatised with the Morpha lemmatiser (Minnen et al., 2001), and parsed with the C&C parser (Clark and Curran, 2007). DISTRIB We obtain count-based distributional semantic models, using the top 10K most frequent lemmatised words in the corpus (excluding stopwords) as contexts. The context window is defined as sentence boundaries. Counts are reweighted using positive pointwise mutual information (PPMI) and vectors are L2-normalised. SVD 300 We also construct 300-dimensional dense semantic representations by applying singular value decomposition (SVD) (Deerwester et al., 1990) to DISTRIB. 1 https://www.cs.cmu.edu/afs/cs/ project/theo-73/www/science2008/data. html 2 We have experimented with different paramete"
D17-1113,C16-1175,0,0.0972466,"Missing"
D17-1113,W10-0609,0,0.474057,"brain activation data associated with the meanings of concepts obtained during functional magnetic resonance imaging (fMRI) experiments. In the computational linguistics community, the availability of such fMRI data provides researchers with a benchmark for evaluating semantic model performance in terms of their ability to represent human semantic memory. Mitchell et al. (2008) were the first to demonstrate that distributional semantic models encode some of the patterns found in the fMRI data. Other researchers followed in their steps, evaluating traditional count-based distributional models (Devereux et al., 2010; Murphy et al., 2012), topic model-based semantic features (Pereira et al., 2013), psycholinguistic and behavioural features (Palatucci et al., 2009; Chang et al., 2010; Fernandino et al., 2015) and visual representations (Anderson et al., 2013, 2017). While all of these studies report correlation between the investigated semantic models and patterns found in the brain imaging data, their focus on individual models and the use of different datasets and prediction methods make their results difficult to compare and to integrate into a coherent evaluation landscape. The work of Murphy et al. (2"
D17-1113,D14-1032,0,0.0337962,"tput by the C&C parser, we create word-context pairs using all words and contexts occurring more than 400 times in the corpus. This resulted in a vocabulary of about 92,000 words, with over 250,000 distinct syntactic contexts. We use 10 negative samples per word-context pair and 15 iterations over the corpus. 4.2 Association-based semantic model Free word association datasets (Nelson et al., 2004; De Deyne et al., 2016) represent a rich source of semantic information and have been successfully used in NLP, including research on semantic memory (Steyvers et al., 2004) and multimodal semantics (Hill and Korhonen, 2014). Recent studies have shown the superiority of semantic models built using data collected from multiple-response free association tasks — where subjects are asked to list multiple associative cues for every target word rather than a single association — over the models built from single-response ones (De Deyne et al., 2013). Moreover, such association-based semantic models have been shown to outperform current stateof-the-art text-based language models on concept relatedness and similarity judgments (De Deyne et al., 2016). We make use of the word association dataset collected as part of the S"
D17-1113,P16-4010,0,0.563309,"for the 60 target words in the Mitchell et al. (2008) dataset under this model are 9854-dimensional. 4.3 Image-based semantic model We also build state-of-the-art deep visual semantic representations (henceforth VISUAL) for the 60 concepts in the Mitchell et al. (2008) dataset. Following previous work in multi-modal semantics (Bergsma and Goebel, 2011; Kiela and Bottou, 2014) and the findings of a recent study of system architectures and data sources for constructing visual representations (Kiela et al., 2016), we retrieve 10 images per concept from Google Images. We use the MMFeat toolkit6 (Kiela, 2016) to build our image representations. We extract the 4096-dimensional pre-softmax layer from a for4 https://smallworldofwords.org/ Total of 9854 words (appearing as both target and responses) and 1092251 association pairs 6 https://github.com/douwekiela/mmfeat 1084 5 ward pass through a convolutional neural network (Krizhevsky et al., 2012), which has been pretrained on the ImageNet classification task using Caffe (Jia et al., 2014). We obtain the visual representation for a given concept by taking the mean of the 10 resulting image representations. 4.4 Multi-modal semantic models We also inclu"
D17-1113,D14-1005,0,0.704069,"ge processing system performance. In this paper, we present a systematic evaluation and comparison of a range of widely-used, stateof-the-art semantic models in their ability to predict patterns of conceptual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in cognitive neuroscience. 1 Introduction Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the loglinear skip-gram model of Mikolov et al. (2013a) to multi-modal meaning representations (Bruni et al., 2012; Kiela and Bottou, 2014; Kiela and Clark, 2015; Kiela et al., 2015a). These models boast of a higher performance accuracy in numerous semantic tasks, including modeling semantic similarity and relatedness (Silberer and Lapata, 2012), lexical entailment (Kiela et al., 2015b), analogy (Mikolov et al., 2013b) and metaphor (Shutova et al., 2016). However, less is known about the extent to which such models correlate with and reflect human conceptual representation. Much research in the cognitive neuroscience community has been concerned with uncovering how the brain represents conceptual knowledge, by leveraging brain a"
D17-1113,P15-2038,1,0.838305,", we present a systematic evaluation and comparison of a range of widely-used, stateof-the-art semantic models in their ability to predict patterns of conceptual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in cognitive neuroscience. 1 Introduction Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the loglinear skip-gram model of Mikolov et al. (2013a) to multi-modal meaning representations (Bruni et al., 2012; Kiela and Bottou, 2014; Kiela and Clark, 2015; Kiela et al., 2015a). These models boast of a higher performance accuracy in numerous semantic tasks, including modeling semantic similarity and relatedness (Silberer and Lapata, 2012), lexical entailment (Kiela et al., 2015b), analogy (Mikolov et al., 2013b) and metaphor (Shutova et al., 2016). However, less is known about the extent to which such models correlate with and reflect human conceptual representation. Much research in the cognitive neuroscience community has been concerned with uncovering how the brain represents conceptual knowledge, by leveraging brain activation data associated with the meanings"
D17-1113,D15-1293,1,0.883032,"formance. In this paper, we present a systematic evaluation and comparison of a range of widely-used, stateof-the-art semantic models in their ability to predict patterns of conceptual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in cognitive neuroscience. 1 Introduction Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the loglinear skip-gram model of Mikolov et al. (2013a) to multi-modal meaning representations (Bruni et al., 2012; Kiela and Bottou, 2014; Kiela and Clark, 2015; Kiela et al., 2015a). These models boast of a higher performance accuracy in numerous semantic tasks, including modeling semantic similarity and relatedness (Silberer and Lapata, 2012), lexical entailment (Kiela et al., 2015b), analogy (Mikolov et al., 2013b) and metaphor (Shutova et al., 2016). However, less is known about the extent to which such models correlate with and reflect human conceptual representation. Much research in the cognitive neuroscience community has been concerned with uncovering how the brain represents conceptual knowledge, by leveraging brain activation data associat"
D17-1113,P15-2020,1,0.902858,"Missing"
D17-1113,D16-1043,1,0.907927,"Missing"
D17-1113,P14-2050,0,0.0362204,"resentations by applying SVD to DEPS. EMBED - BOW We train 300-dimensional embeddings using the standard log-linear skipgram model with negative sampling of Mikolov et al. (2013a). The embeddings were trained using linear bag-of-words contexts, with the window defined as k = 2 (EMBED - BOW 2) or k = 5 (EMBED - BOW 5) words either side of the target word. We use 10 negative samples per wordcontext pair and 15 iterations over the corpus. EMBED - DEPS In addition to the embeddings trained with linear bag-of-words contexts, we also obtain 300-dimensional dependency-based word embeddings using the Levy and Goldberg (2014) implementation of the generalised skip-gram with arbitrary contexts model. Using both incoming and outgoing dependency relations output by the C&C parser, we create word-context pairs using all words and contexts occurring more than 400 times in the corpus. This resulted in a vocabulary of about 92,000 words, with over 250,000 distinct syntactic contexts. We use 10 negative samples per word-context pair and 15 iterations over the corpus. 4.2 Association-based semantic model Free word association datasets (Nelson et al., 2004; De Deyne et al., 2016) represent a rich source of semantic informat"
D17-1113,N16-1020,1,0.875798,"c models and for further research in cognitive neuroscience. 1 Introduction Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the loglinear skip-gram model of Mikolov et al. (2013a) to multi-modal meaning representations (Bruni et al., 2012; Kiela and Bottou, 2014; Kiela and Clark, 2015; Kiela et al., 2015a). These models boast of a higher performance accuracy in numerous semantic tasks, including modeling semantic similarity and relatedness (Silberer and Lapata, 2012), lexical entailment (Kiela et al., 2015b), analogy (Mikolov et al., 2013b) and metaphor (Shutova et al., 2016). However, less is known about the extent to which such models correlate with and reflect human conceptual representation. Much research in the cognitive neuroscience community has been concerned with uncovering how the brain represents conceptual knowledge, by leveraging brain activation data associated with the meanings of concepts obtained during functional magnetic resonance imaging (fMRI) experiments. In the computational linguistics community, the availability of such fMRI data provides researchers with a benchmark for evaluating semantic model performance in terms of their ability to re"
D17-1113,D12-1130,0,0.214005,"ual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in cognitive neuroscience. 1 Introduction Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the loglinear skip-gram model of Mikolov et al. (2013a) to multi-modal meaning representations (Bruni et al., 2012; Kiela and Bottou, 2014; Kiela and Clark, 2015; Kiela et al., 2015a). These models boast of a higher performance accuracy in numerous semantic tasks, including modeling semantic similarity and relatedness (Silberer and Lapata, 2012), lexical entailment (Kiela et al., 2015b), analogy (Mikolov et al., 2013b) and metaphor (Shutova et al., 2016). However, less is known about the extent to which such models correlate with and reflect human conceptual representation. Much research in the cognitive neuroscience community has been concerned with uncovering how the brain represents conceptual knowledge, by leveraging brain activation data associated with the meanings of concepts obtained during functional magnetic resonance imaging (fMRI) experiments. In the computational linguistics community, the availability of such fMRI data"
D17-1113,N13-1090,0,0.167424,"ng. However, semantic models are typically studied in the context of natural language processing system performance. In this paper, we present a systematic evaluation and comparison of a range of widely-used, stateof-the-art semantic models in their ability to predict patterns of conceptual representation in the human brain. Our results provide new insights both for the design of computational semantic models and for further research in cognitive neuroscience. 1 Introduction Recent years have witnessed many breakthroughs in data-driven semantic modelling: from the loglinear skip-gram model of Mikolov et al. (2013a) to multi-modal meaning representations (Bruni et al., 2012; Kiela and Bottou, 2014; Kiela and Clark, 2015; Kiela et al., 2015a). These models boast of a higher performance accuracy in numerous semantic tasks, including modeling semantic similarity and relatedness (Silberer and Lapata, 2012), lexical entailment (Kiela et al., 2015b), analogy (Mikolov et al., 2013b) and metaphor (Shutova et al., 2016). However, less is known about the extent to which such models correlate with and reflect human conceptual representation. Much research in the cognitive neuroscience community has been concerned"
D17-1113,S12-1019,0,0.207323,"ssociated with the meanings of concepts obtained during functional magnetic resonance imaging (fMRI) experiments. In the computational linguistics community, the availability of such fMRI data provides researchers with a benchmark for evaluating semantic model performance in terms of their ability to represent human semantic memory. Mitchell et al. (2008) were the first to demonstrate that distributional semantic models encode some of the patterns found in the fMRI data. Other researchers followed in their steps, evaluating traditional count-based distributional models (Devereux et al., 2010; Murphy et al., 2012), topic model-based semantic features (Pereira et al., 2013), psycholinguistic and behavioural features (Palatucci et al., 2009; Chang et al., 2010; Fernandino et al., 2015) and visual representations (Anderson et al., 2013, 2017). While all of these studies report correlation between the investigated semantic models and patterns found in the brain imaging data, their focus on individual models and the use of different datasets and prediction methods make their results difficult to compare and to integrate into a coherent evaluation landscape. The work of Murphy et al. (2012) is an exception,"
D17-1162,P16-2017,1,0.746585,"l associations are broad generalisations that allow us to project knowledge and inferences across domains; and our metaphorical use of language is a reflection of this process. Given its ubiquity, metaphorical language poses an important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010). A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical. They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014"
D17-1162,E17-2084,1,0.556468,"sentations for the metaphor identification task via supervised training; (3) quantifies metaphoricity via a weighted similarity function that automatically selects the relevant dimensions of similarity. We experimented with two types of word representations 1537 Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1537–1546 c Copenhagen, Denmark, September 7–11, 2017. 2017 Association for Computational Linguistics as inputs to the network: the standard skip-gram word embeddings (Mikolov et al., 2013a) and the cognitively-driven attribute-based vectors (Bulat et al., 2017), as well as a combination thereof. We evaluate our method in the metaphor identification task, focusing on adjective–noun, verb– subject and verb–direct object constructions where the verbs and adjectives can be used metaphorically. Our results show that our architecture outperforms both a metaphor agnostic deep learning baseline (a basic feed forward network) and the previous corpus-based approaches to metaphor identification. We also investigate the effects of training data on this task, and demonstrate that with a sufficiently large training set our method also outperforms the best existin"
D17-1162,W16-1104,0,0.224064,"cepts from corpora. For example, the feature vector for politics would contain GAME or MECHA NISM terms among the frequent features. As a result, distributional clustering of abstract nouns with such features identifies groups of diverse concepts metaphorically associated with the same source domain. Shutova et al. (2010) exploit this property of co-occurrence vectors to identify new metaphorical mappings starting from a set of examples. Shutova and Sun (2013) used hierarchical clustering to derive a network of concepts in which metaphorical associations are learned in an unsupervised way. Do Dinh and Gurevych (2016) investigated metaphors through the task of sequence labelling, detecting metaphor related words in context. Guti´errez et al. (2016) investigated metaphorical composition in the compositional distributional semantics framework. Their method learns metaphors as linear transformations in a vector space and they demonstrated that it produces superior phrase representations for both metaphorical and literal language, as compared to the traditional ”single-sense” compositional distributional model. They then used these representations in the metaphor identification task, achieving promising result"
D17-1162,W15-0107,0,0.0198019,"misclassified examples. The diagram of the complete network can be seen in Figure 1. 4 Word Representations Following Bulat et al. (2017) we experiment with two types of semantic vectors: skip-gram word embeddings and attribute-based representations. The word embeddings are 100-dimensional and were trained using the standard log-linear skipgram model with negative sampling of Mikolov et al. (2013b) on Wikipedia for 3 epochs, using a symmetric window of 5 and 10 negative samples per word-context pair. We use the 2526-dimensional attribute-based vectors trained by Bulat et al. (2017), following Fagarasan et al. (2015). These representations were induced by using partial least squares regression to learn a cross-modal mapping function between the word embeddings described above and the McRae et al. (2005) property-norm semantic space. 5 Datasets We evaluate our method using two datasets of phrases manually annotated for metaphoricity. Literal bloody nose cold weather dry skin empty can frosty morning hot chocolate gold coin soft leather sour cherry steep hill Table 2: Annotated adjective–noun pairs from TSV- TEST . Since these datasets include examples for different senses (both metaphorical and literal) of"
D17-1162,W06-3506,0,0.539391,"ge and inferences across domains; and our metaphorical use of language is a reflection of this process. Given its ubiquity, metaphorical language poses an important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010). A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical. They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016). Their experiments have demonstrated that corpus-"
D17-1162,W13-0907,0,0.669226,"concept). Such metaphorical associations are broad generalisations that allow us to project knowledge and inferences across domains; and our metaphorical use of language is a reflection of this process. Given its ubiquity, metaphorical language poses an important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010). A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical. They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word em"
D17-1162,D14-1005,1,0.818881,"to the traditional ”single-sense” compositional distributional model. They then used these representations in the metaphor identification task, achieving promising results. The more recent approaches of Shutova et al. (2016) and Bulat et al. (2017) used dense skipgram word embeddings (Mikolov et al., 2013a) instead of the sparse distributional features. Shutova et al. (2016) investigated a set of metaphor identification methods using linguistic and visual features. They learned linguistic and visual representations for both words and phrases, using skipgram and convolutional neural networks (Kiela and Bottou, 2014) respectively. They then measured the difference between the phrase representation and those of its component words in terms of their cosine similarity, which served as a predictor of metaphoricity. They found basic cosine similarity between the component words in the phrase to be a powerful measure – the neural embeddings of the words were compared with cosine similar1538 Figure 1: The network architecture for supervised metaphorical phrase classification. The symbol is used to indicate element-wise multiplication. ity and a threshold was tuned on the development set to distinguish between li"
D17-1162,S16-2003,1,0.553565,"Missing"
D17-1162,N16-1020,1,0.690494,"nd higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016). Their experiments have demonstrated that corpus-driven lexical representations already encode information about semantic domains needed to learn the patterns of metaphor usage from linguistic data. We take this intuition a step further and present the first deep learning architecture designed to capture metaphorical composition. Deep learning methods have already been shown successful in many other semantic tasks (e.g. Hermann et al., 2015; Kumar et al., 2015; Zhao et al., 2015), which suggests that designing a specialised neural network architecture for metaphor detection will lead to impro"
D17-1162,N13-1118,1,0.956289,"al and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016). Their experiments have demonstrated that corpus-driven lexical representations already encode information about semantic domains needed to learn the patterns of metaphor usage from linguistic data. We take this intuition a step further and present the first deep learning architecture designed to capture metaphorical composition. Deep learning methods have already been shown successful in many other semantic tasks (e.g. Hermann et al., 2015; Kumar et al., 2015; Zhao et al., 2015), which suggests that designing a s"
D17-1162,C10-1113,1,0.957575,"tures, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016). Their experiments have demonstrated that corpus-driven lexical representations already encode information about semantic domains needed to learn the patterns of metaphor usage from linguistic data. We take this intuition a step further and present the first deep learning architecture designed to capture metaphorical composition. Deep learning methods have already been shown successful in many other semantic tasks (e.g. Hermann et al., 2015; Kumar et al., 2015; Zhao et al., 2015), which sug"
D17-1162,shutova-teufel-2010-metaphor,1,0.874656,"ns between two distinct concepts or domains. For instance, when we talk about “curing juvenile delinquency” or “corruption transmitting through the government ranks”, we view the general concept of crime (the target concept) in terms of the properties of a disease (the source concept). Such metaphorical associations are broad generalisations that allow us to project knowledge and inferences across domains; and our metaphorical use of language is a reflection of this process. Given its ubiquity, metaphorical language poses an important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010). A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical. They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-eng"
D17-1162,W13-0909,0,0.0517548,"s. Given its ubiquity, metaphorical language poses an important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010). A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical. They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016). Their experiments have demonstrated that corpus-driven lexical representations already encode information about semantic domains needed to learn the patt"
D17-1162,P14-1024,0,0.734219,"n important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010). A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical. They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016). Their experiments have demonstrated that corpus-driven lexical representations already encode information about semantic domains needed to learn the patterns of metaphor usage from linguistic data. We"
D17-1162,D11-1063,0,0.371488,"guage is a reflection of this process. Given its ubiquity, metaphorical language poses an important problem for natural language understanding (Cameron, 2003; Shutova and Teufel, 2010). A number of approaches to metaphor processing have thus been proposed, focusing predominantly on classifying linguistic expressions as literal or metaphorical. They experimented with a range of features, including lexical and syntactic information (Hovy et al., 2013; Beigman Klebanov et al., 2016) and higher-level features such as semantic roles (Gedigian et al., 2006), domain types (Dunn, 2013), concreteness (Turney et al., 2011), imageability (Strzalkowski et al., 2013) and WordNet supersenses (Tsvetkov et al., 2014). While reporting promising results, all of these approaches used hand-engineered features and relied on manually-annotated resources to extract them. In order to reduce the reliance on manual annotation, other researchers experimented with sparse distributional features (Shutova et al., 2010; Shutova and Sun, 2013) and dense neural word embeddings (Bracewell et al., 2014; Shutova et al., 2016). Their experiments have demonstrated that corpus-driven lexical representations already encode information about"
D17-1162,W13-0904,0,0.0694063,"nd event status ( PROCESS , STATE , OBJECT ). Tsvetkov et al. (2014) used random forest classifier and coarse semantic features, such as concreteness, animateness, named entity types and WordNet supersenses. They have shown that the model learned with such coarse semantic features is portable across languages. The work of Hovy et al. (2013) is notable as they focused on compositional rather than categorical features. They trained an SVM with dependency-tree kernels to capture compositional information, using lexical, part-of-speech tag and WordNet supersense representations of sentence trees. Mohler et al. (2013) aimed at modelling conceptual information. They derived semantic signatures of texts as sets of highly-related and interlinked WordNet synsets. The semantic signatures served as features to train a set of classifiers (maximum entropy, decision trees, SVM, random forest) that mapped new metaphors to the semantic signatures of the known ones. With the aim of reducing the dependence on manually-annotated lexical resources, other research focused on modelling metaphor using corpus-driven information alone. Shutova et al. (2010) pointed out that the metaphorical uses of words constitute a large po"
D17-1162,W14-1608,1,0.811713,"using annotated metaphor examples, resulting in word representations that are more suitable for this task. Furthermore, the adjectives and nouns use separate mapping weights, which allows the model to better distinguish between the different functionalities of these words. In contrast, the original cosine similarity is not position-specific and would give the same result regardless of the word order. 3.3 Metaphorical absorb cost attack problem attack cancer breathe life design excuse deflate economy leak news swallow anger Table 1: Annotated verb-direct object and verbsubject pairs from MOH. Rei and Briscoe (2014) used a fixed formula to calculate weights for different dimensions of cosine similarity and showed that it helped in recovering hyponym relations. We extend this even further and allow the network to use multiple different weighting strategies which are all optimised during training. This is done by first creating a vector m, which is an element-wise multiplication of the two word representations: mi = z1,i z2,i d = γ(Wd m) If the vectors x1 and x2 are normalised to unit length, the cosine similarity between them is equal to their dot product, which in turn is equal to their elementwise multi"
E17-2084,W15-0107,1,0.825793,"n concept representation relies on salient attributes or properties1 (Tyler et al., 2000; Randall et al., 2004). Property norm datasets (McRae et al., 2005; Devereux et al., 2013) are constructed by asking human participants to identify the most important attributes of a concept (see Table 1) and are widely used to test models of conceptual representation (McRae et al., 1997; Randall et al., 2004; Cree et al., 2006; Tyler et al., 2000; Grondin et al., 2009). Yet, to the best of our knowledge, such property norms have not been investigated in the context of metaphor processing. Recent studies (Fagarasan et al., 2015; Bulat et al., 2016) have shown that wide-coverage property-norm based semantic representations can be automatically constructed using cross-modal maps and that these perform comparably to dense semantic representations (Mikolov et al., 2013) One of the key problems in computational metaphor modelling is finding the optimal level of abstraction of semantic representations, such that these are able to capture and generalise metaphorical mechanisms. In this paper we present the first metaphor identification method that uses representations constructed from property norms. Such norms have been p"
E17-2084,W13-0908,0,0.0966211,"Missing"
E17-2084,C10-1113,1,0.895153,"ut the paper we will be using the terms properties and attributes interchangeably. 523 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 523–528, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics SHOES has_heels, 15 has_laces, 13 worn_on_feet, 13 ANT an_insect, 18 is_small, 18 is_black 15 cepts in terms of more concrete or physical experiences. They developed a method to automatically measure concreteness of words and applied it to identify verbal and adjectival metaphors. Shutova et al. (2010) pointed out that the metaphorical uses of words constitute a large portion of the dependency features extracted for abstract concepts from corpora. As a result, distributional clustering of abstract nouns with such features identifies groups of diverse concepts metaphorically associated with the same source domain. Shutova et al. (2010) exploit this property of co-occurrence vectors to identify new metaphorical mappings starting from a set of examples. Shutova and Sun (2013) used hierarchical clustering to derive a network of concepts in which metaphorical associations are learned in an unsup"
E17-2084,W13-0907,0,0.366933,"m entropy classifier and the verbs’ nominal arguments and their semantic roles as features. Dunn (2013) used a logistic regression classifier and high-level properties of concepts extracted from the SUMO ontology, including domain types (ABSTRACT, PHYSICAL , SOCIAL , MENTAL ) and event status (PROCESS , STATE , OBJECT). Tsvetkov et al. (2013) also used logistic regression and coarse semantic features, such as concreteness, animateness, named entity types and WordNet supersenses. They have shown that the model learned with such coarse semantic features is portable across languages. The work of Hovy et al. (2013) is notable as they focused on compositional features. They trained an SVM with dependency-tree kernels to capture compositional information, using lexical, part-of-speech tag and WordNet supersense representations of parse trees. Mohler et al. (2013) derived semantic signatures of texts as sets of highly-related and interlinked WordNet synsets. The semantic signatures served as features to train a set of classifiers (maximum entropy, decision trees, SVM, random forest) that map new metaphors to the semantic signatures of the known ones. Turney et al. (2011) hypothesized that metaphor is commo"
E17-2084,N16-1020,1,0.812966,"sets of highly-related and interlinked WordNet synsets. The semantic signatures served as features to train a set of classifiers (maximum entropy, decision trees, SVM, random forest) that map new metaphors to the semantic signatures of the known ones. Turney et al. (2011) hypothesized that metaphor is commonly used to describe abstract conMethod Learning dense linguistic representations We construct two types of linguistic representations: context-predicting – based on the skip-gram model of Mikolov et al. (2013) – and contextcounting. We employ 100-dimensional word embeddings constructed by Shutova et al. (2016) from Wikipedia using the standard log-linear skipgram model with negative sampling of Mikolov et al. (2013). The embeddings were trained using a symmetric window of 5 words either side of the target word, 10 negative samples per word-context pair and number of epochs set to 3. EMBED SVD We use Wikipedia to build count-based distributional vectors, using the top 10K most frequent lemmatised words (excluding stopwords) as contexts. Context windows are defined as sentence boundaries and counts are re-weighted using positive pointwise mutual information (PPMI). We obtain 100-dimensional dense sem"
E17-2084,W13-0906,0,0.533176,"odel of cross-domain property projection in metaphorical language. 2 3 Related work 3.1 Much previous research on metaphor processing casts the problem as classification of linguistic expressions as metaphorical or literal. Gedigian et al. (2006) classified verbs using a maximum entropy classifier and the verbs’ nominal arguments and their semantic roles as features. Dunn (2013) used a logistic regression classifier and high-level properties of concepts extracted from the SUMO ontology, including domain types (ABSTRACT, PHYSICAL , SOCIAL , MENTAL ) and event status (PROCESS , STATE , OBJECT). Tsvetkov et al. (2013) also used logistic regression and coarse semantic features, such as concreteness, animateness, named entity types and WordNet supersenses. They have shown that the model learned with such coarse semantic features is portable across languages. The work of Hovy et al. (2013) is notable as they focused on compositional features. They trained an SVM with dependency-tree kernels to capture compositional information, using lexical, part-of-speech tag and WordNet supersense representations of parse trees. Mohler et al. (2013) derived semantic signatures of texts as sets of highly-related and interli"
E17-2084,P14-1024,0,0.63249,". 3.3 Metaphor classification We compare the performance of the aforementioned semantic representations (SVD, EMBED, ATTR - SVD and ATTR - EMBED ) on a metaphor classification task, in order to test our hypothesis as to whether attribute-based semantic representations provide better concept generalisations for metaphor modelling than the widely-used dense linguistic representations. We use an SVM (Joachims, 1998) to perform the classification3 . 4 4.1 Experiments Experimental data We evaluate our method using the dataset of adjective–noun pairs manually annotated for metaphoricity, created by Tsvetkov et al. (2014). This corpus was created by extracting the nouns that co-occur with a list of 1000 frequent adjectives in the TenTen Web Corpus4 using SketchEngine and in collections of metaphor on the Web. The data is divided into a training set (TSV- TRAIN) and test set (TSV- TEST). TSV- TRAIN contains 884 literal and 884 metaphorical pairs annotated for metaphoricity. TSV- TEST contains 100 literal and 100 metaphorical pairs, annotated by 5 annotators with an inter-annotator agreement of κ = 0.76. Table 3 shows a portion of the test set. Metaphorical phrases that depend on wider context for their interpre"
E17-2084,W13-0904,0,0.147262,"HYSICAL , SOCIAL , MENTAL ) and event status (PROCESS , STATE , OBJECT). Tsvetkov et al. (2013) also used logistic regression and coarse semantic features, such as concreteness, animateness, named entity types and WordNet supersenses. They have shown that the model learned with such coarse semantic features is portable across languages. The work of Hovy et al. (2013) is notable as they focused on compositional features. They trained an SVM with dependency-tree kernels to capture compositional information, using lexical, part-of-speech tag and WordNet supersense representations of parse trees. Mohler et al. (2013) derived semantic signatures of texts as sets of highly-related and interlinked WordNet synsets. The semantic signatures served as features to train a set of classifiers (maximum entropy, decision trees, SVM, random forest) that map new metaphors to the semantic signatures of the known ones. Turney et al. (2011) hypothesized that metaphor is commonly used to describe abstract conMethod Learning dense linguistic representations We construct two types of linguistic representations: context-predicting – based on the skip-gram model of Mikolov et al. (2013) – and contextcounting. We employ 100-dim"
E17-2084,D11-1063,0,0.450583,"ortable across languages. The work of Hovy et al. (2013) is notable as they focused on compositional features. They trained an SVM with dependency-tree kernels to capture compositional information, using lexical, part-of-speech tag and WordNet supersense representations of parse trees. Mohler et al. (2013) derived semantic signatures of texts as sets of highly-related and interlinked WordNet synsets. The semantic signatures served as features to train a set of classifiers (maximum entropy, decision trees, SVM, random forest) that map new metaphors to the semantic signatures of the known ones. Turney et al. (2011) hypothesized that metaphor is commonly used to describe abstract conMethod Learning dense linguistic representations We construct two types of linguistic representations: context-predicting – based on the skip-gram model of Mikolov et al. (2013) – and contextcounting. We employ 100-dimensional word embeddings constructed by Shutova et al. (2016) from Wikipedia using the standard log-linear skipgram model with negative sampling of Mikolov et al. (2013). The embeddings were trained using a symmetric window of 5 words either side of the target word, 10 negative samples per word-context pair and"
E17-2084,N13-1118,1,0.900525,"oped a method to automatically measure concreteness of words and applied it to identify verbal and adjectival metaphors. Shutova et al. (2010) pointed out that the metaphorical uses of words constitute a large portion of the dependency features extracted for abstract concepts from corpora. As a result, distributional clustering of abstract nouns with such features identifies groups of diverse concepts metaphorically associated with the same source domain. Shutova et al. (2010) exploit this property of co-occurrence vectors to identify new metaphorical mappings starting from a set of examples. Shutova and Sun (2013) used hierarchical clustering to derive a network of concepts in which metaphorical associations are learned in an unsupervised way. DISHWASHER an_appliance, 19 requires_soap, 15 is_electrical, 14 Table 1: Examples of properties from McRae et al. (2005) together with their production frequencies on standard word similarity tasks. In this paper we hypothesise that such attribute-based representations provide a suitable means for generalisation over the source and target domains in metaphorical language and test this hypothesis. Our results show that these property-based representations can perf"
E17-2084,shutova-teufel-2010-metaphor,1,0.789164,"ratory University of Cambridge es407@cam.ac.uk Introduction According to the Conceptual Metaphor Theory (Lakoff and Johnson, 1980), metaphors are not merely a linguistic, but also a cognitive phenomenon. They arise when one concept (or conceptual domain) can be understood in terms of the properties of another. For example, we interpret the metaphorical expression “He shot down my argument” by projecting our knowledge about battles (the source domain) onto our reasoning about arguments (the target domain). Multiple studies have established the prevalence of metaphor in language (Cameron, 2003; Shutova and Teufel, 2010) and confirmed the key role that it plays in human reasoning (Thibodeau and Boroditsky, 2011). These findings make computational processing of metaphor essential for any NLP application that is focused on semantics, from machine translation (Shutova, 2011) to 1 Throughout the paper we will be using the terms properties and attributes interchangeably. 523 Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 523–528, c Valencia, Spain, April 3-7, 2017. 2017 Association for Computational Linguistics SHOES has_he"
E17-2084,C08-2001,0,\N,Missing
E17-2084,W06-3506,0,\N,Missing
E17-2084,N16-1071,1,\N,Missing
J13-2003,P10-1024,0,0.0334597,"Missing"
J13-2003,W03-1402,0,0.011637,"General-domain lexical resources often include information about metaphorical word senses, although unsystematically and without any accompanying semantic annotation. For example, WordNet2 (Fellbaum 1998) contains the comprehension sense of grasp, deﬁned as “get the meaning of something,” and the reading sense of skim, deﬁned as “read superﬁcially.” A great deal of metaphorical senses are absent from the current version of WordNet, however. A number of researchers have advocated the necessity of systematic inclusion and mark-up of metaphorical senses in such general¨ domain lexical resources (Alonge and Castelli 2003; Lonneker and Eilts 2004) and claim that this would be beneﬁcial for the computational modeling of metaphor. Metaphor processing systems could then either use this knowledge or be evaluated against it. ¨ Lonneker (2004) mapped the senses from EuroWordNet3 to the Hamburg Metaphor ¨ ¨ Database (Lonneker 2004; Reining and Lonneker-Rodman 2007) containing examples of metaphorical expressions in German and French. Currently no explicit information about metaphor is integrated into WordNet for English, however. Although consistent inclusion in WordNet is in principle possible for conventional metap"
J13-2003,andersen-etal-2008-bnc,0,0.0860829,"Missing"
J13-2003,N03-1003,0,0.0247979,"Missing"
J13-2003,P01-1008,0,0.111162,"Missing"
J13-2003,D08-1007,0,0.382018,"Missing"
J13-2003,E06-1042,0,0.245004,"Missing"
J13-2003,W02-1016,0,0.208896,"Missing"
J13-2003,P06-4020,0,0.335837,"Missing"
J13-2003,E03-1034,0,0.184107,"Missing"
J13-2003,N06-1003,0,0.0359736,"Missing"
J13-2003,E99-1042,0,0.140698,"Missing"
J13-2003,P06-2012,0,0.147165,"Missing"
J13-2003,J90-1003,0,0.263128,"Missing"
J13-2003,J07-4004,0,0.0410609,"Missing"
J13-2003,W09-1108,0,0.0380368,"Missing"
J13-2003,W09-1109,0,0.0249527,"Missing"
J13-2003,D09-1046,0,0.0183457,"Missing"
J13-2003,J91-1003,0,0.724298,"solving non-literal meanings via analogical comparisons, the development of a complete and computationally practical account of this phenomenon is a challenging and complex task. Despite the importance of metaphor for NLP systems dealing with semantic interpretation, its automatic processing has received little attention in contemporary NLP, and is far from being a solved problem. The majority of computational approaches to metaphor still exploit ideas articulated two or three decades ago (Wilks 1978; Lakoff and Johnson 1980). They often rely on task-speciﬁc hand-coded knowledge (Martin 1990; Fass 1991; Narayanan 1997, 1999; Barnden and Lee 2002; Feldman and Narayanan 2004; Agerri et al. 2007) and reduce the task to reasoning about a limited domain or a subset of phenomena (Gedigian et al. 2006; Krishnakumaran and Zhu 2007). So far there has been no robust statistical system operating on unrestricted text. State-of-the-art accurate parsing (Klein and Manning 2003; Briscoe, Carroll, and Watson 2006; Clark and Curran 2007), however, as well as recent work on computational lexical semantics (Schulte im Walde 2006; 303 Computational Linguistics Volume 39, Number 2 Mitchell and Lapata 2008; Davi"
J13-2003,J83-3004,0,0.520817,"given context. Selectional restrictions are the semantic constraints that a predicate places onto its arguments. Consider the following example. (17) a. My aunt always drinks her tea on the terrace. b. My car drinks gasoline. (Wilks 1978) The verb drink normally requires a grammatical subject of type ANIMATE and a grammatical object of type LIQUID, as in Example (17a). Therefore, drink taking a car as a subject in (17b) is an anomaly, which, according to Wilks, indicates a metaphorical use of drink. Although Wilks’s idea inspired a number of computational experiments on metaphor recognition (Fass and Wilks 1983; Fass 1991; Krishnakumaran and Zhu 2007), it is important to note that in practice this approach has a number of limitations. Firstly, there are other kinds of non-literalness or anomaly in language that cause a violation of semantic norm, such as metonymies. Thus the method would overgenerate. Secondly, there are kinds of metaphor that do not represent a violation of selectional restrictions (i.e., the approach may also undergenerate). This would happen, for example, when highly conventionalized metaphorical word senses are more frequent than the original literal senses. Due to their frequen"
J13-2003,W06-3506,0,0.716069,"e the importance of metaphor for NLP systems dealing with semantic interpretation, its automatic processing has received little attention in contemporary NLP, and is far from being a solved problem. The majority of computational approaches to metaphor still exploit ideas articulated two or three decades ago (Wilks 1978; Lakoff and Johnson 1980). They often rely on task-speciﬁc hand-coded knowledge (Martin 1990; Fass 1991; Narayanan 1997, 1999; Barnden and Lee 2002; Feldman and Narayanan 2004; Agerri et al. 2007) and reduce the task to reasoning about a limited domain or a subset of phenomena (Gedigian et al. 2006; Krishnakumaran and Zhu 2007). So far there has been no robust statistical system operating on unrestricted text. State-of-the-art accurate parsing (Klein and Manning 2003; Briscoe, Carroll, and Watson 2006; Clark and Curran 2007), however, as well as recent work on computational lexical semantics (Schulte im Walde 2006; 303 Computational Linguistics Volume 39, Number 2 Mitchell and Lapata 2008; Davidov, Reichart, and Rappoport 2009; Erk and McCarthy ´ S´eaghdha 2010) open up 2009; Sun and Korhonen 2009; Abend and Rappoport 2010; O many avenues for the creation of such a system. This is the n"
J13-2003,P93-1023,0,0.193506,"Missing"
J13-2003,W09-2905,0,0.0174715,"Missing"
J13-2003,J98-1002,0,0.203057,"Missing"
J13-2003,N06-1058,0,0.0156241,"Missing"
J13-2003,kingsbury-palmer-2002-treebank,0,0.530837,"Missing"
J13-2003,P03-1054,0,0.0074496,"Missing"
J13-2003,N10-1017,0,0.0115698,"Missing"
J13-2003,korhonen-etal-2006-large,1,0.429092,"Missing"
J13-2003,W03-1601,0,0.0832078,"Missing"
J13-2003,W07-0103,0,0.857218,"taphor for NLP systems dealing with semantic interpretation, its automatic processing has received little attention in contemporary NLP, and is far from being a solved problem. The majority of computational approaches to metaphor still exploit ideas articulated two or three decades ago (Wilks 1978; Lakoff and Johnson 1980). They often rely on task-speciﬁc hand-coded knowledge (Martin 1990; Fass 1991; Narayanan 1997, 1999; Barnden and Lee 2002; Feldman and Narayanan 2004; Agerri et al. 2007) and reduce the task to reasoning about a limited domain or a subset of phenomena (Gedigian et al. 2006; Krishnakumaran and Zhu 2007). So far there has been no robust statistical system operating on unrestricted text. State-of-the-art accurate parsing (Klein and Manning 2003; Briscoe, Carroll, and Watson 2006; Clark and Curran 2007), however, as well as recent work on computational lexical semantics (Schulte im Walde 2006; 303 Computational Linguistics Volume 39, Number 2 Mitchell and Lapata 2008; Davidov, Reichart, and Rappoport 2009; Erk and McCarthy ´ S´eaghdha 2010) open up 2009; Sun and Korhonen 2009; Abend and Rappoport 2010; O many avenues for the creation of such a system. This is the niche the presented work is int"
J13-2003,S01-1009,0,0.016863,"Missing"
J13-2003,P98-2127,0,0.122342,"Missing"
J13-2003,C88-1081,0,0.672595,"B3 0FD, UK. E-mail: {Ekaterina.Shutova, Simone.Teufel, Anna.Korhonen}@cl.cam.ac.uk. Submission received: 28 July 2011; revised submission received: 21 April 2012; accepted for publication: 31 May 2012. doi:10.1162/COLI a 00124 © 2013 Association for Computational Linguistics Computational Linguistics Volume 39, Number 2 Metaphors arise when one concept is viewed in terms of the properties of another. Humans often use metaphor to describe abstract concepts through reference to more concrete or physical experiences. Some examples of metaphor include the following. (1) How can I kill a process? (Martin 1988) (2) Hillary brushed aside the accusations. (3) I invested myself fully in this research. (4) And then my heart with pleasure ﬁlls, And dances with the daffodils. (“I wandered lonely as a cloud,” William Wordsworth, 1804) Metaphorical expressions may take a great variety of forms, ranging from conventional metaphors, which we produce and comprehend every day, for example, those in Examples (1)–(3), to poetic and novel ones, such as Example (4). In metaphorical expressions, seemingly unrelated features of one concept are attributed to another concept. In Example (1), a computational process is"
J13-2003,J04-1002,0,0.937327,"but also those of nouns and adjectives. As opposed to previous approaches that modeled metaphorical reasoning starting from a hand-crafted description and applying it to explain the data, we aim to design a statistical model that captures regular patterns of metaphoricity in a large corpus and thus generalizes to unseen examples. Compared to labor-intensive manual efforts, this approach is more robust and, being nearly unsupervised, cost-effective. In contrast to previous statistical approaches, which addressed metaphors of a speciﬁc topic or did not consider linguistic metaphor at all (e.g., Mason 2004), the proposed method covers all metaphors in principle, can be applied to unrestricted text, and can be adapted to different domains and genres. 306 Shutova, Teufel, and Korhonen Statistical Metaphor Processing Our ﬁrst experiment is concerned with the identiﬁcation of metaphorical expressions in unrestricted text. Starting from a small set of metaphorical expressions, the system learns the analogies involved in their production in a minimally supervised way. It generalizes over the exempliﬁed analogies by means of verb and noun clustering (i.e., the identiﬁcation of groups of similar concept"
J13-2003,W02-0816,0,0.0401881,"Missing"
J13-2003,S07-1009,0,0.0372132,"Missing"
J13-2003,P79-1016,0,0.200731,"Missing"
J13-2003,C88-2088,0,0.631192,"Missing"
J13-2003,P08-1028,0,0.0173268,"Missing"
J13-2003,T87-1040,0,0.278653,"hrasing gold standard by asking human subjects (not previously exposed to system output) to produce their own literal paraphrases for metaphorical verbs. The system paraphrasing was then also evaluated against this gold standard. 2. Theoretical and Computational Background 2.1 Metaphor and Polysemy Theorists of metaphor distinguish between two kinds of metaphorical language: novel (or poetic) metaphors (i.e., those that are imaginative), and conventionalized metaphors 307 Computational Linguistics Volume 39, Number 2 (i.e., those that are used as a part of an ordinary discourse). According to Nunberg (1987), all metaphors emerge as novel, but over time they become part of general usage and their rhetorical effect vanishes, resulting in conventionalized metaphors. Following Orwell (1946), Nunberg calls such metaphors “dead” and claims that they are not psychologically distinct from literally used terms. The scheme described by Nunberg demonstrates how metaphorical associations capture patterns governing polysemy, namely, the capacity of a word to have multiple meanings. Over time some of the aspects of the target domain are added to the meaning of a term in the source domain, resulting in a (meta"
J13-2003,P10-1045,0,0.109223,"Missing"
J13-2003,P93-1024,0,0.173268,"Missing"
J13-2003,peters-peters-2000-lexicalised,0,0.461657,"Missing"
J13-2003,I05-5010,0,0.0684057,"Missing"
J13-2003,P07-1115,1,0.843382,"Missing"
J13-2003,W09-4204,0,0.0354842,"Missing"
J13-2003,W04-3219,0,0.100268,"Missing"
J13-2003,W07-0102,0,0.288064,"Missing"
J13-2003,D10-1114,0,0.0232497,"Missing"
J13-2003,P99-1014,0,0.479383,"Missing"
J13-2003,P10-1093,0,0.0529917,"Missing"
J13-2003,J06-2001,0,0.0415072,"Missing"
J13-2003,W03-1609,0,0.0627777,"Missing"
J13-2003,N10-1147,1,0.808786,"Missing"
J13-2003,C10-1113,1,0.830833,"Missing"
J13-2003,shutova-teufel-2010-metaphor,1,0.842088,"associated with the act of killing. In Example (2) Hillary is not literally cleaning the space by sweeping accusations. Instead, the accusations lose their validity in that situation, in other words Hillary rejects them. The verbs brush aside and reject both entail the resulting disappearance of their object, which is the shared salient property that makes it possible for this analogy to be lexically expressed as a metaphor. Characteristic of all areas of human activity (from poetic to ordinary to scientiﬁc) and thus of all types of discourse, metaphor becomes an important problem for NLP. As Shutova and Teufel (2010) have shown in an empirical study, the use of conventional metaphor is ubiquitous in natural language text (according to their data, on average every third sentence in general-domain text contains a metaphorical expression). This makes metaphor processing essential for automatic text understanding. For example, an NLP application which is unaware that a “leaked report” is a “disclosed report” and not, for example, a “wet report,” would fail further semantic processing of the piece of discourse in which this phrase appears. A system capable of recognizing and interpreting metaphorical expressio"
J13-2003,D09-1067,1,0.593576,"Missing"
J13-2003,D11-1095,1,0.868196,"Missing"
J13-2003,D11-1094,1,0.352036,"Missing"
J13-2003,C08-1119,0,0.183734,"Missing"
J13-2003,P09-2019,0,0.0327936,"Missing"
J13-2003,P08-1089,0,0.0260576,"Missing"
J13-2003,P09-1094,0,0.02327,"Missing"
J13-2003,N06-1057,0,0.0107955,"Missing"
J13-2003,W09-0208,0,\N,Missing
J13-2003,C98-2122,0,\N,Missing
J15-4002,C08-2001,0,0.0111416,"ted via established techniques (e.g., word sense disambiguation), and their metaphorical nature may or may not be of interest to wider NLP. Whether metaphor processing systems should address highly conventional and dead metaphors depends on the task and application in mind, and corpus annotation should reflect this task definition in a consistent way. As the field moves forward, it would also be desirable to conduct extrinsic evaluations of the metaphor processing systems, in order to determine their usefulness for external NLP applications. One such experiment has already been carried out by Agerri (2008), who has demonstrated that metaphor interpretation plays an important role in textual entailment resolution. 8. Conclusion Metaphor makes our thoughts move vivid and enriches our communication with novel imagery, but most importantly it plays a fundamental structural role in our cognition, helping us organize and project knowledge. As a result, its manifestations are pervasive in language and reasoning, making its computational processing an imperative task within NLP and intelligent systems engineering at large. Despite involving complex comparisons and information transfers, metaphor is a w"
J15-4002,S07-1002,0,0.0487486,"Missing"
J15-4002,W08-2227,0,0.0143114,"Missing"
J15-4002,W13-0910,0,0.0815849,"nnotators (strongly relying on dictionary definitions) and report an interannotator agreement of 0.85 in terms of Fleiss’ kappa. MIP laid the basis for the creation of the VU Amsterdam Metaphor Corpus1 (Steen et al. 2010). This corpus is a subset of BNC Baby2 annotated for linguistic metaphor. Its size is 200,000 words and it comprises four genres: news text, academic text, fiction, and conversations. The corpus has already found application in computational metaphor processing research (Dunn 2013b; Niculae and Yaneva 2013), as well as inspiring metaphor annotation efforts in other languages (Badryzlova et al. 2013). The study of Shutova and Teufel (2010) was concerned with annotation of both metaphorical expressions and metaphorical mappings in continuous text. Their annotation procedure is based on MIP, modifying and extending it to the identification of conceptual metaphors along with the linguistic ones. Following MIP, the annotators were asked to identify the more basic sense of the word, and then label the context in which the word occurs in the basic sense as the source domain, and the current context as the target. They were provided with a list of suggested common source 1 http://www.ota.ox.ac.u"
J15-4002,P10-1072,0,0.28355,"Missing"
J15-4002,W13-0902,0,0.144004,"Missing"
J15-4002,E06-1042,0,0.0880886,"argo of gravy, towards a destination neither wished for nor understood by electorates. But the train can be stopped.” (Margaret Thatcher, Sunday Times, 20 Sept 1992) Metaphorical inference: The fact that expensive tracks have to be laid for the train to move forward means that someone has to fund the process of European integration. 581 Computational Linguistics Volume 41, Number 4 2.1.1 Linguistic metaphor. Linguistic metaphor, or metaphorical expressions, concern the surface realization of metaphorical mechanisms, and have been unsurprisingly central to metaphor processing research to date (Birke and Sarkar 2006; Gedigian et al. 2006; Krishnakumaran and Zhu 2007; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Gandy et al. 2013; Heintz et al. 2013; Hovy et al. 2013; Neuman et al. 2013; Shutova 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013). Metaphorical expressions represent the way in which text-processing systems encounter metaphor, and there is little doubt that any real-world metaphor processing system, whatever the approach or the application, ultimately needs to be able to identify and interpret them. When focusing on linguistic metaphor, one needs to fur"
J15-4002,W13-1501,0,0.0480919,"cultural and crosspopulation differences, and thus become a useful tool in data mining. In social science, metaphor is extensively studied as a way to frame cultural and moral models, and to predict social choice (Landau, Sullivan, and Greenberg 2009; Thibodeau and Boroditsky 2011; Lakoff and Wehling 2012). Metaphor is also widely viewed as a creative tool. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). The design of the metaphor processing task should thus be informed by the possible applications. The application in mind may place particular requirements on the types of metaphor the system needs to address and the output representations it is expected to produce. Whereas an NLP application, such as machine translation, would be primarily concerned with linguistic metaphors and, possibly, the more creative instances thereof, a data mining application, aiming to detect a set of trends, may find the identification of conceptual metaphors prominent in the data more informative. The formulation"
J15-4002,O05-5012,0,0.0533904,"Missing"
J15-4002,W13-0901,0,0.529097,"of Metaphor Processing Systems prominent ones include selectional preferences (Martin 1990; Fass 1991; Mason 2004; Krishnakumaran and Zhu 2007; Li and Sporleder 2009, 2010; Shutova 2010; Shutova, Sun, and Korhonen 2010; Hovy et al. 2013; Li, Zhu, and Wang 2013; Wilks et al. 2013); semantic properties of concepts, such as imageability and concreteness (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013); and topical structure of text (Heintz et al. 2013; Strzalkowski et al. 2013). The common methods used include supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013); clustering (Gandy et al. 2013; Shutova and Sun 2013; Shutova, Sun, and Korhonen 2010; Strzalkowski et al. 2013); vector space models (Shutova, Van de Cruys, and Korhonen 2012); the use of lexical resources and ontologies (Mason 2004; Krishnakumaran and Zhu 2007; Dunn 2013b; Gandy et al. 2013; Hovy et al. 2013; Mohler et al. 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Wilks et al. 2013); and Web search (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). A summary of te"
J15-4002,J91-1003,0,0.130512,"13; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with very few focusing on the conceptual level (Mason 2004; Baumer, Tomlinson, and Richland 2009) or identifying both (Gandy et al. 2013; Li, Zhu, and Wang 2013; Shutova and Sun 2013). This section will first present computational approaches to linguistic metaphor identification, then move on to conceptual metaphor. 4.1 Identification of Linguistic Metaphors 4.1.1 Approaches Using Hand-Coded Knowledge and Lexical Resources. One of the first approaches to identify and interpret metaphorical expressions in text was proposed by Fass (1991) in his met* system. This system relies on the hypothesis that metaphors often represent a violation of selectional preferences in a given context (Wilks 1975, 3 EuroWordNet is a multilingual database with wordnets for several European languages (Dutch, Italian, Spanish, German, French, Czech, and Estonian). The wordnets are structured in the same way as the Princeton WordNet for English. http://www.illc.uva.nl/EuroWordNet/. 590 Shutova Design and Evaluation of Metaphor Processing Systems 1978). Selectional preferences are the semantic constraints that a predicate places onto its arguments. Co"
J15-4002,W06-3506,0,0.0708418,"eval (e.g., documents describing “old school gentlemen” should not be returned for the query school [Korkontzelos et al. 2013]); and many others. Because metaphor interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gers"
J15-4002,C92-2082,0,0.0876066,"Missing"
J15-4002,W13-0908,0,0.103521,"Korkontzelos et al. 2013]); and many others. Because metaphor interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 2013) learning, distributional app"
J15-4002,W13-0907,0,0.0681265,"2013]); and many others. Because metaphor interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 2013) learning, distributional approaches (Shutova 2"
J15-4002,W13-0903,0,0.0158028,"ran and Zhu 2007; Gandy et al. 2013; Li, Zhu, and Wang 2013; Neuman et al. 2013) or other nominal metaphors (Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Strzalkowski et al. 2013). A number of approaches to metaphor identification have also addressed multiword metaphors (Li and Sporleder 2010; Heintz et al. 2013; Hovy et al. 2013; Mohler et al. 2013). Corpus-linguistic research has shown that verbs and adjectives account for a large proportion of metaphorical expressions observed in the data (Cameron 2003; Shutova and Teufel 2010). However, a recent study (Jamrozik et al. 2013) has also shown that relational words tend to have a higher metaphorical potential. This corresponds to the data on verbal metaphor frequency, and it also suggests that relational nouns are important (e.g., “words are friends of translators”). Lexical, relation, or sentence level: Finally, one needs to decide if metaphor should be annotated at the word level (i.e., tagging the source domain words alone), relation level (i.e., tagging both source and target words in a particular grammatical relation), or sentence level (i.e., tagging sentences that contain metaphorical language, without explici"
J15-4002,J98-1002,0,0.106626,"Missing"
J15-4002,kingsbury-palmer-2002-treebank,0,0.310569,"Missing"
J15-4002,S13-2007,0,0.0361694,"terally translated into German as “Argumente abschießen” and metaphor interpretation is required); (2) opinion mining: Metaphorical expressions tend to contain a strong emotional component—for example, compare the metaphorical expression “Government loosened stranglehold on business” and its literal counterpart Government deregulated business (Narayanan 1999); (3) information retrieval (IR): Non-literal language without appropriate disambiguation may lead to false positives in information retrieval (e.g., documents describing “old school gentlemen” should not be returned for the query school [Korkontzelos et al. 2013]); and many others. Because metaphor interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy"
J15-4002,W07-0103,0,0.0978988,"and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 2013) learning, distributional approaches (Shutova 2010, 2013; Shutova, Van de Cruys, and Korhonen 2012), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). Although individual approaches tackling individual aspects of metaphor have met with success, the insights gained from these experiments are still difficult to integrate into a single computational metaphor modeling landscape, because of the lack of a unified task definition, a shared data set, and well-defined evaluation standards. This hampers our progress as a community"
J15-4002,W09-2413,0,0.0180391,"Missing"
J15-4002,Q13-1031,0,0.53953,"Missing"
J15-4002,D09-1033,0,0.131781,"pable of identifying novel metaphor as well (Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Gandy et al. 2013; Heintz et al. 2013; Neuman et al. 2013; Shutova 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with few approaches modeling only novel metaphor (Desalle, Gaume, and Duvignau 2009) or discriminating between conventional and novel metaphors (Krishnakumaran and Zhu 2007). Other approaches have Shutova Design and Evaluation of Metaphor Processing Systems looked at literal versus non-literal distinction defined more broadly (Birke and Sarkar 2006; Li and Sporleder 2009, 2010). r r Syntactic constructions covered: Metaphors vary with respect to how they are expressed in language grammatically. The grammatical structure of metaphorical expressions is tightly coupled with the inference processes that produce them and are guided by the semantic frames they evoke (Sullivan 2007, 2013). According to Sullivan, conceptual metaphors are realized in language via mapping semantic roles in the source frame onto roles in the target frame. This suggests that both the source and the target domain impose a set of constraints on the roles that can be mapped, and thus on the"
J15-4002,N10-1039,0,0.124171,"etaphorical language. However, the community has addressed modeling linguistic metaphor in a range of syntactic constructions. Verbal or adjectival metaphors are particularly widely embraced by NLP researchers (most approaches), with a few works focusing on copula constructions (Krishnakumaran and Zhu 2007; Gandy et al. 2013; Li, Zhu, and Wang 2013; Neuman et al. 2013) or other nominal metaphors (Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Strzalkowski et al. 2013). A number of approaches to metaphor identification have also addressed multiword metaphors (Li and Sporleder 2010; Heintz et al. 2013; Hovy et al. 2013; Mohler et al. 2013). Corpus-linguistic research has shown that verbs and adjectives account for a large proportion of metaphorical expressions observed in the data (Cameron 2003; Shutova and Teufel 2010). However, a recent study (Jamrozik et al. 2013) has also shown that relational words tend to have a higher metaphorical potential. This corresponds to the data on verbal metaphor frequency, and it also suggests that relational nouns are important (e.g., “words are friends of translators”). Lexical, relation, or sentence level: Finally, one needs to decid"
J15-4002,S10-1011,0,0.0201754,"strategy for the task in mind is crucial for the development of fully functional NLP systems. In that light, a number of shared tasks have been proposed over the years at Workshops on Semantic Evaluation (SemEval) that enabled performance comparison across systems and methods. Such tasks as sentiment analysis, word similarity, word sense induction and disambiguation, coreference resolution, lexical substitution, and many others are commonly addressed at SemEval and have a number of benchmark data sets created for them (Agirre and Soroa 2007; McCarthy and Navigli 2007; Lefever and Hoste 2010; Manandhar et al. 2010; Mihalcea, Sinha, and McCarthy 2010; Recasens et al. 2010; Nakov et al. 2013), against which the systems are evaluated and compared. Computational work on metaphor, on the contrary, is considerably more fragmented than similar research efforts in other areas of NLP. With the lack of an established data set, the community has utilized a variety of evaluation strategies, including the use of annotated corpora, human judgments of system output, evaluation against the MML, and annotation of individual selected examples (usually phrases or sentences) via Amazon Mechanical Turk. With a few exceptio"
J15-4002,J04-1002,0,0.0647732,"mation retrieval (e.g., documents describing “old school gentlemen” should not be returned for the query school [Korkontzelos et al. 2013]); and many others. Because metaphor interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvet"
J15-4002,S07-1009,0,0.0198946,"Missing"
J15-4002,S10-1002,0,0.0283743,"Missing"
J15-4002,W13-0904,0,0.062519,"interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 2013) learning, distributional approaches (Shutova 2010, 2013; Shutova, Van de Cruys, and Korhon"
J15-4002,S13-2052,0,0.0219102,"NLP systems. In that light, a number of shared tasks have been proposed over the years at Workshops on Semantic Evaluation (SemEval) that enabled performance comparison across systems and methods. Such tasks as sentiment analysis, word similarity, word sense induction and disambiguation, coreference resolution, lexical substitution, and many others are commonly addressed at SemEval and have a number of benchmark data sets created for them (Agirre and Soroa 2007; McCarthy and Navigli 2007; Lefever and Hoste 2010; Manandhar et al. 2010; Mihalcea, Sinha, and McCarthy 2010; Recasens et al. 2010; Nakov et al. 2013), against which the systems are evaluated and compared. Computational work on metaphor, on the contrary, is considerably more fragmented than similar research efforts in other areas of NLP. With the lack of an established data set, the community has utilized a variety of evaluation strategies, including the use of annotated corpora, human judgments of system output, evaluation against the MML, and annotation of individual selected examples (usually phrases or sentences) via Amazon Mechanical Turk. With a few exceptions, the majority of approaches created their own test sets, making the results"
J15-4002,P13-3013,0,0.110876,"Missing"
J15-4002,T87-1040,0,0.735941,"metaphor annotation needs to be done (word, relation, or sentence level). Thus the following considerations become important for the task and system design: r 582 Level of conventionality of the metaphors accepted: Metaphor is a productive phenomenon, that is, its novel examples continue to emerge in language. However, a large number of metaphorical expressions become conventionalized over time (e.g., “I cannot grasp his way of thinking”). Although metaphorical in nature, their meanings are deeply entrenched in everyday use, and their comprehension is likened to that of literally used terms (Nunberg 1987). According to Gibbs (1984), metaphorical expressions are spread along a continuum from highly conventional, lexicalized metaphors to entirely novel and creative ones. Gibbs thus suggests that there is no clear demarcation line between literal and metaphorical language, and the distinction between them is rather governed by the level of conventionality of metaphorical expressions. From the usage perspective, metaphoricity may be viewed as a gradient phenomenon rather than a binary one (Dunn 2011), and conventionality becomes an important factor in the design and evaluation of metaphor processi"
J15-4002,peters-peters-2000-lexicalised,0,0.0852388,"ring of abstract nouns with such features identifies groups of diverse concepts metaphorically associated with the same source domain (or sets of source domains). Shutova, Sun, and Korhonen exploit this property of co-occurrence vectors to identify new metaphorical mappings starting from a set of examples. The work of Shutova and Sun (2013) is based on the same observation. Through the use of hierarchical clustering techniques they derive a network of concepts in which metaphorical associations are exhibited at different levels of generality. 6.6 The Use of Lexical Resources Peters and Peters (2000) and Wilks et al. (2013) detected metaphor directly in lexical resources. Peters and Peters mine WordNet for examples of systematic polysemy, which allows them to capture metonymic and metaphorical relations. Their system searches for nodes that are relatively high in the WordNet hierarchy (i.e., are relatively general) and that share a set of common word forms among their descendants. Peters and Peters found that such nodes often happen to be in a metonymic (e.g., publisher – publication) or a metaphorical (e.g. theory – supporting structure) relation. Wilks et al. (2013) used WordNet glosses"
J15-4002,S10-1001,0,0.0187949,"Missing"
J15-4002,W07-0102,0,0.0626519,"ear structuring principles of the mapping ontology (Lonneker-Rodman 2008). However, to date MML is the most comprehensive resource for conceptual metaphor in the linguistic literature, and the examples from the list have been used by computational approaches (Mason 2004; Krishnakumaran and Zhu 2007; Li, Zhu, and Wang 2013), both for development and evaluation purposes. The MML also inspired the creation of other resources, including resources in multiple languages that could facilitate cross-linguistic research on metaphor. One such example is the Hamburg ¨ ¨ Metaphor Database (Lonneker 2004; Reining and Lonneker-Rodman 2007), which contains examples of metaphorical expressions in German and French. The expressions are mapped to senses from EuroWordNet3 and annotated with source–target domain mappings taken from the MML. 4. Metaphor Identification Systems Early approaches to metaphor relied on information in handcrafted knowledge bases, followed by metaphor identification in and with the help of lexical resources. Recent years have witnessed a growing interest in statistical and machine learning approaches to metaphor identification. As the field of computational semantics—in particular, robust parsing and lexical"
J15-4002,N10-1147,1,0.0633166,"describing “old school gentlemen” should not be returned for the query school [Korkontzelos et al. 2013]); and many others. Because metaphor interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and"
J15-4002,S13-1040,1,0.853759,"edigian et al. (2006) Krishnakumaran, Zhu (2007) Shutova et al. (2010) Li and Sporleder (2010) Turney et al. (2011) Neuman et al. (2013) Dunn (2013) Tsvetkov et al. (2013; 2014) Mohler et al. (2013) Heintz et al. (2013) Hovy et al. (2013) Wilks et al. (2013) Strzalkowski et al. (2013) Shutova and Sun (2013) – – – – 0.79 – – 0.71 – 0.78 0.56 0.54 0.7 0.57 – 0.65 (LM); 0.69 (CM) 0.76 (LM); 0.65 (CM) 0.65–0.73 0.68 – – – – – – – 0.43–0.97 – 0.79 0.93 0.64 0.8 0.82 – 0.61 (CM) – 0.54 – – – 0.75 0.68∗∗ – 0.58 0.78 0.7 0.59 0.75 0.67 – – 0.82 (LM) 0.52–0.66 0.66 Gandy et al. (2013) Li et al. (2013) Shutova (2013) Lim. Open 0.77 – 0.95∗ 0.58 – 0.78 0.79∗∗ – – – – – 0.75 – 0.71 – – – 4 4 – – – 4 – – 4 4 – 4 4 – 4 4 – – 4 4 4 – 4 4 – – 4 – – 4 – – 4 – 0.58–0.69 0.67 – – – – 4 4 ∗ The results of Gedigian et al. (2006) should be interpreted with a reference to the performance of an all metaphor baseline attaining 0.92. ∗∗ Turney et al. (2011) report results on the verb dataset in terms of F-score and on the adjective dataset in terms of accuracy. LM stands for linguistic metaphor and CM for conceptual metaphor. has been used in multiple metaphor interpretation experiments (Shutova 2010; Shutova, Van de Cru"
J15-4002,N13-1118,1,0.88519,"Missing"
J15-4002,C10-1113,1,0.684168,"Missing"
J15-4002,shutova-teufel-2010-metaphor,1,0.718434,"Missing"
J15-4002,J13-2003,1,0.677178,"Missing"
J15-4002,C12-2109,1,0.921118,"Missing"
J15-4002,W13-0909,0,0.0565863,"mains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 2013) learning, distributional approaches (Shutova 2010, 2013; Shutova, Van de Cruys, and Korhonen 2012), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic featu"
J15-4002,D09-1067,0,0.0618632,"Missing"
J15-4002,P14-1024,0,0.609145,"eteness, animateness, named entity labels, and coarse-grained WordNet categories (corresponding to WN lexicographer files,5 e.g., noun.artifact, noun.body, verb.motion, verb.cognition). They focused on subject–verb–object constructions and annotated metaphor at the sentence level. The authors used a logistic regression classifier and the combination of coarse semantic features for this purpose. They evaluated their model on the TroFi data set (Birke and Sarkar 2006) for English and a self-constructed data set of 140 sentences for Russian, attaining the F-scores of 0.78 and 0.76, respectively. Tsvetkov et al. (2014) extended this experiment to identify adjective–noun metaphors using similar features, as well as porting the model to two further languages (Spanish and Farsi), achieving F-scores in the range of 0.72 to 0.85. The results are encouraging and show that porting coarse-grained semantic knowledge across languages is feasible. However, it should be noted that the generalization to coarse semantic features inevitably only captures shallow behavior of metaphorical expressions in the data and bypasses conceptual information. In reality, as confirmed by corpus-linguistic studies (Charteris-Black and E"
J15-4002,W13-0906,0,0.167775,"Missing"
J15-4002,D11-1063,0,0.0500731,"returned for the query school [Korkontzelos et al. 2013]); and many others. Because metaphor interpretation requires complex analogical comparisons and the projection of inference structures across domains, the task of automatic metaphor processing is challenging. For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Dunn 2013a; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; 580 Shutova Design and Evaluation of Metaphor Processing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 20"
J15-4002,P11-1029,0,0.038816,"political affiliation from text or pinning down cross-cultural and crosspopulation differences, and thus become a useful tool in data mining. In social science, metaphor is extensively studied as a way to frame cultural and moral models, and to predict social choice (Landau, Sullivan, and Greenberg 2009; Thibodeau and Boroditsky 2011; Lakoff and Wehling 2012). Metaphor is also widely viewed as a creative tool. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). The design of the metaphor processing task should thus be informed by the possible applications. The application in mind may place particular requirements on the types of metaphor the system needs to address and the output representations it is expected to produce. Whereas an NLP application, such as machine translation, would be primarily concerned with linguistic metaphors and, possibly, the more creative instances thereof, a data mining application, aiming to detect a set of trends, may find the identification of conceptual"
J15-4002,W14-2307,0,0.0797317,"Missing"
J15-4002,C08-1119,0,0.139258,"acy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 2013) learning, distributional approaches (Shutova 2010, 2013; Shutova, Van de Cruys, and Korhonen 2012), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). Although individual approaches tackling individual aspects of metaphor have met with success, the insights gained from these experiments are still difficult to integrate into a single computational metaphor modeling landscape, because of the lack of a unified task definition, a shared data set, and well-defined evaluation standards. This hampers our progress as a community in this area. In this paper we take a step towards closing this gap: We review the recent work on computational modeling of metaphor, the tasks addressed, the system fea"
J15-4002,W13-0905,0,0.0568268,"rocessing Systems Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013) and unsupervised (Heintz et al. 2013; Shutova and Sun 2013) learning, distributional approaches (Shutova 2010, 2013; Shutova, Van de Cruys, and Korhonen 2012), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). Although individual approaches tackling individual aspects of metaphor have met with success, the insights gained from these experiments are still difficult to integrate into a single computational metaphor modeling landscape, because of the lack of a unified task definition, a shared data set, and well-defined evaluation standards. This hampers our progress as a community in this area. In thi"
J15-4002,W09-2419,0,\N,Missing
J15-4002,W09-2412,0,\N,Missing
J15-4002,P92-1053,0,\N,Missing
J17-1003,W13-0910,0,0.0288987,"exts than the current one. The basic meaning was defined as “more concrete; related to bodily action; more precise (as opposed to vague); historically older” and its identification was guided by dictionary definitions. The resulting VU Amsterdam Metaphor Corpus3 is a 200,000-word subset of the British National Corpus (BNC) (Burnard 2007) annotated for linguistic metaphor. The corpus has already found application in computational metaphor processing research (Dunn 2013b; Niculae and Yaneva 2013; Beigman Klebanov et al. 2014), as well as inspiring metaphor annotation efforts in other languages (Badryzlova et al. 2013). Shutova and Teufel (2010) extended MIP to the identification of conceptual metaphors along with the linguistic ones. Following MIP, the annotators were asked to identify the more basic sense of the word, and then label the context in which the word occurs in the basic sense as the source domain, and the current context as the target. Shutova and Teufel’s corpus is a 13,000word subset of the BNC sampling a range of genres, and it has served as a testbed in a number of computational experiments (Shutova 2010; Shutova, Sun, and Korhonen 2010; Bollegala and Shutova 2013). ¨ Lonneker (2004) inves"
J17-1003,W13-0902,0,0.33906,"Missing"
J17-1003,W14-2302,0,0.63721,"11, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012; Shutova 2013; Mohler et al. 2014), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013),"
J17-1003,D08-1007,0,0.0752149,"Missing"
J17-1003,E06-1042,0,0.630525,"ich has been previously evaluated only on English data, in a multilingual setting. Clustering techniques have also been previously used in metaphor processing research in a more traditional sense (i.e., to identify linguistic expressions with a similar or related meaning). Mason (2004) performed WordNet sense clustering to obtain selectional preference classes, and Mohler et al. (2013) used it to determine similarity between concepts and to link them in semantic signatures. Strzalkowski et al. (2013) and Gandy et al. (2013) clustered metaphorically used terms to form potential source domains. Birke and Sarkar (2006) clustered sentences containing metaphorical and literal uses of verbs. Their core assumption was that all instances of the verb in semantically similar sentences have the same sense, either the literal or the metaphorical one. However, the latter approaches did not investigate how metaphorical associations structure the distributional semantic space, which is what we focus on in this article. 2.2.3 LDA Topic Modeling. Heintz et al. (2013) applied LDA topic modeling (Blei, Ng, and Jordan 2003) to the problem of metaphor identification in experiments with English and Spanish. Their hypothesis w"
J17-1003,W02-1016,0,0.204955,"Missing"
J17-1003,P06-4020,0,0.0345005,"Missing"
J17-1003,E03-1034,0,0.0821577,"r processing component for a real-world application—or, depending on the needs of the application, one may choose a more suitable one. In the future, the models need to be extended to identify not only verb–subject and verb–object metaphors, but also metaphorical expressions in other syntactic constructions (e.g., adjectival or nominal metaphors). Previous distributional clustering and lexical acquisition research has shown that it is possible to model the meanings of a range of word classes using similar techniques (Hatzivassiloglou and McKeown 1993; Boleda Torrent and Alonso i Alemany 2003; Brockmann and Lapata 2003; Zapirain, Agirre, and M`arquez 2009). We thus expect our methods to be equally applicable to metaphorical uses of other word classes and syntactic constructions. For spectral clustering systems, such an extension would require incorporation of adjectival and nominal modifier features in clustering, clustering adjectives, and adding seed expressions representing a variety of syntactic constructions. The extension of HGFC would be more straightforward, only requiring ranking additional adjectival and nominal features that the metaphorically associated clusters in the graph share. The results o"
J17-1003,W13-1501,0,0.0137296,"ultural and cross-population differences, and thus become a useful tool in data mining. In social science, metaphor is extensively studied as a way to frame cultural and moral models, and to predict social choice (Landau, Sullivan, and Greenberg 2009; Thibodeau and Boroditsky 2011; Lakoff and Wehling 2012). Metaphor is also widely viewed as a creative tool. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques"
J17-1003,P06-2012,0,0.0278465,"t introduced in Shutova, Sun, and Korhonen (2010). Our expectation is that clustering by association would allow us to learn numerous new target domains that are associated with the same source domain from the data in a minimally supervised way. Following Shutova, Sun, and Korhonen (2010), we also use clustering techniques to collect source domain vocabulary. We perform verb and noun clustering using the spectral clustering algorithm, which has proven to be effective in lexical acquisition tasks (Brew and Schulte im Walde 2002; Sun and Korhonen 2009) and is suitable for high-dimensional data (Chen et al. 2006). We experiment with its unconstrained and constrained versions. The unconstrained algorithm performs clustering (and thus identifies metaphorical patterns) in a fully unsupervised way, relying on the information contained in the data alone. The constrained version uses a small set of example metaphorical mappings as constraints to reinforce clustering by association. We then investigate to what extent adding metaphorical constraints affects the resulting partition of the semantic space as a whole. Further details of these two methods are provided subsequently. Once the clusters have been crea"
J17-1003,W13-0901,0,0.764338,"a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012; Shutova 2013; Mohler et al. 2014), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search using lexico-syntactic patterns (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). However, even the sta"
J17-1003,J91-1003,0,0.217551,"Missing"
J17-1003,P04-2007,0,0.0376376,"s for the metaphorically connected clusters and searches the corpus for metaphorical expressions describing the target domain concepts, using the verbs from the set of salient features. 5.1 Hierarchical Graph Factorization Clustering In contrast to flat clustering, which produces a partition at one level of generality, the goal of hierarchical clustering is to organize the objects into a hierarchy of clusters with different granularities. Traditional hierarchical clustering methods widely used in NLP (such as agglomerative clustering [Schulte im Walde and Brew 2001; Stevenson and Joanis 2003; Ferrer 2004; Devereux and Costello 2005]) take decisions about cluster membership at the level of individual clusters when these are merged. As Sun and Korhonen (2011) pointed out, such algorithms suffer from two problems—error propagation and local pairwise merging—because the clustering solution is not globally optimized. In addition, they are designed to perform hard clustering of objects at each level, by successively merging the clusters. This makes them unsuitable to model multi-way associations between concepts within the hierarchy, albeit such association patterns exist in language and reasoning"
J17-1003,W06-3506,1,0.932957,"f and Wehling 2012). Metaphor is also widely viewed as a creative tool. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013),"
J17-1003,P93-1023,0,0.574624,"1 combination of these methods when designing a metaphor processing component for a real-world application—or, depending on the needs of the application, one may choose a more suitable one. In the future, the models need to be extended to identify not only verb–subject and verb–object metaphors, but also metaphorical expressions in other syntactic constructions (e.g., adjectival or nominal metaphors). Previous distributional clustering and lexical acquisition research has shown that it is possible to model the meanings of a range of word classes using similar techniques (Hatzivassiloglou and McKeown 1993; Boleda Torrent and Alonso i Alemany 2003; Brockmann and Lapata 2003; Zapirain, Agirre, and M`arquez 2009). We thus expect our methods to be equally applicable to metaphorical uses of other word classes and syntactic constructions. For spectral clustering systems, such an extension would require incorporation of adjectival and nominal modifier features in clustering, clustering adjectives, and adding seed expressions representing a variety of syntactic constructions. The extension of HGFC would be more straightforward, only requiring ranking additional adjectival and nominal features that the"
J17-1003,W13-0908,0,0.356447,"jection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approa"
J17-1003,W13-0907,0,0.556111,"elp us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010"
J17-1003,kingsbury-palmer-2002-treebank,0,0.286397,"Missing"
J17-1003,S13-2007,0,0.0163622,"g processing component could help to avoid such errors. Other applications of metaphor processing include, for instance, opinion mining: metaphorical expressions tend to contain a strong emotional component (e.g., compare the metaphor “Government loosened its stranglehold on business” and its literal counterpart “Government deregulated business” [Narayanan 1999]); or information retrieval: non-literal language without appropriate disambiguation may lead to false positives in information retrieval (e.g., documents describing “old school gentlemen” should not be returned for the query “school” [Korkontzelos et al. 2013]); and many others. Because the metaphors we use are also known to be indicative of our underlying viewpoints, metaphor processing is likely to be fruitful in determining political affiliation from text or pinning down cross-cultural and cross-population differences, and thus become a useful tool in data mining. In social science, metaphor is extensively studied as a way to frame cultural and moral models, and to predict social choice (Landau, Sullivan, and Greenberg 2009; Thibodeau and Boroditsky 2011; Lakoff and Wehling 2012). Metaphor is also widely viewed as a creative tool. Its knowledge"
J17-1003,W07-0103,0,0.230929,", and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012; Shutova 2013; Mohler et al. 2014), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search using lexico-syntactic patterns (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). However, even the statistical methods have been predominantly applied in limited-domain, small-scale experiments. This is mainly due to the lack of general-domain corpora annotated for metaphor that are sufficiently large for training wide-coverage supervised systems. In addition, supervised methods tend to rely on lexical resources and ontol"
J17-1003,Q13-1031,0,0.259725,"Missing"
J17-1003,N10-1039,0,0.071695,"Missing"
J17-1003,J04-1002,0,0.744942,"2011; Lakoff and Wehling 2012). Metaphor is also widely viewed as a creative tool. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel"
J17-1003,W13-0904,0,0.410793,"innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012;"
J17-1003,C14-1165,0,0.216178,"Missing"
J17-1003,P13-3013,0,0.0207137,"(MIP), in which every word is tagged as literal or metaphorical, based on whether it has a “more basic meaning” in other contexts than the current one. The basic meaning was defined as “more concrete; related to bodily action; more precise (as opposed to vague); historically older” and its identification was guided by dictionary definitions. The resulting VU Amsterdam Metaphor Corpus3 is a 200,000-word subset of the British National Corpus (BNC) (Burnard 2007) annotated for linguistic metaphor. The corpus has already found application in computational metaphor processing research (Dunn 2013b; Niculae and Yaneva 2013; Beigman Klebanov et al. 2014), as well as inspiring metaphor annotation efforts in other languages (Badryzlova et al. 2013). Shutova and Teufel (2010) extended MIP to the identification of conceptual metaphors along with the linguistic ones. Following MIP, the annotators were asked to identify the more basic sense of the word, and then label the context in which the word occurs in the basic sense as the source domain, and the current context as the target. Shutova and Teufel’s corpus is a 13,000word subset of the BNC sampling a range of genres, and it has served as a testbed in a number of c"
J17-1003,N10-1147,1,0.923202,"etaphor is also widely viewed as a creative tool. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised l"
J17-1003,S13-1040,1,0.864796,"; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012; Shutova 2013; Mohler et al. 2014), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search using lexico-syntactic patterns (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). However, even the statistical methods have been predominantly applied in limited-domain, small-scale experiments. This is mainly due to the lack of general-domain corpora annotated for metaphor that are sufficiently large for training wide-coverage supervised sy"
J17-1003,N13-1118,1,0.756576,"Missing"
J17-1003,C10-1113,1,0.940357,"Missing"
J17-1003,shutova-teufel-2010-metaphor,1,0.789395,"an analysis thereof. The majority of corpus-linguistic studies were concerned with metaphorical expressions and mappings within a limited domain, for example, WAR , BUSINESS , FOOD, or PLANT metaphors (Santa Ana 1999; Izwaini 2003; Koller 2004; Skorczynska Sznajder and Pique-Angordans 2004; Hardie et al. 2007; Lu and Ahrens 2008; Low et al. 2010), or in a particular genre or type of discourse, such as financial (Charteris-Black and Ennis 2001; Martin 2006), political (Lu and Ahrens 2008), or educational (Cameron 2003; Beigman Klebanov and Flor 2013) discourse. Two studies (Steen et al. 2010; Shutova and Teufel 2010) moved away from investigating particular domains to a more general study of how metaphor behaves in unrestricted continuous text. Steen and colleagues (Pragglejaz Group 2007; Steen et al. 2010) proposed a metaphor identification procedure (MIP), in which every word is tagged as literal or metaphorical, based on whether it has a “more basic meaning” in other contexts than the current one. The basic meaning was defined as “more concrete; related to bodily action; more precise (as opposed to vague); historically older” and its identification was guided by dictionary definitions. The resulting VU"
J17-1003,J13-2003,1,0.922705,"Missing"
J17-1003,C12-2109,1,0.887263,"Missing"
J17-1003,W03-0410,0,0.106244,"Missing"
J17-1003,W13-0909,0,0.30345,"for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012; Shutova 2013; Mohler et al. 2014), lexical resou"
J17-1003,D09-1067,1,0.817193,"Missing"
J17-1003,D11-1095,1,0.896085,"Missing"
J17-1003,W13-0906,0,0.239163,"Missing"
J17-1003,D11-1063,0,0.568204,"l. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), d"
J17-1003,P11-1029,0,0.0221485,"political affiliation from text or pinning down cross-cultural and cross-population differences, and thus become a useful tool in data mining. In social science, metaphor is extensively studied as a way to frame cultural and moral models, and to predict social choice (Landau, Sullivan, and Greenberg 2009; Thibodeau and Boroditsky 2011; Lakoff and Wehling 2012). Metaphor is also widely viewed as a creative tool. Its knowledge projection mechanisms help us to grasp new concepts and generate innovative ideas. This opens many avenues for the creation of computational tools that foster creativity (Veale 2011, 2014) and support assessment in education (Burstein et al. 2013). For many years, computational work on metaphor evolved around the use of hand-coded knowledge and rules to model metaphorical associations, making the systems hard to scale. Recent years have seen a growing interest in statistical modeling of metaphor (Mason 2004; Gedigian et al. 2006; Shutova 2010; Shutova, Sun, and Korhonen 2010; Turney et al. 2011; Heintz et al. 2013; Hovy et al. 2013; Li, Zhu, and Wang 2013; Mohler et al. 2013; Shutova and Sun 2013; Strzalkowski et al. 2013; Tsvetkov, Mukomel, and Gershman 2013; Beigman Kl"
J17-1003,W14-2307,0,0.0389221,"Missing"
J17-1003,C08-1119,0,0.0268857,"tigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012; Shutova 2013; Mohler et al. 2014), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search using lexico-syntactic patterns (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). However, even the statistical methods have been predominantly applied in limited-domain, small-scale experiments. This is mainly due to the lack of general-domain corpora annotated for metaphor that are sufficiently large for training wide-coverage supervised systems. In addition, supervised methods tend to rely on lexical resources and ontologies for feature extraction, which limits the robustness of the features themselves and makes the methods dependent on the coverage (and the availability) of these resources. This also makes these met"
J17-1003,W13-0905,0,0.0218841,"Klebanov et al. 2014; Mohler et al. 2014), with many new techniques opening routes for improving system accuracy and robustness. A wide range of methods have been proposed and investigated by the community, including supervised classification (Gedigian et al. 2006; Dunn 2013a; Hovy et al. 2013; Mohler et al. 2013; Tsvetkov, Mukomel, and Gershman 2013), unsupervised learning (Heintz et al. 2013; Shutova and Sun 2013), distributional approaches (Shutova 2010; Shutova, Van de Cruys, and Korhonen 2012; Shutova 2013; Mohler et al. 2014), lexical resource-based methods (Krishnakumaran and Zhu 2007; Wilks et al. 2013), psycholinguistic features (Turney et al. 2011; Gandy et al. 2013; Neuman et al. 2013; Strzalkowski et al. 2013), and Web search using lexico-syntactic patterns (Veale and Hao 2008; Bollegala and Shutova 2013; Li, Zhu, and Wang 2013). However, even the statistical methods have been predominantly applied in limited-domain, small-scale experiments. This is mainly due to the lack of general-domain corpora annotated for metaphor that are sufficiently large for training wide-coverage supervised systems. In addition, supervised methods tend to rely on lexical resources and ontologies for feature ex"
J17-1003,P09-2019,0,0.0389073,"Missing"
J17-1003,P02-1029,0,\N,Missing
J17-1003,J15-4002,1,\N,Missing
J19-3005,P13-2037,0,0.0744461,"Missing"
J19-3005,W17-0401,0,0.0483167,"Missing"
J19-3005,P15-2044,0,0.0358947,"Missing"
J19-3005,W14-4203,0,0.0512933,"Missing"
J19-3005,P15-1040,0,0.0140754,"k is word sense disambiguation, as senses can be propagated from multilingual word graphs (Silberer and Ponzetto 2010) by bootstrapping from a few pivot pairs (Khapra et al. 2011), by imposing constraints in sentence alignments and harvesting bag-of-words features from these (Lefever, Hoste, and De Cock 2011), or by providing seeds for multilingual WordEmbedding-based lexicalized model transfer (Zennaki, Semmar, and Besacier 2016). Another task where lexical semantics is crucial is sentiment analysis, for similar reasons: Bilingual lexicons constrain word alignments for annotation projection (Almeida et al. 2015) and provide pivots for shared multilingual representations in model transfer (Fernández, Esuli, and Sebastiani 2015; Ziser and Reichart 2018). Moreover, sentiment 587 Computational Linguistics Volume 45, Number 3 analysis can leverage morphosyntactic typological information about constructions that alter polarity, such as negation (Ponti, Vuli´c, and Korhonen 2017). Finally, morphological information was shown to aid interpreting the intrinsic difficulty of texts for language modeling and neural machine translation, both in supervised (Johnson et al. 2017) and in unsupervised (Artetxe et al."
J19-3005,Q16-1031,0,0.0249656,"Missing"
J19-3005,D18-1549,0,0.0165078,"da et al. 2015) and provide pivots for shared multilingual representations in model transfer (Fernández, Esuli, and Sebastiani 2015; Ziser and Reichart 2018). Moreover, sentiment 587 Computational Linguistics Volume 45, Number 3 analysis can leverage morphosyntactic typological information about constructions that alter polarity, such as negation (Ponti, Vuli´c, and Korhonen 2017). Finally, morphological information was shown to aid interpreting the intrinsic difficulty of texts for language modeling and neural machine translation, both in supervised (Johnson et al. 2017) and in unsupervised (Artetxe et al. 2018) set-ups. In fact, the degree of fusion between roots and inflectional/derivative morphemes impacts the type/token ratio of texts, and consequently their rate of infrequent words. Moreover, the ambiguity of mapping between form and meaning of morphemes determines the usefulness of injecting character-level information (Gerz et al. 2018a, 2018b). This variation has to be taken into account in both language transfer and multilingual joint learning. As a final note, we stress that the addition of new features does not concern just future work, but also the existing typology-savvy methods, which c"
J19-3005,D17-1011,0,0.193671,"ases. In this article, we provide an extensive survey of typologically informed NLP methods to date, including the more recent neural approaches not previously surveyed in this area. We consider the impact of typological (including both structural and semantic) information on system performance and discuss the optimal sources for such information. Traditionally, typological information has been obtained from hand-crafted databases and, therefore, it tends to be coarse-grained and incomplete. Recent research has focused on inferring typological information automatically from multilingual data (Asgari and Schütze 2017, inter alia), with the specific purpose of obtaining a more complete and finer-grained set of feature values. We survey these techniques and discuss ways to integrate their predictions into the current NLP algorithms. To the best of our knowledge, this has not yet been covered in the existing literature. In short, the key questions our paper addresses can be summarized as follows: (i) Which NLP tasks and applications can benefit from typology? (ii) What are the advantages and limitations of currently available typological databases? Can data-driven inference of typological features offer an a"
J19-3005,D08-1014,0,0.0572004,"Due to their incompatible vocabularies, models are typically delexicalized prior to transfer and take language-independent (Nivre et al. 2016) or harmonized (Zhang et al. 2012) features as input. In order to bridge the vocabulary gap, model transfer was later augmented with multilingual Brown word clusters (Täckström, McDonald, and Uszkoreit 2012) or multilingual distributed word representations (see § 3.3). Machine translation offers an alternative to lexicalization in absence of annotated parallel data. As shown in Figure 1(c), a source sentence is machine translated into a target language (Banea et al. 2008), or through a bilingual lexicon (Durrett, Pauls, and Klein 2012). Its annotation is then projected and used to train a target-side supervised model. Translated documents can also be used to generate multilingual sentence representations, which facilitate language transfer (Zhou, Wan, and Xiao 2016). Some of these methods are hampered by their resource requirements. In fact, annotation projection and translation need parallel texts to align words and train translation systems, respectively (Agi´c, Hovy, and Søgaard 2015). Moreover, comparisons of stateof-the-art algorithms revealed that model"
J19-3005,W09-0106,0,0.0830635,"ction The world’s languages may share universal features at a deep, abstract level, but the structures found in real-world, surface-level texts can vary significantly. This crosslingual variation has challenged the development of robust, multilingually applicable Natural Language Processing (NLP) technology, and as a consequence, existing NLP is still largely limited to a handful of resource-rich languages. The architecture design, training, and hyper-parameter tuning of most current algorithms are far from being language-agnostic, and often inadvertently incorporate language-specific biases (Bender 2009, 2011). In addition, most state-of-the-art machine learning models rely on supervision from (large amounts of) labeled data—a requirement that cannot be met for the majority of the world’s languages (Snyder 2010). Over time, approaches have been developed to address the data bottleneck in multilingual NLP. These include unsupervised models that do not rely on the availability of manually annotated resources (Snyder and Barzilay 2008; Vuli´c, De Smet, and Moens 2011, inter alia) and techniques that transfer data or models from resource-rich to resource-poor languages (Padó and Lapata 2005; Das"
J19-3005,P07-1036,0,0.126415,"Missing"
J19-3005,Q18-1039,0,0.0162199,"al. 2012). The same ideas could be exploited in deep learning algorithms. We have seen in § 3.2 that multilingual joint models combine both shared and language-dependent parameters in order to capture the universal properties and cross-lingual differences, respectively. In order to enforce this division of roles more efficiently, these models could be augmented with the auxiliary task of predicting typological features automatically. This auxiliary objective could update parameters of the language-specific component, or those of the shared component, in an adversarial fashion, similar to what Chen et al. (2018) implemented by predicting language identity. Recently, Hu et al. (2016a, 2016b) and Wang and Poon (2018) proposed frameworks that integrate deep neural models with manually specified or automatically induced constraints. Similar to CODL, the focus in Hu et al. (2016a) and Wang and Poon (2018) is on logical rules, while the ideas in Hu et al. (2016b) are related to PR. These frameworks provide a promising avenue for the integration of typological information and deep models. A particular non-linear deep learning domain where knowledge integration is already prominent is multilingual representa"
J19-3005,C16-1298,0,0.0281595,"Missing"
J19-3005,P11-1061,0,0.244408,"009, 2011). In addition, most state-of-the-art machine learning models rely on supervision from (large amounts of) labeled data—a requirement that cannot be met for the majority of the world’s languages (Snyder 2010). Over time, approaches have been developed to address the data bottleneck in multilingual NLP. These include unsupervised models that do not rely on the availability of manually annotated resources (Snyder and Barzilay 2008; Vuli´c, De Smet, and Moens 2011, inter alia) and techniques that transfer data or models from resource-rich to resource-poor languages (Padó and Lapata 2005; Das and Petrov 2011; Täckström, McDonald, and Uszkoreit 2012, inter alia). Some multilingual applications, such as Neural Machine Translation and Information Retrieval, have been facilitated by learning joint models that learn from several languages (Ammar et al. 2016; Johnson et al. 2017, inter alia) or via multilingual distributed representations of words and sentences (Mikolov, Le, and Sutskever 2013, inter alia). Such techniques can lead to significant improvements in performance and parameter efficiency over monolingual baselines (Pappas and Popescu-Belis 2017). Another, highly promising source of informati"
J19-3005,P07-1009,0,0.17624,"Missing"
J19-3005,P16-1038,0,0.174612,"16) selected 190 binarized phonological features from URIEL (Littel, Mortensen, and Levin 2016). These features encoded the presence of single segments, classes of segments, minimal contrasts in a language inventory, and the number of segments in a class. For instance, they record whether a language allows two sounds to differ only in voicing, such as /t/ and /d/. Finally, a small number of experiments adopted the entire feature inventory of typological databases, without any sort of pre-selection. In particular, Agi´c (2017) and Ammar et al. (2016) extracted all the features in WALS, whereas Deri and Knight (2016) extracted all the features in URIEL. Schone and Jurafsky (2001) did not resort to basic typological features, but rather to “several hundred [implicational universals] applicable to syntax” drawn from the Universal Archive (Plank and Filiminova 1996). Typological attributes that are extracted from typological databases are typically represented as feature vectors in which each dimension encodes a feature value. This feature representation is often binarized (Georgi, Xia, and Lewis 2010): For each possible value v of each database attribute a, a new feature is created with value 1 if it corres"
J19-3005,P15-2139,0,0.0321535,"ver pure model transfer also in scenarios with limited amounts of labeled data in target language(s) (Fang and Cohn 2017).4 A key strategy for multilingual joint learning is parameter sharing (Johnson et al. 2017). More specifically, in state-of-the-art neural architectures, input and hidden representations can be either private (language-specific) or shared across languages. Shared representations are the result of tying the parameters of a network component across languages, such as word embeddings (Guo et al. 2016), character embeddings (Yang, Salakhutdinov, and Cohen 2016), hidden layers (Duong et al. 2015b), or the attention mechanism (Pappas and Popescu-Belis 2017). Figure 2 shows an example where all the components of a PoS tagger are shared between two languages (Bambara on the left and Warlpiri on the right). Parameter sharing, however, does not necessarily imply parameter identity: It can be enforced by minimizing the distance between parameters 4 This approach is also more cost-effective in terms of parameters (Pappas and Popescu-Belis 2017). 566 Ponti et al. Modeling Language Variation and Universals Figure 2 In multilingual joint learning, representations can be private or shared acros"
J19-3005,D15-1040,0,0.041461,"ver pure model transfer also in scenarios with limited amounts of labeled data in target language(s) (Fang and Cohn 2017).4 A key strategy for multilingual joint learning is parameter sharing (Johnson et al. 2017). More specifically, in state-of-the-art neural architectures, input and hidden representations can be either private (language-specific) or shared across languages. Shared representations are the result of tying the parameters of a network component across languages, such as word embeddings (Guo et al. 2016), character embeddings (Yang, Salakhutdinov, and Cohen 2016), hidden layers (Duong et al. 2015b), or the attention mechanism (Pappas and Popescu-Belis 2017). Figure 2 shows an example where all the components of a PoS tagger are shared between two languages (Bambara on the left and Warlpiri on the right). Parameter sharing, however, does not necessarily imply parameter identity: It can be enforced by minimizing the distance between parameters 4 This approach is also more cost-effective in terms of parameters (Pappas and Popescu-Belis 2017). 566 Ponti et al. Modeling Language Variation and Universals Figure 2 In multilingual joint learning, representations can be private or shared acros"
J19-3005,D16-1136,0,0.0403964,"Missing"
J19-3005,D12-1001,0,0.018952,"Missing"
J19-3005,P17-2093,0,0.047937,"Missing"
J19-3005,N15-1184,0,0.0387115,"et al. (2016a, 2016b) and Wang and Poon (2018) proposed frameworks that integrate deep neural models with manually specified or automatically induced constraints. Similar to CODL, the focus in Hu et al. (2016a) and Wang and Poon (2018) is on logical rules, while the ideas in Hu et al. (2016b) are related to PR. These frameworks provide a promising avenue for the integration of typological information and deep models. A particular non-linear deep learning domain where knowledge integration is already prominent is multilingual representation learning (§ 3.3). In this domain, a number of works (Faruqui et al. 2015; Rothe and Schütze 2015; Mrkši´c et al. 2016; Osborne, Narayan, and Cohen 2016) have proposed means through which external knowledge sourced from linguistic resources (such as WordNet, BabelNet, or lists of morphemes) can be encoded in word embeddings. Among the state-of-the-art specialization methods ATTRACT- REPEL (Mrkši´c et al. 2017; Vuli´c et al. 2017) pushes together or pulls apart 589 Computational Linguistics Volume 45, Number 3 vector pairs according to relational constraints, while preserving the relationship between words in the original space and possibly propagating the specializ"
J19-3005,C10-1044,0,0.0863316,"Missing"
J19-3005,Q18-1032,1,0.878475,"Missing"
J19-3005,D18-1029,1,0.881238,"Missing"
J19-3005,N15-1157,0,0.0210384,"Missing"
J19-3005,C16-1002,0,0.0416532,"ching scenarios (Adel, Vu, and Schultz 2013). In fact, multilingual joint learning improves over pure model transfer also in scenarios with limited amounts of labeled data in target language(s) (Fang and Cohn 2017).4 A key strategy for multilingual joint learning is parameter sharing (Johnson et al. 2017). More specifically, in state-of-the-art neural architectures, input and hidden representations can be either private (language-specific) or shared across languages. Shared representations are the result of tying the parameters of a network component across languages, such as word embeddings (Guo et al. 2016), character embeddings (Yang, Salakhutdinov, and Cohen 2016), hidden layers (Duong et al. 2015b), or the attention mechanism (Pappas and Popescu-Belis 2017). Figure 2 shows an example where all the components of a PoS tagger are shared between two languages (Bambara on the left and Warlpiri on the right). Parameter sharing, however, does not necessarily imply parameter identity: It can be enforced by minimizing the distance between parameters 4 This approach is also more cost-effective in terms of parameters (Pappas and Popescu-Belis 2017). 566 Ponti et al. Modeling Language Variation and Univ"
J19-3005,P15-1119,0,0.0603047,"Missing"
J19-3005,P16-1228,0,0.0498272,"Missing"
J19-3005,D16-1173,0,0.0523125,"Missing"
J19-3005,P11-1057,0,0.205918,"gure 1(a), a source text is parsed and word-aligned with a target parallel raw text. Its annotation (e.g., PoS tags and dependency trees) is then projected directly between corresponding words and used to train a supervised model on the target language. Later refinements to this process are known as soft projection, where constraints can be used to complement alignment, based on distributional similarity (Das and Petrov 2011) or constituent membership (Padó and Lapata 2009). Moreover, source model expectations on labels (Wang and Manning 2014; Agi´c et al. 2016) or sets of most likely labels (Khapra et al. 2011; Wisniewski et al. 2014) can be projected instead of single categorical labels. 565 Computational Linguistics Volume 45, Number 3 These can constrain unsupervised models by reducing the divergence between the expectations on target labels and on source labels or supporting “ambiguous learning” on the target language, respectively. Model transfer instead involves training a model (e.g., a parser) on a source language and applying it on a target language (Zeman and Resnik 2008), as shown in Figure 1(b). Due to their incompatible vocabularies, models are typically delexicalized prior to transfer"
J19-3005,C12-1089,0,0.0473073,"Missing"
J19-3005,P13-1117,0,0.0959291,"Missing"
J19-3005,P11-2055,0,0.04082,"Missing"
J19-3005,I08-2093,0,0.0406793,"ions. Similarly, Zhang et al. (2016) transfer PoS annotation with a model transfer technique relying on multilingual embeddings, created through monolingual mapping (see § 3.3). After the projection, they predict feature values with a multiclass support vector machine using PoS tag n-gram features. Finally, typological information can be extracted from Interlinear Glossed Texts (IGT). Such collections of example sentences are collated by linguists and contain grammatical glosses with morphological information. These can guide alignment between the example sentence and its English translation. Lewis and Xia (2008) and Bender et al. (2013) project chunking information from English and train context free grammars on target languages. After collapsing identical rules, they arrange them by frequency and infer word order features. 574 Ponti et al. Modeling Language Variation and Universals Unsupervised Propagation Morphosyntactic Annotation Table 2 An overview of the strategies for prediction of typological features. Author Details Requirements Liu (2010) Lewis and Xia (2008) Treebank count IGT projection Treebank IGT, source chunker 20 97 Bender et al. (2013) IGT projection IGT, source chunker 31 Östling ("
J19-3005,P13-3022,0,0.408676,"k-based language vector WALS 2,150 whole WALS whole whole PoS tag data set 27,824 phonology, morphology, syntax Logistic regression WALS whole whole Bayesian + feature and language interactions Feed-forward Neural Network Genealogy and WALS 2,607 whole Coke, King, and Radev (2016) Littel, Mortensen, and Levin (2016) Berzak, Reichart, and Katz (2014) Supervised Learning Malaviya, Neubig, and Littell (2017) Bjerva and Augenstein (2018) Takamura, Nagata, and Kawasaki (2016) Murawaki (2017) Wang and Eisner (2017) Cotterell and Eisner (2017) Cross-lingual distribution Daumé III and Campbell (2007) Lu (2013) Wälchli and Cysouw (2012) Asgari and Schütze (2017) Roy et al. (2014) Determinant Point Process with neural features Implication universals Automatic discovery Sentence edit distance Pivot alignment Correlations in counts and entropy Genealogy and WALS Genealogy and WALS ESL texts NMT data set WALS, tagger, synthetic treebanks WALS Genealogy and WALS Genealogy and WALS Multi-parallel texts, pivot Multi-parallel texts, pivot None Languages Features word order word and morpheme order, determiners word order and case alignment 986 word order 6 word order 325 whole word order and passive whole 14"
J19-3005,W15-1521,0,0.0349482,"Missing"
J19-3005,D17-1268,0,0.142382,"Missing"
J19-3005,P08-1099,0,0.0527456,"hallenge: How can the output of the model be biased to agree with the constraints while the efficiency of the search procedure is kept? In this article we do not answer this question directly but rather survey a number of approaches that succeed in dealing with it. Because linear models have been prominent in NLP research for a much longer time, it is not surprising that frameworks for the integration of soft constraints into these models are much more developed. The approaches proposed for this purpose include posterior regularization (PR) (Ganchev et al. 2010), generalized expectation (GE) (Mann and McCallum 2008), constraint-driven learning (CODL) (Chang, Ratinov, and Roth 2007), dual decomposition (DD) (Globerson and Jaakkola 2007; Komodakis, Paragios, and Tziritas 2011), and Bayesian modeling (Cohen 2016). These techniques use different types of knowledge encoding—for example, PR uses expectation constraints on the posterior parameter distribution, GE prefers parameter settings where the model’s distribution on unsupervised data matches a predefined target distribution, CODL enriches existing statistical models with Integer Linear Programming constraints, and in Bayesian modeling a prior distributio"
J19-3005,P05-1012,0,0.0516887,"Missing"
J19-3005,Q17-1022,1,0.921061,"Missing"
J19-3005,N16-1018,0,0.029262,"Missing"
J19-3005,I17-1046,0,0.464172,"ea, and typology-based Nearest Neighbors English as a Second Language–based Nearest Neighbors Task-based language vector Task-based language vector WALS 2,150 whole WALS whole whole PoS tag data set 27,824 phonology, morphology, syntax Logistic regression WALS whole whole Bayesian + feature and language interactions Feed-forward Neural Network Genealogy and WALS 2,607 whole Coke, King, and Radev (2016) Littel, Mortensen, and Levin (2016) Berzak, Reichart, and Katz (2014) Supervised Learning Malaviya, Neubig, and Littell (2017) Bjerva and Augenstein (2018) Takamura, Nagata, and Kawasaki (2016) Murawaki (2017) Wang and Eisner (2017) Cotterell and Eisner (2017) Cross-lingual distribution Daumé III and Campbell (2007) Lu (2013) Wälchli and Cysouw (2012) Asgari and Schütze (2017) Roy et al. (2014) Determinant Point Process with neural features Implication universals Automatic discovery Sentence edit distance Pivot alignment Correlations in counts and entropy Genealogy and WALS Genealogy and WALS ESL texts NMT data set WALS, tagger, synthetic treebanks WALS Genealogy and WALS Genealogy and WALS Multi-parallel texts, pivot Multi-parallel texts, pivot None Languages Features word order word and morpheme"
J19-3005,P12-1066,0,0.286336,"Missing"
J19-3005,D10-1120,0,0.0346019,"Tziritas 2011), and Bayesian modeling (Cohen 2016). These techniques use different types of knowledge encoding—for example, PR uses expectation constraints on the posterior parameter distribution, GE prefers parameter settings where the model’s distribution on unsupervised data matches a predefined target distribution, CODL enriches existing statistical models with Integer Linear Programming constraints, and in Bayesian modeling a prior distribution is defined on the model parameters. PR has already been used for incorporating universal linguistic knowledge into an unsupervised parsing model (Naseem et al. 2010). In the future, it could be extended to typological knowledge, which is a good fit for soft constraints. As another option, Bayesian modeling sets prior probability distributions according to the relationships encoded in typological features (Schone and Jurafsky 2001). Finally, DD has been applied to multi-task learning, which paves the way for typological knowledge encoding through a multi-task architecture in which one of the tasks is the actual NLP application and the other is the data-driven prediction of typological features. In fact, a modification of this architecture has already been"
J19-3005,W11-2124,0,0.0331622,"rameter identity: It can be enforced by minimizing the distance between parameters 4 This approach is also more cost-effective in terms of parameters (Pappas and Popescu-Belis 2017). 566 Ponti et al. Modeling Language Variation and Universals Figure 2 In multilingual joint learning, representations can be private or shared across languages. Tied parameters are shown as neurons with identical color. Image adapted from Fang and Cohn (2017), representing multilingual PoS tagging for Bambara (left) and Warlpiri (right). (Duong et al. 2015a) or between latent representations of parallel sentences (Niehues et al. 2011; Zhou et al. 2015) in separate language-specific models. Another common strategy in multilingual joint modeling is providing information about the properties of the language of the current text in the form of input language vectors (Guo et al. 2016). The intuition is that this helps tailoring the joint model toward specific languages. These vectors can be learned end-to-end in neural language modeling tasks (Tsvetkov et al. 2016; Östling and Tiedemann 2017) or neural machine translation tasks (Ha, Niehues, and Waibel 2016; Johnson et al. 2017). Ammar et al. (2016) instead used language vector"
J19-3005,C16-1123,1,0.918794,"Missing"
J19-3005,Q16-1030,0,0.164108,"Missing"
J19-3005,P15-2034,0,0.172911,"syntactically annotated texts. For example, word order features can be calculated by counting the average direction of dependency relations or constituency hierarchies (Liu 2010). Consider the tree of a sentence in Welsh from Bender et al. (2013) in Figure 6. The relative order of verb– subject, and verb–object can be deduced from the position of the relevant nodes VBD, NNS , and NNO (highlighted). Morphosyntactic annotation is often unavailable for resource-lean languages. In such cases, it can be projected from a source language to a target language through language transfer. For instance, Östling (2015) projects source morphosyntactic annotation directly to several languages through a multilingual word alignment. After the alignment and projection, word order features are calculated by the average direction of dependency relations. Similarly, Zhang et al. (2016) transfer PoS annotation with a model transfer technique relying on multilingual embeddings, created through monolingual mapping (see § 3.3). After the projection, they predict feature values with a multiclass support vector machine using PoS tag n-gram features. Finally, typological information can be extracted from Interlinear Gloss"
J19-3005,E17-2102,0,0.0715416,"g multilingual PoS tagging for Bambara (left) and Warlpiri (right). (Duong et al. 2015a) or between latent representations of parallel sentences (Niehues et al. 2011; Zhou et al. 2015) in separate language-specific models. Another common strategy in multilingual joint modeling is providing information about the properties of the language of the current text in the form of input language vectors (Guo et al. 2016). The intuition is that this helps tailoring the joint model toward specific languages. These vectors can be learned end-to-end in neural language modeling tasks (Tsvetkov et al. 2016; Östling and Tiedemann 2017) or neural machine translation tasks (Ha, Niehues, and Waibel 2016; Johnson et al. 2017). Ammar et al. (2016) instead used language vectors as a prior for language identity or typological features. In § 5.2, we discuss ways in which typological knowledge is used to balance private and shared neural network components and provide informative input language vectors. In § 6.3, we argue that language vectors do not need to be limited to features extracted from typological databases, but should also include automatically induced typological information (Malaviya, Neubig, and Littell 2017, see § 4.3"
J19-3005,H05-1108,0,0.0802046,"cific biases (Bender 2009, 2011). In addition, most state-of-the-art machine learning models rely on supervision from (large amounts of) labeled data—a requirement that cannot be met for the majority of the world’s languages (Snyder 2010). Over time, approaches have been developed to address the data bottleneck in multilingual NLP. These include unsupervised models that do not rely on the availability of manually annotated resources (Snyder and Barzilay 2008; Vuli´c, De Smet, and Moens 2011, inter alia) and techniques that transfer data or models from resource-rich to resource-poor languages (Padó and Lapata 2005; Das and Petrov 2011; Täckström, McDonald, and Uszkoreit 2012, inter alia). Some multilingual applications, such as Neural Machine Translation and Information Retrieval, have been facilitated by learning joint models that learn from several languages (Ammar et al. 2016; Johnson et al. 2017, inter alia) or via multilingual distributed representations of words and sentences (Mikolov, Le, and Sutskever 2013, inter alia). Such techniques can lead to significant improvements in performance and parameter efficiency over monolingual baselines (Pappas and Popescu-Belis 2017). Another, highly promisin"
J19-3005,I17-1102,0,0.0522275,"Missing"
J19-3005,P18-1142,1,0.820943,"Missing"
J19-3005,D18-1026,1,0.847658,"Missing"
J19-3005,S17-1003,1,0.801184,"Missing"
J19-3005,N12-1008,1,0.844552,". As another option, Bayesian modeling sets prior probability distributions according to the relationships encoded in typological features (Schone and Jurafsky 2001). Finally, DD has been applied to multi-task learning, which paves the way for typological knowledge encoding through a multi-task architecture in which one of the tasks is the actual NLP application and the other is the data-driven prediction of typological features. In fact, a modification of this architecture has already been applied to minimally supervised learning and domain adaptation with soft (non-typological) constraints (Reichart and Barzilay 2012; Rush et al. 2012). The same ideas could be exploited in deep learning algorithms. We have seen in § 3.2 that multilingual joint models combine both shared and language-dependent parameters in order to capture the universal properties and cross-lingual differences, respectively. In order to enforce this division of roles more efficiently, these models could be augmented with the auxiliary task of predicting typological features automatically. This auxiliary objective could update parameters of the language-specific component, or those of the shared component, in an adversarial fashion, simila"
J19-3005,P15-2040,0,0.0202231,"ribution of each language and example. The selection is typically carried out through general language similarity metrics. For instance, Deri and Knight (2016) base their selection on the URIEL language typology database, considering information about genealogical, geographic, syntactic, and phonetic properties. This facilitates language transfer of grapheme-to-phoneme models, by guiding the choice of source languages and aligning phoneme inventories. Metrics for source selection can also be extracted in a data-driven fashion, without explicit reference to structured taxonomies. For instance, Rosa and Zabokrtsky (2015) estimate the Kullback–Leibler divergence between PoS trigram distributions for delexicalized parser transfer. In order to approximate the divergence in syntactic structures between languages, Ponti et al. (2018a) utilize the Jaccard distance between morphological feature sets and the tree edit distance of delexicalized dependency parses of translationally equivalent sentences. A priori and bottom–up approaches can also be combined. For delexicalized parser transfer, Agi´c (2017) relies on a weighted sum of distances based on (1) the PoS divergence defined by Rosa and Zabokrtsky (2015); (2) th"
J19-3005,P15-1173,0,0.0316864,"Missing"
J19-3005,P18-1084,1,0.891535,"Missing"
J19-3005,C14-1098,0,0.0637796,"Missing"
J19-3005,D12-1131,1,0.808979,"Missing"
J19-3005,S10-1027,0,0.0116844,"s-lingual information about frame semantics can be extracted, for example, from the Valency Patterns Leipzig database (ValPaL). Typological information regarding lexical semantics patterns can further assist various NLP tasks by providing information about translationally equivalent words across languages. Such information is provided in databases such as the World Loanword Database (WOLD), the Intercontinental Dictionary Series (IDS), and the Automated Similarity Judgment Program (ASJP). One example task is word sense disambiguation, as senses can be propagated from multilingual word graphs (Silberer and Ponzetto 2010) by bootstrapping from a few pivot pairs (Khapra et al. 2011), by imposing constraints in sentence alignments and harvesting bag-of-words features from these (Lefever, Hoste, and De Cock 2011), or by providing seeds for multilingual WordEmbedding-based lexicalized model transfer (Zennaki, Semmar, and Besacier 2016). Another task where lexical semantics is crucial is sentiment analysis, for similar reasons: Bilingual lexicons constrain word alignments for annotation projection (Almeida et al. 2015) and provide pivots for shared multilingual representations in model transfer (Fernández, Esuli, a"
J19-3005,P08-1084,0,0.26666,"ure design, training, and hyper-parameter tuning of most current algorithms are far from being language-agnostic, and often inadvertently incorporate language-specific biases (Bender 2009, 2011). In addition, most state-of-the-art machine learning models rely on supervision from (large amounts of) labeled data—a requirement that cannot be met for the majority of the world’s languages (Snyder 2010). Over time, approaches have been developed to address the data bottleneck in multilingual NLP. These include unsupervised models that do not rely on the availability of manually annotated resources (Snyder and Barzilay 2008; Vuli´c, De Smet, and Moens 2011, inter alia) and techniques that transfer data or models from resource-rich to resource-poor languages (Padó and Lapata 2005; Das and Petrov 2011; Täckström, McDonald, and Uszkoreit 2012, inter alia). Some multilingual applications, such as Neural Machine Translation and Information Retrieval, have been facilitated by learning joint models that learn from several languages (Ammar et al. 2016; Johnson et al. 2017, inter alia) or via multilingual distributed representations of words and sentences (Mikolov, Le, and Sutskever 2013, inter alia). Such techniques can"
J19-3005,P11-2120,0,0.0488046,"hand, the accuracy of PoS-based metrics deteriorates easily in scenarios with scarce amounts of data. Source language selection is a special case of source language weighting where weights are one-hot vectors. However, weights can also be gradient and consist of real numbers. Søgaard and Wulff (2012) adapt delexicalized parsers by weighting every 584 Ponti et al. Modeling Language Variation and Universals training instance based on the inverse of the Hamming distance between typological (or genealogical) features in source and target languages. An equivalent bottom–up approach is developed by Søgaard (2011), who weighs source language sentences based on the perplexity between their coarse PoS tags and the predictions of a sequential model trained on the target language. Alternatively, the lack of target annotated data can be alleviated by synthesizing new examples, thus boosting the variety and amount of the source data. For instance, the Galactic Dependency Treebanks stem from real trees whose nodes have been permuted probabilistically, according to the word orders of nouns and verbs in other languages (Wang and Eisner 2016). Synthetic trees improve the performance of model transfer for parsing"
J19-3005,C12-2115,0,0.139636,"from the practice of discarding features that are not discriminative, when they are identical for all the languages in the sample. Another group of studies used more comprehensive feature sets. The feature set of Daiber, Stanojevi´c, and Sima’an (2016) included not only WALS word order features but also nominal categories (e.g., “Conjunctions and Universal Quantifiers”) and nominal syntax (e.g., “Possessive Classification”). Berzak, Reichart, and Katz (2015) considered all features from WALS associated with morphosyntax and pruned out the redundant ones, resulting in a total of 119 features. Søgaard and Wulff (2012) utilized all the 571 Computational Linguistics Volume 45, Number 3 Figure 4 Feature sets used in a sample of typologically informed experiments for dependency parsing. The numbers refer to WALS ordering (Dryer and Haspelmath 2013). features in WALS with the exception of phonological features. Tsvetkov et al. (2016) selected 190 binarized phonological features from URIEL (Littel, Mortensen, and Levin 2016). These features encoded the presence of single segments, classes of segments, minimal contrasts in a language inventory, and the number of segments in a class. For instance, they record whet"
J19-3005,N13-1126,0,0.051696,"Missing"
J19-3005,N12-1052,0,0.116447,"Missing"
J19-3005,P15-1150,0,0.0238395,"Missing"
J19-3005,L16-1011,0,0.120366,"Missing"
J19-3005,W15-2137,0,0.099488,"Missing"
J19-3005,P12-1068,0,0.0507951,"d labor. Furthermore, the immense range of possible tasks and languages makes the aim of a complete coverage unrealistic. One solution to this problem explored by the research community abandons the use of annotated resources altogether and instead focuses on unsupervised learning. This class of methods infers probabilistic models of the observations given some latent variables. In other words, it unravels the hidden structures within unlabeled text data. Although these methods have been used extensively for multilingual applications (Snyder and Barzilay 2008; Vuli´c, De Smet, and Moens 2011; Titov and Klementiev 2012, inter alia), their performance tends to lag behind the more linguistically informed supervised learning approaches (Täckström, McDonald, and Nivre 2013). Moreover, they have been rarely combined with typological knowledge. For these reasons, we do not review them in this section. Other promising ways to overcome data scarcity include transferring models or data from resource-rich to resource-poor languages (§ 3.1) or learning joint models from annotated examples in multiple languages (§ 3.2) in order to leverage language interdependencies. Early approaches of this kind have relied on univers"
J19-3005,N16-1161,0,0.0936611,"hn (2017), representing multilingual PoS tagging for Bambara (left) and Warlpiri (right). (Duong et al. 2015a) or between latent representations of parallel sentences (Niehues et al. 2011; Zhou et al. 2015) in separate language-specific models. Another common strategy in multilingual joint modeling is providing information about the properties of the language of the current text in the form of input language vectors (Guo et al. 2016). The intuition is that this helps tailoring the joint model toward specific languages. These vectors can be learned end-to-end in neural language modeling tasks (Tsvetkov et al. 2016; Östling and Tiedemann 2017) or neural machine translation tasks (Ha, Niehues, and Waibel 2016; Johnson et al. 2017). Ammar et al. (2016) instead used language vectors as a prior for language identity or typological features. In § 5.2, we discuss ways in which typological knowledge is used to balance private and shared neural network components and provide informative input language vectors. In § 6.3, we argue that language vectors do not need to be limited to features extracted from typological databases, but should also include automatically induced typological information (Malaviya, Neubig"
J19-3005,P16-1157,0,0.0178939,"§ 4.3). 3.3 Multilingual Representation Learning The multilingual algorithms reviewed in § 3.1 and § 3.2 are facilitated by dense realvalued vector representations of words, known as multilingual word embeddings. These can be learned from corpora and provide pivotal lexical features to several downstream NLP applications. In multilingual word embeddings, similar words (regardless of the actual language) obtain similar representations. Various methods to generate multilingual word embeddings have been developed. We follow the classification proposed by Ruder (2018), and we refer the reader to Upadhyay et al. (2016) for an empirical comparison. 567 Computational Linguistics Volume 45, Number 3 Monolingual mapping generates independent monolingual representations and subsequently learns a linear map between a source language and a target language based on a bilingual lexicon (Mikolov, Le, and Sutskever 2013) or in an unsupervised fashion through adversarial networks (Conneau et al. 2017). Alternatively, both spaces can be cast into a new, lower-dimensional space through canonical correlation analysis based on dictionaries (Ammar et al. 2016) or word alignments (Guo et al. 2015). Pseudo-cross-lingual appro"
J19-3005,P11-2084,1,0.843653,"Missing"
J19-3005,P15-2118,1,0.902813,"Missing"
J19-3005,P17-1006,1,0.822412,"Missing"
J19-3005,Q16-1035,0,0.0476954,"source and target languages. An equivalent bottom–up approach is developed by Søgaard (2011), who weighs source language sentences based on the perplexity between their coarse PoS tags and the predictions of a sequential model trained on the target language. Alternatively, the lack of target annotated data can be alleviated by synthesizing new examples, thus boosting the variety and amount of the source data. For instance, the Galactic Dependency Treebanks stem from real trees whose nodes have been permuted probabilistically, according to the word orders of nouns and verbs in other languages (Wang and Eisner 2016). Synthetic trees improve the performance of model transfer for parsing when the source is chosen in a supervised way (performance on target development data) and in an unsupervised way (coverage of target PoS sequences). Rather than generating new synthetic data, Ponti et al. (2018a) leverage typological features to pre-process treebanks in order to reduce their variation in language transfer tasks. In particular, they adapt source trees to the typology of a target language with respect to several constructions in a rule-based fashion. For instance, relative clauses in Arabic (Afro–Asiatic) w"
J19-3005,Q17-1011,0,0.141548,"-based Nearest Neighbors English as a Second Language–based Nearest Neighbors Task-based language vector Task-based language vector WALS 2,150 whole WALS whole whole PoS tag data set 27,824 phonology, morphology, syntax Logistic regression WALS whole whole Bayesian + feature and language interactions Feed-forward Neural Network Genealogy and WALS 2,607 whole Coke, King, and Radev (2016) Littel, Mortensen, and Levin (2016) Berzak, Reichart, and Katz (2014) Supervised Learning Malaviya, Neubig, and Littell (2017) Bjerva and Augenstein (2018) Takamura, Nagata, and Kawasaki (2016) Murawaki (2017) Wang and Eisner (2017) Cotterell and Eisner (2017) Cross-lingual distribution Daumé III and Campbell (2007) Lu (2013) Wälchli and Cysouw (2012) Asgari and Schütze (2017) Roy et al. (2014) Determinant Point Process with neural features Implication universals Automatic discovery Sentence edit distance Pivot alignment Correlations in counts and entropy Genealogy and WALS Genealogy and WALS ESL texts NMT data set WALS, tagger, synthetic treebanks WALS Genealogy and WALS Genealogy and WALS Multi-parallel texts, pivot Multi-parallel texts, pivot None Languages Features word order word and morpheme order, determiners word"
J19-3005,D18-1215,0,0.0199401,"ltilingual joint models combine both shared and language-dependent parameters in order to capture the universal properties and cross-lingual differences, respectively. In order to enforce this division of roles more efficiently, these models could be augmented with the auxiliary task of predicting typological features automatically. This auxiliary objective could update parameters of the language-specific component, or those of the shared component, in an adversarial fashion, similar to what Chen et al. (2018) implemented by predicting language identity. Recently, Hu et al. (2016a, 2016b) and Wang and Poon (2018) proposed frameworks that integrate deep neural models with manually specified or automatically induced constraints. Similar to CODL, the focus in Hu et al. (2016a) and Wang and Poon (2018) is on logical rules, while the ideas in Hu et al. (2016b) are related to PR. These frameworks provide a promising avenue for the integration of typological information and deep models. A particular non-linear deep learning domain where knowledge integration is already prominent is multilingual representation learning (§ 3.3). In this domain, a number of works (Faruqui et al. 2015; Rothe and Schütze 2015; Mr"
J19-3005,Q14-1005,0,0.0236961,"et al. (2005). In its original formulation, as illustrated in Figure 1(a), a source text is parsed and word-aligned with a target parallel raw text. Its annotation (e.g., PoS tags and dependency trees) is then projected directly between corresponding words and used to train a supervised model on the target language. Later refinements to this process are known as soft projection, where constraints can be used to complement alignment, based on distributional similarity (Das and Petrov 2011) or constituent membership (Padó and Lapata 2009). Moreover, source model expectations on labels (Wang and Manning 2014; Agi´c et al. 2016) or sets of most likely labels (Khapra et al. 2011; Wisniewski et al. 2014) can be projected instead of single categorical labels. 565 Computational Linguistics Volume 45, Number 3 These can constrain unsupervised models by reducing the divergence between the expectations on target labels and on source labels or supporting “ambiguous learning” on the target language, respectively. Model transfer instead involves training a model (e.g., a parser) on a source language and applying it on a target language (Zeman and Resnik 2008), as shown in Figure 1(b). Due to their incompati"
J19-3005,D14-1187,0,0.0145363,"text is parsed and word-aligned with a target parallel raw text. Its annotation (e.g., PoS tags and dependency trees) is then projected directly between corresponding words and used to train a supervised model on the target language. Later refinements to this process are known as soft projection, where constraints can be used to complement alignment, based on distributional similarity (Das and Petrov 2011) or constituent membership (Padó and Lapata 2009). Moreover, source model expectations on labels (Wang and Manning 2014; Agi´c et al. 2016) or sets of most likely labels (Khapra et al. 2011; Wisniewski et al. 2014) can be projected instead of single categorical labels. 565 Computational Linguistics Volume 45, Number 3 These can constrain unsupervised models by reducing the divergence between the expectations on target labels and on source labels or supporting “ambiguous learning” on the target language, respectively. Model transfer instead involves training a model (e.g., a parser) on a source language and applying it on a target language (Zeman and Resnik 2008), as shown in Figure 1(b). Due to their incompatible vocabularies, models are typically delexicalized prior to transfer and take language-indepe"
J19-3005,W14-1613,0,0.0141525,"ns and subsequently learns a linear map between a source language and a target language based on a bilingual lexicon (Mikolov, Le, and Sutskever 2013) or in an unsupervised fashion through adversarial networks (Conneau et al. 2017). Alternatively, both spaces can be cast into a new, lower-dimensional space through canonical correlation analysis based on dictionaries (Ammar et al. 2016) or word alignments (Guo et al. 2015). Pseudo-cross-lingual approaches merge words with contexts of other languages and generate representations based on this mixed corpus. Substitutions are based on Wiktionary (Xiao and Guo 2014) or machine translation (Gouws and Søgaard 2015; Duong et al. 2016). Moreover, the mixed corpus can be produced by randomly shuffling words between aligned documents in two languages (Vuli´c and Moens 2015). Cross-lingual training approaches jointly learn embeddings from parallel corpora and enforce cross-lingual constraints. This involves minimizing the distance of the hidden sentence representations of the two languages (Hermann and Blunsom 2014) or decoding one from the other (Lauly, Boulanger, and Larochelle 2013), possibly adding a correlation term to the loss (Chandar et al. 2014). Joint"
J19-3005,H01-1035,0,0.123357,"Missing"
J19-3005,I08-3008,0,0.0176835,"). Moreover, source model expectations on labels (Wang and Manning 2014; Agi´c et al. 2016) or sets of most likely labels (Khapra et al. 2011; Wisniewski et al. 2014) can be projected instead of single categorical labels. 565 Computational Linguistics Volume 45, Number 3 These can constrain unsupervised models by reducing the divergence between the expectations on target labels and on source labels or supporting “ambiguous learning” on the target language, respectively. Model transfer instead involves training a model (e.g., a parser) on a source language and applying it on a target language (Zeman and Resnik 2008), as shown in Figure 1(b). Due to their incompatible vocabularies, models are typically delexicalized prior to transfer and take language-independent (Nivre et al. 2016) or harmonized (Zhang et al. 2012) features as input. In order to bridge the vocabulary gap, model transfer was later augmented with multilingual Brown word clusters (Täckström, McDonald, and Uszkoreit 2012) or multilingual distributed word representations (see § 3.3). Machine translation offers an alternative to lexicalization in absence of annotated parallel data. As shown in Figure 1(c), a source sentence is machine translat"
J19-3005,C16-1044,0,0.0230991,"Missing"
J19-3005,D15-1213,0,0.0647972,"Missing"
J19-3005,N16-1156,0,0.0228005,"Missing"
J19-3005,D12-1125,1,0.809705,"orical labels. 565 Computational Linguistics Volume 45, Number 3 These can constrain unsupervised models by reducing the divergence between the expectations on target labels and on source labels or supporting “ambiguous learning” on the target language, respectively. Model transfer instead involves training a model (e.g., a parser) on a source language and applying it on a target language (Zeman and Resnik 2008), as shown in Figure 1(b). Due to their incompatible vocabularies, models are typically delexicalized prior to transfer and take language-independent (Nivre et al. 2016) or harmonized (Zhang et al. 2012) features as input. In order to bridge the vocabulary gap, model transfer was later augmented with multilingual Brown word clusters (Täckström, McDonald, and Uszkoreit 2012) or multilingual distributed word representations (see § 3.3). Machine translation offers an alternative to lexicalization in absence of annotated parallel data. As shown in Figure 1(c), a source sentence is machine translated into a target language (Banea et al. 2008), or through a bilingual lexicon (Durrett, Pauls, and Klein 2012). Its annotation is then projected and used to train a target-side supervised model. Translat"
J19-3005,P16-1133,0,0.0606511,"Missing"
J19-3005,D18-1022,1,0.844622,"om a few pivot pairs (Khapra et al. 2011), by imposing constraints in sentence alignments and harvesting bag-of-words features from these (Lefever, Hoste, and De Cock 2011), or by providing seeds for multilingual WordEmbedding-based lexicalized model transfer (Zennaki, Semmar, and Besacier 2016). Another task where lexical semantics is crucial is sentiment analysis, for similar reasons: Bilingual lexicons constrain word alignments for annotation projection (Almeida et al. 2015) and provide pivots for shared multilingual representations in model transfer (Fernández, Esuli, and Sebastiani 2015; Ziser and Reichart 2018). Moreover, sentiment 587 Computational Linguistics Volume 45, Number 3 analysis can leverage morphosyntactic typological information about constructions that alter polarity, such as negation (Ponti, Vuli´c, and Korhonen 2017). Finally, morphological information was shown to aid interpreting the intrinsic difficulty of texts for language modeling and neural machine translation, both in supervised (Johnson et al. 2017) and in unsupervised (Artetxe et al. 2018) set-ups. In fact, the degree of fusion between roots and inflectional/derivative morphemes impacts the type/token ratio of texts, and co"
J19-3005,Q17-1024,0,\N,Missing
J19-3005,D18-1269,0,\N,Missing
N10-1147,W97-0209,0,0.419868,"Missing"
N10-1147,C88-1081,0,0.877491,"y hand-crafted knowledge about metaphor, but in contrast employs automatically induced selectional preferences. Being the first of its kind, our system is capable of paraphrasing metaphorical expressions with a high accuracy (0.81). 1 Introduction Metaphors arise when one concept is viewed in terms of the properties of the other. In other words it is based on similarity between the concepts. Similarity is a kind of association implying the presence of characteristics in common. Here are some examples of metaphor. (1) News travels fast. (Lakoff and Johnson, 1980) (2) How can I kill a process? (Martin, 1988) (3) And then my heart with pleasure fills, And dances with the daffodils.1 In metaphorical expressions seemingly unrelated features of one concept are associated with another 1 taken from the verse “I wandered lonely as a cloud” written by William Wordsworth in 1804. concept. In the example (2) the computational process is viewed as something alive and, therefore, its forced termination is associated with the act of killing. Metaphorical expressions represent a great variety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (1) and (2), to poetic"
N10-1147,andersen-etal-2008-bnc,0,\N,Missing
N10-1147,J91-1003,0,\N,Missing
N10-1147,C08-1119,0,\N,Missing
N10-1147,D09-1067,0,\N,Missing
N10-1147,P06-4020,0,\N,Missing
N13-1118,D08-1007,0,0.0112559,"We evaluated the performance of the system with the aid of human judges in precision- and recall-oriented settings. In addition, we compared its performance to that of two baselines, an unsupervised baseline using agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN). 2 2.1 Method Dataset and Feature Extraction Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007). Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB – SUBJECT, VERB – DIRECT OBJECT and VERB – INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 20"
N13-1118,E06-1042,0,0.176277,"Missing"
N13-1118,P06-4020,0,0.0192815,"sing agglomerative clustering (AGG) and a supervised baseline built upon WordNet (Fellbaum, 1998) (WN). 2 2.1 Method Dataset and Feature Extraction Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC (Burnard, 2007). Figure 1: Organisation of the hierarchical graph of concepts Following previous semantic noun classification experiments (Pantel and Lin, 2002; Bergsma et al., 2008), we use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB – SUBJECT, VERB – DIRECT OBJECT and VERB – INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been"
N13-1118,J91-1003,0,0.729828,"human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Tur"
N13-1118,P04-2007,0,0.0442301,"ns (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB – SUBJECT, VERB – DIRECT OBJECT and VERB – INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one. The cluster similarity is measured using linkage criteria (e.g. Ward (1963) measures the decrease in variance for the clusters being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts. In a tree, each word"
N13-1118,W06-3506,0,0.763255,"f metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one"
N13-1118,kingsbury-palmer-2002-treebank,0,0.305407,"Missing"
N13-1118,W07-0103,0,0.027013,"stical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings (Mason, 2004) or identification of metaphorical expressions (Shutova et al., 2010; Turney et al., 2011). In this paper, we present the first computational method 978 Proceedings of NAACL-HLT 2013, pages 978–988, c Atlanta, Georgia, 9–14 June 2013. 2013 Association for Computational Linguistics that identifies the generalisations that govern the production of metaphorical expressions, i.e. conceptual metaphors, and then uses these generalisations to identify metaphorical expressions in unrestri"
N13-1118,J04-1002,0,0.779816,"he ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007),"
N13-1118,shutova-teufel-2010-metaphor,1,0.77492,"my argument”. They demonstrate a metaphorical mapping of the concept of argument to that of war. The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept. The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions. Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based"
N13-1118,C10-1113,1,0.943999,"al Linguistics that identifies the generalisations that govern the production of metaphorical expressions, i.e. conceptual metaphors, and then uses these generalisations to identify metaphorical expressions in unrestricted text. As opposed to previous works on statistical metaphor processing that were supervised or semi-supervised, and thus required training data, our method is fully unsupervised. It relies on building a hierarchical graph of concepts connected by their association strength (using hierarchical clustering) and then searching for metaphorical links in this graph. Shutova et al. (2010) introduced the hypothesis of “clustering by association” and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity. We share this intuition, but take this idea a significant step further. Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain (Crutch and Warrington, 2005; Binder et al., 2005; Wiemer-Hastings and Xu, 2005; Huang et"
N13-1118,N10-1147,1,0.881567,"has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metapho"
N13-1118,W03-0410,0,0.0577246,"use the grammatical relations (GRs) as features for clustering. We extracted the features from the Gigaword corpus (Graff et al., 2003), which was first parsed using the RASP parser (Briscoe et al., 2006). The verb lemmas in VERB – SUBJECT, VERB – DIRECT OBJECT and VERB – INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser. The feature values were the relative frequencies of the features. 2.2 Hierarchical Graph Factorization Clustering The most widely used method for hierarchical word clustering is AGG (Schulte im Walde and Brew, 2001; Stevenson and Joanis, 2003; Ferrer, 2004; Devereux and Costello, 2005). The method treats each word as a singleton cluster and then successively merges two closest clusters until all the clusters have been merged into one. The cluster similarity is measured using linkage criteria (e.g. Ward (1963) measures the decrease in variance for the clusters being merged). As opposed to this, HGFC derives probabilistic bipartite graphs from the similarity matrix (Yu et al., 2006). Since we require a graph of concepts, our task is rather different from standard hierarchical word clustering that produces a tree of concepts. In a tr"
N13-1118,D09-1067,1,0.931489,"Missing"
N13-1118,D11-1095,1,0.919358,"to identify metaphorical connections between the concepts. To the best of our knowledge, our method is the first one to use a hierarchical clustering model for the metaphor processing task. The original graph of concepts is built using hierarchical graph factorization clustering (HGFC) (Yu et al., 2006) of nouns, yielding a network of clusters with different levels of generality. The weights on the edges of the graph indicate association between the clusters (concepts). HGFC has not been previously employed for noun clustering in NLP, but showed successful results in the verb clustering task (Sun and Korhonen, 2011). In summary, our system (1) builds a graph of concepts using HGFC, (2) traverses it to find metaphorical associations between clusters using weights on the edges of the graph, (3) generates lists of salient features for the metaphorically connected clusters and (4) searches the British National Corpus (BNC) (Burnard, 2007) for metaphorical expressions describing the target domain concepts using the verbs from the set of salient features. We evaluated the performance of the system with the aid of human judges in precision- and recall-oriented settings. In addition, we compared its performance"
N13-1118,D11-1063,0,0.366484,"orpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application. The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and only addressed one of the metaphor processing subtasks: identification of me"
N13-1118,J13-2003,1,\N,Missing
N13-1118,P02-1029,0,\N,Missing
N16-1020,R11-1055,0,0.124832,"re 1{·} is the indicator function and we train on D examples with K classes. We obtain image embeddings by doing a forward pass with a given image and taking the 4096-dimensional fully connected layer that precedes the softmax (typically called FC7) as the representation of that image. To construct our embeddings, we used up to 10 images for a given word or phrase, which were obtained through Google Images. It has been shown that images from Google yield higher quality representations than comparable resources such as Flickr and are competitive with hand-crafted datasets (Fergus et al., 2005; Bergsma and Goebel, 2011). We created our final visual representations for words and phrases by taking the average of the extracted image embeddings for a given word or phrase. 3.3 Multimodal fusion strategies While it is desirable to jointly learn representations from different modalities at the same time, this is often not feasible (or may lead to poor performance) due to data sparsity. Instead, we learn uni-modal representations independently, as described above, and then combine them into multi-modal ones. Previous work in multi-modal semantics (Bruni et al., 163 2014) investigated different ways of combining, or"
N16-1020,W13-0901,0,0.495777,"een distinct, and seemingly unrelated, concepts. For instance, when we talk about “the turning wheels of a political regime”, “rebuilding the campaign machinery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neu"
N16-1020,W06-3506,0,0.0602043,"and Johnson, 1980; Feldman, 2006). Metaphors arise due to systematic associations between distinct, and seemingly unrelated, concepts. For instance, when we talk about “the turning wheels of a political regime”, “rebuilding the campaign machinery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, a"
N16-1020,W13-0908,0,0.0505639,"es of the known ones. Turney et al. (2011) hypothesized that metaphor is commonly used to describe abstract concepts in terms of more concrete or physical experiences. Thus, Turney and colleagues expected that there would be some discrepancy in the level of concreteness of source and target terms in the metaphor. They developed a method to automatically measure concreteness of words and applied it to identify verbal and adjectival metaphors. Neuman et al. (2013) and Gandy et al. (2013) followed in Turney’s steps, extending the models by incorporating information about selectional preferences. Heintz et al. (2013) and Strzalkowski et al. (2013) focused on modeling topical structure of text to identify metaphor. Their main hypothesis was that metaphorical language (coming from a different domain) would represent atypical vocabulary within the topical structure of the text. Strzalkowski et al. (2013) acquired a set of topic chains by linking semantically related words in a given text. They then looked for vocabulary outside the topic chain and yet connected to topic chain words via syntactic dependencies and exhibiting high imageability. Heintz et al. (2013) used LDA topic modelling to identify sets of s"
N16-1020,W13-0907,0,0.119098,"c associations between distinct, and seemingly unrelated, concepts. For instance, when we talk about “the turning wheels of a political regime”, “rebuilding the campaign machinery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al"
N16-1020,D14-1005,1,0.748079,"al., 2014), lexical entailment (Kiela et al., 2015a), compositionality (Roller and Schulte im Walde, 2013) and bilingual lexicon induction (Kiela et al., 2015b). Using visual information is particularly relevant to modelling metaphor, where imagery is ported across domains. In this paper, we present the first metaphor identification method integrating meaning representations learned from linguistic and visual data. We construct our representations using a skip-gram model of Mikolov et al. (2013a) trained on textual data to obtain linguistic embeddings and a deep convolutional neural network (Kiela and Bottou, 2014) trained on image data to obtain visual embeddings. Linguistic word embeddings have been previously successfully used to answer analogy questions (Mikolov et al., 2013b; Levy and Goldberg, 2014). These works have shown that such representations capture the nuances of word meaning needed to recognise relational similarity (e.g. between pairs “king : queen” and “man : woman”), quantified by the respective vector offsets (king – queen ≈ man – woman). In our experiments, we investigate how well these representations can capture information about source and target domains and their interaction in a"
N16-1020,D15-1293,1,0.417472,"ependently, as described above, and then combine them into multi-modal ones. Previous work in multi-modal semantics (Bruni et al., 163 2014) investigated different ways of combining, or fusing, linguistic and perceptual cues. When calculating similarity, for instance, one can either combine the representations first and subsequently compute similarity scores; or compute similarity scores independently per modality and afterwards combine the scores. In contrast with joint learning (which has also been called early fusion), these two possibilities represent middle and late fusion, respectively (Kiela and Clark, 2015). We experiment with middle and late fusion strategies. In middle fusion, we L-2 normalise and concatenate the vectors for linguistic and visual representations and then compute a metaphoricity score for a phrase based on this joint representation. In late fusion, we first compute the metaphoricity scores based on linguistic and visual representations independently, and then combine the metaphoricity scores by taking their average. 3.4 Measuring metaphoricity We investigate a set of arithmetic operations on the linguistic, visual and multimodal embedding vectors to determine whether the two wo"
N16-1020,P15-2020,1,0.678425,"Missing"
N16-1020,D15-1015,1,0.816301,"Missing"
N16-1020,W07-0103,0,0.0213517,"nery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used manually-annotated linguistic resources to determi"
N16-1020,W14-1618,0,0.0318807,"rticularly relevant to modelling metaphor, where imagery is ported across domains. In this paper, we present the first metaphor identification method integrating meaning representations learned from linguistic and visual data. We construct our representations using a skip-gram model of Mikolov et al. (2013a) trained on textual data to obtain linguistic embeddings and a deep convolutional neural network (Kiela and Bottou, 2014) trained on image data to obtain visual embeddings. Linguistic word embeddings have been previously successfully used to answer analogy questions (Mikolov et al., 2013b; Levy and Goldberg, 2014). These works have shown that such representations capture the nuances of word meaning needed to recognise relational similarity (e.g. between pairs “king : queen” and “man : woman”), quantified by the respective vector offsets (king – queen ≈ man – woman). In our experiments, we investigate how well these representations can capture information about source and target domains and their interaction in a metaphor. We then enrich these representations with visual information. We first acquire linguistic and visual embeddings for individual words and then extend the methods to learn embeddings fo"
N16-1020,Q13-1031,0,0.0263483,"break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used manually-annotated linguistic resources to determine these properties (such as the MRC concreteness database (Wilson, 1988)). To the best of our knowledge"
N16-1020,P14-5010,0,0.00703906,"w and p(c|w; θ) is a softmax function: evc ·vw , vc0 ·vw c0 ∈C e p(c|w; θ) = P (2) where vc and vw are vector representations of c and w. The parameters we need to set are thus vci and vwi for all words in our word vocabulary V and context vocabulary C, and the set of dimensions i ∈ 1, . . . , d. Given a set D of word-context pairs, embeddings are learned by optimizing the following objective: X arg max log p(c|w) = θ X (w,c)∈D (w,c)∈D (log evc ·vw − log X evc0 ·vw ) (3) c0 ∈C We used a recent dump of Wikipedia1 as our corpus. The text was lemmatized, tagged, and parsed with Stanford CoreNLP (Manning et al., 2014). Words that appeared less than 100 times in their lemmatized form were ignored. The 100-dimensional word and phrase embeddings were learned in two stages: in a first pass, we obtained word-level embeddings (e.g. for white and rabbit) using the standard skip-gram with negative sampling of Eq. (3); we then obtained phrase embeddings (e.g. for white rabbit) through a second pass over the same corpus. In the second pass, the vectors vc and vc0 of Eq. (3) were set to their values from the first pass, and kept fixed. Verb-noun phrases were extracted by finding nsubj and dobj arcs with V B head and"
N16-1020,J04-1002,0,0.0216935,"Strzalkowski et al. (2013) acquired a set of topic chains by linking semantically related words in a given text. They then looked for vocabulary outside the topic chain and yet connected to topic chain words via syntactic dependencies and exhibiting high imageability. Heintz et al. (2013) used LDA topic modelling to identify sets of source and target domain vocabulary. In their system, the acquired topics represented source and target domains, and sentences containing vocabulary from both were tagged as metaphorical. Other approaches addressed automatic identification of conceptual metaphor. Mason (2004) automatically acquired domain-specific selectional preferences of verbs, and then, by mapping their common nominal arguments in different domains, arrived at the corresponding metaphorical mappings. For example, the verb pour has a strong preference for liquids in the LAB domain and for money in the FINANCE domain, suggesting the mapping MONEY is LIQUID. Shutova et al. (2010) pointed out that the metaphorical uses of words constitute a large portion of the dependency features extracted for abstract concepts from corpora. For example, the feature vector for politics would contain GAME or MECH"
N16-1020,N13-1090,0,0.20218,"been shown successful in tasks such as modeling semantic similarity and relatedness (Silberer and Lapata, 2012; Bruni et al., 2014), lexical entailment (Kiela et al., 2015a), compositionality (Roller and Schulte im Walde, 2013) and bilingual lexicon induction (Kiela et al., 2015b). Using visual information is particularly relevant to modelling metaphor, where imagery is ported across domains. In this paper, we present the first metaphor identification method integrating meaning representations learned from linguistic and visual data. We construct our representations using a skip-gram model of Mikolov et al. (2013a) trained on textual data to obtain linguistic embeddings and a deep convolutional neural network (Kiela and Bottou, 2014) trained on image data to obtain visual embeddings. Linguistic word embeddings have been previously successfully used to answer analogy questions (Mikolov et al., 2013b; Levy and Goldberg, 2014). These works have shown that such representations capture the nuances of word meaning needed to recognise relational similarity (e.g. between pairs “king : queen” and “man : woman”), quantified by the respective vector offsets (king – queen ≈ man – woman). In our experiments, we in"
N16-1020,W13-0904,0,0.0949705,"man, 2006). Metaphors arise due to systematic associations between distinct, and seemingly unrelated, concepts. For instance, when we talk about “the turning wheels of a political regime”, “rebuilding the campaign machinery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features"
N16-1020,C14-1165,0,0.0451843,"l regime”, “rebuilding the campaign machinery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used m"
N16-1020,D13-1115,0,0.02017,"Missing"
N16-1020,N13-1118,1,0.957214,"For instance, when we talk about “the turning wheels of a political regime”, “rebuilding the campaign machinery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2"
N16-1020,C10-1113,1,0.601483,"tem, the acquired topics represented source and target domains, and sentences containing vocabulary from both were tagged as metaphorical. Other approaches addressed automatic identification of conceptual metaphor. Mason (2004) automatically acquired domain-specific selectional preferences of verbs, and then, by mapping their common nominal arguments in different domains, arrived at the corresponding metaphorical mappings. For example, the verb pour has a strong preference for liquids in the LAB domain and for money in the FINANCE domain, suggesting the mapping MONEY is LIQUID. Shutova et al. (2010) pointed out that the metaphorical uses of words constitute a large portion of the dependency features extracted for abstract concepts from corpora. For example, the feature vector for politics would contain GAME or MECH ANISM terms among the frequent features. As a result, distributional clustering of abstract nouns with such features identifies groups of diverse concepts metaphorically associated with the same source domain (or sets of source domains). Shutova et al. (2010) exploit this property of co-occurrence vectors to identify new metaphorical mappings starting from a set of examples. S"
N16-1020,C12-2109,1,0.550266,"Missing"
N16-1020,N10-1147,1,0.267593,"educing the risk of human annotation noise and having a wider coverage and applicability. Since the method relies on automatically acquired lexical knowledge, in the form of linguistic and visual embeddings, and is otherwise resource-independent, it can be applied to unrestricted text in any domain and easily tailored to other metaphor processing tasks. In the future, it would be interesting to apply multimodal word and phrase embeddings to automatically interpret metaphorical language, e.g. by deriving literal or conventional paraphrases for metaphorical expressions (similarly to the task of Shutova (2010)). Multimodal embeddings are also likely to provide useful information for the models of metaphor translation, as they have already proved successful in bilingual lexicon induction more generally (Kiela et al., 2015b). Finally, it would be interesting to further investigate compositional properties of metaphorical language using multimodal phrase embeddings and to apply the embeddings to automatically generalise metaphorical associations between distinct concepts or domains. Acknowledgment We are grateful to the NAACL reviewers for their helpful feedback. Ekaterina Shutova’s research is suppor"
N16-1020,D12-1130,0,0.011038,"yed information learned from both linguistic and visual data. Ample re160 Proceedings of NAACL-HLT 2016, pages 160–170, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics search in cognitive science suggests that human meaning representations are not merely a product of our linguistic exposure, but are also grounded in our perceptual system and sensori-motor experience (Barsalou, 2008; Louwerse, 2011). Semantic models integrating information from multiple modalities have been shown successful in tasks such as modeling semantic similarity and relatedness (Silberer and Lapata, 2012; Bruni et al., 2014), lexical entailment (Kiela et al., 2015a), compositionality (Roller and Schulte im Walde, 2013) and bilingual lexicon induction (Kiela et al., 2015b). Using visual information is particularly relevant to modelling metaphor, where imagery is ported across domains. In this paper, we present the first metaphor identification method integrating meaning representations learned from linguistic and visual data. We construct our representations using a skip-gram model of Mikolov et al. (2013a) trained on textual data to obtain linguistic embeddings and a deep convolutional neural"
N16-1020,W13-0909,0,0.461432,"Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used manually-annotated linguistic resources to determine these properties (such as the MRC concreteness database (Wilson, 1988)). To the best of our knowledge, there has not yet been a metaphor processing method that employed information learned from both linguistic and visual data. Ample re160 Proceedings of NAACL-HLT 2016, pages 160–170, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics search in cognitive science suggests that human meaning representations are not merely a product of our linguis"
N16-1020,W13-0906,0,0.137075,"arise due to systematic associations between distinct, and seemingly unrelated, concepts. For instance, when we talk about “the turning wheels of a political regime”, “rebuilding the campaign machinery” or “mending foreign policy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identific"
N16-1020,P14-1024,0,0.185534,"tor space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used manually-annotated linguistic resources to determine these properties (such as the MRC concreteness database (Wilson, 1988)). To the best of our knowledge, there has not yet been a metaphor processing method that employed information learned from both linguistic and visual data. Ample re160 Proceedings of NAACL-HLT 2016, pages 160–170, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics search in cognitive science suggests that human meaning representations are not merely a product of our linguistic exposure, but are al"
N16-1020,D11-1063,0,0.0869636,"et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used manually-annotated linguistic resources to determine these properties (such as the MRC concreteness database (Wilson, 1988)). To the best of our knowledge, there has not yet been a metaphor processing method that employed information learned from both linguistic and visual data. Ample re160 Proceedings of NAACL-HLT 2016, pages 160–170, c San Diego, California, June 12-17, 2016. 2016 Association for Computational Linguistics search in cognitive science suggests that h"
N16-1020,C08-1119,0,0.0251462,", they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used manually-annotated linguistic resources to determine these properties (such as the MRC concreteness database (Wilson, 1988)). To the best"
N16-1020,W13-0905,0,0.0391912,"cy”, we view politics and political systems in terms of mechanisms, they can function, break, be mended Metaphor is pervasive in our communication, which makes it important for NLP applications dealing with real-world text. A number of approaches to metaphor processing have thus been proposed, using supervised classification (Gedigian et al., 2006; Mohler et al., 2013; Tsvetkov et al., 2013; Hovy et al., 2013; Dunn, 2013a), clustering (Shutova et al., 2010; Shutova and Sun, 2013), vector space models (Shutova et al., 2012; Mohler et al., 2014), lexical resources (Krishnakumaran and Zhu, 2007; Wilks et al., 2013) and web search with lexicosyntactic patterns (Veale and Hao, 2008; Li et al., 2013; Bollegala and Shutova, 2013). So far, these and other metaphor processing works relied on textual data to construct their models. Yet, several experiments indicated that perceptual properties of concepts, such as concreteness and imageability, are important features for metaphor identification (Turney et al., 2011; Neuman et al., 2013; Gandy et al., 2013; Strzalkowski et al., 2013; Tsvetkov et al., 2014). However, all of these methods used manually-annotated linguistic resources to determine these properties ("
N16-1020,J15-4002,1,\N,Missing
N16-1020,S16-2003,1,\N,Missing
N16-1020,W15-1402,0,\N,Missing
N19-1059,S13-2007,0,0.0206857,"often required to correctly interpret metaphors. To the best of our knowledge, this is the first work to investigate the effects of broader discourse on metaphor identification.1 Introduction From bottled up anger to the world is your oyster, metaphor is a defining component of language, adding poetry and humor to communication (Glucksberg and McGlone, 2001) and serving as a tool for reasoning about relations between concepts (Lakoff and Johnson, 1980). Designing metaphor processing systems has thus seen significant interest in the NLP community, with applications from information retrieval (Korkontzelos et al., 2013) to machine translation (Saygin, 2001). An important first step in any metaphor processing pipeline is metaphor identification. To date, most approaches to its identification operate in restricted contexts, for instance, by only considering isolated verb–argument pairs (e.g. deflate economy) (Rei et al., 2017) or the sentence containing an utterance (Gao et al., 2018). However, wider context is crucial for understanding metaphor: for instance, the phrase drowning students can be interpreted as literal (in the context of water) or metaphorical (in the context of homework). Of2 Related work Meta"
N19-1059,P16-2017,1,0.898693,"tion is typically framed as a binary classification task, either with (1) word tu1 Code and data available at https://github.com/ jayelm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited t"
N19-1059,W16-1609,0,0.0491173,"Missing"
N19-1059,W16-1104,0,0.0177879,"-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results with BiLSTMs and contextualized word embeddings (Peters et al., 2018). To the best of our knowledge, none of the existing approaches ha"
N19-1059,W18-0907,1,0.87645,"istics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results with BiLSTMs and contextualized word embeddings (Peters et al., 2018). To the best of our knowledge, none of the existing approaches have utilized information from wider discourse context in metaphor identification, nor investigated its effects."
N19-1059,D18-1060,0,0.632044,"tool for reasoning about relations between concepts (Lakoff and Johnson, 1980). Designing metaphor processing systems has thus seen significant interest in the NLP community, with applications from information retrieval (Korkontzelos et al., 2013) to machine translation (Saygin, 2001). An important first step in any metaphor processing pipeline is metaphor identification. To date, most approaches to its identification operate in restricted contexts, for instance, by only considering isolated verb–argument pairs (e.g. deflate economy) (Rei et al., 2017) or the sentence containing an utterance (Gao et al., 2018). However, wider context is crucial for understanding metaphor: for instance, the phrase drowning students can be interpreted as literal (in the context of water) or metaphorical (in the context of homework). Of2 Related work Metaphor identification is typically framed as a binary classification task, either with (1) word tu1 Code and data available at https://github.com/ jayelm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) w"
N19-1059,P14-5010,0,0.00466753,"Missing"
N19-1059,W18-0916,0,0.029288,"Missing"
N19-1059,W15-1404,0,0.0211548,"https://github.com/ jayelm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results with BiLSTMs and contextualized word embeddings (Peters et al.,"
N19-1059,D14-1162,0,0.0964298,"Missing"
N19-1059,P14-1024,0,0.0866881,") word tu1 Code and data available at https://github.com/ jayelm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results with BiLSTMs and contextual"
N19-1059,N18-1202,0,0.0815765,"ooksCorpus (Zhu et al., 2015). From this model, we extract 4800-dimensional representations for verb lemma, arguments, and contexts. Models For each utterance, our models learn generic representations of a verb lemma,2 its syntactic arguments, and its broader discourse context. We concatenate these features into a single feature vector and feed them into a gradient boosting decision tree classifier (Chen and Guestrin, 2016).3 By observing performance differences when using the lemma only (L), lemma + arguments (LA), or ELMo Finally, we use ELMo, a model of deep contextualized word embeddings (Peters et al., 2018). We extract 1024-dimensional representations from the last layer of a stacked BiLSTM 4 These methods differ significantly in dimensionality and training data. Our intent is not to exhaustively compare these methods, but rather claim generally that many embeddings give good performance on this task. 5 Since some methods provide only document embeddings and not word embeddings, for consistency, in all methods we use the same embedding process even for single-word verbs and arguments. 2 The lemmatized form of the verb has improved generalization in other systems (Beigman Klebanov et al., 2016)."
N19-1059,D11-1063,0,0.0725586,"task, either with (1) word tu1 Code and data available at https://github.com/ jayelm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results wit"
N19-1059,D17-1162,1,0.825747,"munication (Glucksberg and McGlone, 2001) and serving as a tool for reasoning about relations between concepts (Lakoff and Johnson, 1980). Designing metaphor processing systems has thus seen significant interest in the NLP community, with applications from information retrieval (Korkontzelos et al., 2013) to machine translation (Saygin, 2001). An important first step in any metaphor processing pipeline is metaphor identification. To date, most approaches to its identification operate in restricted contexts, for instance, by only considering isolated verb–argument pairs (e.g. deflate economy) (Rei et al., 2017) or the sentence containing an utterance (Gao et al., 2018). However, wider context is crucial for understanding metaphor: for instance, the phrase drowning students can be interpreted as literal (in the context of water) or metaphorical (in the context of homework). Of2 Related work Metaphor identification is typically framed as a binary classification task, either with (1) word tu1 Code and data available at https://github.com/ jayelm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguist"
N19-1059,W18-0913,0,0.479282,"y of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results with BiLSTMs and contextualized word embeddings (Peters et al., 2018). To the best of our knowledge, none of the existing approaches have utilized information from wider discourse context in metaphor identification, nor investigated its effects. 3 lemma + arguments + context (LAC), we can investigate the effects of including broader context. To obtain arguments for verbs, we extract subjects and direct objects with Stanford Core"
N19-1059,S13-1040,1,0.815273,"ork Metaphor identification is typically framed as a binary classification task, either with (1) word tu1 Code and data available at https://github.com/ jayelm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recentl"
N19-1059,N16-1020,1,0.873034,"elm/broader-metaphor. 596 Proceedings of NAACL-HLT 2019, pages 596–601 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics ples such as SVO triples (car drinks gasoline) or (2) whole sentences as input, where the goal is to predict the metaphoricity of a token in the sentence. Recent work has used a variety of features extracted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results with BiLSTMs and contextualized word embeddings (Peters et al., 2018). To the best of o"
N19-1059,W18-0918,0,0.056736,"racted from these two types of contexts, including selectional preferences (Shutova, 2013; Beigman Klebanov et al., 2016), concreteness/imageability (Turney et al., 2011; Tsvetkov et al., 2014), multi-modal (Tekiroglu et al., 2015; Shutova et al., 2016) and neural features (Do Dinh and Gurevych, 2016; Rei et al., 2017). At the recent VU Amsterdam (VUA) metaphor identification shared task (Leong et al., 2018), neural approaches dominated, with most teams using LSTMs trained on word embeddings and additional linguistic features, such as semantic classes and part of speech tags (Wu et al., 2018; Stemle and Onysko, 2018; Mykowiecka et al., 2018; Swarnkar and Singh, 2018). Most recently, Gao et al. (2018) revisited this task, reporting state-of-the-art results with BiLSTMs and contextualized word embeddings (Peters et al., 2018). To the best of our knowledge, none of the existing approaches have utilized information from wider discourse context in metaphor identification, nor investigated its effects. 3 lemma + arguments + context (LAC), we can investigate the effects of including broader context. To obtain arguments for verbs, we extract subjects and direct objects with Stanford CoreNLP (Manning et al., 2014"
N19-1059,W18-0914,0,0.0224686,"Missing"
N19-1221,C18-1093,1,0.705478,"a heterogeneous graph-structured modeling of communities significantly advances the current state of the art in abusive language detection. 1 2 Introduction Matthew Zook (2012) carried out an interesting study showing that the racist tweets posted in response to President Obama’s re-election were not distributed uniformly across the United States but instead formed clusters. This phenomenon is known as homophily: i.e., people, both in real life and online, tend to cluster with those who appear similar to themselves. To model homophily, recent research in abusive language detection on Twitter (Mishra et al., 2018a) incorporates embeddings for authors (i.e., users who have composed tweets) that encode the structure of their surrounding communities. The embeddings (called author profiles) are generated by applying a node embedding framework to an undirected unlabeled community graph where nodes denote the authors and edges the follower–following relationships amongst them on Twitter. However, these profiles do not capture the linguistic behavior of the authors and their communities and do not convey whether their tweets tend to be abusive or not. Related work Supervised learning for abusive language det"
N19-1221,W18-5101,1,0.755809,"a heterogeneous graph-structured modeling of communities significantly advances the current state of the art in abusive language detection. 1 2 Introduction Matthew Zook (2012) carried out an interesting study showing that the racist tweets posted in response to President Obama’s re-election were not distributed uniformly across the United States but instead formed clusters. This phenomenon is known as homophily: i.e., people, both in real life and online, tend to cluster with those who appear similar to themselves. To model homophily, recent research in abusive language detection on Twitter (Mishra et al., 2018a) incorporates embeddings for authors (i.e., users who have composed tweets) that encode the structure of their surrounding communities. The embeddings (called author profiles) are generated by applying a node embedding framework to an undirected unlabeled community graph where nodes denote the authors and edges the follower–following relationships amongst them on Twitter. However, these profiles do not capture the linguistic behavior of the authors and their communities and do not convey whether their tweets tend to be abusive or not. Related work Supervised learning for abusive language det"
N19-1221,D17-1117,0,0.0515604,"Missing"
N19-1221,W17-4209,0,0.13164,"Missing"
N19-1221,N18-2019,0,0.0582534,"9; Warner and Hirschberg, 2012). Djuric et al. (2015) showed that dense comment representations generated using paragraph2vec outperform bag-of-words features. Several works have since utilized (deep) neural architectures to achieve impressive results on a variety of abuse-annotated datasets (Nobata et al., 2016; Pavlopoulos et al., 2017a). Recently, the research focus has shifted towards extraction of features that capture behavioral and social traits of users. Pavlopoulos et al. (2017b) showed that including randomly-initialized user embeddings improved the performance of their RNN methods. Qian et al. (2018) employed LSTMs to generate inter and intra-user representations based on tweets, but they did not leverage community information. 2145 Proceedings of NAACL-HLT 2019, pages 2145–2150 c Minneapolis, Minnesota, June 2 - June 7, 2019. 2019 Association for Computational Linguistics 3 Dataset Following previous work (Mishra et al., 2018a), we experiment with a subset of the Twitter dataset compiled by Waseem and Hovy (2016). Waseem and Hovy released a list of 16, 907 tweet IDs along with their corresponding annotations,1 labeling each tweet as racist, sexist or neither (clean). Recently, Mishra et"
N19-1221,W12-2103,0,0.341837,"an undirected unlabeled community graph where nodes denote the authors and edges the follower–following relationships amongst them on Twitter. However, these profiles do not capture the linguistic behavior of the authors and their communities and do not convey whether their tweets tend to be abusive or not. Related work Supervised learning for abusive language detection was first explored by Spertus (1997) who extracted rule-based features to train their classifier. Subsequently, manually-engineered lexical– syntactic features formed the crux of most approaches to the task (Yin et al., 2009; Warner and Hirschberg, 2012). Djuric et al. (2015) showed that dense comment representations generated using paragraph2vec outperform bag-of-words features. Several works have since utilized (deep) neural architectures to achieve impressive results on a variety of abuse-annotated datasets (Nobata et al., 2016; Pavlopoulos et al., 2017a). Recently, the research focus has shifted towards extraction of features that capture behavioral and social traits of users. Pavlopoulos et al. (2017b) showed that including randomly-initialized user embeddings improved the performance of their RNN methods. Qian et al. (2018) employed LST"
N19-1221,N16-2013,0,0.0599349,"is set to 3 for the output O ∈ Rn×3 of the GCN to be a softmax distribution over the 3 classes in the data. The GCN is trained by minimizing the crossentropy loss with respect to the labeled nodes of the graph. Once the model is trained, we extract e F W (1) 200-dimensional embeddings E = A from the first layer (i.e., the layer’s output without activation). This contains embeddings for author nodes as well as tweet nodes. For our experiments on author profiles, we make use of the former. 2 Stacking more layers does not improve results on the validation set further. This method is adopted from Waseem and Hovy (2016) wherein they train a logistic regression classifier on character n-grams (up to 4grams) of the tweets. Character n-grams have been shown to be highly effective for abuse detection due to their robustness to spelling variations. + AUTH. This is the state of the art method (Mishra et al., 2018a) for the dataset we are using. For each tweet, the profile of its author (generated by node2vec from the community graph) is appended onto the tweet’s character n-gram representation for training the LR classifier as above. LR + EXTD. This method is identical to LR + AUTH , except that we now run node2ve"
P09-3001,J91-4003,0,0.355121,") and (5) represent a variation of this phenomenon called logical metonymy. Here both the book and three martinis have eventive interpretations, i.e. the noun phrases stand for the events of reading the book and drinking three martinis respectively. Such behaviour is triggered by the type requirements the verb (or the preposition) places onto its argument. This is known in linguistics as a phenomenon of type coercion. Many existing approaches to logical metonymy explain systematic syntactic ambiguity of metonymic verbs (such as enjoy) or prepositions (such as after) by means of type coercion (Pustejovsky, 1991; Pustejovsky, 1995; Briscoe et al., 1990; Verspoor, 1997; Godard and Jayez, 1993). Logical metonymy occurs in natural language texts relatively frequently. Therefore, its automatic interpretation would significantly facilitate the task of many NLP applications that require semantic processing (e.g., machine translation, information extraction, question answering and many others). Utiyama et al. (2000) followed by Lapata and Lascarides (2003) used text corpora to automatically derive interpretations of metonymic phrases. Introduction Metonymy is defined as the use of a word or a phrase to stan"
P09-3001,andersen-etal-2008-bnc,0,0.0121103,"This is due to the fact that there is no word sense disambiguated corpus available, which would be large enough to reliably extract statistics for metonymic interpretations. 4 4.1 Extracting Ambiguous Interpretations Parameter Estimation We used the method developed by Lapata and Lascarides (2003) to create the initial list of nondisambiguated interpretations. The parameters of the model were estimated from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser of Briscoe et al. (2006). We used the grammatical relations (GRs) output of RASP for BNC created by Andersen et al. (2008). In particular, we extracted all direct and indirect object relations for the nouns from the metonymic phrases, i.e. all the verbs that take the head noun in the compliment as an object (direct or indirect), in order to obtain the counts for f (o, e). Relations expressed in the passive voice and with the use of coordination were also extracted. The verb-object pairs attested in the corpus only once were discarded, as well as the verb be, since it does not add any semantic information to the metonymic interpretation. In the case of indirect object relations, the verb was considered to constitu"
P09-3001,C00-2128,0,0.0770911,"on of type coercion. Many existing approaches to logical metonymy explain systematic syntactic ambiguity of metonymic verbs (such as enjoy) or prepositions (such as after) by means of type coercion (Pustejovsky, 1991; Pustejovsky, 1995; Briscoe et al., 1990; Verspoor, 1997; Godard and Jayez, 1993). Logical metonymy occurs in natural language texts relatively frequently. Therefore, its automatic interpretation would significantly facilitate the task of many NLP applications that require semantic processing (e.g., machine translation, information extraction, question answering and many others). Utiyama et al. (2000) followed by Lapata and Lascarides (2003) used text corpora to automatically derive interpretations of metonymic phrases. Introduction Metonymy is defined as the use of a word or a phrase to stand for a related concept which is not explicitly mentioned. Here are some examples of metonymic phrases: (1) The pen is mightier than the sword. (2) He played Bach. 1 Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 1–9, c Suntec, Singapore, 4 August 2009. 2009 ACL and AFNLP Metonymic Phrase finish video Utiyama et al. (2000) used a statistical model for the interpretation of general"
P09-3001,P06-4020,0,0.136247,"challenges of our task is that we use a non-disambiguated corpus while ranking particular senses. This is due to the fact that there is no word sense disambiguated corpus available, which would be large enough to reliably extract statistics for metonymic interpretations. 4 4.1 Extracting Ambiguous Interpretations Parameter Estimation We used the method developed by Lapata and Lascarides (2003) to create the initial list of nondisambiguated interpretations. The parameters of the model were estimated from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser of Briscoe et al. (2006). We used the grammatical relations (GRs) output of RASP for BNC created by Andersen et al. (2008). In particular, we extracted all direct and indirect object relations for the nouns from the metonymic phrases, i.e. all the verbs that take the head noun in the compliment as an object (direct or indirect), in order to obtain the counts for f (o, e). Relations expressed in the passive voice and with the use of coordination were also extracted. The verb-object pairs attested in the corpus only once were discarded, as well as the verb be, since it does not add any semantic information to the meton"
P09-3001,J91-1003,0,0.360538,"Missing"
P09-3001,E93-1021,0,0.168851,"pata and Lascarides (2003). By carrying out a human experiment we prove that such a representation is intuitive to human subjects. We derive a ranking scheme for verb senses using an unannotated corpus, WordNet sense numbering and glosses. We also provide an account of the requirements that different aspectual verbs impose onto the interpretation of logical metonymy. We tested our system on verb-object metonymic phrases. It identifies and ranks metonymic interpretations with the mean average precision of 0.83 as compared to the gold standard. 1 (5) After three martinis John was feeling well. (Godard and Jayez, 1993) The metonymic adage in (1) is a classical example. Here the pen stands for the press and the sword for military power. In the following example Bach is used to refer to the composer’s music and in (3) the glass stands for its content, i.e. the actual drink (beverage). The sentences (4) and (5) represent a variation of this phenomenon called logical metonymy. Here both the book and three martinis have eventive interpretations, i.e. the noun phrases stand for the events of reading the book and drinking three martinis respectively. Such behaviour is triggered by the type requirements the verb (o"
P09-3001,J03-2004,0,0.108617,"ss, 1991) (4) He enjoyed the book. (Lapata and Lascarides, 2003) The use of figurative language is ubiquitous in natural language texts and it is a serious bottleneck in automatic text understanding. We address the problem of interpretation of logical metonymy, using a statistical method. Our approach originates from that of Lapata and Lascarides (2003), which generates a list of nondisambiguated interpretations with their likelihood derived from a corpus. We propose a novel sense-based representation of the interpretation of logical metonymy and a more thorough evaluation method than that of Lapata and Lascarides (2003). By carrying out a human experiment we prove that such a representation is intuitive to human subjects. We derive a ranking scheme for verb senses using an unannotated corpus, WordNet sense numbering and glosses. We also provide an account of the requirements that different aspectual verbs impose onto the interpretation of logical metonymy. We tested our system on verb-object metonymic phrases. It identifies and ranks metonymic interpretations with the mean average precision of 0.83 as compared to the gold standard. 1 (5) After three martinis John was feeling well. (Godard and Jayez, 1993) Th"
P09-3001,J87-3002,0,\N,Missing
P10-1071,J91-1003,0,0.662052,"sions. In other words, metaphor always involves two concepts or conceptual domains: the target (also called topic or tenor in the linguistics literature) and the source (or vehicle). Consider the examples in (5) and (6). (7) My car drinks gasoline. (Wilks, 1978) The verb drink normally takes an animate subject and a liquid object. Therefore, drink taking a car as a subject is an anomaly, which may in turn indicate the metaphorical use of drink. 3 Automatic Metaphor Recognition One of the first attempts to identify and interpret metaphorical expressions in text automatically is the approach of Fass (1991). It originates in the work of Wilks (1978) and utilizes handcoded knowledge. Fass (1991) developed a system called met*, capable of discriminating between literalness, metonymy, metaphor and anomaly. It does this in three stages. First, literalness is distinguished from non-literalness using selectional preference violation as an indicator. In the case that non-literalness is detected, the respective phrase is tested for being a metonymic relation using hand-coded patterns (such as CONTAINERfor-CONTENT). If the system fails to recognize metonymy, it proceeds to search the knowledge base for a"
P10-1071,W06-3506,0,0.356514,"Missing"
P10-1071,W03-1402,0,0.0393051,"Missing"
P10-1071,J98-1002,0,0.018322,"Missing"
P10-1071,kingsbury-palmer-2002-treebank,0,0.0740467,"Missing"
P10-1071,T87-1040,0,0.241694,"e included in WordNet, however without any accompanying semantic annotation. Metaphor and Polysemy The theorists of metaphor distinguish between two kinds of metaphorical language: novel (or poetic) metaphors, that surprise our imagination, and conventionalized metaphors, that become a part of an ordinary discourse. “Metaphors begin their lives as novel poetic creations with marked rhetorical effects, whose comprehension requires a special imaginative leap. As time goes by, they become a part of general usage, their comprehension becomes more automatic, and their rhetorical effect is dulled” (Nunberg, 1987). Following Orwell (1946) Nunberg calls such metaphors “dead” and claims that they are not psychologically distinct from literally-used terms. This scheme demonstrates how metaphorical associations capture some generalisations governing polysemy: over time some of the aspects of the target domain are added to the meaning of a 6.2 Metaphor Identification 6.2.1 Pragglejaz Procedure Pragglejaz Group (2007) proposes a metaphor identification procedure (MIP) within the frame6 Sense definitions are taken from the Oxford English Dictionary. 693 work of the Metaphor in Discourse project (Steen, 2007)."
P10-1071,W07-0103,0,0.492449,"Missing"
P10-1071,peters-peters-2000-lexicalised,0,0.53875,"Missing"
P10-1071,W07-0102,0,0.0316984,"Missing"
P10-1071,shutova-teufel-2010-metaphor,1,0.287075,"t with a similar syntactic frame, (3) this physical significance was related to the abstract one. Team B had to annotate phrases according to their own intuitive definition of metaphor. Besides metaphorical expressions Wallington et al. (2003) attempted to annotate the involved source – target domain mappings. The annotators were given a set of mappings from the Master Metaphor List and were asked to assign the most suitable ones to the examples. However, the authors do not report the level of interannotator agreement nor the coverage of the mappings in the Master Metaphor List on their data. Shutova and Teufel (2010) adopt a different approach to the annotation of source – target domain mappings. They do not rely on predefined mappings, but instead derive independent sets of most common source and target categories. They propose a two stage procedure, whereby the metaphorical expressions are first identified using MIP, and then the source domain (where the basic sense comes from) and the target domain (the given context) are selected from the lists of categories. Shutova and Teufel (2010) report interannotator agreement of 0.61 (κ). 2. If you can establish the basic meaning that is distinct from the meani"
P10-1071,N10-1147,1,0.240088,"great variety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (2) and (3), to poetic and largely novel ones, such as (4). The use of metaphor is ubiquitous in natural language text and it is a serious bottleneck in automatic text understanding. 1 “I wandered lonely as a cloud”, William Wordsworth, 1804. 688 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 688–697, c Uppsala, Sweden, 11-16 July 2010. 2010 Association for Computational Linguistics In order to estimate the frequency of the phenomenon, Shutova (2010) conducted a corpus study on a subset of the British National Corpus (BNC) (Burnard, 2007) representing various genres. They manually annotated metaphorical expressions in this data and found that 241 out of 761 sentences contained a metaphor. Due to such a high frequency of their use, a system capable of recognizing and interpreting metaphorical expressions in unrestricted text would become an invaluable component of any semantics-oriented NLP application. Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaph"
P10-1071,C88-1081,0,0.824288,"tructure of a sentence (parsing), coreference resolution, named entity recognition and many others. Another cohort of researchers set the goal of improving applicationbased statistical inference (e.g. for recognizing textual entailment or automatic summarization). In contrast, there have been fewer attempts to bring the state-of-the-art NLP technologies together to model the way humans use language to frame high-level reasoning processes, such as for example, creative thought. The majority of computational approaches to (1) Hillary brushed aside the accusations. (2) How can I kill a process? (Martin, 1988) (3) I invested myself fully in this relationship. (4) And then my heart with pleasure fills, And dances with the daffodils.1 In metaphorical expressions seemingly unrelated features of one concept are associated with another concept. In the example (2) the computational process is viewed as something alive and, therefore, its forced termination is associated with the act of killing. Metaphorical expressions represent a great variety, ranging from conventional metaphors, which we reproduce and comprehend every day, e.g. those in (2) and (3), to poetic and largely novel ones, such as (4). The u"
P10-1071,D09-1067,0,0.00581774,"t in her” or “a carelessly leaked report” their system produces interpretations “All of this provoked an unfathomable excitement in her” and “a carelessly disclosed report” respectively. They first apply a probabilistic model to rank all possible paraphrases for the metaphorical expression given the context; and then use automatically induced selectional preferences to discriminate between figurative and literal paraphrases. The selectional preference distribution is defined in terms of selectional association measure introduced by Resnik (1993) over the noun classes automatically produced by Sun and Korhonen (2009). Shutova (2010) tested their system only on metaphors expressed by a verb and report a paraphrasing accuracy of 0.81. 5 Metaphor Resources Metaphor is a knowledge-hungry phenomenon. Hence there is a need for either an extensive manually-created knowledge-base or a robust knowledge acquisition system for interpretation of metaphorical expressions. The latter being a hard task, a great deal of metaphor research resorted to 4 http://www.cs.bham.ac.uk/∼jab/ATT-Meta/Databank/ EuroWordNet is a multilingual database with wordnets for several European languages (Dutch, Italian, Spanish, German, Frenc"
P10-1071,J04-1002,0,0.193405,"Missing"
P10-1071,C08-1119,0,0.0402344,"process relies on manually coded knowledge about the world and operates mainly in the source domain. The results are then projected onto the target domain using the conceptual mapping representation. The ATT-Meta project concerns metaphorical and metonymic description of mental states and reasoning about mental states using first order logic. Their system, however, does not take natural language sentences as input, but logical expressions that are representations of small discourse fragments. KARMA in turn deals with a broad range of abstract actions and events and takes parsed text as input. Veale and Hao (2008) derive a “fluid knowledge representation for metaphor interpretation and generation”, called Talking Points. Talking Points are a set of characteristics of concepts belonging to source and target domains and related facts about the world which the authors acquire automatically from WordNet and from the web. Talking Points are then organized in Slipnet, a framework that allows for a number of insertions, deletions and substitutions in definitions of such characteristics in order to establish a connection between the target and the source Automatic Metaphor Interpretation Almost simultaneously"
P10-1071,E06-1042,0,\N,Missing
P15-1092,W99-0901,0,0.0618645,"ratory Max Planck Institute IIIS University of Cambridge, UK for Informatics, Germany Tsinghua University, China es407@cam.ac.uk ntandon@mpi-inf.mpg.de gdm@demelo.org Abstract (Fass, 1991; Mason, 2004; Shutova et al., 2013; Li et al., 2013). Automatic acquisition of SPs from linguistic data has thus become an active area of research. The community has investigated a range of techniques to tackle data sparsity and to perform generalisation from observed arguments to their underlying types, including the use of WordNet synsets as SP classes (Resnik, 1993; Li and Abe, 1998; Clark and Weir, 1999; Abney and Light, 1999; Ciaramita and Johnson, 2000), word clustering (Rooth et al., 1999; Bergsma et al., 2008; Sun and Korhonen, 2009), distributional similarity metrics (Erk, 2007; Peirsman and Pad´o, 2010), latent ´ S´eaghdha, 2010; Ritter et al., variable models (O 2010), and neural networks (Van de Cruys, 2014). Selectional preferences (SPs) are widely used in NLP as a rich source of semantic information. While SPs have been traditionally induced from textual data, human lexical acquisition is known to rely on both linguistic and perceptual experience. We present the first SP learning method that simultaneous"
P15-1092,R11-1055,0,0.066643,"predicate p is frequently observed in the data with the arguments a0 similar to a. The systems compute similarities between distributional representations of arguments in a vector space. Bergsma et al. (2008) trained an SVM classifier to discriminate between felicitous and infelicitous verb-argument pairs. Their training data consisted of observed verb-argument pairs (positive examples) with unobserved, randomly-generated ones (negative examples). They classified nominal arguments of verbs, using their verb co-occurrence probabilities and information about their semantic classes as features. Bergsma and Goebel (2011) extended this method by incorporating image-driven noun features. They extract color and SIFT keypoint features from images found for a particular noun via Google image searches and add them to the feature vectors to classify nouns as felicitous or infelicitous arguments of a given verb. This method is the closest in spirit to ours and the only one so far to investigate the relevance of visual fea951 tures to lexical preference learning. However, our work casts the problem in a different framework: rather than relying on low-level visual properties of nouns in isolation, we explicitly model i"
P15-1092,D08-1007,0,0.0603052,"Missing"
P15-1092,W02-1016,0,0.133523,"Missing"
P15-1092,P06-4020,0,0.0196478,"al., 2013), video descriptions (Rohrbach et al., 2013), or tags (Srivastava et al., 2014). Other applications of multimodal data include language modeling (Kiros et al., 2014) and knowledge mining from images (Chen et al., 2013; Divvala et al., 2014). Young et al. (2014) apply simplification rules to image captions, showing that the resulting hierarchy of mappings between natural language expressions and images can be used for entailment tasks. 3 Experimental data Textual data. We extract linguistic features for our model from the BNC. In particular, we parse the corpus using the RASP parser (Briscoe et al., 2006) and extract subject–verb and verb–object relations from its dependency output. These relations are then used as features for clustering to obtain SP classes, as well as to quantify the strength of association between a particular verb and a particular argument class. Visual data. For the visual features of our model, we mine the Yahoo! Webscope Flickr-100M dataset (Shamma, 2014). Flickr-100M contains 99.3 million images and 0.7 million videos with language tags annotated by users, enabling us to generalise SPs at a large scale. The tags reflect how humans describe objects and actions from a v"
P15-1092,P12-1015,0,0.0266966,"cted of positive (observed) and negative (randomly-generated) examples for training. The network weights were optimized by requiring the model to assign a higher score to an observed pair than to the unobserved one by a given margin. 2.2 Multi-modal methods in semantics Previous work has used multimodal data to determine distributional similarity or to learn multimodal embeddings that project multiple modalities into the same vector space. Some studies rely on extensions of LDA to obtain correlations between words and visual features (Feng and Lapata, 2010; Roller and Schulte im Walde, 2013). Bruni et al. (2012) integrated visual features into distributional similarity models using simple vector concatenation. Instead of generic visual features, Silberer et al. (2013) relied on supervised learning to train 412 higher-level visual attribute classifiers. Applications of multimodal embeddings include zero-shot object detection, i.e. recognizing objects in images without training data for the object class (Socher et al., 2013; Frome et al., 2013; Lazaridou et al., 2014), and automatic generation of image captions (Kulkarni et al., 2013), video descriptions (Rohrbach et al., 2013), or tags (Srivastava et"
P15-1092,C00-1028,0,0.099225,"tute IIIS University of Cambridge, UK for Informatics, Germany Tsinghua University, China es407@cam.ac.uk ntandon@mpi-inf.mpg.de gdm@demelo.org Abstract (Fass, 1991; Mason, 2004; Shutova et al., 2013; Li et al., 2013). Automatic acquisition of SPs from linguistic data has thus become an active area of research. The community has investigated a range of techniques to tackle data sparsity and to perform generalisation from observed arguments to their underlying types, including the use of WordNet synsets as SP classes (Resnik, 1993; Li and Abe, 1998; Clark and Weir, 1999; Abney and Light, 1999; Ciaramita and Johnson, 2000), word clustering (Rooth et al., 1999; Bergsma et al., 2008; Sun and Korhonen, 2009), distributional similarity metrics (Erk, 2007; Peirsman and Pad´o, 2010), latent ´ S´eaghdha, 2010; Ritter et al., variable models (O 2010), and neural networks (Van de Cruys, 2014). Selectional preferences (SPs) are widely used in NLP as a rich source of semantic information. While SPs have been traditionally induced from textual data, human lexical acquisition is known to rely on both linguistic and perceptual experience. We present the first SP learning method that simultaneously draws knowledge from text,"
P15-1092,W99-0631,0,0.0149694,"de Melo Computer Laboratory Max Planck Institute IIIS University of Cambridge, UK for Informatics, Germany Tsinghua University, China es407@cam.ac.uk ntandon@mpi-inf.mpg.de gdm@demelo.org Abstract (Fass, 1991; Mason, 2004; Shutova et al., 2013; Li et al., 2013). Automatic acquisition of SPs from linguistic data has thus become an active area of research. The community has investigated a range of techniques to tackle data sparsity and to perform generalisation from observed arguments to their underlying types, including the use of WordNet synsets as SP classes (Resnik, 1993; Li and Abe, 1998; Clark and Weir, 1999; Abney and Light, 1999; Ciaramita and Johnson, 2000), word clustering (Rooth et al., 1999; Bergsma et al., 2008; Sun and Korhonen, 2009), distributional similarity metrics (Erk, 2007; Peirsman and Pad´o, 2010), latent ´ S´eaghdha, 2010; Ritter et al., variable models (O 2010), and neural networks (Van de Cruys, 2014). Selectional preferences (SPs) are widely used in NLP as a rich source of semantic information. While SPs have been traditionally induced from textual data, human lexical acquisition is known to rely on both linguistic and perceptual experience. We present the first SP learning m"
P15-1092,P07-1028,0,0.149228,"act (Fass, 1991; Mason, 2004; Shutova et al., 2013; Li et al., 2013). Automatic acquisition of SPs from linguistic data has thus become an active area of research. The community has investigated a range of techniques to tackle data sparsity and to perform generalisation from observed arguments to their underlying types, including the use of WordNet synsets as SP classes (Resnik, 1993; Li and Abe, 1998; Clark and Weir, 1999; Abney and Light, 1999; Ciaramita and Johnson, 2000), word clustering (Rooth et al., 1999; Bergsma et al., 2008; Sun and Korhonen, 2009), distributional similarity metrics (Erk, 2007; Peirsman and Pad´o, 2010), latent ´ S´eaghdha, 2010; Ritter et al., variable models (O 2010), and neural networks (Van de Cruys, 2014). Selectional preferences (SPs) are widely used in NLP as a rich source of semantic information. While SPs have been traditionally induced from textual data, human lexical acquisition is known to rely on both linguistic and perceptual experience. We present the first SP learning method that simultaneously draws knowledge from text, images and videos, using image and video descriptions to obtain visual features. Our results show that it outperforms linguistic a"
P15-1092,J91-1003,0,0.600803,"Missing"
P15-1092,N10-1011,0,0.0190818,"elicitous and infelicitous arguments using the data constructed of positive (observed) and negative (randomly-generated) examples for training. The network weights were optimized by requiring the model to assign a higher score to an observed pair than to the unobserved one by a given margin. 2.2 Multi-modal methods in semantics Previous work has used multimodal data to determine distributional similarity or to learn multimodal embeddings that project multiple modalities into the same vector space. Some studies rely on extensions of LDA to obtain correlations between words and visual features (Feng and Lapata, 2010; Roller and Schulte im Walde, 2013). Bruni et al. (2012) integrated visual features into distributional similarity models using simple vector concatenation. Instead of generic visual features, Silberer et al. (2013) relied on supervised learning to train 412 higher-level visual attribute classifiers. Applications of multimodal embeddings include zero-shot object detection, i.e. recognizing objects in images without training data for the object class (Socher et al., 2013; Frome et al., 2013; Lazaridou et al., 2014), and automatic generation of image captions (Kulkarni et al., 2013), video desc"
P15-1092,J04-1002,0,0.0746674,"Missing"
P15-1092,J03-4004,0,0.033834,"ties are more likely to fill the predicate’s argument slot than others. For instance, while the sentences “The authors wrote a new paper.” and “The cat is eating your sausage!” sound natural and describe plausible real-life situations, the sentences “The carrot ate the keys.” and “The law sang a driveway.” appear implausible and difficult to interpret, as the arguments do not satisfy the verbs’ common preferences. SPs provide generalisations about word meaning and use and find a wide range of applications in natural language processing (NLP), including word sense disambiguation (Resnik, 1997; McCarthy and Carroll, 2003; Wagner et al., 2009), resolving ambiguous syntactic attachments (Hindle and Rooth, 1993), semantic role labelling (Gildea and Jurafsky, 2002; Zapirain et al., 2010), natural language inference (Zanzotto et al., 2006; Pantel et al., 2007), and figurative language processing Little research, however, has been concerned with the sources of knowledge that underlie the learning of SPs. There is ample evidence in cognitive and neurolinguistics that our concept learning and semantic representation are grounded in perception and action (Barsalou, 1999; Glenberg and Kaschak, 2002; Barsalou, 2008; Azi"
P15-1092,J02-3001,0,0.0450548,"“The cat is eating your sausage!” sound natural and describe plausible real-life situations, the sentences “The carrot ate the keys.” and “The law sang a driveway.” appear implausible and difficult to interpret, as the arguments do not satisfy the verbs’ common preferences. SPs provide generalisations about word meaning and use and find a wide range of applications in natural language processing (NLP), including word sense disambiguation (Resnik, 1997; McCarthy and Carroll, 2003; Wagner et al., 2009), resolving ambiguous syntactic attachments (Hindle and Rooth, 1993), semantic role labelling (Gildea and Jurafsky, 2002; Zapirain et al., 2010), natural language inference (Zanzotto et al., 2006; Pantel et al., 2007), and figurative language processing Little research, however, has been concerned with the sources of knowledge that underlie the learning of SPs. There is ample evidence in cognitive and neurolinguistics that our concept learning and semantic representation are grounded in perception and action (Barsalou, 1999; Glenberg and Kaschak, 2002; Barsalou, 2008; Aziz-Zadeh and Damasio, 2008). This suggests that word meaning and relational knowledge are acquired not only from linguistic input but also from"
P15-1092,P10-1045,0,0.264068,"Missing"
P15-1092,D07-1042,0,0.0379414,"Missing"
P15-1092,J93-1005,0,0.281033,"he sentences “The authors wrote a new paper.” and “The cat is eating your sausage!” sound natural and describe plausible real-life situations, the sentences “The carrot ate the keys.” and “The law sang a driveway.” appear implausible and difficult to interpret, as the arguments do not satisfy the verbs’ common preferences. SPs provide generalisations about word meaning and use and find a wide range of applications in natural language processing (NLP), including word sense disambiguation (Resnik, 1997; McCarthy and Carroll, 2003; Wagner et al., 2009), resolving ambiguous syntactic attachments (Hindle and Rooth, 1993), semantic role labelling (Gildea and Jurafsky, 2002; Zapirain et al., 2010), natural language inference (Zanzotto et al., 2006; Pantel et al., 2007), and figurative language processing Little research, however, has been concerned with the sources of knowledge that underlie the learning of SPs. There is ample evidence in cognitive and neurolinguistics that our concept learning and semantic representation are grounded in perception and action (Barsalou, 1999; Glenberg and Kaschak, 2002; Barsalou, 2008; Aziz-Zadeh and Damasio, 2008). This suggests that word meaning and relational knowledge are a"
P15-1092,N07-1071,0,0.386902,"nt variable, which represents a cluster of verb-argument interactions. The latent variable distribution and the probabilities that a latent variable generates the verb and the argument are learned from the data using Expectation Maximization (EM). The latent variables enable the model to recognise previously ´ S´eaghdha (2010) unseen verb-argument pairs. O and Ritter et al. (2010) similarly model SPs within a latent variable framework, but use Latent Dirichlet Allocation (LDA) to learn the probability distributions, for single-argument and multi-argument preferences respectively. Pad´o et al. (2007) and Erk (2007) used similarity metrics to approximate selectional preference classes. Their underlying hypothesis is that a predicate-argument combination (p, a) is felicitous if the predicate p is frequently observed in the data with the arguments a0 similar to a. The systems compute similarities between distributional representations of arguments in a vector space. Bergsma et al. (2008) trained an SVM classifier to discriminate between felicitous and infelicitous verb-argument pairs. Their training data consisted of observed verb-argument pairs (positive examples) with unobserved, randomly-"
P15-1092,J03-3005,0,0.78165,"ata. For instance, while concrete verbs, such as run, push or throw, are more likely to be prominent in visual data, abstract verbs, such as understand or speculate, are best 954 represented in text. Relative linguistic and visual frequencies of a verb provide a way to estimate the relevance of linguistic and visual features to its SP learning. 6 VSP ISP: ISP: ISP: ISP: ISP: ISP: ISP: ISP: ISP: ISP: LSP Direct evaluation and data analysis We evaluate the predicate-argument scores assigned by our models against a dataset of human plausibility judgements of verb-direct object pairs collected by Keller and Lapata (2003). Their dataset is balanced with respect to the frequency of verb-argument relations, as well as their plausibility and implausibility, thus creating a realistic SP evaluation task. Keller and Lapata selected 30 predicates and matched each of them to three arguments from different co-occurrence frequency bands according to their BNC counts, e.g. divert attention (high frequency), divert water (medium) and divert fruit (low). This constituted their dataset of Seen verb-noun pairs, 90 in total. Each of the predicates was then also paired with three randomly selected arguments with which it did n"
P15-1092,P14-2135,0,0.0328611,"ere is ample evidence in cognitive and neurolinguistics that our concept learning and semantic representation are grounded in perception and action (Barsalou, 1999; Glenberg and Kaschak, 2002; Barsalou, 2008; Aziz-Zadeh and Damasio, 2008). This suggests that word meaning and relational knowledge are acquired not only from linguistic input but also from our experiences in the physical world. Multi-modal models of word meaning have thus enjoyed a growing interest in semantics (Bruni et al., 2014), outperforming purely text-based models in tasks such as similarity estimation (Bruni et al., 2014; Kiela et al., 2014), predicting compositionality (Roller and Schulte im Walde, 2013), and concept categorization (Silberer and Lapata, 2014). However, to date these approaches relied on low-level image features such as color histograms or SIFT keypoints to represent the meaning of isolated words. To the best of our knowledge, there has not yet been a multimodal semantic approach performing extraction of 950 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 950–960, c Beijing, China, July 26-31,"
P15-1092,N10-1135,0,0.04861,"Missing"
P15-1092,P14-1132,0,0.0240024,"ly on extensions of LDA to obtain correlations between words and visual features (Feng and Lapata, 2010; Roller and Schulte im Walde, 2013). Bruni et al. (2012) integrated visual features into distributional similarity models using simple vector concatenation. Instead of generic visual features, Silberer et al. (2013) relied on supervised learning to train 412 higher-level visual attribute classifiers. Applications of multimodal embeddings include zero-shot object detection, i.e. recognizing objects in images without training data for the object class (Socher et al., 2013; Frome et al., 2013; Lazaridou et al., 2014), and automatic generation of image captions (Kulkarni et al., 2013), video descriptions (Rohrbach et al., 2013), or tags (Srivastava et al., 2014). Other applications of multimodal data include language modeling (Kiros et al., 2014) and knowledge mining from images (Chen et al., 2013; Divvala et al., 2014). Young et al. (2014) apply simplification rules to image captions, showing that the resulting hierarchy of mappings between natural language expressions and images can be used for entailment tasks. 3 Experimental data Textual data. We extract linguistic features for our model from the BNC."
P15-1092,J98-2002,0,0.0244617,"iket Tandon Gerard de Melo Computer Laboratory Max Planck Institute IIIS University of Cambridge, UK for Informatics, Germany Tsinghua University, China es407@cam.ac.uk ntandon@mpi-inf.mpg.de gdm@demelo.org Abstract (Fass, 1991; Mason, 2004; Shutova et al., 2013; Li et al., 2013). Automatic acquisition of SPs from linguistic data has thus become an active area of research. The community has investigated a range of techniques to tackle data sparsity and to perform generalisation from observed arguments to their underlying types, including the use of WordNet synsets as SP classes (Resnik, 1993; Li and Abe, 1998; Clark and Weir, 1999; Abney and Light, 1999; Ciaramita and Johnson, 2000), word clustering (Rooth et al., 1999; Bergsma et al., 2008; Sun and Korhonen, 2009), distributional similarity metrics (Erk, 2007; Peirsman and Pad´o, 2010), latent ´ S´eaghdha, 2010; Ritter et al., variable models (O 2010), and neural networks (Van de Cruys, 2014). Selectional preferences (SPs) are widely used in NLP as a rich source of semantic information. While SPs have been traditionally induced from textual data, human lexical acquisition is known to rely on both linguistic and perceptual experience. We present t"
P15-1092,Q13-1031,0,0.0358004,"Missing"
P15-1092,W97-0209,0,0.351304,"lasses of entities are more likely to fill the predicate’s argument slot than others. For instance, while the sentences “The authors wrote a new paper.” and “The cat is eating your sausage!” sound natural and describe plausible real-life situations, the sentences “The carrot ate the keys.” and “The law sang a driveway.” appear implausible and difficult to interpret, as the arguments do not satisfy the verbs’ common preferences. SPs provide generalisations about word meaning and use and find a wide range of applications in natural language processing (NLP), including word sense disambiguation (Resnik, 1997; McCarthy and Carroll, 2003; Wagner et al., 2009), resolving ambiguous syntactic attachments (Hindle and Rooth, 1993), semantic role labelling (Gildea and Jurafsky, 2002; Zapirain et al., 2010), natural language inference (Zanzotto et al., 2006; Pantel et al., 2007), and figurative language processing Little research, however, has been concerned with the sources of knowledge that underlie the learning of SPs. There is ample evidence in cognitive and neurolinguistics that our concept learning and semantic representation are grounded in perception and action (Barsalou, 1999; Glenberg and Kascha"
P15-1092,P10-1044,0,0.0969056,"Missing"
P15-1092,D13-1115,0,0.0807902,"Missing"
P15-1092,P99-1014,0,0.434155,"matics, Germany Tsinghua University, China es407@cam.ac.uk ntandon@mpi-inf.mpg.de gdm@demelo.org Abstract (Fass, 1991; Mason, 2004; Shutova et al., 2013; Li et al., 2013). Automatic acquisition of SPs from linguistic data has thus become an active area of research. The community has investigated a range of techniques to tackle data sparsity and to perform generalisation from observed arguments to their underlying types, including the use of WordNet synsets as SP classes (Resnik, 1993; Li and Abe, 1998; Clark and Weir, 1999; Abney and Light, 1999; Ciaramita and Johnson, 2000), word clustering (Rooth et al., 1999; Bergsma et al., 2008; Sun and Korhonen, 2009), distributional similarity metrics (Erk, 2007; Peirsman and Pad´o, 2010), latent ´ S´eaghdha, 2010; Ritter et al., variable models (O 2010), and neural networks (Van de Cruys, 2014). Selectional preferences (SPs) are widely used in NLP as a rich source of semantic information. While SPs have been traditionally induced from textual data, human lexical acquisition is known to rely on both linguistic and perceptual experience. We present the first SP learning method that simultaneously draws knowledge from text, images and videos, using image and vi"
P15-1092,N10-1147,1,0.930668,"o improve SP prediction across frequency bands. 7 Task-based evaluation In order to investigate the applicability of perceptually grounded SPs in wider NLP, we evaluate them in the context of an external semantic task – that of metaphor interpretation. Since metaphor is based on transferring imagery and knowledge across domains – typically from more familiar domains of physical experiences to the sphere of vague and elusive abstract thought – metaphor interpretation provides an ideal framework for testing perceptually grounded SPs. Our experiments rely on the metaphor interpretation method of Shutova (2010), in which text-derived SPs are a central component of the system. We replace the SP component with our LSP and ISP (λLM = 0.8) models and compare their performance in the context of metaphor interpretation. Shutova (2010) defined metaphor interpretation as a paraphrasing task, where literal paraphrases for metaphorical expressions are derived from corpus data using a set of statistical measures. For instance, their system interprets the metaphor “a carelessly leaked report” as “a carelessly disclosed report”. Focusing on metaphorical verbs in subject and direct object constructions, Shutova f"
P15-1092,P14-1068,0,0.055673,"grounded in perception and action (Barsalou, 1999; Glenberg and Kaschak, 2002; Barsalou, 2008; Aziz-Zadeh and Damasio, 2008). This suggests that word meaning and relational knowledge are acquired not only from linguistic input but also from our experiences in the physical world. Multi-modal models of word meaning have thus enjoyed a growing interest in semantics (Bruni et al., 2014), outperforming purely text-based models in tasks such as similarity estimation (Bruni et al., 2014; Kiela et al., 2014), predicting compositionality (Roller and Schulte im Walde, 2013), and concept categorization (Silberer and Lapata, 2014). However, to date these approaches relied on low-level image features such as color histograms or SIFT keypoints to represent the meaning of isolated words. To the best of our knowledge, there has not yet been a multimodal semantic approach performing extraction of 950 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 950–960, c Beijing, China, July 26-31, 2015. 2015 Association for Computational Linguistics predicate-argument relations from visual data. In this paper, we pro"
P15-1092,P13-1056,0,0.0243041,"igher score to an observed pair than to the unobserved one by a given margin. 2.2 Multi-modal methods in semantics Previous work has used multimodal data to determine distributional similarity or to learn multimodal embeddings that project multiple modalities into the same vector space. Some studies rely on extensions of LDA to obtain correlations between words and visual features (Feng and Lapata, 2010; Roller and Schulte im Walde, 2013). Bruni et al. (2012) integrated visual features into distributional similarity models using simple vector concatenation. Instead of generic visual features, Silberer et al. (2013) relied on supervised learning to train 412 higher-level visual attribute classifiers. Applications of multimodal embeddings include zero-shot object detection, i.e. recognizing objects in images without training data for the object class (Socher et al., 2013; Frome et al., 2013; Lazaridou et al., 2014), and automatic generation of image captions (Kulkarni et al., 2013), video descriptions (Rohrbach et al., 2013), or tags (Srivastava et al., 2014). Other applications of multimodal data include language modeling (Kiros et al., 2014) and knowledge mining from images (Chen et al., 2013; Divvala e"
P15-1092,D09-1067,0,0.612588,"es407@cam.ac.uk ntandon@mpi-inf.mpg.de gdm@demelo.org Abstract (Fass, 1991; Mason, 2004; Shutova et al., 2013; Li et al., 2013). Automatic acquisition of SPs from linguistic data has thus become an active area of research. The community has investigated a range of techniques to tackle data sparsity and to perform generalisation from observed arguments to their underlying types, including the use of WordNet synsets as SP classes (Resnik, 1993; Li and Abe, 1998; Clark and Weir, 1999; Abney and Light, 1999; Ciaramita and Johnson, 2000), word clustering (Rooth et al., 1999; Bergsma et al., 2008; Sun and Korhonen, 2009), distributional similarity metrics (Erk, 2007; Peirsman and Pad´o, 2010), latent ´ S´eaghdha, 2010; Ritter et al., variable models (O 2010), and neural networks (Van de Cruys, 2014). Selectional preferences (SPs) are widely used in NLP as a rich source of semantic information. While SPs have been traditionally induced from textual data, human lexical acquisition is known to rely on both linguistic and perceptual experience. We present the first SP learning method that simultaneously draws knowledge from text, images and videos, using image and video descriptions to obtain visual features. Our"
P15-1092,D14-1004,0,0.261526,"Missing"
P15-1092,P06-1107,0,0.0193566,"e situations, the sentences “The carrot ate the keys.” and “The law sang a driveway.” appear implausible and difficult to interpret, as the arguments do not satisfy the verbs’ common preferences. SPs provide generalisations about word meaning and use and find a wide range of applications in natural language processing (NLP), including word sense disambiguation (Resnik, 1997; McCarthy and Carroll, 2003; Wagner et al., 2009), resolving ambiguous syntactic attachments (Hindle and Rooth, 1993), semantic role labelling (Gildea and Jurafsky, 2002; Zapirain et al., 2010), natural language inference (Zanzotto et al., 2006; Pantel et al., 2007), and figurative language processing Little research, however, has been concerned with the sources of knowledge that underlie the learning of SPs. There is ample evidence in cognitive and neurolinguistics that our concept learning and semantic representation are grounded in perception and action (Barsalou, 1999; Glenberg and Kaschak, 2002; Barsalou, 2008; Aziz-Zadeh and Damasio, 2008). This suggests that word meaning and relational knowledge are acquired not only from linguistic input but also from our experiences in the physical world. Multi-modal models of word meaning"
P15-1092,N10-1058,0,0.0588702,"Missing"
P15-1092,J13-2003,1,\N,Missing
P15-1092,Q14-1006,0,\N,Missing
P16-1018,D10-1115,0,0.21441,"et this word may exhibit a range of metaphorical meanings—e.g., sweet dreams, sweet person, sweet victory–that are created through the interplay of source and target domains. If metaphor is compositional, how do we represent it, and how can we use it in a compositional framework for meaning? Compositional distributional semantic models (CDSMs) provide a compact model of compositionality that produces vector representations of phrases while avoiding the sparsity and storage issues associated with storing vectors for each phrase in a language explicitly. One of the most popular CDSM frameworks (Baroni and Zamparelli, 2010; Guevara, 2010; Coecke et al., 2010) represents nouns as vectors, adjectives as matrices that act on the noun vectors, and transitive verbs as third-order tensors that act on noun or noun phrase vectors. The meaning of a phrase is then derived by composing these lexical representations. The vast majority of such models build a single representation for all senses of a word, collapsing distinct senses together. One exception is the work of Kartsaklis and Sadrzadeh (2013a), who investigated homonymy, in which lexical items Metaphorical expressions are pervasive in natural language and pose a su"
P16-1018,W13-3206,0,0.0106092,"y literal phrases when learning A ing on literal phrases). 4.2 Figure 1: Reduction in error from training on targeted subset (MET/LIT) rather than on all phrases. lined in Li et al. (2014) to determine the regularization parameters for each regression problem. 4.3 Evaluating Vector Representations Evaluation. Our goal is to produce a vector prediction of each phrase that will be close to its ground truth distributional vector. Phrase vectors directly extracted from the corpus by treating the phrase as a single term are the gold standard for predicting human judgment and producing paraphrases (Dinu et al., 2013), so we use these as our ground truth. The quality of the vector prediction for phrase i is measured using the cosine distance between the phrase’s ground truth vector pi and the vector prediction p ˆi : Experimental Setup Extracting Noun & Phrase Vectors. Our approach for constructing term vector representations is similar to that of Dinu et al. (2013). We first selected the 10K most frequent nouns, adjectives, and verbs to serve as context terms. We then constructed a co-occurrence matrix that recorded term-context co-occurrence within a symmetric 5-word context window of the 50K most freque"
P16-1018,2014.lilt-9.5,0,0.0280915,"that act on noun vectors. Adjective matrices can be learned using regression techniques. Other CDSMs have also been proposed and successfully applied to tasks such as sentiment analysis and paraphrase (Socher et al., 2011; Socher et al., 2012; Tsubaki et al., 2013; Turney, 2013). Handling Polysemy in CDSMs. Several researchers argue that terms with ambiguous senses can be handled by DSMs without any recourse to additional disambiguation steps, as long as contextual information is available (Boleda et al., 2012; Erk and Pad´o, 2010; Pantel and Lin, 2002; Sch¨utze, 1998; Tsubaki et al., 2013). Baroni et al. (2014) conjecture that CDSMs might largely avoid problems handling adjectives with multiple senses because the matrices for adjectives implicitly incorporate contextual information. However, they do draw a distinction between two ways in which the meaning of a term can vary. Continuous polysemy—the subtle and continuous variations in meaning resulting from the different contexts in which a word appears—is relatively tractable, in their opinion. This contrasts with discrete homonymy—the association of a single term with completely independent meanings (e.g., light house vs. light work). Baroni et al."
P16-1018,W13-0901,0,0.0464948,"agged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do not occur frequently with the given adjective, then the AN phrase is labeled as metaphorical. KrishnakuMetaphor"
P16-1018,W09-2002,0,0.0148653,"procedure is modeled on that of Baroni and Zamparelli (2010). The corpus consisted of a 2011 dump of English Wikipedia, the UKWaC (Baroni et al., 2009), the BNC (BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical o"
P16-1018,P10-2017,0,0.0764741,"Missing"
P16-1018,P04-3031,0,0.152555,"ght vs. bright idea), which can be explicitly modeled within a CDSM. The above CDSMs provide no account of such systematic polysemy, which is the gap this paper aims to fill. 3 Experimental Data Corpus. We trained our DSMs from a corpus of 4.58 billion tokens. Our corpus construction procedure is modeled on that of Baroni and Zamparelli (2010). The corpus consisted of a 2011 dump of English Wikipedia, the UKWaC (Baroni et al., 2009), the BNC (BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler"
P16-1018,P15-2120,0,0.016468,"phrase can inform classification of the phrase for metaphoricity. Beyond improvements to the applications we presented, the principles underlying our methods also show potential for other tasks. For instance, the LIT and MET adjective matrices and the CM mapping matrix learned with our methods could be applied to improve automated paraphrasing of AN phrases. Our work is also directly extendable to other syntactic constructions. In the CDSM framework we apply, verbs would be represented as third-order tensors. Tractable and efficient methods for estimating these verb tensors are now available (Fried et al., 2015). It may also be possible to extend the coverage of our system by using automated word-sense disambiguation to bootstrap annotations and therefore construct LIT Our results could also inform debates within cognitive science. First, cognitive scientists debate whether words that are used both literally and figuratively (e.g., long road, long meeting) are best understood as having a single, abstract meaning that varies with context or two distinct but related meanings. For instance, some argue that domains like space, time, and number operate over a shared, generalized magnitude system, yet othe"
P16-1018,E06-1042,0,0.291634,"rpus. We trained our DSMs from a corpus of 4.58 billion tokens. Our corpus construction procedure is modeled on that of Baroni and Zamparelli (2010). The corpus consisted of a 2011 dump of English Wikipedia, the UKWaC (Baroni et al., 2009), the BNC (BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are"
P16-1018,W06-3506,0,0.0867495,"(Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do not occur frequently with the given adjective, then th"
P16-1018,W10-2805,0,0.105203,"nge of metaphorical meanings—e.g., sweet dreams, sweet person, sweet victory–that are created through the interplay of source and target domains. If metaphor is compositional, how do we represent it, and how can we use it in a compositional framework for meaning? Compositional distributional semantic models (CDSMs) provide a compact model of compositionality that produces vector representations of phrases while avoiding the sparsity and storage issues associated with storing vectors for each phrase in a language explicitly. One of the most popular CDSM frameworks (Baroni and Zamparelli, 2010; Guevara, 2010; Coecke et al., 2010) represents nouns as vectors, adjectives as matrices that act on the noun vectors, and transitive verbs as third-order tensors that act on noun or noun phrase vectors. The meaning of a phrase is then derived by composing these lexical representations. The vast majority of such models build a single representation for all senses of a word, collapsing distinct senses together. One exception is the work of Kartsaklis and Sadrzadeh (2013a), who investigated homonymy, in which lexical items Metaphorical expressions are pervasive in natural language and pose a substantial chall"
P16-1018,D09-1033,0,0.0593827,"he corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do not occur frequently with the given adjective, then the AN phrase is labeled a"
P16-1018,W13-0908,0,0.0543505,"and Zamparelli (2010). The corpus consisted of a 2011 dump of English Wikipedia, the UKWaC (Baroni et al., 2009), the BNC (BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007"
P16-1018,N10-1039,0,0.194136,"8 billion tokens. Our corpus construction procedure is modeled on that of Baroni and Zamparelli (2010). The corpus consisted of a 2011 dump of English Wikipedia, the UKWaC (Baroni et al., 2009), the BNC (BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adj"
P16-1018,W13-0907,0,0.211131,"ersity of Cambridge 3 Indiana University Bloomington edg@icsi.berkeley.edu tmarghet@cogsci.ucsd.edu es407@cam.ac.uk bkbergen@ucsd.edu Abstract such as thinking is preparing, communication is feeding, understanding is digestion; and that this mapping can be productively extended to produce novel LMs that obey these correspondences. Recent years have seen the rise of statistical techniques for metaphor detection. Several of these techniques leverage distributional statistics and vector-space models of meaning to classify utterances as literal or metaphorical (Utsumi, 2006; Shutova et al., 2010; Hovy et al., 2013; Tsvetkov et al., 2014). An important insight of these studies is that metaphorical meaning is not merely a property of individual words, but rather arises through cross-domain composition. The meaning of sweet, for instance, is not intrinsically metaphorical. Yet this word may exhibit a range of metaphorical meanings—e.g., sweet dreams, sweet person, sweet victory–that are created through the interplay of source and target domains. If metaphor is compositional, how do we represent it, and how can we use it in a compositional framework for meaning? Compositional distributional semantic models"
P16-1018,P10-1116,0,0.0248388,"on that of Baroni and Zamparelli (2010). The corpus consisted of a 2011 dump of English Wikipedia, the UKWaC (Baroni et al., 2009), the BNC (BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishn"
P16-1018,E14-1046,0,0.0144757,"rror 2 , the opL(AD(a) ) = kp − A n k i i D(a) 2 i∈D(a) timal solution can be found precisely using ordinary least-squares regression. However, this may result in overfitting because of the large number of parameters relative to the number of samples (i.e., phrases). Regularization parameters λ = (λ1 , λ2 ) ˆ D(a) small: can be introduced to keep A Method Our goal is to learn accurate vector representations for unseen adjective-noun (AN) phrases, where adjectives can take on metaphorical or literal senses. Our models build off the CDSM framework of Baroni and Zamparelli (2010), as extended by Li et al. (2014). Each adjective a is treated as a linear map from nouns to AN phrases: p = Aa n, where p is a vector for the phrase, n is a vector for the noun, and Aa is a matrix for the adjective. 186 X ˆ D(a) ni k22 + R(λ; A ˆ D(a) ), kpi − A i∈D(a) ˆ D ) = λ1 kA ˆ D k1 + λ2 kA ˆ D k2 . This where R(λ; A approach, known as elastic-net regression (Zou and Hastie, 2005), produces better adjective matrices than unregularized regression (Li et al., 2014). Note that the same procedure can be used to learn the adjective representations in both the Contextual Variation model and the Discrete Polysemy model by va"
P16-1018,D13-1166,0,0.150261,"Missing"
P16-1018,P08-1028,0,0.0105968,"literal or metaphorical and obtain state-of-the-art performance in the metaphor identification task. 2 Compositional DSMs. Similar issues arose in modeling compositional semantics. Formal semantics has dealt with compositional meaning for decades, by using mathematical structures from abstract algebra, logic, and category theory (Montague, 1970; Partee, 1994; Lambek, 1999). However, formal semantics requires manual crafting of features. The central insight of CDSMs is to model the composition of words as algebraic operations on their vector representations, as provided by a conventional DSM (Mitchell and Lapata, 2008). Guevara (2010) and Baroni and Zamparelli (2010) were the first to treat adjectives and verbs differently from nouns. In their models, adjectives are represented by matrices that act on noun vectors. Adjective matrices can be learned using regression techniques. Other CDSMs have also been proposed and successfully applied to tasks such as sentiment analysis and paraphrase (Socher et al., 2011; Socher et al., 2012; Tsubaki et al., 2013; Turney, 2013). Handling Polysemy in CDSMs. Several researchers argue that terms with ambiguous senses can be handled by DSMs without any recourse to additional"
P16-1018,W13-3513,0,0.0172338,"Missing"
P16-1018,W13-0904,0,0.0526257,"2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do not occur frequently with the given adjective, then the AN phrase is labeled as metaphorical. KrishnakuMetaphor Annotations. We created an annotated dataset of 8592"
P16-1018,W07-0103,0,0.0615281,", 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do not occur frequently with the given adjective, then the AN phrase is labeled as metaphorical. KrishnakuMetaphor Annotations. We created an annotated dataset of 8592 AN phrases (3991 literal, 4601 metaphorical). Our choice of adjectives was inspired by the test set of Tsvetkov et al. (2014), though our annotated dataset is considerably larger. We focused on 23 adjectives that can have both metaphorical and literal senses, and which function as source-domain words in relat"
P16-1018,W13-0909,0,0.0803022,"ish Wikipedia, the UKWaC (Baroni et al., 2009), the BNC (BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for"
P16-1018,D13-1014,0,0.0159253,"central insight of CDSMs is to model the composition of words as algebraic operations on their vector representations, as provided by a conventional DSM (Mitchell and Lapata, 2008). Guevara (2010) and Baroni and Zamparelli (2010) were the first to treat adjectives and verbs differently from nouns. In their models, adjectives are represented by matrices that act on noun vectors. Adjective matrices can be learned using regression techniques. Other CDSMs have also been proposed and successfully applied to tasks such as sentiment analysis and paraphrase (Socher et al., 2011; Socher et al., 2012; Tsubaki et al., 2013; Turney, 2013). Handling Polysemy in CDSMs. Several researchers argue that terms with ambiguous senses can be handled by DSMs without any recourse to additional disambiguation steps, as long as contextual information is available (Boleda et al., 2012; Erk and Pad´o, 2010; Pantel and Lin, 2002; Sch¨utze, 1998; Tsubaki et al., 2013). Baroni et al. (2014) conjecture that CDSMs might largely avoid problems handling adjectives with multiple senses because the matrices for adjectives implicitly incorporate contextual information. However, they do draw a distinction between two ways in which the mea"
P16-1018,W13-0906,0,0.141576,"etaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do not occur frequently with the given adjective, then the AN phrase is labeled as metaphorical. KrishnakuMetaphor Annotations. We created an annotated dataset of 8592 AN phrases (3991 literal, 4601 metaphorical)"
P16-1018,J98-1004,0,0.207053,"Missing"
P16-1018,P14-1024,0,0.743578,"3 Indiana University Bloomington edg@icsi.berkeley.edu tmarghet@cogsci.ucsd.edu es407@cam.ac.uk bkbergen@ucsd.edu Abstract such as thinking is preparing, communication is feeding, understanding is digestion; and that this mapping can be productively extended to produce novel LMs that obey these correspondences. Recent years have seen the rise of statistical techniques for metaphor detection. Several of these techniques leverage distributional statistics and vector-space models of meaning to classify utterances as literal or metaphorical (Utsumi, 2006; Shutova et al., 2010; Hovy et al., 2013; Tsvetkov et al., 2014). An important insight of these studies is that metaphorical meaning is not merely a property of individual words, but rather arises through cross-domain composition. The meaning of sweet, for instance, is not intrinsically metaphorical. Yet this word may exhibit a range of metaphorical meanings—e.g., sweet dreams, sweet person, sweet victory–that are created through the interplay of source and target domains. If metaphor is compositional, how do we represent it, and how can we use it in a compositional framework for meaning? Compositional distributional semantic models (CDSMs) provide a compa"
P16-1018,C10-1113,1,0.840876,"ornia San Diego 2 University of Cambridge 3 Indiana University Bloomington edg@icsi.berkeley.edu tmarghet@cogsci.ucsd.edu es407@cam.ac.uk bkbergen@ucsd.edu Abstract such as thinking is preparing, communication is feeding, understanding is digestion; and that this mapping can be productively extended to produce novel LMs that obey these correspondences. Recent years have seen the rise of statistical techniques for metaphor detection. Several of these techniques leverage distributional statistics and vector-space models of meaning to classify utterances as literal or metaphorical (Utsumi, 2006; Shutova et al., 2010; Hovy et al., 2013; Tsvetkov et al., 2014). An important insight of these studies is that metaphorical meaning is not merely a property of individual words, but rather arises through cross-domain composition. The meaning of sweet, for instance, is not intrinsically metaphorical. Yet this word may exhibit a range of metaphorical meanings—e.g., sweet dreams, sweet person, sweet victory–that are created through the interplay of source and target domains. If metaphor is compositional, how do we represent it, and how can we use it in a compositional framework for meaning? Compositional distributio"
P16-1018,D11-1063,0,0.218323,"iginal object. Category theory provides a general formalism for analyzing relationships as morphisms in a wide range of systems (see Spivak (2014)). Category theory has been used to formalize the CM hypothesis with applications to user interfaces, poetry, and information visualization (Kuhn and Frank, 1991; Goguen and Harrell, 2010; Goguen and Harrell, 2005). Although these formal treatments of metaphors as morphisms are rigorous and wellformalized, they have been applied at a relatively limited scale. This is because this work does not 184 maran and Zhu’s system achieves a precision of 0.67. Turney et al. (2011) classify verb and adjective phrases based on their level of concreteness or abstractness in relation to the noun they appear with. They learn concreteness rankings for words automatically (starting from a set of examples) and then search for expressions where a concrete adjective or verb is used with an abstract noun (e.g., dark humor is tagged as a metaphor; dark hair is not). They measure performance on a set of 100 phrases involving one of five adjectives, attaining an average accuracy of 0.79. Tsvetkov et al. (2014) train a random-forest classifier using several features, including abstra"
P16-1018,J15-4002,1,0.84907,"or detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do not occur frequently with the given adjective, then the AN phrase is labeled as metaphorical. KrishnakuMetaphor Annotations. We created an annotated dataset of 8592 AN phrases (3991 literal, 4601 metaphorical). Our choice of adjectives was inspired by the test set of Tsvetkov et al."
P16-1018,D11-1014,0,0.0271234,"requires manual crafting of features. The central insight of CDSMs is to model the composition of words as algebraic operations on their vector representations, as provided by a conventional DSM (Mitchell and Lapata, 2008). Guevara (2010) and Baroni and Zamparelli (2010) were the first to treat adjectives and verbs differently from nouns. In their models, adjectives are represented by matrices that act on noun vectors. Adjective matrices can be learned using regression techniques. Other CDSMs have also been proposed and successfully applied to tasks such as sentiment analysis and paraphrase (Socher et al., 2011; Socher et al., 2012; Tsubaki et al., 2013; Turney, 2013). Handling Polysemy in CDSMs. Several researchers argue that terms with ambiguous senses can be handled by DSMs without any recourse to additional disambiguation steps, as long as contextual information is available (Boleda et al., 2012; Erk and Pad´o, 2010; Pantel and Lin, 2002; Sch¨utze, 1998; Tsubaki et al., 2013). Baroni et al. (2014) conjecture that CDSMs might largely avoid problems handling adjectives with multiple senses because the matrices for adjectives implicitly incorporate contextual information. However, they do draw a di"
P16-1018,Q13-1029,0,0.0130332,"SMs is to model the composition of words as algebraic operations on their vector representations, as provided by a conventional DSM (Mitchell and Lapata, 2008). Guevara (2010) and Baroni and Zamparelli (2010) were the first to treat adjectives and verbs differently from nouns. In their models, adjectives are represented by matrices that act on noun vectors. Adjective matrices can be learned using regression techniques. Other CDSMs have also been proposed and successfully applied to tasks such as sentiment analysis and paraphrase (Socher et al., 2011; Socher et al., 2012; Tsubaki et al., 2013; Turney, 2013). Handling Polysemy in CDSMs. Several researchers argue that terms with ambiguous senses can be handled by DSMs without any recourse to additional disambiguation steps, as long as contextual information is available (Boleda et al., 2012; Erk and Pad´o, 2010; Pantel and Lin, 2002; Sch¨utze, 1998; Tsubaki et al., 2013). Baroni et al. (2014) conjecture that CDSMs might largely avoid problems handling adjectives with multiple senses because the matrices for adjectives implicitly incorporate contextual information. However, they do draw a distinction between two ways in which the meaning of a term"
P16-1018,D12-1110,0,0.0564086,"ting of features. The central insight of CDSMs is to model the composition of words as algebraic operations on their vector representations, as provided by a conventional DSM (Mitchell and Lapata, 2008). Guevara (2010) and Baroni and Zamparelli (2010) were the first to treat adjectives and verbs differently from nouns. In their models, adjectives are represented by matrices that act on noun vectors. Adjective matrices can be learned using regression techniques. Other CDSMs have also been proposed and successfully applied to tasks such as sentiment analysis and paraphrase (Socher et al., 2011; Socher et al., 2012; Tsubaki et al., 2013; Turney, 2013). Handling Polysemy in CDSMs. Several researchers argue that terms with ambiguous senses can be handled by DSMs without any recourse to additional disambiguation steps, as long as contextual information is available (Boleda et al., 2012; Erk and Pad´o, 2010; Pantel and Lin, 2002; Sch¨utze, 1998; Tsubaki et al., 2013). Baroni et al. (2014) conjecture that CDSMs might largely avoid problems handling adjectives with multiple senses because the matrices for adjectives implicitly incorporate contextual information. However, they do draw a distinction between two"
P16-1018,E09-1086,0,0.0138273,"(BNC Consortium, 2007), and the English Gigaword corpus (Graff et al., 2003). The corpus was tokenized, lemmatized, and POStagged using the NLTK toolkit (Bird and Loper, 2004) for Python. Computational Work on Metaphor. There is now an extensive literature on statistical approaches to metaphor detection. The investigated methods include clustering (Birke and Sarkar, 2006; Shutova et al., 2010; Li and Sporleder, 2010); topic modeling (Bethard et al., 2009; Li et al., 2010; Heintz et al., 2013); topical structure and imageability analysis (Strzalkowski et al., 2013); semantic similarity graphs (Sporleder and Li, 2009), and feature-based classifiers (Gedigian et al., 2006; Li and Sporleder, 2009; Turney et al., 2011; Dunn, 2013a; Dunn, 2013b; Hovy et al., 2013; Mohler et al., 2013; Neuman et al., 2013; Tsvetkov et al., 2013; Tsvetkov et al., 2014). We refer readers to the survey by Shutova (2015) for a more thorough review. Most relevant to the present work are approaches that attempt to identify whether adjective-noun phrases are metaphorical or literal. Krishnakumaran and Zhu (2007) use AN co-occurrence counts and WordNet hyponym/hypernym relations for this task. If the noun and its hyponyms/hypernyms do"
P16-1018,P06-4018,0,\N,Missing
P16-1018,D12-1112,0,\N,Missing
P16-1092,D11-1010,0,0.157272,"mputer Laboratory University of Cambridge es407@cam.ac.uk Abstract speakers *do exceptions and offers instead of making them, and *find decisions instead of finding solutions, since in Russian do and make have a single translational equivalent (delat’), and so do decision and solution (resheniye). As a result, nonnative speakers who tend to fall back to their L1 translate phrases word-for-word, violating English lexico-semantic conventions. The effect of L1 interference on lexical choice in L2 has been pointed out in a number of studies (Chang et al., 2008; Rozovskaya, 2010; Rozovskaya, 2011; Dahlmeier and Ng, 2011). Some of these studies also demonstrated that using L1specific properties, such as the error patterns of speakers of a given L1 or L1-induced paraphrases, improves the performance of automatic error correction in non-native writing. However, neither of the approaches has constructed a semantic model from L1 data and systematically studied the effects of its transfer onto L2. In addition, most previous work has focused on error correction, bypassing the task of error detection for lexical choice. Lexical choice is one of the most challenging tasks for both non-native speakers and automated err"
P16-1092,C14-1164,1,0.834949,"find solution have a high PMI score. However, in English the latter has a high PMI while the former has a negative PMI. We expect such a discrepancy in word association to be an indicator of error of lexical choice, driven by the L1 semantics. We treat the task of lexico-semantic transfer error detection as a binary classification problem and train a classifier for this task. The classifier uses a combination of L1 and L2 semantic features. If our hypothesis holds, we expect to see an improvement in the classifier’s performance when adding L1 semantic features. Semantic vector space features Kochmar and Briscoe (2014) obtained state-of-the-art results in error detection by using the semantic component of the content word combinations. We reimplement these features and test their impact on our task. We extracted the noun and verb vectors from the publicly available word2vec dataset of word embeddings for 3 million words and phrases.2 The 300-dimensional vectors have been trained on a part of Google News dataset (about 100 billion words) using word2vec (Mikolov et al., 2013). The dobj and subj vectors are then built using element-wise addition on the vectors (Mitchell and Lapata, 2008; Mikolov et al., 2013;"
P16-1092,C14-3004,0,0.0625475,"ted translational equivalents and focus on error correction only. In contrast, we construct holistic semantic models of L1 from L1 corpora and use these models to perform the more challenging task of error detection. Related work Error detection in content words Early approaches to collocation error detection relied on manually created databases of correct and incorrect word combinations (Shei and Pain, 2000; Wible et al., 2003; Chang et al., 2008). Constructing such databases is expensive and timeconsuming, and therefore, more recent research turned to the use of machine learning techniques. Leacock et al. (2014) note that most approaches to detection and correction of collocation errors compare the writer’s word choice to the set of alternatives using association strength measures and choose the combination with the highest score, reporting an error if this combination does not coincide with the original choice (Futagi et al., 2008; ¨ Ostling and Knutsson, 2009; Liu et al., 2009). This strategy is expensive as it relies on comparison with a set of alternatives, limited in capacity as it depends on the quality of the alternatives generated and circular as the detection cannot be performed independentl"
P16-1092,W09-2107,0,0.03076,"ombinations (Shei and Pain, 2000; Wible et al., 2003; Chang et al., 2008). Constructing such databases is expensive and timeconsuming, and therefore, more recent research turned to the use of machine learning techniques. Leacock et al. (2014) note that most approaches to detection and correction of collocation errors compare the writer’s word choice to the set of alternatives using association strength measures and choose the combination with the highest score, reporting an error if this combination does not coincide with the original choice (Futagi et al., 2008; ¨ Ostling and Knutsson, 2009; Liu et al., 2009). This strategy is expensive as it relies on comparison with a set of alternatives, limited in capacity as it depends on the quality of the alternatives generated and circular as the detection cannot be performed independently of the correction. Our 3 Data We first use large monolingual corpora in Spanish, Russian and English to build word association models for each of the languages. We then apply the resulting models for error detection in the English learner data. 975 3.1 L1 Data 3.3 To extract the verb–noun combinations that have been used by non-native speakers in practice, we use the Cam"
P16-1092,W12-2005,0,0.070394,"Missing"
P16-1092,P06-4020,0,0.299085,"he verb–noun combinations that have been used by non-native speakers in practice, we use the Cambridge Learner Corpus (CLC), which is a 52.5 million-word corpus of learner English collected by Cambridge University Press and Cambridge English Language Assessment since 1993 (Nicholls, 2003). It comprises English examination scripts written by learners of English with 148 different L1s, ranging across multiple examinations and covering all levels of language proficiency. A 25.5 million-word component of the CLC has been manually error-annotated. We have preprocessed the CLC with the RASP parser (Briscoe et al., 2006), as it is robust when applied to ungrammatical sentences. We have then extracted all dobj and subj combinations: in total, we have extracted 187, 109 dobj and 225, 716 subj combinations. We have used the CLC error annotation to split the data into correct combinations and errors. We note that some verb–noun combinations are annotated both as being correct and as errors, depending on their wider context of use. To ensure that the annotation we use in our experiments is reliable and not context-dependent, we have empirically set a threshold to filter out ambiguously annotated instances. The set"
P16-1092,P08-1028,0,0.0430991,"vector space features Kochmar and Briscoe (2014) obtained state-of-the-art results in error detection by using the semantic component of the content word combinations. We reimplement these features and test their impact on our task. We extracted the noun and verb vectors from the publicly available word2vec dataset of word embeddings for 3 million words and phrases.2 The 300-dimensional vectors have been trained on a part of Google News dataset (about 100 billion words) using word2vec (Mikolov et al., 2013). The dobj and subj vectors are then built using element-wise addition on the vectors (Mitchell and Lapata, 2008; Mikolov et al., 2013; Kochmar and Briscoe, 2014). Once the compositional vectors are created, the method relies on the idea that correct combinations can be distinguished from the erroneous ones by certain vector properties (Vecchi et al., 2011; Kochmar and Briscoe, 2014). We implement a set of numerical features based on the following properties of the vectors: 2 977 code.google.com/archive/p/word2vec/ • length of the additive (vn) vector 4.3 • cosvn∧n – cosine between the vn vector and the noun vector Classifier settings We treat the task as a binary classification problem and apply a line"
P16-1092,W11-1301,0,0.0413422,"oun and verb vectors from the publicly available word2vec dataset of word embeddings for 3 million words and phrases.2 The 300-dimensional vectors have been trained on a part of Google News dataset (about 100 billion words) using word2vec (Mikolov et al., 2013). The dobj and subj vectors are then built using element-wise addition on the vectors (Mitchell and Lapata, 2008; Mikolov et al., 2013; Kochmar and Briscoe, 2014). Once the compositional vectors are created, the method relies on the idea that correct combinations can be distinguished from the erroneous ones by certain vector properties (Vecchi et al., 2011; Kochmar and Briscoe, 2014). We implement a set of numerical features based on the following properties of the vectors: 2 977 code.google.com/archive/p/word2vec/ • length of the additive (vn) vector 4.3 • cosvn∧n – cosine between the vn vector and the noun vector Classifier settings We treat the task as a binary classification problem and apply a linear SVM classifier using scikit-learn LinearSVC implementation.3 The error rates in Table 1 show that we are dealing with a two-class problem where one class (correct word combinations) significantly outnumbers the other class (errors) by up to 11"
P16-1092,C10-2103,0,0.0244315,"ion is see decision with the similarity of 0.8735 while the closest one to find solution is discover solution with the similarity of 0.9048. We implement an additional cosv∧n feature based on the intuition that the distance between the verb and noun vectors themselves may indicate a semantic mismatch and thus help in detecting lexical choice errors. 4.2 Classification Evaluation The goal of the classifier is to detect errors, therefore we primarily focus on its performance on the error class and, in addition to accuracy, report precision (P), recall (R) and F1 on this class. Previous studies (Nagata and Nakatani, 2010) suggest that systems with high precision in detecting errors are more helpful for L2 learning than systems with high recall as non-native speakers find misidentified errors very misleading. In line with this research, we focus on maximising precision on the error class. Baseline We compare the performance of our different feature sets to the baseline classifier which uses L2 co-occurrence frequency of the verb and noun in the pair as a single feature. Frequency sets a competitive baseline as it is often judged to be the measure of acceptability of an expression and many previous works relied"
P16-1092,W14-1701,0,0.049186,"Missing"
P16-1092,D10-1094,0,0.0238142,"the speakers of other languages for both language groups. 2 2.1 2.2 L1 factors in L2 writing The influence of an L1 on lexical choice in L2 and the resulting errors have been previously stud¨ ied (Chang et al., 2008; Ostling and Knutsson, 2009; Dahlmeier and Ng, 2011). These works focus on errors in particular L1s and use the translational equivalents directly to improve candidate selection and quality of corrections. Dahlmeier and Ng (2011) show that L1-induced paraphrases outperform approaches based on edit distance, homophones, and WordNet synonyms in selecting the appropriate corrections. Rozovskaya and Roth (2010) show that an error correction system for prepositions benefits from restricting the set of possible corrections to those observed in the non-native data. Rozovskaya and Roth (2011) further demonstrate that the models perform better when they use knowledge about error patterns of the non-native writers. According to their results, an error correction algorithm that relies on a set of priors dependent on the writer’s preposition and the writer’s L1 outperforms other methods. Madnani et al. (2008) show promising results in whole-sentence grammatical error correction using round-trip translations"
P16-1092,P11-1093,0,0.0226171,"usly stud¨ ied (Chang et al., 2008; Ostling and Knutsson, 2009; Dahlmeier and Ng, 2011). These works focus on errors in particular L1s and use the translational equivalents directly to improve candidate selection and quality of corrections. Dahlmeier and Ng (2011) show that L1-induced paraphrases outperform approaches based on edit distance, homophones, and WordNet synonyms in selecting the appropriate corrections. Rozovskaya and Roth (2010) show that an error correction system for prepositions benefits from restricting the set of possible corrections to those observed in the non-native data. Rozovskaya and Roth (2011) further demonstrate that the models perform better when they use knowledge about error patterns of the non-native writers. According to their results, an error correction algorithm that relies on a set of priors dependent on the writer’s preposition and the writer’s L1 outperforms other methods. Madnani et al. (2008) show promising results in whole-sentence grammatical error correction using round-trip translations from Google Translate via 8 different pivot languages. The results of these studies suggest that L1 is a valuable source of information in EDC. However, all these works use isolate"
P16-1092,N13-1090,0,\N,Missing
P16-2017,W14-2302,1,0.859433,"Missing"
P16-2017,W15-1402,1,0.882725,"icsi.berkeley.edu, ekaterina.shutova@cl.cam.ac.uk Abstract (Tsvetkov et al., 2014; Heintz et al., 2013; Turney et al., 2011; Birke and Sarkar, 2007; Gedigan et al., 2006), rather than using naturally occurring continuous text, as done here. Beigman Klebanov et al. (2014) and Beigman Klebanov et al. (2015) are the exceptions, used as a baseline in the current paper. Features that have been used so far in supervised metaphor classification address concreteness and abstractness, topic models, orthographic unigrams, sensorial features, semantic classifications using WordNet, among others (Beigman Klebanov et al., 2015; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Dunn, 2014; Heintz et al., 2013; Turney et al., 2011). Of the feature sets presented in this paper, all but WordNet features are novel. We investigate the effectiveness of semantic generalizations/classifications for capturing the regularities of the behavior of verbs in terms of their metaphoricity. Starting from orthographic word unigrams, we experiment with various ways of defining semantic classes for verbs (grammatical, resource-based, distributional) and measure the effectiveness of these classes for classifying all verbs in a running text"
P16-2017,W07-0104,0,0.0704928,"Missing"
P16-2017,P07-1115,0,0.0145023,"rated verb clusters as semantic classes. We clustered VerbNet verbs using a spectral clustering algorithm and lexico-syntactic features. We selected the verbs that occur more than 150 times in the British National Corpus, 1,610 in total, and clustered them into 150 clusters (Corpus). We used verb subcategorization frames (SCF) and the verb’s nominal arguments as features for clustering, as they have proved successful in previous verb classification experiments (Shutova et al., 2010). We extracted our features from the Gigaword corpus (Graff et al., 2003) using the SCF classification system of Preiss et al. (2007) to identify verb SCFs and the RASP parser (Briscoe et al., 2006) to extract the verb’s nominal arguments. Spectral clustering partitions the data relying on a similarity matrix that records similarities between all pairs of data points. We use JensenShannon divergence (dJS ) to measure similarity between feature vectors for two verbs, vi and vj , and construct a similarity matrix Sij : Sij = exp(−dJS (vi , vj )) (1) The matrix S encodes a similarity graph G over our verbs. The clustering problem can then be defined as identifying the optimal partition, or cut, of the graph into clusters. We u"
P16-2017,P06-4020,0,0.00877201,"rbs using a spectral clustering algorithm and lexico-syntactic features. We selected the verbs that occur more than 150 times in the British National Corpus, 1,610 in total, and clustered them into 150 clusters (Corpus). We used verb subcategorization frames (SCF) and the verb’s nominal arguments as features for clustering, as they have proved successful in previous verb classification experiments (Shutova et al., 2010). We extracted our features from the Gigaword corpus (Graff et al., 2003) using the SCF classification system of Preiss et al. (2007) to identify verb SCFs and the RASP parser (Briscoe et al., 2006) to extract the verb’s nominal arguments. Spectral clustering partitions the data relying on a similarity matrix that records similarities between all pairs of data points. We use JensenShannon divergence (dJS ) to measure similarity between feature vectors for two verbs, vi and vj , and construct a similarity matrix Sij : Sij = exp(−dJS (vi , vj )) (1) The matrix S encodes a similarity graph G over our verbs. The clustering problem can then be defined as identifying the optimal partition, or cut, of the graph into clusters. We use the multiway normalized cut (MNCut) algorithm of Meila and Shi"
P16-2017,C10-1113,1,0.908946,"h thematic role (VN-Role). Finally, VerbNet provides annotations of the re3.3 Corpus-based We also experimented with automaticallygenerated verb clusters as semantic classes. We clustered VerbNet verbs using a spectral clustering algorithm and lexico-syntactic features. We selected the verbs that occur more than 150 times in the British National Corpus, 1,610 in total, and clustered them into 150 clusters (Corpus). We used verb subcategorization frames (SCF) and the verb’s nominal arguments as features for clustering, as they have proved successful in previous verb classification experiments (Shutova et al., 2010). We extracted our features from the Gigaword corpus (Graff et al., 2003) using the SCF classification system of Preiss et al. (2007) to identify verb SCFs and the RASP parser (Briscoe et al., 2006) to extract the verb’s nominal arguments. Spectral clustering partitions the data relying on a similarity matrix that records similarities between all pairs of data points. We use JensenShannon divergence (dJS ) to measure similarity between feature vectors for two verbs, vi and vj , and construct a similarity matrix Sij : Sij = exp(−dJS (vi , vj )) (1) The matrix S encodes a similarity graph G over"
P16-2017,W14-2304,0,0.0331739,"t al., 2014; Heintz et al., 2013; Turney et al., 2011; Birke and Sarkar, 2007; Gedigan et al., 2006), rather than using naturally occurring continuous text, as done here. Beigman Klebanov et al. (2014) and Beigman Klebanov et al. (2015) are the exceptions, used as a baseline in the current paper. Features that have been used so far in supervised metaphor classification address concreteness and abstractness, topic models, orthographic unigrams, sensorial features, semantic classifications using WordNet, among others (Beigman Klebanov et al., 2015; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Dunn, 2014; Heintz et al., 2013; Turney et al., 2011). Of the feature sets presented in this paper, all but WordNet features are novel. We investigate the effectiveness of semantic generalizations/classifications for capturing the regularities of the behavior of verbs in terms of their metaphoricity. Starting from orthographic word unigrams, we experiment with various ways of defining semantic classes for verbs (grammatical, resource-based, distributional) and measure the effectiveness of these classes for classifying all verbs in a running text as metaphor or non metaphor. 1 Introduction According to t"
P16-2017,W15-1404,0,0.602277,"erina.shutova@cl.cam.ac.uk Abstract (Tsvetkov et al., 2014; Heintz et al., 2013; Turney et al., 2011; Birke and Sarkar, 2007; Gedigan et al., 2006), rather than using naturally occurring continuous text, as done here. Beigman Klebanov et al. (2014) and Beigman Klebanov et al. (2015) are the exceptions, used as a baseline in the current paper. Features that have been used so far in supervised metaphor classification address concreteness and abstractness, topic models, orthographic unigrams, sensorial features, semantic classifications using WordNet, among others (Beigman Klebanov et al., 2015; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Dunn, 2014; Heintz et al., 2013; Turney et al., 2011). Of the feature sets presented in this paper, all but WordNet features are novel. We investigate the effectiveness of semantic generalizations/classifications for capturing the regularities of the behavior of verbs in terms of their metaphoricity. Starting from orthographic word unigrams, we experiment with various ways of defining semantic classes for verbs (grammatical, resource-based, distributional) and measure the effectiveness of these classes for classifying all verbs in a running text as metaphor or non meta"
P16-2017,W06-3506,0,0.313909,"Missing"
P16-2017,P14-1024,0,0.473829,"uk Abstract (Tsvetkov et al., 2014; Heintz et al., 2013; Turney et al., 2011; Birke and Sarkar, 2007; Gedigan et al., 2006), rather than using naturally occurring continuous text, as done here. Beigman Klebanov et al. (2014) and Beigman Klebanov et al. (2015) are the exceptions, used as a baseline in the current paper. Features that have been used so far in supervised metaphor classification address concreteness and abstractness, topic models, orthographic unigrams, sensorial features, semantic classifications using WordNet, among others (Beigman Klebanov et al., 2015; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Dunn, 2014; Heintz et al., 2013; Turney et al., 2011). Of the feature sets presented in this paper, all but WordNet features are novel. We investigate the effectiveness of semantic generalizations/classifications for capturing the regularities of the behavior of verbs in terms of their metaphoricity. Starting from orthographic word unigrams, we experiment with various ways of defining semantic classes for verbs (grammatical, resource-based, distributional) and measure the effectiveness of these classes for classifying all verbs in a running text as metaphor or non metaphor. 1 Introduction Ac"
P16-2017,W13-0908,0,0.126343,"Heintz et al., 2013; Turney et al., 2011; Birke and Sarkar, 2007; Gedigan et al., 2006), rather than using naturally occurring continuous text, as done here. Beigman Klebanov et al. (2014) and Beigman Klebanov et al. (2015) are the exceptions, used as a baseline in the current paper. Features that have been used so far in supervised metaphor classification address concreteness and abstractness, topic models, orthographic unigrams, sensorial features, semantic classifications using WordNet, among others (Beigman Klebanov et al., 2015; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Dunn, 2014; Heintz et al., 2013; Turney et al., 2011). Of the feature sets presented in this paper, all but WordNet features are novel. We investigate the effectiveness of semantic generalizations/classifications for capturing the regularities of the behavior of verbs in terms of their metaphoricity. Starting from orthographic word unigrams, we experiment with various ways of defining semantic classes for verbs (grammatical, resource-based, distributional) and measure the effectiveness of these classes for classifying all verbs in a running text as metaphor or non metaphor. 1 Introduction According to the Conceptual Metapho"
P16-2017,D11-1063,0,\N,Missing
P19-1508,D13-1202,0,0.113946,"al representation. The results pave the way for testing alternate semantic models of negation against human semantic processing in the brain. 1 Introduction Computational semantic models are increasingly being evaluated in their ability to capture aspects of human semantic processing, including similarity and association judgments (De Deyne et al., 2016) and semantic representation in the brain (Bulat et al., 2017). Prior work shows that distributional semantic models (DSMs) are able to decode functional magnetic resonance imaging (fMRI) patterns associated with the meaning of concrete words (Anderson et al., 2013). Relevant to our work, Carota et al. (2017) showed that the similarity structure of DSMs for action words correlates with that of fMRI patterns in brain regions implicated in action-semantic processing. More recent studies have also investigated the ability of DSMs to predict fMRI patterns of sentential meanings (Pereira et al., 2018) and larger narrative text passages (Wehbe et al., 2014; Huth et al., 2016). They have shown that encoding models based on word embeddings are able to capture subtle aspects of sentence meaning in the brain, even when these models are oblivious of word order and"
P19-1508,Q17-1002,0,0.0187937,"gions. These findings lend further support to the hypothesis that negation may involve reduced access to aspects of the affirmative mental representation. 2 Related Work Decoding brain activity Mitchell et al. (2008) were the first to show that DSMs based on cooccurrence counts with 25 sensorimotor verbs (e.g. see, hear, taste) can predict fMRI patterns associated with the meaning of concrete nouns. Later research has demonstrated that a range of DSMs can decode fMRI patterns of concrete nouns (Murphy et al., 2012; Anderson et al., 2013; Bulat et al., 2017) and, more recently, abstract nouns (Anderson et al., 2017). Most relevant to our study, Carota et al. (2017) showed that the similarity structure of a Latent Semantic Analysis (LSA) model for action words (nouns and verbs) correlates with that of fMRI patterns in motor areas (left precentral gyrus (LPG)) and classical language-related brain regions (left inferior frontal gyrus (LIFG), left posterior middle temporal gyurs (LMTP)) implicated in lexico-semantic processing (Binder et al., 2009). Moving beyond words, other studies have shown that DSMs can predict brain activity patterns associated with larger linguistic units (Wehbe et al., 2014; Huth et"
P19-1508,D15-1075,0,0.492633,"ing (Anderson et al., 2016). We also test the extent to which the representational similarity structure (Kriegeskorte et al., 2008) of DSMs of actionverbs correlates with that of fMRI patterns associated with negated versus affirmative sentences containing hand-action verbs. We focus on motor areas and classical language-related brain regions implicated in action-semantic processing (e.g., understanding action words and sentences) (Pulvermuller, 2005; Kemmerer, 2015). DSMs have proven successful in modeling aspects of semantic composition in the context of the natural language inference task (Bowman et al., 2015b). Although the modeling of logical negation using DSMs is wrought with challenges (Kruszewski et al., 2017), current state-of-the-art neural network based models appear to capture elements of markedness asymmetry in negation (Li et al., 2016) and, presumably, implicitly model negation at some level. In our experiments, we investigate the extent to which DSMs are able to decode (correlate with) fMRI patterns associated with the reading of sentences containing negated and affirmative action verbs. We experiment with (1) word-level representations of action verbs; and (2) compositional semantic"
P19-1508,P16-1139,0,0.052494,"Missing"
P19-1508,D17-1113,1,0.910069,"e, within brain regions implicated in action-semantic processing. This supports behavioral and brain imaging studies, suggesting that negation involves reduced access to aspects of the affirmative mental representation. The results pave the way for testing alternate semantic models of negation against human semantic processing in the brain. 1 Introduction Computational semantic models are increasingly being evaluated in their ability to capture aspects of human semantic processing, including similarity and association judgments (De Deyne et al., 2016) and semantic representation in the brain (Bulat et al., 2017). Prior work shows that distributional semantic models (DSMs) are able to decode functional magnetic resonance imaging (fMRI) patterns associated with the meaning of concrete words (Anderson et al., 2013). Relevant to our work, Carota et al. (2017) showed that the similarity structure of DSMs for action words correlates with that of fMRI patterns in brain regions implicated in action-semantic processing. More recent studies have also investigated the ability of DSMs to predict fMRI patterns of sentential meanings (Pereira et al., 2018) and larger narrative text passages (Wehbe et al., 2014; Hu"
P19-1508,C16-1175,0,0.0465424,"Missing"
P19-1508,N16-1082,0,0.385036,"ontaining hand-action verbs. We focus on motor areas and classical language-related brain regions implicated in action-semantic processing (e.g., understanding action words and sentences) (Pulvermuller, 2005; Kemmerer, 2015). DSMs have proven successful in modeling aspects of semantic composition in the context of the natural language inference task (Bowman et al., 2015b). Although the modeling of logical negation using DSMs is wrought with challenges (Kruszewski et al., 2017), current state-of-the-art neural network based models appear to capture elements of markedness asymmetry in negation (Li et al., 2016) and, presumably, implicitly model negation at some level. In our experiments, we investigate the extent to which DSMs are able to decode (correlate with) fMRI patterns associated with the reading of sentences containing negated and affirmative action verbs. We experiment with (1) word-level representations of action verbs; and (2) compositional semantic models (based on addition of word-level representations and long short-term memory (LSTM) networks). In agreement with previous work, our results show that distributional representations of action verbs (and to some extent verb-object phrases)"
P19-1508,S12-1019,0,0.034714,"gation impacts semantic similarity in motor areas, but also to some extent language-related brain regions. These findings lend further support to the hypothesis that negation may involve reduced access to aspects of the affirmative mental representation. 2 Related Work Decoding brain activity Mitchell et al. (2008) were the first to show that DSMs based on cooccurrence counts with 25 sensorimotor verbs (e.g. see, hear, taste) can predict fMRI patterns associated with the meaning of concrete nouns. Later research has demonstrated that a range of DSMs can decode fMRI patterns of concrete nouns (Murphy et al., 2012; Anderson et al., 2013; Bulat et al., 2017) and, more recently, abstract nouns (Anderson et al., 2017). Most relevant to our study, Carota et al. (2017) showed that the similarity structure of a Latent Semantic Analysis (LSA) model for action words (nouns and verbs) correlates with that of fMRI patterns in motor areas (left precentral gyrus (LPG)) and classical language-related brain regions (left inferior frontal gyrus (LIFG), left posterior middle temporal gyurs (LMTP)) implicated in lexico-semantic processing (Binder et al., 2009). Moving beyond words, other studies have shown that DSMs ca"
P19-1508,P15-1130,0,0.443359,"at distributional semantics is a good fit to model conversational negation. Their focus is on compositional distributional methods, which model the negation of nouns via linear transformations. This approach, unlike those used in the present work, relies on the availability of parsed training data. The effect of negation has also been studied in recurrent neural network models for sentiment classification: Li et al. (2016) observe that their LSTM model does not simply learn a fixed transformation for “not”, but rather manages to capture differences in the composition of different words; while Wang et al. (2015) study the behaviour of the LSTM gates in response to negation, showing the network’s ability to simulate complex linguistic phenomena. Both groups of authors, like us, focus on LSTM networks, but their models were trained on a sentiment analysis task. We chose a natural language inference task, as it has over an order of magnitude more training data, and requires models to learn a full range of logical and commonsense inferences (Bowman et al., 2015a). Neurocognitive processing of negation Neuroimaging studies show that negated hand action sentences (e.g., Now I don’t push the button) and neg"
P19-1508,D14-1162,0,0.0855923,"ed with a structural T1-weighted magnetization prepared rapid gradient echo (MPRAGE) with TR=1950 ms, TE=2.26 ms, flip angle 10◦ , 256 × 256 mm matrix, 1 mm resolution, and 208 coronal slices. Whole brain functional images were obtained with a T2* weighted single-shot gradient-recalled echo-planar sequence (EPI) using blood oxygenation-level-dependent contrast with TR=2000 ms, TE=30 ms, flip angle 90◦ , 64 × 64 mm matrix, 3.5 mm resolution. Each functional image consisted of 37 contiguous axial slices, acquired in interleaved mode. 4 Semantic models All our semantic models are based on GloVe (Pennington et al., 2014) word embeddings. We use the 100-dimensional word vectors provided by the authors, trained on Wikipedia and Gigaword corpora.1 We investigate the following models: 1 https://nlp.stanford.edu/projects/glove/ LSTM As a more sophisticated compositional model, we take the long short-term memory (LSTM) recurrent neural network architecture (Hochreiter and Schmidhuber, 1997). Due to the lack of a large training set, directly training the LSTM model for our specific task (i.e. brain decoding) was not possible. Instead, we trained the LSTM on a natural language inference task (Bowman et al., 2015a), a"
Q16-1004,P12-1042,0,0.0104454,"ive-words; and (4) automatically detects differences in perspectiveword distributions in the two languages. We perform a behavioural evaluation of a subset of the differences identified by the model and demonstrate their psychological validity. Our data and dictionaries are available from the first author upon request. 2 Related work View detection. Identifying different viewpoints is related to the well-studied area of subjectivity detection, which aims at exposing opinion, evaluation, and speculation in text (Wiebe et al., 2004) and attributing it to specific people (Awadallah et al., 2011; Abu-Jbara et al., 2012). In our work, we are less interested in explicit local forms of subjectivity, instead aiming at detecting more general contrasts 48 across linguistic communities. Another line of research has focused on inferring author attributes such as gender, age (Garera and Yarowsky, 2009), location (Jones et al., 2007), or political affiliation (Pennacchiotti and Popescu, 2011). Such studies make use of syntactic style, discourse characteristics, as well as lexical choice. The models used for this are typically binary classifiers trained in a fully supervised fashion. In contrast, in our task, we automa"
Q16-1004,D10-1111,0,0.0236667,"detection. LDA also assumes that the distribution of each topic is fixed across all documents in a corpus. Therefore, a topic associated with, e.g., war will have the same distribution over the lexicon regardless of whether the document was taken from a pro-war editorial or an anti-war speech. However, in reality we may expect a single topic to exhibit systematic and predictable variations in its distribution based on authorship. The cross-collection LDA model by Paul and Girju (2009) addresses this by specifically aiming to expose viewpoint differences across different document collections. Ahmed and Xing (2010) proposed a similar model for detecting ideological differences. Fang et al. (2012)’s Cross-Perspective Topic (CPT) model breaks up the terms in the vocabulary into topic terms and perspective terms with different generative processes, and differentiates between different collections of documents within the corpus. The topic terms are assumed to be generated as in LDA. However, the distribution of perspective terms in a document is taken to be dependent on both the topic mixture of the document as well as the collection from which the document is drawn. Recent works proposed models for specifi"
Q16-1004,D10-1005,0,0.00900521,"tion (Jones et al., 2007), or political affiliation (Pennacchiotti and Popescu, 2011). Such studies make use of syntactic style, discourse characteristics, as well as lexical choice. The models used for this are typically binary classifiers trained in a fully supervised fashion. In contrast, in our task, we automatically infer the topic distributions and find topic-specific contrasts. Probabilistic topic models. Probabilistic topic models have proven useful for a variety of semantic tasks, such as selectional-preference induction ´ S´eaghdha, 2010; Ritter et al., 2010), sentiment (O analysis (Boyd-Graber and Resnik, 2010) and studying the evolution of concepts and ideas (Hall et al., 2008). The goal of a topic model is to characterize observed data in terms of a much smaller set of unobserved, semantically coherent topics. A particularly popular probabilistic topic model is Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Under its assumptions, each document has a unique mix of topics, and each topic is a distribution over terms in the vocabulary. A topic is chosen for every word token according to the topic mix of the document to which it belongs, and then the word’s identity is drawn from the correspon"
Q16-1004,D07-1069,0,0.142629,"ing methods to date focus on the analysis of monolingual texts. In contrast, we present a statistical model that simultaneously learns a set of common topics from multilingual, non-parallel data and automatically discovers the differences in perspectives on these topics across linguistic communities. We perform a behavioural evaluation of a subset of the differences identified by our model in English and Spanish to investigate their psychological validity. 1 Introduction Recent years have seen a growing interest in textmining applications aimed at uncovering public opinions and social trends (Fader et al., 2007; Monroe et al., 2008; Gerrish and Blei, 2011; Pennacchiotti and Popescu, 2011). They rest on the assumption that the language we use is indicative of our underlying worldviews. Research in cognitive and sociolinguistics suggests that linguistic variation across communities systematically reflects differences in their cultural and moral models and goes beyond lexicon and grammar (K¨ovecses, 2004; Lakoff and Wehling, 2012). Cross-cultural differences manifest themselves in text in a multitude of ways, most prominently through the use of explicit opinion vocabulary with respect to a certain topi"
Q16-1004,P09-1080,0,0.0190815,"vailable from the first author upon request. 2 Related work View detection. Identifying different viewpoints is related to the well-studied area of subjectivity detection, which aims at exposing opinion, evaluation, and speculation in text (Wiebe et al., 2004) and attributing it to specific people (Awadallah et al., 2011; Abu-Jbara et al., 2012). In our work, we are less interested in explicit local forms of subjectivity, instead aiming at detecting more general contrasts 48 across linguistic communities. Another line of research has focused on inferring author attributes such as gender, age (Garera and Yarowsky, 2009), location (Jones et al., 2007), or political affiliation (Pennacchiotti and Popescu, 2011). Such studies make use of syntactic style, discourse characteristics, as well as lexical choice. The models used for this are typically binary classifiers trained in a fully supervised fashion. In contrast, in our task, we automatically infer the topic distributions and find topic-specific contrasts. Probabilistic topic models. Probabilistic topic models have proven useful for a variety of semantic tasks, such as selectional-preference induction ´ S´eaghdha, 2010; Ritter et al., 2010), sentiment (O anal"
Q16-1004,D13-1191,0,0.0141878,"pic (CPT) model breaks up the terms in the vocabulary into topic terms and perspective terms with different generative processes, and differentiates between different collections of documents within the corpus. The topic terms are assumed to be generated as in LDA. However, the distribution of perspective terms in a document is taken to be dependent on both the topic mixture of the document as well as the collection from which the document is drawn. Recent works proposed models for specific types of data. Qiu and Jiang (2013) use user identities and interactions in threaded discussions, while Gottipati et al. (2013) developed a topic model for Debatepedia, a semi-structured resource in which arguments are explicitly enumerated. However, all of these models perform their analyses on monolingual datasets. Thus, they are useful for comparing different ideologies expressed in the same language, but not for cross-linguistic comparisons. 3 Method The goal of our model is to analyse large, nonparallel, multilingual corpora and present crosslingually valid topics and the associated perspectives, automatically inferring the differences in conceptualization of these topics across cultures. Following Boyd-Graber an"
Q16-1004,P08-1088,0,0.099971,"signed for monolingual text and thus it lacks the structure necessary to model cross-lingually valid topics. While topic models can be trained individually on two languages and then the acquired topics can be matched, the correspondences between the topics for the two terms will be highly unstable. To address this, Boyd-Graber and Blei (2009) (M U T O) and Jagarlamudi and Daum´e III (2010) (J OINT LDA) introduced the notion of crosslingually valid concepts associated with different terms in different languages, using bilingual dictionaries to model topics across languages. Based on a model by Haghighi et al. (2008), M U T O is capable of learning translations–i.e., matching between terms in the different languages being compared. The Polylingual Topic Model of Mimno et al. (2009) is another approach to finding topics in multilingual corpora, but it requires tuples composed of comparable documents in each language of the corpus. Topic models for view detection. LDA also assumes that the distribution of each topic is fixed across all documents in a corpus. Therefore, a topic associated with, e.g., war will have the same distribution over the lexicon regardless of whether the document was taken from a pro-"
Q16-1004,D08-1038,0,0.0125207,"2011). Such studies make use of syntactic style, discourse characteristics, as well as lexical choice. The models used for this are typically binary classifiers trained in a fully supervised fashion. In contrast, in our task, we automatically infer the topic distributions and find topic-specific contrasts. Probabilistic topic models. Probabilistic topic models have proven useful for a variety of semantic tasks, such as selectional-preference induction ´ S´eaghdha, 2010; Ritter et al., 2010), sentiment (O analysis (Boyd-Graber and Resnik, 2010) and studying the evolution of concepts and ideas (Hall et al., 2008). The goal of a topic model is to characterize observed data in terms of a much smaller set of unobserved, semantically coherent topics. A particularly popular probabilistic topic model is Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Under its assumptions, each document has a unique mix of topics, and each topic is a distribution over terms in the vocabulary. A topic is chosen for every word token according to the topic mix of the document to which it belongs, and then the word’s identity is drawn from the corresponding topic’s distribution. Handling multilingual corpora. LDA is desi"
Q16-1004,D09-1092,0,0.0387022,"Missing"
Q16-1004,D11-1024,0,0.399322,"rplexity for topic words wi and perspective-words oi separately. For perplexity is defined P topic words, the w as exp(− wi ∈H logp(wi )/N ). As for standard LDA, exact inference of p(wi ) is intractable under this model. Therefore we adapted the estimator developed by Murray and Salakhutdinov (2009) to our models. Coherence is a measure inspired by pointwise mutual information (Newman et al., 2010). Let D(v) be the the number of documents with at least one token of type v and let D(v, w) be the number of documents containing at least one token of type v and at least one token of type w. Then Mimno et al. (2011) define the coherence of topic k as 1 M 2  M m−1 X X (k) log m=2 `=1 (k) (k) D(vm , v` ) +  (k) D(v` ) , (k) where V (k) = (v1 , ..., vM ) is a list of the M most probable words in topic k and  is a small smoothing constant used to avoid taking the logarithm of zero. Mimno et al. (2011) find that coherence correlates better with human judgments than do likelihoodbased measures. Coherence is topic-specific measure, so for each model variant we trained, we computed the median topic coherence across all the topics learned by the model. We set  = 0.1. Model performance and analysis. Fig. 2 sho"
Q16-1004,N10-1012,0,0.0403447,"anguage pairs. Perplexity is a measure of how well a model trained on a training set predicts the co-occurrence of words on an unseen test set H. Lower perplexity indicates better model fit. We evaluate the held-out perplexity for topic words wi and perspective-words oi separately. For perplexity is defined P topic words, the w as exp(− wi ∈H logp(wi )/N ). As for standard LDA, exact inference of p(wi ) is intractable under this model. Therefore we adapted the estimator developed by Murray and Salakhutdinov (2009) to our models. Coherence is a measure inspired by pointwise mutual information (Newman et al., 2010). Let D(v) be the the number of documents with at least one token of type v and let D(v, w) be the number of documents containing at least one token of type v and at least one token of type w. Then Mimno et al. (2011) define the coherence of topic k as 1 M 2  M m−1 X X (k) log m=2 `=1 (k) (k) D(vm , v` ) +  (k) D(v` ) , (k) where V (k) = (v1 , ..., vM ) is a list of the M most probable words in topic k and  is a small smoothing constant used to avoid taking the logarithm of zero. Mimno et al. (2011) find that coherence correlates better with human judgments than do likelihoodbased measures."
Q16-1004,P10-1045,0,0.0152701,"Missing"
Q16-1004,D09-1146,0,0.0263618,"multilingual corpora, but it requires tuples composed of comparable documents in each language of the corpus. Topic models for view detection. LDA also assumes that the distribution of each topic is fixed across all documents in a corpus. Therefore, a topic associated with, e.g., war will have the same distribution over the lexicon regardless of whether the document was taken from a pro-war editorial or an anti-war speech. However, in reality we may expect a single topic to exhibit systematic and predictable variations in its distribution based on authorship. The cross-collection LDA model by Paul and Girju (2009) addresses this by specifically aiming to expose viewpoint differences across different document collections. Ahmed and Xing (2010) proposed a similar model for detecting ideological differences. Fang et al. (2012)’s Cross-Perspective Topic (CPT) model breaks up the terms in the vocabulary into topic terms and perspective terms with different generative processes, and differentiates between different collections of documents within the corpus. The topic terms are assumed to be generated as in LDA. However, the distribution of perspective terms in a document is taken to be dependent on both the"
Q16-1004,W10-0510,0,0.0188758,"Missing"
Q16-1004,N13-1123,0,0.0120277,"ar model for detecting ideological differences. Fang et al. (2012)’s Cross-Perspective Topic (CPT) model breaks up the terms in the vocabulary into topic terms and perspective terms with different generative processes, and differentiates between different collections of documents within the corpus. The topic terms are assumed to be generated as in LDA. However, the distribution of perspective terms in a document is taken to be dependent on both the topic mixture of the document as well as the collection from which the document is drawn. Recent works proposed models for specific types of data. Qiu and Jiang (2013) use user identities and interactions in threaded discussions, while Gottipati et al. (2013) developed a topic model for Debatepedia, a semi-structured resource in which arguments are explicitly enumerated. However, all of these models perform their analyses on monolingual datasets. Thus, they are useful for comparing different ideologies expressed in the same language, but not for cross-linguistic comparisons. 3 Method The goal of our model is to analyse large, nonparallel, multilingual corpora and present crosslingually valid topics and the associated perspectives, automatically inferring th"
Q16-1004,P10-1044,0,0.024912,"Missing"
Q16-1004,D12-1087,0,0.0108175,"different model variants for different numbers of iterations at K=175. median topic coherence. Once again, this general pattern held true for the English-Russian pair and T WITTER corpora. Overall, the results show that M ULTIPLE S TATIC I NCLUDE provides superior performance across measures, corpora, topic numbers, and languages. We therefore used this variant in further data analysis and evaluation. Incidentally, the observed decrease in topic coherence as K increases is expected, because as K increases, lowerlikelihood topics tend to be more incoherent (Mimno et al., 2011). Experiments by Stevens et al. (2012) show that this effect is observed for LDA-, NMF-, and SVD-based topic models. Cross-linguistic matchings. The matchings inferred by the S INGLE I NFER I NCLUDE variant were of mixed quality. Some of the matchings corrected low-quality translations in the original dictionary. For instance, our prior dictionary matched passage in English to pasaje in Spanish. Though technically correct, the dominant meaning of pasaje is [travel] ticket. The T WITTER model correctly matched passage to ruta instead. Many of the matchings learned by the model did not provide technically correct translations, yet w"
Q16-1004,J04-3002,0,0.0288438,"finds cross-lingual topics specified by distributions over topic-words and perspective-words; and (4) automatically detects differences in perspectiveword distributions in the two languages. We perform a behavioural evaluation of a subset of the differences identified by the model and demonstrate their psychological validity. Our data and dictionaries are available from the first author upon request. 2 Related work View detection. Identifying different viewpoints is related to the well-studied area of subjectivity detection, which aims at exposing opinion, evaluation, and speculation in text (Wiebe et al., 2004) and attributing it to specific people (Awadallah et al., 2011; Abu-Jbara et al., 2012). In our work, we are less interested in explicit local forms of subjectivity, instead aiming at detecting more general contrasts 48 across linguistic communities. Another line of research has focused on inferring author attributes such as gender, age (Garera and Yarowsky, 2009), location (Jones et al., 2007), or political affiliation (Pennacchiotti and Popescu, 2011). Such studies make use of syntactic style, discourse characteristics, as well as lexical choice. The models used for this are typically binary"
S13-1040,E06-1042,0,0.103627,"Missing"
S13-1040,P06-4020,0,0.0129434,"ak SPS are unlikely to be used metaphorically in any context. For every verb in the input text, the filter determines their likelihood of being a metaphor based on their SPS and discards the weak ones. The SPS filter is context-free, and the reverse paraphrasing method is then applied in the next steps to determine if the remaining verbs are indeed used metaphorically in the given context. We automatically acquired selectional preference distributions for verb-subject and verb-direct object relations from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser (Briscoe et al., 2006; Andersen et al., 2008). We applied the noun clustering method of Sun and Korhonen (2009) to 2000 most frequent nouns in the BNC to obtain 200 common selectional preference classes. To quantify selectional preferences, we adopted the SPS measure of Resnik (1993). Resnik defines SPS of a verb as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position (regardless of the verb). He quantifies this difference using the Kullback-Leibler divergence: SR (v) = D(P (c|v)||P (c)) = X P (c|v) P (c|v)"
S13-1040,D08-1094,0,0.062203,"Missing"
S13-1040,W09-0208,0,0.033551,"Missing"
S13-1040,J91-1003,0,0.64954,"t’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference c and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. 2013 Association for Computational Linguistics phenomena"
S13-1040,W06-3506,0,0.14916,"ation extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: P"
S13-1040,kingsbury-palmer-2002-treebank,0,0.270661,"Missing"
S13-1040,W07-0103,0,0.199965,"n, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference c and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. 2013 Association for Computational Linguistics phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and required training data (Shutova et al., 2010; Turney et al., 2011), often resulting in a limited coverage. The metaphor processing task itself has been most commonly addressed in NLP as two individual subtasks: metaphor identification and metaphor interpretation, with the systems focusing only on one of them at a time, or at best combing the two in a pipeline (Shutova et al., 2012a). Metaphor identification systems annotate metaphorical language in text, and metaphor interpretation systems discover literal meanings of the previously annotated expressions. However, cognitive evidence sugg"
S13-1040,J04-1002,0,0.213614,"ation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semant"
S13-1040,S07-1009,0,0.0528993,"are hypernyms of the verb v, or share a common hypernym with it. Following Shutova, we restrict the hypernym search to a depth of three levels in the taxonomy. Table 1 shows the filtered lists of paraphrases for the expressions “stir excitement” and “campaign surged”. The goal of the filter is to discard unrelated paraphrases and thus ensure the meaning retention during paraphrasing. Note, however, that we define meaning retention broadly, as sharing a set of similar basic properties. Such a broad definition distinguishes our system from other WordNet-based approaches to lexical substitution (McCarthy and Navigli, 2007) and allows for a transition from metaphorical to literal language, while preserving the original meaning. 3.2.3 SP-based Re-ranking The lists of paraphrases which were generated as described above contain some irrelevant paraphrases (e.g. “campaign lifted” for “campaign surged”) and some metaphorically-used paraphrases (e.g. “campaign soared”). However, our aim is to identify literal paraphrases among the candidates. Shutova’s method uses selectional preferences of the candiLog-likelihood Verb-DirectObject stir excitement: -14.28 -14.84 -15.53 -15.53 -15.53 -16.23 -16.23 -16.23 -16.23 Subject"
S13-1040,shutova-teufel-2010-metaphor,1,0.90044,"The car in (1) and business in (2) are viewed as living beings and thus they can drink or be strangled respectively. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have invest"
S13-1040,C10-1113,1,0.523714,"taphor identification systems annotate metaphorical language in text, and metaphor interpretation systems discover literal meanings of the previously annotated expressions. However, cognitive evidence suggests that humans are likely to perform identification and interpretation simultaneously, as part of a holistic metaphor comprehension process (Coulson, 2008; Utsumi, 2011; Gibbs and Colston, 2012). In this paper, we also take this stance and present the first computational method that identifies metaphorical expressions in unrestricted text by means of their interpretation. Following Shutova (2010), we define metaphor interpretation as a task of finding a literal paraphrase for a metaphorically used word and introduce the concept of symmetric reverse paraphrasing as a criterion for metaphor identification. The main assumption behind our method is that the literal paraphrases of literally-used words should yield the original phrase when paraphrased in reverse. For example, when the expression “clean the house” is paraphrased as “tidy the house”, the reverse paraphrasing of tidy would generate clean. Our expectation is that such a symmetry in paraphrasing is indicative of literal use. The"
S13-1040,C12-2109,1,0.900901,"Missing"
S13-1040,N10-1147,1,0.887807,"on mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of t"
S13-1040,D09-1067,0,0.0684219,"Missing"
S13-1040,D11-1063,0,0.572029,"le, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference c and the Shared Task, p"
S13-1040,andersen-etal-2008-bnc,0,\N,Missing
S13-1040,J13-2003,1,\N,Missing
S13-1040,C08-2001,0,\N,Missing
S15-2080,C10-1113,1,0.0610957,"Missing"
S16-2003,H05-1073,0,0.0250423,"extracted the following types of instances from WordNet: Emotion annotation: Sentiment analysis is defined as detecting the evaluative or affective attitude in text. A vast majority of work in sentiment analysis has focused on developing classifiers for valence prediction (Kiritchenko et al., 2014; Dong et al., 2014; Socher et al., 2013; Mohammad et al., 2013), i.e., determining whether a piece of text expresses positive, negative, or neutral attitude. However, there is a growing interest in detecting a wider range of emotions such as joy, sadness, optimism, etc. (Holzman and Pottenger, 2003; Alm et al., 2005; Brooks et al., 2013; Mohammad, 2012). Much of the this work has been influenced by the idea that some emotions are more basic than others (Ekman, 1992; Ekman and Friesen, 2003; Plutchik, 1980; Plutchik, 1991). Mohammad (2012) polled the Twitter API for tweets that have hashtag words such as #anger and #sadness corresponding to the eight Plutchik basic emo4 Experimental Setup Instance 1 Target verb: erase Sentence: The Turks erased the Armenians. Here, erase is used metaphorically. We will refer to such instances as metaphorical instances. Now consider an instance similar to the one above, bu"
S16-2003,W13-0902,0,0.0858739,"analysis thereof. The majority of corpus-linguistic studies were concerned with metaphorical expressions and mappings within a limited domain, e.g., WAR , BUSINESS , FOOD or www.crowdflower.com http://saifmohammad.com/WebPages/metaphor.html 3 24 Words used in different senses convey different affect. PLANT metaphors (Santa Ana, 1999; Izwaini, 2003; Koller, 2004; Skorczynska Sznajder and Pique-Angordans, 2004; Lu and Ahrens, 2008; Low et al., 2010; Hardie et al., 2007), in a particular genre or type of discourse (Charteris-Black, 2000; Cameron, 2003; Lu and Ahrens, 2008; Martin, 2006; Beigman Klebanov and Flor, 2013). Two recent studies (Steen et al., 2010; Shutova and Teufel, 2010) moved away from investigating particular domains to a more general study of how metaphor behaves in unrestricted continuous text. Steen and colleagues (Pragglejaz Group, 2007; Steen et al., 2010) proposed a metaphor identification procedure (MIP), in which every word is tagged as literal or metaphorical, based on whether it has a “more basic meaning” in other contexts than the current one. The basic meaning was defined as “more concrete; related to bodily action; more precise (as opposed to vague); historically older” and its"
S16-2003,S12-1023,0,0.0343494,"Missing"
S16-2003,P13-1067,0,0.0419462,"a distinct viewpoint on governmental regulation of business, as opposed to a more neutral factual statement expressed in (1b). The interplay of metaphor and emotion has been an object of interest in fields such as linguistics (Blanchette et al., 2001; Kovecses, 2003), political science (Lakoff and Wehling, 2012), cognitive psychology (Crawford, 2009; Thibodeau and Boroditsky, 2011) and neuroscience (Aziz-Zadeh and Damasio, 2008; Jabbi et al., 2008). A number of computational approaches for sentiment polarity classification of metaphorical language have also been proposed (Veale and Li, 2012; Kozareva, 2013; Strzalkowski et al., 2014). However, there is no quantitative study establishing the extent to which metaphorical language is used to express emotion nor a data-supported account of the mechanisms by which this happens. Our study addresses two questions: (i) whether a metaphorical statement is likely to convey a stronger emotional content than its literal counterpart; and (ii) how this emotional content arises in the metaphor, i.e. whether it comes from the source domain, or from the target domain, or rather arises compositionally through interaction of the source and the target. To answer t"
S16-2003,P14-2009,0,0.00457945,"he usage of one or more of the near-synonyms. We will refer to each of these sentences as the verb-sense sentence, or just sentence. The portion of the sentence excluding the target verb will be called the context. We will refer to each pair of target verb and verb-sense sentence as an instance. We extracted the following types of instances from WordNet: Emotion annotation: Sentiment analysis is defined as detecting the evaluative or affective attitude in text. A vast majority of work in sentiment analysis has focused on developing classifiers for valence prediction (Kiritchenko et al., 2014; Dong et al., 2014; Socher et al., 2013; Mohammad et al., 2013), i.e., determining whether a piece of text expresses positive, negative, or neutral attitude. However, there is a growing interest in detecting a wider range of emotions such as joy, sadness, optimism, etc. (Holzman and Pottenger, 2003; Alm et al., 2005; Brooks et al., 2013; Mohammad, 2012). Much of the this work has been influenced by the idea that some emotions are more basic than others (Ekman, 1992; Ekman and Friesen, 2003; Plutchik, 1980; Plutchik, 1991). Mohammad (2012) polled the Twitter API for tweets that have hashtag words such as #anger"
S16-2003,shutova-teufel-2010-metaphor,1,0.581634,"Missing"
S16-2003,D13-1170,0,0.00351019,"more of the near-synonyms. We will refer to each of these sentences as the verb-sense sentence, or just sentence. The portion of the sentence excluding the target verb will be called the context. We will refer to each pair of target verb and verb-sense sentence as an instance. We extracted the following types of instances from WordNet: Emotion annotation: Sentiment analysis is defined as detecting the evaluative or affective attitude in text. A vast majority of work in sentiment analysis has focused on developing classifiers for valence prediction (Kiritchenko et al., 2014; Dong et al., 2014; Socher et al., 2013; Mohammad et al., 2013), i.e., determining whether a piece of text expresses positive, negative, or neutral attitude. However, there is a growing interest in detecting a wider range of emotions such as joy, sadness, optimism, etc. (Holzman and Pottenger, 2003; Alm et al., 2005; Brooks et al., 2013; Mohammad, 2012). Much of the this work has been influenced by the idea that some emotions are more basic than others (Ekman, 1992; Ekman and Friesen, 2003; Plutchik, 1980; Plutchik, 1991). Mohammad (2012) polled the Twitter API for tweets that have hashtag words such as #anger and #sadness correspo"
S16-2003,strapparava-valitutti-2004-wordnet,0,0.0378304,"or a word predicts the intended sense, based on context. A problem with this approach to WSD is that good coverage of common polysemous English words would require about 3,200 distinct models. Kilgarriff (1997) has argued there are systematic relations among word senses across different words, focusing in particular on metaphor as a ubiquitous source of polysemy. This area of research is known as regular polysemy. Thus, there is a systematic relation between metaphor and word sense (Kilgarriff, 1997; Turney et al., 2011) and the emotion associated with a word depends on the sense of the word (Strapparava and Valitutti, 2004; Mohammad and Turney, 2013).3 This raises the question of whether there is a systematic relation between presence of metaphor and the emotional content of words. As far as we know, this is the first paper to quantitatively explore this question. Gibbs et al. (2002) conducted a study that looked at how listeners respond to metaphor and irony when they are played audio tapes describing emotional experiences. They found that on average metaphors were rated as being more emotional than non-metaphoric expressions. However, that work did not compare paraphrase pairs that differed in just one word ("
S16-2003,S13-2053,1,0.355924,"nyms. We will refer to each of these sentences as the verb-sense sentence, or just sentence. The portion of the sentence excluding the target verb will be called the context. We will refer to each pair of target verb and verb-sense sentence as an instance. We extracted the following types of instances from WordNet: Emotion annotation: Sentiment analysis is defined as detecting the evaluative or affective attitude in text. A vast majority of work in sentiment analysis has focused on developing classifiers for valence prediction (Kiritchenko et al., 2014; Dong et al., 2014; Socher et al., 2013; Mohammad et al., 2013), i.e., determining whether a piece of text expresses positive, negative, or neutral attitude. However, there is a growing interest in detecting a wider range of emotions such as joy, sadness, optimism, etc. (Holzman and Pottenger, 2003; Alm et al., 2005; Brooks et al., 2013; Mohammad, 2012). Much of the this work has been influenced by the idea that some emotions are more basic than others (Ekman, 1992; Ekman and Friesen, 2003; Plutchik, 1980; Plutchik, 1991). Mohammad (2012) polled the Twitter API for tweets that have hashtag words such as #anger and #sadness corresponding to the eight Plutc"
S16-2003,W14-2306,0,0.0297923,"point on governmental regulation of business, as opposed to a more neutral factual statement expressed in (1b). The interplay of metaphor and emotion has been an object of interest in fields such as linguistics (Blanchette et al., 2001; Kovecses, 2003), political science (Lakoff and Wehling, 2012), cognitive psychology (Crawford, 2009; Thibodeau and Boroditsky, 2011) and neuroscience (Aziz-Zadeh and Damasio, 2008; Jabbi et al., 2008). A number of computational approaches for sentiment polarity classification of metaphorical language have also been proposed (Veale and Li, 2012; Kozareva, 2013; Strzalkowski et al., 2014). However, there is no quantitative study establishing the extent to which metaphorical language is used to express emotion nor a data-supported account of the mechanisms by which this happens. Our study addresses two questions: (i) whether a metaphorical statement is likely to convey a stronger emotional content than its literal counterpart; and (ii) how this emotional content arises in the metaphor, i.e. whether it comes from the source domain, or from the target domain, or rather arises compositionally through interaction of the source and the target. To answer these questions, we conduct a"
S16-2003,S12-1033,1,0.46576,"ces from WordNet: Emotion annotation: Sentiment analysis is defined as detecting the evaluative or affective attitude in text. A vast majority of work in sentiment analysis has focused on developing classifiers for valence prediction (Kiritchenko et al., 2014; Dong et al., 2014; Socher et al., 2013; Mohammad et al., 2013), i.e., determining whether a piece of text expresses positive, negative, or neutral attitude. However, there is a growing interest in detecting a wider range of emotions such as joy, sadness, optimism, etc. (Holzman and Pottenger, 2003; Alm et al., 2005; Brooks et al., 2013; Mohammad, 2012). Much of the this work has been influenced by the idea that some emotions are more basic than others (Ekman, 1992; Ekman and Friesen, 2003; Plutchik, 1980; Plutchik, 1991). Mohammad (2012) polled the Twitter API for tweets that have hashtag words such as #anger and #sadness corresponding to the eight Plutchik basic emo4 Experimental Setup Instance 1 Target verb: erase Sentence: The Turks erased the Armenians. Here, erase is used metaphorically. We will refer to such instances as metaphorical instances. Now consider an instance similar to the one above, but where the target verb is replaced by"
S16-2003,D11-1063,1,0.2517,"sambiguation (WSD) is to develop a model for each polysemous word (Navigli, 2009). The model for a word predicts the intended sense, based on context. A problem with this approach to WSD is that good coverage of common polysemous English words would require about 3,200 distinct models. Kilgarriff (1997) has argued there are systematic relations among word senses across different words, focusing in particular on metaphor as a ubiquitous source of polysemy. This area of research is known as regular polysemy. Thus, there is a systematic relation between metaphor and word sense (Kilgarriff, 1997; Turney et al., 2011) and the emotion associated with a word depends on the sense of the word (Strapparava and Valitutti, 2004; Mohammad and Turney, 2013).3 This raises the question of whether there is a systematic relation between presence of metaphor and the emotional content of words. As far as we know, this is the first paper to quantitatively explore this question. Gibbs et al. (2002) conducted a study that looked at how listeners respond to metaphor and irony when they are played audio tapes describing emotional experiences. They found that on average metaphors were rated as being more emotional than non-met"
S16-2003,P12-3002,0,0.0197562,"” in (1a) we express a distinct viewpoint on governmental regulation of business, as opposed to a more neutral factual statement expressed in (1b). The interplay of metaphor and emotion has been an object of interest in fields such as linguistics (Blanchette et al., 2001; Kovecses, 2003), political science (Lakoff and Wehling, 2012), cognitive psychology (Crawford, 2009; Thibodeau and Boroditsky, 2011) and neuroscience (Aziz-Zadeh and Damasio, 2008; Jabbi et al., 2008). A number of computational approaches for sentiment polarity classification of metaphorical language have also been proposed (Veale and Li, 2012; Kozareva, 2013; Strzalkowski et al., 2014). However, there is no quantitative study establishing the extent to which metaphorical language is used to express emotion nor a data-supported account of the mechanisms by which this happens. Our study addresses two questions: (i) whether a metaphorical statement is likely to convey a stronger emotional content than its literal counterpart; and (ii) how this emotional content arises in the metaphor, i.e. whether it comes from the source domain, or from the target domain, or rather arises compositionally through interaction of the source and the tar"
S17-1018,P14-2135,0,0.0807651,"direct object relations in the BNC. In case of the indirect object relations, the accompanying prepostions were discarded and the noun counts were aggregated. 5 Discussion and Data Analysis Our results show that the vision-based model outperforms the language-only model on our dataset. The difference in performance is particularly pronounced for the concrete verbs. For the abstract verbs in isolation, however, LING attains a higher 151 precision and recall. This is not surprising, as the visual information is better suited to capture the properties of concrete concepts than the abstract ones (Kiela et al., 2014). However, our results indicate that integrating linguistic and visual information provides a better overall model than the linguistic information alone. Our qualitative analysis of the data revealed a number of interesting trends. Some of the errors of both systems can be traced back to the clustering step. Different argument roles according to FrameNet are sometimes found in one cluster. For instance, both the killer and the victim are in the same cluster, as shown in Figure 2. However, it is also the case that one FrameNet role can be split into several clusters, e.g. the Victim role in the"
S17-1018,P15-2020,0,0.087498,"Missing"
S17-1018,D15-1015,0,0.0390626,"Missing"
S17-1018,P06-4020,0,0.00909538,"implemented in a lexicalsemantic resource called FrameNet (Fillmore et al., 2003). Each semantic frame is encoded in FrameNet as a list of lexical units that evoke this frame (typically verbs) and the roles that their semantic arguments may take given the scenario represented by the frame. FrameNet has inspired a direction in NLP research known as semantic role labelling (Gildea and Jurafsky, 2002; M`arquez et al., 2 Experimental Data Textual data. We extracted linguistic features for our model from the British National Corpus (BNC) (Burnard, 2007). We parsed the corpus using the RASP parser (Briscoe et al., 2006) and 149 Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017), pages 149–154, c Vancouver, Canada, August 3-4, 2017. 2017 Association for Computational Linguistics graph as P = D−1 S, where theP degree matrix D is a diagonal matrix with Dii = N j=1 Sij . It then computes the K leading eigenvectors of P , where K is the desired number of clusters. The graph is partitioned by finding approximately equal elements in the eigenvectors using a simpler clustering algorithm, such as k-means. Meila and Shi (2001) have shown that the partition I derived in this way"
S17-1018,P12-1015,0,0.0367722,"tensor factorization model to identify argument fillers based on the role predictions and the predicate. To the best of our knowledge, ours is the first approach to this task exploiting visual data, in the form of image and video descriptions. 6 7 6.1 6.2 Multi-modal Methods in Semantics Visual data has been previously used to learn meaning representations that project multiple modalities into the same vector space. Semantic models integrating linguistic and visual information have been shown successful in tasks such as modeling semantic similarity and relatedness (Silberer and Lapata, 2014; Bruni et al., 2012), lexical entailment (Kiela et al., 2015a), compositionality (Roller and Schulte im Walde, 2013), bilingual lexicon induction (Kiela et al., 2015b) and metaphor identification (Shutova et al., 2016). Other applications of multimodal data include language modeling (Kiros et al., 2014) and knowledge mining from images (Chen et al., 2013; Divvala et al., 2014). Young et al. (2014) show that large collections of image captions can be exploited for entailment tasks. Shutova et al. (2015) used image and video descriptions to induce verb selectional preferences enhanced with visual information. Relat"
S17-1018,N10-1137,0,0.0605021,"Missing"
S17-1018,J14-3006,0,0.0377643,"Missing"
S17-1018,J08-2001,0,0.0688829,"Missing"
S17-1018,D13-1115,0,0.244547,"Missing"
S17-1018,P12-2029,0,0.0431008,"Missing"
S17-1018,J02-3001,0,0.30793,"which can be mapped to higher-level semantic roles such as agent, patient, instrument etc. The verbs linked to this frame are buy, sell, pay, cost and charge, each evoking different aspects of the frame. This theory has been implemented in a lexicalsemantic resource called FrameNet (Fillmore et al., 2003). Each semantic frame is encoded in FrameNet as a list of lexical units that evoke this frame (typically verbs) and the roles that their semantic arguments may take given the scenario represented by the frame. FrameNet has inspired a direction in NLP research known as semantic role labelling (Gildea and Jurafsky, 2002; M`arquez et al., 2 Experimental Data Textual data. We extracted linguistic features for our model from the British National Corpus (BNC) (Burnard, 2007). We parsed the corpus using the RASP parser (Briscoe et al., 2006) and 149 Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017), pages 149–154, c Vancouver, Canada, August 3-4, 2017. 2017 Association for Computational Linguistics graph as P = D−1 S, where theP degree matrix D is a diagonal matrix with Dii = N j=1 Sij . It then computes the K leading eigenvectors of P , where K is the desired number of cl"
S17-1018,N16-1020,1,0.86271,"ta, in the form of image and video descriptions. 6 7 6.1 6.2 Multi-modal Methods in Semantics Visual data has been previously used to learn meaning representations that project multiple modalities into the same vector space. Semantic models integrating linguistic and visual information have been shown successful in tasks such as modeling semantic similarity and relatedness (Silberer and Lapata, 2014; Bruni et al., 2012), lexical entailment (Kiela et al., 2015a), compositionality (Roller and Schulte im Walde, 2013), bilingual lexicon induction (Kiela et al., 2015b) and metaphor identification (Shutova et al., 2016). Other applications of multimodal data include language modeling (Kiros et al., 2014) and knowledge mining from images (Chen et al., 2013; Divvala et al., 2014). Young et al. (2014) show that large collections of image captions can be exploited for entailment tasks. Shutova et al. (2015) used image and video descriptions to induce verb selectional preferences enhanced with visual information. Related Work Semantic Role Induction Conclusion We have presented a method for semantic frame induction from text, images and videos and shown that it operates with a high precision and recall. Although"
S17-1018,W06-1601,0,0.107857,"Missing"
S17-1018,P15-1092,1,0.896099,"Missing"
S17-1018,P14-1068,0,0.0591984,"eatures and a probabilistic tensor factorization model to identify argument fillers based on the role predictions and the predicate. To the best of our knowledge, ours is the first approach to this task exploiting visual data, in the form of image and video descriptions. 6 7 6.1 6.2 Multi-modal Methods in Semantics Visual data has been previously used to learn meaning representations that project multiple modalities into the same vector space. Semantic models integrating linguistic and visual information have been shown successful in tasks such as modeling semantic similarity and relatedness (Silberer and Lapata, 2014; Bruni et al., 2012), lexical entailment (Kiela et al., 2015a), compositionality (Roller and Schulte im Walde, 2013), bilingual lexicon induction (Kiela et al., 2015b) and metaphor identification (Shutova et al., 2016). Other applications of multimodal data include language modeling (Kiros et al., 2014) and knowledge mining from images (Chen et al., 2013; Divvala et al., 2014). Young et al. (2014) show that large collections of image captions can be exploited for entailment tasks. Shutova et al. (2015) used image and video descriptions to induce verb selectional preferences enhanced with visu"
S17-1018,D09-1067,0,0.0346383,"eneralise the predicateargument structure in semantic frames. Example clusters produced by our method are shown in Fig. 1. The resulting clusters represent frame elements, i.e. argument roles, in our model. Frame Induction Model Argument Clustering We use a clustering method to obtain semantic classes of arguments of verbs, thus generalising from individual arguments to their semantic types which correspond to frame roles. We obtain argument classes by means of spectral clustering of nouns with lexico-syntactic features, which has been shown effective in previous lexical classification tasks (Sun and Korhonen, 2009). Spectral clustering partitions the data relying on a similarity matrix that records similarities between all pairs of data points. We use JensenShannon divergence to measure similarity between feature vectors for two nouns, wi and wj , defined as follows: 1 1 dJS (wi , wj ) = dKL (wi ||m) + dKL (wj ||m), 2 2 (1) where dKL is the Kullback-Leibler divergence, and m is the average of wi and wj . We construct the similarity matrix S computing similarities Sij as Sij = exp(−dJS (wi , wj )). The matrix S then encodes a similarity graph G (over our nouns), where Sij are the adjacency weights. The c"
S17-1018,D11-1095,0,0.0232301,"ion that minimizes the cluster distortion, i.e. distances to its centroid. We clustered the 2,000 most frequent nouns in the BNC, using their grammatical relations as features. The features consisted of verb lemmas appearing in the subject, direct object and indirect object relations with the given nouns in the RASPparsed BNC, indexed by relation type. The feature vectors were first constructed from the corpus counts, and subsequently normalized by the sum of the feature values. Our use of linguistic dependency features for argument clustering is motivated by the results of previous research (Sun and Korhonen, 2011; Shutova et al., 2015), that has shown that such features lead to clusters of nouns belonging to the same semantic type, as opposed to topic or scene as it is the case with linguistic windowbased features or image-derived features (Shutova et al., 2015). Since the argument roles in semantic frames correspond to semantic types (such as location or instrument), the linguistic dependency features are best suited to generalise the predicateargument structure in semantic frames. Example clusters produced by our method are shown in Fig. 1. The resulting clusters represent frame elements, i.e. argum"
S17-1018,N15-1001,0,0.014369,"ked lower or not appearing at all. In contrast, the output of VIS encompases a range of situational roles, such as Instrument, Location, Time etc. The two models also sometimes differ in the roles that they identify. For instance, for the verb risk the VIS output is dominated by arguments of type Asset and the LING output by the arguments related to the Bad outcome role in FrameNet. Bayesian clustering based on Chinese Restaurant Process (Titov and Klementiev, 2012) and integer linear programming to incorporate semantic and structural constraints during clustering (Woodsend and Lapata, 2015). Titov and Khoddam (2015) proposed a reconstruction-error minimization approach using a log-linear model to predict roles given syntactic and lexical features and a probabilistic tensor factorization model to identify argument fillers based on the role predictions and the predicate. To the best of our knowledge, ours is the first approach to this task exploiting visual data, in the form of image and video descriptions. 6 7 6.1 6.2 Multi-modal Methods in Semantics Visual data has been previously used to learn meaning representations that project multiple modalities into the same vector space. Semantic models integratin"
S17-1018,E12-1003,0,0.0245883,"orical transfer. A common trend in the LING output is that it is dominated by the Agent and Theme roles, with situational roles (e.g. Location) typically ranked lower or not appearing at all. In contrast, the output of VIS encompases a range of situational roles, such as Instrument, Location, Time etc. The two models also sometimes differ in the roles that they identify. For instance, for the verb risk the VIS output is dominated by arguments of type Asset and the LING output by the arguments related to the Bad outcome role in FrameNet. Bayesian clustering based on Chinese Restaurant Process (Titov and Klementiev, 2012) and integer linear programming to incorporate semantic and structural constraints during clustering (Woodsend and Lapata, 2015). Titov and Khoddam (2015) proposed a reconstruction-error minimization approach using a log-linear model to predict roles given syntactic and lexical features and a probabilistic tensor factorization model to identify argument fillers based on the role predictions and the predicate. To the best of our knowledge, ours is the first approach to this task exploiting visual data, in the form of image and video descriptions. 6 7 6.1 6.2 Multi-modal Methods in Semantics Vis"
S17-1018,D15-1295,0,0.0124214,"e.g. Location) typically ranked lower or not appearing at all. In contrast, the output of VIS encompases a range of situational roles, such as Instrument, Location, Time etc. The two models also sometimes differ in the roles that they identify. For instance, for the verb risk the VIS output is dominated by arguments of type Asset and the LING output by the arguments related to the Bad outcome role in FrameNet. Bayesian clustering based on Chinese Restaurant Process (Titov and Klementiev, 2012) and integer linear programming to incorporate semantic and structural constraints during clustering (Woodsend and Lapata, 2015). Titov and Khoddam (2015) proposed a reconstruction-error minimization approach using a log-linear model to predict roles given syntactic and lexical features and a probabilistic tensor factorization model to identify argument fillers based on the role predictions and the predicate. To the best of our knowledge, ours is the first approach to this task exploiting visual data, in the form of image and video descriptions. 6 7 6.1 6.2 Multi-modal Methods in Semantics Visual data has been previously used to learn meaning representations that project multiple modalities into the same vector space."
S17-1018,J14-1002,0,\N,Missing
S17-1018,Q14-1006,0,\N,Missing
S19-1013,D13-1202,0,0.0463116,"Missing"
S19-1013,P16-4010,0,0.0159689,"th black pixels, leaving only the visual context (black pixels are used as a simple way to represent no information). All images are re-scaled to 256x256 and the original aspect ratios are maintained, padding any remaining area with black pixels. We use a Caffe (Jia et al., 2014) implementation of a pre-trained AlexNet model (Krizhevsky et al., 2012) to extract a visual representation for each of the images. We first take an image as input to the network, perform a forward pass, and extract the pre-softmax layer in the network (FC7) as a representation of the image. We use the MMfeat toolkit (Kiela, 2016) to load the AlexNet model and extract visual representations for the INTER NAL , EXTERNAL , WHOLE images corresponding Learning linguistic representations We use the skip-gram model with negative sampling (Mikolov et al., 2013) to learn 100dimensional word embeddings from a lemmatized 2015 copy of Wikipedia (Rimell et al., 2016). 4.2 Learning visual representations Object detection and segmentation We use the FRCNN unified object detection model (Ren et al., 2015) to automatically detect objects and their bounding boxes in images associated with our nouns. FRCNN combines a region proposal net"
S19-1013,Q17-1002,0,0.0263286,"Missing"
S19-1013,D14-1005,0,0.142612,"visual word representations, without differentiating between these two kinds of visual information. In contrast, we investigate whether differentiating between internal visual properties and external visual context is beneficial compared to learning visual representations 2 Related Work Multimodal Semantics Multimodal models are inspired by cognitive science research, suggesting that human semantic knowledge relies on perceptual and sensori-motor experience (Louwerse, 2011). Contemporary approaches use deep CNNs trained on image classification tasks to extract visual representations of words. Kiela and Bottou (2014) extract visual word representations from feature extraction layers in CNNs and con118 Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM), pages 118–124 c Minneapolis, June 6–7, 2019. 2019 Association for Computational Linguistics (a) VIS - WHOLE (b) VIS - INTERNAL (c) VIS - EXTERNAL Figure 1: An example of images processed to extract the internal and external visual features using the bounding box around the concept. Figure 2: Semantic model similarity encoding. Where the coloured columns represent semantic vectors from the same model (i.e. VIS - INTERNAL"
S19-1013,P15-2020,0,0.0223078,"hat differentiate between internal visual properties of the objects and their external visual context. We evaluate the models on the task of decoding brain activity associated with the meanings of nouns, demonstrating their advantage over those based on complete images. 1 Introduction Multimodal models combining linguistic and visual information have enjoyed a growing interest in the field of semantics. Recent research has shown that such models outperform purely linguistic models on a range of NLP tasks, including modelling semantic similarity (Silberer and Lapata, 2014), lexical entailment (Kiela et al., 2015), and metaphor identification (Shutova et al., 2016). Despite this success, little is known about the nature of semantic information learned from images and why it is useful. For instance, some concepts may be better characterised by their own (internal) visual properties and others by the (external) visual context, in which they appear. However, existing neural multimodal semantic approaches use entire images to learn visual word representations, without differentiating between these two kinds of visual information. In contrast, we investigate whether differentiating between internal visual p"
S19-1013,D17-1113,1,0.780848,"ested a wider range of distributional models in this task. Recent research shows that multimodal models grounded in the visual modality strongly correlate with neural activation patterns associated with word meaning. Anderson et al. (2013) construct semantic models using visual data and show a high correlation to brain activation patterns from fMRI. While Anderson et al. (2015) find that linguisticonly semantic models better predict brain activity associated with linguistic processing, and imagebased semantic models better predict similarity within the visual processing portions of the brain. Bulat et al. (2017) compare and evaluate a range of distributional semantic models in their ability to predict brain activity associated with concepts. Two key differences between our work and both Anderson et al. (2013) and Anderson et al. (2015) are 1) we make use of neural-network-based visual features as opposed to SIFT features (Lowe, 3 Data Visual Data In the first experiment, we used the Visual Genome (Krishna et al., 2016) dataset of images manually-annotated for objects and their bounding boxes. In the second experiment, we trained Faster-RCNN networks on manually annotated images from ImageNet (Deng et"
S19-1013,W10-0609,0,0.0384541,"n the task of decoding brain activity associated with the meanings of nouns. Decoding Brain Activity Research in neuroscience supports the view that concepts are represented as patterns of neural activation and, similarly to distributed semantic representations, are naturally encoded in neural semantic vector space (Haxby et al., 2001; Huth et al., 2012; Anderson et al., 2013). Mitchell et al. (2008) were the first to employ distributional semantic models to predict neural activation in the human brain using data obtained via functional Magentic Resonance Imaging (fMRI). Murphy et al. (2012); Devereux et al. (2010); Pereira et al. (2013) have since successfully tested a wider range of distributional models in this task. Recent research shows that multimodal models grounded in the visual modality strongly correlate with neural activation patterns associated with word meaning. Anderson et al. (2013) construct semantic models using visual data and show a high correlation to brain activation patterns from fMRI. While Anderson et al. (2015) find that linguisticonly semantic models better predict brain activity associated with linguistic processing, and imagebased semantic models better predict similarity wit"
S19-1013,S12-1019,0,0.0279017,"valuating our models on the task of decoding brain activity associated with the meanings of nouns. Decoding Brain Activity Research in neuroscience supports the view that concepts are represented as patterns of neural activation and, similarly to distributed semantic representations, are naturally encoded in neural semantic vector space (Haxby et al., 2001; Huth et al., 2012; Anderson et al., 2013). Mitchell et al. (2008) were the first to employ distributional semantic models to predict neural activation in the human brain using data obtained via functional Magentic Resonance Imaging (fMRI). Murphy et al. (2012); Devereux et al. (2010); Pereira et al. (2013) have since successfully tested a wider range of distributional models in this task. Recent research shows that multimodal models grounded in the visual modality strongly correlate with neural activation patterns associated with word meaning. Anderson et al. (2013) construct semantic models using visual data and show a high correlation to brain activation patterns from fMRI. While Anderson et al. (2015) find that linguisticonly semantic models better predict brain activity associated with linguistic processing, and imagebased semantic models bette"
S19-1013,J16-4004,0,0.0231165,"del (Krizhevsky et al., 2012) to extract a visual representation for each of the images. We first take an image as input to the network, perform a forward pass, and extract the pre-softmax layer in the network (FC7) as a representation of the image. We use the MMfeat toolkit (Kiela, 2016) to load the AlexNet model and extract visual representations for the INTER NAL , EXTERNAL , WHOLE images corresponding Learning linguistic representations We use the skip-gram model with negative sampling (Mikolov et al., 2013) to learn 100dimensional word embeddings from a lemmatized 2015 copy of Wikipedia (Rimell et al., 2016). 4.2 Learning visual representations Object detection and segmentation We use the FRCNN unified object detection model (Ren et al., 2015) to automatically detect objects and their bounding boxes in images associated with our nouns. FRCNN combines a region proposal network (RPN) with Fast R-CNN, an object detection network, and minimizes computational cost during training and testing by sharing convolutional layers between the networks. To maximize accuracy, we train an FRCNN network for each semantic class in the M ITCHELL dataset, starting from a VGG16 network (Simonyan and Zisserman, 2014)"
S19-1013,N16-1020,1,0.848245,"es of the objects and their external visual context. We evaluate the models on the task of decoding brain activity associated with the meanings of nouns, demonstrating their advantage over those based on complete images. 1 Introduction Multimodal models combining linguistic and visual information have enjoyed a growing interest in the field of semantics. Recent research has shown that such models outperform purely linguistic models on a range of NLP tasks, including modelling semantic similarity (Silberer and Lapata, 2014), lexical entailment (Kiela et al., 2015), and metaphor identification (Shutova et al., 2016). Despite this success, little is known about the nature of semantic information learned from images and why it is useful. For instance, some concepts may be better characterised by their own (internal) visual properties and others by the (external) visual context, in which they appear. However, existing neural multimodal semantic approaches use entire images to learn visual word representations, without differentiating between these two kinds of visual information. In contrast, we investigate whether differentiating between internal visual properties and external visual context is beneficial"
S19-1013,P14-1068,0,0.158528,"e. In contrast, we construct multimodal models that differentiate between internal visual properties of the objects and their external visual context. We evaluate the models on the task of decoding brain activity associated with the meanings of nouns, demonstrating their advantage over those based on complete images. 1 Introduction Multimodal models combining linguistic and visual information have enjoyed a growing interest in the field of semantics. Recent research has shown that such models outperform purely linguistic models on a range of NLP tasks, including modelling semantic similarity (Silberer and Lapata, 2014), lexical entailment (Kiela et al., 2015), and metaphor identification (Shutova et al., 2016). Despite this success, little is known about the nature of semantic information learned from images and why it is useful. For instance, some concepts may be better characterised by their own (internal) visual properties and others by the (external) visual context, in which they appear. However, existing neural multimodal semantic approaches use entire images to learn visual word representations, without differentiating between these two kinds of visual information. In contrast, we investigate whether"
S19-1013,Q14-1017,0,0.0481827,"ty encoding. Where the coloured columns represent semantic vectors from the same model (i.e. VIS - INTERNAL). The bottom row represents the similarity codes for the concept “Leg”, calculated by computing the Pearson correlation between “Leg” and the other semantic vectors from the dataset. catenate them with linguistic representations obtained from a skip-gram model. Their results presented empirical improvements over the previous bag-of-visual-words method (Bruni et al., 2012). Other approaches use restricted Boltzmann machines (Srivastava and Salakhutdinov, 2012), recursive neural networks (Socher et al., 2014) and autoencoders (Silberer and Lapata, 2014). 2004), and 2) we perform a word-level decoding analysis as opposed to representational similarity analysis (Kriegeskorte et al., 2008). We aim to further our understanding of the role of vision in semantic processing by evaluating our models on the task of decoding brain activity associated with the meanings of nouns. Decoding Brain Activity Research in neuroscience supports the view that concepts are represented as patterns of neural activation and, similarly to distributed semantic representations, are naturally encoded in neural semantic vector"
S19-2100,W18-5109,1,0.709828,"Related Work There has been much work characterising offensive online discourse including hate speech and cyberbullying (Warner and Hirschberg, 2012; Kwok and Wang, 2013; Xu et al., 2013; Waseem et al., 2017; Ribeiro et al., 2018). This work also includes creating datasets for training and evaluating detection models, for example the Hate Speech Twitter Annotations and Wikipedia Comments Corpora (Waseem and Hovy, 2016; Davidson et al., 2017; Wulczyn et al., 2017). Most work has been conducted on English data – tweets in particular – with some extensions to other domains (e.g. hacking forums (Caines et al., 2018)) 556 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 556–563 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics A OFF OFF OFF OFF NOT All and other languages (e.g. Arabic (Mubarak et al., 2017), Chinese (Su et al., 2017), Slovene (Fiˇser et al., 2017)). Automated detection approaches have drawn on traditional document classification methods for spam detection and sentiment analysis, and tend to use lexical and syntactic features (Nobata et al., 2016; Li et al., 2017; Bourgonje et al., 2018). Machine learning"
S19-2100,D14-1179,0,0.0468349,"Missing"
S19-2100,L18-1008,0,0.0298282,"to the GBDT classifier. We provide details of each extension in the following sections. For each subtask, we experiment with combinations of the above and additionally tune the RNN type (between LSTM (Hochreiter and Schmidhuber, 1997) and GRU (Cho et al., 2014)), dimension, and batch size, whether to use character ngrams (n ∈ [1, 4]), and, when used, the size of self-attention layers. We also run experiments using the unmodified model to find which pretrained embeddings give the best performance. We compare publicly available embeddings trained using Word2Vec (Mikolov et al., 2013), FastText (Mikolov et al., 2018), and GLoVe (Pennington et al., 2014). 4.1 and a further 1-dimensional dense layer. The final dense layer has either sigmoid or exponential activation, corresponding to soft or sharp attention respectively. The weights are normalised to sum to 1, yielding final attention values aei , which are used P to obtain the final sentential representation s = i aei hi . The RNN is then trained using categorical cross-entropy on s passed through a final tanh layer. 4.3 This modification includes the post-softmax output of the RNN as an additional input feature to the decision tree. 4.4 ELMo Self-attentio"
S19-2100,W17-3007,0,0.0223019,"Missing"
S19-2100,C18-1093,1,0.299803,"nstitute for Logic, Language and Computation, University of Amsterdam, Netherlands e.shutova@uva.nl Abstract one, but one with real world impact: if measures can be taken to identify and curtail trolling, the toxicity of the internet can to some extent be reduced. There is evidence that online harassment is connected with oppression, violence and suicide (Dinakar et al., 2011; Sood et al., 2012; Wulczyn et al., 2017), and there may moreover be reasons for concern about the perpetrator’s wellbeing along with that of the victims (Cheng et al., 2017). Our approach to the task extends the work of Mishra et al. (2018b), who extract features from tweets using an RNN for subsequent use in a gradient-boosted decision tree (GBDT) (Ke et al., 2017). Firstly, we experiment with changes to the RNN, including the use of self-attention (Rei and Søgaard, 2019) and ELMo embeddings (Peters et al., 2018). Secondly, we add additional features to the GBDT, including globally-optimised hashtag embeddings learned from a graph of tweet contents using node2vec (Grover and Leskovec, 2016). We show that this method of learning distributional information about hashtags improves performance over just learning their embeddings w"
S19-2100,W17-3013,0,0.0443658,"Missing"
S19-2100,W18-5101,1,0.388541,"nstitute for Logic, Language and Computation, University of Amsterdam, Netherlands e.shutova@uva.nl Abstract one, but one with real world impact: if measures can be taken to identify and curtail trolling, the toxicity of the internet can to some extent be reduced. There is evidence that online harassment is connected with oppression, violence and suicide (Dinakar et al., 2011; Sood et al., 2012; Wulczyn et al., 2017), and there may moreover be reasons for concern about the perpetrator’s wellbeing along with that of the victims (Cheng et al., 2017). Our approach to the task extends the work of Mishra et al. (2018b), who extract features from tweets using an RNN for subsequent use in a gradient-boosted decision tree (GBDT) (Ke et al., 2017). Firstly, we experiment with changes to the RNN, including the use of self-attention (Rei and Søgaard, 2019) and ELMo embeddings (Peters et al., 2018). Secondly, we add additional features to the GBDT, including globally-optimised hashtag embeddings learned from a graph of tweet contents using node2vec (Grover and Leskovec, 2016). We show that this method of learning distributional information about hashtags improves performance over just learning their embeddings w"
S19-2100,W17-3008,0,0.0259519,"training and evaluating detection models, for example the Hate Speech Twitter Annotations and Wikipedia Comments Corpora (Waseem and Hovy, 2016; Davidson et al., 2017; Wulczyn et al., 2017). Most work has been conducted on English data – tweets in particular – with some extensions to other domains (e.g. hacking forums (Caines et al., 2018)) 556 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 556–563 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics A OFF OFF OFF OFF NOT All and other languages (e.g. Arabic (Mubarak et al., 2017), Chinese (Su et al., 2017), Slovene (Fiˇser et al., 2017)). Automated detection approaches have drawn on traditional document classification methods for spam detection and sentiment analysis, and tend to use lexical and syntactic features (Nobata et al., 2016; Li et al., 2017; Bourgonje et al., 2018). Machine learning techniques range from logistic regression (Cheng et al., 2015) to support vector machines (Yin et al., 2009) to neural networks (Gamb¨ack and Sikdar, 2017). We draw on the work by Mishra and colleagues, who used a character-based recurrent neural network to form contextual word"
S19-2100,N13-1082,0,0.0285617,"nline texts, including those posted in discussion forums, news article comment sections, and social networks. Such detection is not straightforwardly a matter of identifying texts containing obscene words (Malmasi and Zampieri, 2018); offensiveness often arises from the context, current affairs, world knowledge, the use of acronyms and slang, and the identity of the authors and audience. Therefore the task is a challenging 2 Related Work There has been much work characterising offensive online discourse including hate speech and cyberbullying (Warner and Hirschberg, 2012; Kwok and Wang, 2013; Xu et al., 2013; Waseem et al., 2017; Ribeiro et al., 2018). This work also includes creating datasets for training and evaluating detection models, for example the Hate Speech Twitter Annotations and Wikipedia Comments Corpora (Waseem and Hovy, 2016; Davidson et al., 2017; Wulczyn et al., 2017). Most work has been conducted on English data – tweets in particular – with some extensions to other domains (e.g. hacking forums (Caines et al., 2018)) 556 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 556–563 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Associatio"
S19-2100,D14-1162,0,0.0840716,"details of each extension in the following sections. For each subtask, we experiment with combinations of the above and additionally tune the RNN type (between LSTM (Hochreiter and Schmidhuber, 1997) and GRU (Cho et al., 2014)), dimension, and batch size, whether to use character ngrams (n ∈ [1, 4]), and, when used, the size of self-attention layers. We also run experiments using the unmodified model to find which pretrained embeddings give the best performance. We compare publicly available embeddings trained using Word2Vec (Mikolov et al., 2013), FastText (Mikolov et al., 2018), and GLoVe (Pennington et al., 2014). 4.1 and a further 1-dimensional dense layer. The final dense layer has either sigmoid or exponential activation, corresponding to soft or sharp attention respectively. The weights are normalised to sum to 1, yielding final attention values aei , which are used P to obtain the final sentential representation s = i aei hi . The RNN is then trained using categorical cross-entropy on s passed through a final tanh layer. 4.3 This modification includes the post-softmax output of the RNN as an additional input feature to the decision tree. 4.4 ELMo Self-attention The model proposed by Mishra et al."
S19-2100,N18-1202,0,0.144031,"Missing"
S19-2100,N19-1144,0,0.0368619,"gs in instances where words were deliberately obscured to evade detection. Following common practice in named entity recognition (Sang and De Meulder, 2003), where fine-grained labels are used to improve performance on the sequence labeling task, we take advantage of the hierarchical labels available for each tweet. For subtasks A and B we train a model to predict all cascading labels, and sum the probabilities of labels under the relevant class to make a final prediction. For example, for subtask A the Data The OffensEval shared task uses the Offensive Language Identification Dataset (OLID) (Zampieri et al., 2019a), which hierarchically labels tweets according to whether or not they are offensive, whether any offence is targeted, and if so targeted at whom: an individual, a group or otherwise. The three subtasks in this shared task correspond to predicting labels at each level of granularity. The data is structured to allow this: all tweets presented in subtask B are guaranteed to be offensive, and all of those in subtask C are targeted. Tweets were collected by using the Twitter API to search for terms that are frequently associated with offensive behaviour. These included political keywords, as poli"
S19-2100,S19-2010,0,0.0283946,"gs in instances where words were deliberately obscured to evade detection. Following common practice in named entity recognition (Sang and De Meulder, 2003), where fine-grained labels are used to improve performance on the sequence labeling task, we take advantage of the hierarchical labels available for each tweet. For subtasks A and B we train a model to predict all cascading labels, and sum the probabilities of labels under the relevant class to make a final prediction. For example, for subtask A the Data The OffensEval shared task uses the Offensive Language Identification Dataset (OLID) (Zampieri et al., 2019a), which hierarchically labels tweets according to whether or not they are offensive, whether any offence is targeted, and if so targeted at whom: an individual, a group or otherwise. The three subtasks in this shared task correspond to predicting labels at each level of granularity. The data is structured to allow this: all tweets presented in subtask B are guaranteed to be offensive, and all of those in subtask C are targeted. Tweets were collected by using the Twitter API to search for terms that are frequently associated with offensive behaviour. These included political keywords, as poli"
S19-2100,W03-0419,0,0.229996,"Missing"
S19-2100,W17-3003,0,0.0202596,"n models, for example the Hate Speech Twitter Annotations and Wikipedia Comments Corpora (Waseem and Hovy, 2016; Davidson et al., 2017; Wulczyn et al., 2017). Most work has been conducted on English data – tweets in particular – with some extensions to other domains (e.g. hacking forums (Caines et al., 2018)) 556 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 556–563 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics A OFF OFF OFF OFF NOT All and other languages (e.g. Arabic (Mubarak et al., 2017), Chinese (Su et al., 2017), Slovene (Fiˇser et al., 2017)). Automated detection approaches have drawn on traditional document classification methods for spam detection and sentiment analysis, and tend to use lexical and syntactic features (Nobata et al., 2016; Li et al., 2017; Bourgonje et al., 2018). Machine learning techniques range from logistic regression (Cheng et al., 2015) to support vector machines (Yin et al., 2009) to neural networks (Gamb¨ack and Sikdar, 2017). We draw on the work by Mishra and colleagues, who used a character-based recurrent neural network to form contextual word representations of out-of-v"
S19-2100,W12-2103,0,0.0540799,"tic detection of offensive opinions expressed in online texts, including those posted in discussion forums, news article comment sections, and social networks. Such detection is not straightforwardly a matter of identifying texts containing obscene words (Malmasi and Zampieri, 2018); offensiveness often arises from the context, current affairs, world knowledge, the use of acronyms and slang, and the identity of the authors and audience. Therefore the task is a challenging 2 Related Work There has been much work characterising offensive online discourse including hate speech and cyberbullying (Warner and Hirschberg, 2012; Kwok and Wang, 2013; Xu et al., 2013; Waseem et al., 2017; Ribeiro et al., 2018). This work also includes creating datasets for training and evaluating detection models, for example the Hate Speech Twitter Annotations and Wikipedia Comments Corpora (Waseem and Hovy, 2016; Davidson et al., 2017; Wulczyn et al., 2017). Most work has been conducted on English data – tweets in particular – with some extensions to other domains (e.g. hacking forums (Caines et al., 2018)) 556 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 556–563 Minneapolis, Minnesota,"
S19-2100,W17-3012,0,0.0306069,"uding those posted in discussion forums, news article comment sections, and social networks. Such detection is not straightforwardly a matter of identifying texts containing obscene words (Malmasi and Zampieri, 2018); offensiveness often arises from the context, current affairs, world knowledge, the use of acronyms and slang, and the identity of the authors and audience. Therefore the task is a challenging 2 Related Work There has been much work characterising offensive online discourse including hate speech and cyberbullying (Warner and Hirschberg, 2012; Kwok and Wang, 2013; Xu et al., 2013; Waseem et al., 2017; Ribeiro et al., 2018). This work also includes creating datasets for training and evaluating detection models, for example the Hate Speech Twitter Annotations and Wikipedia Comments Corpora (Waseem and Hovy, 2016; Davidson et al., 2017; Wulczyn et al., 2017). Most work has been conducted on English data – tweets in particular – with some extensions to other domains (e.g. hacking forums (Caines et al., 2018)) 556 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 556–563 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational L"
S19-2100,N16-2013,0,0.0364426,"018); offensiveness often arises from the context, current affairs, world knowledge, the use of acronyms and slang, and the identity of the authors and audience. Therefore the task is a challenging 2 Related Work There has been much work characterising offensive online discourse including hate speech and cyberbullying (Warner and Hirschberg, 2012; Kwok and Wang, 2013; Xu et al., 2013; Waseem et al., 2017; Ribeiro et al., 2018). This work also includes creating datasets for training and evaluating detection models, for example the Hate Speech Twitter Annotations and Wikipedia Comments Corpora (Waseem and Hovy, 2016; Davidson et al., 2017; Wulczyn et al., 2017). Most work has been conducted on English data – tweets in particular – with some extensions to other domains (e.g. hacking forums (Caines et al., 2018)) 556 Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 556–563 Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics A OFF OFF OFF OFF NOT All and other languages (e.g. Arabic (Mubarak et al., 2017), Chinese (Su et al., 2017), Slovene (Fiˇser et al., 2017)). Automated detection approaches have drawn on traditional docu"
shutova-teufel-2010-metaphor,J91-1003,0,\N,Missing
shutova-teufel-2010-metaphor,C88-1081,0,\N,Missing
shutova-teufel-2010-metaphor,T87-1040,0,\N,Missing
W17-5033,P06-4020,0,0.137558,"rner English collected by Cambridge University Press and Cambridge English Language Assessment (Nicholls, 2003). It comprises essays written during examinations in English by language learners with over 80 L1s and representing all 6 CEFR levels (Council of Europe, 2011a). Since the learners are not restricted in the word choice,2 we believe that the range of vocabulary used in the essays is representative of what is in learners’ active lexicon and, therefore, reflects semantic knowledge internalised at this point. We have extracted the word combinations from the full CLC parsed with the RASP (Briscoe et al., 2006). Table 2 summarises learner data: we include the number of types (unique combinations), tokens (overall number of combinations), typetoken ratio (T T R) as well as the number of predicates for each level. Table 2 demonstrates that the overall number of the combinations and predicates as well as T T R constantly increase from A1 through to C2, with the largest increase between levels A2 and B1,3 when the learners transfer from beginners to intermediate and start using the vocabulary beyond basic and simple, and between levels C1 and C2, when learners are expected to master idiomatic expression"
W17-5033,W02-1016,0,0.201087,"Missing"
W17-5033,D09-1067,0,0.0265999,"wer the value of DKL . To support the results, we additionally measure the Pearson correlation coefficient (P CC) between the predicates and content word combinations in the learner and native data. P CC is higher for the more similar distributions. Argument clustering: To address the issue of data sparsity, we estimate selectional preferences (SP) over argument classes as well as individual arguments. We obtain SP classes using spectral clustering of nouns with lexico-syntactic features, which has been shown effective in previous lexical classification tasks (Brew and Schulte im Walde, 2002; Sun and Korhonen, 2009). Spectral clustering partitions the data relying on a matrix that records similarities between all pairs of data points. We use Jensen-Shannon divergence to measure the similarity between feature vectors for nouns wi and wj as follows: X c p(c|v) log p(c|v) , p(c) (3) where R is the grammatical relation for which SPs are computed. SPS measures how strongly the predicate constrains its arguments. Selectional association with a particular argument class is then defined as a relative contribution of that argument class to the overall SPS of the predicate: AssR (v, c) = 1 p(c|v) p(c|v) log SPSR ("
W17-5033,C14-3004,0,0.116308,"of a second language (L2), including appropriate word choice and awareness of selectional preference restrictions, are widely recognised as important aspects of L2 learning by native speakers, language teachers and learners themselves. Previous research demonstrated strong correlation between semantic knowledge and proficiency level (Shei and Pain, 2000; Alderson, 2005), and argued that the use of collocations makes one’s speech more native-like (Kjellmer, 1991; Aston, 1995; Granger and Bestgen, 2014). James (1998) noted that learners often equate L2 mastery with mastery of L2 vocabulary, and Leacock et al. (2014) mention an experiment in which teachers of English ranked word choice errors among the most serious errors in L2 writing. At the same time, it has also been argued that acquisition of semantic knowledge proceeds on a word-by-word basis with each word being acquired as a separate construct (Gyllstad et al., 2015), and acquisition of content word combinations knowledge is slow and uneven, presenting challenges even at high proficiency levels (Bahns and Eldaw, 1993; Laufer and Waldman, 2011; Thewissen, 2013). (1) the pace of semantic knowledge and vocabulary acquisition across levels; (2) the in"
W18-0907,N18-2014,1,0.408162,"her subjects and contexts (Lakoff and Johnson, 2008); it is a fundamental way to structure our understanding of the world even without our conscious realization of its presence as we speak and write. It highlights the unknown using the known, explains the complex using the simple, and helps us to emphasize the relevant aspects of meaning resulting in effective communication. Consider the following examples of metaphor use in Table 1. Metaphor has been studied in the context of political communication, marketing, mental health, teaching, assessment of English proficiency, among others (Beigman Klebanov et al., 2018; Gutierrez et al., 2017; Littlemore et al., 2013; Thibodeau and Boroditsky, 2011; Kaviani and Hamedi, 2011; Kathpalia and Carmel, 2011; Landau et al., 2009; Beigman Klebanov et al., 2008; Zaltman and Zaltman, 2008; Littlemore and Low, 2006; Cameron, 2003; Lakoff, 2010; Billow et al., 1997; Bosman, 1987); see chapter 7 in Veale et al. (2016) for a recent review. Table 1: Metaphorical sentences (M) characterized by metaphors in bold and their literal interpretations (I) In this paper, we report on the first shared task on automatic metaphor detection. By making available an easily accessible co"
W18-0907,P16-2017,1,0.639013,"gly popular topic, which manifests itself in both a variety of approaches and in an increasing variety of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of"
W18-0907,W14-2302,1,0.856765,"in an increasing variety of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network"
W18-0907,P16-1018,1,0.852524,"utomated detection of metaphor has become an increasingly popular topic, which manifests itself in both a variety of approaches and in an increasing variety of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed l"
W18-0907,P04-3031,0,0.145739,"fiers We make available to shared task participants a number of features from prior published work on metaphor detection, including unigram features, features based on WordNet, VerbNet, and those derived from a distributional semantic model, POS-based, concreteness and difference in concreteness, as well as topic models. As baselines, we train two logistic regression classifiers for each track (Verbs and All-POS), with instance weights inversely proportional to class frequencies. Lemmatized unigrams (UL) is a simple yet fairly strong baseline (Baseline 1). This feature is produced using NLTK (Bird and Loper, 2004) to generate the lemma of each word according to its tagged POS. As Baseline 2, we use the best system from Beigman Klebanov et al. (2016). The features are: lemmatized unigrams, generalized WordNet semantic classes, and difference in concreteness ratings between verbs/adjectives and nouns (UL + WordNet + CCDB).5 4.1 nsu ai (Mosolova et al., 2018) used linguistic features based on unigrams, lemmas, POS tags, topical LDAs, concreteness, WordNet, VerbNet and verb clusters and trained a Conditional Random Field (CRF) model with gradient descent using the L-BFGS method to generate predictions. OCO"
W18-0907,W13-0907,0,0.0910459,"f methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling app"
W18-0907,E06-1042,0,0.299486,"per later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection systems, researchers used specially constructed or selected sets, such as adjective noun pairs (Gutierrez et al., 2016; Tsvetkov et al., 2014), WordNet synsets and glosses (Mohammad et al., 2016), annotated lexical items (from a range of word classes) in sentences sampled from cor¨ pora (Ozbal et al., 2016; Jang et al., 2015; Hovy et al., 2013; Birke and Sarkar, 2006), all the way to annotation of all words in running text for metaphoricity (Beigman Klebanov et al., 2018; Steen et al., 2010); Veale et al. (2016) review additional annotated datasets. By far the largest annotated dataset is the VU Amsterdam Metaphor Corpus; it has also been used for evaluating many of the cited supervised learning-based systems. Due to its size, availability, reliability of annotation, 3 Task Description The goal of this shared task is to detect, at the word level, all metaphors in a given text. Specifically, there are two tracks, namely, All Part-Of-Speech (POS) and Verbs."
W18-0907,W15-4650,0,0.0706848,"h, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection systems, researchers used specially constructed or selected sets, such as adjective noun pairs (Gutierrez et al., 2016; Tsvetkov et al., 2014), WordNet synsets and glosses (Mohammad et al., 2016), annotated lexical items (from a range of word classes) in sentences sampled from cor¨ pora (Ozbal et al., 2016; Jang et al., 2015; Hovy et al., 2013; Birke and Sarkar, 2006), all the way to annotation of all words in running text for metaphoricity (Beigman Klebanov et al., 2018; Steen et al., 2010); Veale et al. (2016) review additional annotated datasets. By far the largest annotated dataset is the VU Amsterdam Metaphor Corpus; it has also been used for evaluating many of the cited supervised learning-based systems. Due to its size, availability, reliability of annotation, 3 Task Description The goal of this shared task is to detect, at the word level, all metaphors in a given text. Specifically, there are two tracks,"
W18-0907,W18-0911,0,0.541678,"generate the lemma of each word according to its tagged POS. As Baseline 2, we use the best system from Beigman Klebanov et al. (2016). The features are: lemmatized unigrams, generalized WordNet semantic classes, and difference in concreteness ratings between verbs/adjectives and nouns (UL + WordNet + CCDB).5 4.1 nsu ai (Mosolova et al., 2018) used linguistic features based on unigrams, lemmas, POS tags, topical LDAs, concreteness, WordNet, VerbNet and verb clusters and trained a Conditional Random Field (CRF) model with gradient descent using the L-BFGS method to generate predictions. OCOTA (Bizzoni and Ghanimifard, 2018) experimented with a deep neural network composed of a Bi-LSTM preceded and followed by fully connected layers, as well as a simpler model that has a sequence of fully connected neural networks. The authors also experiment with word embeddings trained on various data, with explicit features based on concreteness, and with preprocessing that addresses variability in sentence length. The authors observe that a model that combines Bi-LSTM with the explicit features and sentence-length manipulation shows the best performance. The authors also show that an ensemble of the two types of neural models"
W18-0907,E17-2084,1,0.829013,"ed task. 2 Related Work Over the last decade, automated detection of metaphor has become an increasingly popular topic, which manifests itself in both a variety of approaches and in an increasing variety of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al."
W18-0907,W17-1903,0,0.571942,"Missing"
W18-0907,W16-1104,0,0.143776,"d im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection systems, researchers used specially constructed or selected sets, such as adjective noun pairs (Gutierrez et al., 2016; Tsvetkov et al., 2014), WordNet synsets and glosses (Mohammad et al., 2016), annotated lexical items (from a range of word classes) in sentences sampled from cor¨ pora (Ozbal et al., 2016; Jang et"
W18-0907,W13-0901,0,0.0396711,"y of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architecture"
W18-0907,W06-3506,0,0.0195224,"aradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection systems, researchers used s"
W18-0907,S16-2003,1,0.487324,"ep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection systems, researchers used specially constructed or selected sets, such as adjective noun pairs (Gutierrez et al., 2016; Tsvetkov et al., 2014), WordNet synsets and glosses (Mohammad et al., 2016), annotated lexical items (from a range of word classes) in sentences sampled from cor¨ pora (Ozbal et al., 2016; Jang et al., 2015; Hovy et al., 2013; Birke and Sarkar, 2006), all the way to annotation of all words in running text for metaphoricity (Beigman Klebanov et al., 2018; Steen et al., 2010); Veale et al. (2016) review additional annotated datasets. By far the largest annotated dataset is the VU Amsterdam Metaphor Corpus; it has also been used for evaluating many of the cited supervised learning-based systems. Due to its size, availability, reliability of annotation, 3 Task Descriptio"
W18-0907,W13-0904,0,0.0694103,"e applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity o"
W18-0907,W18-0915,0,0.0237534,"o logistic regression classifiers for each track (Verbs and All-POS), with instance weights inversely proportional to class frequencies. Lemmatized unigrams (UL) is a simple yet fairly strong baseline (Baseline 1). This feature is produced using NLTK (Bird and Loper, 2004) to generate the lemma of each word according to its tagged POS. As Baseline 2, we use the best system from Beigman Klebanov et al. (2016). The features are: lemmatized unigrams, generalized WordNet semantic classes, and difference in concreteness ratings between verbs/adjectives and nouns (UL + WordNet + CCDB).5 4.1 nsu ai (Mosolova et al., 2018) used linguistic features based on unigrams, lemmas, POS tags, topical LDAs, concreteness, WordNet, VerbNet and verb clusters and trained a Conditional Random Field (CRF) model with gradient descent using the L-BFGS method to generate predictions. OCOTA (Bizzoni and Ghanimifard, 2018) experimented with a deep neural network composed of a Bi-LSTM preceded and followed by fully connected layers, as well as a simpler model that has a sequence of fully connected neural networks. The authors also experiment with word embeddings trained on various data, with explicit features based on concreteness,"
W18-0907,W18-0918,0,0.0701424,"authors also experiment with word embeddings trained on various data, with explicit features based on concreteness, and with preprocessing that addresses variability in sentence length. The authors observe that a model that combines Bi-LSTM with the explicit features and sentence-length manipulation shows the best performance. The authors also show that an ensemble of the two types of neural models works even better, due to a substantial increase in recall over single models. System Descriptions The best-performing system from each participant is described below, in alphabetic order. bot.zen (Stemle and Onysko, 2018) used word embeddings from different standard corpora representing different levels of language mastery, encoding each word in a sentence into multiple vector-based embeddings which are then fed into an LSTM RNN network architecture. Specifically, the backpropagation step was performed using weightings computed based on the logarithmic function of the inverse of the count of the metaphors and non-metaphors. Their implementation is hosted on Github6 under the Apache License Version 2.0. Samsung RD PL (Skurniak et al., 2018) explored the use of several orthogonal resources in a cascading manner"
W18-0907,W18-0914,0,0.198339,"ithub6 under the Apache License Version 2.0. Samsung RD PL (Skurniak et al., 2018) explored the use of several orthogonal resources in a cascading manner to predict metaphoricity. For a given word in a sentence, they extracted three feature sets: concreteness score from the Brysbaert database, intermediate hidden vector representing the word in a neural translation framework, and generated logits of a CRF sequence tagging model trained using word embeddings and contextual information. Trained on the VUA data, the CRF model alone outperforms that of a GRU taking all three features. DeepReader (Swarnkar and Singh, 2018) The authors present a neural network architecture that concatenates hidden states of forward and backward LSTMs, with feature selection and classification. The authors also show that reweighting examples and adding linguistic features (WordNet, POS, concreteness) helps improve performance further. 5 6 THU NGN (Wu et al., 2018) created word embeddings using a pre-trained word2vec model and added features such as embedding clusterings and POS tags before using CNN and Baseline 2 is “all-16” in Beigman Klebanov et al. (2018). https://github.com/bot-zen/naacl flp st 59 two introduce explicit ling"
W18-0907,W15-1404,0,0.705695,"h manifests itself in both a variety of approaches and in an increasing variety of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams"
W18-0907,L16-1600,0,0.0452044,"Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection systems, researchers used specially constructed or selected sets, such as adjective noun pairs (Gutierrez et al., 2016; Tsvetkov et al., 2014), WordNet synsets and glosses (Mohammad et al., 2016), annotated lexical items (from a range of word classes) in sentences sampled from cor¨ pora (Ozbal et al., 2016; Jang et al., 2015; Hovy et al., 2013; Birke and Sarkar, 2006), all the way to annotation of all words in running text for metaphoricity (Beigman Klebanov et al., 2018; Steen et al., 2010); Veale et al. (2016) review additional annotated datasets. By far the largest annotated dataset is the VU Amsterdam Metaphor Corpus; it has also been used for evaluating many of the cited supervised learning-based systems. Due to its size, availability, reliability of annotation, 3 Task Description The goal of this shared task is to detect, at the word level, all metaphors in a given text. Specifically, the"
W18-0907,W18-0908,0,0.0535889,"s can refer to the Testing phase In this phase, instances for evaluation are released.2 Each participating system generated predictions for the test instances, for up to N models.3 Predictions are submitted to CodaLab4 1 https://github.com/EducationalTestingService/metaphor /tree/master/NAACL-FLP-shared-task 2 In principle, participants could have access to the test data by independently obtaining the VUA corpus. The shared task was based on a presumption of fair play by participants. 3 We set N =12. 4 https://competitions.codalab.org/competitions/17805 58 teams’ papers for more details. MAP (Pramanick et al., 2018) used a hybrid architecture of Bi-directional LSTM and Conditional Random Fields (CRF) for metaphor detection, relying on features such as token, lemma and POS, and using word2vec embeddings trained on English Wikipedia. Specifically, the authors considered contextual information within a sentence for generating predictions. Baseline Classifiers We make available to shared task participants a number of features from prior published work on metaphor detection, including unigram features, features based on WordNet, VerbNet, and those derived from a distributional semantic model, POS-based, concr"
W18-0907,P14-1024,0,0.524498,"th a variety of approaches and in an increasing variety of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task ex"
W18-0907,D17-1162,1,0.780118,"based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection systems, researchers used specially constructed or selected sets, such as adjective noun pairs (Gutierrez et al., 2016; Tsvetkov et al., 2014), WordNet synsets and glosses (Mohammad et al., 2016), annotated lexical items (from a range of word classes) in sentences"
W18-0907,W13-0906,0,0.123869,"es based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data"
W18-0907,N16-1020,1,0.838762,"taphor has become an increasingly popular topic, which manifests itself in both a variety of approaches and in an increasing variety of data to which the methods are applied. In terms of methods, approaches based on feature-engineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper late"
W18-0907,D11-1063,0,0.370862,"ineering in a supervised machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating"
W18-0907,J17-1003,1,0.902706,"Missing"
W18-0907,C10-1113,1,0.812699,"sed machine learning paradigm explored features based on concreteness and imageability, semantic classification using WordNet, FrameNet, VerbNet, SUMO ontology, property norms, and distributional semantic models, syntactic dependency patterns, sensorial and vision-based features (Bulat et al., 2017; K¨oper and im Walde, 2017; Gutierrez et al., 2016; Shutova et al., 2016; Beigman Klebanov et al., 2016; Tekiroglu et al., 2015; Tsvetkov et al., 2014; Beigman Klebanov et al., 2014; Dunn, 2013; Neuman et al., 2013; Mohler et al., 2013; Hovy et al., 2013; Tsvetkov et al., 2013; Turney et al., 2011; Shutova et al., 2010; Gedigian et al., 2006); see Shutova et al. (2017) and Veale et al. (2016) for reviews of supervised as well as semi-supervised and unsupervised approaches. Recently, deep learning methods have been explored for token-level metaphor detection (Rei et al., 2017; Gutierrez et al., 2017; Do Dinh and Gurevych, 2016). As discussed later in the paper later, the fact that all but one of the participating teams for the shared task experimented with neural network architectures testifies to the increasing popularity of this modeling approach. In terms of data used for evaluating metaphor detection sys"
W18-5101,Q17-1010,0,0.0498626,"dding for the word ‘c1 . . . ck ’. Bi-directionality of the LSTM allows for the semantics of both the prefix and the suffix (last hidden forward and backward state) of the input word to be captured, which are then combined to form the hidden state for the input word. The model is trained by minimizing the mean squared error (MSE) between the embeddings that it produces and the task-tuned embeddings of words in the training set. This ensures that newly composed embeddings are endowed with characteristics from both the GLoVe space as well as the tasktuning process. While approaches like that of Bojanowski et al. (2017) can also compose embeddings for unseen words, they cannot endow the newly composed embeddings with characteristics from the task-tuning process; this may constitute a significant drawback (Kim, 2014). During the training of our character-based word composition model, to emphasize frequent words, we feed a word as many times as it appears in the training corpus. We note that a 1-layer CNN with global max-pooling in place of the 2-layer LSTM provides comparable performance while requiring significantly less time to train. This is expected since words are not very long sequences, and the filters"
W18-5101,D14-1181,0,0.0479864,"antic information. By not mapping these words to a single random embedding, we mitigate against the errors that may arise due to their conflation (Madhyastha et al., 2015). A special OOV (out of vocabulary) token is also initialized in the same range. All the embeddings are updated during training, allowing for some of the randomly-initialized ones to get 1 We also experimented with 1-layer GRU/LSTM and 1/2layer bi-directional GRUs/LSTMs but the performance only worsened or showed no gains; using sigmoid instead of softmax did not have any noteworthy effects on the results either. task-tuned (Kim, 2014); the ones that do not get tuned lie closely clustered around the OOV token to which unseen words in the test set are mapped. Word-sum (WS). The “LSTM+GLoVe+GBDT” method of Badjatiya et al. (2017) constitutes our second baseline. The authors first employ an LSTM to task-tune GLoVe-initialized word embeddings by propagating error back from an LR layer. They then train a gradient-boosted decision tree (GBDT) classifier to classify texts based on the average of the constituent word embeddings.2 We make two minor modifications to the original method: we utilize a 2-layer GRU3 instead of the LSTM t"
W18-5101,D15-1176,0,0.240267,"rams (AUGMENTED WS + CNG), and Context word-sum + char n-grams (CONTEXT WS + CNG ). These methods are identical to the (context/ augmented) hidden-state + char n-grams methods except that here we include the character n-grams and our character-based word composition model on top of the word-sum baseline. Char hidden-state (CHAR HS) and Char wordsum (CHAR WS). In all the methods described up till now, the input to the core RNN is word embeddings. To gauge whether character-level inputs are themselves sufficient or not, we construct two methods based on the character to word (C 2 W) approach of Ling et al. (2015). For the char hiddenstate method, the input is one-hot representations of characters from a fixed vocabulary. These representations are encoded into a sequence w1 , . . . , wn of intermediate word embeddings by a 2-layer bi-directional LSTM. The word embeddings are then fed into a 2-layer GRU that transforms them into hidden states h1 , . . . , hn . Finally, as in the hidden-state baseline, an LR layer with softmax activation uses the last hidden state hn to perform classification while propagating error backwards to train the network. The char word-sum method is similar except that once the"
W18-5101,C18-1093,1,0.914305,"s alone (Pavlopoulos et al., 2017; Badjatiya et al., 2017). Since the problem of deliberately 1 Proceedings of the Second Workshop on Abusive Language Online (ALW2), pages 1–10 c Brussels, Belgium, October 31, 2018. 2018 Association for Computational Linguistics noisy input is not explicitly accounted for, these approaches resort to the use of a generic OOV (out of vocabulary) embedding for words not seen in the training phase. However, in using a single embedding for all unseen words, such approaches lose the ability to distinguish obfuscated words from non-obfuscated or rare ones. Recently, Mishra et al. (2018) and Qian et al. (2018), working with the same Twitter dataset as we do, reported that many of the misclassifications by their RNN-based methods happen due to intentional misspellings and/or rare words. Our contributions are two-fold: first, we experimentally demonstrate that character n-gram features are complementary to the current state of the art RNN approaches to abusive language detection and can strengthen their performance. We then explicitly address the problem of deliberately noisy input by constructing a model that operates at the character level and learns to predict embeddings for"
W18-5101,W17-3006,0,0.0372037,"omposition model. In all the models, besides dropout regularization (Srivastava et al., 2014), we hold out a small part of the training set as validation data to prevent over-fitting. We use 300d embeddings and 1 to 5 character ngrams for Wikipedia and 200d embeddings and 1 to 4 character n-grams for Twitter. We implement the models in Keras (Chollet et al., 2015) with Theano back-end. We employ Lightgbm (Ke et al., 2017) as our GDBT classifier and tune its hyper-parameters using 5-fold grid search. 5.2 Twitter results For the Twitter dataset, unlike previous research (Badjatiya et al., 2017; Park and Fung, 2017), we report the macro precision, recall, and F1 averaged over 10 folds of stratified CV (Table 1). For a classification problem with N classes, macro precision (similarly, macro recall and macro F1 ) is given by: N 1 X M acro P = Pi N upon the results obtained with character n-grams. All the improvements are statistically significant with p &lt; 0.05 under 10-fold CV paired t-test. As Ling et al. (2015) noted in their POS tagging experiments, we observe that the CHAR HS and CHAR WS methods perform worse than their counterparts that use pre-trained word embeddings, i.e., the HS and WS baselines re"
W18-5101,W17-3004,0,0.56049,"uch provisions. Nobata et al. (2016) go on to show that simple character n-gram features prove to be highly promising for supervised classification approaches to abuse detection due to their robustness to spelling variations; however, they do not address obfuscations explicitly. Waseem and Hovy (2016) and Wulczyn et al. (2017) also use character ngrams to attain impressive results on their respective datasets. That said, the current state of the art methods do not exploit character-level information, but instead utilize recurrent neural network (RNN) models operating on word embeddings alone (Pavlopoulos et al., 2017; Badjatiya et al., 2017). Since the problem of deliberately 1 Proceedings of the Second Workshop on Abusive Language Online (ALW2), pages 1–10 c Brussels, Belgium, October 31, 2018. 2018 Association for Computational Linguistics noisy input is not explicitly accounted for, these approaches resort to the use of a generic OOV (out of vocabulary) embedding for words not seen in the training phase. However, in using a single embedding for all unseen words, such approaches lose the ability to distinguish obfuscated words from non-obfuscated or rare ones. Recently, Mishra et al. (2018) and Qian et"
W18-5101,D14-1162,0,0.0938289,"tate of the art results on the Wikipedia datasets. Given a text formed of a sequence w1 , . . . , wn of words (represented by ddimensional word embeddings), the method utilizes a 1-layer GRU to encode the words into hidden states h1 , . . . , hn . This is followed by an LR layer that classifies the text based on the last hidden state hn . We modify the authors’ original architecture in two minor ways: we extend the 1layer GRU to a 2-layer GRU and use softmax as the activation in the LR layer instead of sigmoid.1 Following Pavlopoulos et al., we initialize the word embeddings to GLoVe vectors (Pennington et al., 2014). In all our methods, words not present in the GLoVe set are randomly initialized in the range ±0.05, indicating the lack of semantic information. By not mapping these words to a single random embedding, we mitigate against the errors that may arise due to their conflation (Madhyastha et al., 2015). A special OOV (out of vocabulary) token is also initialized in the same range. All the embeddings are updated during training, allowing for some of the randomly-initialized ones to get 1 We also experimented with 1-layer GRU/LSTM and 1/2layer bi-directional GRUs/LSTMs but the performance only worse"
W18-5101,D17-1010,0,0.0215418,"imply mapped to the OOV token since we do not have a way of obtaining any semantic information about them. However, this is undesirable since racial slurs and expletives are often deliberately fudged by users to prevent detection. In using a single embedding for all unseen words, we lose the ability to distinguish such obfuscations from other non-obfuscated or rare words. Taking inspiration from the effectiveness of character-level features in abuse detection, we address this issue by having a character-based word composition model that can compose embeddings for unseen words in the test set (Pinter et al., 2017). We then augment the hidden-state + char n-grams method with it. 2 In their work, the authors report that initializing embeddings randomly rather than with GLoVe yields state of the art performance on the Twitter dataset that we are using. However, we found the opposite when performing 10-fold stratified cross-validation (CV). A possible explanation of this lies in the authors’ decision to not use stratification, which for such a highly imbalanced dataset can lead to unexpected outcomes (Forman and Scholz, 2010). Furthermore, the authors train their LSTM on the entire dataset including the te"
W18-5101,N18-2019,0,0.0437389,"l., 2017; Badjatiya et al., 2017). Since the problem of deliberately 1 Proceedings of the Second Workshop on Abusive Language Online (ALW2), pages 1–10 c Brussels, Belgium, October 31, 2018. 2018 Association for Computational Linguistics noisy input is not explicitly accounted for, these approaches resort to the use of a generic OOV (out of vocabulary) embedding for words not seen in the training phase. However, in using a single embedding for all unseen words, such approaches lose the ability to distinguish obfuscated words from non-obfuscated or rare ones. Recently, Mishra et al. (2018) and Qian et al. (2018), working with the same Twitter dataset as we do, reported that many of the misclassifications by their RNN-based methods happen due to intentional misspellings and/or rare words. Our contributions are two-fold: first, we experimentally demonstrate that character n-gram features are complementary to the current state of the art RNN approaches to abusive language detection and can strengthen their performance. We then explicitly address the problem of deliberately noisy input by constructing a model that operates at the character level and learns to predict embeddings for unseen words. We show"
W18-5101,W16-5618,0,0.039788,"s formed the optimal feature set for the task. On the other hand, geographic and word-length distribution features provided little to no improvement. Experimenting with the same dataset, Badjatiya et al. (2017) improved on their results by training a gradient-boosted decision tree (GBDT) classifier on averaged word embeddings learnt using a long short-term memory (LSTM) models initialized with random embeddings. Mishra et al. (2018) went on to incorporate community-based profiling features of users in their classification methods, which led to the state of the art performance on this dataset. Waseem (2016) studied the influence of annotators’ knowledge on the task of hate speech detection. For this, they sampled 7k tweets from the same corpus as Waseem and Hovy (2016) and recruited expert and amateur annotators to annotate the tweets as racism, sexism, both or neither. Combining this dataset with that of Waseem and Hovy (2016), Park et al. (2017) evaluated the efficacy of a 2-step classification process: they first used an LR classifier to separate abusive and nonabusive tweets, and then used another LR classifier to distinguish between the racist and sexist ones. They showed that this setup ha"
W18-5101,W17-3000,0,0.130449,"LR layer to classify the comments based on those representations. Davidson et al. (2017) produced a dataset of about 25k racist, offensive or clean tweets. They evaluated several multi-class classifiers with the aim of discerning clean tweets from racist and offensive tweets, while simultaneously being able to distinguish between the racist and offensive ones. Their best model was an LR classifier trained using TF – IDF and POS n-gram features coupled with features like count of hash tags and number of words. 3 Datasets Following the proceedings of the 1st Workshop on Abusive Language Online (Waseem et al., 2017), we use three datasets from two different domains. 3.1 Twitter Waseem and Hovy (2016) prepared a dataset of 16, 914 tweets from a corpus of approximately 136k tweets retrieved over a period of two months. They bootstrapped their collection process with a search for commonly used slurs and expletives related to religious, sexual, gender and ethnic minorities. After having manually annotated 16, 914 of the tweets as racism, sexism or neither, they asked an expert to review their annotations in order to mitigate against any biases. The inter-annotator agreement was reported at κ = 0.84, with fur"
W18-5101,N16-2013,0,0.451279,"ridge United Kingdom pm576@alumni.cam.ac.uk Helen Yannakoudakis The ALTA Institute University of Cambridge United Kingdom hy260@cl.cam.ac.uk Abstract Two conclusions can be drawn from these statistics: (i) abuse (a term we use henceforth to collectively refer to toxic language, hate speech, etc.) is prevalent in social media, and (ii) passive and/or manual techniques for curbing its propagation (such as flagging) are neither effective nor easily scalable (Pavlopoulos et al., 2017). Consequently, the efforts to automate the detection and moderation of such content have been gaining popularity (Waseem and Hovy, 2016; Wulczyn et al., 2017). The advent of social media in recent years has fed into some highly undesirable phenomena such as proliferation of offensive language, hate speech, sexist remarks, etc. on the Internet. In light of this, there have been several efforts to automate the detection and moderation of such abusive content. However, deliberate obfuscation of words by users to evade detection poses a serious challenge to the effectiveness of these efforts. The current state of the art approaches to abusive language detection, based on recurrent neural networks, do not explicitly address this p"
