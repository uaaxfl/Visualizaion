1995.mtsummit-1.35,1994.amta-1.17,0,0.05492,"Missing"
1997.mtsummit-papers.11,1995.mtsummit-1.35,1,0.793855,"on machine translation systems since the 1996 Japanese fiscal year. An overview of this bilingual corpus is presented in this paper. And other linguistic data recently developed in Japan, which includes the RWC text database and the simple sentence data by the CRL and IPA. 1. Introduction The committee on text processing technology of JEIDA (Japan Electronics Industry Development Association) is a subcommittee of JEIDA’s committee on natural language processing (chairman: Prof. Nagao of Kyoto University), and developed JEIDA’s testsets for the quality evaluation of machine translation systems [1]. The committee has been developing its bilingual corpus for research on machine translation systems since the 1996 Japanese fiscal year. An overview of this bilingual corpus is presented in this paper. And other linguistic data recently developed in Japan, which includes the RWC text database and the simple sentence data by the CRL and IPA. 2. JEIDA’s bilingual corpus A huge amount of bilingual data is necessary for MT research, especially for corpus-based research on MT systems. There are some such corpora for Indo-European languages, however, there is no such bilingual corpus for Japanese a"
2002.tmi-papers.14,W99-0606,0,0.0689983,"Missing"
2002.tmi-papers.14,A00-2020,0,0.0829102,"achine translation. We describe the modality corpus in Section 2, the method of corpus correction in Section 3, and our experiments on corpus correction in Section 4. 2 Modality Corpus for Machine Translation In this section, we describe the modality corpus. A part of the modality corpus is shown in Figure 1. It is composed of a Japanese-English bilingual corpus; each English sentence can include two types of tags: 1 There is no previous paper on error correction in corpora. In terms of error detection in corpora, there has been research using boosting or anomaly detection (Abney et al. 1999; Eskin 2000). , kono kodomo wa aa ieba kou iu kara koniku-rashii This child always talks back to me, and this &lt;v>is&lt;/v> why I &lt;vj>hate&lt;/vj> him. d kare ga aa okubyou da to wa omowanakatta I &lt;v>did not think&lt;/v> he was so timid. c aa isogashikute wa yasumu hima mo nai hazu da Such a busy man as he &lt;v>cannot have&lt;/v> any spare time. Figure 1: Part of the modality corpus • The English main verb phrase is tagged with &lt;v>. • The English verb phrase corresponding to the Japanese main verb phrase is tagged with &lt;vj>. The symbols at the beginning of each Japanese sentence, such as “c” and “d”, indicate a category"
2002.tmi-papers.14,1999.tmi-1.7,1,0.874862,"Missing"
2002.tmi-papers.14,P94-1013,0,0.00968044,"f each category/feature pair as calculated from p˜(a, b) are the same as those from p(a, b) (this corresponds to Equation (1).) These estimated values are not so sparse. We can thus use the above assumption for calculating p(a, b). Furthermore, we maximize the entropy of the distribution of p˜(a, b) to obtain one solution of p˜(a, b), because using only Equation 1 produces several solutions for p˜(a, b). Maximizing the entropy has the effect of making the distribution more uniform and is considered to be a good solution for data sparseness problems. • Method based on the decision-list method (Yarowsky 1994) In this method, the probability of each category is calculated using one of the features, f j (∈ F,  ≤ j ≤ k). The probability that produces category a in context b is given by the following equation: p(a|b) = p(a|f max ), (3) such that f max is defined by f max = argmaxf j ∈F maxai ∈A p˜(ai |f j ), (4) where p˜(ai |f j ) is the occurrence rate of category a i when the context has feature f j. In this paper, we used the following items as features, which are the context when the probabilities are calculated; 26 (= 5 + 10 + 10 + 1) features appear in each English sentence: • the strings of 1-"
2005.eamt-1.8,A97-1001,0,0.0737007,"Missing"
2005.eamt-1.8,W02-0710,1,0.794173,"Missing"
2005.eamt-1.8,P03-2024,1,0.844535,"Missing"
2005.eamt-1.8,2005.eamt-1.8,1,0.106122,"Missing"
2005.eamt-1.8,2004.tmi-1.3,1,\N,Missing
2005.mtsummit-invited.7,J03-1002,0,0.00441278,"Missing"
2005.mtsummit-invited.7,2003.mtsummit-papers.51,0,0.0620587,"Missing"
2005.mtsummit-invited.7,H93-1040,0,0.0440308,"Missing"
2005.mtsummit-papers.10,J97-2004,0,0.152501,"d (&c&&)). (3) Posstra expresses the possibility estimated by and Aaug as alignment results. using the traditional Chinese characters. 5.1.2 Algorithm for broadening coverage Let WJ ( WC ) denote the list of words Bilingual Dictionary j ∈ WJ (c ∈ WC ) that are still not aligned. In this A translation dictionary can help to identify the translation relations. Let C j denote the Chinese phase, we only consider one to one alignment. ~ ~ For j (∈ WJ ) , we estimate the possibility of j translation set of j . We can estimate the possibility of j being aligned with &c&& using the following formula (Ker and Chang, 1997). Possdic ( j ,&c&&) = max Sim(c' ,&c&&). c '∈C j being aligned with c~ (∈ WC ) as follows. ~ For an alignment candidate ( j , c~ ) , we estimate its likelihood by taking the established alignments into account. Here we consider four established alignments: the two alignments that are the nearest ~ to j on the left and right and the two alignments that are the nearest to c~ on the left and right. Null0 , Null0 ) and First, add ( (4) Possdic expresses the possibility estimated by using a translation dictionary. An automatically built Japanese-Chinese dictionary is used here, which was built fro"
2005.mtsummit-papers.10,maekawa-etal-2000-spontaneous,1,0.906267,"Missing"
2005.mtsummit-papers.10,P01-1067,0,0.0308519,"Missing"
2005.mtsummit-papers.10,C94-2209,0,0.0409686,"Annotation on Chinese Sentences For Chinese morphological analysis, we used the analyser developed by Peking University, where the research on definition of Chinese words and the criteria of word segmentation has been conducted for over ten years. The achievements include a grammatical knowledge base of contemporary Chinese, an automatic morphological analyser, and an annotated People’s Daily Corpus. Since the definition and tagset are widely used in Chinese language processing, we also took the criteria as the basis of our guidelines. A morphological analyzer developed by Peking University (Zhou and Yu, 1994) was applied for automatic annotation of the Chinese sentences and then the automatically tagged sentences were revised by humans. An annotated sentence is illustrated in Figure 3, which is the Chinese sentence in Ex. 1 in Section 2. The interface of the tool is shown in Figure 4 and Figure 5. S-ID: 950104141-008 这些/r 俄军/j 士兵/n 均/d 为/v 十九/m 岁/q 左右/m 的/u 年青人/n ，/w 他们/r 甚至/d 连/p 回答/v 问题/n 的/u 气力/n 也/d 没有/v 。/w Figure 3 An annotated Chinese sentence 4.3 Tool for Manual Revision We developed a tool to assist annotators in revision. The tool has both Japanese and Chinese versions. Here, we introduc"
2005.mtsummit-papers.10,W04-2208,1,\N,Missing
2005.mtsummit-papers.18,J93-2003,0,0.0071722,"of the multi-aligner. 1 Introduction In a parallel corpus, automatic word alignment is to identify the translation relations between the words in a source sentence and those in a target sentence. A word-aligned parallel corpus has many applications, such as machine translation, machineaided translation, bilingual lexicography, and wordsense disambiguation. For these applications, much research on automatic word alignment has been conducted and reported. The statistics-based approach is widely studied (Och and Ney, 2003), and is mainly based on the research of statistical machine translation (Brown et al., 1993). However, this approach incorrectly aligns less frequently occurring words when statistically significant evidence is not available. Instead of word-based statistics, Ker proposed a class-based approach by using lexicon resources (Ker and Chang, 1997). Based on this idea, various 2 Japanese-Chinese Parallel Corpus The corpus we used in this study consists of 38,383 Japanese sentences from Mainichi newspaper and their Chinese translations. The corpus has been morphological annotated (word segmented and part-of-speech tagged) in the first phase of the project. For Japanese morphological 133 spe"
2005.mtsummit-papers.18,P00-1050,0,0.0436575,"Missing"
2005.mtsummit-papers.18,J97-2004,0,0.207324,"such as machine translation, machineaided translation, bilingual lexicography, and wordsense disambiguation. For these applications, much research on automatic word alignment has been conducted and reported. The statistics-based approach is widely studied (Och and Ney, 2003), and is mainly based on the research of statistical machine translation (Brown et al., 1993). However, this approach incorrectly aligns less frequently occurring words when statistically significant evidence is not available. Instead of word-based statistics, Ker proposed a class-based approach by using lexicon resources (Ker and Chang, 1997). Based on this idea, various 2 Japanese-Chinese Parallel Corpus The corpus we used in this study consists of 38,383 Japanese sentences from Mainichi newspaper and their Chinese translations. The corpus has been morphological annotated (word segmented and part-of-speech tagged) in the first phase of the project. For Japanese morphological 133 special case when k = 0 . Actually, the case of more-to-one has also been considered in the study. For simplicity of describtion, however, only the case of one-to-more is described here. Three kinds of lexical resources used for the estimation are describ"
2005.mtsummit-papers.18,maekawa-etal-2000-spontaneous,1,0.796201,"Missing"
2005.mtsummit-papers.18,J03-1002,0,0.0088417,"statistics-based aligner at the same time. Quantitative results confirmed the effectiveness of the multi-aligner. 1 Introduction In a parallel corpus, automatic word alignment is to identify the translation relations between the words in a source sentence and those in a target sentence. A word-aligned parallel corpus has many applications, such as machine translation, machineaided translation, bilingual lexicography, and wordsense disambiguation. For these applications, much research on automatic word alignment has been conducted and reported. The statistics-based approach is widely studied (Och and Ney, 2003), and is mainly based on the research of statistical machine translation (Brown et al., 1993). However, this approach incorrectly aligns less frequently occurring words when statistically significant evidence is not available. Instead of word-based statistics, Ker proposed a class-based approach by using lexicon resources (Ker and Chang, 1997). Based on this idea, various 2 Japanese-Chinese Parallel Corpus The corpus we used in this study consists of 38,383 Japanese sentences from Mainichi newspaper and their Chinese translations. The corpus has been morphological annotated (word segmented and"
2005.mtsummit-papers.18,C94-2209,0,0.0449107,"ir Chinese translations. The corpus has been morphological annotated (word segmented and part-of-speech tagged) in the first phase of the project. For Japanese morphological 133 special case when k = 0 . Actually, the case of more-to-one has also been considered in the study. For simplicity of describtion, however, only the case of one-to-more is described here. Three kinds of lexical resources used for the estimation are described below . annotation, the definition of the Corpus of Spontaneous Japanese was adopted (Maekawa, 2000). For Chinese, the definition of Peking University was adopted (Zhou and Yu, 1994). The average lengths of the sentences on both sides are about 30 words. The study, word alignment, aims to assist to word alignment annotation, which is a task in the second phase of the project. 3 Orthography About half of Japanese words contain kanji, the Chinese characters used in Japanese writing. We call them kanji words. Japanese words may also contain hiragana or katakana, which are phonetic characters. Because some kanji words were adapted directly from China, their Chinese translations are the same as the words themselves. For example, the Chinese translations for the Japanese words"
2005.mtsummit-papers.2,W00-1314,0,0.190796,"Missing"
2005.mtsummit-papers.2,P03-2025,0,0.18048,"Missing"
2005.mtsummit-papers.2,sahlgren-2004-automatic,0,0.122369,"Missing"
2005.mtsummit-papers.2,J96-1001,0,0.260356,"Missing"
2005.mtsummit-papers.2,C02-1002,0,0.23936,"Missing"
2005.mtsummit-papers.2,utsuro-etal-2002-semi,0,0.131439,"Missing"
2005.mtsummit-papers.2,2005.mtsummit-papers.2,1,0.0530913,"Missing"
2005.mtsummit-papers.25,E03-2010,1,0.865288,"Missing"
2005.mtsummit-papers.25,2005.eamt-1.8,1,0.80735,"ality of pain, and the factors that increase or decrease the pain. The answers to these questions can be successfully communicated by a limited number of one or two word responses (e.g. yes/no, left/right, numbers) or even gestures (e.g. nodding or shaking the head, pointing to an area of the body). Translation can thus be unidirectional. In order to obtain an accurate translation, the system uses a grammar-based speech recogniser. For this type of application a grammar-based approach appears to give better results than a statistical-based recognition (Knight et al., 2001, Rayner et al. 2004, Bouillon et al. 2005). Diagnosis seems to be a very convergent sublanguage, where it is possible to guess the syntactic structures that a doctor will use, and thus to describe them in a grammar. The advantage of this approach is that the grammar enforces more global constraints on the recognized utterance than the simple bigrams or trigrams of a statistical language model: more complete sentences are thus well recognized, which improves the translation. The drawback is the lack of robustness: if the sentence structure is not in the grammar or if a word is not in the lexicon, the recognition completely fails. Helpi"
2005.mtsummit-papers.25,lavie-etal-2002-nespole,0,0.0623047,"Missing"
2005.mtsummit-papers.25,W02-0710,1,\N,Missing
2005.mtsummit-papers.25,2004.tmi-1.3,1,\N,Missing
2005.mtsummit-papers.31,P02-1040,0,0.147985,"Missing"
2007.mtsummit-papers.47,P02-1051,0,0.623701,"to estimate its parameters. Therefore, we called a in their Romanized form with single quotation marks and hyphens between syllables. transliteration engine based on GM, PM, or CM a “singlemodel engine” and one based on HM a “hybrid-model engine.” We used seven transliteration engines. Three were single-model engines corresponding to GM, PM, and CM. The other four were hybrid-model engines. Three of these corresponded to HM using two of GM, PM, and CM — HM(G+P) , HM(G+C) , and HM(P+C) — and the last was based on HM using all three (HM(G+P+C) ). Note that HM(G+P) has previously been described (Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004), and the other HMs are newly proposed here. 2.1. Single-Model Engines Let SW be a source word, PSW be the pronunciation of SW , TSW be a target word corresponding to SW , and CSW be the correspondence between SW and PSW . PSW and TSW can be segmented into a series of sub-strings, each of which corresponds to a source grapheme. We can thus write SW = s1 , · · · , sn = sn1 , PSW = p1 , · · · , pn = pn1 , TSW = t1 , · · · , tn = tn1 , and CSW = c1 , · · · , cn = cn1 , where si , pi , ti , and ci = < si , pi > respectively represent the ith source grapheme, source phoneme"
2007.mtsummit-papers.47,J96-1002,0,0.138837,"simplified into a series of products. P rG = P rG (TSW |SW ) = P r(tn1 |sn1 ) Y i+k ≈ P r(ti |ti−1 i−k , si−k ) (1) i P rP = P rP (TSW |SW ) (2) n n n n = P r(p1 |s1 ) × P r(t1 |p1 ) Y i+k i−1 i+k ≈ P r(pi |pi−1 i−k , si−k ) × P r(ti |ti−k , pi−k ) i P rC = P rC (TSW |SW ) = ≈ × P r(tn1 |cn1 ) Y i+k P r(pi |pi−1 i−k , si−k ) × i (3) P r(pn1 |sn1 ) i−1 i+k P r(ti |ti−k , ci−k ) i−1 i+k probabilities, P r(ti |ti−k , si−k ), i−1 i+k P r(ti |ti−k , pi−k ), and To estimate the i+k P r(pi |pi−1 i−k , si−k ), i−1 i+k P r(ti |ti−k , ci−k ), in Eqs. (1), (2), and (3), we use the maximum entropy model (Berger et al., 1996). Event ev in this model is composed of a target event (te) and a 4 ARPAbet symbols are used to represent English phonemes. ARPAbet is one of the methods used for coding English phonemes into ASCII characters (http://www.cs.cmu. edu/˜laura/pages/arpabet.ps) history event (he) and is represented by a bundle of feature functions (fi (he, te)) that represent certain characteristics in event ev. The feature functions enable a model based on the maximum entropy model to estimate probability (Berger et al., 1996). Therefore, designing the feature functions, which effectively support certain decision"
2007.mtsummit-papers.47,J05-1003,0,0.033184,"W ) = δ1 × P rG + δ2 × P rP + δ3 × P rC (5) (6) gSV M (xi ) = w · xi + b (7) (8) We first produce n-best transliteration hypotheses using a stack decoder (Schwartz and Chow, 1990) for each transliteration engine. We then make a set of transliteration hypotheses comprising the n-best transliteration hypotheses produced by the seven transliteration engines. 3. Re-Ranking Transliteration Hypotheses The transliteration hypotheses in the set are re-ranked to enable a correct hypothesis to be identified. Re-ranking has been successfully applied to several NLP problems including statistical parsing (Collins and Koo, 2005; Daume III and Marcu, 2004; Shen and Joshi, 2003), machine translation (Shen et al., 2004), and name entity taggers (Ji et al., 2006). We selected support vector machines (SVMs) and the maximum entropy model (MEM) (Daume III and Marcu, 2004; Ji et al., 2006) from the machine-learning algorithms used for re-ranking. Let hi ∈ H be the ith transliteration hypothesis of source word s, hcorrect be a correct transliteration hypothesis corresponding to s, xi ∈ X be a feature vector of hi , and yi be the training label for xi . What we need to do is devise a rank function, g(xi ), in Eq. (9) that ran"
2007.mtsummit-papers.47,W04-3233,0,0.052748,"Missing"
2007.mtsummit-papers.47,2003.mtsummit-papers.17,0,0.170005,"ames and technical terms from languages using the Roman alphabet into ones using non-Roman alphabets such as Chinese, Japanese, or Korean. Because transliteration is one of the main causes of the out-of-vocabulary (OOV) problem, machine transliteration has received a significant degree of attention as a tool to support machine translation (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002) and cross-language information retrieval (Fujii and Tetsuya, 2001). A variety of paradigms for machine transliteration have been developed over the years: grapheme1 -based model (GM) (Kang and Kim, 2000; Goto et al., 2003), phoneme2 -based model (PM) (Knight and Graehl, 1998; Kang, 2001), hybrid model (HM) (Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004), and correspondence-based model (CM) (Oh and Choi, 2002; Oh and Choi, 2005). These models are classified in terms of the information sources used for transliteration or the units that are transliterated. GM, PM, HM, and CM make use of source graphemes, source phonemes, both source graphemes and source phonemes, and the correspondence between source graphemes and phonemes, respectively. Transliteration is generally a phonetic rather than an orthographic pro"
2007.mtsummit-papers.47,W06-3607,0,0.0197639,"stack decoder (Schwartz and Chow, 1990) for each transliteration engine. We then make a set of transliteration hypotheses comprising the n-best transliteration hypotheses produced by the seven transliteration engines. 3. Re-Ranking Transliteration Hypotheses The transliteration hypotheses in the set are re-ranked to enable a correct hypothesis to be identified. Re-ranking has been successfully applied to several NLP problems including statistical parsing (Collins and Koo, 2005; Daume III and Marcu, 2004; Shen and Joshi, 2003), machine translation (Shen et al., 2004), and name entity taggers (Ji et al., 2006). We selected support vector machines (SVMs) and the maximum entropy model (MEM) (Daume III and Marcu, 2004; Ji et al., 2006) from the machine-learning algorithms used for re-ranking. Let hi ∈ H be the ith transliteration hypothesis of source word s, hcorrect be a correct transliteration hypothesis corresponding to s, xi ∈ X be a feature vector of hi , and yi be the training label for xi . What we need to do is devise a rank function, g(xi ), in Eq. (9) that ranks hcorrect higher and the others lower. g(xi ) : X → {r : r is ordering of hi ∈ H} We first train SVMs and MEM with training data set"
2007.mtsummit-papers.47,C00-1061,0,0.160935,"o translate proper names and technical terms from languages using the Roman alphabet into ones using non-Roman alphabets such as Chinese, Japanese, or Korean. Because transliteration is one of the main causes of the out-of-vocabulary (OOV) problem, machine transliteration has received a significant degree of attention as a tool to support machine translation (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002) and cross-language information retrieval (Fujii and Tetsuya, 2001). A variety of paradigms for machine transliteration have been developed over the years: grapheme1 -based model (GM) (Kang and Kim, 2000; Goto et al., 2003), phoneme2 -based model (PM) (Knight and Graehl, 1998; Kang, 2001), hybrid model (HM) (Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004), and correspondence-based model (CM) (Oh and Choi, 2002; Oh and Choi, 2005). These models are classified in terms of the information sources used for transliteration or the units that are transliterated. GM, PM, HM, and CM make use of source graphemes, source phonemes, both source graphemes and source phonemes, and the correspondence between source graphemes and phonemes, respectively. Transliteration is generally a phonetic rather than"
2007.mtsummit-papers.47,kawahara-kurohashi-2006-case,0,0.0139792,"The confidence score features for hi can then be acquired using Eq. (12). ACS(s, hi ) = P rM (hi |s) X 1 × CSM (s, hi ) |M| (12) 4. Evaluation M Language Model (1 feature total): We used a list of transliterations as mono-lingual corpora to construct the language model for transliteration. Note that the monolingual corpora differed from the training data set used to train the transliteration engines. We used a list of Korean transliterations published by “The National Institute of the Korean Language”6 for the Korean language model and a list of katakana terms extracted from Web texts used in Kawahara and Kurohashi (2006) for the Japanese language model. Note that katakana is usually used to represent Japanese transliterations. We then construct a transliteration language model using the SRI Language Modeling Toolkit (SRILM) (Stolcke, 2002). Let hi = ts1 , · · · , tsl be a transliteration hypothesis having l target language syllables. We calculate P r(hi ) = logP r(ts1 , · · · , tsl ) using SRILM. Note that the language-model features are based on target-language syllables rather than target-language graphemes. Web Frequency (6 features total): Several researchers have used Web frequency, i.e., the number of W"
2007.mtsummit-papers.47,P04-1063,0,0.02908,"cause each of the transliteration models depends on a particular information source, each can produce transliterations with errors. Moreover, different transliteration models usually produce different errors and different transliterations. This means we should be able to improve transliteration by combining various transliteration models into one machinetransliteration system that combines the advantages of the individual models and suffers from few of their disadvantages. A similar idea has been successfully applied to automatic speech recognition (ASR) and machine translation (Fiscus, 1997; Nomoto, 2004). In our previous work (Oh et al., 2006b), we have shown that this idea is also helpful for improving machine transliteration. It used transliteration hypotheses derived from four transliteration engines and re-ranked them with the product of two ranking functions, each of which was based on the rank of hypotheses in each transliteration engine and Web frequency. Even though the re-ranking in Oh et al. (2006b) performed well, it had limitations in taking various features into account and effectively combining them. To address this problem, we developed SVM-based and MEM-based re-ranking method"
2007.mtsummit-papers.47,C02-1099,1,0.795388,"out-of-vocabulary (OOV) problem, machine transliteration has received a significant degree of attention as a tool to support machine translation (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002) and cross-language information retrieval (Fujii and Tetsuya, 2001). A variety of paradigms for machine transliteration have been developed over the years: grapheme1 -based model (GM) (Kang and Kim, 2000; Goto et al., 2003), phoneme2 -based model (PM) (Knight and Graehl, 1998; Kang, 2001), hybrid model (HM) (Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004), and correspondence-based model (CM) (Oh and Choi, 2002; Oh and Choi, 2005). These models are classified in terms of the information sources used for transliteration or the units that are transliterated. GM, PM, HM, and CM make use of source graphemes, source phonemes, both source graphemes and source phonemes, and the correspondence between source graphemes and phonemes, respectively. Transliteration is generally a phonetic rather than an orthographic process (Knight and Graehl, 1998). However, both the source grapheme and source phoneme or either of them can affect the target-language transliteration (e.g. a Japanese or Korean transliteration)."
2007.mtsummit-papers.47,I05-1040,1,0.919135,"OOV) problem, machine transliteration has received a significant degree of attention as a tool to support machine translation (Knight and Graehl, 1998; Al-Onaizan and Knight, 2002) and cross-language information retrieval (Fujii and Tetsuya, 2001). A variety of paradigms for machine transliteration have been developed over the years: grapheme1 -based model (GM) (Kang and Kim, 2000; Goto et al., 2003), phoneme2 -based model (PM) (Knight and Graehl, 1998; Kang, 2001), hybrid model (HM) (Al-Onaizan and Knight, 2002; Bilac and Tanaka, 2004), and correspondence-based model (CM) (Oh and Choi, 2002; Oh and Choi, 2005). These models are classified in terms of the information sources used for transliteration or the units that are transliterated. GM, PM, HM, and CM make use of source graphemes, source phonemes, both source graphemes and source phonemes, and the correspondence between source graphemes and phonemes, respectively. Transliteration is generally a phonetic rather than an orthographic process (Knight and Graehl, 1998). However, both the source grapheme and source phoneme or either of them can affect the target-language transliteration (e.g. a Japanese or Korean transliteration). For this reason, the"
2007.mtsummit-papers.47,P04-1024,0,0.0219425,"construct a transliteration language model using the SRI Language Modeling Toolkit (SRILM) (Stolcke, 2002). Let hi = ts1 , · · · , tsl be a transliteration hypothesis having l target language syllables. We calculate P r(hi ) = logP r(ts1 , · · · , tsl ) using SRILM. Note that the language-model features are based on target-language syllables rather than target-language graphemes. Web Frequency (6 features total): Several researchers have used Web frequency, i.e., the number of Web documents retrieved by a search engine, for transliteration or ranking translations (Al-Onaizan and Knight, 2002; Qu and Grefenstette, 2004; Zhang et al., 2005; Oh et al., 2006b). There have been several methods of acquiring Web frequency. For source word s and target transliteration (or translation) t, some of them have used t as a query for Web frequency (Al-Onaizan and Knight, 2002; Oh et al., 2006b), which is called a monolingual keyword search (MKS), and others have used both s and t for acquiring Web frequency (Qu and Grefenstette, 2004; Zhang et al., 2005; Oh et al., 2006b), which is called a bilingual keyword search (BKS). However, Web pages retrieved by MKS tend to show whether t is used in target-language texts rather t"
2007.mtsummit-papers.47,W03-0402,0,0.0299329,"V M (xi ) = w · xi + b (7) (8) We first produce n-best transliteration hypotheses using a stack decoder (Schwartz and Chow, 1990) for each transliteration engine. We then make a set of transliteration hypotheses comprising the n-best transliteration hypotheses produced by the seven transliteration engines. 3. Re-Ranking Transliteration Hypotheses The transliteration hypotheses in the set are re-ranked to enable a correct hypothesis to be identified. Re-ranking has been successfully applied to several NLP problems including statistical parsing (Collins and Koo, 2005; Daume III and Marcu, 2004; Shen and Joshi, 2003), machine translation (Shen et al., 2004), and name entity taggers (Ji et al., 2006). We selected support vector machines (SVMs) and the maximum entropy model (MEM) (Daume III and Marcu, 2004; Ji et al., 2006) from the machine-learning algorithms used for re-ranking. Let hi ∈ H be the ith transliteration hypothesis of source word s, hcorrect be a correct transliteration hypothesis corresponding to s, xi ∈ X be a feature vector of hi , and yi be the training label for xi . What we need to do is devise a rank function, g(xi ), in Eq. (9) that ranks hcorrect higher and the others lower. g(xi ) :"
2007.mtsummit-papers.47,N04-1023,0,0.0243166,"uce n-best transliteration hypotheses using a stack decoder (Schwartz and Chow, 1990) for each transliteration engine. We then make a set of transliteration hypotheses comprising the n-best transliteration hypotheses produced by the seven transliteration engines. 3. Re-Ranking Transliteration Hypotheses The transliteration hypotheses in the set are re-ranked to enable a correct hypothesis to be identified. Re-ranking has been successfully applied to several NLP problems including statistical parsing (Collins and Koo, 2005; Daume III and Marcu, 2004; Shen and Joshi, 2003), machine translation (Shen et al., 2004), and name entity taggers (Ji et al., 2006). We selected support vector machines (SVMs) and the maximum entropy model (MEM) (Daume III and Marcu, 2004; Ji et al., 2006) from the machine-learning algorithms used for re-ranking. Let hi ∈ H be the ith transliteration hypothesis of source word s, hcorrect be a correct transliteration hypothesis corresponding to s, xi ∈ X be a feature vector of hi , and yi be the training label for xi . What we need to do is devise a rank function, g(xi ), in Eq. (9) that ranks hcorrect higher and the others lower. g(xi ) : X → {r : r is ordering of hi ∈ H} We firs"
2007.mtsummit-papers.63,J93-2003,0,0.0367977,"Missing"
2007.mtsummit-papers.63,J93-1004,0,0.457946,"patent parallel corpus. We used simple pattern matching programs to extract the embodiment and background parts from the whole document pairs and obtained 77,014 embodiment part pairs and 72,589 background part pairs. We then applied the alignment procedure described in Section 3. to these 149,603 pairs. We call these embodiment and background parts documents. 3. 3.1. Alignment procedure Score of sentence alignment We used Utiyama and Isahara’s method (Utiyama and Isahara, 2003) to score sentence alignments. We first aligned sentences3 in each document by using a standard DP matching method (Gale and Church, 1993; Utsuro et al., 1994). We allowed 1-to-n, n-to-1 (0 ≤ n ≤ 5), or 2-to-2 alignments when aligning the sentences. A concise description of the algorithm used is described elsewhere (Utsuro et 2 Some USPTO patents have priority information that identify foreign applications for the same subject matters. Higuchi et al. (2001) have used such corresponding patents filed in both Japan and the United States to extract bilingual lexicons. 3 We split the Japanese documents into sentences by using simple heuristics and split the English documents into sentences by using a maximum entropy sentence splitt"
2007.mtsummit-papers.63,2001.mtsummit-papers.30,0,0.073559,"Missing"
2007.mtsummit-papers.63,W06-3114,0,0.0811281,"Missing"
2007.mtsummit-papers.63,2005.iwslt-1.8,0,0.0181508,"t in TEST that contained example 5R, even though these two patents were different. These examples show that even long and/or specific expressions are reused in patent documents. We think that this characteristic of patents contributed to the good translations. The middle and bottom examples (6 to 15) were generally not good translations. These examples adequately translated individual phrases. However, they failed to adequately reorder phrases. This suggests that we need more accurate models for reordering. Thus, our patent corpus will be a good corpus for comparing various reordering models (Koehn et al., 2005; Nagata et al., 2006; Xiong et al., 2006). 6. Discussion We have described the characteristic of our patent parallel corpus and showed that it could be a good corpus for promoting MT research. In this section, we describe three issues about ALL that we found during investigating it as described in Sections 3., 4., and 5. We want to resolve these issues when we extend it for the NTCIR-7 patent MT task. Issue 1. Our noise reduction procedure described in Section 3.2. reduced the number of sentences from about 4.2 million to about 3.9 million. This reduction could be too aggressive. We want to i"
2007.mtsummit-papers.63,koen-2004-pharaoh,0,0.0562327,"Missing"
2007.mtsummit-papers.63,2005.mtsummit-papers.11,0,0.132568,"Missing"
2007.mtsummit-papers.63,ma-cieri-2006-corpus,0,0.0478548,"Missing"
2007.mtsummit-papers.63,J05-4003,0,0.0346251,"ess in corpus-based machine translation (MT) (Nagao, 1981; Brown et al., 1993) has been supported by large parallel corpora, such as the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium (Ma and Cieri, 2006) and the Europarl corpus (Koehn, 2005) consisting of 11 European languages. However, large parallel corpora do not exist for many language pairs. Much work has been undertaken to overcome this lack of parallel corpora. For example, Resnik and Smith (2003) have proposed mining the web to collect parallel corpora for low-density language pairs. Munteanu and Marcu (2005) have extracted parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Utiyama and Isahara (2003) have extracted JapaneseEnglish parallel sentences from a noisy-parallel corpus. We have recently aligned Japanese and English sentences in Japanese and US patent data provided for the NTCIR-6 patent retrieval task (Fujii et al., 2007). We used Utiyama and Isahara’s method to extract clean sentence alignments. The number of extracted sentence alignments was about 2 million. These sentence pairs and all alignment data that were produced during the alignment proced"
2007.mtsummit-papers.63,P06-1090,0,0.0239539,"ined example 5R, even though these two patents were different. These examples show that even long and/or specific expressions are reused in patent documents. We think that this characteristic of patents contributed to the good translations. The middle and bottom examples (6 to 15) were generally not good translations. These examples adequately translated individual phrases. However, they failed to adequately reorder phrases. This suggests that we need more accurate models for reordering. Thus, our patent corpus will be a good corpus for comparing various reordering models (Koehn et al., 2005; Nagata et al., 2006; Xiong et al., 2006). 6. Discussion We have described the characteristic of our patent parallel corpus and showed that it could be a good corpus for promoting MT research. In this section, we describe three issues about ALL that we found during investigating it as described in Sections 3., 4., and 5. We want to resolve these issues when we extend it for the NTCIR-7 patent MT task. Issue 1. Our noise reduction procedure described in Section 3.2. reduced the number of sentences from about 4.2 million to about 3.9 million. This reduction could be too aggressive. We want to investigate the effect"
2007.mtsummit-papers.63,J03-1002,0,0.0201032,"Missing"
2007.mtsummit-papers.63,E99-1010,0,0.0918638,"Missing"
2007.mtsummit-papers.63,P03-1021,0,0.0839448,"Missing"
2007.mtsummit-papers.63,P02-1040,0,0.0912947,"Missing"
2007.mtsummit-papers.63,J03-3002,0,0.0579747,"almost perfectly the contents of the corresponding Japanese sentences. 1. Introduction The rapid and steady progress in corpus-based machine translation (MT) (Nagao, 1981; Brown et al., 1993) has been supported by large parallel corpora, such as the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium (Ma and Cieri, 2006) and the Europarl corpus (Koehn, 2005) consisting of 11 European languages. However, large parallel corpora do not exist for many language pairs. Much work has been undertaken to overcome this lack of parallel corpora. For example, Resnik and Smith (2003) have proposed mining the web to collect parallel corpora for low-density language pairs. Munteanu and Marcu (2005) have extracted parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Utiyama and Isahara (2003) have extracted JapaneseEnglish parallel sentences from a noisy-parallel corpus. We have recently aligned Japanese and English sentences in Japanese and US patent data provided for the NTCIR-6 patent retrieval task (Fujii et al., 2007). We used Utiyama and Isahara’s method to extract clean sentence alignments. The number of extracted sentence alignme"
2007.mtsummit-papers.63,P03-1010,1,0.951793,"the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium (Ma and Cieri, 2006) and the Europarl corpus (Koehn, 2005) consisting of 11 European languages. However, large parallel corpora do not exist for many language pairs. Much work has been undertaken to overcome this lack of parallel corpora. For example, Resnik and Smith (2003) have proposed mining the web to collect parallel corpora for low-density language pairs. Munteanu and Marcu (2005) have extracted parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Utiyama and Isahara (2003) have extracted JapaneseEnglish parallel sentences from a noisy-parallel corpus. We have recently aligned Japanese and English sentences in Japanese and US patent data provided for the NTCIR-6 patent retrieval task (Fujii et al., 2007). We used Utiyama and Isahara’s method to extract clean sentence alignments. The number of extracted sentence alignments was about 2 million. These sentence pairs and all alignment data that were produced during the alignment procedure are planed to be used in the NTCIR-7 patent MT task.1 This is the largest Japanese-English parallel corpus, which will be availab"
2007.mtsummit-papers.63,C94-2175,0,0.0839682,". We used simple pattern matching programs to extract the embodiment and background parts from the whole document pairs and obtained 77,014 embodiment part pairs and 72,589 background part pairs. We then applied the alignment procedure described in Section 3. to these 149,603 pairs. We call these embodiment and background parts documents. 3. 3.1. Alignment procedure Score of sentence alignment We used Utiyama and Isahara’s method (Utiyama and Isahara, 2003) to score sentence alignments. We first aligned sentences3 in each document by using a standard DP matching method (Gale and Church, 1993; Utsuro et al., 1994). We allowed 1-to-n, n-to-1 (0 ≤ n ≤ 5), or 2-to-2 alignments when aligning the sentences. A concise description of the algorithm used is described elsewhere (Utsuro et 2 Some USPTO patents have priority information that identify foreign applications for the same subject matters. Higuchi et al. (2001) have used such corresponding patents filed in both Japan and the United States to extract bilingual lexicons. 3 We split the Japanese documents into sentences by using simple heuristics and split the English documents into sentences by using a maximum entropy sentence splitter available at http:/"
2007.mtsummit-papers.63,P06-1066,0,0.0226571,"though these two patents were different. These examples show that even long and/or specific expressions are reused in patent documents. We think that this characteristic of patents contributed to the good translations. The middle and bottom examples (6 to 15) were generally not good translations. These examples adequately translated individual phrases. However, they failed to adequately reorder phrases. This suggests that we need more accurate models for reordering. Thus, our patent corpus will be a good corpus for comparing various reordering models (Koehn et al., 2005; Nagata et al., 2006; Xiong et al., 2006). 6. Discussion We have described the characteristic of our patent parallel corpus and showed that it could be a good corpus for promoting MT research. In this section, we describe three issues about ALL that we found during investigating it as described in Sections 3., 4., and 5. We want to resolve these issues when we extend it for the NTCIR-7 patent MT task. Issue 1. Our noise reduction procedure described in Section 3.2. reduced the number of sentences from about 4.2 million to about 3.9 million. This reduction could be too aggressive. We want to investigate the effect of noise reduction o"
2007.mtsummit-papers.73,C94-2209,0,0.128581,"Missing"
2008.amta-govandcom.25,2001.mtsummit-papers.20,0,0.0457505,"Missing"
2008.amta-govandcom.25,2007.mtsummit-papers.35,1,0.808622,"Missing"
2008.amta-govandcom.25,P03-1010,1,0.873862,"Missing"
2008.amta-govandcom.25,2007.mtsummit-papers.63,1,0.850731,"Missing"
2008.amta-govandcom.25,P07-2045,0,0.00907839,"Missing"
2008.amta-govandcom.25,P02-1040,0,0.0742141,"Missing"
2012.eamt-1.57,2002.tc-1.7,0,0.0680251,"in the software domain. More specific studies have been undertaken to identify those rules which have the greatest impact on the usability of MT output (e.g., O’Brien and Roturier, 2007). © 2012 European Association for Machine Translation. 237 Overwhelmingly, controlled language studies have focused on English as source language. This is not to say that CL varieties do not exist for languages other than English. Among recent work, Barthe (1998) relates the process of developing GIFAS, the ‘rationalised’ French counterpart of the AECMA documentation standard for the aerospace industry, while Lieske et al. (2002) describe a controlled German. In the case of Japanese, the application of the CL notion dates back to (Nagao and Tanaka, 1984), who describe a framework for assisting authors in producing what they termed ‘machinereadable’ Japanese. Yoshida (1987) outlines a framework for designing a ‘standardised’ Japanese for MT. Kaji (1999) offers a few Japanese examples. More recent computational work has focused on automatic re-writing of what we can term ‘MT-intractable’ Japanese (e.g., Shirai, 1998; Matsuyoshi et al., 2004). Since such re-writing is a machine-internal process, these studies are not nec"
2012.eamt-1.57,1999.mtsummit-1.6,0,0.0603831,"is not to say that CL varieties do not exist for languages other than English. Among recent work, Barthe (1998) relates the process of developing GIFAS, the ‘rationalised’ French counterpart of the AECMA documentation standard for the aerospace industry, while Lieske et al. (2002) describe a controlled German. In the case of Japanese, the application of the CL notion dates back to (Nagao and Tanaka, 1984), who describe a framework for assisting authors in producing what they termed ‘machinereadable’ Japanese. Yoshida (1987) outlines a framework for designing a ‘standardised’ Japanese for MT. Kaji (1999) offers a few Japanese examples. More recent computational work has focused on automatic re-writing of what we can term ‘MT-intractable’ Japanese (e.g., Shirai, 1998; Matsuyoshi et al., 2004). Since such re-writing is a machine-internal process, these studies are not necessarily directly applicable to guiding the authoring of human-readable texts. Morita and Ishida (2011) provide protocols to enable monolingual users to converge on a correct Japanese/English machine translation, but no a priori writing or editing rules are proposed. The proposals in (Sato et al., 2003) are motivated by persona"
2012.eamt-1.9,1999.mtsummit-1.6,0,0.094763,"Missing"
2019.gwc-1.23,D08-1104,0,0.0565317,"Missing"
2020.paclic-1.62,D15-1166,0,0.0145295,"e, we set four BERT models and two kinds of corpora to calculate idf value, and investigated which setting is most suitable for evaluation of novel translation. As a result, the setting with the model based on novel corpus, the idf based novel corpus and the penalty had the highest correlation with human-rated scores. 1 Introduction In recent years, machine translation quality has dramatically improved due to the development of neural translation models that utilize deep learning, such as the sequence transformation model (Sutskever et al., 2014) and the attention model (Dzmitry et al., 2015. Luong et al., 2015), which is an application of the attention mechanism, and improved computer performance. Due to these improvements, not only documents consisting of formal expressions such as patent sentences and academic papers that have been fixed to some extent but also informal expressions such as novels and colloquial expressions could be machine translated. However, previous research has revealed that problems that have not been considered as important in machine translation research so far have a great influence on the learning and results of novel translation. Among them, the variety of text expressio"
2020.paclic-1.62,W18-6450,0,0.0149234,"eliminary experiment under multiple settings and confirmed the setting with the best performance. Then, we conducted a verification experiment comparing it with the existing method to examine whether the proposed method is effective. In order to distinguish the similarity between tokens based on the cosine similarity, the evaluation on how the two sentences are semantically similar, performed by the human or the automatic evaluation system, is called “similarity score”. 4.1 Data The experimental data and the experimental procedure are based on the evaluation sharing task (Metric Shared Task) (Ma et al, 2018) in WMT. Verification experiments to be described later and comparison experiments with other existing methods were also performed under the same experimental settings. For the experiment, we extracted 100 sentences, 10 sentences each from 10 novels randomly selected from Project Gutenberg Canada (http://gutenberg.ca/index.html). Then, we asked expert translator to translate the extracted English sentences into Japanese. The 100 translated Japanese sentences obtained were used as the reference sentences in the test set. When translating, we requested that the translation be performed based on"
2020.paclic-1.62,P02-1040,0,0.127071,"w. English My name is John. My name is Maria Japanese 俺はジョンという。 (I am called John.) 私の名前はマリアよ。 (My name is Maria.) When a language resource (corpus) containing such parallel translations is used as learning data in neural translation that receives the whole sentence as input and learns so as to maximize the likelihood that a correct word sequence will be output, learning becomes difficult and the output of the translation system becomes unstable. In addition, different expressions cause problems not only in learning but also in translation performance evaluation. In machine translation, BLEU (Papineni et al, 2002) is the de facto standard as an automatic evaluation method for evaluating the performance of translation systems in many previous studies. BLEU is a n-gram matching that scores the translation quality between 0.0 and 1.0 by counting the number of matching words n-grams between the reference sentence that is the human-translated correct data and the sentence to be evaluated output by the translation system. BLEU is used in many machine translation studies because it is a simple and easy-to-interpret method, but it is necessary that the surface text strings of the words in the reference sentenc"
bond-etal-2008-boot,isahara-etal-2008-development,1,\N,Missing
bond-etal-2008-boot,W04-2209,0,\N,Missing
bond-etal-2008-boot,kanzaki-etal-2008-extraction,1,\N,Missing
bond-etal-2008-boot,2001.mtsummit-papers.10,1,\N,Missing
bond-etal-2008-boot,W07-0734,0,\N,Missing
bond-etal-2008-boot,W06-0601,0,\N,Missing
bond-etal-2008-boot,kaji-watanabe-2006-automatic,0,\N,Missing
bouillon-etal-2008-developing,H05-2014,1,\N,Missing
bouillon-etal-2008-developing,2005.mtsummit-papers.25,1,\N,Missing
bouillon-etal-2008-developing,2005.eamt-1.8,1,\N,Missing
bouillon-etal-2008-developing,2005.jeptalnrecital-long.17,1,\N,Missing
bouillon-etal-2008-developing,W07-0806,1,\N,Missing
bouillon-etal-2008-developing,W06-3702,1,\N,Missing
C00-1074,W96-0102,0,0.0512099,"Missing"
C00-1074,C94-1027,0,0.0855273,"Missing"
C00-1074,J94-2001,0,\N,Missing
C00-1074,J95-4004,0,\N,Missing
C00-1082,J96-1002,0,0.00692912,"of information, (i) major POS, (ii) minor POS, (iii) semantic information, and (iv) word, mentioned in the previous section were also used as features with the decision-tree learning method. As shown in Figure 3, the number of features is 12 (2 + 4 + 4 + 2) because we do not use (iii) semantic information and (iv) word information from the two outside morphemes. In Figure 2, for example, the value of the feature `the major POS of the far left morpheme&apos; is `Noun.&apos; 3.2 Maximum-entropy method The maximum-entropy method is useful with sparse data conditions and has been used by many researchers (Berger et al., 1996; Ratnaparkhi, 1996; Ratnaparkhi, 1997; Borthwick et al., 1998; Uchimoto et al., 1999). In our maximum-entropy experiment we used Ristad&apos;s system (Ristad, 1998). The analysis is performed by calculating the probability of inserting or not inserting a partition mark, from the output of the system. Whichever probability is higher is selected as the desired answer. In the maximum-entropy method, we use the same four types of morphological information, (i) major POS, (ii) minor POS, (iii) semantic information, and (iv) word, as in the decision-tree method. However, it does not consider a combinati"
C00-1082,W98-1118,0,0.0131898,"tic information, and (iv) word, mentioned in the previous section were also used as features with the decision-tree learning method. As shown in Figure 3, the number of features is 12 (2 + 4 + 4 + 2) because we do not use (iii) semantic information and (iv) word information from the two outside morphemes. In Figure 2, for example, the value of the feature `the major POS of the far left morpheme&apos; is `Noun.&apos; 3.2 Maximum-entropy method The maximum-entropy method is useful with sparse data conditions and has been used by many researchers (Berger et al., 1996; Ratnaparkhi, 1996; Ratnaparkhi, 1997; Borthwick et al., 1998; Uchimoto et al., 1999). In our maximum-entropy experiment we used Ristad&apos;s system (Ristad, 1998). The analysis is performed by calculating the probability of inserting or not inserting a partition mark, from the output of the system. Whichever probability is higher is selected as the desired answer. In the maximum-entropy method, we use the same four types of morphological information, (i) major POS, (ii) minor POS, (iii) semantic information, and (iv) word, as in the decision-tree method. However, it does not consider a combination of features. Unlike the decision-tree method, as a result w"
C00-1082,W95-0107,0,0.0509382,"hashi, for example, made 146 rules for bunsetsu identi cation (Kurohashi, 1998). In an attempt to reduce the number of manhours, we used machine-learning methods for bunsetsu identi cation. Because it was not clear which machine-learning method would be the one most appropriate for bunsetsu identi cation, so we tried a variety of them. In this paper we report experiments comparing four machine-learning methods (decision tree, maximum entropy, example-based, and decision list methods) and our new methods using category-exclusive rules. 1 Bunsetsu identi cation is a problem similar to chunking (Ramshaw and Marcus, 1995; Sang and Veenstra, 1999) in other languages. 2 Bunsetsu identi cation problem We conducted experiments on the following supervised learning methods for identifying bunsetsu:  Decision tree method  Maximum entropy method  Example-based method (use of similarity)  Decision list (use of probability and frequency)  Method 1 (use of exclusive rules)  Method 2 (use of exclusive rules with the highest similarity). In general, bunsetsu identi cation is done after morphological and before syntactic analysis. Morphological analysis corresponds to part-of-speech tagging in English. Japanese synta"
C00-1082,W96-0213,0,0.0136307,"major POS, (ii) minor POS, (iii) semantic information, and (iv) word, mentioned in the previous section were also used as features with the decision-tree learning method. As shown in Figure 3, the number of features is 12 (2 + 4 + 4 + 2) because we do not use (iii) semantic information and (iv) word information from the two outside morphemes. In Figure 2, for example, the value of the feature `the major POS of the far left morpheme&apos; is `Noun.&apos; 3.2 Maximum-entropy method The maximum-entropy method is useful with sparse data conditions and has been used by many researchers (Berger et al., 1996; Ratnaparkhi, 1996; Ratnaparkhi, 1997; Borthwick et al., 1998; Uchimoto et al., 1999). In our maximum-entropy experiment we used Ristad&apos;s system (Ristad, 1998). The analysis is performed by calculating the probability of inserting or not inserting a partition mark, from the output of the system. Whichever probability is higher is selected as the desired answer. In the maximum-entropy method, we use the same four types of morphological information, (i) major POS, (ii) minor POS, (iii) semantic information, and (iv) word, as in the decision-tree method. However, it does not consider a combination of features. Unl"
C00-1082,W97-0301,0,0.0125915,"or POS, (iii) semantic information, and (iv) word, mentioned in the previous section were also used as features with the decision-tree learning method. As shown in Figure 3, the number of features is 12 (2 + 4 + 4 + 2) because we do not use (iii) semantic information and (iv) word information from the two outside morphemes. In Figure 2, for example, the value of the feature `the major POS of the far left morpheme&apos; is `Noun.&apos; 3.2 Maximum-entropy method The maximum-entropy method is useful with sparse data conditions and has been used by many researchers (Berger et al., 1996; Ratnaparkhi, 1996; Ratnaparkhi, 1997; Borthwick et al., 1998; Uchimoto et al., 1999). In our maximum-entropy experiment we used Ristad&apos;s system (Ristad, 1998). The analysis is performed by calculating the probability of inserting or not inserting a partition mark, from the output of the system. Whichever probability is higher is selected as the desired answer. In the maximum-entropy method, we use the same four types of morphological information, (i) major POS, (ii) minor POS, (iii) semantic information, and (iv) word, as in the decision-tree method. However, it does not consider a combination of features. Unlike the decision-tr"
C00-1082,E99-1023,0,0.0134246,"46 rules for bunsetsu identi cation (Kurohashi, 1998). In an attempt to reduce the number of manhours, we used machine-learning methods for bunsetsu identi cation. Because it was not clear which machine-learning method would be the one most appropriate for bunsetsu identi cation, so we tried a variety of them. In this paper we report experiments comparing four machine-learning methods (decision tree, maximum entropy, example-based, and decision list methods) and our new methods using category-exclusive rules. 1 Bunsetsu identi cation is a problem similar to chunking (Ramshaw and Marcus, 1995; Sang and Veenstra, 1999) in other languages. 2 Bunsetsu identi cation problem We conducted experiments on the following supervised learning methods for identifying bunsetsu:  Decision tree method  Maximum entropy method  Example-based method (use of similarity)  Decision list (use of probability and frequency)  Method 1 (use of exclusive rules)  Method 2 (use of exclusive rules with the highest similarity). In general, bunsetsu identi cation is done after morphological and before syntactic analysis. Morphological analysis corresponds to part-of-speech tagging in English. Japanese syntactic structures are usuall"
C00-1082,E99-1026,1,0.925638,"t for analyzing Japanese sentences. In experiments comparing the four previously available machinelearning methods (decision tree, maximum-entropy method, example-based approach and decision list) and two new methods using category-exclusive rules, the new method using the category-exclusive rules with the highest similarity performed best. 1 Introduction This paper is about machine learning methods for identifying bunsetsus, which correspond to English phrasal units such as noun phrases and prepositional phrases. Since Japanese syntactic analysis is usually done after bunsetsu identi cation (Uchimoto et al., 1999), identifying bunsetsu is important for analyzing Japanese sentences. The conventional studies on bunsetsu identi cation1 have used hand-made rules (Kameda, 1995; Kurohashi, 1998), but bunsetsu identi cation is not an easy task. Conventional studies used many hand-made rules developed at the cost of many man-hours. Kurohashi, for example, made 146 rules for bunsetsu identi cation (Kurohashi, 1998). In an attempt to reduce the number of manhours, we used machine-learning methods for bunsetsu identi cation. Because it was not clear which machine-learning method would be the one most appropriate"
C00-1082,P94-1013,0,0.0437241,"| Symbol Punctuation 2 2 Figure 5: Example of levels of similarity but are expanded by combining all the features, and are stored in a one-dimensional list. A priority order is de ned in a certain way and all of the rules are arranged in this order. The decision-list method searches for rules from the top of the list and analyzes a particular problem by using only the rst applicable rule. In this study we used in the decision-list method the same 152 types of patterns that were used in the maximum-entropy method. To determine the priority order of the rules, we referred to Yarowsky&apos;s method (Yarowsky, 1994) and Nishiokayama&apos;s method (Nishiokayama et al., 1998) and used the probability and frequency of each rule as measures of this priority order. When multiple rules had the same probability, the rules were arranged in order of their frequency. Suppose, for example, that Pattern A Noun: Normal Noun; Particle: Case-Particle: none: wo; Verb: Normal Form: 217; Symbol: Punctuation&quot; occurs 13 times in a learning set and that ten of the occurrences include the inserted partition mark. Suppose also that Pattern B Noun; Particle; Verb; Symbol&quot; occurs 123 times in a learning set and that 90 of the occur"
C00-2109,W98-1512,0,0.0643188,"Missing"
C00-2109,W98-1510,0,\N,Missing
C00-2109,E99-1026,1,\N,Missing
C00-2109,P97-1003,0,\N,Missing
C00-2109,P98-1083,0,\N,Missing
C00-2109,C98-1080,0,\N,Missing
C00-2109,P95-1037,0,\N,Missing
C00-2109,W98-1511,0,\N,Missing
C00-2126,J96-1002,0,\N,Missing
C00-2126,P99-1018,0,\N,Missing
C00-2128,P99-1008,0,0.0150643,"in corpora, i.e. noun phrases of the form A no B can be found in corpora but their semantic relations are not. If we need such semantic relations, we must semantically analyze the noun phrases (Kurohashi and Sakai, 1999). Applicability to other languages Japanese noun phrases of the form A no B are specific to Japanese. The proposed method, however, could easily be extended to other languages. For example, in English, noun phrases B of A could be used to extract semantically related nouns. Nouns related by is-a relations or part-of relations could also be extracted from corpora (Hearst, 1992; Berland and Charniak, 1999). If such semantically related nouns are extracted, Candidates beer, cola, mizu (water) yu (hot water), oyu (hot water), nettˆo (boiling water) zyˆoyˆ osya (car), best seller, kuruma (vehicle) e (painting), image,aizin (lover) gensaku (original work), meisaku (famous story), daihyˆosaku (important work) menuetto (minuet), kyoku (music), piano si (poem), tyosyo (writings), tyosaku (writings) care,kyˆ usoku (rest), kaigo (nursing) hito (person),tomodati (friend), byˆonin (sick person) Nihon (Japan),ziko (accident), kigyˆo (company) zikanho (assistant vice-minister), seikai (political world), gik"
C00-2128,C96-1025,0,0.271611,"rocessing applications, especially for machine translation (Kamei and Wakao, 1992; Fass, 1997). A metonymy may be acceptable in a source language but unacceptable in a target language. For example, a direct translation of ‘he read Mao’, which is acceptable in English and Japanese, is completely unacceptable in Chinese (Kamei and Wakao, 1992). In such cases, the machine translation system has to interpret metonymies to generate acceptable translations. Previous approaches to processing metonymy have used hand-constructed ontologies or semantic networks (Fass, 1988; Iverson and Helmreich, 1992; Bouaud et al., 1996; Fass, 1997).1 1 As for metaphor processing, Ferrari (1996) used texSuch approaches are restricted by the knowledge bases they use, and may only be applicable to domain-specific tasks because the construction of large knowledge bases could be very difficult. The method outlined in this paper, on the other hand, uses corpus statistics to interpret metonymy, so that a variety of metonymies can be handled without using hand-constructed knowledge bases. The method is quite promising as shown by the experimental results given in section 5. 2 Recognition and Interpretation Two main steps, recogniti"
C00-2128,J92-4003,0,0.0133448,"below).3 Examples of these and similar types of metonymic concepts (Lakoff and Johnson, 1980; Fass, 1997) are given below. Container for contents • glass no mizu (water) • nabe (pot) no ryˆ ori (food) Artist for artform • Beethoven no kyoku (music) • Picasso no e (painting) Object for user • ham sandwich no kyaku (customer) • sax no sˆosya (performer) Whole for part • kuruma (car) no tire Information Source We use a large corpus to extract nouns which can be syntactically related to the explicit term of a metonymy. A large corpus is valuable as a source of such nouns (Church and Hanks, 1990; Brown et al., 1992). We used Japanese noun phrases of the form A no B to extract nouns that were syntactically related to A. Nouns in such a syntactic relation are usually close semantic relatives of each other (Murata et al., 1999), and occur relatively infrequently. We thus also used an A near B relation, i.e. identifying the other nouns within the target sentence, to extract nouns that may be more loosely related to A, but occur more frequently. These two types of syntactic relation are treated differently by the statistical measure which we will discuss in section 4. The Japanese noun phrase A no B roughly c"
C00-2128,J90-1003,0,0.0136441,"s and artist for artform below).3 Examples of these and similar types of metonymic concepts (Lakoff and Johnson, 1980; Fass, 1997) are given below. Container for contents • glass no mizu (water) • nabe (pot) no ryˆ ori (food) Artist for artform • Beethoven no kyoku (music) • Picasso no e (painting) Object for user • ham sandwich no kyaku (customer) • sax no sˆosya (performer) Whole for part • kuruma (car) no tire Information Source We use a large corpus to extract nouns which can be syntactically related to the explicit term of a metonymy. A large corpus is valuable as a source of such nouns (Church and Hanks, 1990; Brown et al., 1992). We used Japanese noun phrases of the form A no B to extract nouns that were syntactically related to A. Nouns in such a syntactic relation are usually close semantic relatives of each other (Murata et al., 1999), and occur relatively infrequently. We thus also used an A near B relation, i.e. identifying the other nouns within the target sentence, to extract nouns that may be more loosely related to A, but occur more frequently. These two types of syntactic relation are treated differently by the statistical measure which we will discuss in section 4. The Japanese noun ph"
C00-2128,C88-1036,0,0.0563287,"metonymy is vital for natural language processing applications, especially for machine translation (Kamei and Wakao, 1992; Fass, 1997). A metonymy may be acceptable in a source language but unacceptable in a target language. For example, a direct translation of ‘he read Mao’, which is acceptable in English and Japanese, is completely unacceptable in Chinese (Kamei and Wakao, 1992). In such cases, the machine translation system has to interpret metonymies to generate acceptable translations. Previous approaches to processing metonymy have used hand-constructed ontologies or semantic networks (Fass, 1988; Iverson and Helmreich, 1992; Bouaud et al., 1996; Fass, 1997).1 1 As for metaphor processing, Ferrari (1996) used texSuch approaches are restricted by the knowledge bases they use, and may only be applicable to domain-specific tasks because the construction of large knowledge bases could be very difficult. The method outlined in this paper, on the other hand, uses corpus statistics to interpret metonymy, so that a variety of metonymies can be handled without using hand-constructed knowledge bases. The method is quite promising as shown by the experimental results given in section 5. 2 Recogn"
C00-2128,P96-1048,0,0.0173931,"and Wakao, 1992; Fass, 1997). A metonymy may be acceptable in a source language but unacceptable in a target language. For example, a direct translation of ‘he read Mao’, which is acceptable in English and Japanese, is completely unacceptable in Chinese (Kamei and Wakao, 1992). In such cases, the machine translation system has to interpret metonymies to generate acceptable translations. Previous approaches to processing metonymy have used hand-constructed ontologies or semantic networks (Fass, 1988; Iverson and Helmreich, 1992; Bouaud et al., 1996; Fass, 1997).1 1 As for metaphor processing, Ferrari (1996) used texSuch approaches are restricted by the knowledge bases they use, and may only be applicable to domain-specific tasks because the construction of large knowledge bases could be very difficult. The method outlined in this paper, on the other hand, uses corpus statistics to interpret metonymy, so that a variety of metonymies can be handled without using hand-constructed knowledge bases. The method is quite promising as shown by the experimental results given in section 5. 2 Recognition and Interpretation Two main steps, recognition and interpretation, are involved in the processing of met"
C00-2128,C92-2082,0,0.00414663,"tly expressed in corpora, i.e. noun phrases of the form A no B can be found in corpora but their semantic relations are not. If we need such semantic relations, we must semantically analyze the noun phrases (Kurohashi and Sakai, 1999). Applicability to other languages Japanese noun phrases of the form A no B are specific to Japanese. The proposed method, however, could easily be extended to other languages. For example, in English, noun phrases B of A could be used to extract semantically related nouns. Nouns related by is-a relations or part-of relations could also be extracted from corpora (Hearst, 1992; Berland and Charniak, 1999). If such semantically related nouns are extracted, Candidates beer, cola, mizu (water) yu (hot water), oyu (hot water), nettˆo (boiling water) zyˆoyˆ osya (car), best seller, kuruma (vehicle) e (painting), image,aizin (lover) gensaku (original work), meisaku (famous story), daihyˆosaku (important work) menuetto (minuet), kyoku (music), piano si (poem), tyosyo (writings), tyosaku (writings) care,kyˆ usoku (rest), kaigo (nursing) hito (person),tomodati (friend), byˆonin (sick person) Nihon (Japan),ziko (accident), kigyˆo (company) zikanho (assistant vice-minister),"
C00-2128,P92-1047,0,0.423418,"on Metonymy is a figure of speech in which the name of one thing is substituted for that of something to which it is related. The explicit term is ‘the name of one thing’ and the implicit term is ’the name of something to which it is related’. A typical example of metonymy is He read Shakespeare. (1) ‘Shakespeare’ is substituted for ‘the works of Shakespeare’. ‘Shakespeare’ is the explicit term and ‘works’ is the implicit term. Metonymy is pervasive in natural language. The correct treatment of metonymy is vital for natural language processing applications, especially for machine translation (Kamei and Wakao, 1992; Fass, 1997). A metonymy may be acceptable in a source language but unacceptable in a target language. For example, a direct translation of ‘he read Mao’, which is acceptable in English and Japanese, is completely unacceptable in Chinese (Kamei and Wakao, 1992). In such cases, the machine translation system has to interpret metonymies to generate acceptable translations. Previous approaches to processing metonymy have used hand-constructed ontologies or semantic networks (Fass, 1988; Iverson and Helmreich, 1992; Bouaud et al., 1996; Fass, 1997).1 1 As for metaphor processing, Ferrari (1996) u"
C00-2128,P99-1062,0,0.0621513,"lly related to A. Nouns in such a syntactic relation are usually close semantic relatives of each other (Murata et al., 1999), and occur relatively infrequently. We thus also used an A near B relation, i.e. identifying the other nouns within the target sentence, to extract nouns that may be more loosely related to A, but occur more frequently. These two types of syntactic relation are treated differently by the statistical measure which we will discuss in section 4. The Japanese noun phrase A no B roughly corresponds to the English noun phrase B of A, but it has a much broader range of usage (Kurohashi and Sakai, 1999). In fact, A no B can express most of the possible types of semantic relation between two nouns including metonymic • door no knob These examples suggest that we can extract semantically related nouns by using the A no B relation. 4 Statistical Measure A metonymy ‘Noun A Case-Marker R Predicate V ’ can be regarded as a contraction of ‘Noun A Syntactic-Relation Q Noun B CaseMarker R Predicate V ’, where A has relation Q to B (Yamamoto et al., 1998). For example, Shakespeare wo yomu (read) (read Shakespeare) is regarded as a contraction of Shakespeare no sakuhin (works) wo yomu (read the works o"
C00-2128,W99-0205,1,0.768329,"artform • Beethoven no kyoku (music) • Picasso no e (painting) Object for user • ham sandwich no kyaku (customer) • sax no sˆosya (performer) Whole for part • kuruma (car) no tire Information Source We use a large corpus to extract nouns which can be syntactically related to the explicit term of a metonymy. A large corpus is valuable as a source of such nouns (Church and Hanks, 1990; Brown et al., 1992). We used Japanese noun phrases of the form A no B to extract nouns that were syntactically related to A. Nouns in such a syntactic relation are usually close semantic relatives of each other (Murata et al., 1999), and occur relatively infrequently. We thus also used an A near B relation, i.e. identifying the other nouns within the target sentence, to extract nouns that may be more loosely related to A, but occur more frequently. These two types of syntactic relation are treated differently by the statistical measure which we will discuss in section 4. The Japanese noun phrase A no B roughly corresponds to the English noun phrase B of A, but it has a much broader range of usage (Kurohashi and Sakai, 1999). In fact, A no B can express most of the possible types of semantic relation between two nouns inc"
C02-1060,P94-1038,0,\N,Missing
C02-1060,P93-1022,0,\N,Missing
C02-1060,P90-1034,0,\N,Missing
C02-1060,P97-1009,0,\N,Missing
C02-1060,P98-2148,0,\N,Missing
C02-1060,C98-2143,0,\N,Missing
C02-1064,C00-1007,0,0.0708941,"ndidate-text sentences or word lattices by applying rules, and apply their language model, an n-gram model, to select the most appropriate surface text. While we cannot use their rules to generate candidate-text sentences when given keywords, we can apply their language model to our system to generate surface-text sentences from candidate-text sentences in the form of dependency trees. We can also apply the formalism proposed by Langkilde (Langkilde, 2000) to express the candidate-text sentences. Bangalore and Rambow proposed a method to generate candidate-text sentences in the form of trees (Bangalore and Rambow, 2000). They consider dependency information when deriving trees by using XTAG grammar, but they assume that the input contains dependency information. Our system generates candidate-text sentences without relying on dependency information in the input, and our model estimates the dependencies between keywords. Ratnaparkhi proposed models to generate text from semantic attributes (Ratnaparkhi, 2000). The input of these models is semantic attributes. His models are similar to ours if the semantic attributes are replaced with keywords. However, his models need a training corpus in which certain words"
C02-1064,J96-1002,0,0.00733679,"n bunsetsus. 4. posterior dependency bigram model We assume that ki depends only on the headword, ws , and the word on its right, ws+1 , in the bunsetsu that is modiﬁed by the bunsetsu including ki (see Fig. 3). Text-Generation Model We next describe the model represented by Eq. (4); that is, a keyword-production model, a morpheme model that estimates how likely a string is to be a morpheme, and a dependency model. The goal of this model is to select optimal sets of morphemes and dependencies that can generate natural sentences. We implemented these models within an maximum entropy framework (Berger et al., 1996; Ristad, 1997; Ristad, 1998). 4.1 Keyword-Production Models This section describes ﬁve keyword-production models which are represented by P (K|M, D, T ) in Eq. (4). In these models, we deﬁne the set of headwords whose frequency in the corpus is over a certain threshold as a set of keywords, KS, and we restrict the bunsetsus to those generated by the generation rules represented in form (5). We assume that all keywords are independent and that ki corresponds to word wj (1 ≤ j ≤ m) when text is given as a series of words w1 . . . wm . 1. trigram model We assume that ki depends only on the two a"
C02-1064,J90-2002,0,0.0214748,"uction Text generation is an important technique used for applications like machine translation, summarization, and human/computer dialogue. In recent years, many corpora have become available, and have been used to generate natural surface sentences. For example, corpora have been used to generate sentences for language model estimation in statistical machine translation. In such translation, given a source language text, S, the translated text, T , in the target language that maximizes the probability P (T |S) is selected as the most appropriate translation, Tbest , which is represented as (Brown et al., 1990) Tbest = argmaxT P (T |S) = argmaxT (P (S|T ) × P (T )) . (1) In this equation, P (S|T ) represents the model used to replace words or phrases in a source language with those in the target language. It is called a translation model. P (T ) represents a language model that is used to reorder translated words or phrases into a natural order in Hitoshi Isahara† ‡ New York University 715 Broadway, 7th floor New York, NY 10003, USA sekine@cs.nyu.edu the target language. The input of the language model is a “bag of words,” and the goal of the model is basically to reorder the words. At this point, t"
C02-1064,W01-0812,0,0.0111773,"erate text from semantic attributes (Ratnaparkhi, 2000). The input of these models is semantic attributes. His models are similar to ours if the semantic attributes are replaced with keywords. However, his models need a training corpus in which certain words are replaced with semantic attributes. Although our model also needs a training corpus, the corpus can be automatically created by using a morphological analyzer and a dependency analyzer, both of which are readily available. Humphreys et al. proposed using models developed for sentence-structure analysis to rank candidate-text sentences (Humphreys et al., 2001). As well as models developed for sentence-structure analysis, we also use those developed for morphological analysis and found that these models contribute to the generation of appropriate text. Berger and Laﬀerty proposed a language model for information retrieval (Berger and Lafferty, 1999). Their concept is similar to that of our model, which can be regarded as a model that translates keywords into text, while their model can be regarded as one that translates query words into documents. However, the purpose of their model is diﬀerent: their goal is to retrieve text that already exists whi"
C02-1064,P95-1034,0,0.051106,"ed. In this section, we describe the diﬀerences between our method and several previous methods. Japanese words are often followed by postpositional particles, such as “ga” and “wo”, to indicate the subject and object of a sentence. There are no corresponding words in English. Instead, English words are preceded by articles, “the” and “a,” to distinguish definite and indeﬁnite nouns, and so on, and in this case there are no corresponding words in Japanese. Knight et al. proposed a way to compensate for missing information caused by a lack of language-dependent knowledge, or a “knowledge gap” (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998a; Langkilde and Knight, 1998b). They use semantic expressions as input, whereas we use keywords. Also, they construct candidate-text sentences or word lattices by applying rules, and apply their language model, an n-gram model, to select the most appropriate surface text. While we cannot use their rules to generate candidate-text sentences when given keywords, we can apply their language model to our system to generate surface-text sentences from candidate-text sentences in the form of dependency trees. We can also apply the formalism proposed by Langkilde (Langkil"
C02-1064,P98-1116,0,0.053813,"e diﬀerences between our method and several previous methods. Japanese words are often followed by postpositional particles, such as “ga” and “wo”, to indicate the subject and object of a sentence. There are no corresponding words in English. Instead, English words are preceded by articles, “the” and “a,” to distinguish definite and indeﬁnite nouns, and so on, and in this case there are no corresponding words in Japanese. Knight et al. proposed a way to compensate for missing information caused by a lack of language-dependent knowledge, or a “knowledge gap” (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998a; Langkilde and Knight, 1998b). They use semantic expressions as input, whereas we use keywords. Also, they construct candidate-text sentences or word lattices by applying rules, and apply their language model, an n-gram model, to select the most appropriate surface text. While we cannot use their rules to generate candidate-text sentences when given keywords, we can apply their language model to our system to generate surface-text sentences from candidate-text sentences in the form of dependency trees. We can also apply the formalism proposed by Langkilde (Langkilde, 2000) to express the can"
C02-1064,W98-1426,0,0.0486915,"e diﬀerences between our method and several previous methods. Japanese words are often followed by postpositional particles, such as “ga” and “wo”, to indicate the subject and object of a sentence. There are no corresponding words in English. Instead, English words are preceded by articles, “the” and “a,” to distinguish definite and indeﬁnite nouns, and so on, and in this case there are no corresponding words in Japanese. Knight et al. proposed a way to compensate for missing information caused by a lack of language-dependent knowledge, or a “knowledge gap” (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998a; Langkilde and Knight, 1998b). They use semantic expressions as input, whereas we use keywords. Also, they construct candidate-text sentences or word lattices by applying rules, and apply their language model, an n-gram model, to select the most appropriate surface text. While we cannot use their rules to generate candidate-text sentences when given keywords, we can apply their language model to our system to generate surface-text sentences from candidate-text sentences in the form of dependency trees. We can also apply the formalism proposed by Langkilde (Langkilde, 2000) to express the can"
C02-1064,A00-2023,0,0.031131,"u, 1995; Langkilde and Knight, 1998a; Langkilde and Knight, 1998b). They use semantic expressions as input, whereas we use keywords. Also, they construct candidate-text sentences or word lattices by applying rules, and apply their language model, an n-gram model, to select the most appropriate surface text. While we cannot use their rules to generate candidate-text sentences when given keywords, we can apply their language model to our system to generate surface-text sentences from candidate-text sentences in the form of dependency trees. We can also apply the formalism proposed by Langkilde (Langkilde, 2000) to express the candidate-text sentences. Bangalore and Rambow proposed a method to generate candidate-text sentences in the form of trees (Bangalore and Rambow, 2000). They consider dependency information when deriving trees by using XTAG grammar, but they assume that the input contains dependency information. Our system generates candidate-text sentences without relying on dependency information in the input, and our model estimates the dependencies between keywords. Ratnaparkhi proposed models to generate text from semantic attributes (Ratnaparkhi, 2000). The input of these models is semant"
C02-1064,A00-2026,0,0.0407408,"y the formalism proposed by Langkilde (Langkilde, 2000) to express the candidate-text sentences. Bangalore and Rambow proposed a method to generate candidate-text sentences in the form of trees (Bangalore and Rambow, 2000). They consider dependency information when deriving trees by using XTAG grammar, but they assume that the input contains dependency information. Our system generates candidate-text sentences without relying on dependency information in the input, and our model estimates the dependencies between keywords. Ratnaparkhi proposed models to generate text from semantic attributes (Ratnaparkhi, 2000). The input of these models is semantic attributes. His models are similar to ours if the semantic attributes are replaced with keywords. However, his models need a training corpus in which certain words are replaced with semantic attributes. Although our model also needs a training corpus, the corpus can be automatically created by using a morphological analyzer and a dependency analyzer, both of which are readily available. Humphreys et al. proposed using models developed for sentence-structure analysis to rank candidate-text sentences (Humphreys et al., 2001). As well as models developed fo"
C02-1064,E99-1026,1,0.849331,"appropriate. We used headwords that were found ﬁve times or more in the newspaper articles appearing from January 1st to 16th in the Kyoto University text corpus and also found in those appearing on January 1st as the set of headwords, KS. For headwords that were not in KS, we added their major part-of-speech categories to the set. We trained our keyword-production models by using 1,129 sentences (containing 10,201 headwords) from newspaper articles appearing on January 1st. We used a morpheme model and a dependency model identical to those proposed by Uchimoto et al. (Uchimoto et al., 2001; Uchimoto et al., 1999; Uchimoto et al., 2000b). To train the models, we used 8,835 sentences from newspaper articles appearing from January 1st to 9th in 1995. Generation rules were acquired from newspaper articles appearing from January 1st to 16th. The total number of sentences was 18,435. First, we evaluated the outputs generated when the rightmost two keywords, such as “連 覇 and 達成,” on each line of Table 1 were input. Table 2 shows the results. KM1 through KM5 stand for the ﬁve keyword-production models described in Section 4.1, and MM and DM stand for the morpheme and the dependency models, respectively. The"
C02-1064,C00-2126,1,0.918068,"eadwords that were found ﬁve times or more in the newspaper articles appearing from January 1st to 16th in the Kyoto University text corpus and also found in those appearing on January 1st as the set of headwords, KS. For headwords that were not in KS, we added their major part-of-speech categories to the set. We trained our keyword-production models by using 1,129 sentences (containing 10,201 headwords) from newspaper articles appearing on January 1st. We used a morpheme model and a dependency model identical to those proposed by Uchimoto et al. (Uchimoto et al., 2001; Uchimoto et al., 1999; Uchimoto et al., 2000b). To train the models, we used 8,835 sentences from newspaper articles appearing from January 1st to 9th in 1995. Generation rules were acquired from newspaper articles appearing from January 1st to 16th. The total number of sentences was 18,435. First, we evaluated the outputs generated when the rightmost two keywords, such as “連 覇 and 達成,” on each line of Table 1 were input. Table 2 shows the results. KM1 through KM5 stand for the ﬁve keyword-production models described in Section 4.1, and MM and DM stand for the morpheme and the dependency models, respectively. The symbol + indicates a co"
C02-1064,2000.iwpt-1.43,1,0.881498,"eadwords that were found ﬁve times or more in the newspaper articles appearing from January 1st to 16th in the Kyoto University text corpus and also found in those appearing on January 1st as the set of headwords, KS. For headwords that were not in KS, we added their major part-of-speech categories to the set. We trained our keyword-production models by using 1,129 sentences (containing 10,201 headwords) from newspaper articles appearing on January 1st. We used a morpheme model and a dependency model identical to those proposed by Uchimoto et al. (Uchimoto et al., 2001; Uchimoto et al., 1999; Uchimoto et al., 2000b). To train the models, we used 8,835 sentences from newspaper articles appearing from January 1st to 9th in 1995. Generation rules were acquired from newspaper articles appearing from January 1st to 16th. The total number of sentences was 18,435. First, we evaluated the outputs generated when the rightmost two keywords, such as “連 覇 and 達成,” on each line of Table 1 were input. Table 2 shows the results. KM1 through KM5 stand for the ﬁve keyword-production models described in Section 4.1, and MM and DM stand for the morpheme and the dependency models, respectively. The symbol + indicates a co"
C02-1064,W01-0512,1,0.834673,"priate, it is judged as appropriate. We used headwords that were found ﬁve times or more in the newspaper articles appearing from January 1st to 16th in the Kyoto University text corpus and also found in those appearing on January 1st as the set of headwords, KS. For headwords that were not in KS, we added their major part-of-speech categories to the set. We trained our keyword-production models by using 1,129 sentences (containing 10,201 headwords) from newspaper articles appearing on January 1st. We used a morpheme model and a dependency model identical to those proposed by Uchimoto et al. (Uchimoto et al., 2001; Uchimoto et al., 1999; Uchimoto et al., 2000b). To train the models, we used 8,835 sentences from newspaper articles appearing from January 1st to 9th in 1995. Generation rules were acquired from newspaper articles appearing from January 1st to 16th. The total number of sentences was 18,435. First, we evaluated the outputs generated when the rightmost two keywords, such as “連 覇 and 達成,” on each line of Table 1 were input. Table 2 shows the results. KM1 through KM5 stand for the ﬁve keyword-production models described in Section 4.1, and MM and DM stand for the morpheme and the dependency mod"
C02-1064,C98-1112,0,\N,Missing
C02-2019,maekawa-etal-2000-spontaneous,1,0.820306,"ethod to tag a spontaneous speech corpus. Their method uses a model that can not only consult a dictionary but can also identify unknown words by learning certain characteristics. To learn these characteristics, we focused on such information as whether or not a string is found in a dictionary and what types of characters are used in a string. The model estimates how likely a string is to be a morpheme. This model is independent of the domain of corpora; in this paper we demonstrate that this is true by applying our model to the spontaneous speech corpus, Corpus of Spontaneous Japanese (CSJ) (Maekawa et al., 2000). We also show that a dictionary developed for a corpus on a certain domain is helpful for improving accuracy in analyzing a corpus on another domain. 2 A Morpheme Model This section describes a model which estimates how likely a string is to be a morpheme. We implemented this model within an M.E. framework. Given a tokenized test corpus, the problem of Japanese morphological analysis can be reduced to the problem of assigning one of two tags to each string in a sentence. A string is tagged with a 1 or a 0 to indicate whether or not it is a morpheme. When a string is a morpheme, a grammatical"
C02-2019,C96-2202,0,0.317545,"Japanese sentence analysis. A morpheme is a minimal grammatical unit, such as a word or a suﬃx, and morphological analysis is the process of segmenting a given sentence into a row of morphemes and assigning to each morpheme grammatical attributes such as part-of-speech (POS) and inﬂection type. One of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither a dictionary nor a training corpus. Two statistical approaches have been applied to this problem. One is to ﬁnd unknown words from corpora and put them into a dictionary (e.g., (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). Uchimoto et al. used both approaches. They proposed a morphological analysis method based on a maximum entropy (M.E.) model (Uchimoto et al., 2001). We used their method to tag a spontaneous speech corpus. Their method uses a model that can not only consult a dictionary but can also identify unknown words by learning certain characteristics. To learn these characteristics, we focused on such information as whether or not a string is found in a dictionary and what typ"
C02-2019,P99-1036,0,0.261165,"ess of segmenting a given sentence into a row of morphemes and assigning to each morpheme grammatical attributes such as part-of-speech (POS) and inﬂection type. One of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither a dictionary nor a training corpus. Two statistical approaches have been applied to this problem. One is to ﬁnd unknown words from corpora and put them into a dictionary (e.g., (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). Uchimoto et al. used both approaches. They proposed a morphological analysis method based on a maximum entropy (M.E.) model (Uchimoto et al., 2001). We used their method to tag a spontaneous speech corpus. Their method uses a model that can not only consult a dictionary but can also identify unknown words by learning certain characteristics. To learn these characteristics, we focused on such information as whether or not a string is found in a dictionary and what types of characters are used in a string. The model estimates how likely a string is to be a morpheme. This model is independent"
C02-2019,W01-0512,1,0.81887,"and inﬂection type. One of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither a dictionary nor a training corpus. Two statistical approaches have been applied to this problem. One is to ﬁnd unknown words from corpora and put them into a dictionary (e.g., (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). Uchimoto et al. used both approaches. They proposed a morphological analysis method based on a maximum entropy (M.E.) model (Uchimoto et al., 2001). We used their method to tag a spontaneous speech corpus. Their method uses a model that can not only consult a dictionary but can also identify unknown words by learning certain characteristics. To learn these characteristics, we focused on such information as whether or not a string is found in a dictionary and what types of characters are used in a string. The model estimates how likely a string is to be a morpheme. This model is independent of the domain of corpora; in this paper we demonstrate that this is true by applying our model to the spontaneous speech corpus, Corpus of Spontaneous"
C02-2019,J96-1002,0,\N,Missing
C04-1159,P96-1025,0,0.0898547,"ependency is represented by a probability estimated by a dependency probability model. Given sentence S, let us assume that it is uniquely divided into n bunsetsus, b1 , . . . , bn , and that it is represented as an ordered set of bunsetsus, B = {b1 , . . . , bn }. Let D be an ordered set of dependencies in the sentence and let Di be a dependency whose modiﬁer is bunsetsu bi (i = 1, . . . , n − 1). Let us also assume that D = {D1 , . . . , Dn−1 }. Statistical dependency structure analysis ﬁnds dependencies that maximize probability P (D|S) given sentence S. The conventional statistical model (Collins, 1996; Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999) uses only the relationship between two bunsetsus to estimate the probability of dependency, whereas the model in this study (Uchimoto et al., 2000) takes into account not only the relationship between two bunsetsus but also the relationship between the left bunsetsu and all the bunsetsus to its right. This model uses more information than the conventional model. We implemented this model within a maximum entropy modeling framework. The features used in the model were basically attributes of bunsetsus, such as character st"
C04-1159,W98-1511,0,0.65108,"is a big diﬀerence between a written text corpus and a spontaneous speech corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence"
C04-1159,P98-1083,0,0.545732,"a written text corpus and a spontaneous speech corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be"
C04-1159,W00-1303,0,0.079418,"us speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or during dependency structure analysis in order to obta"
C04-1159,N01-1025,0,0.0382378,"e extracted as sentence boundary candidates. So, an output sequence is selected from all possible conversion patterns generated using two words to the left and two words to the right of each sentence boundary candidate. To perform this operation, we used a beam search with a width of 10 because a number of conversion patterns can be generated with such a search. 3.4 Sentence Boundary Detection Based on Machine Learning (Method 2) We use Support Vector Machine (SVM) as a machine learning model and we approached the problem of sentence boundary detection as a text chunking task. We used YamCha (Kudo and Matsumoto, 2001) as a text chunker, which is based on SVM and uses polynomial kernel functions. To determine the appropriate chunk label for a target word, YamCha uses two words to the right and two words to the left of the We used the IOE labeling scheme for proper chunking, and the following parameters for YamCha. • Degree of polynomial kernel: 3rd • Analysis direction: Left to right • Multi-class method: Pairwise 4 Experiments and Discussion In our experiments, we used the transcriptions of 188 talks in the CSJ. We used 10 talks for testing. Dependency structure analysis results were evaluated for closed-"
C04-1159,maekawa-etal-2000-spontaneous,1,0.878846,"Missing"
C04-1159,C02-1136,0,0.184882,"were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or during dependency structure analysis in order to obtain the dependency structure of each sentence. In this paper, we ﬁrst describe the problems with dependency structure ana"
C04-1159,E99-1026,1,0.947104,"and a spontaneous speech corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or dur"
C04-1159,2000.iwpt-1.43,1,0.944091,"ch corpus: In spontaneous speech, especially when it is long, sentence boundaries are often ambiguous. In the CSJ, therefore, sentence boundaries were deﬁned based on clauses whose boundaries were automatically detected by using surface information (Maruyama et al., 2003), and they were detected manually (Takanashi et al., 2003). Our deﬁnition of sentence boundaries follows the deﬁnition used in the CSJ. Almost all previous research on Japanese dependency structure analysis dealt with dependency structures in written text (Fujio and Matsumoto, 1998; Haruno et al., 1998; Uchimoto et al., 1999; Uchimoto et al., 2000; Kudo and Matsumoto, 2000). Although Matsubara and colleagues did investigate dependency structures in spontaneous speech (Matsubara et al., 2002), the target speech was dialogues where the utterances were short and sentence boundaries could be easily deﬁned based on turn-taking data. In contrast, we investigated dependency structures in spontaneous and long speeches in the CSJ. The biggest problem in dependency structure analysis with spontaneous and long speeches is that sentence boundaries are ambiguous. Therefore, sentence boundaries should be detected before or during dependency structur"
C04-1159,A97-1004,0,\N,Missing
C04-1159,C98-1080,0,\N,Missing
C04-1165,P90-1034,0,0.139456,"ocused on classifying the semantic relationship between abstract nouns and adjectives (Nemoto 1969, Takahashi 1975). We constructed linguistic data by extracting semantic relations between abstract nouns and adjectives from corpus data and classifying abstract nouns based on adjective similarity using a self-organizing semantic map (SOM), which is a neural network model (Kohonen 1995). The relative proximity of words in the semantic map indicates their relative similarity. In previous research, word meanings have been statistically modeled based on syntactic information derived from a corpus. Hindle (1990) used noun-verb syntactic relations, and Hatzivassiloglou and McKeown (1993) used coordinated adjective-adjective modifier pairs. These methods are useful for the organization of words deep within a hierarchy, but do not seem to provide a solution for the top levels of the hierarchy. To find an objective hierarchical word structure, we utilize the complementary similarity measure (CSM), which estimates a one-to-many relation, such as superordinate–subordinate relations (Hagita and Sawaki 1995, Yamamoto and Umemura 2002). In this paper we propose an automated method for constructing adjective h"
C04-1165,W00-0110,1,0.825311,"e., the goat, and “hana (nose)” in (b) indicates part of something, i.e., the elephant. He recognized abstract nouns in (a) as a hyperonym of the attribute that the predicative adjectives express. Nemoto (1969) identified expressions such as “iro ga akai (the color is red)” and “hayasa ga hayai (the speed is fast)” as a kind of meaning repetition, or tautology. In this paper we define such abstract nouns that co-occur with adjectives as adjective hyperonyms. We semi-automatically extracted from corpora 365 abstract nouns used as this kind of head noun, according to the procedures described in Kanzaki et al. (2000). We collected abstract nouns from two year's worth of articles from the Mainichi Shinbun newspaper, and extracted adjectives co-occurring with abstract nouns in the Abstract nouns are located in the semantic map based on the similarity of co-occurring adjectives after iteratively learning over input data. In this research, we focus on abstract nouns co-occurring with adjectives. In the semantic map, there are 365 abstract nouns co-occurring with adjectives. The similarities between the 365 abstract nouns are determined according to the number of common co-occurring adjectives. We made a list"
C04-1165,P93-1023,0,\N,Missing
C08-1015,I08-1012,1,0.723879,"at the primary cause of loss from adaptation is because of differences in the annotation guidelines. Without specific knowledge of the target domain’s annotation standards, significant improvement can not be made. Reichart and Rappoport (2007) studied selftraining method for domain adaptation (The WSJ data and the Brown data) of phrase-based parsers. McClosky et al. (2006) presented a successful instance of parsing with self-training by using a reranker. Both of them used the whole sentences as newly labeled data for adapting the parsers, while our approach uses the information on word pairs. Chen et al. (2008) presented an approach by using the information of adjacent words for indomain parsing. As Figure 2 shows, the score curves of sameDomain (in-domain) parsing and diffDomain (out-domain) parsing are quite different. Our work focuses on parsing adaptation and is based on the fact that current parsers perform much better for shorter dependencies than for longer ones. This causes that our work differs in that we use the information on shorter dependencies in auto-parsed target data to help parse the words with longer distance for parsing adaptation. In this paper, “shorter” and “longer” are relati"
C08-1015,P07-1033,0,0.292809,"Missing"
C08-1015,D07-1013,0,0.0240162,"g new parsers. It is difficult to detect reliable parsed sentences, but we can find relative reliable parsed word pairs according to dependency length. The experimental results show that our approach significantly outperforms baseline system and current state of the art techniques. 2 Motivation and prior work In dependency parsing, we assign head-dependent relations between words in a sentence. A simple example is shown in Figure 1, where the arc between a and hat indicates that hat is the head of a. Current statistical dependency parsers perform better if the dependency lengthes are shorter (McDonald and Nivre, 2007). Here the length of the dependency from word wi to word w j is simply equal to |i − j|. Figure 2 shows the results (F1 113 Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 113–120 Manchester, August 2008 The boy saw a red hat an idea that the information on shorter dependencies in auto-parsed target data is reliable for parsing the words with longer distance for domain adaptation. Here, “shorter” is not exactly short. That is to say, the information on dependency length l in auto-parsed data can be used to help parse the words whose distances"
C08-1015,D07-1119,0,0.0728408,"is paper, we focus on the latter one. Current statistical dependency parsers perform worse while the distance of two words is becoming longer for domain adaptation. An important characteristic of parsing adaptation is that the parsers perform much better for shorter dependencies than for longer ones (the score at length l is much higher than the scores at length> l ). In this paper, we propose an approach by using the information on shorter dependencies in autoparsed target data to help parse longer distance words for adapting a parser. Compared with the adaptation methods of Sagae and Tsujii (2007) and Reichart and Rappoport (2007), our approach uses the information on word pairs in auto-parsed data instead of using the whole sentences as newly labeled data for training new parsers. It is difficult to detect reliable parsed sentences, but we can find relative reliable parsed word pairs according to dependency length. The experimental results show that our approach significantly outperforms baseline system and current state of the art techniques. 2 Motivation and prior work In dependency parsing, we assign head-dependent relations between words in a sentence. A simple example is shown in"
C08-1015,W06-2932,0,0.0176366,"operations: Shift, Reduce, Left-Arc, and Right-Arc, for the stack and the queue. TOP is the token on top of the stack and NEXT is next token in the queue. The Left-Arc and Right-Arc operations mean that there is a dependency relation between TOP and NEXT. The model uses a classifier to produce a sequence of actions for a sentence. In this paper, we use the SVM model. And LIBSVM(Chang and Lin, 2001) is used in our experiments. Note that the approach (see section 4)we present in this paper can also be applied to 115 other parsers, such as the parser by Yamada and Matsumoto (2003), or the one by McDonald et al. (2006). 3.2 Parsing with basic features The parser is a history-based parsing model, which relies on features of the parsed tokens to predict next parsing action. We represent basic features based on words and part-of-speech (POS) tags. The basic features are listed as follows: • Lexical Features on TOP: the word of TOP, the word of the head of TOP, and the words of leftmost and rightmost dependent of TOP. • Lexical Features on NEXT: the word of NEXT and the word of the token immediately after NEXT in the original input string. • POS features on TOP: the POS of TOP, the POS of the token immediately"
C08-1015,W06-2933,0,0.0252486,"n the fact that current parsers perform much better for shorter dependencies than for longer ones. This causes that our work differs in that we use the information on shorter dependencies in auto-parsed target data to help parse the words with longer distance for parsing adaptation. In this paper, “shorter” and “longer” are relative. Length l is relatively shorter than length l + 1, where l can be any number. 3 The parsing approach In this paper, we choose the model described by Nivre (2003) as our parsing model. It is a deterministic parser and works quite well in the sharedtask of CoNLL2006(Nivre et al., 2006). 3.1 The parsing model The Nivre (2003) model is a shift-reduce type algorithm, which uses a stack to store processed tokens and a queue to store remaining input tokens. It can perform dependency parsing in O(n) time. The dependency parsing tree is built from atomic actions in a left-to-right pass over the input. The parsing actions are defined by four operations: Shift, Reduce, Left-Arc, and Right-Arc, for the stack and the queue. TOP is the token on top of the stack and NEXT is next token in the queue. The Left-Arc and Right-Arc operations mean that there is a dependency relation between TO"
C08-1015,W03-3017,0,0.152535,"rsing and diffDomain (out-domain) parsing are quite different. Our work focuses on parsing adaptation and is based on the fact that current parsers perform much better for shorter dependencies than for longer ones. This causes that our work differs in that we use the information on shorter dependencies in auto-parsed target data to help parse the words with longer distance for parsing adaptation. In this paper, “shorter” and “longer” are relative. Length l is relatively shorter than length l + 1, where l can be any number. 3 The parsing approach In this paper, we choose the model described by Nivre (2003) as our parsing model. It is a deterministic parser and works quite well in the sharedtask of CoNLL2006(Nivre et al., 2006). 3.1 The parsing model The Nivre (2003) model is a shift-reduce type algorithm, which uses a stack to store processed tokens and a queue to store remaining input tokens. It can perform dependency parsing in O(n) time. The dependency parsing tree is built from atomic actions in a left-to-right pass over the input. The parsing actions are defined by four operations: Shift, Reduce, Left-Arc, and Right-Arc, for the stack and the queue. TOP is the token on top of the stack and"
C08-1015,P07-1078,0,0.345964,"e focus on the latter one. Current statistical dependency parsers perform worse while the distance of two words is becoming longer for domain adaptation. An important characteristic of parsing adaptation is that the parsers perform much better for shorter dependencies than for longer ones (the score at length l is much higher than the scores at length> l ). In this paper, we propose an approach by using the information on shorter dependencies in autoparsed target data to help parse longer distance words for adapting a parser. Compared with the adaptation methods of Sagae and Tsujii (2007) and Reichart and Rappoport (2007), our approach uses the information on word pairs in auto-parsed data instead of using the whole sentences as newly labeled data for training new parsers. It is difficult to detect reliable parsed sentences, but we can find relative reliable parsed word pairs according to dependency length. The experimental results show that our approach significantly outperforms baseline system and current state of the art techniques. 2 Motivation and prior work In dependency parsing, we assign head-dependent relations between words in a sentence. A simple example is shown in Figure 1, where the arc between a"
C08-1015,D07-1111,0,0.463543,"arget data. In this paper, we focus on the latter one. Current statistical dependency parsers perform worse while the distance of two words is becoming longer for domain adaptation. An important characteristic of parsing adaptation is that the parsers perform much better for shorter dependencies than for longer ones (the score at length l is much higher than the scores at length> l ). In this paper, we propose an approach by using the information on shorter dependencies in autoparsed target data to help parse longer distance words for adapting a parser. Compared with the adaptation methods of Sagae and Tsujii (2007) and Reichart and Rappoport (2007), our approach uses the information on word pairs in auto-parsed data instead of using the whole sentences as newly labeled data for training new parsers. It is difficult to detect reliable parsed sentences, but we can find relative reliable parsed word pairs according to dependency length. The experimental results show that our approach significantly outperforms baseline system and current state of the art techniques. 2 Motivation and prior work In dependency parsing, we assign head-dependent relations between words in a sentence. A simple example is shown in"
C08-1015,W03-3023,0,0.051719,"t. The parsing actions are defined by four operations: Shift, Reduce, Left-Arc, and Right-Arc, for the stack and the queue. TOP is the token on top of the stack and NEXT is next token in the queue. The Left-Arc and Right-Arc operations mean that there is a dependency relation between TOP and NEXT. The model uses a classifier to produce a sequence of actions for a sentence. In this paper, we use the SVM model. And LIBSVM(Chang and Lin, 2001) is used in our experiments. Note that the approach (see section 4)we present in this paper can also be applied to 115 other parsers, such as the parser by Yamada and Matsumoto (2003), or the one by McDonald et al. (2006). 3.2 Parsing with basic features The parser is a history-based parsing model, which relies on features of the parsed tokens to predict next parsing action. We represent basic features based on words and part-of-speech (POS) tags. The basic features are listed as follows: • Lexical Features on TOP: the word of TOP, the word of the head of TOP, and the words of leftmost and rightmost dependent of TOP. • Lexical Features on NEXT: the word of NEXT and the word of the token immediately after NEXT in the original input string. • POS features on TOP: the POS of"
C08-1015,A00-1031,0,\N,Missing
C08-1015,P06-1043,0,\N,Missing
C08-1015,D07-1112,0,\N,Missing
C08-1015,D07-1096,0,\N,Missing
C08-2030,kozawa-etal-2008-automatic,1,0.880303,"Missing"
C08-2031,N01-1025,0,0.129083,"Missing"
C08-2031,C04-1010,0,0.0620355,"Missing"
C08-2031,W95-0107,0,0.031669,"Missing"
C08-2031,E99-1023,0,0.0312358,"of wi and wj and 6. positions of wi and wj . Assuming that {i0 , i1 , i2 , i4 } are the first four tokens in the remaining input and {s0 , s1 } are the two topmost tokens on the stack, we use the default features including: 1. POS of {i0 , i1 , i2 , i3 , s0 , s1 }, 2. word form of {s0 , i0 , i1 , head(s0 )}, 3. dependency type of s0 and its leftmost and rightmost dependent and the leftmost dependent of i0 . To examine the role of base-NP chunk information in dependency parsing, we include chunk labels in the feature sets of both parsers. BaseNP chunks are represented by using the IOB2 format (Sang and Veenstra, 1999). In the first parsing model, the chunk label of the current word is added as a feature of the root model, while the chunk labels of both considered words are added in the dependency model. We also add a feature showing that both words reside in the same chunk or not to the dependency model. In the second model, we include chunk labels of {s0 , s1 , i0 , i1 , i2 , i3 } as its feature set. We use a section of completely annotated corpus consisting of 2616 sentences to experiment with dependency parsing. The sentence length ranges between 2 words to 20 words with an average of 5.68. These Thai s"
C08-2031,I05-3003,0,0.0451225,"Missing"
C08-2031,C00-2109,1,0.850505,"Missing"
C08-2031,E06-1012,0,0.0534003,"Missing"
C08-2031,N03-1028,0,0.0649361,"Missing"
C98-2127,H90-1055,0,0.0759493,"Missing"
C98-2127,W96-0102,0,0.0420088,"Missing"
C98-2127,J94-2001,0,0.284868,"Missing"
C98-2127,C94-1027,0,0.0333278,"ements are adopted in the inputs for tagging and that there are 50 POSs. The n-gram models must estimate 50 r = 7.8e + 11 n-grams, while the single-neuro tagger with the longest input uses 805 only 70,000 weights, which can be calculated by nipt • nhid + nhid • ltopt where ?~,ipt, ~Zhid, and nopt are, respectively, the number of units in the input, the hidden, and the output layers, and nhid is set to be nipt/2. T h a t neuro models require few parameters may offer another advantage: their performance is less affected by a small amount of training d a t a than that of the statistical methods (Schmid, 1994). Neuro taggers also offer last tagging compared to other models, although its training stage is longer. 5 Experimental Results The Thai corpus used in tile computer experiments contains 10,452 sentences that are randomly divided into two sets: one with 8,322 sentences for training and another with 2,130 sentences for testing. The training and testing sets contain, respectively, 22,311 and 6,7117 ambiguous words that serve as more than one POS and were used for training and testing. Because there are 47 types of POSs in Thai (Charoenporn et al., 1997), n in (6), (10), and (14) was set at 47. T"
charoenporn-etal-2006-word,J98-2002,0,\N,Missing
charoenporn-etal-2006-word,C02-1065,0,\N,Missing
charoenporn-etal-2006-word,P98-1013,0,\N,Missing
charoenporn-etal-2006-word,C98-1013,0,\N,Missing
D07-1122,P06-2013,1,0.896796,"Missing"
D07-1122,W07-2416,0,0.0297342,"stage. For four languages with different values of ROOT, we design some special features for the ROOT labeler. Then we present evaluation results and error analyses focusing on Chinese. 1 2 Two-Stage Parsing 2.1 The Unlabeled Parser Introduction The CoNLL-2007 shared tasks include two tracks: the Multilingual Track and Domain Adaptation Track(Nivre et al., 2007). We took part the Multilingual Track of all ten languages provided by the CoNLL-2007 shared task organizers(Hajiˇc et al., 2004; Aduriz et al., 2003; Mart´ı et al., 2007; Chen et al., 2003; B¨ohmov´a et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oﬂazer et al., 2003) . In this paper, we describe a two-stage parsing system consisting of an unlabeled parser and a sequence labeler, which was submitted to the Multilingual Track. At the ﬁrst stage, we use the parsing model proposed by (Nivre, 2003) to assign the arcs between the words. Then we obtain a dependency parsing tree based on the arcs. At the second stage, we use a SVM-based approach(Kudo and The unlabeled parser predicts unlabeled directed dependencies. This parser is primarily based on the parsing models de"
D07-1122,N01-1025,0,0.0441799,"duced the dependency tree y at the ﬁrst stage. In this stage, we assign a label l(i,j) to each pair. As described in (McDonald et al., 2006), we treat the labeling of dependencies as a sequence labeling problem. Suppose that we consider a head xi with dependents xj1 , ..., xjM . We then consider the labels of (i, j1), ..., (i, jM ) as a sequence. We use the model to ﬁnd the solution: lmax = arg max s(l, i, y, x) l (1) And we consider a ﬁrst-order Markov chain of labels. We used the package YamCha (V0.33)2 to implement the SVM model for labeling. YamCha is a powerful tool for sequence labeling(Kudo and Matsumoto, 2001). 2.2.2 Features for Labeling After the ﬁrst stage, we know the unlabeled dependency parsing tree for the input sentence. This information forms the basis for part of the features of the second stage. For the sequence labeler, we deﬁne the individual features, the pair features, the verb features, the neighbor features, and the position features. All the features are listed as follows: • The individual features: the FORM, the LEMMA, the CPOSTAG, the POSTAG, and the FEATS of the parent and child node. • The pair features: the direction of dependency, the combination of lemmata of the parent and"
D07-1122,W06-2932,0,0.02086,"AG of TOP and NEXT, the POSTAG of next three tokens after NEXT, the POSTAG of the token immediately before NEXT in original input string, the POSTAG of the token immediately below TOP, and the POSTAG of the token immediately after rightmost dependent of TOP. • The FEATS features: the FEATS of TOP and NEXT. But note that the ﬁelds LEMMA and FEATS are not available for all languages. with a set of ordered pairs (i, j) ∈ y in which xj is a dependent and xi is the head. We have produced the dependency tree y at the ﬁrst stage. In this stage, we assign a label l(i,j) to each pair. As described in (McDonald et al., 2006), we treat the labeling of dependencies as a sequence labeling problem. Suppose that we consider a head xi with dependents xj1 , ..., xjM . We then consider the labels of (i, j1), ..., (i, jM ) as a sequence. We use the model to ﬁnd the solution: lmax = arg max s(l, i, y, x) l (1) And we consider a ﬁrst-order Markov chain of labels. We used the package YamCha (V0.33)2 to implement the SVM model for labeling. YamCha is a powerful tool for sequence labeling(Kudo and Matsumoto, 2001). 2.2.2 Features for Labeling After the ﬁrst stage, we know the unlabeled dependency parsing tree for the input sen"
D07-1122,W06-2933,0,0.0231911,"cies. This parser is primarily based on the parsing models described by (Nivre, 2003). The algorithm makes a dependency parsing tree in one leftto-right pass over the input, and uses a stack to store the processed tokens. The behaviors of the parser are deﬁned by four elementary actions (where TOP is the token on top of the stack and NEXT is the next token in the original input string): • Left-Arc(LA): Add an arc from NEXT to TOP; pop the stack. • Right-Arc(RA): Add an arc from TOP to NEXT; push NEXT onto the stack. • Reduce(RE): Pop the stack. • Shift(SH): Push NEXT onto the stack. Although (Nivre et al., 2006) used the pseudoprojective approach to process non-projective dependencies, here we only derive projective dependency tree. We use MaltParser(Nivre et al., 2006) 1129 Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp. 1129–1133, c Prague, June 2007. 2007 Association for Computational Linguistics V0.41 to implement the unlabeled parser, and use the SVM model as the classiﬁer. More speciﬁcally, the MaltParser use LIBSVM(Chang and Lin, 2001) with a quadratic kernel and the built-in one-versusall strategy for multi-class classiﬁcation. 2.1.1 Features for Parsing The MaltParser i"
D07-1122,W03-3017,0,0.0404162,"Track(Nivre et al., 2007). We took part the Multilingual Track of all ten languages provided by the CoNLL-2007 shared task organizers(Hajiˇc et al., 2004; Aduriz et al., 2003; Mart´ı et al., 2007; Chen et al., 2003; B¨ohmov´a et al., 2003; Marcus et al., 1993; Johansson and Nugues, 2007; Prokopidis et al., 2005; Csendes et al., 2005; Montemagni et al., 2003; Oﬂazer et al., 2003) . In this paper, we describe a two-stage parsing system consisting of an unlabeled parser and a sequence labeler, which was submitted to the Multilingual Track. At the ﬁrst stage, we use the parsing model proposed by (Nivre, 2003) to assign the arcs between the words. Then we obtain a dependency parsing tree based on the arcs. At the second stage, we use a SVM-based approach(Kudo and The unlabeled parser predicts unlabeled directed dependencies. This parser is primarily based on the parsing models described by (Nivre, 2003). The algorithm makes a dependency parsing tree in one leftto-right pass over the input, and uses a stack to store the processed tokens. The behaviors of the parser are deﬁned by four elementary actions (where TOP is the token on top of the stack and NEXT is the next token in the original input strin"
D07-1122,J93-2004,0,\N,Missing
D07-1122,D07-1096,0,\N,Missing
E99-1026,W98-1512,0,0.0661847,"Missing"
E99-1026,J96-1002,0,0.112055,". Because of the statistical property, we can incorporate a beam search, an effective way of limiting the search space in a backward analysis. 0 : otherwise. Here ""has(h,z)"" is a binary function which returns true if the history h has an attribute x. We focus on attributes on a bunsetsu itself and those between bunsetsus. Section 3 will mention these attributes. Given a set of features and some training data, the maximum entropy estimation process produces a model in which every feature gi has associated with it a parameter ai. This allows us to compute the conditional probability as follows (Berger et al., 1996): P(flh) Y I iz~(h) a [ '(n'l) - ~,i I 2 The Probability Model Given a tokenization of a test corpus, the problem of dependency structure analysis in Japanese can be reduced to the problem of assigning one of two tags to each relationship which consists of two bunsetsus. A relationship could be tagged as ""0"" or ""1"" to indicate whether or not there is a dependency between the bunsetsus, respectively. The two tags form the space of ""futures"" for a maximum entropy formulation of our dependency problem between bunsetsus. A maximum entropy solution to this, or any other similar problem allows the c"
E99-1026,P96-1025,0,0.102655,"Missing"
E99-1026,W98-1511,0,0.439654,"consistent rules or assign consistent scores. • As syntactic characteristics differ across different domains, the rules have to be changed when the target domain changes. It is costly to create a new hand-made rule for each domain. At/other approach is a fully automatic corpusbased approach. This approach has the potential to overcome the problems of the rule-based approach. It automatically learns the likelihoods of dependencies from a tagged corpus and calculates the best dependencies for an input sentence. We take this approach. This approach is taken by some other systems (Collins, 1996; Fujio and Matsumoto, 1998; Haruno et ah, 1998). The parser proposed by Ratnaparkhi (Ratnaparkhi, 1997) is considered to be one of the most accurate parsers in English. Its probability estimation is based on the maximum entropy models. We also use the maximum entropy model. This model learns the weights of given features from a training corpus. The weights are calculated based on the frequencies of the features in the training data. The set of features is defined by a human. In our model, we use features of bunsetsu, such as character strings, parts of speech, and inflection types of bunsetsu, as well as information be"
E99-1026,P98-1083,0,0.271188,"eriments and the results. Then we describe some interesting statistics that we found in our experiments. Finally, we compare our work with some related systems. 3.1 R e s u l t s o f E x p e r i m e n t s The features used in our experiments are listed in Tables 1 and 2. Each row in Table 1 contains a feature type, feature values, and an experimental result that will be explained later. Each feature consists of a type and a value. The features are basically some attributes of a bunsetsu itself or those between bunsetsus. We call them 'basic features.' The list is expanded from tIaruno's list (Haruno et al., 1998). The features in the list are classified into five categories that are related to the ""Head"" part of the anterior bunsetsu (category ""a""), the '~rype"" part of the anterior bunsetsu (category ""b""), the ""Head"" part of the posterior bunsetsu (category ""c""), the '~l~ype"" part of the posterior bunsetsu (category ""d""), and the features between bunsetsus (category ""e"") respectively. The term ""Head"" basically means a rightmost content word in a bunsetsu, and the term ""Type"" basically means a function word following a ""Head"" word or an inflection type of a ""Head"" word. The terms are defined in the fol"
E99-1026,W97-0301,0,0.0805237,"Missing"
E99-1026,C98-1080,0,\N,Missing
H05-2014,2005.eamt-1.8,1,0.774145,"me recognizer using Nuance tools. Previously, the R EGULUS grammar specialization programme has only been implemented for English. In this demo, we will show how we can apply the same methodology to Japanese. Japanese is structurally a very different language from English, so it is by no means obvious that methods which work for English will be applicable in this new context: in fact, they appear to work very well. We will demo the grammars and resulting recognizers in the context of Japanese → English and Japanese → French versions of the Open Source MedSLT medical speech translation system (Bouillon et al., 2005; MedSLT, 2005). The generic problem to be solved when building any sort of recognition grammar is that syntax alone is insufficiently constraining; many of the real constraints in a given domain and use situation tend to be semantic and pragmatic in nature. The challenge is thus to include enough non-syntactic constraints in the grammar to create a language model that can support reliable domain-specific speech recognition: we sketch our solution for Japanese. The basic structure of our current general Japanese grammar is as follows. There are four main groups of rules, covering NP, PP, VP an"
H05-2014,H01-1007,0,0.0292655,"ram language model requires substantial quantities of corpus data, which is generally not available at the start of a new project. Head-to-head comparisons of class N-gram/robust and grammar-based systems also suggest that users who are familiar with system coverage get better results from grammar-based architectures (Knight et al., 2001). As a consequence, deployed spoken dialogue systems for real-world applications frequently use grammar-based methods. This is particularly the case for speech translation systems. Although leading research systems like Verbmobil and NESPOLE! (Wahlster, 2000; Lavie et al., 2001) usually employ complex architectures combining statistical and rule-based methods, successful practical examples like Phraselator and S-MINDS (Phraselator, 2005; Sehda, 2005) are typically phrasal translators with grammar-based recognizers. Voice recognition platforms like the Nuance Toolkit provide CFG-based languages for writing grammar-based language models (GLMs), but it is challenging to develop and maintain grammars consisting of large sets of ad hoc phrase-structure rules. For this reason, there has been considerable interest in developing systems that permit language models be specifi"
H05-2014,E03-2010,1,0.69704,"lop and maintain grammars consisting of large sets of ad hoc phrase-structure rules. For this reason, there has been considerable interest in developing systems that permit language models be specified in higher-level formalisms, normally some kind of unification grammar (UG), and then compile these grammars down to the low-level platform formalisms. A prominent early example of this approach is the Gemini system (Moore, 1998). Gemini raises the level of abstraction significantly, but still assumes that the grammars will be domain-dependent. In the Open Source R EGULUS project (Regulus, 2005; Rayner et al., 2003), we have taken a further step in the direction of increased abstraction, and derive all recognizers from a single linguistically motivated UG. This derivation procedure starts with a large, application-independent UG for a language. An application-specific UG is then derived using an Explanation Based Learning (EBL) specialization technique. This corpus-based specialization process is parameterized by the training corpus and operationality criteria. The training corpus, which can be relatively small, consists of examples of utterances that should be recognized by the target application. The s"
I05-1031,P00-1064,0,0.0595142,"Missing"
I05-1031,N04-4008,0,0.0372856,"Missing"
I05-1031,C02-1162,0,0.0573564,"Missing"
I05-1031,O05-2003,0,0.0572515,"Missing"
I05-1031,1997.mtsummit-workshop.7,0,0.0704653,"Missing"
I05-1031,C96-2195,0,0.0715933,"Missing"
I05-1031,C04-1164,0,\N,Missing
I05-2015,J97-2004,0,0.0332403,"he annotated data to improve the performance of automatic word alignment. We will also investigate a method to automatically identify phrase alignments from the annotated word alignment and a method to automatically discover the syntactic structures on the Chinese side from the annotated phrase alignments. Annotation of word alignment Since automatic word alignment techniques cannot reach as high a level as the morphological analyses, we adopt a practical method of using multiple aligners. One aligner is a lexical knowledge-based approach, which was implemented by us based on the work of Ker (Ker and Chang, 1997). Another aligner is the well-known GIZA++ toolkit, which is a statistics-based approach. For GIZA++, two directions were adopted: the Chinese sentences were used as source sentences and the Japanese sentences as target sentences, and vice versa. The results produced by the lexical knowledgebased aligner, C → J of GIZA++, and J → C of GIZA++ were selected in a majority decision. If an alignment result was produced by two or three aligners at the same time, the result was accepted. Otherwise, was abandoned. In this way, we aimed to utilize the results of each aligner and maintain high precision"
I05-2015,maekawa-etal-2000-spontaneous,1,0.909793,"Missing"
I05-2015,P01-1067,0,0.0246433,"Missing"
I05-2015,C94-2209,0,0.0395746,"Annotation on Chinese Sentences For Chinese morphological analysis, we used the analyser developed by Peking University, where the research on definition of Chinese words and the criteria of word segmentation has been conducted for over ten years. The achievements include a grammatical knowledge base of contemporary Chinese, an automatic morphological analyser, and an annotated People’s Daily Corpus. Since the definition and tagset are widely used in Chinese language processing, we also took the criteria as the basis of our guidelines. A morphological analyzer developed by Peking University (Zhou and Yu, 1994) was applied for automatic annotation of the Chinese sentences and then the automatically tagged sentences were revised by humans. An annotated sentence is illustrated in Figure 3, which is the Chinese sentence in Ex. 1 in Section 2. The interface of the tool is shown in Figure 4 and Figure 5. S-ID: 950104141-008 这些/r 俄军/j 士兵/n 均/d 为/v 十九/m 岁/q 左右/m 的/u 年青人/n ，/w 他们/r 甚至/d 连/p 回答/v 问题/n 的/u 气力/n 也/d 没有/v 。/w Figure 3 An annotated Chinese sentence 4.3 Tool for Manual Revision We developed a tool to assist annotators in revision. The tool has both Japanese and Chinese versions. Here, we introduc"
I05-2015,W04-2208,1,\N,Missing
I05-2024,P96-1003,0,0.0357172,"osed method was much higher than that of the conventional TFIDF method when the process was focused on retrieving highly relevant documents, suggesting that the proposed method might be especially suited to information retrieval tasks in which precision is more critical than recall. 1 Introduction Information retrieval (IR) has been studied since an earlier stage [e.g., (Menzel, 1966)] and several kinds of basic retrieval models have been proposed (Salton and Buckley, 1988) and a number of improved IR systems based on these models have been developed by adopting various NLP techniques [e.g., (Evans and Zhai, 1996; Mitra et al., 1997; Mandara, et al., 1998; Murata, et al., 2000)]. However, an epoch-making technique 138 1 There have been a number of studies of SOM on data mining and visualization [e.g., (Kohonen, et al., 2000)] since the WEBSOM was developed in 1996. To our knowledge, however, these works mainly focused on confirming the capabilities of SOM in the self-organization and/or in the visualization. In this study, we slot the SOM-based processing into a practical IR system that enables visualization of the IR while at the same time improving its precision. The another feature of our study dif"
I05-2024,W98-0704,0,0.0308187,"he conventional TFIDF method when the process was focused on retrieving highly relevant documents, suggesting that the proposed method might be especially suited to information retrieval tasks in which precision is more critical than recall. 1 Introduction Information retrieval (IR) has been studied since an earlier stage [e.g., (Menzel, 1966)] and several kinds of basic retrieval models have been proposed (Salton and Buckley, 1988) and a number of improved IR systems based on these models have been developed by adopting various NLP techniques [e.g., (Evans and Zhai, 1996; Mitra et al., 1997; Mandara, et al., 1998; Murata, et al., 2000)]. However, an epoch-making technique 138 1 There have been a number of studies of SOM on data mining and visualization [e.g., (Kohonen, et al., 2000)] since the WEBSOM was developed in 1996. To our knowledge, however, these works mainly focused on confirming the capabilities of SOM in the self-organization and/or in the visualization. In this study, we slot the SOM-based processing into a practical IR system that enables visualization of the IR while at the same time improving its precision. The another feature of our study differing from others is that we performed com"
I05-2042,P02-1040,0,0.147958,"MI Katsunori KOTANI Sharp Corporation Ryukoku University National Institute of Infor492 Minosho-cho, Yamatomation and Communications 1-5, Yokotani, Setaoe-cho, koriyama-shi, Nara, Japan, Otsu-shi, Shiga, Japan, Technology 639-1185 520-2195 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan, 619-0289 kat@khn.nict.go.jp Hitoshi ISAHARA Ichiko SATA National Institute of Information and Sharp Corporation Communications Technology 492 Minosho-cho, Yamatokoriyama-shi, 3-5 Hikaridai, Seika-cho, Soraku-gun, Nara, Japan, 639-1185 Kyoto, Japan, 619-0289 evaluation methods for these systems, e.g., BLEU (Papineni et al. 2002), these methods are basically incapable of dealing with an MTsystem and a w/p-MT-system at the same time, as they have different output forms. On the contrary, there are further methods which examine the efficacy of these systems (Ohguro 1993; Fuji et al. 2001). These studies demonstrate the effectiveness of the reading support systems by comparing reading comprehension test scores between an English-only text and the one with outputs of either an MT-system (Fuji et al. 2001) or a w/p-MT-system (Ohguro 1993). In our evaluation method, we examined the system based not only con comprehension but"
I05-6002,P98-1013,0,0.182561,"Missing"
I05-6002,C04-1134,0,0.0162456,"hat are compatible with the BFN, but for Japanese at least, no data has been released in a usable form, except for a few annotation examples for verbs of motion. In sum, no useful resource exists for framebased description/analysis of Japanese. This is one of the reasons that we attempted the task in this paper, along with our efforts to assess the usefulness of the database provided by BFN. The anonymous reviewers of our paper pointed out that there have been some similar projects and other methodologies that have tried to translate BFN into other languages automatically, such as BiFrameNet (Chen and Fung, 2004) and Romance FrameNet2 , and that it would have been better to include the comparison against them. BiFrameNet presented an automatic approach to constructing a bilingual semantic network using the Chinese HowNet, which is a Chinese ontology. While it is an interesting approach, we have not compared their results with ours, mainly because they seem to have used different resources and had somewhat different goals, along with the space consideration. No papers are released, let alone being available to us, related to the Romance FrameNet project for the time being. We couldn’t help putting a co"
I05-6002,P03-1068,0,0.384504,"Missing"
I05-6002,P03-1010,1,0.825151,"comparison against them. BiFrameNet presented an automatic approach to constructing a bilingual semantic network using the Chinese HowNet, which is a Chinese ontology. While it is an interesting approach, we have not compared their results with ours, mainly because they seem to have used different resources and had somewhat different goals, along with the space consideration. No papers are released, let alone being available to us, related to the Romance FrameNet project for the time being. We couldn’t help putting a comparison with it on hold.3 Proposed Procedure We used a bilingual corpus (Utiyama and Isahara, 2003) to examine which semantic frames of BFN contained LUs relevant to the Japanese verb osou. JFN, for example, used a mono-lingual corpus to construct the semantic frames. In cases like this, the construction might be inefficient because they have to construct all semantic frames by themselves. But this affects on the reliability of the frames identified and described. This risk of arbitrary description can be reduced by using a bilingual corpus, if it is of high-quality. 2.1 Identifying English equivalents of ”osou” We chose Japanese-English alignments from the bilingual corpus in which the Jap"
I05-6002,kingsbury-palmer-2002-treebank,0,0.0288436,"y situation-based, or “case-based” in the sense of Case-based Reasoning (Kolodner, 1993), and difficult to specify in terms of the lexical semantic descriptions available in resources such as WordNet (Fellbaum, 1998) which don’t specify associative relationships among concepts, including the relationships between ROBBER (e.g., a man) and WAREHOUSE OF VALUABLES (e.g., a bank, museum, jewelry shop), and the one between a PREDATOR (e.g., a wolf) and its PREY (e.g., sheep, rabbit). Thus, the NLP community has a critical need for resources that encode this kind of information. Along with PropBank (Kingsbury and Palmer, 2002; Ellsworth et al., 2004), Berkeley FrameNet An attempt was made to semi-automatically obtain “lexical units” (LUs) for Japanese from the English LUs defined in the semantic frame database provided by Berkeley FrameNet (BFN) using an English-Japanese bilingual corpus. This task was a prerequisite to building a complete database of semantic frames for Japanese. In the task, a Japanese word is first translated into an English word or phrase, E. E is one of the lexical units that evoked a particular semantic frame, F, in the BFN database. When other lexical units of F are translated back into Jap"
I05-6002,C98-1013,0,\N,Missing
I05-6009,izumi-etal-2004-overview,1,0.818468,"Missing"
I08-1012,A00-1031,0,0.0519108,"2 in our experiments. We used the same rules for conversion and created the same data split as (Wang et al., 2007): ﬁles 1-270 and 400-931 as training, 271-300 as testing and ﬁles 301-325 as development. We used the gold standard segmentation and POS tags in the CTB. For unlabeled data, we used the PFR corpus 3 . It includes the documents from People’s Daily at 1998 (12 months). There are about 290 thousand sentences and 15 million words in the PFR corpus. To simplify, we used its segmentation. And we discarded the POS tags because PFR and CTB used different POS sets. We used the package TNT (Brants, 2000), a very efﬁcient statistical part-of-speech tagger, to train a POS tagger4 on training data of the CTB. We measured the quality of the parser by the unlabeled attachment score (UAS), i.e., the percentage of tokens with correct HEAD. We reported two types of scores: “UAS without p” is the UAS score without all punctuation tokens and “UAS with p” is the one with all punctuation tokens. 4.1 Experimental results In the experiments, we trained the parsers on training data and tuned the parameters on development data. In the following sessions, “baseline” refers to Basic Parser (the model with basi"
I08-1012,D07-1097,0,0.013766,"case frames. And we represent additional information as the features for learning models while they use the case frames as one component for a probabilistic model. 3 Our Approach In this section, we describe our approach of exploiting reliable features from unlabeled data, which is parsed by a basic parser. We then train another parser based on new feature space. 3.1 Training a basic parser In this paper, we implement a deterministic parser based on the model described by (Nivre, 2003). This model is simple and works very well in the shared-tasks of CoNLL2006(Nivre et al., 2006) and CoNLL2007(Hall et al., 2007). In fact, our approach 90 can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)’s parser, (McDonald et al., 2006)’s parser, and so on. 3.1.1 The parser The parser predicts unlabeled directed dependencies between words in sentences. The algorithm (Nivre, 2003) makes a dependency parsing tree in one left-to-right pass over the input, and uses a stack to store the processed tokens. The behaviors of the parser are deﬁned by four elementary actions (where TOP is the token on top of the stack and NEXT is the next token in the original input string): • Left-Arc(LA): Add an arc f"
I08-1012,N06-1023,1,0.793343,"successful instance of parsing with self-training by using a re-ranker. As Figure 1 suggests, the dependency parser performs bad for parsing the words with long distances. In our approach, we choose partial reliable information which comes from short dependency relations for the dependency parser. (Smith and Eisner, 2006) presents an approach to improve the accuracy of a dependency grammar induction models by EM from unlabeled data. They obtain consistent improvements by penalizing dependencies between two words that are farther apart in the string. The study most relevant to ours is done by (Kawahara and Kurohashi, 2006). They present an integrated probabilistic model for Japanese parsing. They also use partial information after current parser parses the sentences. Our work differs in that we consider general dependency relations while they only consider case frames. And we represent additional information as the features for learning models while they use the case frames as one component for a probabilistic model. 3 Our Approach In this section, we describe our approach of exploiting reliable features from unlabeled data, which is parsed by a basic parser. We then train another parser based on new feature sp"
I08-1012,P06-1043,0,0.0775317,"mance. Our study is relative to incorporating unlabeled data into a model for parsing. There are several other studies relevant to ours as described below. A simple method is self-training in which the existing model ﬁrst labels unlabeled data and then the newly labeled data is then treated as hand annotated data for training a new model. But it seems that selftraining is not so effective. (Steedman et al., 2003) reports minor improvement by using self-training for syntactic parsing on small labeled data. The reason may be that errors in the original model would be ampliﬁed in the new model. (McClosky et al., 2006) presents a successful instance of parsing with self-training by using a re-ranker. As Figure 1 suggests, the dependency parser performs bad for parsing the words with long distances. In our approach, we choose partial reliable information which comes from short dependency relations for the dependency parser. (Smith and Eisner, 2006) presents an approach to improve the accuracy of a dependency grammar induction models by EM from unlabeled data. They obtain consistent improvements by penalizing dependencies between two words that are farther apart in the string. The study most relevant to ours"
I08-1012,D07-1013,0,0.091155,"Missing"
I08-1012,E06-1011,0,0.0577863,"Missing"
I08-1012,W06-2932,0,0.0408924,"onent for a probabilistic model. 3 Our Approach In this section, we describe our approach of exploiting reliable features from unlabeled data, which is parsed by a basic parser. We then train another parser based on new feature space. 3.1 Training a basic parser In this paper, we implement a deterministic parser based on the model described by (Nivre, 2003). This model is simple and works very well in the shared-tasks of CoNLL2006(Nivre et al., 2006) and CoNLL2007(Hall et al., 2007). In fact, our approach 90 can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)’s parser, (McDonald et al., 2006)’s parser, and so on. 3.1.1 The parser The parser predicts unlabeled directed dependencies between words in sentences. The algorithm (Nivre, 2003) makes a dependency parsing tree in one left-to-right pass over the input, and uses a stack to store the processed tokens. The behaviors of the parser are deﬁned by four elementary actions (where TOP is the token on top of the stack and NEXT is the next token in the original input string): • Left-Arc(LA): Add an arc from NEXT to TOP; pop the stack. • Right-Arc(RA): Add an arc from TOP to NEXT; push NEXT onto the stack. • Reduce(RE): Pop the stack. •"
I08-1012,W06-2933,0,0.0192393,"elations while they only consider case frames. And we represent additional information as the features for learning models while they use the case frames as one component for a probabilistic model. 3 Our Approach In this section, we describe our approach of exploiting reliable features from unlabeled data, which is parsed by a basic parser. We then train another parser based on new feature space. 3.1 Training a basic parser In this paper, we implement a deterministic parser based on the model described by (Nivre, 2003). This model is simple and works very well in the shared-tasks of CoNLL2006(Nivre et al., 2006) and CoNLL2007(Hall et al., 2007). In fact, our approach 90 can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)’s parser, (McDonald et al., 2006)’s parser, and so on. 3.1.1 The parser The parser predicts unlabeled directed dependencies between words in sentences. The algorithm (Nivre, 2003) makes a dependency parsing tree in one left-to-right pass over the input, and uses a stack to store the processed tokens. The behaviors of the parser are deﬁned by four elementary actions (where TOP is the token on top of the stack and NEXT is the next token in the original input stri"
I08-1012,W03-3017,0,0.0749943,"t parser parses the sentences. Our work differs in that we consider general dependency relations while they only consider case frames. And we represent additional information as the features for learning models while they use the case frames as one component for a probabilistic model. 3 Our Approach In this section, we describe our approach of exploiting reliable features from unlabeled data, which is parsed by a basic parser. We then train another parser based on new feature space. 3.1 Training a basic parser In this paper, we implement a deterministic parser based on the model described by (Nivre, 2003). This model is simple and works very well in the shared-tasks of CoNLL2006(Nivre et al., 2006) and CoNLL2007(Hall et al., 2007). In fact, our approach 90 can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)’s parser, (McDonald et al., 2006)’s parser, and so on. 3.1.1 The parser The parser predicts unlabeled directed dependencies between words in sentences. The algorithm (Nivre, 2003) makes a dependency parsing tree in one left-to-right pass over the input, and uses a stack to store the processed tokens. The behaviors of the parser are deﬁned by four elementary actions (w"
I08-1012,P06-1072,0,0.0195353,"model. But it seems that selftraining is not so effective. (Steedman et al., 2003) reports minor improvement by using self-training for syntactic parsing on small labeled data. The reason may be that errors in the original model would be ampliﬁed in the new model. (McClosky et al., 2006) presents a successful instance of parsing with self-training by using a re-ranker. As Figure 1 suggests, the dependency parser performs bad for parsing the words with long distances. In our approach, we choose partial reliable information which comes from short dependency relations for the dependency parser. (Smith and Eisner, 2006) presents an approach to improve the accuracy of a dependency grammar induction models by EM from unlabeled data. They obtain consistent improvements by penalizing dependencies between two words that are farther apart in the string. The study most relevant to ours is done by (Kawahara and Kurohashi, 2006). They present an integrated probabilistic model for Japanese parsing. They also use partial information after current parser parses the sentences. Our work differs in that we consider general dependency relations while they only consider case frames. And we represent additional information as"
I08-1012,E03-1008,0,0.0855318,"ta for dependency parsing. We use a parser to parse the sentences in unlabeled data. Then another parser makes use of the information on short dependency relations in the newly parsed data to improve performance. Our study is relative to incorporating unlabeled data into a model for parsing. There are several other studies relevant to ours as described below. A simple method is self-training in which the existing model ﬁrst labels unlabeled data and then the newly labeled data is then treated as hand annotated data for training a new model. But it seems that selftraining is not so effective. (Steedman et al., 2003) reports minor improvement by using self-training for syntactic parsing on small labeled data. The reason may be that errors in the original model would be ampliﬁed in the new model. (McClosky et al., 2006) presents a successful instance of parsing with self-training by using a re-ranker. As Figure 1 suggests, the dependency parser performs bad for parsing the words with long distances. In our approach, we choose partial reliable information which comes from short dependency relations for the dependency parser. (Smith and Eisner, 2006) presents an approach to improve the accuracy of a dependen"
I08-1012,W05-1516,0,0.0438281,"Missing"
I08-1012,P06-1054,0,0.0376974,"Missing"
I08-1012,N07-3002,0,0.0308211,"Missing"
I08-1012,W03-3023,0,0.171228,"le they use the case frames as one component for a probabilistic model. 3 Our Approach In this section, we describe our approach of exploiting reliable features from unlabeled data, which is parsed by a basic parser. We then train another parser based on new feature space. 3.1 Training a basic parser In this paper, we implement a deterministic parser based on the model described by (Nivre, 2003). This model is simple and works very well in the shared-tasks of CoNLL2006(Nivre et al., 2006) and CoNLL2007(Hall et al., 2007). In fact, our approach 90 can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)’s parser, (McDonald et al., 2006)’s parser, and so on. 3.1.1 The parser The parser predicts unlabeled directed dependencies between words in sentences. The algorithm (Nivre, 2003) makes a dependency parsing tree in one left-to-right pass over the input, and uses a stack to store the processed tokens. The behaviors of the parser are deﬁned by four elementary actions (where TOP is the token on top of the stack and NEXT is the next token in the original input string): • Left-Arc(LA): Add an arc from NEXT to TOP; pop the stack. • Right-Arc(RA): Add an arc from TOP to NEXT; push NEXT onto the stac"
I08-1012,D07-1096,0,\N,Missing
I08-1031,P02-1051,0,0.0703275,"hms including support vector machines and maximum entropy model designed to select the correct transliteration hypothesis. In our experiments, our proposed method based on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language. 1 Introduction Machine transliteration has been a great challenge for cross-lingual information retrieval and machine translation systems. Many researchers have developed machine transliteration systems that accept a source language term as input and then output its transliteration in a target language (Al-Onaizan and Knight, 2002; Goto et al., 2003; Grefenstette et al., 2004; Kang and Kim, 2000; Li et al., 2004; Meng et al., 2001; Oh and Choi, 2002; Oh et al., 2006; Qu and Grefenstette, 2004). Some of these have used the Web to select machine-generated transliteration hypotheses and have obtained promising results (AlOnaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). More precisely, they used simple Web counts, estimated as the number of hits (Web pages) retrieved by a Web search engine. However, there are several limitations imposed on the ability of Web counts to select"
I08-1031,2003.mtsummit-papers.17,0,0.305944,"machines and maximum entropy model designed to select the correct transliteration hypothesis. In our experiments, our proposed method based on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language. 1 Introduction Machine transliteration has been a great challenge for cross-lingual information retrieval and machine translation systems. Many researchers have developed machine transliteration systems that accept a source language term as input and then output its transliteration in a target language (Al-Onaizan and Knight, 2002; Goto et al., 2003; Grefenstette et al., 2004; Kang and Kim, 2000; Li et al., 2004; Meng et al., 2001; Oh and Choi, 2002; Oh et al., 2006; Qu and Grefenstette, 2004). Some of these have used the Web to select machine-generated transliteration hypotheses and have obtained promising results (AlOnaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). More precisely, they used simple Web counts, estimated as the number of hits (Web pages) retrieved by a Web search engine. However, there are several limitations imposed on the ability of Web counts to select a correct translit"
I08-1031,C00-1061,0,0.442383,"select the correct transliteration hypothesis. In our experiments, our proposed method based on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language. 1 Introduction Machine transliteration has been a great challenge for cross-lingual information retrieval and machine translation systems. Many researchers have developed machine transliteration systems that accept a source language term as input and then output its transliteration in a target language (Al-Onaizan and Knight, 2002; Goto et al., 2003; Grefenstette et al., 2004; Kang and Kim, 2000; Li et al., 2004; Meng et al., 2001; Oh and Choi, 2002; Oh et al., 2006; Qu and Grefenstette, 2004). Some of these have used the Web to select machine-generated transliteration hypotheses and have obtained promising results (AlOnaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). More precisely, they used simple Web counts, estimated as the number of hits (Web pages) retrieved by a Web search engine. However, there are several limitations imposed on the ability of Web counts to select a correct transliteration hypothesis. First, the assumption that"
I08-1031,P04-1021,0,0.218473,"transliteration hypothesis. In our experiments, our proposed method based on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language. 1 Introduction Machine transliteration has been a great challenge for cross-lingual information retrieval and machine translation systems. Many researchers have developed machine transliteration systems that accept a source language term as input and then output its transliteration in a target language (Al-Onaizan and Knight, 2002; Goto et al., 2003; Grefenstette et al., 2004; Kang and Kim, 2000; Li et al., 2004; Meng et al., 2001; Oh and Choi, 2002; Oh et al., 2006; Qu and Grefenstette, 2004). Some of these have used the Web to select machine-generated transliteration hypotheses and have obtained promising results (AlOnaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). More precisely, they used simple Web counts, estimated as the number of hits (Web pages) retrieved by a Web search engine. However, there are several limitations imposed on the ability of Web counts to select a correct transliteration hypothesis. First, the assumption that hit counts approx"
I08-1031,C02-1099,1,0.807946,"xperiments, our proposed method based on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language. 1 Introduction Machine transliteration has been a great challenge for cross-lingual information retrieval and machine translation systems. Many researchers have developed machine transliteration systems that accept a source language term as input and then output its transliteration in a target language (Al-Onaizan and Knight, 2002; Goto et al., 2003; Grefenstette et al., 2004; Kang and Kim, 2000; Li et al., 2004; Meng et al., 2001; Oh and Choi, 2002; Oh et al., 2006; Qu and Grefenstette, 2004). Some of these have used the Web to select machine-generated transliteration hypotheses and have obtained promising results (AlOnaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). More precisely, they used simple Web counts, estimated as the number of hits (Web pages) retrieved by a Web search engine. However, there are several limitations imposed on the ability of Web counts to select a correct transliteration hypothesis. First, the assumption that hit counts approximate the Web frequency of a given que"
I08-1031,P04-1024,0,0.182867,"d on Web mining consistently outperformed systems based on simple Web counts used in previous work, regardless of the language. 1 Introduction Machine transliteration has been a great challenge for cross-lingual information retrieval and machine translation systems. Many researchers have developed machine transliteration systems that accept a source language term as input and then output its transliteration in a target language (Al-Onaizan and Knight, 2002; Goto et al., 2003; Grefenstette et al., 2004; Kang and Kim, 2000; Li et al., 2004; Meng et al., 2001; Oh and Choi, 2002; Oh et al., 2006; Qu and Grefenstette, 2004). Some of these have used the Web to select machine-generated transliteration hypotheses and have obtained promising results (AlOnaizan and Knight, 2002; Grefenstette et al., 2004; Oh et al., 2006; Qu and Grefenstette, 2004). More precisely, they used simple Web counts, estimated as the number of hits (Web pages) retrieved by a Web search engine. However, there are several limitations imposed on the ability of Web counts to select a correct transliteration hypothesis. First, the assumption that hit counts approximate the Web frequency of a given query usually introduces noise (Lapata and Kelle"
I08-2091,kaji-watanabe-2006-automatic,0,\N,Missing
I08-2100,P02-1054,0,0.036911,"and “Tokyo is also one of Japan’s 47 prefectures”, from Websites, newspaper articles, or encyclopedias. The system then outputs “Tokyo” as the correct answer. We believe question-answering systems will become a more convenient alternative to other systems designed for information retrieval and a basic component of future artificial intelligence systems. Numerous researchers have recently been attracted to this important topic. These researchers have produced many interesting studies on question-answering systems (Kupiec, 1993; Ittycheriah et al., 2001; Clarke et al., 2001; Dumis et al., 2002; Magnini et al., 2002; Moldovan et al., 2003). Evaluation conferences and contests on question-answering systems have also been held. In particular, the U.S.A. has held the Text REtrieval Conferences (TREC) (TREC-10 committee, 2001), and Japan has hosted the QuestionAnswering Challenges (QAC) (National Institute of Informatics, 2002) at NTCIR (NII Test Collection for IR Systems ) 3. These conferences and contests have aimed at improving question-answering systems. The researchers who participate in these create question-answering systems that they then use to answer the same questions, and each system’s performanc"
I08-2100,N04-1008,0,0.0336121,"systems that they then use to answer the same questions, and each system’s performance is then evaluated to yield possible improvements. We addressed non-factoid question answering in NTCIR-6 QAC-4. For example, when the question was “Why are people opposed to the Private Information Protection Law?” the system retrieved sentences based on terms appearing in the question and output an answer using the retrieved sentences. Numerous studies have addressed issues that are involved in the answering of non-factoid questions (Berger et al., 2000; Blair-Goldensohn et al., 2003; 727 Xu et al., 2003; Soricut and Brill, 2004; Han et al., 2005; Morooka and Fukumoto, 2006; Maehara et al., 2006; Asada, 2006). We constructed a system for answering nonfactoid Japanese questions for QAC-4. We used methods of passage retrieval for the system. We extracted paragraphs based on terms from an input question and output them as the preferred answers. We classified the non-factoid questions into six categories. We used a particular method for each category. For example, we increased the scores of paragraphs including the word “reason” for questions including the word “why.” We performed experiments using the NTCIR-6 QAC-4 data"
I11-1165,N06-1028,0,0.0316625,"t of linguistic objects that learners produce. Language processing data indicate how they produce linguistic outputs. Thus, we have eight types of language data that are useful for the SLA research on the development of learners’ proficiency (Hinkel 2010, Segalowitz 2003). Among these eight types of language data, the previous studies (Granger et al. 2009, Izumi et al. 2004, Meurers et al. 2010, Wen et al. 2008) compiled the language output data of speaking, writing, and reading for constructing a learner corpus. See Section 2 for further detail. On the other hand, the other previous studies (Zechner & Bejar 2006, Arthur 1979, Hirai 1999, Kotani et al. 2010, Chang 2010) compiled the language processing data not for constructing a learner corpus but for examining learners’ performance. See Section 3 for further detail. Thus, there is a shortage of language output data of listening, and furthermore we have to construct a learner corpus that integrates all these eight types of data. Hereafter, we refer to this corpus as I(ntegrated)-Learner Corpus. In order to construct I-Learner Corpus, we have compiled data of linguistic output and language processing of the four modalities when learners actually use t"
isahara-etal-2008-application,P02-1040,0,\N,Missing
isahara-etal-2008-application,P07-2045,0,\N,Missing
isahara-etal-2008-application,P03-1010,1,\N,Missing
isahara-etal-2008-development,vossen-etal-2008-kyoto,1,\N,Missing
isahara-etal-2008-development,kanzaki-etal-2008-extraction,1,\N,Missing
isahara-etal-2008-development,kaji-watanabe-2006-automatic,0,\N,Missing
izumi-etal-2004-overview,W00-0708,0,\N,Missing
kanzaki-etal-2006-semantic,C04-1161,0,\N,Missing
kanzaki-etal-2006-semantic,C02-1144,0,\N,Missing
kanzaki-etal-2006-semantic,C92-2082,0,\N,Missing
kanzaki-etal-2006-semantic,P99-1016,0,\N,Missing
kanzaki-etal-2006-semantic,P90-1034,0,\N,Missing
kanzaki-etal-2006-semantic,P99-1063,1,\N,Missing
kanzaki-etal-2006-semantic,P99-1008,0,\N,Missing
kanzaki-etal-2006-semantic,P02-1029,0,\N,Missing
kanzaki-etal-2006-semantic,P93-1023,0,\N,Missing
kanzaki-etal-2006-semantic,N04-1041,0,\N,Missing
kanzaki-etal-2008-extraction,isahara-etal-2008-development,1,\N,Missing
kanzaki-etal-2008-extraction,C92-2082,0,\N,Missing
kanzaki-etal-2008-extraction,P99-1016,0,\N,Missing
kanzaki-etal-2008-extraction,P99-1008,0,\N,Missing
kanzaki-etal-2008-extraction,bond-etal-2008-boot,1,\N,Missing
kanzaki-etal-2008-extraction,N04-1041,0,\N,Missing
kruengkrai-etal-2004-enriching,J98-2002,0,\N,Missing
kruengkrai-etal-2004-enriching,E95-1016,0,\N,Missing
kruengkrai-etal-2004-enriching,C02-1065,0,\N,Missing
kruengkrai-etal-2006-conditional,J00-4006,0,\N,Missing
kruengkrai-etal-2006-conditional,W04-3230,0,\N,Missing
kruengkrai-etal-2006-conditional,C04-1081,0,\N,Missing
kruengkrai-etal-2006-conditional,W03-0430,0,\N,Missing
kruengkrai-etal-2006-conditional,N03-1028,0,\N,Missing
kruengkrai-etal-2006-conditional,N04-4028,0,\N,Missing
kruengkrai-etal-2006-conditional,W97-0126,0,\N,Missing
kuroda-etal-2006-getting,A00-2008,0,\N,Missing
kuroda-etal-2006-getting,P98-1013,0,\N,Missing
kuroda-etal-2006-getting,C98-1013,0,\N,Missing
kuroda-etal-2006-getting,P03-1010,1,\N,Missing
kuroda-etal-2006-getting,P03-1068,0,\N,Missing
kuroda-etal-2006-getting,I05-6002,1,\N,Missing
L16-1350,W14-7001,1,0.377751,"her unit belonging to the same paper in the translated data are extracted. Therefore, there is no sentence pairs sharing the same paper across the training, development, development-test and test sets. This is a practical setting of the machine translation for scientific papers in the future where the input sentences are not in the training data. Application: Workshop on Asian Translation (WAT) 4.1. Overview of WAT The Workshop on Asian Translation (WAT) is a new open evaluation campaign focusing on Asian languages hosted by JST, NICT and Kyoto University. The first workshop was held in 2014 (Nakazawa et al., 2014) where the ASPEC was centered as the official dataset for the scientific paper translation subtasks. ASPEC was again used in the workshop in 2015 (Nakazawa et al., 2015) to observe the contiguous development of machine translation technologies together with the newly added dataset. WAT will keep growing as the leader of the machine translation technology development in Asia. WAT is working toward the practical use of machine translation among all Asian countries. WAT tries to understand the essence of machine translation and the problems to be solved by collecting and sharing the knowledge acq"
L16-1350,W15-5001,1,0.860841,"development-test and test sets. This is a practical setting of the machine translation for scientific papers in the future where the input sentences are not in the training data. Application: Workshop on Asian Translation (WAT) 4.1. Overview of WAT The Workshop on Asian Translation (WAT) is a new open evaluation campaign focusing on Asian languages hosted by JST, NICT and Kyoto University. The first workshop was held in 2014 (Nakazawa et al., 2014) where the ASPEC was centered as the official dataset for the scientific paper translation subtasks. ASPEC was again used in the workshop in 2015 (Nakazawa et al., 2015) to observe the contiguous development of machine translation technologies together with the newly added dataset. WAT will keep growing as the leader of the machine translation technology development in Asia. WAT is working toward the practical use of machine translation among all Asian countries. WAT tries to understand the essence of machine translation and the problems to be solved by collecting and sharing the knowledge acquired in the workshop. WAT is unique in the following points: As described in Section 2., ASPEC-JC includes only 8 scientific fields. The distribution of the fields is s"
L16-1350,2007.mtsummit-papers.63,1,0.812108,"Missing"
L18-1376,D08-1104,0,0.0716416,"Missing"
ma-etal-2008-selection,H05-1059,0,\N,Missing
ma-etal-2008-selection,W05-1514,0,\N,Missing
ma-etal-2008-selection,P98-1069,0,\N,Missing
ma-etal-2008-selection,C98-1066,0,\N,Missing
ma-etal-2008-selection,P03-1010,1,\N,Missing
N07-1005,2001.mtsummit-papers.3,0,0.0334423,"ere, the term Qj corresponds to the rate of accomplishment of the sub-goal having the i-th ID, and λQj is a weight for the rate of accomplishment. The  term Qj corresponds to the rate of unaccomplishment of the sub-goal having the i-th ID, and λQ is a j weight for the rate of unaccomplishment. The value n indicates the number of types of sub-goals. The term λ is constant. The term Si indicates a similarity between a translated sentence and its reference translation, and λSi is a weight for the similarity. Many methods for calculating the similarity have been proposed (Niessen et al., 2000; Akiba et al., 2001; Papineni et al., 2002; NIST, 2002; Leusch et al., 2003; Turian et al., 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gime´nez et al., 2005). In our research, 23 scores, namely BLEU (Papineni et al., 2002) with maximum n-gram lengths of 1, 2, 3, and 4, NIST (NIST, 2002) with maximum n-gram lengths of 1, 2, 3, 4, and 5, GTM (Turian et al., 2003) with exponents of 1.0, 2.0, and 3.0, METEOR (exact) (Banerjee and Lavie, 2005), WER (Niessen et 37 Automatic Estimation of Rate of Accomplishment of Sub-goals The rate of accomplishment of sub-goals is estimated by determ"
N07-1005,P04-1079,0,0.130077,"ine Translation Based on Rate of Accomplishment of Sub-goals Kiyotaka Uchimoto and Katsunori Kotani and Yujie Zhang and Hitoshi Isahara National Institute of Information and Communications Technology 3-5, Hikari-dai, Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan {uchimoto,yujie,isahara}@nict.go.jp, kat@khn.nict.go.jp Abstract issue. In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations (Niessen et al., 2000; Akiba et al., 2001; Papineni et al., 2002; NIST, 2002; Leusch et al., 2003; Turian et al., 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gime´nez et al., 2005) because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently. For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system (Och, 2003). This report shows that the quality of MT results improves as the performance of automatic MT evaluation improves. The quality of a sentence translated by a machine translation (MT) system is difficult to evaluate. We propose a method f"
N07-1005,W05-0909,0,0.126772,"nt of Sub-goals Kiyotaka Uchimoto and Katsunori Kotani and Yujie Zhang and Hitoshi Isahara National Institute of Information and Communications Technology 3-5, Hikari-dai, Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan {uchimoto,yujie,isahara}@nict.go.jp, kat@khn.nict.go.jp Abstract issue. In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations (Niessen et al., 2000; Akiba et al., 2001; Papineni et al., 2002; NIST, 2002; Leusch et al., 2003; Turian et al., 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gime´nez et al., 2005) because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently. For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system (Och, 2003). This report shows that the quality of MT results improves as the performance of automatic MT evaluation improves. The quality of a sentence translated by a machine translation (MT) system is difficult to evaluate. We propose a method for automatically evaluating the quality of ea"
N07-1005,2005.iwslt-1.26,0,0.0249315,"Missing"
N07-1005,1995.mtsummit-1.35,1,0.83169,"nguistic phenomena that are difficult to automatically translate. Recently, MT evaluation campaigns such 34 as the International Workshop on Spoken Language Translation 1 , NIST Machine Translation Evaluation 2 , and HTRDP Evaluation 3 were organized to support the improvement of MT techniques. The data used in the evaluation campaigns were arbitrarily collected from newspaper articles or travel conversation data for fair evaluation. They are classified as the former type of data mentioned above. On the other hand, the data provided by NTT (Ikehara et al., 1994) and that constructed by JEIDA (Isahara, 1995) are classified as the latter type. Almost all the data mentioned above consist of only parallel translations in two languages. Data with information for evaluating MT results, such as JEIDA’s are rarely found. In this paper, we call data that consist of parallel translations collected for MT evaluation and that the information for MT evaluation is assigned to, a test set. The most characteristic information assigned to the JEIDA test set is the yes/no question for assessing the translation results. For example, a yes/no question such as “Is ‘for’ translated into an expression representing a c"
N07-1005,W04-3250,0,0.0286266,"ach question. The third procedure is combining a measure based on the questions and conventional measures. We also present a method for automatically generating sub-goals in the form of yes/no questions and estimating the rate of accomplishment of the sub-goals. Promising results are shown. 1 Introduction In machine translation (MT) research, appropriately evaluating the quality of MT results is an important MT systems can be ranked if a set of MT results for each system and their reference translations are given. Usually, about 300 or more sentences are used to automatically rank MT systems (Koehn, 2004). However, the quality of a sentence translated by an MT system is difficult to evaluate. For example, the results of five MTs into Japanese of the sentence “The percentage of stomach cancer among the workers appears to be the highest for any asbestos workers.” are shown in Table 1. A conventional automatic evaluation method ranks the fifth MT result first although its human subjective evaluation is the lowest. This is because conventional methods are based on the similarity between a translated sentence and its reference translation, and they give the translated sentence a high score when the"
N07-1005,2003.mtsummit-papers.32,0,0.19761,"Zealand. The personal pronoun “they” is omitted in a translation like “nyuujiilando de wa eigo wo hanasu”? The answer is yes if the pattern [karera wa|sore ra wa] is not included in a translation. Otherwise, the answer is no. ear regression model as follows using the rate of accomplishment of the sub-goals and the similarities between a given translation and its reference translation. The best-fitted line for the observed data is calculated by the method of least-squares (Draper and Smith, 1981). A = m  i=1 +  Qj =   Qj = λSi × Si n  (1)  (λQj × Qj + λQ × Qj ) + λ j=1 al., 2000), PER (Leusch et al., 2003), and ROUGE (Lin, 2004) with n-gram lengths of 1, 2, 3, and 4 and 4 variants (LCS, S∗, SU∗, W-1.2), were used to calculate each similarity Si . Therefore, the value of m in Eq. (1) was 23. Japanese word segmentation was performed by using JUMAN 4 in our experiments. As you can see, the definition of our new measure is based on a combination of an evaluation measure focusing on local information and that focusing on global information. j 1 : if subgoal is accomplished 0 : otherwise 3.2 (2) 1 : if subgoal is unaccomplished (3) 0 : otherwise Here, the term Qj corresponds to the rate of accomplish"
N07-1005,C04-1072,0,0.0727122,"ate of Accomplishment of Sub-goals Kiyotaka Uchimoto and Katsunori Kotani and Yujie Zhang and Hitoshi Isahara National Institute of Information and Communications Technology 3-5, Hikari-dai, Seika-cho, Soraku-gun, Kyoto, 619-0289, Japan {uchimoto,yujie,isahara}@nict.go.jp, kat@khn.nict.go.jp Abstract issue. In recent years, many researchers have tried to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations (Niessen et al., 2000; Akiba et al., 2001; Papineni et al., 2002; NIST, 2002; Leusch et al., 2003; Turian et al., 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gime´nez et al., 2005) because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently. For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system (Och, 2003). This report shows that the quality of MT results improves as the performance of automatic MT evaluation improves. The quality of a sentence translated by a machine translation (MT) system is difficult to evaluate. We propose a method for automatically ev"
N07-1005,W04-1013,0,0.00357986,"ey” is omitted in a translation like “nyuujiilando de wa eigo wo hanasu”? The answer is yes if the pattern [karera wa|sore ra wa] is not included in a translation. Otherwise, the answer is no. ear regression model as follows using the rate of accomplishment of the sub-goals and the similarities between a given translation and its reference translation. The best-fitted line for the observed data is calculated by the method of least-squares (Draper and Smith, 1981). A = m  i=1 +  Qj =   Qj = λSi × Si n  (1)  (λQj × Qj + λQ × Qj ) + λ j=1 al., 2000), PER (Leusch et al., 2003), and ROUGE (Lin, 2004) with n-gram lengths of 1, 2, 3, and 4 and 4 variants (LCS, S∗, SU∗, W-1.2), were used to calculate each similarity Si . Therefore, the value of m in Eq. (1) was 23. Japanese word segmentation was performed by using JUMAN 4 in our experiments. As you can see, the definition of our new measure is based on a combination of an evaluation measure focusing on local information and that focusing on global information. j 1 : if subgoal is accomplished 0 : otherwise 3.2 (2) 1 : if subgoal is unaccomplished (3) 0 : otherwise Here, the term Qj corresponds to the rate of accomplishment of the sub-goal ha"
N07-1005,niessen-etal-2000-evaluation,0,0.0410402,"ed (3) 0 : otherwise Here, the term Qj corresponds to the rate of accomplishment of the sub-goal having the i-th ID, and λQj is a weight for the rate of accomplishment. The  term Qj corresponds to the rate of unaccomplishment of the sub-goal having the i-th ID, and λQ is a j weight for the rate of unaccomplishment. The value n indicates the number of types of sub-goals. The term λ is constant. The term Si indicates a similarity between a translated sentence and its reference translation, and λSi is a weight for the similarity. Many methods for calculating the similarity have been proposed (Niessen et al., 2000; Akiba et al., 2001; Papineni et al., 2002; NIST, 2002; Leusch et al., 2003; Turian et al., 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gime´nez et al., 2005). In our research, 23 scores, namely BLEU (Papineni et al., 2002) with maximum n-gram lengths of 1, 2, 3, and 4, NIST (NIST, 2002) with maximum n-gram lengths of 1, 2, 3, 4, and 5, GTM (Turian et al., 2003) with exponents of 1.0, 2.0, and 3.0, METEOR (exact) (Banerjee and Lavie, 2005), WER (Niessen et 37 Automatic Estimation of Rate of Accomplishment of Sub-goals The rate of accomplishment of sub-goals is"
N07-1005,P03-1021,0,0.0239749,"ed to automatically evaluate the quality of MT and improve the performance of automatic MT evaluations (Niessen et al., 2000; Akiba et al., 2001; Papineni et al., 2002; NIST, 2002; Leusch et al., 2003; Turian et al., 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gime´nez et al., 2005) because improving the performance of automatic MT evaluation is expected to enable us to use and improve MT systems efficiently. For example, Och reported that the quality of MT results was improved by using automatic MT evaluation measures for the parameter tuning of an MT system (Och, 2003). This report shows that the quality of MT results improves as the performance of automatic MT evaluation improves. The quality of a sentence translated by a machine translation (MT) system is difficult to evaluate. We propose a method for automatically evaluating the quality of each translation. In general, when translating a given sentence, one or more conditions should be satisfied to maintain a high translation quality. In EnglishJapanese translation, for example, prepositions and infinitives must be appropriately translated. We show several procedures that enable evaluating the quality of"
N07-1005,P02-1040,0,0.0808433,"responds to the rate of accomplishment of the sub-goal having the i-th ID, and λQj is a weight for the rate of accomplishment. The  term Qj corresponds to the rate of unaccomplishment of the sub-goal having the i-th ID, and λQ is a j weight for the rate of unaccomplishment. The value n indicates the number of types of sub-goals. The term λ is constant. The term Si indicates a similarity between a translated sentence and its reference translation, and λSi is a weight for the similarity. Many methods for calculating the similarity have been proposed (Niessen et al., 2000; Akiba et al., 2001; Papineni et al., 2002; NIST, 2002; Leusch et al., 2003; Turian et al., 2003; Babych and Hartley, 2004; Lin and Och, 2004; Banerjee and Lavie, 2005; Gime´nez et al., 2005). In our research, 23 scores, namely BLEU (Papineni et al., 2002) with maximum n-gram lengths of 1, 2, 3, and 4, NIST (NIST, 2002) with maximum n-gram lengths of 1, 2, 3, 4, and 5, GTM (Turian et al., 2003) with exponents of 1.0, 2.0, and 3.0, METEOR (exact) (Banerjee and Lavie, 2005), WER (Niessen et 37 Automatic Estimation of Rate of Accomplishment of Sub-goals The rate of accomplishment of sub-goals is estimated by determining the answer to eac"
N07-1005,C04-1046,0,\N,Missing
N07-1061,J93-2003,0,0.0264764,"h sentences and then translate these n sentences into target language sentences separately. Then, we select the highest scoring sentence from these target sentences. We conducted controlled experiments using the Europarl corpus to evaluate the performance of these pivot strategies as compared to directly trained SMT systems. The phrase translation strategy significantly outperformed the sentence translation strategy. Its relative performance was 0.92 to 0.97 compared to directly trained SMT systems. 1 Introduction The rapid and steady progress in corpus-based machine translation (Nagao, 1981; Brown et al., 1993) has been supported by large parallel corpora such as the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium and the Europarl corpus (Koehn, 2005), which consists of 11 European languages. However, large parallel corpora do not exist for many language pairs. For example, there are no publicly available Arabic-Chinese large-scale parallel corpora even though there are Arabic-English and Chinese-English parallel corpora. Much work has been done to overcome the lack of parallel corpora. For example, Resnik and Smith (2003) propose mining the web to c"
N07-1061,N06-1003,0,0.490064,"rpora for low-density language pairs. Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. Munteanu and Marcu (2005) extract parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Researchers can also make the best use of existing (small) parallel corpora. For example, Nießen and Ney (2004) use morpho-syntactic information to take into account the interdependencies of inflected forms of the same lemma in order to reduce the amount of bilingual data necessary to sufficiently cover the vocabulary in translation. Callison-Burch et al. (2006a) use paraphrases to deal with unknown source language phrases to improve coverage and translation quality. In this paper, we focus on situations where no parallel corpus is available (except a few hundred parallel sentences for tuning parameters). To tackle these extremely scarce training data situations, we propose using a pivot language (English) to bridge the 484 Proceedings of NAACL HLT 2007, pages 484–491, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics source and target languages in translation. We first translate source language sentences or phrases into En"
N07-1061,E06-1032,0,0.041808,"rpora for low-density language pairs. Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. Munteanu and Marcu (2005) extract parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Researchers can also make the best use of existing (small) parallel corpora. For example, Nießen and Ney (2004) use morpho-syntactic information to take into account the interdependencies of inflected forms of the same lemma in order to reduce the amount of bilingual data necessary to sufficiently cover the vocabulary in translation. Callison-Burch et al. (2006a) use paraphrases to deal with unknown source language phrases to improve coverage and translation quality. In this paper, we focus on situations where no parallel corpus is available (except a few hundred parallel sentences for tuning parameters). To tackle these extremely scarce training data situations, we propose using a pivot language (English) to bridge the 484 Proceedings of NAACL HLT 2007, pages 484–491, c Rochester, NY, April 2007. 2007 Association for Computational Linguistics source and target languages in translation. We first translate source language sentences or phrases into En"
N07-1061,W06-3114,0,0.0236121,"is a parallel corpus consisting of the source language and English as well as one consisting of English and the target language. Selecting English as a pivot language is a reasonable pragmatic choice because English is included in parallel corpora more often than other languages are, though any language can be used as a pivot language. In Section 2, we describe a phrase-based statistical machine translation (SMT) system that was used to develop the pivot methods described in Section 3. This is the shared task baseline system for the 2006 NAACL/HLT workshop on statistical machine translation (Koehn and Monz, 2006) and consists of the Pharaoh decoder (Koehn, 2004), SRILM (Stolcke, 2002), GIZA++ (Och and Ney, 2003), mkcls (Och, 1999), Carmel,1 and a phrase model training code. 2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al., 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002). It is a state-of-the-art SMT system with freely available software, as described in the introduction. The system segments the source sentence into socalled phrases (a number of sequences of consecutive words). Each phrase is translated into a target language phrase. Phrases"
N07-1061,2005.iwslt-1.8,0,0.017247,"the SMT system outˆ that satisfies puts an e ˆ = arg max Pr(e|f ) e e = arg max e M X λm hm (e, f ) (1) (2) m=1 where hm (e, f ) is a feature function and λm is a weight. The system uses a total of eight feature functions: a trigram language model probability of the target language, two phrase translation probabilities (both directions), two lexical translation prob1 http://www.isi.edu/licensed-sw/carmel/ 485 abilities (both directions), a word penalty, a phrase penalty, and a linear reordering penalty. For details on these feature functions, please refer to (Koehn et al., 2003; Koehn, 2004; Koehn et al., 2005). To set the weights, λm , we carried out minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) as the objective function. 3 Pivot methods We use the phrase-based SMT system described in the previous section to develop pivot methods. We use English e as the pivot language. We use French f and German g as examples of the source and target languages in this section. We describe two types of pivot strategies, namely phrase translation and sentence translation. The phrase translation strategy means that we directly construct a French-German phrase translation table (phrase-tab"
N07-1061,koen-2004-pharaoh,0,0.0335287,"English as well as one consisting of English and the target language. Selecting English as a pivot language is a reasonable pragmatic choice because English is included in parallel corpora more often than other languages are, though any language can be used as a pivot language. In Section 2, we describe a phrase-based statistical machine translation (SMT) system that was used to develop the pivot methods described in Section 3. This is the shared task baseline system for the 2006 NAACL/HLT workshop on statistical machine translation (Koehn and Monz, 2006) and consists of the Pharaoh decoder (Koehn, 2004), SRILM (Stolcke, 2002), GIZA++ (Och and Ney, 2003), mkcls (Och, 1999), Carmel,1 and a phrase model training code. 2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al., 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002). It is a state-of-the-art SMT system with freely available software, as described in the introduction. The system segments the source sentence into socalled phrases (a number of sequences of consecutive words). Each phrase is translated into a target language phrase. Phrases may be reordered. Let f be a source sentence (e.g"
N07-1061,E99-1010,0,0.0122897,"electing English as a pivot language is a reasonable pragmatic choice because English is included in parallel corpora more often than other languages are, though any language can be used as a pivot language. In Section 2, we describe a phrase-based statistical machine translation (SMT) system that was used to develop the pivot methods described in Section 3. This is the shared task baseline system for the 2006 NAACL/HLT workshop on statistical machine translation (Koehn and Monz, 2006) and consists of the Pharaoh decoder (Koehn, 2004), SRILM (Stolcke, 2002), GIZA++ (Och and Ney, 2003), mkcls (Och, 1999), Carmel,1 and a phrase model training code. 2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al., 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002). It is a state-of-the-art SMT system with freely available software, as described in the introduction. The system segments the source sentence into socalled phrases (a number of sequences of consecutive words). Each phrase is translated into a target language phrase. Phrases may be reordered. Let f be a source sentence (e.g, French) and e be a target sentence (e.g., English), the SMT system o"
N07-1061,2005.mtsummit-papers.11,0,0.0238744,"s using the Europarl corpus to evaluate the performance of these pivot strategies as compared to directly trained SMT systems. The phrase translation strategy significantly outperformed the sentence translation strategy. Its relative performance was 0.92 to 0.97 compared to directly trained SMT systems. 1 Introduction The rapid and steady progress in corpus-based machine translation (Nagao, 1981; Brown et al., 1993) has been supported by large parallel corpora such as the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium and the Europarl corpus (Koehn, 2005), which consists of 11 European languages. However, large parallel corpora do not exist for many language pairs. For example, there are no publicly available Arabic-Chinese large-scale parallel corpora even though there are Arabic-English and Chinese-English parallel corpora. Much work has been done to overcome the lack of parallel corpora. For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. Munteanu and Marcu (2005) extract pa"
N07-1061,P03-1021,0,0.0489827,"hm (e, f ) (1) (2) m=1 where hm (e, f ) is a feature function and λm is a weight. The system uses a total of eight feature functions: a trigram language model probability of the target language, two phrase translation probabilities (both directions), two lexical translation prob1 http://www.isi.edu/licensed-sw/carmel/ 485 abilities (both directions), a word penalty, a phrase penalty, and a linear reordering penalty. For details on these feature functions, please refer to (Koehn et al., 2003; Koehn, 2004; Koehn et al., 2005). To set the weights, λm , we carried out minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) as the objective function. 3 Pivot methods We use the phrase-based SMT system described in the previous section to develop pivot methods. We use English e as the pivot language. We use French f and German g as examples of the source and target languages in this section. We describe two types of pivot strategies, namely phrase translation and sentence translation. The phrase translation strategy means that we directly construct a French-German phrase translation table (phrase-table for short) from a French-English phrase-table and an English-German phrase-tab"
N07-1061,J05-4003,0,0.016542,"nd the Europarl corpus (Koehn, 2005), which consists of 11 European languages. However, large parallel corpora do not exist for many language pairs. For example, there are no publicly available Arabic-Chinese large-scale parallel corpora even though there are Arabic-English and Chinese-English parallel corpora. Much work has been done to overcome the lack of parallel corpora. For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. Munteanu and Marcu (2005) extract parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Researchers can also make the best use of existing (small) parallel corpora. For example, Nießen and Ney (2004) use morpho-syntactic information to take into account the interdependencies of inflected forms of the same lemma in order to reduce the amount of bilingual data necessary to sufficiently cover the vocabulary in translation. Callison-Burch et al. (2006a) use paraphrases to deal with unknown source language phrases to improve coverage and translation quality. In this paper, we focus on s"
N07-1061,P02-1040,0,0.0794409,"where hm (e, f ) is a feature function and λm is a weight. The system uses a total of eight feature functions: a trigram language model probability of the target language, two phrase translation probabilities (both directions), two lexical translation prob1 http://www.isi.edu/licensed-sw/carmel/ 485 abilities (both directions), a word penalty, a phrase penalty, and a linear reordering penalty. For details on these feature functions, please refer to (Koehn et al., 2003; Koehn, 2004; Koehn et al., 2005). To set the weights, λm , we carried out minimum error rate training (Och, 2003) using BLEU (Papineni et al., 2002) as the objective function. 3 Pivot methods We use the phrase-based SMT system described in the previous section to develop pivot methods. We use English e as the pivot language. We use French f and German g as examples of the source and target languages in this section. We describe two types of pivot strategies, namely phrase translation and sentence translation. The phrase translation strategy means that we directly construct a French-German phrase translation table (phrase-table for short) from a French-English phrase-table and an English-German phrase-table. We assume that these French-Eng"
N07-1061,J03-3002,0,0.0116956,"chine translation (Nagao, 1981; Brown et al., 1993) has been supported by large parallel corpora such as the Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium and the Europarl corpus (Koehn, 2005), which consists of 11 European languages. However, large parallel corpora do not exist for many language pairs. For example, there are no publicly available Arabic-Chinese large-scale parallel corpora even though there are Arabic-English and Chinese-English parallel corpora. Much work has been done to overcome the lack of parallel corpora. For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. Munteanu and Marcu (2005) extract parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Researchers can also make the best use of existing (small) parallel corpora. For example, Nießen and Ney (2004) use morpho-syntactic information to take into account the interdependencies of inflected forms of the same lemma in order to reduce the amount of bilingual data necessary to suff"
N07-1061,W02-2026,0,0.0522002,"ot significantly affected by this low precision, as is shown in Table 1. This indicates that recall is more important than precision in building phrase-tables. 5 Related work Pivot languages have been used in rule-based machine translation systems. Boitet (1988) discusses the pros and cons of the pivot approaches in multilingual machine translation. Schubert (1988) argues that a pivot language needs to be a natural language, due to the inherent lack of expressiveness of artificial languages. Pivot-based methods have also been used in other related areas, such as translation lexicon induction (Schafer and Yarowsky, 2002), word alignment (Wang et al., 2006), and cross language information retrieval (Gollins and Sanderson, 2001). The translation disambiguation techniques used in these studies could be used for improving the quality of phrase translation tables. In contrast to these, very little work has been done on pivot-based methods for SMT. Kauers et al. (2002) used an artificial interlingua for spoken language translation. Gispert and Mari˜no (2006) created an English-Catalan parallel corpus by automatically translating the Spanish part of an EnglishSpanish parallel corpus into Catalan with a SpanishCatala"
N07-1061,C88-2125,0,0.70696,"ose sentences were aligned to each other across all four languages, as described in Section 4.1. Thus, there is a lot of room for improvement with respect to recall. Precision, on the other hand, was very low. However, translation performance was not significantly affected by this low precision, as is shown in Table 1. This indicates that recall is more important than precision in building phrase-tables. 5 Related work Pivot languages have been used in rule-based machine translation systems. Boitet (1988) discusses the pros and cons of the pivot approaches in multilingual machine translation. Schubert (1988) argues that a pivot language needs to be a natural language, due to the inherent lack of expressiveness of artificial languages. Pivot-based methods have also been used in other related areas, such as translation lexicon induction (Schafer and Yarowsky, 2002), word alignment (Wang et al., 2006), and cross language information retrieval (Gollins and Sanderson, 2001). The translation disambiguation techniques used in these studies could be used for improving the quality of phrase translation tables. In contrast to these, very little work has been done on pivot-based methods for SMT. Kauers et a"
N07-1061,J04-2003,0,0.0102487,"scale parallel corpora even though there are Arabic-English and Chinese-English parallel corpora. Much work has been done to overcome the lack of parallel corpora. For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. Munteanu and Marcu (2005) extract parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Researchers can also make the best use of existing (small) parallel corpora. For example, Nießen and Ney (2004) use morpho-syntactic information to take into account the interdependencies of inflected forms of the same lemma in order to reduce the amount of bilingual data necessary to sufficiently cover the vocabulary in translation. Callison-Burch et al. (2006a) use paraphrases to deal with unknown source language phrases to improve coverage and translation quality. In this paper, we focus on situations where no parallel corpus is available (except a few hundred parallel sentences for tuning parameters). To tackle these extremely scarce training data situations, we propose using a pivot language (Engl"
N07-1061,P02-1038,0,0.0158062,"t language. In Section 2, we describe a phrase-based statistical machine translation (SMT) system that was used to develop the pivot methods described in Section 3. This is the shared task baseline system for the 2006 NAACL/HLT workshop on statistical machine translation (Koehn and Monz, 2006) and consists of the Pharaoh decoder (Koehn, 2004), SRILM (Stolcke, 2002), GIZA++ (Och and Ney, 2003), mkcls (Och, 1999), Carmel,1 and a phrase model training code. 2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al., 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002). It is a state-of-the-art SMT system with freely available software, as described in the introduction. The system segments the source sentence into socalled phrases (a number of sequences of consecutive words). Each phrase is translated into a target language phrase. Phrases may be reordered. Let f be a source sentence (e.g, French) and e be a target sentence (e.g., English), the SMT system outˆ that satisfies puts an e ˆ = arg max Pr(e|f ) e e = arg max e M X λm hm (e, f ) (1) (2) m=1 where hm (e, f ) is a feature function and λm is a weight. The system uses a total of eight feature function"
N07-1061,P03-1010,1,0.610487,"e Arabic-English and Chinese-English parallel corpora distributed by the Linguistic Data Consortium and the Europarl corpus (Koehn, 2005), which consists of 11 European languages. However, large parallel corpora do not exist for many language pairs. For example, there are no publicly available Arabic-Chinese large-scale parallel corpora even though there are Arabic-English and Chinese-English parallel corpora. Much work has been done to overcome the lack of parallel corpora. For example, Resnik and Smith (2003) propose mining the web to collect parallel corpora for low-density language pairs. Utiyama and Isahara (2003) extract Japanese-English parallel sentences from a noisy-parallel corpus. Munteanu and Marcu (2005) extract parallel sentences from large Chinese, Arabic, and English non-parallel newspaper corpora. Researchers can also make the best use of existing (small) parallel corpora. For example, Nießen and Ney (2004) use morpho-syntactic information to take into account the interdependencies of inflected forms of the same lemma in order to reduce the amount of bilingual data necessary to sufficiently cover the vocabulary in translation. Callison-Burch et al. (2006a) use paraphrases to deal with unkno"
N07-1061,J03-1002,0,0.0159768,"and the target language. Selecting English as a pivot language is a reasonable pragmatic choice because English is included in parallel corpora more often than other languages are, though any language can be used as a pivot language. In Section 2, we describe a phrase-based statistical machine translation (SMT) system that was used to develop the pivot methods described in Section 3. This is the shared task baseline system for the 2006 NAACL/HLT workshop on statistical machine translation (Koehn and Monz, 2006) and consists of the Pharaoh decoder (Koehn, 2004), SRILM (Stolcke, 2002), GIZA++ (Och and Ney, 2003), mkcls (Och, 1999), Carmel,1 and a phrase model training code. 2 Phrase-based SMT We use a phrase-based SMT system, Pharaoh, (Koehn et al., 2003; Koehn, 2004), which is based on a log-linear formulation (Och and Ney, 2002). It is a state-of-the-art SMT system with freely available software, as described in the introduction. The system segments the source sentence into socalled phrases (a number of sequences of consecutive words). Each phrase is translated into a target language phrase. Phrases may be reordered. Let f be a source sentence (e.g, French) and e be a target sentence (e.g., English"
N07-1061,P06-2112,0,0.228586,"aligned with the phrase e¯ in the parallel corpus. Eq. 7 means that φ(f¯|¯ e) is calculated using maximum likelihood estimation. The definition of the lexical translation probability is pw (f¯|¯ e) = max pw (f¯|¯ e, a) (8) pw (f¯|¯ e, a) = a n Y Ew (fi |¯ e, a) (9) i=1 Ew (fi |¯ e, a) = X 1 w(fi |ej ) |{j|(i, j) ∈ a} |∀(i,j)∈a (10) 2 Feature functions scores are calculated using these probabilities. For example, for a translation probability of a French sentence f = f¯1 .Q . . f¯K and a German sentence g = g¯1 . . . g¯K , K h(g, f ) = log i=1 φ(f¯i |¯ gi ), where K is the number of phrases. 3 Wang et al. (2006) use essentially the same definition to induce the translation probability of the source and target language word alignment that is bridged by an intermediate language. Callison-Burch et al. (2006a) use a similar definition for a paraphrase probability. 486 count(f, e) 0 f 0 count(f , e) w(f |e) = P (11) where count(f, e) gives the total number of times the word f is aligned with the word e in the parallel corpus. Thus, w(f |e) is the maximum likelihood estimation of the word translation probability of f given e. Ew(fi |¯ e, a) is calculated from a word alignment a between a phrase pair f¯ = f"
N07-1061,J04-4002,0,0.0256699,"ir f¯ = f1 f2 . . . fn and e¯ = e1 e2 . . . em where fi is connected to several (|{j|(i, j) ∈ a}|) English words. Thus, Ew(fi |¯ e, a) is the average (or mixture) of w(fi |ej ). This means that Ew(fi |¯ e, a) is an estimation of the probability of fi in a. Consequently, pw (f¯|¯ e, a) estimates the probability of f¯ given e¯ and a using the product of the probabilities Ew(fi |¯ e, a). This assumes that the probability of fi is independent given e¯ and a. pw (f¯|¯ e) takes the highest pw (f¯|¯ e, a) if there are multiple alignments a. This discussion, which is partly based on Section 4.1.2 of (Och and Ney, 2004), means that the lexical translation probability pw (f¯|¯ e) is another probability estimated using the word translation probability w(f |e). The justification of Eqs. 3–6 is straightforward. From the discussion above, we know that the probabilities, φ(f¯|¯ e), φ(¯ e|f¯), φ(¯ g |¯ e), φ(¯ e|¯ g ), pw (f¯|¯ e), ¯ pw (¯ e|f ), pw (¯ g |¯ e), and pw (¯ e|¯ g ) are probabilities in the ordinary sense. Thus, we can derive φ(f¯|¯ g ), ¯ ¯ ¯ φ(¯ g |f ), pw (f |¯ g ), and pw (¯ g |f ) by assuming that these probabilities are independent given an English phrase e¯ (e.g., φ(f¯|¯ g , e¯) = φ(f¯|¯ e)). We"
N07-1061,N03-1017,0,\N,Missing
nobata-etal-2002-summarization,P98-1009,0,\N,Missing
nobata-etal-2002-summarization,C98-1009,0,\N,Missing
nobata-etal-2002-summarization,H01-1009,1,\N,Missing
nobata-etal-2002-summarization,A00-1039,1,\N,Missing
P00-1042,W98-1120,0,\N,Missing
P00-1042,M98-1018,0,\N,Missing
P00-1042,W98-1118,0,\N,Missing
P00-1042,W96-0213,0,\N,Missing
P00-1042,M95-1012,0,\N,Missing
P00-1042,E99-1026,1,\N,Missing
P00-1042,J96-1002,0,\N,Missing
P00-1042,J95-4004,0,\N,Missing
P00-1042,M98-1006,0,\N,Missing
P00-1042,M95-1013,0,\N,Missing
P00-1042,A97-1029,0,\N,Missing
P01-1064,A00-2004,0,0.63446,"00). In information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves. To meet such needs, documents should be segmented into coherent topics. Summarization is often used for a long document that includes multiple topics. A summary of such a document can be composed of summaries of the component topics. Identification of topics is the task of text segmentation. A lot of research has been done on text segmentation (Kozima, 1993; Hearst, 1994; Okumura and Honda, 1994; Salton et al., 1996; Yaari, 1997; Kan et al., 1998; Choi, 2000; Nakao, 2000). A major characteristic of the methods used in this research is that they do not require training data to segment given texts. Hearst (1994), for example, used only the similarity of word distributions in a given text to segment the text. Consequently, these methods can be applied to any text in any domain, even if training data do not exist. This property is important when text segmentation is applied to information retrieval or summarization, because both tasks deal with domain-independent documents. Another application of text segmentation is the segmentation of a continuous"
P01-1064,P94-1002,0,0.864752,"earst and Plaunt, 1993; Salton et al., 1996) and summarization (Kan et al., 1998; Nakao, 2000). In information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves. To meet such needs, documents should be segmented into coherent topics. Summarization is often used for a long document that includes multiple topics. A summary of such a document can be composed of summaries of the component topics. Identification of topics is the task of text segmentation. A lot of research has been done on text segmentation (Kozima, 1993; Hearst, 1994; Okumura and Honda, 1994; Salton et al., 1996; Yaari, 1997; Kan et al., 1998; Choi, 2000; Nakao, 2000). A major characteristic of the methods used in this research is that they do not require training data to segment given texts. Hearst (1994), for example, used only the similarity of word distributions in a given text to segment the text. Consequently, these methods can be applied to any text in any domain, even if training data do not exist. This property is important when text segmentation is applied to information retrieval or summarization, because both tasks deal with domain-independent"
P01-1064,P98-2244,0,0.264207,"ntation L 12 ¯ 1 2 b¨« ¬± 3 «  Step 2. Find the minimum-cost path from    . of edge for Step 1. Calculate the cost by using Equation (16). to Algorithms for finding the minimum-cost path in a graph are well known. An algorithm that can provide a solution for Step 2 will be a simpler version of the algorithm used to find the maximumprobability solution in Japanese morphological analysis (Nagata, 1994). Therefore, a solution can be obtained by applying a dynamic programming (DP) algorithm.4 DP algorithms have also been used for text segmentation by other researchers (Ponte and Croft, 1997; Heinonen, 1998). The path thus obtained represents the when edges minimum-cost segmentation in correspond with segments. In Figure 1, for example, if is the minimum-cost path, then is the minimum-cost segmentation. The algorithm automatically determines the number of segments. But the number of segments can also be specified explicitly by specifying the number of edges in the minimum-cost path. The algorithm allows the text to be segmented anywhere between words; i.e., all the positions ¯ &¯¦?´¯""µ ¶ ¨?· ¶ ¸ 9· ¶ ¸µ9· 4 A program that implements the algorithm described in this section is av"
P01-1064,W98-1123,0,0.751156,"Missing"
P01-1064,P93-1041,0,0.703934,"n retrieval (Hearst and Plaunt, 1993; Salton et al., 1996) and summarization (Kan et al., 1998; Nakao, 2000). In information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves. To meet such needs, documents should be segmented into coherent topics. Summarization is often used for a long document that includes multiple topics. A summary of such a document can be composed of summaries of the component topics. Identification of topics is the task of text segmentation. A lot of research has been done on text segmentation (Kozima, 1993; Hearst, 1994; Okumura and Honda, 1994; Salton et al., 1996; Yaari, 1997; Kan et al., 1998; Choi, 2000; Nakao, 2000). A major characteristic of the methods used in this research is that they do not require training data to segment given texts. Hearst (1994), for example, used only the similarity of word distributions in a given text to segment the text. Consequently, these methods can be applied to any text in any domain, even if training data do not exist. This property is important when text segmentation is applied to information retrieval or summarization, because both tasks deal with doma"
P01-1064,maekawa-etal-2000-spontaneous,1,0.345853,"Missing"
P01-1064,C94-1032,0,0.0196192,"boundaries are at the ends of sentences. Given these definitions, we describe the algorithm to find the minimum-cost segmentation or maximum-probability segmentation as follows: 3.2 Properties of the segmentation L 12 ¯ 1 2 b¨« ¬± 3 «  Step 2. Find the minimum-cost path from    . of edge for Step 1. Calculate the cost by using Equation (16). to Algorithms for finding the minimum-cost path in a graph are well known. An algorithm that can provide a solution for Step 2 will be a simpler version of the algorithm used to find the maximumprobability solution in Japanese morphological analysis (Nagata, 1994). Therefore, a solution can be obtained by applying a dynamic programming (DP) algorithm.4 DP algorithms have also been used for text segmentation by other researchers (Ponte and Croft, 1997; Heinonen, 1998). The path thus obtained represents the when edges minimum-cost segmentation in correspond with segments. In Figure 1, for example, if is the minimum-cost path, then is the minimum-cost segmentation. The algorithm automatically determines the number of segments. But the number of segments can also be specified explicitly by specifying the number of edges in the minimum-cost path. The algori"
P01-1064,P00-1039,0,0.247342,"thod does not require training data because it estimates probabilities from the given text. Therefore, it can be applied to any text in any domain. An experiment showed that the method is more accurate than or at least as accurate as a state-of-the-art text segmentation system. 1 Introduction Documents usually include various topics. Identifying and isolating topics by dividing documents, which is called text segmentation, is important for many natural language processing tasks, including information retrieval (Hearst and Plaunt, 1993; Salton et al., 1996) and summarization (Kan et al., 1998; Nakao, 2000). In information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves. To meet such needs, documents should be segmented into coherent topics. Summarization is often used for a long document that includes multiple topics. A summary of such a document can be composed of summaries of the component topics. Identification of topics is the task of text segmentation. A lot of research has been done on text segmentation (Kozima, 1993; Hearst, 1994; Okumura and Honda, 1994; Salton et al., 1996; Yaari, 1997; Kan et al., 1998; Cho"
P01-1064,C94-2121,0,0.00963597,"nt, 1993; Salton et al., 1996) and summarization (Kan et al., 1998; Nakao, 2000). In information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves. To meet such needs, documents should be segmented into coherent topics. Summarization is often used for a long document that includes multiple topics. A summary of such a document can be composed of summaries of the component topics. Identification of topics is the task of text segmentation. A lot of research has been done on text segmentation (Kozima, 1993; Hearst, 1994; Okumura and Honda, 1994; Salton et al., 1996; Yaari, 1997; Kan et al., 1998; Choi, 2000; Nakao, 2000). A major characteristic of the methods used in this research is that they do not require training data to segment given texts. Hearst (1994), for example, used only the similarity of word distributions in a given text to segment the text. Consequently, these methods can be applied to any text in any domain, even if training data do not exist. This property is important when text segmentation is applied to information retrieval or summarization, because both tasks deal with domain-independent documents. Another appli"
P01-1064,P94-1050,0,0.366264,"requires only the given documents for segmentation. It can, however, incorporate training data when they are available, as discussed in Section 5. The algorithm selects the optimum segmentation in terms of the probability defined by a statistical model. This is a new approach for domain-independent text segmentation. Previous approaches usually used lexical cohesion to segment texts into topics. Kozima (1993), for example, used cohesion based on the spreading activation on a semantic network. Hearst (1994) used the similarity of word distributions as measured by the cosine to gauge cohesion. Reynar (1994) used word repetition as a measure of cohesion. Choi (2000) used the rank of the cosine, rather than the cosine itself, to measure the similarity of sentences. The statistical model for the algorithm is described in Section 2, and the algorithm for obtaining the maximum-probability segmentation is described in Section 3. Experimental results are presented in Section 4. Further discussion and our conclusions are given in Sections 5 and 6, respectively. 2 Statistical Model for Text Segmentation We first define the probability of a segmentation of a given text in this section. In the next section"
P01-1064,P99-1046,0,0.0156788,"(in words). Another major difference from their algorithm is that our algorithm does not require training data to estimate probabilities, while their algorithm does. Therefore, our algorithm can be applied to domain-independent texts, while their algorithm is restricted to domains for which training data are available. It would be interesting, however, to compare our algorithm with their algorithm for the case when training data are available. In such a case, our model should be extended to incorporate various features such as the average segment length, clue words, named entities, and so on (Reynar, 1999; Beeferman et al., 1999). Our proposed algorithm naturally estimates the probabilities of words in segments. These probabilities, which are called word densities, have been used to detect important descriptions of words in texts (Kurohashi et al., 1997). This method is based on the assumption that the density of a word is high in a segment in which the word is discussed (defined and/or explained) in some depth. It would be interesting to apply our method to this application. 6 Conclusion We have proposed a statistical model for domainindependent text segmentation. This method finds the maximu"
P01-1064,C98-2239,0,\N,Missing
P03-1010,P98-1041,0,0.12065,"pus available to the public. 1 Introduction A large-scale Japanese-English parallel corpus is an invaluable resource in the study of natural language processing (NLP) such as machine translation and cross-language information retrieval (CLIR). It is also valuable for language education. However, no such corpus has been available to the public. We recently have obtained a noisy parallel corpus of Japanese and English newspapers consisting of issues published over more than a decade and have tried to align their articles and sentences. We first aligned the articles using a method based on CLIR (Collier et al., 1998; Matsumoto and Tanaka, 2002) and then aligned the sentences in these articles by using a method based on dynamic programming (DP) matching (Gale and Church, 1993; Utsuro et al., 1994). However, the results included many incorrect alignments due to noise in the corpus. To remove these, we propose two measures (scores) that evaluate the validity of article and sentence alignments. Using these, we can selectively extract valid alignments. In this paper, we first discuss the basic statistics on the Japanese and English newspapers. We next explain methods and measures used for alignment. We then e"
P03-1010,H92-1022,0,0.00854577,"ment. Let Ji and Ei be the words of Japanese and English sentences for i-th alignment. The similarity6 between Ji and Ei is: SIM(Ji , Ei ) = where l(X) = co(Ji × Ei ) + 1 l(Ji ) + l(Ei ) − 2co(Ji × Ei ) + 2 P x∈X f (x) f (x) is the frequency of x in the sentences. co(Ji × Ei ) = P (j,e)∈Ji ×Ei min(f (j), f (e)) Ji × Ei = {(j, e)|j ∈ Ji , e ∈ Ei } and Ji × Ei is a one-to-one correspondence between Japanese and English words. Ji and Ei are obtained as follows. We use ChaSen to morphologically analyze the Japanese sentences and extract content words, which consists of Ji . We use Brill’s tagger (Brill, 1992) to POS-tag the English sentences, extract content words, and use WordNet’s library7 to obtain lemmas of the words, which consists of Ei . We use simple heuristics to obtain Ji × Ei , i.e., a one-to-one correspondence between the words in Ji and Ei , by looking up JapaneseEnglish and English-Japanese dictionaries made up by combining entries in the EDR Japanese-English bilingual dictionary and the EDR English-Japanese bilingual dictionary. Each of the constructed dictionaries has over 300,000 entries. We evaluated the implemented program against a corpus consisting of manually aligned Japanese"
P03-1010,J93-1004,0,0.929982,"(NLP) such as machine translation and cross-language information retrieval (CLIR). It is also valuable for language education. However, no such corpus has been available to the public. We recently have obtained a noisy parallel corpus of Japanese and English newspapers consisting of issues published over more than a decade and have tried to align their articles and sentences. We first aligned the articles using a method based on CLIR (Collier et al., 1998; Matsumoto and Tanaka, 2002) and then aligned the sentences in these articles by using a method based on dynamic programming (DP) matching (Gale and Church, 1993; Utsuro et al., 1994). However, the results included many incorrect alignments due to noise in the corpus. To remove these, we propose two measures (scores) that evaluate the validity of article and sentence alignments. Using these, we can selectively extract valid alignments. In this paper, we first discuss the basic statistics on the Japanese and English newspapers. We next explain methods and measures used for alignment. We then evaluate the effectiveness of the proposed measures. Finally, we show that our aligned corpus has attracted people both inside and outside the NLP community. 2 New"
P03-1010,matsumoto-tanaka-2002-automatic,0,0.0426027,"ublic. 1 Introduction A large-scale Japanese-English parallel corpus is an invaluable resource in the study of natural language processing (NLP) such as machine translation and cross-language information retrieval (CLIR). It is also valuable for language education. However, no such corpus has been available to the public. We recently have obtained a noisy parallel corpus of Japanese and English newspapers consisting of issues published over more than a decade and have tried to align their articles and sentences. We first aligned the articles using a method based on CLIR (Collier et al., 1998; Matsumoto and Tanaka, 2002) and then aligned the sentences in these articles by using a method based on dynamic programming (DP) matching (Gale and Church, 1993; Utsuro et al., 1994). However, the results included many incorrect alignments due to noise in the corpus. To remove these, we propose two measures (scores) that evaluate the validity of article and sentence alignments. Using these, we can selectively extract valid alignments. In this paper, we first discuss the basic statistics on the Japanese and English newspapers. We next explain methods and measures used for alignment. We then evaluate the effectiveness of"
P03-1010,A97-1004,0,0.0113373,"mmarize, we first translate each of the Japanese articles into a set of English words. We then use each of the English articles as a query and search for the most similar Japanese article in terms of BM25 and assume that it corresponds to the English article. 3.2 Sentence alignment The sentences5 in the aligned Japanese and English articles are aligned by a method based on DP matching (Gale and Church, 1993; Utsuro et al., 1994). 4 http://trec.nist.gov/ We split the Japanese articles into sentences by using simple heuristics and split the English articles into sentences by using MXTERMINATOR (Reynar and Ratnaparkhi, 1997). 5 We allow 1-to-n or n-to-1 (1 ≤ n ≤ 6) alignments when aligning the sentences. Readers are referred to Utsuro et al. (1994) for a concise description of the algorithm. Here, we only discuss the similarities between Japanese and English sentences for alignment. Let Ji and Ei be the words of Japanese and English sentences for i-th alignment. The similarity6 between Ji and Ei is: SIM(Ji , Ei ) = where l(X) = co(Ji × Ei ) + 1 l(Ji ) + l(Ei ) − 2co(Ji × Ei ) + 2 P x∈X f (x) f (x) is the frequency of x in the sentences. co(Ji × Ei ) = P (j,e)∈Ji ×Ei min(f (j), f (e)) Ji × Ei = {(j, e)|j ∈ Ji , e"
P03-1010,C94-2175,0,0.476751,"ranslation and cross-language information retrieval (CLIR). It is also valuable for language education. However, no such corpus has been available to the public. We recently have obtained a noisy parallel corpus of Japanese and English newspapers consisting of issues published over more than a decade and have tried to align their articles and sentences. We first aligned the articles using a method based on CLIR (Collier et al., 1998; Matsumoto and Tanaka, 2002) and then aligned the sentences in these articles by using a method based on dynamic programming (DP) matching (Gale and Church, 1993; Utsuro et al., 1994). However, the results included many incorrect alignments due to noise in the corpus. To remove these, we propose two measures (scores) that evaluate the validity of article and sentence alignments. Using these, we can selectively extract valid alignments. In this paper, we first discuss the basic statistics on the Japanese and English newspapers. We next explain methods and measures used for alignment. We then evaluate the effectiveness of the proposed measures. Finally, we show that our aligned corpus has attracted people both inside and outside the NLP community. 2 Newspapers Aligned The Ja"
P03-1010,C98-1041,0,\N,Missing
P03-1061,J96-1002,0,0.0122742,"a sentence. A string is tagged with a 1 or a 0 to indicate whether it is a morpheme. When a string is a morpheme, a grammatical attribute is assigned to it. A tag designated as a 1 is thus assigned one of a number, n, of grammatical attributes assigned to morphemes, and the problem becomes to assign an attribute (from 0 to n) to every string in a given sentence. We define a model that estimates the likelihood that a given string is a morpheme and has a grammatical attribute i(1 ≤ i ≤ n) as a morpheme model. We implemented this model within an ME modeling framework (Jaynes, 1957; Jaynes, 1979; Berger et al., 1996). The model is represented by Eq. (1): pλ (a|b) = exp  i,j λi,j gi,j (a, b) Zλ (b)  (1) Word 形態 (form) Short word Pronunciation POS Others ケータイ(keitai) Noun Word 形態素解析 (morphological 素 (element) ソ (so) Suffix 解析 (analysis) カイセキ(kaiseki) Noun に ニ (ni) PPP case marker について Verb KA-GYO, ADF, euphonic change PPP conjunctive Prefix Long word Pronunciation POS ケー タ イ ソ カ イ セ(keitaisokaiseki) Noun analysis) キ (about) ニツイテ (nitsuite) オハナシシタシ (ohanashiitasi) Verb つい (relate) ツイ (tsui) て お テ オ (te) (o) 話し (talk) いたし(do) ます ハナシ イタシ マス (hanashi) Verb SA-GYO, ADF (itashi) Verb SA-GYO, ADF (masu) AUX end"
P03-1061,maekawa-etal-2000-spontaneous,1,0.907195,"Missing"
P03-1061,C96-2202,0,0.498087,"tioned in Section 1, tagging the whole of the CSJ manually would be difficult. Therefore, we are taking a semi-automatic approach. This section describes major problems in tagging a large spontaneous speech corpus with high precision in a semiautomatic way, and our solutions to those problems. One of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither a dictionary nor a training corpus. Two statistical approaches have been applied to this problem. One is to find unknown words from corpora and put them into a dictionary (e.g., (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). Uchimoto et al. used both approaches. They proposed a morphological analysis method based on a maximum entropy (ME) model (Uchimoto et al., 2001). Their method uses a model that estimates how likely a string is to be a morpheme as its probability, and thus it has a potential to overcome the unknown word problem. Therefore, we use their method for morphological analysis of the CSJ. However, Uchimoto et al. reported that the accuracy of automatic word segmentation and"
P03-1061,P99-1036,0,0.44756,"s section describes major problems in tagging a large spontaneous speech corpus with high precision in a semiautomatic way, and our solutions to those problems. One of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither a dictionary nor a training corpus. Two statistical approaches have been applied to this problem. One is to find unknown words from corpora and put them into a dictionary (e.g., (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). Uchimoto et al. used both approaches. They proposed a morphological analysis method based on a maximum entropy (ME) model (Uchimoto et al., 2001). Their method uses a model that estimates how likely a string is to be a morpheme as its probability, and thus it has a potential to overcome the unknown word problem. Therefore, we use their method for morphological analysis of the CSJ. However, Uchimoto et al. reported that the accuracy of automatic word segmentation and POS tagging was 94 points in F-measure (Uchimoto et al., 2002). That is much lower than the accuracy obtained by manual taggin"
P03-1061,W01-0512,1,0.862115,"ns to those problems. One of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither a dictionary nor a training corpus. Two statistical approaches have been applied to this problem. One is to find unknown words from corpora and put them into a dictionary (e.g., (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). Uchimoto et al. used both approaches. They proposed a morphological analysis method based on a maximum entropy (ME) model (Uchimoto et al., 2001). Their method uses a model that estimates how likely a string is to be a morpheme as its probability, and thus it has a potential to overcome the unknown word problem. Therefore, we use their method for morphological analysis of the CSJ. However, Uchimoto et al. reported that the accuracy of automatic word segmentation and POS tagging was 94 points in F-measure (Uchimoto et al., 2002). That is much lower than the accuracy obtained by manual tagging. Several problems led to this inaccuracy. In the following, we describe these problems and our solutions to them. • Fillers and disfluencies Fille"
P03-1061,C02-2019,1,0.560951,"that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). Uchimoto et al. used both approaches. They proposed a morphological analysis method based on a maximum entropy (ME) model (Uchimoto et al., 2001). Their method uses a model that estimates how likely a string is to be a morpheme as its probability, and thus it has a potential to overcome the unknown word problem. Therefore, we use their method for morphological analysis of the CSJ. However, Uchimoto et al. reported that the accuracy of automatic word segmentation and POS tagging was 94 points in F-measure (Uchimoto et al., 2002). That is much lower than the accuracy obtained by manual tagging. Several problems led to this inaccuracy. In the following, we describe these problems and our solutions to them. • Fillers and disfluencies Fillers and disfluencies are characteristic expressions often used in spoken language, but they are randomly inserted into text, so detecting their segmentation is difficult. In the CSJ, they are tagged manually. Therefore, we first delete fillers and disfluencies and then put them back in their original place after analyzing a text. • Accuracy for unknown words The morpheme model that will"
P03-1061,W99-0606,0,\N,Missing
P03-1061,A00-2020,0,\N,Missing
P03-2024,C00-2097,1,0.838812,"ght, numbers) or even gestures (e.g. pointing to an area of the body). This is clearly a domain in which the constraints of the task are sufficient for a limited domain, one way spoken translation system to be a useful tool. 2 An architecture for limited-domain speech translation The basic philosophy behind the architecture of the system is to attempt an intelligent compromise between fixed-phrase translation on one hand (e.g. (IntegratedWaveTechnologies, 2002)) and linguistically motivated grammar-based processing on the other (e.g. V ERBMOBIL (Wahlster, 2000) and Spoken Language Translator (Rayner et al., 2000a)). At run-time, the system behaves essentially like a phrasal translator which allows some variation in the input language. This is close in spirit to the approach used in most normal phrase-books, which typically allow “slots” in at least some phrases (“How much does — cost?”; “How do I get to — ?”). However, in order to minimize the overhead associated with defining and maintaining large sets of phrasal patterns, these patterns are derived from a single large linguistically motivated unification grammar; thus the compile-time architecture is that of a linguistically motivated system. Phras"
P03-2024,E03-2010,1,0.673693,"le for source language speech recognition, including parsing and production of semantic representation; transfer and generation; and synthesis of target language speech. The speech processing modules (recognition and synthesis) are implemented on top of the standard Nuance Toolkit platform (Nuance, 2003). Recognition is constrained by a CFG language model written in Nuance Grammar Specification Language (GSL), which also specifies the semantic representations produced. This language model is compiled from a linguistically motivated unification grammar using the Open Source REGULUS 2 platform (Rayner et al., 2003; Regulus, 2003); the compilation process is driven by a small corpus of examples. The language processing modules (transfer and generation) are a suite of simple routines written in SICStus Prolog. The speech and language processing modules communicate with each other through a minimal file-based protocol. The semantic representations on both the source and target sides are expressed as attribute-value structures. In accordance with the generally minimalistic design philosophy of the project, semantic representations have been kept as simple as possible. The basic principle is that the repres"
P04-3015,P99-1008,0,0.0273383,"uman intuition. This is a good way to make a lexical database for users having a specific purpose. However, word hierarchies based on human intuition tend to vary greatly depending on the lexicographer. In addition, hierarchical relations based on various data may be needed depending on each user. Accordingly, we try to extract a hierarchical relation of words automatically and statistically. In previous research, ways of extracting from definition sentences in dictionaries (Tsurumaru et al., 1986; Shoutsu et al., 2003) or from a corpus by using patterns such as “a part of”, “is-a”, or “and” (Berland and Charniak, 1999; Caraballo, 1999) have been proposed. Also, there is a method that uses the dependence relation between words taken from a corpus (Matsumoto et al., 1996). In contrast, isahara@nict.go.jp we propose a method based on the inclusion relation of appearance patterns from corpora. In this paper, to verify the suitability of our method, we attempt to extract hierarchies of abstract nouns co-occurring with adjectives in Japanese. We select two similarity measures to estimate the inclusion relation between word appearance patterns. One is a complementary similarity measure; i.e., a similarity measure"
P04-3015,P99-1016,0,0.0261696,"od way to make a lexical database for users having a specific purpose. However, word hierarchies based on human intuition tend to vary greatly depending on the lexicographer. In addition, hierarchical relations based on various data may be needed depending on each user. Accordingly, we try to extract a hierarchical relation of words automatically and statistically. In previous research, ways of extracting from definition sentences in dictionaries (Tsurumaru et al., 1986; Shoutsu et al., 2003) or from a corpus by using patterns such as “a part of”, “is-a”, or “and” (Berland and Charniak, 1999; Caraballo, 1999) have been proposed. Also, there is a method that uses the dependence relation between words taken from a corpus (Matsumoto et al., 1996). In contrast, isahara@nict.go.jp we propose a method based on the inclusion relation of appearance patterns from corpora. In this paper, to verify the suitability of our method, we attempt to extract hierarchies of abstract nouns co-occurring with adjectives in Japanese. We select two similarity measures to estimate the inclusion relation between word appearance patterns. One is a complementary similarity measure; i.e., a similarity measure developed for the"
P04-3015,kanzaki-etal-2004-extraction,1,0.783806,"Missing"
P05-3030,Y04-1017,1,0.796124,"On the contrary, 1 http://www.cnn.com/ http://www.time.com/time/ 3 http://www.bbc.co.uk/ 4 http://www.gradedreading.pwp.blueyonder.co.uk/ EFL teachers have to carefully select texts, if they want their students to learn a specialized vocabulary through reading in a particular discipline such as medicine, engineering, or economics. However, it is problematic for teachers to select materials for learning a target vocabulary with short authentic texts. It is possible to automate this selection process given the target vocabulary to be learned and the target corpus from which texts are gathered (Utiyama et al., 2004). In this research (Utiyama et al., 2004), we used a specialized vocabulary for an English certification test as the target vocabulary and used newspaper articles from The Daily Yomiuri as the target corpus. We then organized a set of reading materials, which we called courseware5 , using the algorithm in Section 2. The courseware consisted of 116 articles and contained all the target vocabulary. We used the courseware in university English classes from May 2004 to January 2005. We found that the courseware was effective in learning vocabulary (Tanimura and Utiyama, in preparation). Based on t"
P06-2013,J95-4004,0,0.083355,"n an n window. • POS: uni-gram and bi-grams of POS in an n window. • WORD+POS: Both the features of WORD and POS. where n is a predefined number to denote window size. For instance, the WORD features at the 3rd position (北 京-NR) in Example 1 (set n as 2): ”他 L2 到 达 L1 北 京 0 机 场 R1 。 R2”(unigram) and ”他 到达 LB1 到达 北京 B0 北京 机 场 RB1 机场 。 RB2”(bi-gram). Thus features of WORD have 9 items(5 from uni-gram and 4 from bi-grams). In the similar way, features of POS also have 9 items and features of WORD+POS have 18 items(9+9). 3.1.3 TBL Transformation based learning(TBL), first introduced by Eric Brill(Brill, 1995), is mainly based on the idea of successively transforming the data in order to correct the error. The transformation rules obtained are usually few , yet powerful. TBL was applied to Chinese chunking by Li et al.(Li et al., 2004) and TBL provided good performance on their corpus. In this paper, we used fnTBL (V1.0)7 to implement the TBL model. 4 Tag-Extension In Chinese chunking, there are some difficult problems, which are related to Special Terms, NounNoun Compounds, Named Entities Tagging and Coordination. In this section, we propose an approach to resolve these problems by extending the c"
P06-2013,W00-0730,0,0.0141815,"tances are based(Walter et al., 1999). The similarity between the new instance X and example Y in memory is computed using a distance metric. Tjong Kim Sang(Sang, 2002) applied memorybased learning(MBL) to English chunking. MBL performs well for a variety of shallow parsing tasks, often yielding good results. In this paper, we used TiMBL8 (Daelemans et al., 2004) to implement the MBL model. 3.1.1 SVMs Support Vector Machines (SVMs) is a powerful supervised learning paradigm based on the Structured Risk Minimization principle from computational learning theory(Vapnik, 1995). Kudo and Matsumoto(Kudo and Matsumoto, 2000) applied SVMs to English chunking and achieved the best performance in the CoNLL00 shared task(Sang and Buchholz, 2000). They created 231 SVMs classifiers to predict the unique pairs of chunk tags.The final decision was given by their weighted voting. Then the label sequence was chosen using a dynamic programming algorithm. Tan et al. (Tan et al., 2004) applied SVMs to Chinese chunking. They used sigmoid functions to extract probabilities from SVMs outputs as the post-processing of classification. In this paper, we used Yamcha (V0.33)5 in our experiments. 3.2 Features The observations are base"
P06-2013,N01-1025,0,0.289957,"fficult to tell whether ”最低” is a shared modifier or not, even for people. We extend the tags with COO for Coordination: B-NP-COO and I-NP-COO. 3) Named Entities Tagging: Named Entities(NE)(Sang and Meulder, 2003) are not distinguished in CTB4, and they are all tagged as ”NR”. However, they play different roles in chunks, especial in noun phrases. For instance, ”澳 门-NR(Macau)/ 机 场-NN(Airport)” and ”香 港-NR(Hong Kong)/ 机场-NN(Airport)” vs ”邓小 平-NR(Deng Xiaoping)/ 先生-NN(Mr.)” and ”宋 卫 平-NR(Song Weiping) 主 席-NN(President)”. Here ”澳门” and ”香港” are LOCATION, while 5 Voting Methods Kudo and Matsumoto(Kudo and Matsumoto, 2001) reported that they achieved higher accuracy by applying voting of systems that were trained using different data representations. Tjong Kim Sang et al.(Sang and Buchholz, 2000) reported similar results by combining different systems. In order to provide better results, we also apply the voting of basic systems, including SVMs, CRFs, MBL and TBL. Depending on the characteristics in the chunking task, we propose two new voting methods. In these two voting methods, we consider long distance information. In the weighted voting method, we can assign different weights to the results of the individu"
P06-2013,O05-1017,0,0.0624368,"Linguistics Group National Institute of Information and Communications Technology 3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan, 619-0289 {chenwl, yujie, isahara}@nict.go.jp Abstract Conditional Random Fields (CRFs)(Lafferty et al., 2001), Memory-based Learning (MBL)(Park and Zhang, 2003), Transformation-based Learning (TBL)(Brill, 1995), and Hidden Markov Models (HMMs)(Zhou et al., 2000), have been applied to text chunking(Sang and Buchholz, 2000; Hammerton et al., 2002). Chinese chunking is a difficult task, and much work has been done on this topic(Li et al., 2003a; Tan et al., 2005; Wu et al., 2005; Zhao et al., 2000). However, there are many different Chinese chunk definitions, which are derived from different data sets(Li et al., 2004; Zhang and Zhou, 2002). Therefore, comparing the performance of previous studies in Chinese chunking is very difficult. Furthermore, compared with the other languages, there are some special problems for Chinese chunking(Li et al., 2004). In this paper, we extracted the chunking corpus from UPENN Chinese Treebank-4(CTB4). We presented an empirical study of Chinese chunking on this corpus. First, we made an evaluation on the corpus to clarify the performa"
P06-2013,W04-1107,0,0.131808,"89 {chenwl, yujie, isahara}@nict.go.jp Abstract Conditional Random Fields (CRFs)(Lafferty et al., 2001), Memory-based Learning (MBL)(Park and Zhang, 2003), Transformation-based Learning (TBL)(Brill, 1995), and Hidden Markov Models (HMMs)(Zhou et al., 2000), have been applied to text chunking(Sang and Buchholz, 2000; Hammerton et al., 2002). Chinese chunking is a difficult task, and much work has been done on this topic(Li et al., 2003a; Tan et al., 2005; Wu et al., 2005; Zhao et al., 2000). However, there are many different Chinese chunk definitions, which are derived from different data sets(Li et al., 2004; Zhang and Zhou, 2002). Therefore, comparing the performance of previous studies in Chinese chunking is very difficult. Furthermore, compared with the other languages, there are some special problems for Chinese chunking(Li et al., 2004). In this paper, we extracted the chunking corpus from UPENN Chinese Treebank-4(CTB4). We presented an empirical study of Chinese chunking on this corpus. First, we made an evaluation on the corpus to clarify the performance of stateof-the-art models in Chinese chunking. Then we proposed two approaches in order to improve the performance of Chinese chunking. 1"
P06-2013,W02-1818,0,0.0174475,", isahara}@nict.go.jp Abstract Conditional Random Fields (CRFs)(Lafferty et al., 2001), Memory-based Learning (MBL)(Park and Zhang, 2003), Transformation-based Learning (TBL)(Brill, 1995), and Hidden Markov Models (HMMs)(Zhou et al., 2000), have been applied to text chunking(Sang and Buchholz, 2000; Hammerton et al., 2002). Chinese chunking is a difficult task, and much work has been done on this topic(Li et al., 2003a; Tan et al., 2005; Wu et al., 2005; Zhao et al., 2000). However, there are many different Chinese chunk definitions, which are derived from different data sets(Li et al., 2004; Zhang and Zhou, 2002). Therefore, comparing the performance of previous studies in Chinese chunking is very difficult. Furthermore, compared with the other languages, there are some special problems for Chinese chunking(Li et al., 2004). In this paper, we extracted the chunking corpus from UPENN Chinese Treebank-4(CTB4). We presented an empirical study of Chinese chunking on this corpus. First, we made an evaluation on the corpus to clarify the performance of stateof-the-art models in Chinese chunking. Then we proposed two approaches in order to improve the performance of Chinese chunking. 1) We proposed an approa"
P06-2013,W00-1211,0,0.0256491,"National Institute of Information and Communications Technology 3-5 Hikari-dai, Seika-cho, Soraku-gun, Kyoto, Japan, 619-0289 {chenwl, yujie, isahara}@nict.go.jp Abstract Conditional Random Fields (CRFs)(Lafferty et al., 2001), Memory-based Learning (MBL)(Park and Zhang, 2003), Transformation-based Learning (TBL)(Brill, 1995), and Hidden Markov Models (HMMs)(Zhou et al., 2000), have been applied to text chunking(Sang and Buchholz, 2000; Hammerton et al., 2002). Chinese chunking is a difficult task, and much work has been done on this topic(Li et al., 2003a; Tan et al., 2005; Wu et al., 2005; Zhao et al., 2000). However, there are many different Chinese chunk definitions, which are derived from different data sets(Li et al., 2004; Zhang and Zhou, 2002). Therefore, comparing the performance of previous studies in Chinese chunking is very difficult. Furthermore, compared with the other languages, there are some special problems for Chinese chunking(Li et al., 2004). In this paper, we extracted the chunking corpus from UPENN Chinese Treebank-4(CTB4). We presented an empirical study of Chinese chunking on this corpus. First, we made an evaluation on the corpus to clarify the performance of stateof-the-a"
P06-2013,P03-1063,0,0.0370304,"Missing"
P06-2013,W00-0737,0,0.089585,"Missing"
P06-2013,W95-0107,0,0.0145654,"opose two novel voting methods based on the characteristics of chunking task. Compared with traditional voting methods, the proposed voting methods consider long distance information. The experimental results show that the SVMs model outperforms the other models and that our proposed approaches can improve performance significantly. 1 Introduction Chunking identifies the non-recursive cores of various types of phrases in text, possibly as a precursor to full parsing or information extraction. Steven P. Abney was the first person to introduce chunks for parsing(Abney, 1991). Ramshaw and Marcus(Ramshaw and Marcus, 1995) first represented base noun phrase recognition as a machine learning problem. In 2000, CoNLL-2000 introduced a shared task to tag many kinds of phrases besides noun phrases in English(Sang and Buchholz, 2000). Additionally, many machine learning approaches, such as Support Vector Machines (SVMs)(Vapnik, 1995), 97 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 97–104, c Sydney, July 2006. 2006 Association for Computational Linguistics Each chunk type could be extended with I or B tags. For instance, NP could be represented as two types of tags, B-NP or I-NP. Therefor"
P06-2013,W00-0726,0,0.168927,"Missing"
P06-2013,N03-1028,0,0.563936,"inside a chunk), O (outside a chunk), and B (inside a chunk, but also the first word of the chunk). 3 Chinese Chunking 3.1 Models for Chinese Chunking In this paper, we applied four models, including SVMs, CRFs, TBL, and MBL, which have 1 More detailed information at achieved good performance in other languages. http://www.cis.upenn.edu/ chinese/. 2 Tool is available at We only describe these models briefly since full http://www.nlplab.cn/chenwl/tools/chunklinkctb.txt. details are presented elsewhere(Kudo and Mat3 Tool is available at http://ilk.uvt.nl/software.html#chunklink. 4 sumoto, 2001; Sha and Pereira, 2003; Ramshaw There are 15 types in the Upenn Chinese TreeBank. The other chunk types are FRAG, PRN, and UCP. and Marcus, 1995; Sang, 2002). 98 3.1.4 MBL Memory-based Learning (also called instance based learning) is a non-parametric inductive learning paradigm that stores training instances in a memory structure on which predictions of new instances are based(Walter et al., 1999). The similarity between the new instance X and example Y in memory is computed using a distance metric. Tjong Kim Sang(Sang, 2002) applied memorybased learning(MBL) to English chunking. MBL performs well for a variety of"
P06-2013,P98-1081,0,0.0903512,"Missing"
P06-2013,W99-0707,0,\N,Missing
P06-2013,C98-1078,0,\N,Missing
P06-2013,W03-0419,0,\N,Missing
P06-2042,N01-1025,0,0.0438954,"ed to have no modifiee. In our experiments, we defined their dependencies as follows. ¯ The rightmost bunsetsu in a quotation or an inserted clause depends on the rightmost one in the sentence. ¯ If a sentence boundary is included in a quotation or an inserted clause, the bunsetsu to the immediate left of the boundary depends on the rightmost bunsetsu in the quotation or the inserted clause. ¯ Other bunsetsus that have no modifiee depend on the next one. 3.2 Detection of Quotations and Inserted Clauses We regard the problem of clause boundary detection as a text chunking task. We used YamCha (Kudo and Matsumoto, 2001) as a text chunker, which is based on Support Vector Machine (SVM). We used the chunk labels consisting of three tags which correspond to sentence boundaries, boundaries of quotations, and boundaries of inserted clauses, respectively. The tag for sentence 326 Table 1: Tag categories used for chunking Tag B E I O S Explanation of tag Beginning of a clause End of a clause Interior of a clause (except B and E) Exterior of a clause Clause consisting of one bunsetsu boundaries can be either E (the rightmost bunsetsu in a sentence) or I (the others). The tags for the boundaries of quotations and ins"
P06-2042,maekawa-etal-2000-spontaneous,1,0.746056,"a sentence is represented by dependency relationships between bunsetsus in the CSJ. For example, the sentence “彼は ゆっくり歩いている” (He is walking slowly) can be divided into three bunsetsus, “彼は, kare-wa” (he), “ゆっくり, yukkuri” (slowly), and “歩いて いる, arui-te-iru” (is walking). In this sentence, the first and second bunsetsus depend on the third one. The dependency structure is described as follows. 彼は─────┐ (he) │ ゆっくり─┤ (slowly) 歩いている (is walking) 1 Introduction The “Spontaneous Speech: Corpus and Processing Technology” project sponsored the construction of the Corpus of Spontaneous Japanese (CSJ) (Maekawa et al., 2000). The CSJ is the biggest spontaneous speech corpus in the world, consisting of roughly 7M words with the total speech length of 700 hours, and is a collection of monologues such as academic presentations and simulated public speeches. The CSJ includes transcriptions of the speeches as well as audio recordings of them. Approximately one tenth of the In this paper, we first describe the problems with dependency structure analysis of spontaneous speech. We focus on ambiguous clause boundaries as the biggest problem and present a solution. 2 Problems with Dependency Structure Analysis in Spontaneo"
P06-2042,2000.iwpt-1.43,1,0.73658,"propose a method for improving dependency structure analysis based on automatic detection of quotations and inserted clauses. 3 Dependency Structure Analysis and Detection of Quotations and Inserted Clauses The outline of the proposed processes is shown in Figure 1. Here, we use “clause” to describe a quotation and an inserted clause. Inserted Clauses In spontaneous speech, speakers insert clauses in the middle of other clauses. This occurs when speakers change their speech plans while produc325 3.1 Dependency Structure Analysis In this research, we use the method proposed by Uchimoto et al. (Uchimoto et al., 2000) to analyze dependency structures. This method is a twostep procedure, and the first step is preparation of a dependency matrix in which each element represents the likelihood that one bunsetsu depends on another. The second step of the analysis is finding an optimal set of dependencies for the entire sentence. The likelihood of dependency is represented by a probability, using a dependency probability model. The model in this study (Uchimoto et al., 2000) takes into account not only the relationship between two bunsetsus but also the relationship between the left bunsetsu and all the bunsetsu"
P06-2042,C04-1159,1,0.824005,"en written text and spontaneous speech, and consequently, problems peculiar to spontaneous speech arise in de324 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 324–330, c Sydney, July 2006. 2006 Association for Computational Linguistics pendency structure analysis, such as ambiguous clause boundaries, independent bunsetsus, crossed dependencies, self-corrections, and inversions. In this study, we address the problem of ambiguous clause boundaries in dependency structure analysis in spontaneous speech. We treated the other problems in the same way as Shitaoka et al. (Shitaoka et al., 2004). For example, inversions are represented as dependency relationships going in the direction from right to left in the CSJ, and their direction was changed to that from left to right in our experiments. In this paper, therefore, all the dependency relationships were assumed to go in the direction from left to right (Uchimoto et al., 2006). There are several types of clause boundaries such as sentence boundaries, boundaries of quotations and inserted clauses. In the CSJ, clause boundaries were automatically detected by using surface information (Maruyama et al., 2003), and sentence boundaries w"
P06-2076,W00-0730,0,0.0252752,"ginal case particles in passivevoice sentences source case particles. We created tags for target case particles in the corpus. If we can determine the target case particles in a given sentence, we can transform the case particles in passive-voice sentences into case particles for the active voice. Therefore, our goal was to determine the target case particles. 3 Machine learning method (support vector machine) We used a support vector machine as the basis of our machine-learning method. This is because support vector machines are comparatively better than other methods in many research areas (Kudoh and Matsumoto, 2000; Taira and Haruno, 2001; 588 Large Margin Figure 4: Maximizing margin Murata et al., 2002). Data consisting of two categories were classified by using a hyperplane to divide a space with the support vector machine. When these two categories were, positive and negative, for example, enlarging the margin between them in the training data (see Figure 42 ), reduced the possibility of incorrectly choosing categories in blind data (test data). A hyperplane that maximized the margin was thus determined, and classification was done using that hyperplane. Although the basics of this method are as desc"
P07-2036,P99-1008,0,0.0300605,"ly) related word sets among words in documents by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonomical relation and the thematic relation. The for"
P07-2036,N07-3001,0,0.0148079,"additional key words and the contents of the retrieved pages in order to verify the availability of our word sets. Among 847 word sets, we used 294 word sets in which one of the terms is classified into one category and the rest are classified into another. Experiment In our experiment, we used domain-specific Japanese documents within the medical domain (225,402 sentences, 10,144 pages, 37MB) gathered from the Web pages of a medical school and the 2005 Medical Subject Headings (MeSH) thesaurus 1 . Recently, there has been a study on query expansion with this thesaurus as domain information (Friberg 2007). 1 The U.S. National Library of Medicine created, maintains, and provides the MeSH® thesaurus. 142 4. Verification ovary - spleen - palpation (NN) variation - cross reactions - outbreaks - secretion (Wo) bleeding - pyrexia - hematuria - consciousness disorder - vertigo - high blood pressure (Ga) space flight - insemination - immunity (Ni) cough - fetus - bronchiolitis obliterans organizing pneumonia (Ha) latency period - erythrocyte - hepatic cell (SO) Type3: With additional term in a different category Type1: With additional term in same category Figure 1. Examples of word sets used to verif"
P07-2036,P05-1014,0,0.0141615,"derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonomical relation and the thematic relation. The former is a relation representing the physical resemblance among objects, which is"
P07-2036,W03-1210,0,0.0258196,"s by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonomical relation and the thematic relation. The former is a relation representing"
P07-2036,C92-2082,0,0.0473164,"ract thematically (non-taxonomically) related word sets among words in documents by employing case-marking particles derived from syntactic analysis. We then verified the usefulness of word sets with non-taxonomical relation that seems to be a thematic relation for information retrieval. 1. Introduction Related word sets are useful linguistic resources for language understanding and generation, information retrieval, and so on. In previous research on natural language processing, many methodologies for extracting various relations from corpora have been developed, such as the “is-a” relation (Hearst 1992), “part-of” relation (Berland and Charniak 1999), causal relation (Girju 2003), and entailment relation (Geffet and Dagan 2005). Related words can be used to support retrieval in order to lead users to high-quality information. One simple method is to provide additional words related to the key words users have input, such as an input support function within the Google search engine. What kind of relation between the key words that have been input and the additional word is effective for information retrieval? As for the relations among words, at least two kinds of relations exist: the taxonom"
P09-1058,J96-2001,0,0.0305502,"of unknown words (with characterlevel nodes) as well as those of known words (with word-level nodes). We can directly estimate the statistics of known words from an annotated corpus where a sentence is already segmented into words and assigned POS tags. If we select the correct path yt that corresponds to the annotated sentence, it will only consist of word-level nodes that do not allow learning for unknown words. We therefore need to choose character-level nodes as correct nodes instead of word-level nodes for some words. We expect that those words could reflect unknown words in the future. Baayen and Sproat (1996) proposed that the characteristics of infrequent words in a training corpus resemble those of unknown words. Their idea has proven effective for estimating the statistics of unknown words in previous studies (Ratnaparkhi, 1996; Nagata, 1999; Nakagawa, 2004). We adopt Baayen and Sproat’s approach as the baseline policy in our word-character hybrid model. In the baseline policy, we first count the frequencies of words3 in the training corpus. We then collect infrequent words that appear less than or equal to r times.4 If these infrequent words are in the correct path, we use character-level node"
P09-1058,J95-4004,0,0.503119,"Missing"
P09-1058,P99-1036,0,0.028539,"s. If we select the correct path yt that corresponds to the annotated sentence, it will only consist of word-level nodes that do not allow learning for unknown words. We therefore need to choose character-level nodes as correct nodes instead of word-level nodes for some words. We expect that those words could reflect unknown words in the future. Baayen and Sproat (1996) proposed that the characteristics of infrequent words in a training corpus resemble those of unknown words. Their idea has proven effective for estimating the statistics of unknown words in previous studies (Ratnaparkhi, 1996; Nagata, 1999; Nakagawa, 2004). We adopt Baayen and Sproat’s approach as the baseline policy in our word-character hybrid model. In the baseline policy, we first count the frequencies of words3 in the training corpus. We then collect infrequent words that appear less than or equal to r times.4 If these infrequent words are in the correct path, we use character-level nodes to represent them, and hence the characteristics of unknown words can be learned. For example, in Figure 1 we select the character-level nodes of the word “ ” (Chongming) as the correct nodes. As a result, the correct path yt can contain"
P09-1058,W02-1001,0,0.0750953,"lgorithm has two main search steps: forward and backward. For the forward search, we use Viterbi-style decoding to find the best partial path and its score up to each node in the lattice. For the backward search, we use A∗ style decoding to generate the top k-best paths. A complete path is found when the backward search reaches the beginning node of the lattice, and the algorithm terminates when the number of generated paths equals k. In summary, we use k-best MIRA to iteratively update w(i) . The final weight vector w is the average of the weight vectors after each iteration. As reported in (Collins, 2002; McDonald et al., 2005), parameter averaging can effectively avoid overfitting. For inference, we can use Viterbi-style decoding to search for the most likely path y∗ for a given sentence x where: Input: Training set S = {(xt , yt )}Tt=1 Output: Model weight vector w 1: w(0) = 0; v = 0; i = 0 2: for iter = 1 to N do 3: for t = 1 to T do 4: w(i+1) = update w(i) according to (xt , yt ) 5: v = v + w(i+1) 6: i=i+1 7: end for 8: end for 9: w = v/(N × T ) within a few iterations (McDonald, 2006). Algorithm 1 outlines the generic online learning algorithm (McDonald, 2006) used in our framework. 4.2"
P09-1058,P07-2055,1,0.292461,"taka Uchimoto‡ and Jun’ichi Kazama‡ Yiou Wang‡ and Kentaro Torisawa‡ and Hitoshi Isahara†‡ † Graduate School of Engineering, Kobe University 1-1 Rokkodai-cho, Nada-ku, Kobe 657-8501 Japan ‡ National Institute of Information and Communications Technology 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289 Japan {canasai,uchimoto,kazama,wangyiou,torisawa,isahara}@nict.go.jp tem’s word dictionary1 . The word boundaries and the POS tags of unknown words, which are very difficult to identify, cause numerous errors. The word-character hybrid model proposed by Nakagawa and Uchimoto (Nakagawa, 2004; Nakagawa and Uchimoto, 2007) shows promising properties for solving this problem. However, it suffers from structural complexity. Nakagawa (2004) described a training method based on a word-based Markov model and a character-based maximum entropy model that can be completed in a reasonable time. However, this training method is limited by the generatively-trained Markov model in which informative features are hard to exploit. In this paper, we overcome such limitations concerning both efficiency and effectiveness. We propose a new framework for training the wordcharacter hybrid model based on the Margin Infused Relaxed A"
P09-1058,C04-1067,0,0.417122,"gkrai†‡ and Kiyotaka Uchimoto‡ and Jun’ichi Kazama‡ Yiou Wang‡ and Kentaro Torisawa‡ and Hitoshi Isahara†‡ † Graduate School of Engineering, Kobe University 1-1 Rokkodai-cho, Nada-ku, Kobe 657-8501 Japan ‡ National Institute of Information and Communications Technology 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0289 Japan {canasai,uchimoto,kazama,wangyiou,torisawa,isahara}@nict.go.jp tem’s word dictionary1 . The word boundaries and the POS tags of unknown words, which are very difficult to identify, cause numerous errors. The word-character hybrid model proposed by Nakagawa and Uchimoto (Nakagawa, 2004; Nakagawa and Uchimoto, 2007) shows promising properties for solving this problem. However, it suffers from structural complexity. Nakagawa (2004) described a training method based on a word-based Markov model and a character-based maximum entropy model that can be completed in a reasonable time. However, this training method is limited by the generatively-trained Markov model in which informative features are hard to exploit. In this paper, we overcome such limitations concerning both efficiency and effectiveness. We propose a new framework for training the wordcharacter hybrid model based o"
P09-1058,W04-3236,0,0.900606,"our approach on the Penn Chinese Treebank, and show that it achieves superior performance compared to the state-ofthe-art approaches reported in the literature. 1 Introduction In Chinese, word segmentation and part-of-speech (POS) tagging are indispensable steps for higherlevel NLP tasks. Word segmentation and POS tagging results are required as inputs to other NLP tasks, such as phrase chunking, dependency parsing, and machine translation. Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b). In joint word segmentation and the POS tagging process, one serious problem is caused by unknown words, which are defined as words that are not found in a training corpus or in a sys1 A system’s word dictionary usually consists of a word list, and each word in the list has its own POS category. In this paper, we constructed the system’s word dictionary from a training corpus. 513 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 513–521, c Suntec, Singapore, 2"
P09-1058,W96-0213,0,0.439508,"nd assigned POS tags. If we select the correct path yt that corresponds to the annotated sentence, it will only consist of word-level nodes that do not allow learning for unknown words. We therefore need to choose character-level nodes as correct nodes instead of word-level nodes for some words. We expect that those words could reflect unknown words in the future. Baayen and Sproat (1996) proposed that the characteristics of infrequent words in a training corpus resemble those of unknown words. Their idea has proven effective for estimating the statistics of unknown words in previous studies (Ratnaparkhi, 1996; Nagata, 1999; Nakagawa, 2004). We adopt Baayen and Sproat’s approach as the baseline policy in our word-character hybrid model. In the baseline policy, we first count the frequencies of words3 in the training corpus. We then collect infrequent words that appear less than or equal to r times.4 If these infrequent words are in the correct path, we use character-level nodes to represent them, and hence the characteristics of unknown words can be learned. For example, in Figure 1 we select the character-level nodes of the word “ ” (Chongming) as the correct nodes. As a result, the correct path y"
P09-1058,W03-1719,0,0.0612588,"nese Treebank (CTB) (Xia et al., 2000) in experiments. However, versions of CTB and experimental settings vary across different studies. In this paper, we used CTB 5.0 (LDC2005T01) as our main corpus, defined the training, development and test sets according to (Jiang et al., 2008a; Jiang et al., 2008b), and designed our experiments to explore the impact of the training corpus size on our approach. Table 5 provides the statistics of our experimental settings on the small and large training data. The out-of-vocabulary (OOV) is defined as tokens in the test set that are not in the training set (Sproat and Emerson, 2003). Note that the development set was only used for evaluating the trained model to obtain the optimal values of tunable parameters. 5.4 Impact of policies for correct path selection Table 6 shows the results of our word-character hybrid model using the error-driven and baseline policies. The third and fourth columns indicate the numbers of known and artificial unknown words in the training phase. The total number of words is the same, but the different policies yield different balances between the known and artificial unknown words for learning the hybrid model. Optimal balances were selected u"
P09-1058,P08-1102,0,0.671136,"Missing"
P09-1058,W01-0512,1,0.806822,"cond is a discriminative online learning algorithm based on MIRA that enables us to incorporate arbitrary features to our hybrid model. Based on extensive comparisons, we showed that our approach is superior to the existing approaches reported in the literature. In future work, we plan to apply our framework to other Asian languages, including Thai and Japanese. 7 Related work In this section, we discuss related approaches based on several aspects of learning algorithms and search space representation methods. Maximum entropy models are widely used for word segmentation and POS tagging tasks (Uchimoto et al., 2001; Ng and Low, 2004; Nakagawa, 2004; Nakagawa and Uchimoto, 2007) since they only need moderate training times while they provide reasonable performance. Conditional random fields (CRFs) (Lafferty et al., 2001) further improve the performance (Kudo et al., 2004; Shi and Wang, 2007) by performing whole-sequence normalization to avoid label-bias and length-bias problems. However, CRF-based algorithms typically require longer training times, and we observed an infeasible convergence time for our hybrid model. Online learning has recently gained popularity for many NLP tasks since it performs compa"
P09-1058,C08-1049,0,0.775572,"uperior performance compared to the state-ofthe-art approaches reported in the literature. 1 Introduction In Chinese, word segmentation and part-of-speech (POS) tagging are indispensable steps for higherlevel NLP tasks. Word segmentation and POS tagging results are required as inputs to other NLP tasks, such as phrase chunking, dependency parsing, and machine translation. Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b). In joint word segmentation and the POS tagging process, one serious problem is caused by unknown words, which are defined as words that are not found in a training corpus or in a sys1 A system’s word dictionary usually consists of a word list, and each word in the list has its own POS category. In this paper, we constructed the system’s word dictionary from a training corpus. 513 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 513–521, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP Figure 1: Lattice used in word-charac"
P09-1058,W04-3230,0,0.04645,"n future work, we plan to apply our framework to other Asian languages, including Thai and Japanese. 7 Related work In this section, we discuss related approaches based on several aspects of learning algorithms and search space representation methods. Maximum entropy models are widely used for word segmentation and POS tagging tasks (Uchimoto et al., 2001; Ng and Low, 2004; Nakagawa, 2004; Nakagawa and Uchimoto, 2007) since they only need moderate training times while they provide reasonable performance. Conditional random fields (CRFs) (Lafferty et al., 2001) further improve the performance (Kudo et al., 2004; Shi and Wang, 2007) by performing whole-sequence normalization to avoid label-bias and length-bias problems. However, CRF-based algorithms typically require longer training times, and we observed an infeasible convergence time for our hybrid model. Online learning has recently gained popularity for many NLP tasks since it performs comparably or better than batch learning using shorter training times (McDonald, 2006). For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b). Another potent"
P09-1058,xia-etal-2000-developing,0,0.388731,"2005; McDonald, 2006). We describe k-best decoding for our hybrid model and design its loss function and the features appropriate for our task. In our word-character hybrid model, allowing the model to learn the characteristics of both known and unknown words is crucial to achieve optimal performance. Here, we describe our strategies that yield good balance for learning these two characteristics. We propose an errordriven policy that delivers this balance by acquiring examples of unknown words from particular errors in a training corpus. We conducted our experiments on Penn Chinese Treebank (Xia et al., 2000) and compared our approach with the best previous approaches reported in the literature. Experimental results indicate that our approach can achieve state-of-the-art performance. Abstract In this paper, we present a discriminative word-character hybrid model for joint Chinese word segmentation and POS tagging. Our word-character hybrid model offers high performance since it can handle both known and unknown words. We describe our strategies that yield good balance for learning the characteristics of known and unknown words and propose an errordriven policy that delivers such balance by acquiri"
P09-1058,P08-1101,0,0.620356,"show that it achieves superior performance compared to the state-ofthe-art approaches reported in the literature. 1 Introduction In Chinese, word segmentation and part-of-speech (POS) tagging are indispensable steps for higherlevel NLP tasks. Word segmentation and POS tagging results are required as inputs to other NLP tasks, such as phrase chunking, dependency parsing, and machine translation. Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b). In joint word segmentation and the POS tagging process, one serious problem is caused by unknown words, which are defined as words that are not found in a training corpus or in a sys1 A system’s word dictionary usually consists of a word list, and each word in the list has its own POS category. In this paper, we constructed the system’s word dictionary from a training corpus. 513 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 513–521, c Suntec, Singapore, 2-7 August 2009. 2009 ACL and AFNLP Figure 1: Lattice"
P09-1058,H05-1066,0,0.00424798,"o main search steps: forward and backward. For the forward search, we use Viterbi-style decoding to find the best partial path and its score up to each node in the lattice. For the backward search, we use A∗ style decoding to generate the top k-best paths. A complete path is found when the backward search reaches the beginning node of the lattice, and the algorithm terminates when the number of generated paths equals k. In summary, we use k-best MIRA to iteratively update w(i) . The final weight vector w is the average of the weight vectors after each iteration. As reported in (Collins, 2002; McDonald et al., 2005), parameter averaging can effectively avoid overfitting. For inference, we can use Viterbi-style decoding to search for the most likely path y∗ for a given sentence x where: Input: Training set S = {(xt , yt )}Tt=1 Output: Model weight vector w 1: w(0) = 0; v = 0; i = 0 2: for iter = 1 to N do 3: for t = 1 to T do 4: w(i+1) = update w(i) according to (xt , yt ) 5: v = v + w(i+1) 6: i=i+1 7: end for 8: end for 9: w = v/(N × T ) within a few iterations (McDonald, 2006). Algorithm 1 outlines the generic online learning algorithm (McDonald, 2006) used in our framework. 4.2 k-best MIRA We focus on"
P09-1058,C94-1032,0,0.27228,"hybrid model since it quickly converges 3 We consider a word and its POS tag a single entry. In our experiments, the optimal threshold value r is selected by evaluating the performance of joint word segmentation and POS tagging on the development set. 4 515 Algorithm 1 Generic Online Learning Algorithm above quadratic programming (QP) problem can be solved using Hildreth’s algorithm (Yair Censor, 1997). Replacing Eq. (2) into line 4 of Algorithm 1, we obtain k-best MIRA. The next question is how to efficiently generate bestk (xt ; w(i) ). In this paper, we apply a dynamic programming search (Nagata, 1994) to kbest MIRA. The algorithm has two main search steps: forward and backward. For the forward search, we use Viterbi-style decoding to find the best partial path and its score up to each node in the lattice. For the backward search, we use A∗ style decoding to generate the top k-best paths. A complete path is found when the backward search reaches the beginning node of the lattice, and the algorithm terminates when the number of generated paths equals k. In summary, we use k-best MIRA to iteratively update w(i) . The final weight vector w is the average of the weight vectors after each iterat"
P09-1058,W03-1726,0,\N,Missing
P98-2131,P92-1004,1,0.801198,"Missing"
P98-2131,A97-1001,0,0.0214321,"3, we examine the dialogue processing requirement in a complex scenario involving multiple users and multiple simultaneous dialogues of diverse types. We describe how our architecture supports implementations of such a scenario. Finally, we describe two implemented spoken dialogue systems that embody this architecture (Section 4). Introduction We present an architecture for spoken dialogue systems for both human-computer interaction and computer mediation or analysis of human dialogue. The architecture shares many components with those of existing spoken dialogue systems, such as CommandTalk (Moore et al. 1997), Galaxy (Goddeau et al. 1994), TRAINS (Allen et al. 1995), Verbmobil (Wahlster 1993), Waxholm (Carlson 1996), and others. Our architecture is distinguished from these in its treatment of discourse-level processing. 1 Component Tasks of Discourse Processing We divide discourse-level processing into three component tasks: Dialogue Management, Context Tracking, and Pragmatic Adaptation. 1.1 Dialogue Management The Dialogue Manager is an oversight module whose purpose is to facilitate the interaction between dialogue participants. In a user-initiated system, the dialogue manager directs the proce"
P98-2131,W96-0102,0,\N,Missing
P98-2131,H90-1055,0,\N,Missing
P98-2131,J94-2001,0,\N,Missing
P98-2131,C94-1027,0,\N,Missing
P99-1063,C96-1026,0,0.391329,"n level. 1 Introduction Natural language processing must disambiguate polysemous constituents in the input sentences. A good description of information necessary for disambiguation in the lexicon is crucial in high quality NLP systems. This paper discusses the treatment of linguistic phenomena in Japanese adnominM constituents and it focuses on how to generate the same semantic representation from different syntactic structures, and how to generate different semantic representations from a semantically ambiguous sentence. We exploit and extend the Generative Lexicon Theory (Pustejovsky, 1995; Bouillon, 1996) to develop a formal description of adnominal constituents in a lexicon which can offer a solution to these problems. We classify the problematic behavior of Japanese adnominal constituents into &quot;static disambiguation&quot; and &quot;dynamic disambiguation&quot; tasks. Whereas static disambiguation can be done using the lexical information in a dictionary, dynamic disambiguation needs inferences at the knowledge representation level. This paper mainly discusses dynamic disambiguation. 2 Classification of the Usage of Japanese Adnominal Constituents On consideration of the syntactic relations between adnomina"
S01-1033,W00-0730,0,0.0142784,"kernel functions. We have used the following polynomial function exclusively. K(x,y) =(x·y+l)d (9) C and d are constants set by experimentation. For all of the experiments reported in this paper, C was fixed as 1 and d was fixed as 2. A set of Xi that satisfies O:i &gt; 0 is called a support vector (SVs) 4 . The summation portion of Equation (4) was calculated using only the examples that were support vectors. Support vector machine methods are capable of handling data consisting of two categories. In general, data consisting of more than two categories is handled by using the pair-wise method (Kudoh and Matsumoto, 2000). In this method, for data consisting of N categories, pairs of two different categories (N (N1)/2 pairs) are constructed. The better cate1rn Figure 1, the circles in the broken lines indicate support vectors. gory is determined by using a 2-category classifier (in this paper, a support vector machine 5 was used as the 2-category classifier), and the correct category is finally determined by ""voting"" on the N(N-1)/2 pairs that result from analysis using the 2-category classifier. The support vector machine method is, in fact, performed by combining the support vector machine and pair-wise meth"
S01-1038,W01-1415,1,0.879344,"ources of information related to the input sentence and examples. Since we want to avoid making complicated rules, we use machine learning models to calculate the similarity. Instead of all examples in the TM, English headwords are used as classes in machine learning models. Therefore, examples having the same English headword are put into the same class and are considered to have the same similarity. 1 A description on how to use ""diff"" can be found in (Murata and Isahara, 2001). 2 Work on using machine learning methods for the tra!lslation of tenses, aspects, and modalities can be found'in {Murata et al., 2001a). 156 Classes identified by machine learning models are basically English headwords in TM, and they are detected manually. For example, English headwords of the examples in Figure 1 are ""feel constrained"", ""constraint"", and ""refrain"", respectively. When English headwords are verbs, they are represented by their basic forms. English words obtained when a Japanese headword is looked up in a Japanese-English dictionary are also used as classes. For the training data, we use not only examples in the TM but also other data collected from bilingual dictionaries or a parallel corpus. The collected"
sornlertlamvanich-etal-2010-language,isahara-etal-2008-development,1,\N,Missing
sornlertlamvanich-etal-2010-language,W09-3401,1,\N,Missing
sornlertlamvanich-etal-2010-language,I08-2091,1,\N,Missing
tohyama-etal-2008-construction-metadata,kozawa-etal-2008-automatic,1,\N,Missing
tongchim-etal-2006-blind,J90-1003,0,\N,Missing
tongchim-etal-2008-dependency,W03-3023,0,\N,Missing
tongchim-etal-2008-dependency,E99-1026,1,\N,Missing
tongchim-etal-2008-dependency,W02-2016,0,\N,Missing
tongchim-etal-2008-dependency,C04-1040,0,\N,Missing
tongchim-etal-2008-dependency,E06-1012,0,\N,Missing
tongchim-etal-2008-dependency,C04-1010,0,\N,Missing
tongchim-etal-2008-dependency,2006.iwslt-evaluation.9,0,\N,Missing
tongchim-etal-2008-dependency,kruengkrai-etal-2006-conditional,1,\N,Missing
tongchim-etal-2008-dependency,W00-1303,0,\N,Missing
tongchim-etal-2008-dependency,C00-2109,1,\N,Missing
tongchim-etal-2008-dependency,W97-0126,0,\N,Missing
uchimoto-etal-2006-automatic,P02-1028,0,\N,Missing
uchimoto-etal-2006-automatic,2005.mtsummit-papers.31,1,\N,Missing
uchimoto-etal-2006-dependency,E99-1026,1,\N,Missing
uchimoto-etal-2006-dependency,C02-1136,0,\N,Missing
uchimoto-etal-2006-dependency,P98-1083,0,\N,Missing
uchimoto-etal-2006-dependency,C98-1080,0,\N,Missing
uchimoto-etal-2006-dependency,C04-1159,1,\N,Missing
uchimoto-etal-2006-dependency,W98-1511,0,\N,Missing
uchimoto-etal-2006-dependency,maekawa-etal-2000-spontaneous,1,\N,Missing
uchimoto-etal-2006-dependency,W00-1303,0,\N,Missing
vossen-etal-2008-kyoto,W02-1304,1,\N,Missing
vossen-etal-2008-kyoto,W01-0703,1,\N,Missing
vossen-etal-2008-kyoto,magnini-cavaglia-2000-integrating,0,\N,Missing
vossen-etal-2008-kyoto,atserias-etal-2004-towards,1,\N,Missing
vossen-etal-2008-kyoto,soria-etal-2006-moving,1,\N,Missing
vossen-etal-2008-kyoto,chou-huang-2006-hantology,1,\N,Missing
vossen-etal-2008-kyoto,W06-1003,1,\N,Missing
W00-0110,C96-1026,0,0.0253457,"el. 1 Introduction Pustejovsky (Pustejovsky, 1995) proposed the theory of a generative lexicon as a framework by which meanings of words are expressed in one unified representation. This kind ofgenerativity would be very useful for NLP, especially if it is applicable to the complex semantic structures represented by various modification relations. In our previous research on adjectives (Isahara and Kanzaki, 1999) we used Pustejovsky's theory to classify adjectives in Japanese. In this paper we take the first steps in a similar classification of the Japanese &quot;noun + NO&quot; construction. Bouillon (Bouillon, 1996) applied this theory to the adnominal constituent of mental states. Saint-Dizier (Saint-Dizier, 1998) discussed adjectives in French. Isahara and Kanzaki (Isahara and Kanzaki, 1999) treated a much wider range of phenomena of adnominal constituents. They classified the semantic roles of adnominal constituents in .Japanese. where many parts of speech act as adnominal constituents, and discussed a for59 mal treatment of their semantic roles. In their research, adnominal constituents, mainly adjectives which function as adverbials, are discussed. The present paper describes the similarities and di"
W00-0110,P99-1063,1,0.835997,"r also proposes an objective method of classifying these constructs using a large amount of linguistic data. The feasibility of this was verified with a selforganizing semantic map based on a neural network model. 1 Introduction Pustejovsky (Pustejovsky, 1995) proposed the theory of a generative lexicon as a framework by which meanings of words are expressed in one unified representation. This kind ofgenerativity would be very useful for NLP, especially if it is applicable to the complex semantic structures represented by various modification relations. In our previous research on adjectives (Isahara and Kanzaki, 1999) we used Pustejovsky's theory to classify adjectives in Japanese. In this paper we take the first steps in a similar classification of the Japanese &quot;noun + NO&quot; construction. Bouillon (Bouillon, 1996) applied this theory to the adnominal constituent of mental states. Saint-Dizier (Saint-Dizier, 1998) discussed adjectives in French. Isahara and Kanzaki (Isahara and Kanzaki, 1999) treated a much wider range of phenomena of adnominal constituents. They classified the semantic roles of adnominal constituents in .Japanese. where many parts of speech act as adnominal constituents, and discussed a for"
W00-0110,P98-2187,0,0.017927,"a framework by which meanings of words are expressed in one unified representation. This kind ofgenerativity would be very useful for NLP, especially if it is applicable to the complex semantic structures represented by various modification relations. In our previous research on adjectives (Isahara and Kanzaki, 1999) we used Pustejovsky's theory to classify adjectives in Japanese. In this paper we take the first steps in a similar classification of the Japanese &quot;noun + NO&quot; construction. Bouillon (Bouillon, 1996) applied this theory to the adnominal constituent of mental states. Saint-Dizier (Saint-Dizier, 1998) discussed adjectives in French. Isahara and Kanzaki (Isahara and Kanzaki, 1999) treated a much wider range of phenomena of adnominal constituents. They classified the semantic roles of adnominal constituents in .Japanese. where many parts of speech act as adnominal constituents, and discussed a for59 mal treatment of their semantic roles. In their research, adnominal constituents, mainly adjectives which function as adverbials, are discussed. The present paper describes the similarities and differences among adnominal constituents, i.e. adjectives and &quot;noun + NO t (in English &quot;of + noun&quot;)&quot; st"
W00-0110,C98-2182,0,\N,Missing
W01-0512,J96-1002,0,0.030443,") : verb (1) ( ) = > & =1 : 0 : otherwise h; x g h; f ; 00 x ; f : Here has(h,x)&quot; is a binary function that returns true if the history h has feature x. In our experiments, we focused on such information as whether or not a string is found in a dictionary, the length of the string, what types of characters are used in the string, and the part-of-speech of the adjacent morpheme. Given a set of features and some training data, the M.E. estimation process produces a model in which every feature gi has an associated parameter i . This enables us to compute the conditional probability as follows (Berger et al., 1996): P (f jh) = Z (h) = Q g (h;f ) i i i Z (h) gi i (h;f ) : f i XY (2) (3) The M.E. estimation process guarantees that for every feature gi , the expected value of gi according to the M.E. model will equal the empirical expectation of gi in the training corpus. In other words, X~ h;f P (h; f ) 1 gi (h; f ) = X~ h P (h) 1 X f PM:E: (f jh) 1 gi (h; f ): (4) Here P~ is an empirical probability and PM:E: is the probability assigned by the model. We de ne part-of-speech and bunsetsu boundaries as grammatical attributes. Here a bunsetsu is a phrasal unit consisting of one or more morphemes. When the"
W01-0512,J95-4004,0,0.149518,"Missing"
W01-0512,A92-1018,0,0.0221582,"Missing"
W01-0512,P97-1030,0,0.0242452,"Missing"
W01-0512,P97-1031,0,0.0336342,"Missing"
W01-0512,C96-2202,0,0.211023,"Missing"
W01-0512,C94-1032,0,0.0153311,"pheme and has the grammatical attribute i(1  i  n). We call it a morpheme model. This model is represented by Eq. (2), in which f can be one of (n + 1) tags from 0 to n. A given sentence is divided into morphemes, and a grammatical attribute is assigned to each morpheme so as to maximize the sentence probability estimated by our morpheme model. Sentence probability is de ned as the product of the probabilities estimated for a particular division of morphemes in a sentence. We use the Viterbi algorithm to nd the optimal set of morphemes in a sentence and we use the method proposed by Nagata (Nagata, 1994) to search for the Nbest sets. 3 Experiments and Discussion 3.1 Experimental Conditions The part-of-speech categories that we used follow those of JUMAN (Kurohashi and Nagao, 1999). There are 53 categories covering all possible combinations of major and minor categories as de ned in JUMAN. The number of grammatical attributes is 106 if we include the detection of whether or not the left side of a morpheme is a bunsetsu boundary. We do not identify in ection types probabilistically since 1 Not only morphemes but also bunsetsus can be identi ed by considering the information related to their bun"
W01-0512,P99-1036,0,0.582214,"menting a given sentence into a row of morphemes and assigning to each morpheme grammatical attributes such as a partof-speech (POS) and an in ection type. One of the most important problems in morphological analysis is that posed by unknown words, which are words found in neither a dictionary nor a training corpus, and there have been two statistical approaches to this problem. One is to acquire unknown words from corpora and put them into a dictionary (e.g., (Mori and Nagao, 1996)), and the other is to estimate a model that can identify unknown words correctly (e.g., (Kashioka et al., 1997; Nagata, 1999)). We would like to be able to make good use of both approaches. If words acquired by the former method could be added to a dictionary and a model developed by the latter method could consult the amended dictionary, then the model could be the best statistical model which has the potential to overcome the unknown word problem. Mori and Nagao proposed a statistical model that can consult a dictionary (Mori and Nagao, 1998). In their model the probability that a string of letters or characters is y Hitoshi Isahara sekine@cs.nyu.edu a morpheme is augmented when the string is found in a dictionary"
W01-0512,W96-0213,0,0.0502922,"Missing"
W01-0512,C94-1027,0,0.0244018,"Missing"
W01-0512,P94-1025,0,0.048906,"Missing"
W01-0512,E99-1026,1,0.87637,"Missing"
W01-0512,P98-1081,0,0.0207993,"Missing"
W01-1415,1999.tmi-1.7,1,\N,Missing
W01-1415,A97-1015,0,\N,Missing
W01-1415,C00-1082,1,\N,Missing
W01-1415,W00-0730,0,\N,Missing
W02-1107,P93-1023,0,0.0854817,"Missing"
W02-1107,W00-0110,1,\N,Missing
W02-1107,P90-1034,0,\N,Missing
W02-1107,P99-1063,1,\N,Missing
W03-1204,P98-1009,0,0.0289388,"eatures we use are worth analyzing. Sentence extraction is one of the main methods required for a summarization system to reduce the size of a document. Edmundson (1969) proposed a method of integrating several features, such as the positions of sentences and the frequencies of words in an article, in order to extract sentences. He manually assigned parameter values to integrate features for estimating the significance scores of sentences. On the other hand, machine learning methods can also be applied to integrate features. For sentence extraction from training data, Kupiec et al. (1995) and Aone et al. (1998) used Bayes’ rule, Lin (1999) and Nomoto and Matsumoto (1997) generated a decision tree, and Hirao et al. (2002) generated an SVM. In this paper, we not only show evaluation results for our sentence extraction system using combinations of features but also analyze the features for different types of corpora. The analysis gives us some indication about how to use these features and how to combine them. 2 Summarization data The summarization data we used for this research were prepared from Japanese newspaper articles, Japanese lectures, and English newspaper articles. By using these three types"
W03-1204,C02-1053,0,0.0850511,"system to reduce the size of a document. Edmundson (1969) proposed a method of integrating several features, such as the positions of sentences and the frequencies of words in an article, in order to extract sentences. He manually assigned parameter values to integrate features for estimating the significance scores of sentences. On the other hand, machine learning methods can also be applied to integrate features. For sentence extraction from training data, Kupiec et al. (1995) and Aone et al. (1998) used Bayes’ rule, Lin (1999) and Nomoto and Matsumoto (1997) generated a decision tree, and Hirao et al. (2002) generated an SVM. In this paper, we not only show evaluation results for our sentence extraction system using combinations of features but also analyze the features for different types of corpora. The analysis gives us some indication about how to use these features and how to combine them. 2 Summarization data The summarization data we used for this research were prepared from Japanese newspaper articles, Japanese lectures, and English newspaper articles. By using these three types of data, we could compare two languages and also two different types of corpora, a written corpus and a speech"
W03-1204,maekawa-etal-2000-spontaneous,1,0.885642,"Missing"
W03-1204,H01-1009,1,0.780656,"Si ) = w∈H∩Si tf(w) DN log tf(w)+1 df(w) X tf(w) w∈H tf(w)+1 log Ratio System Lead DN df(w) We also evaluated another method based on this scoring function by using only named entities (NEs) instead of words for the TSC data and DUC data. Only the term frequency was used for NEs, because we judged that the document frequency for an entity was usually quite small, thereby making the differences between entities negligible. 3.1.5 Patterns For the DUC data, we used dependency patterns as a type of scoring function. These patterns were extracted by pattern discovery during information extraction (Sudo et al., 2001). The details of this approach are not explained here, because this feature is not among the features we analyze in Section 5. The definition of the function appears in (Nobata et al., 2002). 3.2 Optimal weight Our system set weights for each scoring function in order to calculate the total score of a sentence. The total score (Si ) is defined from the scoring functions (Scorej ()) and weights (αj ) as follows: TotalScore(Si ) = X αj Scorej (Si ) (1) j We estimated the optimal values of these weights from the training data. After the range of each weight was set manually, the system changed th"
W03-1204,C98-1009,0,\N,Missing
W03-1204,nobata-etal-2002-summarization,1,\N,Missing
W03-1607,J96-1002,0,0.00571759,"Missing"
W03-1714,J93-2003,0,\N,Missing
W03-1714,C02-1060,1,\N,Missing
W03-1714,C88-1016,0,\N,Missing
W03-1714,C92-2101,0,\N,Missing
W03-1714,P95-1033,0,\N,Missing
W03-1714,P93-1004,0,\N,Missing
W03-1714,C02-1032,0,\N,Missing
W04-2208,C00-1007,0,0.0337696,"h expressions corresponding to a Japanese expression is 1.3 as shown in Table 2. Even when there are two or more possible English expressions, an appropriate English expression can be chosen by selecting a Japanese expression by referring to dependencies in extracted translation pairs. Therefore, in many cases, English sentences can be generated just by reordering the selected expressions. The English word order was estimated manually in this experiment. However, we can automatically estimate English word order by using a language model or an English surface sentence generator such as FERGUS (Bangalore and Rambow, 2000). Unnatural or ungrammatical parallel translations are sometimes generated in the above steps. However, comprehensible translations can be generated as shown in Figure 4. The biggest advantage of this framework is that comprehensible target sentences can be generated basically by referring only to source sentences. Although it is costly to search and select appropriate translation pairs, we believe that human labor can be reduced by developing a human interface. For example, when we use a Japanese text generation system from keywords (Uchimoto et al., 2002), users should only select appropriat"
W04-2208,P01-1030,0,0.0114299,"o a given sentence can be semiautomatically generated. In this paper we show that the framework can be achieved by using our aligned parallel treebank corpus. 1 ‡ New York University 715 Broadway, 7th floor 3-5 Hikari-dai, Seika-cho, Soraku-gun, New York, NY 10003, USA Kyoto 619-0289, Japan {sudo,sekine}@cs.nyu.edu {uchimoto,yujie,murata,isahara}@nict.go.jp Abstract pora and do not have bilingual or multilinNational Institute of Information and Communications Technology Introduction Recently, accurate machine translation systems can be constructed by using parallel corpora (Och and Ney, 2000; Germann et al., 2001). However, almost all existing machine translation systems do not consider the problem of translating a given sentence into a natural sentence reﬂecting its contextual information in the target language. One of the main reasons for this is that we had many problems that had to be solved by one-sentence to one-sentence machine translation before we could solve the contextual problem. Another reason is that it was diﬃcult to simply investigate the inﬂuence of the context on the translation because sentence correspondences of the existing bilingual documents are rarely one-to-one, and are usually"
W04-2208,2002.tmi-papers.9,0,0.015857,"and Japanese-English machine translation. We can directly compare various methods of machine translation by using this corpus. It can be summarized as follows in terms of the characteristics of the corpus. One-sentence to one-sentence translation can be simply used for the evaluation of various methods of machine translation. Morphological and syntactic information can be used for the evaluation of methods that actively use morphological and syntactic information, such as methods for examplebased machine translation (Nagao, 1981; Watanabe et al., 2003), or transfer-based machine translation (Imamura, 2002). Phrasal alignment is used for the evaluation of automatically acquired translation knowledge (Yamamoto and Matsumoto, 2003). An actual comparison and evaluation is our future work. 3.2 Analysis of Translation One-sentence to one-sentence translation reﬂects contextual information. Therefore, it is suitable to investigate the inﬂuence of the context on the translation. For example, we can investigate the diﬀerence in the use of demonstratives and pronouns between English and Japanese. We can also investigate the diﬀerence in the use of anaphora. Morphological and syntactic information and phr"
W04-2208,J93-2004,0,0.0235999,"ng a given sentence into a natural sentence reﬂecting its contextual information in the target language. One of the main reasons for this is that we had many problems that had to be solved by one-sentence to one-sentence machine translation before we could solve the contextual problem. Another reason is that it was diﬃcult to simply investigate the inﬂuence of the context on the translation because sentence correspondences of the existing bilingual documents are rarely one-to-one, and are usually one-to-many or many-to-many. On the other hand, high-quality treebanks such as the Penn Treebank (Marcus et al., 1993) and the Kyoto University text corpus (Kurohashi and Nagao, 1997) have contributed to improving the accuracies of fundamental techniques for natural language processing such as morphological analysis and syntactic structure analysis. However, almost all of these highquality treebanks are based on monolingual corgual information. There are few high-quality bilingual or multilingual treebank corpora because parallel corpora have mainly been actively used for machine translation between related languages such as English and French, therefore their syntactic structures are not required so much for"
W04-2208,P00-1056,0,0.126608,"ntence is similar to a given sentence can be semiautomatically generated. In this paper we show that the framework can be achieved by using our aligned parallel treebank corpus. 1 ‡ New York University 715 Broadway, 7th floor 3-5 Hikari-dai, Seika-cho, Soraku-gun, New York, NY 10003, USA Kyoto 619-0289, Japan {sudo,sekine}@cs.nyu.edu {uchimoto,yujie,murata,isahara}@nict.go.jp Abstract pora and do not have bilingual or multilinNational Institute of Information and Communications Technology Introduction Recently, accurate machine translation systems can be constructed by using parallel corpora (Och and Ney, 2000; Germann et al., 2001). However, almost all existing machine translation systems do not consider the problem of translating a given sentence into a natural sentence reﬂecting its contextual information in the target language. One of the main reasons for this is that we had many problems that had to be solved by one-sentence to one-sentence machine translation before we could solve the contextual problem. Another reason is that it was diﬃcult to simply investigate the inﬂuence of the context on the translation because sentence correspondences of the existing bilingual documents are rarely one-"
W04-2208,C02-1064,1,0.816552,"tence generator such as FERGUS (Bangalore and Rambow, 2000). Unnatural or ungrammatical parallel translations are sometimes generated in the above steps. However, comprehensible translations can be generated as shown in Figure 4. The biggest advantage of this framework is that comprehensible target sentences can be generated basically by referring only to source sentences. Although it is costly to search and select appropriate translation pairs, we believe that human labor can be reduced by developing a human interface. For example, when we use a Japanese text generation system from keywords (Uchimoto et al., 2002), users should only select appropriate keywords. We are investigating whether or not we can generate similar parallel translations to all of the Japanese sentences appearing on January 17, 1995. So far, we found that we can generate similar parallel translations to 691 out of 840 sentences (the average number of bunsetsus is about 10.3) including the 102 sentences described in Section 3.3. We found that we could not generate similar parallel translations to 149 out of 840 sentences. In the proposed framework of similar parallel translation generation, the language appearing in a corpus corresp"
W04-2208,P01-1067,0,0.102382,"erefore their syntactic structures are not required so much for aligning words or phrases. However, syntactic structures are necessary for machine translation between languages whose syntactic structures are diﬀerent from each other, such as in Japanese-English, Japanese-Chinese, and Chinese-English machine translations, because it is more diﬃcult to automatically align words or phrases between two unrelated languages than between two related languages. Actually, it has been reported that syntactic structures contribute to improving the accuracy of word alignment between Japanese and English (Yamada and Knight, 2001). Therefore, if we had a high-quality parallel treebank corpus, the accuracies of machine translation between languages whose syntactic structures are diﬀerent from each other would improve. Furthermore, if the parallel treebank corpus had word or phrase alignment, the accuracy of automatic word or phrase alignment would increase by using the parallel treebank corpus as training data. However, so far, there is no aligned parallel treebank corpus whose domain is not restricted. For example, the Japanese Electronics Industry Development Association’s (JEIDA’s) bilingual corpus (Isahara and Harun"
W04-2208,A00-2018,0,\N,Missing
W06-0116,N03-1028,0,0.101057,"eatures via doing statistics in training corpus. Our system incorporates basic features and additional features based on Conditional Random Fields (CRFs). In order to correct inconsistently results, we perform the postprocessing procedure according to n-best results given by the CRFs model. Our final system achieved a F-score of 85.14 at MSRA, 89.03 at CityU, and 76.27 at LDC. 1 2 Conditional Random Fields 2.1 The model Conditional Random Fields(CRFs), a statistical sequence modeling framework, was first introduced by Lafferty et al(Lafferty et al., 2001). The model has been used for chunking(Sha and Pereira, 2003). We only describe the model briefly since full details are presented in the paper(Lafferty et al., 2001). In this paper, we regard Chinese NER as a sequence labeling problem. For our sequence labeling problem, we create a linear-chain CRFs based on an undirected graph G = (V, E), where V is the set of random variables Y = {Yi |1 ≤ i ≤ n}, for each of n tokens in an input sentence and E = {(Yi−1 , Yi )|1 ≤ i ≤ n} is the set of n − 1 edges forming a linear chain. For each sentence x, we define two non-negative factors: P exp( K λk fk (yi−1 , yi , x)) for each edge k=1 PK 0 0 0 exp( k=1 λk fk (y"
W06-0201,I05-2043,1,0.873246,"Missing"
W06-3707,2005.eamt-1.8,1,0.885548,"Missing"
W06-3707,2002.tmi-papers.17,0,0.0583709,"s domain for the three main input languages. Differences in the sizes of the recognition vocabularies are primarily due to differences in use of inflection. Japanese, with little inflectional morphology, has the smallest vocabulary; French, which inflects most parts of speech, has the largest. 3 The development environment Although the MedSLT system is rule-based, we would, for the usual reasons, prefer to acquire these rules from corpora using some well-defined method. There is, however, little or no material available for most medical speech translation domains, including ours. As noted in (Probst and Levin, 2002), scarcity of data generally implies use of some strategy to obtain a carefully structured training corpus. If the corpus is not organised in this way, conflicts between alternate learned rules occur, and it is hard to inWhere? “do you experience the pain in your jaw” “does the pain spread to the shoulder” When? “have you had the pain for more than a month” “do the headaches ever occur in the morning” How long? “does the pain typically last a few minutes” “does the pain ever last more than two hours” How often? “do you get headaches several times a week” “are the headaches occurring more often"
W06-3707,E03-2010,1,0.863259,"Missing"
W06-3707,2005.jeptalnrecital-long.17,1,0.922576,"k is for the moment statistical, but rule-based systems are still a very respectable alternative. In particular, nearly all systems which have actually been deployed are rulebased. Prominent examples are (Phraselator, 2006; S-MINDS, 2006; MedBridge, 2006). MedSLT (MedSLT, 2005; Bouillon et al., 2005) is a unidirectional medical speech translation system for use in doctor-patient diagnosis dialogues, which covers several different language pairs and subdomains. Recognition is performed using grammarThe MedSLT demonstrator has already been extensively described elsewhere (Bouillon et al., 2005; Rayner et al., 2005a), so this section will only present a brief summary. The main components are a set of speech recognisers for the source languages, a set of generators for the target languages, a translation engine, sets of rules for translating to and from interlingua, a simple discourse engine for dealing with context-dependent translation, and a top-level which manages the information flow between the other modules and the user. MedSLT also includes an intelligent help module, which adds robustness to the system and guides the user towards the supported coverage. The help module uses a backup recogniser,"
W06-3707,2005.mtsummit-papers.25,1,0.872166,"Missing"
W08-1506,W07-1806,1,0.886739,"Missing"
W08-1506,bouillon-etal-2008-developing,1,0.895278,"fr Abstract 1 Introduction MedSLT is a medium-vocabulary grammar-based medical speech translation system built on top of the Regulus platform (Rayner et al., 2006). It is intended for use in doctor-patient diagnosis dialogues, and provides coverage of several subdomains and a large number of different languagepairs. Coverage is based on standard examination questions obtained from physicians, and focusses primarily on yes/no questions, though there is also support for WH-questions and elliptical utterances. Detailed descriptions of MedSLT can be found in earlier papers (Bouillon et al., 2005; Bouillon et al., 2008)1 . In the rest of this note, we will briefly sketch several versions of the system that we intend to demo at the workshop, each of which displays new features developed over the last year. Section 2 describes an any-language-toany-language multilingual version of the system; Section 3, a bidirectional English ↔ Spanish version; Section 4, a version running on a mobile PDA MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs. Vocabulary ranges from"
W08-1506,W06-3702,1,0.905634,"Missing"
W08-1506,W07-1807,1,0.893685,"Missing"
W08-1506,tsourakis-etal-2008-building,1,0.874379,"Missing"
W08-1506,2005.eamt-1.8,1,0.858642,"ukie.nakao@univ-nantes.fr Abstract 1 Introduction MedSLT is a medium-vocabulary grammar-based medical speech translation system built on top of the Regulus platform (Rayner et al., 2006). It is intended for use in doctor-patient diagnosis dialogues, and provides coverage of several subdomains and a large number of different languagepairs. Coverage is based on standard examination questions obtained from physicians, and focusses primarily on yes/no questions, though there is also support for WH-questions and elliptical utterances. Detailed descriptions of MedSLT can be found in earlier papers (Bouillon et al., 2005; Bouillon et al., 2008)1 . In the rest of this note, we will briefly sketch several versions of the system that we intend to demo at the workshop, each of which displays new features developed over the last year. Section 2 describes an any-language-toany-language multilingual version of the system; Section 3, a bidirectional English ↔ Spanish version; Section 4, a version running on a mobile PDA MedSLT is a grammar-based medical speech translation system intended for use in doctor-patient diagnosis dialogues, which provides coverage of several different subdomains and multiple language pairs."
W08-1910,A00-2006,0,\N,Missing
W08-1910,C02-1144,0,\N,Missing
W08-1910,P06-2072,0,\N,Missing
W08-1910,kanzaki-etal-2006-semantic,1,\N,Missing
W09-3401,vossen-etal-2008-kyoto,1,\N,Missing
W09-3401,C04-1053,0,\N,Missing
W09-3401,W04-2209,0,\N,Missing
W09-3401,W04-2208,1,\N,Missing
W09-3401,W07-1522,0,\N,Missing
W09-3401,I08-2108,1,\N,Missing
W09-3401,bond-etal-2008-boot,1,\N,Missing
W09-3401,francopoulo-etal-2006-lexical,0,\N,Missing
W09-3401,1991.mtsummit-papers.16,0,\N,Missing
W09-3420,I08-2091,1,0.885731,"Missing"
W09-3420,W98-0709,0,0.103363,"Missing"
W09-3420,isahara-etal-2008-development,1,\N,Missing
W09-3426,W09-3426,1,0.0512755,"Missing"
W14-0144,N06-1023,0,0.0295357,"nd noise-resistant measure. Values obtained by CSM indicate relations between words, such as Hypernym-Hyponym. We named data obtained in these process “CSM data.” Comparing the Japanese Wordnet and the CSM data, we found a lot of words and word relations that retrieved from web corpus but that have not been stored in the Wordnet. Therefore, we constructed new conceptual system based on the Japanese Wordnet that enriched by conceptual relationships with word pairs in CSM data. 2.3 Experimental data based on case relation In our experiment, we use web corpus with 500 million Japanese sentences (Kawahara and Kurohashi, 2006). We analyze syntactically 500 million sentences and extract pairs of words having co-occurrence relations in an actual sentence by focusing on case relation, namely modified/modifier relationship. Then, we calculate CSM value for each pairs, after we reduce some noises in the extracted pairs by setting a threshold value. To estimate inclusive relations between words, we applied the method based on the CSM, which estimates inclusive relations between two vectors (Yamamoto et al., 2011). By using an appearance pattern as a feature vector for each word in treating linguistic resource such as a c"
W98-0202,H94-1070,0,0.0548158,"research has been limited to generating abstracts or extracting some topics. However, they are immature and still have many problems. No one, yet, has established a way for the user to tell a news reader what he/she requires. 3 Information Reader Retrieval and News There is much on-going research in information retrieval. In document retrieval, the key technology is the utilization of keywords, titles, and user defined &quot;key words&quot; (Jacobs, 1992). Full text search is now very fast using some programming techniques. T R E C (Text Retrieval Conference) by A R P A includes this kind of approach (Harman, 1994). One of the targets of the summarization and information extraction domains is to plug information into some templates. MUC (Message Understanding Conference) by ARPA is in~colved in doing this kind of work (ARPA, 1993). However, these approaches are not suitable for information retrieval from the network news on the Internet. Therefore, there have been many proposals for network news readers. For example, &quot;Galaxy of News&quot; retrieves sets of information related to one another by adopting a stochastic method to produce a hierarchy of keywords and it presents the results of the search visually,"
W99-0205,1993.tmi-1.18,1,0.887395,"an example of the form &quot;Noun X no Noun Y&quot; (Y of X), when noun Y is a 33 Table 5: Case frame of verb &quot;mukad&apos; (go to) Surface case ga-case (subject) n/-case (object) Semantic constraint concrete place a focus is defined as a word which is stressed by the speaker (or the writer). But we cannot detect topics and foci correctly. Therefore we approximated them as shown in Table 3 and Table 4. The distance D is the number of the topics (foci) between the anaphor and a possible antecedent which is a topic (focus). The value P is given by the score of the definiteness in referential property analysis (Murata and Nagao, 1993). This is because it is easier for a definite noun phrase to have an antecedent than for an indefinite noun phrase to have one. The value S is the semantic similarity between a possible antecedent and Noun X of &quot;Noun X no Noun Y.&quot; Semantic similarity is shown by level in Bunrui Goi Hyou (NLRI, 1964). in meaning. ojiisan-wa ooyorokobi-wo-shite ie-ni kaerimashita. (the old man) (in great joy) (house) (returned) [The old man returned home (house) in great joy,] okotta koto-wo hitobito-ni hanashimashita (happened to him) (all things) (everybody) (told) (and told everybody all that had happened to"
W99-0205,J94-2003,0,\N,Missing
W99-0206,P86-1031,0,0.018776,"Missing"
W99-0206,J94-2003,0,\N,Missing
W99-0206,C94-2188,0,\N,Missing
W99-0206,C96-2134,1,\N,Missing
Y04-1017,P03-1010,1,0.875737,"Missing"
Y04-1018,C02-1011,0,0.01304,"words is an important problem related to the construction of translation dictionaries. On the one hand, the published paper bilingual dictionaries usually collect translations for simple words but not for compound words. On the other hand, new compound words emerge every day. It is reported that most compound words are nominal words. In natural language comprehension, entities or concepts to be recognized are usually described by nouns or compound nouns. Therefore, acquiring translations for compound nouns is extremely important in machine translation and cross-language information retrieval [Cao and Li, 2002; Nakagawa, 2001]. In resolving this problem, we propose a self-learning mechanism that can dynamically and automatically acquire compound words translations from the web and corpora. Here we take Japanese-Chinese language pairs as an instance for illustration and report initial experiment results. The proposed method can also be applied to other language pairs since it is language-independent. 2 Overview of the self-learning mechanism The self-learning mechanism aims at automatically and dynamically expanding the translation dictionary of compound word. It is implemented in two parts: collect"
Y04-1018,W01-1413,0,0.0314006,"osition patterns. Two examples of the obtained compound words are listed below. Ex.1. Ex.2. アーバンソシオロジー (urban sociology) Part-Of-Speech: noun Composition: ”アーバン(urban) + ソシオロジー (sociology)” Composition pattern: ”noun + noun” アーク電流 (arc current) Part-Of-Speech: noun Composition: ”アーク(arc)+ 電流(current)” Composition pattern: ”noun + noun” Table 1 Extracted composition patterns within the top 4 Composition Pattern Noun + Noun Noun + Suffix Noun + Verb Verb + Verb 3 Count 17,481 8089 6838 6322 Approaches to acquiring translations There are two points underlying our approach: (1) exploring the web [Nagata, et al., 2001] because most new compound words or terminology appear there before they appear in corpora, and (2) utilizing English translations to link the Japanese word and corresponding Chinese translations because there is an abundance of resources for Japanese-English and English-Chinese translation. For a given Japanese compound word, we can try the following approach in turn. Approach 1 First, get an English translation by looking it up in the Japanese-English dictionary or by searching the Japanese web where the Japanese compound word is followed by an English expression, which might be its English"
Y04-1019,P02-1051,0,0.205523,"Missing"
Y04-1019,C02-2020,0,0.0574249,"Missing"
Y04-1019,A94-1006,0,0.0361235,"as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is well known, statistical methods often encounter serious problems. Although literature on this task is available (Dagan & Church 1994; Tsuji 2001), it calls for further investigation to determine what kinds of linguistic information we should use and how we should combine them. - 187 - We propose a method of extracting the bilingual pair of an English multi-word named entity (hereafter MWNE) and its Japanese counterpart. Here we focus our attention on the MWNEs which appear just once in a parallel corpus and are not listed in the dictionary of a practical English-to-Japanese machine translation (MT) system. Our method keeps four kinds of scores for a bilingual pair based on the internal and external evidence of the pair. In"
Y04-1019,1994.amta-1.26,0,0.0146349,". 1 Introduction Over the past few decades, English-to-Japanese bilingual dictionaries have been expanded both in quality and in quantity. The development has led to the practical use of MT systems which have the dictionaries of more than two millions of entries. But words which are not found even in such large-scale dictionaries can appear in real life texts. Since they are not found in the large dictionaries, they would appear infrequently in corpora. Many researches have pursued the extraction of bilingual pairs from a parallel corpus in which sentences are aligned (Eijk 1993; Kupiec 1993; Dekai & Xia 1994; Smadja & McKeown 1996; Ker & Chang 1997; Le et al. 1999; Huang et al. 2003), as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is well known, statistical methods of"
Y04-1019,E93-1015,0,0.0397683,"ere judged to be correct. 1 Introduction Over the past few decades, English-to-Japanese bilingual dictionaries have been expanded both in quality and in quantity. The development has led to the practical use of MT systems which have the dictionaries of more than two millions of entries. But words which are not found even in such large-scale dictionaries can appear in real life texts. Since they are not found in the large dictionaries, they would appear infrequently in corpora. Many researches have pursued the extraction of bilingual pairs from a parallel corpus in which sentences are aligned (Eijk 1993; Kupiec 1993; Dekai & Xia 1994; Smadja & McKeown 1996; Ker & Chang 1997; Le et al. 1999; Huang et al. 2003), as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is wel"
Y04-1019,W03-1502,0,0.0229944,"ictionaries have been expanded both in quality and in quantity. The development has led to the practical use of MT systems which have the dictionaries of more than two millions of entries. But words which are not found even in such large-scale dictionaries can appear in real life texts. Since they are not found in the large dictionaries, they would appear infrequently in corpora. Many researches have pursued the extraction of bilingual pairs from a parallel corpus in which sentences are aligned (Eijk 1993; Kupiec 1993; Dekai & Xia 1994; Smadja & McKeown 1996; Ker & Chang 1997; Le et al. 1999; Huang et al. 2003), as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is well known, statistical methods often encounter serious problems. Although literature on this task is available"
Y04-1019,C96-1006,0,0.0246768,"of the pronunciation of its possible translation J. Then we can obtain the score of phonological correspondences for the bilingual pair, S2, according to such a formula as (1). In the case of the above example, the member of the intersection of the two sets X and Y is ナラ nara “nara”, and the members of the union of the two sets are ナラ nara “nara”, “festival” and マツリ matsuri “festival”. We obtain the score of S2(Nara festival, 奈良祭り nara matsuri “nara festival”) equal to 1/3. 3.3 Similarity of Neighboring Nouns In a parallel corpus, bilingual pairs of words commonly appear in similar contexts (Kaji & Aizono 1996; Fung 1998). This means that a similar context would encourage the likelihood of a bilingual pair. We represent the context of an MWNE by a set of nouns surrounding it, which we refer to as neighboring nouns. We suppose that the number of the neighboring nouns of an MWNE is proportional to the total number of nouns in the sentence in which the MWNE appears: the number of the neighboring nouns is a quarter of the total number of nouns which locate on the right and left of the MWNE respectively. We do the same for the possible translations of an MWNE. (2) a. Germany provided a new impetus to Eu"
Y04-1019,J97-2004,0,0.0242007,"s, English-to-Japanese bilingual dictionaries have been expanded both in quality and in quantity. The development has led to the practical use of MT systems which have the dictionaries of more than two millions of entries. But words which are not found even in such large-scale dictionaries can appear in real life texts. Since they are not found in the large dictionaries, they would appear infrequently in corpora. Many researches have pursued the extraction of bilingual pairs from a parallel corpus in which sentences are aligned (Eijk 1993; Kupiec 1993; Dekai & Xia 1994; Smadja & McKeown 1996; Ker & Chang 1997; Le et al. 1999; Huang et al. 2003), as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is well known, statistical methods often encounter serious problems. Although"
Y04-1019,C94-1009,0,0.0444005,"Missing"
Y04-1019,P93-1003,0,0.039368,"to be correct. 1 Introduction Over the past few decades, English-to-Japanese bilingual dictionaries have been expanded both in quality and in quantity. The development has led to the practical use of MT systems which have the dictionaries of more than two millions of entries. But words which are not found even in such large-scale dictionaries can appear in real life texts. Since they are not found in the large dictionaries, they would appear infrequently in corpora. Many researches have pursued the extraction of bilingual pairs from a parallel corpus in which sentences are aligned (Eijk 1993; Kupiec 1993; Dekai & Xia 1994; Smadja & McKeown 1996; Ker & Chang 1997; Le et al. 1999; Huang et al. 2003), as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is well known, stat"
Y04-1019,E03-1035,0,0.0151174,"can appear in real life texts. Since they are not found in the large dictionaries, they would appear infrequently in corpora. Many researches have pursued the extraction of bilingual pairs from a parallel corpus in which sentences are aligned (Eijk 1993; Kupiec 1993; Dekai & Xia 1994; Smadja & McKeown 1996; Ker & Chang 1997; Le et al. 1999; Huang et al. 2003), as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is well known, statistical methods often encounter serious problems. Although literature on this task is available (Dagan & Church 1994; Tsuji 2001), it calls for further investigation to determine what kinds of linguistic information we should use and how we should combine them. - 187 - We propose a method of extracting the bilingual pair of an English multi-wo"
Y04-1019,J96-1001,0,0.0205255,"ver the past few decades, English-to-Japanese bilingual dictionaries have been expanded both in quality and in quantity. The development has led to the practical use of MT systems which have the dictionaries of more than two millions of entries. But words which are not found even in such large-scale dictionaries can appear in real life texts. Since they are not found in the large dictionaries, they would appear infrequently in corpora. Many researches have pursued the extraction of bilingual pairs from a parallel corpus in which sentences are aligned (Eijk 1993; Kupiec 1993; Dekai & Xia 1994; Smadja & McKeown 1996; Ker & Chang 1997; Le et al. 1999; Huang et al. 2003), as well as from a comparable corpus in which sentences are not aligned (e.g. Tanaka 1999; Nakagawa 2001; Chiao 2002). Furthermore, some researchers have focused on the extraction of multi-word named entity translations (Al-Onaizan 2002; Moore 2003). The methods of extracting the bilingual pairs from a parallel corpus seem to have been established. However, in the case of aiming at extraction of the bilingual pair of a word with low frequency of occurrence and its counterpart, as is well known, statistical methods often encounter serious p"
Y04-1019,1999.tmi-1.11,0,0.061267,"Missing"
Y04-1019,P03-1010,1,0.881922,"Missing"
Y04-1019,C96-2164,0,0.0148538,"the order of S3 < S1 = S4 < S2, the result of the logistic regression analysis shows that the appropriate order is S4 < S3 < S2 < S1. Each bilingual pair is given one of the two evaluations: ``correct&apos;&apos; or ``incorrect&apos;&apos;. A bilingual pair would be judged to be correct when it can be registered in the MT dictionary without any modification of Japanese words: for example, the bilingual pair of “Comprehensive Security Board” and 総合安全保障審議会 sogo anzen hosho shingikai “comprehensive safety security council” is judged to 6 Regression analysis has been used for NLP research such as text summarization (Watanabe 1996). - 192 - PACLIC 18, December 8th-10th, 2004, Waseda University, Tokyo be correct. The judgment “incorrect” would be given to a pair when it needs adding, deleting or replacing of Japanese words. 4.2 Evaluation For evaluation, we randomly sampled 264 MWNEs from the full results. The number of possible translations for these 264 MWNEs were 1086. Each MWNE has 4.11 (1086/264) possible translations on average. Table 2 shows the results of the two experiments: one is carried out with the use of the weights decided empirically (ED), and the other with the use of the weights obtained by the logistic"
Y04-1032,1993.tmi-1.18,1,0.653491,"freading. (For a detailed description of the method used to extract diﬀerences, see (Murata and Isahara, 2002a; Murata and Isahara, 2002c; Murata, 2002; Murata and Isahara, 2002b).) We then counted the frequencies of the extracted English error patterns. The results are shown in Table 1. φ indicates a void: “φ ⇒” and “⇒ φ” indicate insertion and deletion, respectively. The results showed that most of the errors made by the ﬁrst author related to usage of “the”, with “a” being the next most frequent source of error. Correct usage of articles (“a” and “the”) is very diﬃcult for Japanese people (Murata and Nagao, 1993) and in this case, the author was Japanese. The next most frequent source of error was tenses such as “is” ⇒ “was” and “are” ⇒ “were”. Interestingly, the errors relating to articles were symmetrical, while those relating to tenses were not. The frequency of “is” ⇒ “was” was high, but that of “was” ⇒ “is” was low. The reason for this lack of symmetry may be that “is” and “are” are default forms and they are often used. The next most common errors related to prepositions such as φ ⇒ “of”, “of” ⇒ “for”, and “in” ⇒ “of”. We also noticed errors relating to “which” ⇒ “that” and “having” ⇒ “with”. We"
Y04-1032,P98-2174,0,0.0121267,"“recorededed”, which is a typo, is also given “[Caution!]”. In future work, we would like to develop a system that stores all the sentences that a user has written and read and show him/her which word he/she ﬁrst encountered when a new sentence is presented. (We have already investigated a system for highlighting expressions that appear ﬁrst in documents (Murata and Isahara, 2002c).) We also consider that it may be interesting to highlight the words that appear ﬁrst in English language school textbooks. Although there are systems that provide translations or meaning glosses to assist readers (Poznanski et al., 1998), the ideas of user-dependent processing and highlighting expressions that appear ﬁrst are novel and in future, we would like to further examine these concepts. 5 Conclusion We used automatic paraphrasing techniques based on natural language processing to develop three systems for helping English learners and beginners. They included a system for extracting personal error patterns in the user’s English usage; a system for transforming English sentences containing the letters “l” and “r”, which Japanese people have trouble pronouncing, into sentences containing fewer instances of these letters;"
Y04-1032,C98-2169,0,\N,Missing
Y04-1032,murata-isahara-2002-automatic,1,\N,Missing
Y05-1014,W00-1303,0,0.012695,"nai (do not), shinakatta (did not). • Feature Set 2 This set consisted of all of the morphemes in each of the input sentences, e.g., kyou (today), watashi (I), wa (topic-marker particle), hashiru (run). 1 This corpus was made in our previous studies (Murata et al., 2002b; Murata et al., 2005). We found that support vector machines were more accurate than other kinds of machine learning methods such as the decision-list method and maximum entropy method (Murata et al., 2001). In addition, the use of support vector machines has been found to be effective in many studies (Taira and Haruno, 2001; Kudo and Matsumoto, 2000; Nakagawa et al., 2001; Murata et al., 2002a). Therefore, we used support vector machines in our translation systems. The detailed parameter settings we used are described in our previous paper (Murata et al., 2001). 2 Proceedings of PACLIC 19, the 19th Asia-Pacific Conference on Language, Information and Computation. Table 1: Occurrence rates of correct categories for tense, aspect, and modality. Category Occurrence rate present 0.65 (516/800) past 0.45 (356/800) prefect 0.32 (259/800) “can” 0.11 (90/800) “will” 0.11 (87/800) progressive 0.10 (82/800) imperative 0.09 (74/800) “should” 0.07 ("
Y05-1014,W01-1415,1,0.931958,"(one category) 5. participial constructions (one category) 6. verb ellipses (one category) 7. interjections or greeting sentences (one category) We used 800 sentences extracted from a corpus1 containing 40,198 sentences for the evaluation. We calculated the accuracy rates of six translation systems on the market and our new translation systems and examined the error patterns in the results. The six translation systems were the latest of leading translation system companies as of October 2003. Our systems for translating tense, aspect, and modality are based on support vector machines (SVMs) (Murata et al., 2001).2 They translate Japanese tense, aspect, and modality expressions into English. They detect categories of tense, aspect, and modality previously defined from English expressions. The categories are detected as a categorization problem by SVMs (Cristianini and Shawe-Taylor, 2000; Kudoh, 2000). However, an SVM can handle only two categories at a time. Therefore, we used a pairwise method in addition to the SVM to handle more than two categories (Moreira and Mayoraz, 1998). As training sentences, we used the sentences remaining after eliminating the 800 evaluation sentences from the 40,198-sente"
Y05-1014,2002.tmi-papers.14,1,0.747648,"Missing"
Y06-1039,P97-1023,0,0.237241,"Missing"
Y06-1039,C00-1044,0,0.0919864,"Missing"
yamamoto-etal-2006-detection,C04-1165,1,\N,Missing
yamamoto-etal-2006-detection,H92-1074,0,\N,Missing
yamamoto-etal-2006-detection,P04-3015,1,\N,Missing
yamamoto-etal-2008-extraction,W04-2607,0,\N,Missing
yamamoto-etal-2008-extraction,C00-1027,0,\N,Missing
yamamoto-etal-2008-extraction,C96-1009,0,\N,Missing
yamamoto-etal-2008-extraction,P07-2036,1,\N,Missing
yamamoto-etal-2008-extraction,P03-2016,0,\N,Missing
yamamoto-etal-2008-extraction,P98-2127,0,\N,Missing
yamamoto-etal-2008-extraction,C98-2122,0,\N,Missing
yamamoto-etal-2008-extraction,kiyota-nakagawa-2006-domain,0,\N,Missing
zhang-etal-2008-word,W04-2208,1,\N,Missing
zhang-etal-2008-word,I05-2015,1,\N,Missing
zhang-etal-2008-word,2005.mtsummit-papers.10,1,\N,Missing
zhang-etal-2008-word,maekawa-etal-2000-spontaneous,1,\N,Missing
