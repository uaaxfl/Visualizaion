2021.woah-1.6,{DALC}: the {D}utch Abusive Language Corpus,2021,-1,-1,7,0,6,tommaso caselli,Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021),0,"As socially unacceptable language become pervasive in social media platforms, the need for automatic content moderation become more pressing. This contribution introduces the Dutch Abusive Language Corpus (DALC v1.0), a new dataset with tweets manually an- notated for abusive language. The resource ad- dress a gap in language resources for Dutch and adopts a multi-layer annotation scheme modeling the explicitness and the target of the abusive messages. Baselines experiments on all annotation layers have been conducted, achieving a macro F1 score of 0.748 for binary classification of the explicitness layer and .489 for target classification."
2021.teachingnlp-1.7,A dissemination workshop for introducing young {I}talian students to {NLP},2021,-1,-1,7,0,786,lucio messina,Proceedings of the Fifth Workshop on Teaching NLP,0,We describe and make available the game-based material developed for a laboratory run at several Italian science festivals to popularize NLP among young students.
2021.teachingnlp-1.26,Teaching {NLP} with Bracelets and Restaurant Menus: An Interactive Workshop for {I}talian Students,2021,-1,-1,7,0,790,ludovica pannitto,Proceedings of the Fifth Workshop on Teaching NLP,0,"Although Natural Language Processing is at the core of many tools young people use in their everyday life, high school curricula (in Italy) do not include any computational linguistics education. This lack of exposure makes the use of such tools less responsible than it could be, and makes choosing computational linguistics as a university degree unlikely. To raise awareness, curiosity, and longer-term interest in young people, we have developed an interactive workshop designed to illustrate the basic principles of NLP and computational linguistics to high school Italian students aged between 13 and 18 years. The workshop takes the form of a game in which participants play the role of machines needing to solve some of the most common problems a computer faces in understanding language: from voice recognition to Markov chains to syntactic parsing. Participants are guided through the workshop with the help of instructors, who present the activities and explain core concepts from computational linguistics. The workshop was presented at numerous outlets in Italy between 2019 and 2020, both face-to-face and online."
2021.gem-1.2,Human Perception in Natural Language Generation,2021,-1,-1,4,1,6234,lorenzo mattei,"Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)",0,"We ask subjects whether they perceive as human-produced a bunch of texts, some of which are actually human-written, while others are automatically generated. We use this data to fine-tune a GPT-2 model to push it to generate more human-like texts, and observe that this fine-tuned model produces texts that are indeed perceived more human-like than the original model. Contextually, we show that our automatic evaluation strategy well correlates with human judgements. We also run a linguistic analysis to unveil the characteristics of human- vs machine-perceived language."
2021.findings-acl.74,As Good as New. How to Successfully Recycle {E}nglish {GPT}-2 to Make Models for Other Languages,2021,-1,-1,2,1,3041,wietse vries,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.findings-acl.433,Adapting Monolingual Models: Data can be Scarce when Language Similarity is High,2021,-1,-1,3,1,3041,wietse vries,Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021,0,None
2021.emnlp-main.349,Generic resources are what you need: Style transfer tasks without task-specific parallel training data,2021,-1,-1,3,1,6235,huiyuan lai,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Style transfer aims to rewrite a source text in a different target style while preserving its content. We propose a novel approach to this task that leverages generic resources, and without using any task-specific parallel (source{--}target) data outperforms existing unsupervised approaches on the two most popular style transfer tasks: formality transfer and polarity swap. In practice, we adopt a multi-step procedure which builds on a generic pre-trained sequence-to-sequence model (BART). First, we strengthen the model{'}s ability to rewrite by further pre-training BART on both an existing collection of generic paraphrases, as well as on synthetic pairs created using a general-purpose lexical resource. Second, through an iterative back-translation approach, we train two models, each in a transfer direction, so that they can provide each other with synthetically generated pairs, dynamically in the training process. Lastly, we let our best resulting model generate static synthetic pairs to be used in a supervised training regime. Besides methodology and state-of-the-art results, a core contribution of this work is a reflection on the nature of the two tasks we address, and how their differences are highlighted by their response to our approach."
2021.acl-short.62,Thank you {BART}! Rewarding Pre-Trained Models Improves Formality Style Transfer,2021,-1,-1,3,1,6235,huiyuan lai,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"Scarcity of parallel data causes formality style transfer models to have scarce success in preserving content. We show that fine-tuning pre-trained language (GPT-2) and sequence-to-sequence (BART) models boosts content preservation, and that this is possible even with limited amounts of parallel data. Augmenting these models with rewards that target style and content {--}the two core aspects of the task{--} we achieve a new state-of-the-art."
2020.restup-1.4,"Lower Bias, Higher Density Abusive Language Datasets: A Recipe",2020,-1,-1,3,0,15629,juliet rosendaal,Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language,0,"Datasets to train models for abusive language detection are at the same time necessary and still scarce. One the reasons for their limited availability is the cost of their creation. It is not only that manual annotation is expensive, it is also the case that the phenomenon is sparse, causing human annotators having to go through a large number of irrelevant examples in order to obtain some significant data. Strategies used until now to increase density of abusive language and obtain more meaningful data overall, include data filtering on the basis of pre-selected keywords and hate-rich sources of data. We suggest a recipe that at the same time can provide meaningful data with possibly higher density of abusive language and also reduce top-down biases imposed by corpus creators in the selection of the data to annotate. More specifically, we exploit the controversy channel on Reddit to obtain keywords that are used to filter a Twitter dataset. While the method needs further validation and refinement, our preliminary experiments show a higher density of abusive tweets in the filtered vs unfiltered dataset, and a more meaningful topic distribution after filtering."
2020.peoples-1.2,Matching Theory and Data with Personal-{ITY}: What a Corpus of {I}talian {Y}ou{T}ube Comments Reveals About Personality,2020,-1,-1,2,0,15727,elisa bassignana,"Proceedings of the Third Workshop on Computational Modeling of People's Opinions, Personality, and Emotion's in Social Media",0,"As a contribution to personality detection in languages other than English, we rely on distant supervision to create Personal-ITY, a novel corpus of YouTube comments in Italian, where authors are labelled with personality traits. The traits are derived from one of the mainstream personality theories in psychology research, named MBTI. Using personality prediction experiments, we (i) study the task of personality prediction in itself on our corpus as well as on TWISTY, a Twitter dataset also annotated with MBTI labels; (ii) carry out an extensive, in-depth analysis of the features used by the classifier, and view them specifically under the light of the original theory that we used to create the corpus in the first place. We observe that no single model is best at personality detection, and that while some traits are easier than others to detect, and also to match back to theory, for other, less frequent traits the picture is much more blurred."
2020.lrec-1.35,{MAGPIE}: A Large Corpus of Potentially Idiomatic Expressions,2020,-1,-1,3,1,16657,hessel haagsma,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Given the limited size of existing idiom corpora, we aim to enable progress in automatic idiom processing and linguistic analysis by creating the largest-to-date corpus of idioms for English. Using a fixed idiom list, automatic pre-extraction, and a strictly controlled crowdsourced annotation procedure, we show that it is feasible to build a high-quality corpus comprising more than 50K instances, an order of a magnitude larger than previous resources. Crucial ingredients of crowdsourcing were the selection of crowdworkers, clear and comprehensive instructions, and an interface that breaks down the task in small, manageable steps. Analysis of the resulting corpus revealed strong effects of genre on idiom distribution, providing new evidence for existing theories on what influences idiom usage. The corpus also contains rich metadata, and is made publicly available."
2020.lrec-1.828,Invisible to People but not to Machines: Evaluation of Style-aware {H}eadline{G}eneration in Absence of Reliable Human Judgment,2020,-1,-1,4,1,6234,lorenzo mattei,Proceedings of the 12th Language Resources and Evaluation Conference,0,"We automatically generate headlines that are expected to comply with the specific styles of two different Italian newspapers. Through a data alignment strategy and different training/testing settings, we aim at decoupling content from style and preserve the latter in generation. In order to evaluate the generated headlines{'} quality in terms of their specific newspaper-compliance, we devise a fine-grained evaluation strategy based on automatic classification. We observe that our models do indeed learn newspaper-specific style. Importantly, we also observe that humans aren{'}t reliable judges for this task, since although familiar with the newspapers, they are not able to discern their specific styles even in the original human-written headlines. The utility of automatic evaluation goes therefore beyond saving the costs and hurdles of manual annotation, and deserves particular care in its design."
2020.gebnlp-1.1,Unmasking Contextual Stereotypes: Measuring and Mitigating {BERT}{'}s Gender Bias,2020,-1,-1,2,0,19257,marion bartl,Proceedings of the Second Workshop on Gender Bias in Natural Language Processing,0,"Contextualized word embeddings have been replacing standard embeddings as the representational knowledge source of choice in NLP systems. Since a variety of biases have previously been found in standard word embeddings, it is crucial to assess biases encoded in their replacements as well. Focusing on BERT (Devlin et al., 2018), we measure gender bias by studying associations between gender-denoting target words and names of professions in English and German, comparing the findings with real-world workforce statistics. We mitigate bias by fine-tuning BERT on the GAP corpus (Webster et al., 2018), after applying Counterfactual Data Substitution (CDS) (Maudslay et al., 2019). We show that our method of measuring bias is appropriate for languages such as English, but not for languages with a rich morphology and gender-marking, such as German. Our results highlight the importance of investigating bias and mitigation techniques cross-linguistically,especially in view of the current emphasis on large-scale, multilingual language models."
2020.findings-emnlp.389,What{'}s so special about {BERT}{'}s layers? A closer look at the {NLP} pipeline in monolingual and multilingual models,2020,16,0,3,1,3041,wietse vries,Findings of the Association for Computational Linguistics: EMNLP 2020,0,"Peeking into the inner workings of BERT has shown that its layers resemble the classical NLP pipeline, with progressively more complex tasks being concentrated in later layers. To investigate to what extent these results also hold for a language other than English, we probe a Dutch BERT-based model and the multilingual BERT model for Dutch NLP tasks. In addition, through a deeper analysis of part-of-speech tagging, we show that also within a given task, information is spread over different parts of the network and the pipeline might not be as neat as it seems. Each layer has different specialisations, so that it may be more useful to combine information from different layers, instead of selecting a single one based on the best overall performance."
2020.evalnlgeval-1.5,On the interaction of automatic evaluation and task framing in headline style transfer,2020,-1,-1,5,1,6234,lorenzo mattei,Proceedings of the 1st Workshop on Evaluating NLG Evaluation,0,"An ongoing debate in the NLG community concerns the best way to evaluate systems, with human evaluation often being considered the most reliable method, compared to corpus-based metrics. However, tasks involving subtle textual differences, such as style transfer, tend to be hard for humans to perform. In this paper, we propose an evaluation method for this task based on purposely-trained classifiers, showing that it better reflects system differences than traditional metrics such as BLEU."
2020.cl-2.7,Fair Is Better than Sensational: Man Is to Doctor as Woman Is to Doctor,2020,5,0,1,1,29,malvina nissim,Computational Linguistics,0,"Analogies such as man is to king as woman is to X are often used to illustrate the amazing power of word embeddings. Concurrently, they have also been used to expose how strongly human biases are encoded in vector spaces trained on natural language, with examples like man is to computer programmer as woman is to homemaker. Recent work has shown that analogies are in fact not an accurate diagnostic for bias, but this does not mean that they are not used anymore, or that their legacy is fading. Instead of focusing on the intrinsic problems of the analogy task as a bias detection tool, we discuss a series of issues involving implementation as well as subjective choices that might have yielded a distorted picture of bias in word embeddings. We stand by the truth that human biases are present in word embeddings, and, of course, the need to address them. But analogies are not an accurate tool to do so, and the way they have been most often used has exacerbated some possibly non-existing biases and perhaps hidden others. Because they are still widely popular, and some of them have become classics within and outside the NLP community, we deem it important to provide a series of clarifications that should put well-known, and potentially new analogies, into the right perspective."
P19-1246,You Write like You Eat: Stylistic Variation as a Predictor of Social Stratification,2019,46,0,3,0,11971,angelo basile,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Inspired by Labov{'}s seminal work on stylisticvariation as a function of social stratification,we develop and compare neural models thatpredict a person{'}s presumed socio-economicstatus, obtained through distant supervision,from their writing style on social media. Thefocus of our work is on identifying the mostimportant stylistic parameters to predict socio-economic group. In particular, we show theeffectiveness of morpho-syntactic features aspredictors of style, in contrast to lexical fea-tures, which are good predictors of topic"
W18-4919,The Other Side of the Coin: Unsupervised Disambiguation of Potentially Idiomatic Expressions by Contrasting Senses,2018,0,0,2,1,16657,hessel haagsma,"Proceedings of the Joint Workshop on Linguistic Annotation, Multiword Expressions and Constructions ({LAW}-{MWE}-{C}x{G}-2018)",0,"Disambiguation of potentially idiomatic expressions involves determining the sense of a potentially idiomatic expression in a given context, e.g. determining that make hay in {`}Investment banks made hay while takeovers shone.{'} is used in a figurative sense. This enables automatic interpretation of idiomatic expressions, which is important for applications like machine translation and sentiment analysis. In this work, we present an unsupervised approach for English that makes use of literalisations of idiom senses to improve disambiguation, which is based on the lexical cohesion graph-based method by Sporleder and Li (2009). Experimental results show that, while literalisation carries novel information, its performance falls short of that of state-of-the-art unsupervised methods."
S18-1167,Discriminator at {S}em{E}val-2018 Task 10: Minimally Supervised Discrimination,2018,0,0,4,0.952381,10899,artur kulmizev,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"We participated to the SemEval-2018 shared task on capturing discriminative attributes (Task 10) with a simple system that ranked 8th amongst the 26 teams that took part in the evaluation. Our final score was 0.67, which is competitive with the winning score of 0.75, particularly given that our system is a zero-shot system that requires no training and minimal parameter optimisation. In addition to describing the submitted system, and discussing the implications of the relative success of such a system on this task, we also report on other, more complex models we experimented with."
P18-2061,Bleaching Text: Abstract Features for Cross-lingual Gender Prediction,2018,0,5,4,0.666667,3851,rob goot,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Gender prediction has typically focused on lexical and social network features, yielding good performance, but making systems highly language-, topic-, and platform dependent. Cross-lingual embeddings circumvent some of these limitations, but capture gender-specific style less. We propose an alternative: bleaching text, i.e., transforming lexical strings into more abstract features. This study provides evidence that such features allow for better transfer across languages. Moreover, we present a first study on the ability of humans to perform cross-lingual gender prediction. We find that human predictive power proves similar to that of our bleached models, and both perform better than lexical models."
W17-5043,The Power of Character N-grams in Native Language Identification,2017,0,5,4,0.952381,10899,artur kulmizev,Proceedings of the 12th Workshop on Innovative Use of {NLP} for Building Educational Applications,0,"In this paper, we explore the performance of a linear SVM trained on language independent character features for the NLI Shared Task 2017. Our basic system (GRONINGEN) achieves the best performance (87.56 F1-score) on the evaluation set using only 1-9 character n-grams as features. We compare this against several ensemble and meta-classifiers in order to examine how the linear system fares when combined with other, especially non-linear classifiers. Special emphasis is placed on the topic bias that exists by virtue of the assessment essay prompt distribution."
W17-4404,"To normalize, or not to normalize: The impact of normalization on Part-of-Speech tagging",2017,0,5,3,0.666667,3851,rob goot,Proceedings of the 3rd Workshop on Noisy User-generated Text,0,"Does normalization help Part-of-Speech (POS) tagging accuracy on noisy, non-canonical data? To the best of our knowledge, little is known on the actual impact of normalization in a real-world scenario, where gold error detection is not available. We investigate the effect of automatic normalization on POS tagging of tweets. We also compare normalization to strategies that leverage large amounts of unlabeled data kept in its raw form. Our results show that normalization helps, but does not add consistently beyond just word embedding layer initialization. The latter approach yields a tagging model that is competitive with a Twitter state-of-the-art tagger."
J17-4007,Last Words: Sharing Is Caring: The Future of Shared Tasks,2017,8,2,1,1,29,malvina nissim,Computational Linguistics,0,None
W16-4304,Distant supervision for emotion detection using {F}acebook reactions,2016,13,5,2,0,33590,chris pool,"Proceedings of the Workshop on Computational Modeling of People{'}s Opinions, Personality, and Emotions in Social Media ({PEOPLES})",0,"We exploit the Facebook reaction feature in a distant supervised fashion to train a support vector machine classifier for emotion detection, using several feature combinations and combining different Facebook pages. We test our models on existing benchmarks for emotion detection and show that employing only information that is derived completely automatically, thus without relying on any handcrafted lexicon as it{'}s usually done, we can achieve competitive results. The results also show that there is large room for improvement, especially by gearing the collection of Facebook pages, with a view to the target domain."
L16-1449,Leveraging Native Data to Correct Preposition Errors in Learners{'} {D}utch,2016,15,0,2,0,25167,lennart kloppenburg,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We address the task of automatically correcting preposition errors in learners{'} Dutch by modelling preposition usage in native language. Specifically, we build two models exploiting a large corpus of Dutch. The first is a binary model for detecting whether a preposition should be used at all in a given position or not. The second is a multiclass model for selecting the appropriate preposition in case one should be used. The models are tested on native as well as learners data. For the latter we exploit a crowdsourcing strategy to elicit native judgements. On native test data the models perform very well, showing that we can model preposition usage appropriately. However, the evaluation on learners{'} data shows that while detecting that a given preposition is wrong is doable reasonably well, detecting the absence of a preposition is a lot more difficult. Observing such results and the data we deal with, we envisage various ways of improving performance, and report them in the final section of this article."
W15-1832,Uncovering Noun-Noun Compound Relations by Gamification,2015,7,4,2,0,6245,johan bos,Proceedings of the 20th Nordic Conference of Computational Linguistics ({NODALIDA} 2015),0,"Can relations described by English nounnoun compounds be adequately captured by prepositions? We attempt to answer this question in a data-driven way, using gamification to annotate a set of about a thousand noun-noun compound examples. Annotators could make a choice out of five prepositions generated with the help of paraphrases found in the Google ngram corpus. We show that there is substantial agreement among the players of our linguistic annotation game, and that their answers differ in about 50% of raw frequency counts of the Google n-gram corpus. Prepositions can be used to describe the majority of the implicit relations present in noun-noun compounds, but not all relations are captured by natural prepositions and some compounds are not easy to paraphrase with the use of a preposition."
P15-1146,Adding Semantics to Data-Driven Paraphrasing,2015,39,24,3,0,7335,ellie pavlick,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),1,"We add an interpretable semantics to the paraphrase database (PPDB). To date, the relationship between phrase pairs in the database has been weakly defined as approximately equivalent. We show that these pairs represent a variety of relations, including directed entailment (little girl/girl) and exclusion (nobody/someone). We automatically assign semantic entailment relations to entries in PPDB using features derived from past work on discovering inference rules from text and semantic taxonomy induction. We demonstrate that our model assigns these relations with high accuracy. In a downstream RTE task, our labels rival relations from WordNet and improve the coverage of a proof-based RTE system by 17%."
S14-2114,The Meaning Factory: Formal Semantics for Recognizing Textual Entailment and Determining Semantic Similarity,2014,19,54,4,0.17316,996,johannes bjerva,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"Shared Task 1 of SemEval-2014 comprised two subtasks on the same dataset of sentence pairs: recognizing textual entailment and determining textual similarity. We used an existing system based on formal semantics and logical inference to participate in the first subtask, reaching an accuracy of 82%, ranking in the top 5 of more than twenty participating systems. For determining semantic similarity we took a supervised approach using a variety of features, the majority of which was produced by our system for recognizing textual entailment. In this subtask our system achieved a mean squared error of 0.322, the best of all participating systems."
del-tredici-nissim-2014-modular,A Modular System for Rule-based Text Categorisation,2014,-1,-1,2,0,21574,marco tredici,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We introduce a modular rule-based approach to text categorisation which is more flexible and less time consuming to build than a standard rule-based system because it works with a hierarchical structure and allows for re-usability of rules. When compared to currently more wide-spread machine learning models on a case study, our modular system shows competitive results, and it has the advantage of reducing manual effort over time, since only fewer rules must be written when moving to a (partially) new domain, while annotation of training data is always required in the same amount."
W13-1614,Sentiment analysis on {I}talian tweets,2013,27,54,2,0,7,valerio basile,"Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",0,"We describe TWITA, the first corpus of Italiann tweets, which is created via a completely automatic procedure, portable to any other language. We experiment with sentiment analysis on two datasets from TWITA: a genericn collection and a topic-specific collection. Then only resource we use is a polarity lexicon,n which we obtain by automatically matchingn three existing resources thereby creating then first polarity database for Italian. We observen that albeit shallow, our simple system capturesn polarity distinctions matching reasonably welln the classification done by human judges, withn differences in performance across polarity values and on the two sets."
W13-1007,Modelling the Internal Variability of {MWE}s,2013,0,0,1,1,29,malvina nissim,Proceedings of the 9th Workshop on Multiword Expressions,0,"The issue of flexibility of multiword expressions (MWEs) is crucial towards their identification and extraction in running text, as well as their better understanding from a linguistic perspective. If we project a large MWE lexicon onto a corpus, projecting fixed forms suffers from low recall, while an unconstrained flexible search for lemmas yields a loss in precision. In this talk, I will describe a method aimed at maximising precision in the identification of MWEs in flexible mode, building on the idea that internal variability can be modelled via so-called variation patterns. I will discuss the advantages and limitations of using variation patterns, compare their performance to that of association measures, and explore their usability in MWE extraction, too."
W13-1015,A Repository of Variation Patterns for Multiword Expressions,2013,11,1,1,1,29,malvina nissim,Proceedings of the 9th Workshop on Multiword Expressions,0,"One of the crucial issues in the analysis and processing of MWEs is their internal variability. Indeed, the feature that mostly characterises MWEs is their fixedness at some level of linguistic analysis, be it morphology, syntax, or semantics. The morphological aspect is not trivial in languages which exhibit a rich morphology, such as Romance languages. The issue is relevant in at least three aspects of MWE representation and processing: lexicons, identification, and extraction (Calzolari et al., 2002). At the lexicon level, MWEs are usual stored as one form only, the so-called quotation form (or citation form). However, some variations of the quotation form might also be valid instances of MWEs (Bond et al., 2005) xe2x80x94 some but not all, as some of them might actually be plain compositional phrases. This becomes relevant for automatic identification and extraction. If a lexicon stores the quotation form only, identification on a corpus done via matching lexicon strings as such would miss valid variations of a given MWE. Identification could be done exploiting lemmas rather than quotation forms, but an unrestricted match would also possibly return compositional phrases. Extraction is usually done applying association measures over instances of given POS patterns (Evert and Krenn, 2005), and because lemmas are matched, no restrictions on internal variation is enforced as such. Knowing which variations should be allowed for the quotation form of a given MWE would help in increasing recall while keeping precision high. However, specifying such variations for each MWE would be too costly and wouldnxe2x80x99t help in extraction, as no specifications could be done a priori on yet unknown MWEs. Optimally, one would need to find more general variation patterns that could be applied to classes of MWEs. Indeed, the main idea behind this work is that MWEs can be handled through more general patterns. This is also claimed, for instance, by Masini (2007) whose analysis on Italian MWEs takes a constructionist perspective (Goldberg, 2003), by Weller and Heid (2010), who treat verbal expressions in German, and also by Gregoire (2010), who bases his work on the Equivalence Class Method (ECM, (Odijk, 2004)) assuming that MWEs may be clustered according to their syntactic pattern and treated homogeneously. We suggest that variation patterns can be found and defined over POS sequences. Working on Italian, in this paper we report the results of ongoing research and show how such patterns can be derived, we then propose a way to encode them in a repository, which can be combined with existing lexicons of MWEs. For the moment, we restrict our study to contiguous MWEs although we are aware that non-contiguous expressions are common and should be treated, too (see also (Pianta and Bentivogli, 2004)). Thus, only morphological variation is considered at this stage, while phenomena such as insertion and word order variation are left for future work."
W13-0501,Cross-linguistic annotation of modality: a data-driven hierarchical model,2013,16,11,1,1,29,malvina nissim,Proceedings of the 9th Joint {ISO} - {ACL} {SIGSEM} Workshop on Interoperable Semantic Annotation,0,"We present an annotation model of modality which is (i) cross-linguistic, relying on a wide, strongly typologically motivated approach, and (ii) hierarchical and layered, accounting for both factuality and speakerxe2x80x99s attitude, while modelling these two aspects through separate annotation schemes. Modality is defined through cross-linguistic categories, but the classification of actual linguistic expressions is language-specific. This makes our annotation model a powerful tool for investigating linguistic diversity in the field of modality on the basis of real language data, being thus also useful from the perspective of machine translation systems."
zaninello-nissim-2010-creation,Creation of Lexical Resources for a Characterisation of Multiword Expressions in {I}talian,2010,9,9,2,0,17623,andrea zaninello,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The theoretical characterisation of multiword expressions (MWEs) is tightly connected to their actual occurrences in data and to their representation in lexical resources. We present three lexical resources for Italian MWEs, namely an electronic lexicon, a series of example corpora and a database of MWEs represented around morphosyntactic patterns. These resources are matched against, and created from, a very large web-derived corpus for Italian that spans across registers and domains. We can thus test expressions coded by lexicographers in a dictionary, thereby discarding unattested expressions, revisiting lexicographers's choices on the basis of frequency information, and at the same time creating an example sub-corpus for each entry. We organise MWEs on the basis of the morphosyntactic information obtained from the data in an electronic, flexible knowledge-base containing structured annotation exploitable for multiple purposes. We also suggest further work directions towards characterising MWEs by analysing the data organised in our database through lexico-semantic information available in WordNet or MultiWordNet-like resources, also in the perspective of expanding their set through the extraction of other similar compact expressions."
W09-3707,Automatic identification of semantic relations in {I}talian complex nominals,2009,27,6,2,0,33595,fabio celli,Proceedings of the Eight International Conference on Computational Semantics,0,"This paper addresses the problem of the identification of the semantic relations in Italian complex nominals (CNs) of the type NPN. We exploit the fact that the semantic relation, which is underspecified in most cases, is partially made explicit by the preposition. We develop an annotation framework around five different semantic relations, which we use to create a corpus of 1700 Italian CNs, obtaining an inter-annotator agreement of K=.695. Exploiting this data, for each preposition p we train a classifier to assign one of the five semantic relations to any CN of the type NpN, by using both string and supersense features. To obtain supersenses, we experiment with a sequential tagger as well as a plain lookup in MultiWordNet, and find that using information obtained from the former yields better results."
nissim-perboni-2008-italian,The {I}talian Particle {``}ne{''}: Corpus Construction and Analysis,2008,9,0,1,1,29,malvina nissim,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The Italian particle ÂneÂ exhibits interesting anaphoric properties that have not been yet explored in depth from a corpus and computational linguistic perspective. We provide: (i) an overview of the phenomenon; (ii) a set of annotation schemes for marking up occurrences of ÂneÂ; (iii) the description of a corpus annotated for this phenomenon ; (iv) a first assessment of the resolution task. We show that the schemes we developed are reliable, and that the actual distribution of partitive and non-partitive uses of ÂneÂ is inversely proportional to the amount of attention that the two different uses have received in the linguistic literature. As an assessment of the complexity of the resolution task, we find that a recency-based baseline yields an accuracy of less than 30{\%} on both development and test data."
S07-1007,{S}em{E}val-2007 Task 08: Metonymy Resolution at {S}em{E}val-2007,2007,18,35,2,1,10765,katja markert,Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007),0,"We provide an overview of the metonymy resolution shared task organised within SemEval-2007. We describe the problem, the data provided to participants, and the evaluation measures we used to assess performance. We also give an overview of the systems that have taken part in the task, and discuss possible directions for future work."
W06-1602,An Empirical Approach to the Interpretation of Superlatives,2006,14,19,2,0,6245,johan bos,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we introduce an empirical approach to the semantic interpretation of superlative adjectives. We present a corpus annotated for superlatives and propose an interpretation algorithm that uses a wide-coverage parser and produces semantic representations. We achieve F-scores between 0.84 and 0.91 for detecting attributive superlatives and an accuracy in the range of 0.69--0.84 for determining the correct comparison set. As far as we are aware, this is the first automated approach to superlatives for open-domain texts and questions."
W06-1612,Learning Information Status of Discourse Entities,2006,30,17,1,1,29,malvina nissim,Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we address the issue of automatically assigning information status to discourse entities. Using an annotated corpus of conversational English and exploiting morpho-syntactic and lexical features, we train a decision tree to classify entities introduced by noun phrases as old, mediated, or new. We compare its performance with hand-crafted rules that are mainly based on morpho-syntactic features and closely relate to the guidelines that had been used for the manual annotation. The decision tree model achieves an overall accuracy of 79.5%, significantly outperforming the hand-crafted algorithm (64.4%). We also experiment with binary classifications by collapsing in turn two of the three target classes into one and retraining the model. The highest accuracy achieved on binary classification is 93.1%."
alex-etal-2006-impact,The Impact of Annotation on the Performance of Protein Tagging in Biomedical Text,2006,11,9,2,0,826,beatrice alex,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,In this paper we discuss five different corpora annotated forprotein names. We present several within- and cross-dataset proteintagging experiments showing that different annotation schemes severelyaffect the portability of statistical protein taggers. By means of adetailed error analysis we identify crucial annotation issues thatfuture annotation projects should take into careful consideration.
W05-0307,A Framework for Annotating Information Structure in Discourse,2005,27,39,2,0,49326,sasha calhoun,Proceedings of the Workshop on Frontiers in Corpus Annotations {II}: Pie in the Sky,0,"We present a framework for the integrated analysis of the textual and prosodic characteristics of information structure in the Switchboard corpus of conversational English. Information structure describes the availability, organisation and salience of entities in a discourse model. We present standards for the annotation of information status (old, mediated and new), and give guidelines for annotating information structure, i.e. theme/rheme and back-ground/kontrast. We show that information structure in English can only be analysed concurrently with prosodic prominence and phrasing. This annotation, using stand-off XML in NXT, can help establish standards for the annotation of information structure in discourse."
J05-3004,Comparing Knowledge Sources for Nominal Anaphora Resolution,2005,41,55,2,1,10765,katja markert,Computational Linguistics,0,"We compare two ways of obtaining lexical knowledge for antecedent selection in other-anaphora and definite noun phrase coreference. Specifically, we compare an algorithm that relies on links encoded in the manually created lexical hierarchy WordNet and an algorithm that mines corpora by means of shallow lexico-semantic patterns. As corpora we use the British National Corpus (BNC), as well as the Web, which has not been previously used for this task. Our results show that (a) the knowledge encoded in WordNet is often insufficient, especially for anaphorxe2x80x93antecedent relations that exploit subjective or context-dependent knowledge; (b) for other-anaphora, the Web-based method outperforms the WordNet-based method; (c) for definite NP coreference, the Web-based method yields results comparable to those obtained using WordNet over the whole data set and outperforms the WordNet-based method on subsets of the data set; (d) in both case studies, the BNC-based method is worse than the other methods because of data sparseness. Thus, in our studies, the Web-based method alleviated the lexical knowledge gap often encountered in anaphora resolution and handled examples with context-dependent relations between anaphor and antecedent. Because it is inexpensive and needs no hand-modeling of lexical knowledge, it is a promising knowledge source to integrate into anaphora resolution systems."
W04-1217,Exploiting Context for Biomedical Entity Recognition: From Syntax to the Web,2004,9,126,4,0,39103,jenny finkel,Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications ({NLPBA}/{B}io{NLP}),0,"We describe a machine learning system for the recognition of names in biomedical texts. The system makes extensive use of local and syntactic features within the text, as well as external resources including the web and gazetteers. It achieves an F-score of 70% on the Coling 2004 NLPBA/BioNLP shared task of identifying five biomedical named entities in the GENIA corpus."
carletta-etal-2004-using,Using the {NITE} {XML} Toolkit on the Switchboard Corpus to Study Syntactic Choice: a Case Study,2004,2,19,3,0,46163,jean carletta,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The NITE XML Toolkit (NXT) provides library support for working with multimodal language corpora. We describe our experiences in using it to study discourse effects on syntactic choice using the parsed Switchboard Corpus as a starting point, as a case study for others who may wish to adopt similar techniques using NXT or one of the other libraries that are beginning to emerge. We discuss conversion into the NXT data format; automatic annotation of markables and of constituent length; hand-annotation of markables for animacy information structure, and coreferential links; and data analysis."
nissim-etal-2004-annotation,An Annotation Scheme for Information Status in Dialogue,2004,15,55,1,1,29,malvina nissim,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"We present an annotation scheme for information status (IS) in dialogue, and validate it on three Switchboard dialogues. We show that our scheme has good reproducibility, and compare it with previous attempts to code IS and related features. We eventually apply the scheme to 147 dialogues, thus producing a corpus that contains nearly 70,000 NPs annotated for IS and over 15,000 coreference links."
W03-2606,Using the Web for Nominal Anaphora Resolution,2003,-1,-1,2,0,10765,katja markert,Proceedings of the 2003 {EACL} Workshop on The Computational Treatment of Anaphora,0,None
W03-1023,Using the Web in Machine Learning for Other-Anaphora Resolution,2003,16,50,3,0,52584,natalia modjeska,Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,0,"We present a machine learning framework for resolving other-anaphora. Besides morpho-syntactic, recency, and semantic features based on existing lexical knowledge resources, our algorithm obtains additional semantic knowledge from the Web. We search the Web via lexico-syntactic patterns that are specific to other-anaphors. Incorporating this innovative feature leads to an 11.4 percentage point improvement in the classifier's F-measure (25% improvement relative to results without this feature)."
P03-1008,Syntactic Features and Word Similarity for Supervised Metonymy Resolution,2003,25,32,1,1,29,malvina nissim,Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,1,"We present a supervised machine learning algorithm for metonymy resolution, which exploits the similarity between examples of conventional metonymy. We show that syntactic head-modifier relations are a high precision feature for metonymy recognition but suffer from data sparseness. We partially overcome this problem by integrating a thesaurus and introducing simpler grammatical features, thereby preserving precision and increasing recall. Our algorithm generalises over two levels of contextual similarity. Resulting inferences exceed the complexity of inferences undertaken in word sense disambiguation. We also compare automatic and manual methods for syntactic feature extraction."
W02-1027,Metonymy Resolution as a Classification Task,2002,26,27,2,0,10765,katja markert,Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing ({EMNLP} 2002),0,"We reformulate metonymy resolution as a classification task. This is motivated by the regularity of metonymic readings and makes general classification and word sense disambiguation methods available for metonymy resolution. We then present a case study for location names, presenting both a corpus of location names annotated for metonymy as well as experiments with a supervised classification algorithm on this corpus. We especially explore the contribution of features used in word sense disambiguation to metonymy resolution."
markert-nissim-2002-towards,Towards a Corpus Annotated for Metonymies: the Case of Location Names,2002,20,32,2,0,10765,katja markert,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"At the moment, language resources do not contain the necessary information for large-scale metonymy processing. As a contribution, we here present a corpus annotated for metonymies. We describe a framework for annotating metonymies in domain-independent text that considers the regularity, productivity and underspecification of metonymic usage. We then present a fully worked out annotation scheme for location names and a gold standard corpus containing 2000 annotated location names. The annotation scheme is rigorously evaluated as to its reliability and compared to previous metonymy classification proposals. In particular, we show that it is not sufficient to rely on intuitions for reliable metonymy identification and that an annotation effort with trained annotators and explicit guidelines is necessary."
