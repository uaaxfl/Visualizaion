2021.metanlp-1.5,On the cross-lingual transferability of multilingual prototypical models across {NLU} tasks,2021,-1,-1,2,0,5279,oralie cattan,Proceedings of the 1st Workshop on Meta Learning and Its Applications to Natural Language Processing,0,"Supervised deep learning-based approaches have been applied to task-oriented dialog and have proven to be effective for limited domain and language applications when a sufficient number of training examples are available. In practice, these approaches suffer from the drawbacks of domain-driven design and under-resourced languages. Domain and language models are supposed to grow and change as the problem space evolves. On one hand, research on transfer learning has demonstrated the cross-lingual ability of multilingual Transformers-based models to learn semantically rich representations. On the other, in addition to the above approaches, meta-learning have enabled the development of task and language learning algorithms capable of far generalization. Through this context, this article proposes to investigate the cross-lingual transferability of using synergistically few-shot learning with prototypical neural networks and multilingual Transformers-based models. Experiments in natural language understanding tasks on MultiATIS++ corpus shows that our approach substantially improves the observed transfer learning performances between the low and the high resource languages. More generally our approach confirms that the meaningful latent space learned in a given language can be can be generalized to unseen and under-resourced ones using meta-learning."
2020.semeval-1.172,{LIMSI}{\\_}{UPV} at {S}em{E}val-2020 Task 9: Recurrent Convolutional Neural Network for Code-mixed Sentiment Analysis,2020,-1,-1,3,0,8790,somnath banerjee,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"This paper describes the participation of LIMSI{\_}UPV team in SemEval-2020 Task 9: Sentiment Analysis for Code-Mixed Social Media Text. The proposed approach competed in SentiMix HindiEnglish subtask, that addresses the problem of predicting the sentiment of a given Hindi-English code-mixed tweet. We propose Recurrent Convolutional Neural Network that combines both the recurrent neural network and the convolutional network to better capture the semantics of the text, for code-mixed sentiment analysis. The proposed system obtained 0.69 (best run) in terms of F1 score on the given test data and achieved the 9th place (Codalab username: somban) in the SentiMix Hindi-English subtask."
2020.repl4nlp-1.12,A Metric Learning Approach to Misogyny Categorization,2020,-1,-1,3,0,15645,juan coria,Proceedings of the 5th Workshop on Representation Learning for NLP,0,"The task of automatic misogyny identification and categorization has not received as much attention as other natural language tasks have, even though it is crucial for identifying hate speech in social Internet interactions. In this work, we address this sentence classification task from a representation learning perspective, using both a bidirectional LSTM and BERT optimized with the following metric learning loss functions: contrastive loss, triplet loss, center loss, congenerous cosine loss and additive angular margin loss. We set new state-of-the-art for the task with our fine-tuned BERT, whose sentence embeddings can be compared with a simple cosine distance, and we release all our code as open source for easy reproducibility. Moreover, we find that almost every loss function performs equally well in this setting, matching the regular cross entropy loss."
2020.lrec-1.556,Where are we in Named Entity Recognition from Speech?,2020,0,0,2,0,17778,antoine caubriere,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Named entity recognition (NER) from speech is usually made through a pipeline process that consists in (i) processing audio using an automatic speech recognition system (ASR) and (ii) applying a NER to the ASR outputs. The latest data available for named entity extraction from speech in French were produced during the ETAPE evaluation campaign in 2012. Since the publication of ETAPE{'}s campaign results, major improvements were done on NER and ASR systems, especially with the development of neural approaches for both of these components. In addition, recent studies have shown the capability of End-to-End (E2E) approach for NER / SLU tasks. In this paper, we propose a study of the improvements made in speech recognition and named entity recognition for pipeline approaches. For this type of systems, we propose an original 3-pass approach. We also explore the capability of an E2E system to do structured NER. Finally, we compare the performances of ETAPE{'}s systems (state-of-the-art systems in 2012) with the performances obtained using current technologies. The results show the interest of the E2E approach, which however remains below an updated pipeline approach."
2020.jeptalnrecital-jep.8,O{\\`u} en sommes-nous dans la reconnaissance des entit{\\'e}s nomm{\\'e}es structur{\\'e}es {\\`a} partir de la parole ? (Where are we in Named Entity Recognition from speech ?),2020,-1,-1,2,0,17778,antoine caubriere,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 1 : Journ{\\'e}es d'{\\'E}tudes sur la Parole",0,"La reconnaissance des entit{\'e}s nomm{\'e}es (REN) {\`a} partir de la parole est traditionnellement effectu{\'e}e par l{'}interm{\'e}diaire d{'}une cha{\^\i}ne de composants, exploitant un syst{\`e}me de reconnaissance de la parole (RAP), puis un syst{\`e}me de REN appliqu{\'e} sur les transcriptions automatiques. Les derni{\`e}res donn{\'e}es disponibles pour la REN structur{\'e}es {\`a} partir de la parole en fran{\c{c}}ais proviennent de la campagne d{'}{\'e}valuation ETAPE en 2012. Depuis la publication des r{\'e}sultats, des am{\'e}liorations majeures ont {\'e}t{\'e} r{\'e}alis{\'e}es pour les syst{\`e}mes de REN et de RAP. Notamment avec le d{\'e}veloppement des syst{\`e}mes neuronaux. De plus, certains travaux montrent l{'}int{\'e}r{\^e}t des approches de bout en bout pour la t{\^a}che de REN dans la parole. Nous proposons une {\'e}tude des am{\'e}liorations en RAP et REN dans le cadre d{'}une cha{\^\i}ne de composants, ainsi qu{'}une nouvelle approche en trois {\'e}tapes. Nous explorons aussi les capacit{\'e}s d{'}une approche bout en bout pour la REN structur{\'e}es. Enfin, nous comparons ces deux types d{'}approches {\`a} l{'}{\'e}tat de l{'}art de la campagne ETAPE. Nos r{\'e}sultats montrent l{'}int{\'e}r{\^e}t de l{'}approche bout en bout, qui reste toutefois en de{\c{c}}{\`a} d{'}une cha{\^\i}ne de composants enti{\`e}rement mise {\`a} jour."
2020.coling-main.245,Neural Networks approaches focused on {F}rench Spoken Language Understanding: application to the {MEDIA} Evaluation Task,2020,-1,-1,3,0,862,sahar ghannay,Proceedings of the 28th International Conference on Computational Linguistics,0,"In this paper, we present a study on a French Spoken Language Understanding (SLU) task: the MEDIA task. Many works and studies have been proposed for many tasks, but most of them are focused on English language and tasks. The exploration of a richer language like French within the framework of a SLU task implies to recent approaches to handle this difficulty. Since the MEDIA task seems to be one of the most difficult, according several previous studies, we propose to explore Neural Networks approaches focusing of three aspects: firstly, the Neural Network inputs and more specifically the word embeddings; secondly, we compared French version of BERT against the best setup through different ways; Finally, the comparison against State-of-the-Art approaches. Results show that the word embeddings trained on a small corpus need to be updated during SLU model training. Furthermore, the French BERT fine-tuned approaches outperform the classical Neural Network Architectures and achieves state of the art results. However, the contextual embeddings extracted from one of the French BERT approaches achieve comparable results in comparison to word embedding, when integrated into the proposed neural architecture."
L18-1619,"Corpora with Part-of-Speech Annotations for Three Regional Languages of {F}rance: {A}lsatian, {O}ccitan and {P}icard",2018,0,1,13,0,27324,delphine bernhard,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,"This article describes the creation of corpora with part-of-speech annotations for three regional languages of France: Alsatian, Occitan and Picard. These manual annotations were performed in the context of the RESTAURE project, whose goal is to develop resources and tools for these under-resourced French regional languages. The article presents the tagsets used in the annotation process as well as the resulting annotated corpora."
2018.jeptalnrecital-long.6,{\\'E}tiquetage en parties du discours de langues peu dot{\\'e}es par sp{\\'e}cialisation des plongements lexicaux ({POS} tagging for low-resource languages by adapting word embeddings ),2018,-1,-1,3,0,15790,pierre magistry,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"Cet article pr{\'e}sente une nouvelle m{\'e}thode d{'}{\'e}tiquetage en parties du discours adapt{\'e}e aux langues peu dot{\'e}es : la d{\'e}finition du contexte utilis{\'e} pour construire les plongements lexicaux est adapt{\'e}e {\`a} la t{\^a}che, et de nouveaux vecteurs sont cr{\'e}{\'e}s pour les mots inconnus. Les exp{\'e}riences men{\'e}es sur le picard, le malgache et l{'}alsacien montrent que cette m{\'e}thode am{\'e}liore l{'}{\'e}tat de l{'}art pour ces trois langues peu dot{\'e}es."
2018.jeptalnrecital-court.22,Detecting context-dependent sentences in parallel corpora,2018,0,0,3,0,7687,rachel bawden,"Actes de la Conf{\\'e}rence TALN. Volume 1 - Articles longs, articles courts de TALN",0,"In this article, we provide several approaches to the automatic identification of parallel sentences that require sentence-external linguistic context to be correctly translated. Our long-term goal is to automatically construct a test set of context-dependent sentences in order to evaluate machine translation models designed to improve the translation of contextual, discursive phenomena. We provide a discussion and critique that show that current approaches do not allow us to achieve our goal, and suggest that for now evaluating individual phenomena is likely the best solution."
W17-2343,Automatic classification of doctor-patient questions for a virtual patient record query task,2017,20,3,2,1,31973,leonardo llanos,{B}io{NLP} 2017,0,"We present the work-in-progress of automating the classification of doctor-patient questions in the context of a simulated consultation with a virtual patient. We classify questions according to the computational strategy (rule-based or other) needed for looking up data in the clinical record. We compare {`}traditional{'} machine learning methods (Gaussian and Multinomial Naive Bayes, and Support Vector Machines) and a neural network classifier (FastText). We obtained the best results with the SVM using semantic annotations, whereas the neural classifier achieved promising results without it."
2017.jeptalnrecital-long.13,"Apprendre des repr{\\'e}sentations jointes de mots et d{'}entit{\\'e}s pour la d{\\'e}sambigu{\\\\\i}sation d{'}entit{\\'e}s (Combining Word and Entity Embeddings for Entity Linking)""",2017,-1,-1,6,0,2103,jose moreno,Actes des 24{\\`e}me Conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Volume 1 - Articles longs,0,"La d{\'e}sambigu{\""\i}sation d{'}entit{\'e}s (ou liaison d{'}entit{\'e}s), qui consiste {\`a} relier des mentions d{'}entit{\'e}s d{'}un texte {\`a} des entit{\'e}s d{'}une base de connaissance, est un probl{\`e}me qui se pose, entre autre, pour le peuplement automatique de bases de connaissances {\`a} partir de textes. Une difficult{\'e} de cette t{\^a}che est la r{\'e}solution d{'}ambigu{\""\i}t{\'e}s car les syst{\`e}mes ont {\`a} choisir parmi un nombre important de candidats. Cet article propose une nouvelle approche fond{\'e}e sur l{'}apprentissage joint de repr{\'e}sentations distribu{\'e}es des mots et des entit{\'e}s dans le m{\^e}me espace, ce qui permet d{'}{\'e}tablir un mod{\`e}le robuste pour la comparaison entre le contexte local de la mention d{'}entit{\'e} et les entit{\'e}s candidates."
L16-1226,"The {CAMOMILE} Collaborative Annotation Platform for Multi-modal, Multi-lingual and Multi-media Documents",2016,0,7,15,0,34774,johann poignant,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In this paper, we describe the organization and the implementation of the CAMOMILE collaborative annotation framework for multimodal, multimedia, multilingual (3M) data. Given the versatile nature of the analysis which can be performed on 3M data, the structure of the server was kept intentionally simple in order to preserve its genericity, relying on standard Web technologies. Layers of annotations, defined as data associated to a media fragment from the corpus, are stored in a database and can be managed through standard interfaces with authentication. Interfaces tailored specifically to the needed task can then be developed in an agile way, relying on simple but reliable services for the management of the centralized annotations. We then present our implementation of an active learning scenario for person annotation in video, relying on the CAMOMILE server; during a dry run experiment, the manual annotation of 716 speech segments was thus propagated to 3504 labeled tracks. The code of the CAMOMILE framework is distributed in open source."
L16-1297,Generating Task-Pertinent sorted Error Lists for Speech Recognition,2016,0,0,4,1,13778,olivier galibert,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Automatic Speech recognition (ASR) is one of the most widely used components in spoken language processing applications. ASR errors are of varying importance with respect to the application, making error analysis keys to improving speech processing applications. Knowing the most serious errors for the applicative case is critical to build better systems. In the context of Automatic Speech Recognition (ASR) used as a first step towards Named Entity Recognition (NER) in speech, error seriousness is usually determined by their frequency, due to the use of the WER as metric to evaluate the ASR output, despite the emergence of more relevant measures in the literature. We propose to use a different evaluation metric form the literature in order to classify ASR errors according to their seriousness for NER. Our results show that the ASR errors importance is ranked differently depending on the used evaluation metric. A more detailed analysis shows that the estimation of the error impact given by the ATENE metric is more adapted to the NER task than the estimation based only on the most used frequency metric WER."
L16-1366,Transfer-Based Learning-to-Rank Assessment of Medical Term Technicality,2016,0,3,4,1,35102,dhouha bouamor,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"While measuring the readability of texts has been a long-standing research topic, assessing the technicality of terms has only been addressed more recently and mostly for the English language. In this paper, we train a learning-to-rank model to determine a specialization degree for each term found in a given list. Since no training data for this task exist for French, we train our system with non-lexical features on English data, namely, the Consumer Health Vocabulary, then apply it to French. The features include the likelihood ratio of the term based on specialized and lay language models, and tests for containing morphologically complex words. The evaluation of this approach is conducted on 134 terms from the UMLS Metathesaurus and 868 terms from the Eugloss thesaurus. The Normalized Discounted Cumulative Gain obtained by our system is over 0.8 on both test sets. Besides, thanks to the learning-to-rank approach, adding morphological features to the language model features improves the results on the Eugloss thesaurus."
L16-1433,Purely Corpus-based Automatic Conversation Authoring,2016,0,6,4,0,18755,guillaume duplessis,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"This paper presents an automatic corpus-based process to author an open-domain conversational strategy usable both in chatterbot systems and as a fallback strategy for out-of-domain human utterances. Our approach is implemented on a corpus of television drama subtitles. This system is used as a chatterbot system to collect a corpus of 41 open-domain textual dialogues with 27 human participants. The general capabilities of the system are studied through objective measures and subjective self-reports in terms of understandability, repetition and coherence of the system responses selected in reaction to human utterances. Subjective evaluations of the collected dialogues are presented with respect to amusement, engagement and enjoyability. The main factors influencing those dimensions in our chatterbot experiment are discussed."
L16-1505,Managing Linguistic and Terminological Variation in a Medical Dialogue System,2016,10,3,4,1,31973,leonardo llanos,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We introduce a dialogue task between a virtual patient and a doctor where the dialogue system, playing the patient part in a simulated consultation, must reconcile a specialized level, to understand what the doctor says, and a lay level, to output realistic patient-language utterances. This increases the challenges in the analysis and generation phases of the dialogue. This paper proposes methods to manage linguistic and terminological variation in that situation and illustrates how they help produce realistic dialogues. Our system makes use of lexical resources for processing synonyms, inflectional and derivational variants, or pronoun/verb agreement. In addition, specialized knowledge is used for processing medical roots and affixes, ontological relations and concept mapping, and for generating lay variants of terms according to the patient{'}s non-expert discourse. We also report the results of a first evaluation carried out by 11 users interacting with the system. We evaluated the non-contextual analysis module, which supports the Spoken Language Understanding step. The annotation of task domain entities obtained 91.8{\%} of Precision, 82.5{\%} of Recall, 86.9{\%} of F-measure, 19.0{\%} of Slot Error Rate, and 32.9{\%} of Sentence Error Rate."
L16-1534,Named Entity Resources - Overview and Outlook,2016,37,3,3,0,16860,maud ehrmann,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Recognition of real-world entities is crucial for most NLP applications. Since its introduction some twenty years ago, named entity processing has undergone a significant evolution with, among others, the definition of new tasks (e.g. entity linking) and the emergence of new types of data (e.g. speech transcriptions, micro-blogging). These pose certainly new challenges which affect not only methods and algorithms but especially linguistic resources. Where do we stand with respect to named entity resources? This paper aims at providing a systematic overview of named entity resources, accounting for qualities such as multilingualism, dynamicity and interoperability, and to identify shortfalls in order to guide future developments."
2016.jeptalnrecital-long.9,{\\'E}valuation de l{'}apprentissage incr{\\'e}mental par analogie (Incremental Learning From Scratch Using Analogical Reasoning ),2016,-1,-1,3,1,35176,vincent letard,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs),0,"Cet article examine l{'}utilisation du raisonnement analogique dans le contexte de l{'}apprentissage incr{\'e}mental. Le probl{\`e}me d{'}apprentissage sous-jacent d{\'e}velopp{\'e} est le transfert de requ{\^e}tes formul{\'e}es en langue naturelle vers des commandes dans un langage de programmation. Nous y explorons deux questions principales : Comment se comporte le raisonnement par analogie dans le contexte de l{'}apprentissage incr{\'e}mental ? De quelle mani{\`e}re la s{\'e}quence d{'}apprentissage influence-t-elle la performance globale ? Pour y r{\'e}pondre, nous proposons un protocole exp{\'e}rimental simulant deux utilisateurs et diff{\'e}rentes s{\'e}quences d{'}apprentissage. Nous montrons que l{'}ordre dans la s{\'e}quence d{'}apprentissage incr{\'e}mental n{'}a d{'}influence notable que sous des conditions sp{\'e}cifiques. Nous constatons {\'e}galement la compl{\'e}mentarit{\'e} de l{'}apprentissage incr{\'e}mental avec l{'}analogie pour un nombre d{'}exemples d{'}apprentissage minimal."
2016.jeptalnrecital-jep.15,Comparaison de listes d{'}erreurs de transcription automatique de la parole : quelle compl{\\'e}mentarit{\\'e} entre les diff{\\'e}rentes m{\\'e}triques ? (Comparing error lists for {ASR} systems : contribution of different metrics),2016,-1,-1,3,1,13778,olivier galibert,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP,0,"Le travail que nous pr{\'e}sentons ici s{'}inscrit dans le domaine de l{'}{\'e}valuation des syst{\`e}mes de reconnaissance automatique de la parole en vue de leur utilisation dans une t{\^a}che aval, ici la reconnaissance des entit{\'e}s nomm{\'e}es. Plus largement, la question que nous nous posons est {``}que peut apporter une m{\'e}trique d{'}{\'e}valuation en dehors d{'}un score ?''. Nous nous int{\'e}ressons particuli{\`e}rement aux erreurs des syst{\`e}mes et {\`a} leur analyse et {\'e}ventuellement {\`a} l{'}utilisation de ce que nous connaissons de ces erreurs. Nous {\'e}tudions dans ce travail les listes ordonn{\'e}es d{'}erreurs g{\'e}n{\'e}r{\'e}es {\`a} partir de diff{\'e}rentes m{\'e}triques et analysons ce qui en ressort. Nous avons appliqu{\'e} la m{\^e}me m{\'e}thode sur les sorties de diff{\'e}rents syst{\`e}mes de reconnaissance de la parole. Nos exp{\'e}riences mettent en {\'e}vidence que certaines m{\'e}triques apportent une information plus pertinente {\'e}tant donn{\'e} une t{\^a}che et transverse {\`a} diff{\'e}rents syst{\`e}mes."
2016.jeptalnrecital-jep.31,Estimation de la qualit{\\'e} d{'}un syst{\\`e}me de reconnaissance de la parole pour une t{\\^a}che de compr{\\'e}hension (Quality estimation of a Speech Recognition System for a Spoken Language Understanding task),2016,-1,-1,4,1,13778,olivier galibert,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP,0,"Nous nous int{\'e}ressons {\`a} l{'}{\'e}valuation de la qualit{\'e} des syst{\`e}mes de reconnaissance de la parole {\'e}tant donn{\'e} une t{\^a}che de compr{\'e}hension. L{'}objectif de ce travail est de fournir un outil permettant la s{\'e}lection d{'}un syst{\`e}me de reconnaissance automatique de la parole le plus adapt{\'e} pour un syst{\`e}me de dialogue donn{\'e}. Nous comparons ici diff{\'e}rentes m{\'e}triques, notamment le WER, NE-WER et ATENE m{\'e}trique propos{\'e}e r{\'e}cemment pour l{'}{\'e}valuation des syst{\`e}mes de reconnaissance de la parole {\'e}tant donn{\'e} une t{\^a}che de reconnaissance d{'}entit{\'e}s nomm{\'e}es. Cette derni{\`e}re m{\'e}trique montrait une meilleure corr{\'e}lation avec les r{\'e}sultats de la t{\^a}che globale que toutes les autres m{\'e}triques test{\'e}es. Nos mesures indiquent une tr{\`e}s forte corr{\'e}lation avec la mesure ATENE et une moins forte avec le WER."
2016.jeptalnrecital-demo.18,Un syst{\\`e}me automatique de s{\\'e}lection de r{\\'e}ponse en domaine ouvert int{\\'e}grable {\\`a} un syst{\\`e}me de dialogue social (An automatic open-domain response selection system integrable to a social dialogue system),2016,-1,-1,5,0,36101,franck charras,Actes de la conf{\\'e}rence conjointe JEP-TALN-RECITAL 2016. volume 5 : D{\\'e}monstrations,0,Cette d{\'e}monstration pr{\'e}sente un syst{\`e}me de dialogue en domaine ouvert qui utilise une base d{'}exemples de dialogue automatiquement constitu{\'e}e depuis un corpus de sous-titres afin de g{\'e}rer un dialogue social de type Â« chatbot Â».
W15-4660,Description of the {P}atient{G}enesys Dialogue System,2015,9,2,6,1,31973,leonardo llanos,Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,0,"This paper describes the work-in-progress prototype of a dialog system that simulates a virtual patient (VP) consultation. We report some challenges and difficulties that are found during its development, especially in managing the interaction and the vocabulary from the medical domain."
2015.jeptalnrecital-long.3,Identification de facteurs de risque pour des patients diab{\\'e}tiques {\\`a} partir de comptes-rendus cliniques par des approches hybrides,2015,-1,-1,3,0.561416,5675,cyril grouin,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Dans cet article, nous pr{\'e}sentons les m{\'e}thodes que nous avons d{\'e}velopp{\'e}es pour analyser des comptes- rendus hospitaliers r{\'e}dig{\'e}s en anglais. L{'}objectif de cette {\'e}tude consiste {\`a} identifier les facteurs de risque de d{\'e}c{\`e}s pour des patients diab{\'e}tiques et {\`a} positionner les {\'e}v{\'e}nements m{\'e}dicaux d{\'e}crits par rapport {\`a} la date de cr{\'e}ation de chaque document. Notre approche repose sur (i) HeidelTime pour identifier les expressions temporelles, (ii) des CRF compl{\'e}t{\'e}s par des r{\`e}gles de post-traitement pour identifier les traitements, les maladies et facteurs de risque, et (iii) des r{\`e}gles pour positionner temporellement chaque {\'e}v{\'e}nement m{\'e}dical. Sur un corpus de 514 documents, nous obtenons une F-mesure globale de 0,8451. Nous observons que l{'}identification des informations directement mentionn{\'e}es dans les documents se r{\'e}v{\`e}le plus performante que l{'}inf{\'e}rence d{'}informations {\`a} partir de r{\'e}sultats de laboratoire."
2015.jeptalnrecital-demonstration.8,Un patient virtuel dialogant,2015,-1,-1,6,0,37967,leonardo campillos,Actes de la 22e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,Le d{\'e}monstrateur que nous d{\'e}crivons ici est un prototype de syst{\`e}me de dialogue dont l{'}objectif est de simuler un patient. Nous d{\'e}crivons son fonctionnement g{\'e}n{\'e}ral en insistant sur les aspects concernant la langue et surtout le rapport entre langue m{\'e}dicale de sp{\'e}cialit{\'e} et langue g{\'e}n{\'e}rale.
P14-3005,A Mapping-Based Approach for General Formal Human Computer Interaction Using Natural Language,2014,13,0,2,1,35176,vincent letard,Proceedings of the {ACL} 2014 Student Research Workshop,0,"We consider the problem of mapping natural language written utterances expressing operational instructions 1 to formal language expressions, applied to French and the R programming language. Developing a learning operational assistant requires the means to train and evaluate it, that is, a baseline system able to interact with the user. After presenting the guidelines of our work, we propose a model to represent the problem and discuss the fit of direct mapping methods to our task. Finally, we show that, while not resulting in excellent scores, a simple approach seems to be sufficient to provide a baseline for an interactive learning system."
goryainova-etal-2014-morpho,Morpho-Syntactic Study of Errors from Speech Recognition System,2014,8,2,3,0,39602,maria goryainova,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"The study provides an original standpoint of the speech transcription errors by focusing on the morpho-syntactic features of the erroneous chunks and of the surrounding left and right context. The typology concerns the forms, the lemmas and the POS involved in erroneous chunks, and in the surrounding contexts. Comparison with error free contexts are also provided. The study is conducted on French. Morpho-syntactic analysis underlines that three main classes are particularly represented in the erroneous chunks: (i) grammatical words (to, of, the), (ii) auxiliary verbs (has, is), and (iii) modal verbs (should, must). Such items are widely encountered in the ASR outputs as frequent candidates to transcription errors. The analysis of the context points out that some left 3-grams contexts (e.g., repetitions, that is disfluencies, bracketing formulas such as {``}cÂest{''}, etc.) may be better predictors than others. Finally, the surface analysis conducted through a Levensthein distance analysis, highlighted that the most common distance is of 2 characters and mainly involves differences between inflected forms of a unique item."
luzzati-etal-2014-human,Human annotation of {ASR} error regions: Is {``}gravity{''} a sharable concept for human annotators?,2014,12,1,10,0,39857,daniel luzzati,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper is concerned with human assessments of the severity of errors in ASR outputs. We did not design any guidelines so that each annotator involved in the study could consider the {``}seriousness{''} of an ASR error using their own scientific background. Eight human annotators were involved in an annotation task on three distinct corpora, one of the corpora being annotated twice, hiding this annotation in duplicate to the annotators. None of the computed results (inter-annotator agreement, edit distance, majority annotation) allow any strong correlation between the considered criteria and the level of seriousness to be shown, which underlines the difficulty for a human to determine whether a ASR error is serious or not."
ben-jannet-etal-2014-eter,{ETER} : a new metric for the evaluation of hierarchical named entity recognition,2014,12,3,5,0,35025,mohamed jannet,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"This paper addresses the question of hierarchical named entity evaluation. In particular, we focus on metrics to deal with complex named entity structures as those introduced within the QUAERO project. The intended goal is to propose a smart way of evaluating partially correctly detected complex entities, beyond the scope of traditional metrics. None of the existing metrics are fully adequate to evaluate the proposed QUAERO task involving entity detection, classification and decomposition. We are discussing the strong and weak points of the existing metrics. We then introduce a new metric, the Entity Tree Error Rate (ETER), to evaluate hierarchical and structured named entity detection, classification and decomposition. The ETER metric builds upon the commonly accepted SER metric, but it takes the complex entity structure into account by measuring errors not only at the slot (or complex entity) level but also at a basic (atomic) entity level. We are comparing our new metric to the standard one using first some examples and then a set of real data selected from the ETAPE evaluation results."
W13-2321,Automatic Named Entity Pre-annotation for Out-of-domain Human Annotation,2013,23,3,1,1,5280,sophie rosset,Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,0,"Automatic pre-annotation is often used to improve human annotation speed and accuracy. We address here out-of-domain named entity annotation, and examine whether automatic pre-annotation is still beneficial in this setting. Our study design includes two different corpora, three pre-annotation schemes linked to two annotation levels, both expert and novice annotators, a questionnaire-based subjective assessment and a corpus-based quantitative assessment. We observe that preannotation helps in all cases, both for speed and for accuracy, and that the subjective assessment of the annotators does not always match the actual benefits measured in the annotation outcome."
F13-1035,Web pages segmentation for document selection in Question Answering (Pr{\\'e}-segmentation de pages web et s{\\'e}lection de documents pertinents en Questions-R{\\'e}ponses) [in {F}rench],2013,0,0,2,1,35201,nicolas foucault,Proceedings of TALN 2013 (Volume 1: Long Papers),0,None
W12-3606,Structured Named Entities in two distinct press corpora: Contemporary Broadcast News and Old Newspapers,2012,18,16,1,1,5280,sophie rosset,Proceedings of the Sixth Linguistic Annotation Workshop,0,"This paper compares the reference annotation of structured named entities in two corpora with different origins and properties. It addresses two questions linked to such a comparison. On the one hand, what specific issues were raised by reusing the same annotation scheme on a corpus that differs from the first in terms of media and that predates it by more than a century? On the other hand, what contrasts were observed in the resulting annotations across the two corpora?"
W12-0512,Methods Combination and {ML}-based Re-ranking of Multiple Hypothesis for Question-Answering Systems,2012,13,3,3,0,42529,arnaud grappy,Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data,0,"Question answering systems answer correctly to different questions because they are based on different strategies. In order to increase the number of questions which can be answered by a single process, we propose solutions to combine two question answering systems, QAVAL and RITEL. QAVAL proceeds by selecting short passages, annotates them by question terms, and then extracts from them answers which are ordered by a machine learning validation process. RITEL develops a multi-level analysis of questions and documents. Answers are extracted and ordered according to two strategies: by exploiting the redundancy of candidates and a Bayesian model. In order to merge the system results, we developed different methods either by merging passages before answer ordering, or by merging end-results. The fusion of end-results is realized by voting, merging, and by a machine learning process on answer characteristics, which lead to an improvement of the best system results of 19 %."
galibert-etal-2012-extended,Extended Named Entities Annotation on {OCR}ed Documents: From Corpus Constitution to Evaluation Campaign,2012,16,6,2,1,13778,olivier galibert,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Within the framework of the Quaero project, we proposed a new definition of named entities, based upon an extension of the coverage of named entities as well as the structure of those named entities. In this new definition, the extended named entities we proposed are both hierarchical and compositional. In this paper, we focused on the annotation of a corpus composed of press archives, OCRed from French newspapers of December 1890. We present the methodology we used to produce the corpus and the characteristics of the corpus in terms of named entities annotation. This annotated corpus has been used in an evaluation campaign. We present this evaluation, the metrics we used and the results obtained by the participants."
doukhan-etal-2012-designing,Designing {F}rench Tale Corpora for Entertaining Text To Speech Synthesis,2012,0,5,2,0,29766,david doukhan,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Text and speech corpora for training a tale telling robot have been designed, recorded and annotated. The aim of these corpora is to study expressive storytelling behaviour, and to help in designing expressive prosodic and co-verbal variations for the artificial storyteller). A set of 89 children tales in French serves as a basis for this work. The tales annotation principles and scheme are described, together with the corpus description in terms of coverage and inter-annotator agreement. Automatic analysis of a new tale with the help of this corpus and machine learning is discussed. Metrics for evaluation of automatic annotation methods are discussed. A speech corpus of about 1 hour, with 12 tales has been recorded and aligned and annotated. This corpus is used for predicting expressive prosody in children tales, above the level of the sentence."
dinarelli-rosset-2012-tree-structured,"Tree-Structured Named Entity Recognition on {OCR} Data: Analysis, Processing and Results",2012,19,8,2,1,14129,marco dinarelli,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"In this paper we deal with named entity detection on data acquired via OCR process on documents dating from 1890. The resulting corpus is very noisy. We perform an analysis to find possible strategies to overcome errors introduced by the OCR process. We propose a preprocessing procedure in three steps to clean data and correct, at least in part, OCR mistakes. The task is made even harder by the complex tree-structure of named entities annotated on data, we solve this problem however by adopting an effective named entity detection system we proposed in previous work. We evaluate our procedure for preprocessing OCR-ized data in two ways: in terms of perplexity and OOV rate of a language model on development and evaluation data, and in terms of the performance of the named entity detection system on the preprocessed data. The preprocessing procedure results to be effective, allowing to improve by a large margin the system we proposed for the official evaluation campaign on Old Press, and allowing to outperform also the best performing system of the evaluation campaign."
F12-2028,Quel est l{'}apport de la d{\\'e}tection d{'}entit{\\'e}s nomm{\\'e}es pour l{'}extraction d{'}information en domaine restreint ? (What is the contribution of named entities detection for information extraction in restricted domain ?) [in {F}rench],2012,-1,-1,3,0,35957,camille dutrey,"Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN",0,None
E12-1018,Tree Representations in Probabilistic Models for Extended Named Entities Detection,2012,29,3,2,1,14129,marco dinarelli,Proceedings of the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper we deal with Named Entity Recognition (NER) on transcriptions of French broadcast data. Two aspects make the task more difficult with respect to previous NER tasks: i) named entities annotated used in this work have a tree structure, thus the task cannot be tackled as a sequence labelling task; ii) the data used are more noisy than data used for previous NER tasks. We approach the task in two steps, involving Conditional Random Fields and Probabilistic Context-Free Grammars, integrated in a single parsing algorithm. We analyse the effect of using several tree representations. Our system outperforms the best system of the evaluation campaign by a significant margin."
C12-2079,Manual Corpus Annotation: Giving Meaning to the Evaluation Metrics,2012,15,13,8,0,32781,yann mathet,Proceedings of {COLING} 2012: Posters,0,"Computing inter-annotator agreement measures on a manually annotated corpus is necessary to evaluate the reliability of its annotation. However, the interpretation of the obtained results is recognized as highly arbitrary. We describe in this article a method and a tool that we developed which shuffles a reference annotation according to different error paradigms, thereby creating artificial annotations with controlled errors. Agreement measures are computed on these corpora, and the obtained results are used to model the behavior of these measures and understand their actual meaning."
C12-1055,Modeling the Complexity of Manual Annotation Tasks: a Grid of Analysis,2012,24,10,3,0,10472,karen fort,Proceedings of {COLING} 2012,0,"Manual corpus annotation is getting widely used in Natural Language Processing (NLP). While being recognized as a difficult task, no in-depth analysis of its complexity has been performed yet. We provide in this article a grid of analysis of the different complexity dimensions of an annotation task, which helps estimating beforehand the difficulties and cost of annotation campaigns. We observe the applicability of this grid on existing annotation campaigns and detail its application on a real-world example."
W11-0411,"Proposal for an Extension of Traditional Named Entities: From Guidelines to Evaluation, an Overview",2011,27,36,2,0.615385,5675,cyril grouin,Proceedings of the 5th Linguistic Annotation Workshop,0,"Within the framework of the construction of a fact database, we defined guidelines to extract named entities, using a taxonomy based on an extension of the usual named entities definition. We thus defined new types of entities with broader coverage including substantive-based expressions. These extended named entities are hierarchical (with types and components) and compositional (with recursive type inclusion and metonymy annotation). Human annotators used these guidelines to annotate a 1.3M word broadcast news corpus in French. This article presents the definition and novelty of extended named entity annotation guidelines, the human annotation of a global corpus and of a mini reference corpus, and the evaluation of annotations through the computation of inter-annotator agreements. Finally, we discuss our approach and the computed results, and outline further work."
R11-1104,Language Modeling for Document Selection in Question Answering,2011,5,2,3,1,35201,nicolas foucault,Proceedings of the International Conference Recent Advances in Natural Language Processing 2011,0,"Usually, in the Question Answering domain, for a question in natural language, precise answers to the question are extracted from documents according only to the context of the question. In this work, we complemented this approach by adding a filtering process on top of the document retrieval. This way, the system reevaluates the documents it has originally selected during the information retrieval step before the answer extraction and scoring. Such re-evaluation aims at filtering out documents considered unusable for the search. Based on statistical language modeling, the filtering process firstly determines the intrinsic relevancy of a document and then decides whether this document is a priori relevant for finding answers. Evaluation on factoid questions and a collection of 500k web documents has shown our approach properly supports the Question Answering task."
I11-1058,Structured and Extended Named Entity Evaluation in Automatic Speech Transcriptions,2011,25,23,2,1,13778,olivier galibert,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"The evaluation of named entity recognition (NER) methods is an active field of research. This includes the recognition of named entities in speech transcripts. Evaluating NER systems on automatic speech recognition (ASR) output whereas human reference annotation was prepared on clean manual transcripts raises difficult alignment issues. These issues are emphasized when named entities are structured, as is the case in the Quaero NER challenge organized in 2010. This paper describes the structured named entity definition used in this challenge and presents a method to transfer reference annotations to ASR output. This method was used in the Quaero 2010 evaluation of extended named entity annotation on speech transcripts, whose results are given in the paper."
I11-1142,Models Cascade for Tree-Structured Named Entity Detection,2011,27,28,2,1,14129,marco dinarelli,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Named Entity Recognition (NER) is a well-known Natural Language Processing (NLP) task, used as a preliminary processing to provide a semantic level to more complex tasks. In this paper we describe a new set of named entities having a multilevel tree structure, where base entities are combined to define more complex ones. This definition makes the NER task more complex than previous tasks, even more due to the use of noisy data for the annotation: transcriptions of French broadcast data. We propose an original and effective system to tackle this new task, putting together the strengths of solutions for sequence labeling approaches and syntactic parsing via cascading of different models. Our system was evaluated in the 2011 Quaero named entity detection evaluation campaign and ranked first, with results far better than those of the other participating systems."
D11-1102,Hypotheses Selection Criteria in a Reranking Framework for Spoken Language Understanding,2011,41,8,2,1,14129,marco dinarelli,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"Reranking models have been successfully applied to many tasks of Natural Language Processing. However, there are two aspects of this approach that need a deeper investigation: (i) Assessment of hypotheses generated for reranking at classification phase: baseline models generate a list of hypotheses and these are used for reranking without any assessment; (ii) Detection of cases where reranking models provide a worst result: the best hypothesis provided by the reranking model is assumed to be always the best result. In some cases the reranking model provides an incorrect hypothesis while the baseline best hypothesis is correct, especially when baseline models are accurate. In this paper we propose solutions for these two aspects: (i) a semantic inconsistency metric to select possibly more correct n-best hypotheses, from a large set generated by an SLU basiline model. The selected hypotheses are reranked applying a state-of-the-art model based on Partial Tree Kernels, which encode SLU hypotheses in Support Vector Machines with complex structured features; (ii) finally, we apply a decision strategy, based on confidence values, to select the final hypothesis between the first ranked hypothesis provided by the baseline SLU model and the first ranked hypothesis provided by the re-ranker. We show the effectiveness of these solutions presenting comparative results obtained reranking hypotheses generated by a very accurate Conditional Random Field model. We evaluate our approach on the French MEDIA corpus. The results show significant improvements with respect to current state-of-the-art and previous re-ranking models."
2011.jeptalnrecital-long.6,Acc{\\`e}s au contenu s{\\'e}mantique en langue de sp{\\'e}cialit{\\'e} : extraction des prescriptions et concepts m{\\'e}dicaux (Accessing the semantic content in a specialized language: extracting prescriptions and medical concepts),2011,-1,-1,4,0.615385,5675,cyril grouin,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Pourtant essentiel pour appr{\'e}hender rapidement et globalement l{'}{\'e}tat de sant{\'e} des patients, l{'}acc{\`e}s aux informations m{\'e}dicales li{\'e}es aux prescriptions m{\'e}dicamenteuses et aux concepts m{\'e}dicaux par les outils informatiques se r{\'e}v{\`e}le particuli{\`e}rement difficile. Ces informations sont en effet g{\'e}n{\'e}ralement r{\'e}dig{\'e}es en texte libre dans les comptes rendus hospitaliers et n{\'e}cessitent le d{\'e}veloppement de techniques d{\'e}di{\'e}es. Cet article pr{\'e}sente les strat{\'e}gies mises en oeuvre pour extraire les prescriptions m{\'e}dicales et les concepts m{\'e}dicaux dans des comptes rendus hospitaliers r{\'e}dig{\'e}s en anglais. Nos syst{\`e}mes, fond{\'e}s sur des approches {\`a} base de r{\`e}gles et d{'}apprentissage automatique, obtiennent une F1-mesure globale de 0,773 dans l{'}extraction des prescriptions m{\'e}dicales et dans le rep{\'e}rage et le typage des concepts m{\'e}dicaux."
2011.jeptalnrecital-long.10,Extraction de patrons s{\\'e}mantiques appliqu{\\'e}e {\\`a} la classification d{'}Entit{\\'e}s Nomm{\\'e}es (Extraction of semantic patterns applied to the classification of named entities),2011,-1,-1,3,0,6346,ismail maarouf,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"La variabilit{\'e} des corpus constitue un probl{\`e}me majeur pour les syst{\`e}mes de reconnaissance d{'}entit{\'e}s nomm{\'e}es. L{'}une des pistes possibles pour y rem{\'e}dier est l{'}utilisation d{'}approches linguistiques pour les adapter {\`a} de nouveaux contextes : la construction de patrons s{\'e}mantiques peut permettre de d{\'e}sambigu{\""\i}ser les entit{\'e}s nomm{\'e}es en structurant leur environnement syntaxico-s{\'e}mantique. Cet article pr{\'e}sente une premi{\`e}re r{\'e}alisation sur un corpus de presse d{'}un syst{\`e}me de correction. Apr{\`e}s une {\'e}tape de segmentation sur des crit{\`e}res discursifs de surface, le syst{\`e}me extrait et pond{\`e}re les patrons li{\'e}s {\`a} une classe d{'}entit{\'e} nomm{\'e}e fournie par un analyseur. Malgr{\'e} des mod{\`e}les encore relativement {\'e}l{\'e}mentaires, les r{\'e}sultats obtenus sont encourageants et montrent la n{\'e}cessit{\'e} d{'}un traitement plus approfondi de la classe Organisation."
2011.jeptalnrecital-demonstration.12,Extraction d{'}informations m{\\'e}dicales au {LIMSI} (Medical information extraction at {LIMSI}),2011,-1,-1,9,0.615385,5675,cyril grouin,Actes de la 18e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. D{\\'e}monstrations,0,
galibert-etal-2010-hybrid,Hybrid Citation Extraction from Patents,2010,7,3,2,1,13778,olivier galibert,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The Quaero project organized a set of evaluations of Named Entity recognition systems in 2009. One of the sub-tasks consists in extracting citations from patents, i.e. references to other documents, either other patents or general literature from English-language patents. We present in this paper the participation of LIMSI in this evaluation, with a complete system description and the evaluation results. The corpus shown that patent and non-patent citations have a very different nature. We then separated references to other patents and to general literature papers and we created a hybrid system. For patent citations, the system used rule-based expert knowledge on the form of regular expressions. The system for detecting non-patent citations, on the other hand, is purely stochastic (machine learning with CRF++). Then we mixed both approaches to provide a single output. 4 teams participated to this task and our system obtained the best results of this evaluation campaign, even if the difference between the first two systems is poorly significant."
quintard-etal-2010-question,Question Answering on Web Data: The {QA} Evaluation in Qu{\\ae}ro,2010,10,24,7,0,42953,ludovic quintard,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In the QA and information retrieval domains progress has been assessed via evaluation campaigns(Clef, Ntcir, Equer, Trec).In these evaluations, the systems handle independent questions and should provide one answer to each question, extracted from textual data, for both open domain and restricted domain. Qu{\ae}ro is a program promoting research and industrial innovation on technologies for automatic analysis and classification of multimedia and multilingual documents. Among the many research areas concerned by Qu{\ae}ro. The Quaero project organized a series of evaluations of Question Answering on Web Data systems in 2008 and 2009. For each language, English and French the full corpus has a size of around 20Gb for 2.5M documents. We describe the task and corpora, and especially the methodologies used in 2008 to construct the test of question and a new one in the 2009 campaign. Six types of questions were addressed, factual, Non-factual(How, Why, What), List, Boolean. A description of the participating systems and the obtained results is provided. We show the difficulty for a question-answering system to work with complex data and questions."
galibert-etal-2010-named,Named and Specific Entity Detection in Varied Data: The Qu{\\ae}ro Named Entity Baseline Evaluation,2010,9,14,3,1,13778,olivier galibert,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The Qu{\ae}ro program that promotes research and industrial innovation on technologies for automatic analysis and classification of multimedia and multilingual documents. Within its context a set of evaluations of Named Entity recognition systems was held in 2009. Four tasks were defined. The first two concerned traditional named entities in French broadcast news for one (a rerun of ESTER 2) and of OCR-ed old newspapers for the other. The third was a gene and protein name extraction in medical abstracts. The last one was the detection of references in patents. Four different partners participated, giving a total of 16 systems. We provide a synthetic descriptions of all of them classifying them by the main approaches chosen (resource-based, rules-based or statistical), without forgetting the fact that any modern system is at some point hybrid. The metric (the relatively standard Slot Error Rate) and the results are also presented and discussed. Finally, a process is ongoing with preliminary acceptance of the partners to ensure the availability for the community of all the corpora used with the exception of the non-Qu{\ae}ro produced ESTER 2 one."
garcia-fernandez-etal-2010-macaq,{MACAQ} : A Multi Annotated Corpus to Study how we Adapt Answers to Various Questions,2010,5,3,2,1,39320,anne garciafernandez,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents a corpus of human answers in natural language collected in order to build a base of examples useful when generating natural language answers. We present the corpus and the way we acquired it. Answers correspond to questions with fixed linguistic form, focus, and topic. Answers to a given question exist for two modalities of interaction: oral and written. The whole corpus of answers was annotated manually and automatically on different levels including words from the questions being reused in the answer, the precise element answering the question (or information-answer), and completions. A detailed description of the annotations is presented. Two examples of corpus analyses are described. The first analysis shows some differences between oral and written modality especially in terms of length of the answers. The second analysis concerns the reuse of the question focus in the answers."
moreau-etal-2010-evaluation,Evaluation Protocol and Tools for Question-Answering on Speech Transcripts,2010,12,2,4,0,46066,nicolas moreau,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"Question Answering (QA) technology aims at providing relevant answers to natural language questions. Most Question Answering research has focused on mining document collections containing written texts to answer written questions. In addition to written sources, a large (and growing) amount of potentially interesting information appears in spoken documents, such as broadcast news, speeches, seminars, meetings or telephone conversations. The QAST track (Question-Answering on Speech Transcripts) was introduced in CLEF to investigate the problem of question answering in such audio documents. This paper describes in detail the evaluation protocol and tools designed and developed for the CLEF-QAST evaluation campaigns that have taken place between 2007 and 2009. We first remind the data, question sets, and submission procedures that were produced or set up during these three campaigns. As for the evaluation procedure, the interface that was developed to ease the assessorsÂ work is described. In addition, this paper introduces a methodology for a semi-automatic evaluation of QAST systems based on time slot comparisons. Finally, the QAST Evaluation Package 2007-2009 resulting from these evaluation campaigns is also introduced."
vasilescu-etal-2010-role,On the Role of Discourse Markers in Interactive Spoken Question Answering Systems,2010,26,3,2,0.952381,14729,ioana vasilescu,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper presents a preliminary analysis of the role of some discourse markers and the vocalic hesitation ''``euh'''' in a corpus of spoken human utterances collected with the Ritel system, an open domain and spoken dialog system. The frequency and contextual combinatory of classical discourse markers and of the vocalic hesitation have been studied. This analysis pointed out some specificity in terms of combinatory of the analyzed items. The classical discourse markers seem to help initiating larger discursive blocks both at initial and medial positions of the on-going turns. The vocalic hesitation stand also for marking the user's embarrassments and wish to close the dialog."
bernard-etal-2010-question,A Question-answer Distance Measure to Investigate {QA} System Progress,2010,8,6,2,0,29860,guillaume bernard,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The performance of question answering system is evaluated through successive evaluations campaigns. A set of questions are given to the participating systems which are to find the correct answer in a collection of documents. The creation process of the questions may change from one evaluation to the next. This may entail an uncontroled question difficulty shift. For the QAst 2009 evaluation campaign, a new procedure was adopted to build the questions. Comparing results of QAst 2008 and QAst 2009 evaluations, a strong performance loss could be measured in 2009 for French and English, while the Spanish systems globally made progress. The measured loss might be related to this new way of elaborating questions. The general purpose of this paper is to propose a measure to calibrate the difficulty of a question set. In particular, a reasonable measure should output higher values for 2009 than for 2008. The proposed measure relies on a distance measure between the critical elements of a question and those of the associated correct answer. An increase of the proposed distance measure for French and English 2009 evaluations as compared to 2008 could be established. This increase correlates with the previously observed degraded performances. We conclude on the potential of this evaluation criterion: the importance of such a measure for the elaboration of new question corpora for questions answering systems and a tool to control the level of difficulty for successive evaluation campaigns."
2010.jeptalnrecital-long.27,Comment formule-t-on une r{\\'e}ponse en langue naturelle ?,2010,-1,-1,2,1,39320,anne garciafernandez,Actes de la 17e conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Cet article pr{\'e}sente l{'}{\'e}tude d{'}un corpus de r{\'e}ponses formul{\'e}es par des humains {\`a} des questions factuelles. Des observations qualitatives et quantitatives sur la reprise d{'}{\'e}l{\'e}ments de la question dans les r{\'e}ponses sont expos{\'e}es. La notion d{'}information-r{\'e}ponse est introduite et une {\'e}tude de la pr{\'e}sence de cet {\'e}l{\'e}ment dans le corpus est propos{\'e}e. Enfin, les formulations des r{\'e}ponses sont {\'e}tudi{\'e}es."
2009.jeptalnrecital-court.26,Collecte et analyses de r{\\'e}ponses naturelles pour les syst{\\`e}mes de questions-r{\\'e}ponses,2009,-1,-1,2,1,39320,anne garciafernandez,Actes de la 16{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,Notre travail se situe dans le cadre des syst{\`e}mes de r{\'e}ponse a une question et {\`a} pour but de fournir une r{\'e}ponse en langue naturelle aux questions pos{\'e}es en langue naturelle. Cet article pr{\'e}sente une exp{\'e}rience permettant d{'}analyser les r{\'e}ponses de locuteurs du fran{\c{c}}ais {\`a} des questions que nous leur posons. L{'}exp{\'e}rience se d{\'e}roule {\`a} l{'}{\'e}crit comme {\`a} l{'}oral et propose {\`a} des locuteurs fran{\c{c}}ais des questions relevant de diff{\'e}rents types s{\'e}mantiques et syntaxiques. Nous mettons en valeur une large variabilit{\'e} dans les formes de r{\'e}ponses possibles en langue fran{\c{c}}aise. D{'}autre part nous {\'e}tablissons un certain nombre de liens entre formulation de question et formulation de r{\'e}ponse. Nous proposons d{'}autre part une comparaison des r{\'e}ponses selon la modalit{\'e} oral / {\'e}crit. Ces r{\'e}sultats peuvent {\^e}tre int{\'e}gr{\'e}s {\`a} des syst{\`e}mes existants pour produire une r{\'e}ponse en langue naturelle de fa{\c{c}}on dynamique.
lamel-etal-2008-question,Question Answering on Speech Transcriptions: the {QAST} evaluation in {CLEF},2008,8,11,2,0,14730,lori lamel,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper reports on the QAST track of CLEF aiming to evaluate Question Answering on Speech Transcriptions. Accessing information in spoken documents provides additional challenges to those of text-based QA, needing to address the characteristics of spoken language, as well as errors in the case of automatic transcriptions of spontaneous speech. The framework and results of the pilot QAst evaluation held as part of CLEF 2007 is described, illustrating some of the additional challenges posed by QA in spoken documents relative to written ones. The current plans for future multiple-language and multiple-task QAst evaluations are described."
toney-etal-2008-evaluation,An Evaluation of Spoken and Textual Interaction in the {RITEL} Interactive Question Answering System,2008,6,12,2,0,48266,dave toney,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The RITEL project aims to integrate a spoken language dialogue system and an open-domain information retrieval system in order to enable human users to ask a general question and to refine their search for information interactively. This type of system is often referred to as an Interactive Question Answering (IQA) system. In this paper, we present an evaluation of how the performance of the RITEL system differs when users interact with it using spoken versus textual input and output. Our results indicate that while users do not perceive the two versions to perform significantly differently, many more questions are asked in a typical text-based dialogue."
rosset-petel-2006-ritel,The Ritel Corpus - An annotated Human-Machine open-domain question answering spoken dialog corpus,2006,2,6,1,1,5280,sophie rosset,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper we present a real (as opposed to Wizard-of-Oz) Human-Computer QA-oriented spoken dialog corpus collected with our Ritel platform. This corpus has been orthographically transcribed and annotated in terms of Specific Entities and Topics. Twelve main topics have been chosen. They are refined into 22 sub-topics. The Specific Entities are from five categories and cover Named Entities, linguistic entities, topic-defining entities, general entities and extended entities. The corpus contains 582 dialogs for 6 hours of user speech."
2005.jeptalnrecital-long.29,D{\\'e}tection automatique d{'}actes de dialogue par l{'}utilisation d{'}indices multiniveaux,2005,-1,-1,1,1,5280,sophie rosset,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Ces derni{\`e}res ann{\'e}es, il y a eu de nombreux travaux portant sur l{'}utilisation d{'}actes de dialogue pour caract{\'e}riser les dialogues homme-homme ou homme-machine. Cet article fait {\'e}tat de nos travaux sur la d{\'e}tection automatique d{'}actes de dialogue dans des corpus r{\'e}els de dialogue homme-homme. Notre travail est fond{\'e} essentiellement sur deux hypoth{\`e}ses . (i) la position des mots et la classe s{\'e}mantique du mot sont plus importants que les mots eux-m{\^e}mes pour identifier l{'}acte de dialogue et (ii) il y a une forte pr{\'e}dictivit{\'e} dans la succession des actes de dialogues port{\'e}s sur un m{\^e}me segment dialogique. Une approche de type Memory Based Learning a {\'e}t{\'e} utilis{\'e}e pour la d{\'e}tection automatique des actes de dialogue. Le premier mod{\`e}le n{'}utilise pas d{'}autres informations que celles contenus dans le tour de parole. Dans lex exp{\'e}riences suivantes, des historiques dialogiques de taille variables sont utilis{\'e}s. Le taux d{'}erreur de d{\'e}tection d{'}actes de dialogue est d{'}environ 16{\%} avec le premier mod{\`e}le est descend avec une utilisation plus large de l{'}historique du dialogue {\`a} environ 14{\%}."
2005.jeptalnrecital-court.10,Ritel : un syst{\\`e}me de dialogue homme-machine {\\`a} domaine ouvert,2005,-1,-1,3,1,13778,olivier galibert,Actes de la 12{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles courts,0,"L{'}objectif du projet RITEL est de r{\'e}aliser un syst{\`e}me de dialogue homme-machine permettant {\`a} un utilisateur de poser oralement des questions, et de dialoguer avec un syst{\`e}me de recherche d{'}information g{\'e}n{\'e}raliste (par exemple, chercher sur l{'}Internet {``}Qui est le Pr{\'e}sident du S{\'e}nat ?{''}) et d{'}en {\'e}tudier les potentialit{\'e}s. Actuellement, la plateforme RITEL permet de collecter des corpus de dialogue homme-machine. Les utilisateurs peuvent parfois obtenir une r{\'e}ponse, de type factuel (Q : qui est le pr{\'e}sident de la France ; R : Jacques Chirac.). Cet article pr{\'e}sente bri{\`e}vement la plateforme d{\'e}velopp{\'e}e, le corpus collect{\'e} ainsi que les questions que soul{\`e}vent un tel syst{\`e}me et quelques unes des premi{\`e}res solutions envisag{\'e}es."
devillers-etal-2004-french,The {F}rench {MEDIA}/{EVALDA} Project: the Evaluation of the Understanding Capability of Spoken Language Dialogue Systems,2004,9,30,3,1,39952,laurence devillers,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,The aim of the MEDIA project is to design and test a methodology for the evaluat ion of context-dependent and independent spoken dialogue systems. We propose an evaluation paradigm based on the use of test suites from real-world corpora and a common semantic representation and common metrics. This paradigm should allow us to diagnose the context-sensitive understanding capability of dialogue system s. This paradigm will be used within an evaluation campaign involving several si tes all of which will carry out the task of querying information from a database .
W03-2802,The {PEACE} {SLDS} understanding evaluation paradigm of the {F}rench {MEDIA} campaign,2003,17,4,4,1,39952,laurence devillers,"Proceedings of the {EACL} 2003 Workshop on Evaluation Initiatives in Natural Language Processing: are evaluation methods, metrics and resources reusable?",0,"This paper presents a paradigm for evaluating the context-sensitive understanding capability of any spoken language dialog system: PEACE (French acronym for Paradigme d'Evaluation Automatique de la Comprehension hors et En-contexte). This paradigm will be the basis of the French Technolangue MEDIA project, in which dialog systems from various academic and industrial sites will be tested in an evaluation campaign coordinated by ELRA/ELDA (over the next two years). Despite previous efforts such as Eagles, Disc, Aupelf Arcb2 or the ongoing American Darpa Communicator project, the spoken dialog community still lacks common reference tasks and widely agreed upon methods for comparing and diagnosing systems and techniques. Automatic solutions are nowadays being sought both to make possible the comparison of different approaches by means of reliable indicators with generic evaluation methodologies and also to reduce system development costs. However achieving independence from both the dialog system and the task performed seems to be more and more a utopia. Most of the evaluations have up to now either tackled the system as a whole, or based the measurements on dialog-context-free information. The PEACE proposal aims at bypassing some of these shortcomings by extracting, from real dialog corpora, test sets that synthesize contextual information."
antoine-etal-2002-predictive,Predictive and objective evaluation of speech understanding: the {``}challenge{''} evaluation campaign of the I3 speech workgroup of the {F}rench {CNRS},2002,13,10,5,0,5666,jeanyves antoine,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper presents a new paradigm of xe2x80x9cchallengexe2x80x9d evaluation of Spoken Language Understanding. This methodology aims at a quantitative assessment with a high diagnostic power, by opposition with standard ATIS-like frameworks. This paper details the methodology as well as the results of an evaluation campaign held by the French CNRS research agency. The benefits of this methodology are also discussed."
devillers-etal-2002-annotations,Annotations for Dynamic Diagnosis of the Dialog State,2002,4,10,2,1,39952,laurence devillers,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper describes recent work aimed at relating multi-level dialog annotations with meta-data annotations for a corpus of real humanhuman dialogs. This work is carried out in the context of the AMITIES project in which spoken dialog systems for call center services are being developed. A corpus of 100 agent-client dialogs have been annotated with three types of annotations. The first are utterance-level DAMSL-style dialogic labels. The second set of annotations applies to exchanges and takes into account of the dynamic aspect of dialog progress. Finally, 5 emotions types are annotated at the utterance level. Some of these multi-style annotations were used in a multiple linear regression analysis to predict dialog quality. The predictive factors are able to explain about 80% of the dialog accidents."
2001.jeptalnrecital-poster.10,Gestionnaire de dialogue pour un syst{\\`e}me d{'}informations {\\`a} reconnaissance vocale,2001,0,0,1,1,5280,sophie rosset,Actes de la 8{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Posters,0,"Dans cet article, nous pr{\'e}sentons un gestionnaire de dialogue pour un syst{\`e}me de demande d{'}informations {\`a} reconnaissance vocale. Le gestionnaire de dialogue dispose de diff{\'e}rentes sources de connaissance, des connaissances statiques et des connaissances dynamiques. Ces connaissances sont g{\'e}r{\'e}es et utilis{\'e}es par le gestionnaire de dialogue via des strat{\'e}gies. Elles sont mises en oeuvre et organis{\'e}es en fonction des objectifs concernant le syst{\`e}me de dialogue et en fonction des choix ergonomiques que nous avons retenus. Le gestionnaire de dialogue utilise un mod{\`e}le de dialogue fond{\'e} sur la d{\'e}termination de phases et un mod{\`e}le de la t{\^a}che dynamique. Il augmente les possibilit{\'e}s d{'}adaptation de la strat{\'e}gie en fonction des historiques et de l{'}{\'e}tat du dialogue. Ce gestionnaire de dialogue, impl{\'e}ment{\'e} et {\'e}valu{\'e} lors de la derni{\`e}re campagne d{'}{\'e}valuation du projet LE-3 ARISE, a permi une am{\'e}lioration du taux de succ{\`e}s de dialogue (de 53{\%} {\`a} 85{\%})."
