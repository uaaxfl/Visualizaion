2020.icon-main.34,E17-2106,0,0.063099,"Missing"
2020.icon-main.4,W19-5605,1,0.827508,"Missing"
2020.lrec-1.415,W19-5605,1,0.888471,"section 5.1.2. 5.1 Hadith Segmentation Tool Building a Hadith segmentation tool is a non-trivial task that possesses key challenges associated with Hadith structure that requires novel methods to overcome them. In fact, recognizing sentence boundaries in a running text is a diﬀicult task in languages such as Arabic, especially in the absence of strict punctuation rules and the lack of capitalization. Moreover, segmenting Hadith components is a domain-specific task that can be even tricky for the non-specialist. Therefore, automating it ensures consistency in segmentation. In a previous work (Altammami et al., 2019), we created the first version of the Hadith segmenter which uses look-up lists and applies a back-off algorithm to segment Isnad from Matn. Although it produced acceptable results, we improve its performance by incorporating a machine learning (ML) model into the pipeline, and modified the algorithm to deal with irregular Hadith structures. Moreover, we doubled the evaluation data to 500 Hadiths extracted from the six canonical books where Hadiths with irregular structures were manually chosen. This is to ensure the evaluation data is representative of the whole corpus. 5. Finally, the segmen"
2021.wanlp-1.19,2019.nsurl-1.17,0,0.0347504,"Missing"
2021.wanlp-1.19,2020.osact-1.2,0,0.0394464,"Missing"
2021.wanlp-1.19,N19-1423,0,0.0774553,"Missing"
2021.wanlp-1.19,2020.wanlp-1.5,0,0.0833627,"Missing"
2021.wanlp-1.19,S15-2040,0,0.0557908,"Missing"
2021.wanlp-1.19,N18-1049,0,0.0810146,"Missing"
2021.wanlp-1.19,2020.acl-main.630,0,0.0816939,"Missing"
2021.wanlp-1.19,N18-1202,0,0.0699434,"Missing"
2021.wanlp-1.19,D19-1410,0,0.0623536,"Missing"
2021.wanlp-1.19,2020.tacl-1.54,0,0.0232937,"2 2.1 Introduction In recent years, Natural Language Processing (NLP) has been evolved with the introduction of Transformer architecture by Vaswani et al. (2017). BERT, built on the transformer layer, has showed and produced state-of-the-art accuracy in a number of NLP tasks such as machine translation and text classification (Devlin et al., 2019). There are two stages of BERT: pre-training and fine-tuning. Pre-training is used for masked language modeling and next sentence prediction. For fine-tuning, is to add one or more layers designed for specific task on top of the final encoder layer (Rogers et al., 2020). Google provides pre-trained models for English and other languages including Arabic. Several studies provide their own language model based on BERT to perform better on specific tasks. AraBERT is recently published that contributes to Arabic language model that is pre-trained to suit a wide range of Arabic NLP related tasks. In this paper, we have used AraBERT language model to classify QurSim dataset in semantic relatedness task. Section 2 will outline the related work in semantic similarity and relatedness while section 3 Related Work Semantic Similarity/Relatedness in Arabic and Quranic T"
2021.wanlp-1.19,2019.nsurl-1.12,0,0.0408657,"Missing"
2021.wanlp-1.19,2019.nsurl-1.1,0,0.0475646,"Missing"
2021.wanlp-1.19,sharaf-atwell-2012-qursim,1,0.590815,"Elimination We found there were duplicated pairs of verses in QurSim datasets with the total of 764 records of duplicated pairs of verses. When we examined the duplicates, there were 592 records of duplicated pairs were labelled the same but ordered differently. For example, chapter 2 verse 2 is paired with chapter 2 verse 3 and the pair is labelled ‘2’ and vice versa, shown in Table 1. For this case, we opted to remove the duplicates since they were redundant considering that the relationship is naturally bidirectional. QurSim QurSim is a work of Arabic text that pertains to the Holy Quran (Sharaf and Atwell, 2012). The dataset showcases 7679 pairs of verses that are similar or related verses according to comments of Ibn Kathir’s Tafsir, which is highly respected for its interpretation of the Holy Quran. It also improves its dataset using lexical similarity approach such as Term Frequency-Inverse Document Frequency (TFIDF). QurSim dataset classifies pairs of Quranic Mapping QurSim dataset to Quranic Verses Text ID SS SV TS TV Label 91 98 2 2 2 3 2 2 3 2 1 1 Table 1: Duplicated pairs of verses with same label, where SS stands for source Soura (chapter) , SV is the source verse, TS is target Soura and TV"
2021.wanlp-1.19,W19-4619,0,0.0215277,"nce-BERT (SBERT) that uses siamese and triplets network structure with modified pre-trained BERT to derive semantically meaningful text embeddings that can be compared using cosine-similarity. However, to the best of our knowledge there is no research on semantic similarity or relatedness using BERT or AraBERT on Holy Quran text. 3 AraBERT AraBERT is an Arabic language model in which BERT was trained on a large Arabic corpus (Antoun et al., 2020). The dataset includes Arabic Wikipedia, 1.5 billion words from Arabic corpora (El-Khair, 2016) and the Open Source International Arabic News Corpus (Zeroual et al., 2019). The corpus covers news articles from several Arab news media with different topics and from different Arab countries. The size of the pre-training dataset is 70 million sentences that amounts to approximately 24GB of text (Antoun et al., 2020). AraBERT has produced better results on various Arabic NLP tasks. In sentiment analysis, AraBERT performed better than mBERT, which is a multilingual BERT model developed by Google, on most tested datasets (Antoun et al., 2020). Also, AraBERT outperformed mBERT and TF-IDF on the new Twitter-based benchmark dataset for Arabic Sentiment Analysis (Alharbi"
brierley-atwell-2008-proposel-prosody,C02-1094,0,\N,Missing
brierley-atwell-2008-proposel-prosody,W94-0103,1,\N,Missing
brierley-atwell-2010-proposec,brierley-atwell-2008-proposel-prosody,1,\N,Missing
brierley-atwell-2010-proposec,W08-1904,1,\N,Missing
brierley-etal-2012-open,sawalha-atwell-2010-fine,1,\N,Missing
brierley-etal-2012-open,brierley-atwell-2010-proposec,1,\N,Missing
brierley-etal-2012-open,brierley-atwell-2008-proposel-prosody,1,\N,Missing
brierley-etal-2012-open,sawalha-etal-2012-predicting,1,\N,Missing
brierley-etal-2014-tools,sawalha-atwell-2010-fine,1,\N,Missing
brierley-etal-2014-tools,brierley-etal-2012-open,1,\N,Missing
brierley-etal-2014-tools,sawalha-etal-2012-predicting,1,\N,Missing
demetriou-etal-2000-using,J87-3001,0,\N,Missing
demetriou-etal-2000-using,E93-1028,0,\N,Missing
demetriou-etal-2000-using,C90-2067,0,\N,Missing
demetriou-etal-2000-using,P94-1020,0,\N,Missing
demetriou-etal-2000-using,P91-1019,0,\N,Missing
demetriou-etal-2000-using,C88-1019,0,\N,Missing
demetriou-etal-2000-using,P97-1007,0,\N,Missing
demetriou-etal-2000-using,H93-1021,0,\N,Missing
dukes-atwell-2012-lamp,A00-2018,0,\N,Missing
dukes-atwell-2012-lamp,brierley-atwell-2008-proposel-prosody,1,\N,Missing
dukes-atwell-2012-lamp,E09-1087,0,\N,Missing
dukes-atwell-2012-lamp,J03-4003,0,\N,Missing
dukes-atwell-2012-lamp,A00-1031,0,\N,Missing
dukes-atwell-2012-lamp,P11-2009,0,\N,Missing
dukes-atwell-2012-lamp,W11-2912,1,\N,Missing
dukes-atwell-2012-lamp,D07-1096,0,\N,Missing
dukes-atwell-2012-lamp,dukes-habash-2010-morphological,1,\N,Missing
dukes-atwell-2012-lamp,dukes-etal-2010-syntactic,1,\N,Missing
dukes-etal-2010-syntactic,P08-2030,0,\N,Missing
dukes-etal-2010-syntactic,dukes-habash-2010-morphological,1,\N,Missing
E87-1007,J83-3004,0,\N,Missing
E87-1007,J80-2003,0,\N,Missing
E87-1007,J81-2002,0,\N,Missing
E87-1007,J83-3003,0,\N,Missing
E87-1007,J83-3005,0,\N,Missing
E87-1007,J83-3001,0,\N,Missing
E87-1007,J83-3002,0,\N,Missing
E87-1007,E87-1010,1,\N,Missing
E87-1007,J81-4002,0,\N,Missing
E87-1010,E87-1007,1,\N,Missing
E87-1010,E85-1025,0,\N,Missing
elliott-etal-2004-fluency,P02-1040,0,\N,Missing
elliott-etal-2004-fluency,takezawa-etal-2002-toward,0,\N,Missing
elliott-etal-2004-fluency,vanni-miller-2002-scaling,0,\N,Missing
elliott-etal-2004-fluency,2001.mtsummit-eval.6,0,\N,Missing
elliott-etal-2004-fluency,rajman-hartley-2002-automatic,1,\N,Missing
elliott-etal-2004-fluency,2001.mtsummit-papers.3,0,\N,Missing
L16-1080,boulaknadel-etal-2008-multi,0,0.152369,"h can be seen in the work of Choueka (1988), Mel’cuk ( 1998; 2003) and Bartsch (2004, 76) who defines collocations as: 502 ''…lexically and-or pragmatically constrained recurrent cooccurrences of at least two lexical items which are in a direct syntactic relation with each other''. The third approach used a combination of statistical and linguistic methods in different types of collocation extraction models. In Arabic, several studies have attempted to automatically or semi-automatically extract lists of collocations based on different experimental settings and language domains. For instance, Boulaknadel et al. (2008) developed a programme for multi-word extractions based on linguistic analysis and the evaluation of statistical scores, in which a list of Arabic terms from the environmental domain was used as the gold standard list in the evaluation of four AMs, LLR, T-score, FLR and Mutual Information. The experiment was conducted on an environmental corpus, the extracted terms tested against the reference list, and the result shows that the LogLikelihood Ratio, and the FLR and t-score measures outperform the MI measure. In another study by Saif and Aziz (2011) using a hybrid method for extracting the coll"
L16-1080,J90-1003,0,0.253134,"s an umbrella one to refer to various types of linguistic units in general. Thus, the current study adopts a practical definition of Arabic FSs which basically concentrates on any type of syntactic construction from different language domains that makes high frequency use of semantically regular phrases. 2. Related work In the literature there are three main approaches for collocation extraction – data-driven, knowledge-based and hybrid methods. These approaches have been applied in many experimental studies in different languages and different experimental settings. Studies by Smadja (1993), Church and Hanks (1990) and Sinclair (1991) represent the use of data-driven statistical approaches as the main feature in the process of collocation extraction. For instance, Sinclair defined collocation as ''…lexical co-occurrence, more or less independently of grammatical pattern or positional relationship'' (ibid. p.170), while knowledgebased or linguistic models of collocation extractions emphasise the role of a syntactic relationship between the lexical items in the collocations. Examples of using such an approach can be seen in the work of Choueka (1988), Mel’cuk ( 1998; 2003) and Bartsch (2004, 76) who defin"
L16-1080,C00-1027,0,0.018265,"Missing"
L16-1080,J93-1003,0,0.435662,"Missing"
L16-1080,P05-2003,0,0.0765278,"Missing"
L16-1080,J93-1007,0,0.747572,"ing this term as an umbrella one to refer to various types of linguistic units in general. Thus, the current study adopts a practical definition of Arabic FSs which basically concentrates on any type of syntactic construction from different language domains that makes high frequency use of semantically regular phrases. 2. Related work In the literature there are three main approaches for collocation extraction – data-driven, knowledge-based and hybrid methods. These approaches have been applied in many experimental studies in different languages and different experimental settings. Studies by Smadja (1993), Church and Hanks (1990) and Sinclair (1991) represent the use of data-driven statistical approaches as the main feature in the process of collocation extraction. For instance, Sinclair defined collocation as ''…lexical co-occurrence, more or less independently of grammatical pattern or positional relationship'' (ibid. p.170), while knowledgebased or linguistic models of collocation extractions emphasise the role of a syntactic relationship between the lexical items in the collocations. Examples of using such an approach can be seen in the work of Choueka (1988), Mel’cuk ( 1998; 2003) and Bar"
L16-1285,L16-1080,1,0.861802,"Missing"
L16-1285,E87-1007,1,0.277846,"level hierarchy for the genre: Folktales Most genres can be defined via 2-levels, but the example in 1810 Figure 5 shows an Arabian Nights story classified via 3 levels for the Folktales genre: Fiction, Folktale, and Arabian Nights. Figure 6 displays the hierarchy of genres in this current version of the corpus. It is unusual for collectors of corpora to proofread corpus texts, as normally the corpus is used as evidence of real language usage; but corpora aimed at language teaching and learning may be an exception, as we need correct exemplars of the language to be taught (Alfaifi et al 2013; Atwell 1987). Another issue is vowelisation: some texts are fully vowelled (i.e. contain short vowels and other diacritics), while others are not; this may create problems for analysis later (e.g. use of a concordancer). Finally, though we consider genre to be an important feature for inclusion in the corpus, texts are very difficult to categorise. For example, a biography can contain anecdotal stories, or a story with animals as characters may preach a moral lesson. 8. Figure 6: Screenshot from SketchEngine showing simple tree structure for text genres As previously mentioned, our Arabic Children’s Corpu"
L16-1285,2006.eamt-1.31,0,0.0289033,"re very few and some are scanned PDF files or audio files. To make the corpus more balanced, it was decided to manually type these texts for younger children. Once suitable websites were determined, each researcher embarked on text collection, making sure to keep a record of the title and source of each text in an Excel file. This ensured that the list of texts collected by the two researchers was not the same because some websites copy stories from other sources. 4. Collecting the Corpus Our initial plan for collecting the corpus was to use bespoke web-as-corpus software, namely: WebBootCat (Baroni et al 2006). This offers two alternatives for corpus collection: (i) via seed terms used as queries in Google, where subsequent hits then constitute a first-pass specialist corpus; (ii) and by uploading URLs. In practice, however, we found that sometimes, when the corpus was downloaded from the website, the text was not complete; when compared to the original document either the beginning or the end of the text was missing. This is related to the fact that when the tool tries to remove unwanted data such as navigation menus, links, ads, headers and footers – all referred to as boilerplate – a slice of th"
L18-1621,P13-4001,0,0.10383,"Missing"
L18-1621,dukes-habash-2010-morphological,0,0.0290688,"are tagged with the feature enabled (F=True) and then disabled (F=False) but in a different order for each half. The steps are {H1F=True,H2 F=False,H1 3937 F=False,H2 F=True }, and first two steps are first round. In the last two steps, the annotator already knows the texts and should annotate it faster. However, results between step 3 and 4 are comparable as the word counts are similar. In Arabic cases, we used Quranic Arabic Corpus and asked the annotation to follow its annotation guidelines, and the annotator understands well its tagset. UDPipe is trained as well on Quranic Arabic Corpus (Dukes & Habash, 2010) (converted to CoNLL-U by the author and available on Github6). The morphological analyser used here is MADAMIRA and its results are parsed and converted to CoNLL-U format using Sawaref toolkit. A manual mapping from MADAMIRA tagset to QAC is defined and used. Time is used as a metric for efficiency. The Intra-rater reliability is high in all cases which shows that using features does not affect the accuracy. Mismatches between the two rounds are reviewed and corrected in a third round. The accuracy in terms of the fraction of correctly annotated words is then evaluated for the two rounds comp"
L18-1621,W13-3711,0,0.0202565,"on and labelling In the next section, we provide an overview of major related tools for annotating corpora, with a tabular comparison of support for these features with Wasim. 2. Related Work We limit our literature review to tools that meet our four conditions, which results in five tools. Brat (Stenetorp et al., 2012) is a widely-used visualization and annotation tool that is mainly for syntactic annotation in addition to morpho-syntactic annotation. WebAnno (Yimam, Gurevych, de Castilho, & Biemann, 2013) is a Java-based set of well-documented tools for multiple annotation tasks. Arborator (Gerdes, 2013) is a dependency annotation tool, that supports RTL languages natively. Sequence Annotation Web Tool (Samih, Maier, & Kallmeyer, 2016) is a basic web-based tool for the annotation of token sequences with an arbitrary set of labels (e.g. POS tags). The authors claimed to publish the code on GitHub, but we could not find a link to it, so we exclude it from the table comparison. CorA (Marcel Bollmann, Florian Petran, Stefanie Dipper, 2014) is a web-based tool for morpho-syntactic annotation of nonstandard texts. In Table 1, we compare the support of the six features. Although these tools did not"
L18-1621,W14-0612,0,0.204173,"Missing"
L18-1621,W16-5808,0,0.0129242,"tabular comparison of support for these features with Wasim. 2. Related Work We limit our literature review to tools that meet our four conditions, which results in five tools. Brat (Stenetorp et al., 2012) is a widely-used visualization and annotation tool that is mainly for syntactic annotation in addition to morpho-syntactic annotation. WebAnno (Yimam, Gurevych, de Castilho, & Biemann, 2013) is a Java-based set of well-documented tools for multiple annotation tasks. Arborator (Gerdes, 2013) is a dependency annotation tool, that supports RTL languages natively. Sequence Annotation Web Tool (Samih, Maier, & Kallmeyer, 2016) is a basic web-based tool for the annotation of token sequences with an arbitrary set of labels (e.g. POS tags). The authors claimed to publish the code on GitHub, but we could not find a link to it, so we exclude it from the table comparison. CorA (Marcel Bollmann, Florian Petran, Stefanie Dipper, 2014) is a web-based tool for morpho-syntactic annotation of nonstandard texts. In Table 1, we compare the support of the six features. Although these tools did not meet all of our requirements, we must say that some of them support other features (e.g. syntactic annotation) that are not needed in"
L18-1621,E12-2021,0,0.133928,"aphical accents or diacritics Listing a set of solutions from a lexicon dictionary (internally or externally using a morphological analyser) Consistency validation and integrating annotation guidelines (e.g. homographs). Adaptive prediction based on historical tagging Efficient keyboard-based navigation and labelling In the next section, we provide an overview of major related tools for annotating corpora, with a tabular comparison of support for these features with Wasim. 2. Related Work We limit our literature review to tools that meet our four conditions, which results in five tools. Brat (Stenetorp et al., 2012) is a widely-used visualization and annotation tool that is mainly for syntactic annotation in addition to morpho-syntactic annotation. WebAnno (Yimam, Gurevych, de Castilho, & Biemann, 2013) is a Java-based set of well-documented tools for multiple annotation tasks. Arborator (Gerdes, 2013) is a dependency annotation tool, that supports RTL languages natively. Sequence Annotation Web Tool (Samih, Maier, & Kallmeyer, 2016) is a basic web-based tool for the annotation of token sequences with an arbitrary set of labels (e.g. POS tags). The authors claimed to publish the code on GitHub, but we co"
L18-1621,K17-3009,0,0.0226856,"he new segmentation will be added. A similar process is applied for morphological tagging. The list is regenerated periodically from the annotated part of the corpus, and the possible segmentations/POS tags of homographs are kept. Each homograph will have a set of examples in context for each sense. Moderators can edit the list, and/or add guideline notes for tagging of special cases. The list will appear in Wasim with relevant notes when selecting a word in the list. 3.3 POS tagging Integration Instead of starting the annotation process of a corpus from scratch, Wasim integrates with UDPipe (Straka & Straková, 2017) to kick start the annotation process. UDPipe provides trained models for more than 60 languages that tokenize, tag, lemmatize and dependency parse raw text and save results in CoNLL-U formatted files. Wasim uses UDPipe as well to improve its prediction model by periodically adding instances of the corpus that has been annotated so far. Other tools can be used as long as they generate CoNLLU formatted files. For example, SAWAREF toolkit can be used for Arabic and the translation from popular POS tagger into CoNLL-U format can be done using one of its tools. 4. Data Representation Wasim follows"
P88-1013,C86-1033,1,0.940083,"c English inputs by seeking labelled trce-su~ctures that maximize a measure of plausibility defined in terms of empirical statistics on parse-tree configurations drawn from a dmahase of mavnolly parsed English toxL This approach is a response to the fact that &quot;real-life&quot; English, such as the m~u,Jial in the Lancaster-Oslo/Bergen Corpus on which our research focuses, does not appear to conform to a fixed set of grammatical rules. (On the LOB Corpus and the research background from which Project APRIL emerged, see Garside et al. (1987). A crude pilot version of the APRIL system was described in Sampson (1986).) Orthodox computational linguistics is heavily influenced by a concept of language according to which the set of all strings over the vocabulary of the language is partitioned into a class of grammatical strings, which possess analyses all parts of which conform to a finite set of rules defining the language, and a class of strings which are ungrammatical and for which the question of their grammatical stntcture accordingly does not arise. Even systems which set out to handle &quot;deviant&quot; sentences commonly do so by referring them to particular &quot;non-deviant&quot; sentences of which they are deemed t"
sawalha-atwell-2010-constructing,D08-1030,0,\N,Missing
sawalha-atwell-2010-fine,C08-2027,1,\N,Missing
sawalha-atwell-2010-fine,mohamed-kubler-2010-arabic,0,\N,Missing
sawalha-atwell-2010-fine,D08-1030,0,\N,Missing
sawalha-atwell-2010-fine,N04-4038,0,\N,Missing
sawalha-atwell-2010-fine,C08-1098,0,\N,Missing
sawalha-atwell-2010-fine,sawalha-atwell-2010-constructing,1,\N,Missing
sawalha-atwell-2010-fine,P05-1071,0,\N,Missing
sawalha-atwell-2010-fine,J95-4004,0,\N,Missing
sawalha-atwell-2010-fine,W05-0701,0,\N,Missing
sawalha-etal-2012-predicting,sawalha-atwell-2010-fine,1,\N,Missing
sawalha-etal-2012-predicting,brierley-atwell-2010-proposec,1,\N,Missing
sawalha-etal-2012-predicting,brierley-etal-2012-open,1,\N,Missing
sawalha-etal-2012-predicting,dukes-habash-2010-morphological,0,\N,Missing
sharaf-atwell-2012-qurana,W98-1119,0,\N,Missing
sharaf-atwell-2012-qurana,P10-2010,0,\N,Missing
sharaf-atwell-2012-qurana,sharaf-atwell-2012-qursim,1,\N,Missing
sharaf-atwell-2012-qurana,hasler-etal-2006-nps,0,\N,Missing
sharaf-atwell-2012-qurana,dukes-etal-2010-syntactic,1,\N,Missing
sharaf-atwell-2012-qursim,C04-1051,0,\N,Missing
sharaf-atwell-2012-qursim,sharaf-atwell-2012-qurana,1,\N,Missing
sharaf-atwell-2012-qursim,dukes-etal-2010-syntactic,1,\N,Missing
shawar-atwell-2008-ai,P03-1051,0,\N,Missing
shawar-atwell-2008-ai,P06-1086,0,\N,Missing
shawar-atwell-2008-ai,2006.eamt-1.31,0,\N,Missing
W00-0705,C00-2150,1,\N,Missing
W00-1901,W94-0103,1,0.821962,"gged texts are Machine Learning researchers, who want tagged text to train a learning algorithm, but want a small tagset to reduce the problem space; another advantage of the ICE tagset is that it is easy to reduce the tagset to major categories only by ignoring the bracketed features. 5. Mapping between tagging schemes To re-tag the old parts of speech of a corpus with a new scheme of another, we apply our tagger to just the words of the corpus. This might appear to be ‘cheating’; but earlier experiments with devising a set of mapping rules from one tagset to another (Hughes and Atwell 1994, Atwell et al 1994, Hughes et al 1995) concluded that one-to-many and manyto-many mappings predominated over simple one-to-one (and many-to-one) mappings, resulting in more errors than the apparently naïve approach of ignoring the source tags. 6. Comparing tagging schemes The descriptions of each tagset and multitagged corpus on our website enable corpus-based comparisons between the tagsets. However, quantitative measures are not straightforward. As a simple metric, consider the number of tags in the tagset: this is generally not as simple as it first seems. Most tagsets use tags which are actually a combinati"
W00-1901,J93-1002,0,0.102284,"Missing"
W00-1901,J93-2004,0,0.0238198,"ight schemes (Brown, ICE, LLC,LOB, Parts, POW, SEC, UPenn). The tagged text is returned one email reply message per scheme. A verbose mode can also be selected, which gives the long name for each tag as well as its short form in the output file. This sentence is part of our multi-parsed corpus or MultiTreebank (Atwell 1996). The parsing schemes exemplified in our MultiTreebank include some which have been used for hand annotation of corpora or manual post-editing of automatic parsers: EPOW (O’Donoghue 1991), ICE (Greenbaum 1992), POW (Souter 1989a,b), SEC (Taylor and Knowles 1988), and UPenn (Marcus et al 1993). Linguist experts in each of these corpus annotation schemes kindly provided us with their parsings of the 60 IPSM sentences. Others are unedited output of parsing programs: Alice (Black and Neal 1996), 6 Table 7. Evaluation of MultiTreebank parse schemes in terms of EAGLES layers of syntactic annotation : (a) Bracketing of segments (b) Labelling of segments (c) Showing dependency relations (d) Indicating functional labels (e) Marking sub-classification of syntactic segments (f) Deep or ‘logical’ information (g) Information about the rank of a syntactic unit (h) Special syntactic characterist"
W00-1901,C00-2150,1,0.774159,"Missing"
W00-1901,C94-1079,0,0.0820557,"Missing"
W07-0313,W98-1233,0,\N,Missing
W07-0313,W95-0203,0,\N,Missing
W08-1904,C02-1094,0,0.0232673,"ields as users may wish to use the SAM-PA phonetic transcriptions). This filter retrieves sixty-seven candidates - most but not all of them end in /eIt/ - and includes one oddity among the examples in Table 4. Further examples of live filtered searches are presented in section 5. assigned to each entry in ProPOSEL in field (10). It is anticipated that further research will suggest modifications to this default status when the CFP attribute interacts with other text-based features. Syllable counts - field (7) in ProPOSEL - have already been used successfully in phrase break models for English (Atterer and Klein, 2002). However, they assume uniformity in terms of duration of syllables whereas we know that in connected speech, an indefinite number of unstressed syllables are packed into the gap between one stress pulse (Mortimer, 1985) and another, English being a stress-timed language. A lexical stress pattern, where syllables are weighted 0, 1 or 2, has therefore been included in fields (8) and (14) for entries in ProPOSEL because of its potential as a classificatory feature in the machine learning task of phrase break prediction. The thematic programme for PASCAL 3 in 2008 focuses on approaches to supplem"
W08-1904,brierley-atwell-2008-proposel-prosody,1,0.846315,"chine-readable, and is intended for open source distribution with the Natural Language ToolKit. It is therefore supported by Python software tools which transform ProPOSEL into a Python dictionary or associative array of linguistic concepts mapped to compound lookup keys. Users can also conduct searches on a subset of the lexicon and access entries by word class, phonetic transcription, syllable count and lexical stress pattern. ProPOSEL caters for a range of different cognitive aspects of the lexicon. 1 Eric Atwell School of Computing University of Leeds LEEDS LS2 9JT Introduction ProPOSEL (Brierley and Atwell, 2008) is a prosody and part-of-speech (PoS) English lexicon which merges information from respected electronic dictionaries and databases, and which is purpose-built for linkage with corpora; for populating tokenized corpus text with a priori linguistic knowledge; for machine learning tasks which involve the prosodic-syntactic chunking of text; and for open source distribution with NLTK - the Python-based Natural Language Toolkit (Bird et al, 2007a). guages, including US-English, have been created via the European-funded LC-STAR project (Hartinkainen et al, 2003) to address the shortage of language"
W16-4826,W09-0807,0,0.0334347,"SA is based on the text of the Quran, the holy book of Islam; and MSA is taught in Arab schools, and promoted by Arab civil as well as religious authorities and governments. There are many dialects spoken around the Arab World; Arabic dialectologists have studied hundreds of local variations, but generally agree these cluster into five main regional dialects: Iraqi Dialect (IRQ), Levantine Dialect (LAV), Egyptian Dialect (EGY), North Africa Dialect (NOR), and Gulf Dialect (GLF) which is a subclass of Peninsular Arabic. Studies in Arabic dialectology focus on phonetic variation (Alorifi, 2008; Biadsy et al., 2009; Horesh and Cotter, 2016; Sadat et al., 2014). Horesh and Cotter (Horesh and Cotter, 2016) confirmed that past and current research is focussed on phonetic and phonological variation between Arabic dialects: all examples that they presented are of phoneme variation, and they did not mention any work on text, or corpus-based research, or of lexical or morpho-syntactic or grammar variation. However, Arabic spoken dialect does include local words, phrases, and even local variant morphology and grammar. With the spread of informal writing, for example on social networks and in local-dialect blogs"
W16-4826,P13-2081,0,0.0538519,"Missing"
W16-4826,W13-1728,0,0.0711536,"Missing"
W16-4826,W16-4801,0,0.0284495,"d to avoid the problem of translation into MSA by using Automatic Speech Recognition rather than human scribes. However, these texts were often much shorter than 20100 words, sometimes only 1 or 2 word utterances; and these short utterances could be common to two or more dialects, with no further indicators for differentiation. Arabic linguistics experts in our team found clear evidence of MSA in numerous dialect texts, possibly introduced by the ASR transcription method; and numerous short utterance instances which had no linguistic evidence of a specific Arabic dialect. The DSL shared task (Malmasi et al., 2016) was to identify Arabic dialects in texts in five classes: EGY, GLF, LAV, NOR, and MSA; in utterance/phrase level identification which is more challenging than document dialect identification, since short texts have fewer identifying features. Arabic dialects classification is becoming important due to the increasing use of Arabic dialect in social media, and the importance of identification of the dialect before machine translation takes place, or search and retrieval of data (Lu and Mohamed, 2011). Furthermore, identifying the dialect may improve the Part-Of-Speech tagging: for example, the"
W16-4826,pasha-etal-2014-madamira,0,0.0821366,"Missing"
W16-4826,W14-5904,0,0.0182269,"book of Islam; and MSA is taught in Arab schools, and promoted by Arab civil as well as religious authorities and governments. There are many dialects spoken around the Arab World; Arabic dialectologists have studied hundreds of local variations, but generally agree these cluster into five main regional dialects: Iraqi Dialect (IRQ), Levantine Dialect (LAV), Egyptian Dialect (EGY), North Africa Dialect (NOR), and Gulf Dialect (GLF) which is a subclass of Peninsular Arabic. Studies in Arabic dialectology focus on phonetic variation (Alorifi, 2008; Biadsy et al., 2009; Horesh and Cotter, 2016; Sadat et al., 2014). Horesh and Cotter (Horesh and Cotter, 2016) confirmed that past and current research is focussed on phonetic and phonological variation between Arabic dialects: all examples that they presented are of phoneme variation, and they did not mention any work on text, or corpus-based research, or of lexical or morpho-syntactic or grammar variation. However, Arabic spoken dialect does include local words, phrases, and even local variant morphology and grammar. With the spread of informal writing, for example on social networks and in local-dialect blogs, news and other online sources, Arabs are sta"
W16-4826,J14-1006,0,0.0431755,"Missing"
W16-4826,W15-5411,0,0.595063,"Missing"
W19-5605,dukes-atwell-2012-lamp,1,0.866255,"Missing"
W19-5607,W17-1301,0,0.0334188,"Missing"
W19-5607,P13-2081,0,0.0625135,"Missing"
W19-5607,W14-3601,0,0.0345085,"Missing"
W19-5607,pasha-etal-2014-madamira,0,0.0505754,"Missing"
W19-5607,W14-5904,0,0.0453942,"Missing"
W19-5607,W15-3205,0,0.0479523,"Missing"
W19-5607,J14-1006,0,0.0760828,"Missing"
W94-0103,C92-2099,0,0.0315011,"Missing"
W94-0103,C92-2070,0,0.0665764,"Missing"
W94-0103,J93-2005,0,0.0494189,"Missing"
W94-0103,H90-1055,0,\N,Missing
W94-0103,H92-1022,0,\N,Missing
W94-0103,A92-1021,0,\N,Missing
W97-0602,A97-1007,0,\N,Missing
