2021.emnlp-main.226,From Alignment to Assignment: Frustratingly Simple Unsupervised Entity Alignment,2021,-1,-1,4,0,9117,xin mao,Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,0,"Cross-lingual entity alignment (EA) aims to find the equivalent entities between crosslingual KGs (Knowledge Graphs), which is a crucial step for integrating KGs. Recently, many GNN-based EA methods are proposed and show decent performance improvements on several public datasets. However, existing GNN-based EA methods inevitably inherit poor interpretability and low efficiency from neural networks. Motivated by the isomorphic assumption of GNN-based methods, we successfully transform the cross-lingual EA problem into an assignment problem. Based on this re-definition, we propose a frustratingly Simple but Effective Unsupervised entity alignment method (SEU) without neural networks. Extensive experiments have been conducted to show that our proposed unsupervised approach even beats advanced supervised methods across all public datasets while having high efficiency, interpretability, and stability."
2020.semeval-1.129,{ECNU} at {S}em{E}val-2020 Task 7: Assessing Humor in Edited News Headlines Using {B}i{LSTM} with Attention,2020,-1,-1,3,0,15172,tiantian zhang,Proceedings of the Fourteenth Workshop on Semantic Evaluation,0,"In this paper we describe our system submitted to SemEval 2020 Task 7: {``}Assessing Humor in Edited News Headlines{''}. We participated in all subtasks, in which the main goal is to predict the mean funniness of the edited headline given the original and the edited headline. Our system involves two similar sub-networks, which generate vector representations for the original and edited headlines respectively. And then we do a subtract operation of the outputs from two sub-networks to predict the funniness of the edited headline."
2020.acl-main.299,A Span-based Linearization for Constituent Trees,2020,30,0,3,0,4718,yang wei,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"We propose a novel linearization of a constituent tree, together with a new locally normalized model. For each split point in a sentence, our model computes the normalizer on all spans ending with that split point, and then predicts a tree span from them. Compared with global models, our model is fast and parallelizable. Different from previous local models, our linearization method is tied on the spans directly and considers more local features when performing span prediction, which is more interpretable and effective. Experiments on PTB (95.8 F1) and CTB (92.4 F1) show that our model significantly outperforms existing local models and efficiently achieves competitive results with global models."
P19-1131,Joint Type Inference on Entities and Relations via Graph Convolutional Networks,2019,0,6,6,1,8176,changzhi sun,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"We develop a new paradigm for the task of joint entity relation extraction. It first identifies entity spans, then performs a joint inference on entity types and relation types. To tackle the joint type inference task, we propose a novel graph convolutional network (GCN) running on an entity-relation bipartite graph. By introducing a binary relation classification task, we are able to utilize the structure of entity-relation bipartite graph in a more efficient and interpretable way. Experiments on ACE05 show that our model outperforms existing joint models in entity performance and is competitive with the state-of-the-art in relation performance."
P19-1237,Graph-based Dependency Parsing with Graph Neural Networks,2019,0,7,3,1,9401,tao ji,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"We investigate the problem of efficiently incorporating high-order features into neural graph-based dependency parsing. Instead of explicitly extracting high-order features from intermediate parse trees, we develop a more powerful dependency tree node representation which captures high-order information concisely and efficiently. We use graph neural networks (GNNs) to learn the representations and discuss several new configurations of GNN{'}s updating and aggregation functions. Experiments on PTB show that our parser achieves the best UAS and LAS on PTB (96.0{\%}, 94.3{\%}) among systems without using any external resources."
P19-1514,Scaling up Open Tagging from Tens to Thousands: Comprehension Empowered Attribute Value Extraction from Product Title,2019,0,1,5,0,25857,huimin xu,Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,1,"Supplementing product information by extracting attribute values from title is a crucial task in e-Commerce domain. Previous studies treat each attribute only as an entity type and build one set of NER tags (e.g., BIO) for each of them, leading to a scalability issue which unfits to the large sized attribute system in real world e-Commerce. In this work, we propose a novel approach to support value extraction scaling up to thousands of attributes without losing performance: (1) We propose to regard attribute as a query and adopt only one global set of BIO tags for any attributes to reduce the burden of attribute tag or model explosion; (2) We explicitly model the semantic representations for attribute and title, and develop an attention mechanism to capture the interactive semantic relations in-between to enforce our framework to be attribute comprehensive. We conduct extensive experiments in real-life datasets. The results show that our model not only outperforms existing state-of-the-art NER tagging models, but also is robust and generates promising results for up to 8,906 attributes."
D19-1635,Exploring Human Gender Stereotypes with Word Association Test,2019,0,2,3,0,10190,yupei du,Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP),0,"Word embeddings have been widely used to study gender stereotypes in texts. One key problem regarding existing bias scores is to evaluate their validities: do they really reflect true bias levels? For a small set of words (e.g. occupations), we can rely on human annotations or external data. However, for most words, evaluating the correctness of them is still an open problem. In this work, we utilize word association test, which contains rich types of word connections annotated by human participants, to explore how gender stereotypes spread within our minds. Specifically, we use random walk on word association graph to derive bias scores for a large amount of words. Experiments show that these bias scores correlate well with bias in the real world. More importantly, comparing with word-embedding-based bias scores, it provides a different perspective on gender stereotypes in words."
S18-1035,{ECNU} at {S}em{E}val-2018 Task 1: Emotion Intensity Prediction Using Effective Features and Machine Learning Models,2018,0,1,2,0,25857,huimin xu,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes our submissions to SemEval 2018 task 1. The task is affect intensity prediction in tweets, including five subtasks. We participated in all subtasks of English tweets. We extracted several traditional NLP, sentiment lexicon, emotion lexicon and domain specific features from tweets, adopted supervised machine learning algorithms to perform emotion intensity prediction."
S18-1068,{ECNU} at {S}em{E}val-2018 Task 2: Leverage Traditional {NLP} Features and Neural Networks Methods to Address {T}witter Emoji Prediction Task,2018,0,1,3,0,28805,xingwu lu,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes our submissions to Task 2 in SemEval 2018, i.e., Multilingual Emoji Prediction. We first investigate several traditional Natural Language Processing (NLP) features, and then design several deep learning models. For subtask 1: Emoji Prediction in English, we combine two different methods to represent tweet, i.e., supervised model using traditional features and deep learning model. For subtask 2: Emoji Prediction in Spanish, we only use deep learning model."
S18-1098,{ECNU} at {S}em{E}val-2018 Task 3: Exploration on Irony Detection from Tweets via Machine Learning and Deep Learning Methods,2018,0,0,3,0,28842,zhenghang yin,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"The paper describes our submissions to task 3 in SemEval-2018. There are two subtasks: Subtask A is a binary classification task to determine whether a tweet is ironic, and Subtask B is a fine-grained classification task including four classes. To address them, we explored supervised machine learning method alone and in combination with neural networks."
S18-1165,{ECNU} at {S}em{E}val-2018 Task 10: Evaluating Simple but Effective Features on Machine Learning Methods for Semantic Difference Detection,2018,0,1,2,1,28907,yunxiao zhou,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes the system we submitted to Task 10 (Capturing Discriminative Attributes) in SemEval 2018. Given a triple (word1, word2, attribute), this task is to predict whether it exemplifies a semantic difference or not. We design and investigate several word embedding features, PMI features and WordNet features together with supervised machine learning methods to address this task. Officially released results show that our system ranks above average."
S18-1175,{ECNU} at {S}em{E}val-2018 Task 11: Using Deep Learning Method to Address Machine Comprehension Task,2018,0,1,2,0,28915,yixuan sheng,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper describes the system we submitted to the Task 11 in SemEval 2018, i.e., Machine Comprehension using Commonsense Knowledge. Given a passage and some questions that each have two candidate answers, this task requires the participate system to select out one answer meet the meaning of original text or commonsense knowledge from the candidate answers. For this task, we use a deep learning method to obtain final predict answer by calculating relevance of choices representations and question-aware document representation."
S18-1184,{ECNU} at {S}em{E}val-2018 Task 12: An End-to-End Attention-based Neural Network for the Argument Reasoning Comprehension Task,2018,0,0,2,1,2031,junfeng tian,Proceedings of The 12th International Workshop on Semantic Evaluation,0,"This paper presents our submissions to SemEval 2018 Task 12: the Argument Reasoning Comprehension Task. We investigate an end-to-end attention-based neural network to represent the two lexically close candidate warrants. On the one hand, we extract their different parts as attention vectors to obtain distinguishable representations. On the other hand, we use their surrounds (i.e., claim, reason, debate context) as another attention vectors to get contextual representations, which work as final clues to select the correct warrant. Our model achieves 60.4{\%} accuracy and ranks 3rd among 22 participating systems."
K18-2025,{A}nt{NLP} at {C}o{NLL} 2018 Shared Task: A Graph-Based Parser for {U}niversal {D}ependency Parsing,2018,0,1,5,1,9401,tao ji,Proceedings of the {C}o{NLL} 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"We describe the graph-based dependency parser in our system (AntNLP) submitted to the CoNLL 2018 UD Shared Task. We use bidirectional lstm to get the word representation, then a bi-affine pointer networks to compute scores of candidate dependency edges and the MST algorithm to get the final dependency tree. From the official testing results, our system gets 70.90 LAS F1 score (rank 9/26), 55.92 MLAS (10/26) and 60.91 BLEX (8/26)."
D18-1249,Extracting Entities and Relations with Joint Minimum Risk Training,2018,0,4,3,1,8176,changzhi sun,Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,0,"We investigate the task of joint entity relation extraction. Unlike prior efforts, we propose a new lightweight joint learning paradigm based on minimum risk training (MRT). Specifically, our algorithm optimizes a global loss function which is flexible and effective to explore interactions between the entity model and the relation model. We implement a strong and simple neural network where the MRT is executed. Experiment results on the benchmark ACE05 and NYT datasets show that our model is able to achieve state-of-the-art joint extraction performances."
S17-2028,{ECNU} at {S}em{E}val-2017 Task 1: Leverage Kernel-based Traditional {NLP} features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity,2017,0,25,3,1,2031,junfeng tian,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"To address semantic similarity on multilingual and cross-lingual sentences, we firstly translate other foreign languages into English, and then feed our monolingual English system with various interactive features. Our system is further supported by combining with deep learning semantic similarity and our best run achieves the mean Pearson correlation 73.16{\%} in primary track."
S17-2060,{ECNU} at {S}em{E}val-2017 Task 3: Using Traditional and Deep Learning Methods to Address Community Question Answering Task,2017,0,3,3,1,32290,guoshun wu,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes the systems we submitted to the task 3 (Community Question Answering) in SemEval 2017 which contains three subtasks on English corpora, i.e., subtask A: Question-Comment Similarity, subtask B: Question-Question Similarity, and subtask C: Question-External Comment Similarity. For subtask A, we combined two different methods to represent question-comment pair, i.e., supervised model using traditional features and Convolutional Neural Network. For subtask B, we utilized the information of snippets returned from Search Engine with question subject as query. For subtask C, we ranked the comments by multiplying the probability of the pair related question comment being Good by the reciprocal rank of the related question."
S17-2078,{ECNU} at {S}em{E}val-2017 Task 7: Using Supervised and Unsupervised Methods to Detect and Locate {E}nglish Puns,2017,0,3,2,0,32309,yuhuan xiu,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes our submissions to task 7 in SemEval 2017, i.e., Detection and Interpretation of English Puns. We participated in the first two subtasks, which are to detect and locate English puns respectively. For subtask 1, we presented a supervised system to determine whether or not a sentence contains a pun using similarity features calculated on sense vectors or cluster center vectors. For subtask 2, we established an unsupervised system to locate the pun by scoring each word in the sentence and we assumed that the word with the smallest score is the pun."
S17-2086,{ECNU} at {S}em{E}val-2017 Task 8: Rumour Evaluation Using Effective Features and Supervised Ensemble Models,2017,0,9,2,1,28843,feixiang wang,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes our submissions to task 8 in SemEval 2017, i.e., Determining rumour veracity and support for rumours. Given a rumoured tweet and a lot of reply tweets, the subtask A is to label whether these tweets are support, deny, query or comment, and the subtask B aims to predict the veracity (i.e., true, false, and unverified) with a confidence (in range of 0-1) of the given rumoured tweet. For both subtasks, we adopted supervised machine learning methods, incorporating rich features. Since training data is imbalanced, we specifically designed a two-step classifier to address subtask A ."
S17-2137,{ECNU} at {S}em{E}val-2017 Task 4: Evaluating Effective Features on Machine Learning Methods for {T}witter Message Polarity Classification,2017,0,2,2,1,28907,yunxiao zhou,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper reports our submission to subtask A of task 4 (Sentiment Analysis in Twitter, SAT) in SemEval 2017, i.e., Message Polarity Classification. We investigated several traditional Natural Language Processing (NLP) features, domain specific features and word embedding features together with supervised machine learning methods to address this task. Officially released results showed that our system ranked above average."
S17-2152,{ECNU} at {S}em{E}val-2017 Task 5: An Ensemble of Regression Algorithms with Effective Features for Fine-Grained Sentiment Analysis in Financial Domain,2017,0,11,2,0,32374,mengxiao jiang,Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017),0,"This paper describes our systems submitted to the Fine-Grained Sentiment Analysis on Financial Microblogs and News task (i.e., Task 5) in SemEval-2017. This task includes two subtasks in microblogs and news headline domain respectively. To settle this problem, we extract four types of effective features, including linguistic features, sentiment lexicon features, domain-specific features and word embedding features. Then we employ these features to construct models by using ensemble regression algorithms. Our submissions rank 1st and rank 5th in subtask 1 and subtask 2 respectively."
K17-3025,A Fast and Lightweight System for Multilingual Dependency Parsing,2017,5,1,3,1,9401,tao ji,Proceedings of the {C}o{NLL} 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,0,"We present a multilingual dependency parser with a bidirectional-LSTM (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier. We trained our transition-based projective parser in UD version 2.0 datasets without any additional data. The parser is fast, lightweight and effective on big treebanks. In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33{\%}."
E17-1097,Large-scale Opinion Relation Extraction with Distantly Supervised Neural Network,2017,25,0,3,1,8176,changzhi sun,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"We investigate the task of open domain opinion relation extraction. Different from works on manually labeled corpus, we propose an efficient distantly supervised framework based on pattern matching and neural network classifiers. The patterns are designed to automatically generate training data, and the deep learning model is design to capture various lexical and syntactic features. The result algorithm is fast and scalable on large-scale corpus. We test the system on the Amazon online review dataset. The result shows that our model is able to achieve promising performances without any human annotations."
D17-1134,Multi-task Attention-based Neural Networks for Implicit Discourse Relationship Representation and Identification,2017,0,12,1,1,9119,man lan,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We present a novel multi-task attention based neural network model to address implicit discourse relationship representation and identification through two types of representation learning, an attention based neural network for learning discourse relationship representation with two arguments and a multi-task framework for learning knowledge from annotated and unannotated corpora. The extensive experiments have been performed on two benchmark corpora (i.e., PDTB and CoNLL-2016 datasets). Experimental results show that our proposed model outperforms the state-of-the-art systems on benchmark corpora."
S16-1040,{ECNU} at {S}em{E}val-2016 Task 4: An Empirical Investigation of Traditional {NLP} Features and Word Embedding Features for Sentence-level and Topic-level Sentiment Analysis in {T}witter,2016,14,7,3,1,28907,yunxiao zhou,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,"This paper reports our submissions to Task 4, i.e., Sentiment Analysis in Twitter (SAT), in SemEval 2016, which consists of five subtasks grouped into two levels: (1) sentence level, i.e., message polarity classification (subtask A), and (2) topic level, i.e., tweet classification and quantification according to two-point scale (subtask B and D) or five-point scale (subtask C and E). We participated in all these five subtasks. To address these subtasks, we investigated several traditional Natural Language Processing (NLP) features including sentiment lexicon, linguistic and domain specific features, and word embedding features together with supervised machine learning methods. Officially released results showed that our systems rank above average."
S16-1058,{ECNU} at {S}em{E}val-2016 Task 5: Extracting Effective Features from Relevant Fragments in Sentence for Aspect-Based Sentiment Analysis in Reviews,2016,0,1,3,0,32374,mengxiao jiang,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
S16-1073,{ECNU} at {S}em{E}val 2016 Task 6: Relevant or Not? Supportive or Not? A Two-step Learning System for Automatic Detecting Stance in Tweets,2016,7,11,2,1,8383,zhihua zhang,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
S16-1080,{ECNU} at {S}em{E}val-2016 Task 7: An Enhanced Supervised Learning Method for Lexicon Sentiment Intensity Ranking,2016,5,3,3,1,28843,feixiang wang,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
S16-1094,{ECNU} at {S}em{E}val-2016 Task 1: Leveraging Word Embedding From Macro and Micro Views to Boost Performance for Semantic Textual Similarity,2016,10,6,2,1,2031,junfeng tian,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
S16-1135,{ECNU} at {S}em{E}val-2016 Task 3: Exploring Traditional Method and Deep Learning Method for Question Retrieval and Answer Ranking in Community Question Answering,2016,7,7,2,1,32290,guoshun wu,Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016),0,None
K16-2004,Two End-to-end Shallow Discourse Parsers for {E}nglish and {C}hinese in {C}o{NLL}-2016 Shared Task,2016,0,8,2,1,33132,jianxiang wang,Proceedings of the {C}o{NLL}-16 shared task,0,None
S15-2006,{ECNU}: Leveraging Word Embeddings to Boost Performance for Paraphrase in {T}witter,2015,21,9,2,1,37183,jiang zhao,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes our approaches to paraphrase recognition in Twitter organized as task 1 in Semantic Evaluation 2015. Lots of approaches have been proposed to address the paraphrasing task on conventional texts ( surveyed in (Madnani and Dorr, 2010)). In this work we examined the effectiveness of various linguistic features proposed in traditional paraphrasing task on informal texts, (i.e., Twitter), for example, string based, corpus based, and syntactic features, which served as input of a classification algorithm. Besides, we also proposed novel features based on distributed word representations, which were learned using deep learning paradigms. Results on test dataset show that our proposed features improve the performance by a margin of 1.9% in terms of F1-score and our team ranks third among 10 teams with 38 systems."
S15-2021,{ECNU}: Using Traditional Similarity Measurements and Word Embedding for Semantic Textual Similarity Estimation,2015,20,8,2,1,37183,jiang zhao,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper reports our submissions to semantic textual similarity task, i.e., task 2 in Semantic Evaluation 2015. We built our systems using various traditional features, such as string-based, corpus-based and syntactic similarity metrics, as well as novel similarity measures based on distributed word representations, which were trained using deep learning paradigms. Since the training and test datasets consist of instances collected from various domains, three different strategies of the usage of training datasets were explored: (1) use all available training datasets and build a unified supervised model for all test datasets; (2) select the most similar training dataset and separately construct a individual model for each test set; (3) adopt multi-task learning framework to make full use of available training sets. Results on the test datasets show that using all datasets as training set achieves the best averaged performance and our best system ranks 15 out of 73."
S15-2042,{ECNU}: Using Multiple Sources of {CQA}-based Information for Answers Selection and {YES}/{NO} Response Inference,2015,18,10,3,0,37211,liang yi,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper reports our submissions to community question answering task in SemEval2015, which consists of two subtasks: (1) predict the quality of answers to given question as good, bad, or potentially relevant and (2) identify yes, no or unsure response to a given YES/NO question based on the good answers identified by subtask 1. For both subtasks, we adopted supervised classification method and examined the effects of heterogeneous features generated from community question answering data, such as bag-of-words, string matching, semantic similarity, answerer information, answer-specific features, questionspecific features, etc. Our submitted primary systems ranked the forth and the second for the two subtasks of English data respectively."
S15-2094,{ECNU}: Multi-level Sentiment Analysis on {T}witter Using Traditional Linguistic Features and Word Embedding Features,2015,20,7,3,1,8383,zhihua zhang,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper reports our submission to task 10 (Sentiment Analysis on Tweet, SAT) (Rosenthal et al., 2015) in SemEval 2015 , which contains five subtasks, i.e., contextual polarity disambiguation (subtask A: expressionlevel), message polarity classification (subtask B: message-level), topic-based message polarity classification and detecting trends towards a topic (subtask C and D: topic-level), and determining sentiment strength of twitter terms (subtask E: term-level). For the first four subtasks, we built supervised models using traditional features and word embedding features to perform sentiment polarity classification. For subtask E, we first expanded the training data with the aid of external sentiment lexicons and then built a regression model to estimate the sentiment strength. Despite the simplicity of features, our systems rank above the average."
S15-2125,{ECNU}: Extracting Effective Features from Multiple Sequential Sentences for Target-dependent Sentiment Analysis in Reviews,2015,15,14,2,1,8383,zhihua zhang,Proceedings of the 9th International Workshop on Semantic Evaluation ({S}em{E}val 2015),0,"This paper describes our systems submitted to the target-dependent sentiment polarity classification subtask in aspect based sentiment analysis (ABSA) task (i.e., Task 12) in SemEval 2015. To settle this problem, we extracted several effective features from three sequential sentences, including sentiment lexicon, linguistic and domain specific features. Then we employed these features to construct classifiers using supervised classification algorithm. In laptop domain, our systems ranked 2nd out of 6 constrained submissions and 2nd out of 7 unconstrained submissions. In restaurant domain, the rankings are 5th out of 6 and 2nd out of 8 respectively."
K15-2002,A Refined End-to-End Discourse Parser,2015,10,11,2,1,33132,jianxiang wang,Proceedings of the Nineteenth Conference on Computational Natural Language Learning - Shared Task,0,"The CoNLL-2015 shared task focuses on shallow discourse parsing, which takes a piece of newswire text as input and returns the discourse relations in a PDTB style. In this paper, we describe our discourse parser that participated in the shared task. We use 9 components to construct the whole parser to identify discourse connectives, label arguments and classify the sense of Explicit or Non-Explicit relations in free texts. Compared to previous discourse parser, new components and features are added in our system, which further improves the overall performance of the discourse parser. Our parser ranks the first on two test datasets, i.e., PDTB Section 23 and a blind test dataset."
S14-2041,{ECNU}: A Combination Method and Multiple Features for Aspect Extraction and Sentiment Polarity Classification,2014,14,4,3,0,38965,fangxi zhang,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper reports our submissions to the four subtasks of Aspect Based Sentiment Analysis (ABSA) task (i.e., task 4) in SemEval 2014 including aspect term extraction and aspect sentiment polarity classification (Aspect-level tasks), aspect category detection and aspect category sentiment polarity classification (Categorylevel tasks). For aspect term extraction, we present three methods, i.e., noun phrase (NP) extraction, Named Entity Recognition (NER) and a combination of NP and NER method. For aspect sentiment classification, we extracted several features, i.e., topic features, sentiment lexicon features, and adopted a Maximum Entropy classifier. Our submissions rank above average."
S14-2042,{ECNU}: Expression- and Message-level Sentiment Orientation Classification in {T}witter Using Multiple Effective Features,2014,18,15,2,1,37183,jiang zhao,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"Microblogging websites (such as Twitter, Facebook) are rich sources of data for opinion mining and sentiment analysis. In this paper, we describe our approaches used for sentiment analysis in twitter (task 9) organized in SemEval 2014. This task tries to determine whether the sentiment orientations conveyed by the whole tweets or pieces of tweets are positive, negative or neutral. To solve this problem, we extracted several simple and basic features considering the following aspects: surface text, syntax, sentiment score and twitter characteristic. Then we exploited these features to build a classifier using SVM algorithm. Despite the simplicity of features, our systems rank above the average."
S14-2043,{ECNU}: Leveraging on Ensemble of Heterogeneous Features and Information Enrichment for Cross Level Semantic Similarity Estimation,2014,14,2,2,0.862069,38966,tiantian zhu,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper reports our submissions to the Cross Level Semantic Similarity (CLSS) task in SemEval 2014. We submitted one Random Forest regression system on each cross level text pair, i.e., Paragraph to Sentence (P-S), Sentence to Phrase (SPh), Phrase to Word (Ph-W) and Word to Sense (W-Se). For text pairs on P-S level and S-Ph level, we consider them as sentences and extract heterogeneous types of similarity features, i.e., string features, knowledge based features, corpus based features, syntactic features, machine translation based features, multi-level text features, etc. For text pairs on Ph-W level and W-Se level, due to lack of information, most of these features are not applicable or available. To overcome this problem, we propose several information enrichment methods using WordNet synonym and definition. Our systems rank the 2nd out of 18 teams both on Pearson correlation (official rank) and Spearman rank correlation. Specifically, our systems take the second place on P-S level, S-Ph level and Ph-W level and the 4th place on W-Se level in terms of Pearson correlation."
S14-2044,{ECNU}: One Stone Two Birds: Ensemble of Heterogenous Measures for Semantic Relatedness and Textual Entailment,2014,24,61,3,1,37183,jiang zhao,Proceedings of the 8th International Workshop on Semantic Evaluation ({S}em{E}val 2014),0,"This paper presents our approach to semantic relatedness and textual entailment subtasks organized as task 1 in SemEval 2014. Specifically, we address two questions: (1) Can we solve these two subtasks together? (2) Are features proposed for textual entailment task still effective for semantic relatedness task? To address them, we extracted seven types of features including text difference measures proposed in entailment judgement subtask, as well as common text similarity measures used in both subtasks. Then we exploited the same feature set to solve the both subtasks by considering them as a regression and a classification task respectively and performed a study of influence of different features. We achieved the first and the second rank for relatedness and entailment task respectively."
S13-2021,{ECNUCS}: Recognizing Cross-lingual Textual Entailment Using Multiple Text Similarity and Text Difference Measures,2013,14,6,2,1,37183,jiang zhao,"Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",0,"This paper presents our approach used for cross-lingual textual entailment task (task 8) organized within SemEval 2013. Crosslingual textual entailment (CLTE) tries to detect the entailment relationship between two text fragments in different languages. We solved this problem in three steps. Firstly, we use a off-the-shelf machine translation (MT) tool to convert the two input texts into the same language. Then after performing a text preprocessing,we extract multiple feature types with respect to surface text and grammar. We also propose novel feature types regarding to sentence difference and semantic similarity based on our observations in the preliminary experiments. Finally, we adopt a multiclass SVM algorithm for classification. The results on the cross-lingual data collections providedby SemEval 2013 show that (1) we can build portable and effective systems across languages using MT and multiple effective features; (2) our systems achieve the best results among the participants on two test datasets, i.e., FRA-ENG and DEU-ENG."
P13-1047,Leveraging Synthetic Discourse Data via Multi-task Learning for Implicit Discourse Relation Recognition,2013,29,35,1,1,9119,man lan,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"To overcome the shortage of labeled data for implicit discourse relation recognition, previous works attempted to automatically generate training data by removing explicit discourse connectives from sentences and then built models on these synthetic implicit examples. However, a previous study (Sporleder and Lascarides, 2008) showed that models trained on these synthetic data do not generalize very well to natural (i.e. genuine) implicit discourse data. In this work we revisit this issue and present a multi-task learning based system which can effectively use synthetic data for implicit discourse relation recognition. Results on PDTB data show that under the multi-task learning framework our models with the use of the prediction of explicit discourse connectives as auxiliary learning tasks, can achieve an averaged F1 improvement of 5.86% over baseline models."
P13-1097,Probabilistic Sense Sentiment Similarity through Hidden Emotions,2013,19,6,2,0,12657,mitra mohtarami,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Sentiment Similarity of word pairs reflects the distance between the words regarding their underlying sentiments. This paper aims to infer the sentiment similarity between word pairs with respect to their senses. To achieve this aim, we propose a probabilistic emotionbased approach that is built on a hidden emotional model. The model aims to predict a vector of basic human emotions for each sense of the words. The resultant emotional vectors are then employed to infer the sentiment similarity of word pairs. We apply the proposed approach to address two main NLP tasks, namely, Indirect yes/no Question Answer Pairs inference and Sentiment Orientation prediction. Extensive experiments demonstrate the effectiveness of the proposed approach."
S12-1084,{T}iantianzhu7:System Description of Semantic Textual Similarity ({STS}) in the {S}em{E}val-2012 (Task 6),2012,9,0,2,0.862069,38966,tiantian zhu,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,This paper briefly reports our submissions to the Semantic Textual Similarity (STS) task in the SemEval 2012 (Task 6). We first use knowledge-based methods to compute word semantic similarity as well as Word Sense Disambiguation (WSD). We also consider word order similarity from the structure of the sentence. Finally we sum up several aspects of similarity with different coefficients and get the sentence similarity score.
W10-4326,The Effects of Discourse Connectives Prediction on Implicit Discourse Relation Recognition,2010,19,8,2,0,45087,zhi zhou,Proceedings of the {SIGDIAL} 2010 Conference,0,"Implicit discourse relation recognition is difficult due to the absence of explicit discourse connectives between arbitrary spans of text. In this paper, we use language models to predict the discourse connectives between the arguments pair. We present two methods to apply the predicted connectives to implicit discourse relation recognition. One is to use the sense frequency of the specific connectives in a supervised framework. The other is to directly use the presence of the predicted connectives in an unsupervised way. Results on PDTB2 show that using language model to predict the connectives can achieve comparable F-scores to the previous state-of-art method. Our method is quite promising in that not only it has a very small number of features but also once a language model based on other resources is trained it can be more adaptive to other languages and domains."
S10-1050,{ECNU}: Effective Semantic Relations Classification without Complicated Features or Multiple External Corpora,2010,8,8,2,0,13047,yuan chen,Proceedings of the 5th International Workshop on Semantic Evaluation,0,This paper describes our approach to the automatic identification of semantic relations between nominals in English sentences. The basic idea of our strategy is to develop machine-learning classifiers which: (1) make use of class-independent features and classifier; (2) make use of a simple and effective feature set without high computational cost; (3) make no use of external annotated or unannotated corpus at all. At SemEval 2010 Task 8 our system achieved an F-measure of 75.43% and a accuracy of 70.22%.
C10-2172,Predicting Discourse Connectives for Implicit Discourse Relation Recognition,2010,18,78,4,0,46509,zhimin zhou,Coling 2010: Posters,0,Existing works indicate that the absence of explicit discourse connectives makes it difficult to recognize implicit discourse relations. In this paper we attempt to overcome this difficulty for implicit relation recognition by automatically inserting discourse connectives between arguments with the use of a language model. Then we propose two algorithms to leverage the information of these predicted connectives. One is to use these predicted implicit connectives as additional features in a supervised model. The other is to perform implicit relation recognition based only on these predicted connectives. Results on Penn Discourse Treebank 2.0 show that predicted discourse connectives help implicit relation recognition and the first algorithm can achieve an absolute average f-score improvement of 3% over a state of the art baseline system.
