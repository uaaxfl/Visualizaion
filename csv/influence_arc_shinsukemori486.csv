1995.iwpt-1.22,H91-1060,0,0.0833004,"Missing"
2014.amta-researchers.18,W08-0336,0,0.177985,"ey reported the improvement in word segmentation, and did not report its effect on the patent MT. Their work can be seen an application of a semisupervised learning method (Sun and Xu, 2011) to the domain adaptation. Such an approach is appropriate for the patent domain where a huge number of patent documents are publicly available. We extend their domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the do"
2014.amta-researchers.18,P08-1115,0,0.0286095,"omain adaptation. Such an approach is appropriate for the patent domain where a huge number of patent documents are publicly available. We extend their domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the domain adaptation. Machine transliteration is an important problem for translating names and other imported words (Knight and Graehl, 1998). Conventional methods need to prepare parallel transliterati"
2014.amta-researchers.18,J04-1004,0,0.0347997,"ses B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and Xu (2011). Our baseline features follow the work of Japanese word segmentation by Neubig et al. (2011): label bigrams, character n-grams (n=1, 2), and character type n-grams (n=1, 2, 3). We use the n-gram features within [i-2, i+2] for classifying the word at the position i. The character types are kanji, katakana, hiragana, digits, roman characters, and others. 4.2 Conventional Method: Word Segmentation Adaptation using Accessor Variety Sun and Xu (2011) and Guo et al. (2012) used Accessor Variety (AV) (Feng et al., 2004) derived from unlabeled corpora as word segmentation features. AV is a word extraction criterion from un-segmented corpora, focusing on the number of distinct characters appearing around a string. The AV of a string xn is defined as AV (xn ) = min {AVL (xn ), AVR (xn )} , where AVL (xn ) is the left AV (the number of distinct predecessor characters) and AVR (xn ) is the right AV (the number of distinct successor characters). The AV-based word extraction is based on an intuitive assumption; a word appears in many different context so that there is a large variation of its accessor characters. I"
2014.amta-researchers.18,N04-1035,0,0.0159661,"© The Authors 234 Finalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), while most previous studies did not deal with the second problem. Since the lexical translation also affects the reordering based on a lexicalized reordering model and an n-gram language model, considering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentat"
2014.amta-researchers.18,P06-1085,0,0.0412818,"s Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and X"
2014.amta-researchers.18,I13-1147,1,0.845609,"translation experiments. 2 Related Work The patent MT between Japanese and English has been studied actively on shared tasks in NTCIR (Fujii et al., 2008, 2010; Goto et al., 2011, 2013). Recent important achievements in these studies are on the reordering problem especially in English-to-Japanese direction. Isozaki et al. (2010) proposed a very simple but effective rule-based syntactic pre-ordering method called Head Finalization. It is very effective for the long distance reordering. On the other hand, the Japanese-to-English direction is more difficult due to the lack of such simple rules. Hoshino et al. (2013) proposed an effective rule-based syntactic pre-ordering based on predicate-argument structures. Sudoh et al. (2013b) proposed a different approach called postordering for the Japanese-to-English patent MT, and achieved high translation performance by an efficient syntax-based translation. Our system uses the latter approach based on English syntax rather than the former one based on Japanese syntax. This is because our word segmentation adaptation can be applied directly to it without the Japanese parser adaptation as described earlier. General-purpose Japanese parsers do not work well in the"
2014.amta-researchers.18,W10-1736,1,0.907546,"erence from general-purpose MT. This work focuses on statistical MT (SMT) for patents, from Japanese to English. It is more difficult than English-to-Japanese in: 1) long distance reordering, and 2) word segmentation and lexical translation of domain-specific terms. The first problem is due to large syntactic differences between Japanese and English. Although the reordering in the English-to-Japanese direction can be solved effectively by very simple heuristics called Head Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 234 Finalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), wh"
2014.amta-researchers.18,P06-2056,0,0.0397128,"Missing"
2014.amta-researchers.18,W99-0702,0,0.0703583,"ings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a w"
2014.amta-researchers.18,W04-3250,0,0.0288226,"and the large-scale unlabeled patent corpus with the BE and PD features • KyTea, MeCab, and JUMAN10 : publicly available Japanese morphological analyzers We also compared the results by the post-ordering with those by standard SAMT and PBMT. The search space parameters of the standard SAMT were set to the same value as the HFE-toEnglish SAMT, to compare the performance with similar computation time11 . 5.2.3 Results and Discussion Table 4 shows the translation performance in BLEU and TER (Snover et al., 2006) with the results of statistical significance tests (p=0.05) by bootstrap resampling (Koehn, 2004), in which our overall system resulted in the best. The table also shows the results of intermediate Japanese-to-HFE translation. The advantage of our system can be attributed to three techniques included in the system: domain adaption of word segmentation, katakana unknown word transliteration, and post-ordering. 9 It exceeded the maximum sentence length in the development and test sets. 10 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN 11 Actually the post-ordering needs the time for the first monotone PBMT but it ran very fast and did not affect so much (Sudoh et al., 2013b). Al-Onaizan"
2014.amta-researchers.18,P11-2093,1,0.789822,"e monolingual corpora. Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ f"
2014.amta-researchers.18,P03-1021,0,0.0420166,"implemented with Moses-chart and trained using the HFE sentences and the corresponding English parse trees. Its reordering parameter max-chart-span was set to 200 to allow arbitrary distance reordering for accurate Japanse-toEnglish translation9 . The search space parameter cube-pruning-pop-limit was set to 32 for efficiency, according to Sudoh et al. (2013b). Their language models were word 6-gram models trained using a large-scale English patent corpus with more than 300 million sentences. Model weights were optimized in BLEU (Papineni et al., 2002) using Minimum Error Rate Training (MERT) (Och, 2003). We chose the best weights among ten individual runs of MERT. The katakana transliteration was implemented as a Moses-based monotone PBMT in the character level, trained using transliteration pairs mined from the Japanese-English phrase table entries whose Japanese part consisted of katakana only. Its character-level language model was character 9-gram models trained using the large-scale English patent corpus which is used for the word-level language models described above. It was used to replace katakana words remained in the intermediate results in HFE with their transliteration results. 5"
2014.amta-researchers.18,P02-1040,0,0.0899612,"strain adjacent phrase translations. The HFE-to-English SAMT was implemented with Moses-chart and trained using the HFE sentences and the corresponding English parse trees. Its reordering parameter max-chart-span was set to 200 to allow arbitrary distance reordering for accurate Japanse-toEnglish translation9 . The search space parameter cube-pruning-pop-limit was set to 32 for efficiency, according to Sudoh et al. (2013b). Their language models were word 6-gram models trained using a large-scale English patent corpus with more than 300 million sentences. Model weights were optimized in BLEU (Papineni et al., 2002) using Minimum Error Rate Training (MERT) (Och, 2003). We chose the best weights among ten individual runs of MERT. The katakana transliteration was implemented as a Moses-based monotone PBMT in the character level, trained using transliteration pairs mined from the Japanese-English phrase table entries whose Japanese part consisted of katakana only. Its character-level language model was character 9-gram models trained using the large-scale English patent corpus which is used for the word-level language models described above. It was used to replace katakana words remained in the intermediate"
2014.amta-researchers.18,C04-1081,0,0.0601299,"al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and Xu (2011). Our baseline features follow the work of Japanese word segmentation by Neubig et al. (2011): label bigrams, character n-grams (n=1, 2), and character type n-grams (n=1, 2, 3). We use the n-gram features within [i-2, i+2] for classifying the word at the position i. The character types are kanji, katakana, hiragana, digits, roman characters, and others. 4.2 Conventional Method: Word Seg"
2014.amta-researchers.18,P12-1049,0,0.166158,"nsidering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentation, using effective features derived from a large-scale patent corpus. We also incorporate machine transliteration for the unknown Japanese words written in katakana (Japanese phonograms), bootstrapped from the parallel corpus (Sajjad et al., 2012; Sudoh et al., 2013a). Our SMT system integrates these techniques with a post-ordering framework (Sudoh et al., 2013b), which divides the SMT problem explicitly into two sub-problems of the lexical translation and the reordering. In the post-ordering framework, the lexical translation precedes the reordering, different from pre-ordering in which the reordering precedes the lexical translation (Xia and McCord, 2004; Isozaki et al., 2010). An advantage of the post-ordering is that it is easy to integrate the domain-adapted word segmentation and the unknown word transliteration in its lexical tr"
2014.amta-researchers.18,2006.amta-papers.25,0,0.0160653,"tation experiments above • Proposed: the patent-adapted segmenter using the labeled general-domain corpus and the large-scale unlabeled patent corpus with the BE and PD features • KyTea, MeCab, and JUMAN10 : publicly available Japanese morphological analyzers We also compared the results by the post-ordering with those by standard SAMT and PBMT. The search space parameters of the standard SAMT were set to the same value as the HFE-toEnglish SAMT, to compare the performance with similar computation time11 . 5.2.3 Results and Discussion Table 4 shows the translation performance in BLEU and TER (Snover et al., 2006) with the results of statistical significance tests (p=0.05) by bootstrap resampling (Koehn, 2004), in which our overall system resulted in the best. The table also shows the results of intermediate Japanese-to-HFE translation. The advantage of our system can be attributed to three techniques included in the system: domain adaption of word segmentation, katakana unknown word transliteration, and post-ordering. 9 It exceeded the maximum sentence length in the development and test sets. 10 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN 11 Actually the post-ordering needs the time for the firs"
2014.amta-researchers.18,D13-1021,1,0.223791,"ms is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentation, using effective features derived from a large-scale patent corpus. We also incorporate machine transliteration for the unknown Japanese words written in katakana (Japanese phonograms), bootstrapped from the parallel corpus (Sajjad et al., 2012; Sudoh et al., 2013a). Our SMT system integrates these techniques with a post-ordering framework (Sudoh et al., 2013b), which divides the SMT problem explicitly into two sub-problems of the lexical translation and the reordering. In the post-ordering framework, the lexical translation precedes the reordering, different from pre-ordering in which the reordering precedes the lexical translation (Xia and McCord, 2004; Isozaki et al., 2010). An advantage of the post-ordering is that it is easy to integrate the domain-adapted word segmentation and the unknown word transliteration in its lexical translation step and t"
2014.amta-researchers.18,D11-1090,0,0.0334295,"Missing"
2014.amta-researchers.18,I05-3027,0,0.0216655,"are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In this work we employ four classes B, M, E (beginning/middle/end of a word), and S (single-character word)2 , as Sun and Xu (2011). Our baseline features follow the work of Japanese word segmentation by Neubig et al. (2011): label bigrams, character n-grams (n=1, 2), and character type n-grams (n=1, 2, 3). We use the n-gram features within [i-2, i+2] for classifying the word at the position i. The character types are kanji, katakana, hiragana, digits, roman characters, and others. 4.2 Conventional Method: Word Segmentation Adaptation"
2014.amta-researchers.18,C08-1113,1,0.738883,"are trained using the monolingual corpora. Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 237 4 Domain Adaptation of Japanese Word Segmentation for Patents We aim to improve the Japanese-to-English translation performance further by the word segmentation adaptation for patent-specific words and technical terms. We use the large-scale monolingual Japanese patent corpora for the domain adaptation, by the semi-supervised approach as Sun and Xu (2011) and Guo et al. (2012). There are also active learning-based supervised domain adaptation (Tsuboi et al., 2008; Neubig et al., 2011) and unsupervised word segmentation (Kempe, 1999; Kubota Ando and Lee, 2003; Goldwater et al., 2006, and many others) approaches, but the semi-supervised approach is expected to be effective; the active learning method is not easy to utilize for such large-scale corpora and the unsupervised method is not so accurate as existing supervised word segmenters. 4.1 Baseline Word Segmentation based on Conditional Random Fields We use a character-based word segmenter based on CRFs (Peng et al., 2004; Tseng et al., 2005). It solves a character-based sequential labeling problem. In"
2014.amta-researchers.18,2007.mtsummit-papers.63,0,0.0507407,"s an extended transliteration mining method for Japanese compound words (Sudoh et al., 2013a). 3 System Overview Our Japanese-to-English patent SMT is based on large-scale language resources in the patent domain. This work uses NTCIR PatentMT dataset (Goto et al., 2011, 2013) including a Japanese-English parallel corpus of 3.2 million sentences and monolingual corpora of more than 300 million sentences of Japanese and English. The parallel corpus was developed by an automatic sentence alignment over patent documents in the Japan Patent Office and the United States Patent and Trademark Office (Utiyama and Isahara, 2007). The workflow of our SMT system is illustrated in Figure 1. The translation is divided into the following four processes. 1. Japanese word segmentation using a patent-adapted word segmentation model 2. Translation into an intermediate language, Head Final English (HFE), by a monotone phrase-based SMT 3. Transliteration of untranslated Japanese katakana words (i.e. unknown words in the previous process) into English words, by a monotone phrase-based SMT in the character level 4. Post-ordering into English by a syntax-based SMT Here, HFE is Japanese-ordered English, which was proposed by Isozak"
2014.amta-researchers.18,C04-1073,0,0.0524449,"arge-scale patent corpus. We also incorporate machine transliteration for the unknown Japanese words written in katakana (Japanese phonograms), bootstrapped from the parallel corpus (Sajjad et al., 2012; Sudoh et al., 2013a). Our SMT system integrates these techniques with a post-ordering framework (Sudoh et al., 2013b), which divides the SMT problem explicitly into two sub-problems of the lexical translation and the reordering. In the post-ordering framework, the lexical translation precedes the reordering, different from pre-ordering in which the reordering precedes the lexical translation (Xia and McCord, 2004; Isozaki et al., 2010). An advantage of the post-ordering is that it is easy to integrate the domain-adapted word segmentation and the unknown word transliteration in its lexical translation step and that the reordering can use the improved lexical translation results. If we are to do the same thing in the pre-ordering, we need domain adaptation of its Japanese syntactic parser in addition to the word segmenter, and have to integrate the transliteration process with the SMT decoder as Durrani et al. (2014). Our system shows better translation accuracy in BLEU and TER than baseline methods in"
2014.amta-researchers.18,C08-1128,0,0.022744,"ir domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the domain adaptation. Machine transliteration is an important problem for translating names and other imported words (Knight and Graehl, 1998). Conventional methods need to prepare parallel transliteration pairs for training. Sajjad et al. (2012) proposed an unsupervised transliteration mining from standard parallel corpora for bootstrapping machin"
2014.amta-researchers.18,P02-1039,0,0.0604915,"Researchers Vancouver, BC © The Authors 234 Finalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), while most previous studies did not deal with the second problem. Since the lexical translation also affects the reordering based on a lexicalized reordering model and an n-gram language model, considering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method f"
2014.amta-researchers.18,W08-0335,0,0.0231886,"an approach is appropriate for the patent domain where a huge number of patent documents are publicly available. We extend their domain adaptation by more effective and easy-to-use features, and also incorporate additional Japanese-oriented features to improve the Japanese word segmentation in the patent domain. With respect to the relation between word segmentation and SMT, Chang et al. (2008) reported consistency and granularity of word segmentation is important in Chinese-to-English MT and modified their Chinese word segmenter to optimize the translation performance. Dyer et al. (2008) and Zhang et al. (2008) used multiple word segmentation results to overcome the problem of different word segmentation standards. Xu et al. (2008) optimized Chinese word segmentation for Chinese-to-English SMT using an extended Bayesian word segmentation method with bilingual correspondence. These studies aim to optimize word segmentation using bilingual correspondence and are different from the domain adaptation. Machine transliteration is an important problem for translating names and other imported words (Knight and Graehl, 1998). Conventional methods need to prepare parallel transliteration pairs for training. S"
2014.amta-researchers.18,Y06-1012,0,0.0222236,"proportional to the corpus size in general. Previous studies use several frequency classes with corresponding threshold values tuned according to the corpus, but it is not straightforward to determine appropriate classes and threshold values. Sun and Xu (2011) used the following features based on the left and right AVs of character n-grams for classifying xi , which imply word boundaries around xi , as illustrated in Figure 4. • Left AV of n-gram starting from xi : AVL (xi , ..., xi+n−1 ) 2 Guo et al. (2012) used six classes including B2, B3 (second and third character in a word) proposed by Zhao et al. (2006) for Chinese word segmentation. This paper uses the four classes, because the six classes did not improve the word segmentation accuracy in our pilot test. Al-Onaizan & Simard (Eds.) Proceedings of AMTA 2014, vol. 1: MT Researchers Vancouver, BC © The Authors 238 と前記複数の の前後方向で と前記ノード 直前に、その と前後で交差 predecessors: と: 3 の: 1 直: 1 Left AV of 前: 3 Right AV of 前: 3 Left BE of 前: 3 3 log 5 5 successors: 記: 2 後: 2 に: 1 2⇥ 1 1 log = 1.057 5 5 Right BE of 前: 2⇥ 2 3 log 5 5 1 1 log = 1.308 5 5 Figure 3: Example of accessor variety (AV) and branching entropy (BE) for a character “前”. character to be classi"
2014.amta-researchers.18,W06-3119,0,0.01628,"nalization (Isozaki et al., 2010), the reordering in Japanese-to-English is not so straightforward. The second problem results from the Japanese orthography in which there are no explicit word boundaries. General-purpose word segmenters often fail to segment the domain-specific words and those words are translated incorrectly or remain untranslated. Some domain-specific words cannot be translated as unknown words even if they are segmented correctly, due to limited SMT training data. The first problem has been addressed by a syntax-based approach (Yamada and Knight, 2002; Galley et al., 2004; Zollmann and Venugopal, 2006), while most previous studies did not deal with the second problem. Since the lexical translation also affects the reordering based on a lexicalized reordering model and an n-gram language model, considering both problems is important for an overall SMT system. The goal of this work is to improve the Japanese-to-English patent SMT by tackling both problems at the same time. The domain-specific words have important roles in the patents and should be translated carefully for meaningful translations. We propose a novel domain adaptation method for the word segmentation, using effective features d"
2014.amta-researchers.18,E14-4029,0,\N,Missing
2014.amta-researchers.18,J98-4003,0,\N,Missing
2020.lrec-1.251,P18-2041,0,0.0279953,"n Section 6., we report the results of the experiment that we conducted using our corpus; and after presenting an envisaged application of the corpus in Section 7., we conclude the paper in Section 8.. 2. Related Work The legal domain is a recent target for NLP. However, there is a limited number of studies on the application of NLP to contracts. In this section, we introduce existing work on NLP for legal documents including contracts. 2.1. Recognition of Rights and Obligations There have been several attempts at recognizing rights and obligations (Glaser et al., 2018; O’ Neill et al., 2017; Chalkidis et al., 2018). However, there are several differences between our research and these studies. First of all, we specify an annotation standard to build a corpus. Second, the existing approaches are based on sentence classiﬁcation, whereas our approach is based on the extraction of spans that consist of word sequences. Third, we also build a 2045 corpus so that we can associate relationships among spans, such as that between parties and rights. Title 2.2. Information Extraction from Contracts This Agreement is made as of the fifth day of November, 2019, between ABC Corporation, a corporation organized and ex"
2020.lrec-1.251,L18-1713,0,0.0433324,"Missing"
2020.lrec-1.251,L16-1378,0,0.0667404,"Missing"
2020.lrec-1.251,N16-1030,0,0.037902,"low. 6.1. Extraction of Spans The ﬁrst step is the extraction of spans, which correspond to parties, rights, obligations, conditions, and exceptions. As illustrated in Figure 13, given the contract text input, the system performs word segmentation and converts words to the word embedding. It also removes stop words and low-frequency words, and normalizes numbers. Then, we train sequences of combinations between a word and a BIO tag (Ramshaw and Marcus, 1995) concerning the labels of parties, rights, obligations, conditions, and exceptions (see Table 4.1.) using BiLSTM-CRF (Huang et al., 2015; Lample et al., 2016), where the dimension of the hidden layers is 256 and the dimension of the input embedding vector is 128. From the dataset, we used 32 contracts for training and 14 contracts for testing. 6.2. Association of Parties with Rights and Obligations The second step is the association of parties with rights and obligations, which is illustrated in Figure 14. The system determines which parties with rights and obligations are associated from extracted spans in the prior step. Let Np ∈ N denote the number of parties, Nr ∈ N denote the number of rights, and No ∈ N denote the number of obligations. The a"
2020.lrec-1.251,L18-1177,0,0.0152464,"as follows: Operative part Article 1 (Definitions) For purposes of this Agreement, including Exhibit A, the following terms shall have the following meanings: ??? Closing IN WITNESS WHEREOF, the parties have caused this Agreement to be executed by their duly authorized representatives as of the date first above written. 2.3. Building a Corpus of Legal Documents The main purpose of our study is to build a corpus. Therefore, the studies concerning annotation for legal documents, which we discuss in this section, are related to ours. There have been several studies on annotating legal text. In (Nazarenko et al., 2018), legal documents were annotated as XML compliant documents using LegalRuleML for the purpose of semantic search. This study is related to our research because its annotation included obligations, permissions, prohibitions, and rights, and the annotation target was legal documents. In (Kr´ızˇ et al., 2016; Kr´ızˇ and Hladk´a, 2018), the Czech Legal Text Treebank was built, which included annotations of morphologically and syntactically annotated sentences for documents from the Collection of Laws of the Czech Republic. In the later paper, the layer of semantic relation was introduced and the r"
2020.lrec-1.251,W95-0107,0,0.0960483,"hrough these steps, we achieve the recognition of which parties have what rights and obligations are given in what cases is achieved. We explain the three steps below. 6.1. Extraction of Spans The ﬁrst step is the extraction of spans, which correspond to parties, rights, obligations, conditions, and exceptions. As illustrated in Figure 13, given the contract text input, the system performs word segmentation and converts words to the word embedding. It also removes stop words and low-frequency words, and normalizes numbers. Then, we train sequences of combinations between a word and a BIO tag (Ramshaw and Marcus, 1995) concerning the labels of parties, rights, obligations, conditions, and exceptions (see Table 4.1.) using BiLSTM-CRF (Huang et al., 2015; Lample et al., 2016), where the dimension of the hidden layers is 256 and the dimension of the input embedding vector is 128. From the dataset, we used 32 contracts for training and 14 contracts for testing. 6.2. Association of Parties with Rights and Obligations The second step is the association of parties with rights and obligations, which is illustrated in Figure 14. The system determines which parties with rights and obligations are associated from extr"
2020.lrec-1.527,K19-1041,0,0.0182672,"ical usage of our dataset, where the pairs of a node in the flow graph 4275 Figure 1: An overview of our annotation. Concept tag F T D Q Ac Af Sf St Total Meaning Food Tool Duration Quantity Action by the chef Action by foods State of foods State of tools – Frequency 12.37 3.59 0.73 0.74 13.21 2.67 3.03 0.31 36.65 Table 1: Recipe named entity (r-NE) tags and frequencies per recipe in our r-FG-BB dataset. and bounding boxes help a model understand which region they have to pay attention to at decoding a sentence. One may leverage the pairs for multimodal state tracking (Yagcioglu et al., 2018; Amac et al., 2019) by tracing nodes via arcs in the flow graphs. 2 Recipe Flow Graph Corpus The language part of our r-FG-BB dataset is compatible with the r-FG corpus (Mori et al., 2014). The r-FG corpus consists of cooking recipe texts (or simply “recipes” hereafter) annotated with flow graphs connecting important terms in the texts. Our r-FG-BB dataset is an extension connecting some of the important terms to bounding boxes in the image attached to each step in the text. In this section, we explain cooking recipe texts and flow graphs of the r-FG corpus. 2.1 Cooking Recipe Text A recipe describes instruction"
2020.lrec-1.527,P19-1606,0,0.0202916,"This attention mechanism encourages models to know which objects and regions they have to pay attention to when decoding words, and it helps them to generate visually grounded captions. Our dataset provides researchers with pairs of an r-NE and bounding boxes, which leads a model to decode visually grounded words correctly. Moreover, we would like to emphasize that the text part is not a general text but a procedural text. Procedural text generation from an image sequence is a prominent area because it requires a model to consider the context and the output coherency (Nishimura et al., 2019; Chandu et al., 2019). Thus these studies focused on generating grounded captions: incorporating a structure into the model implicitly (Chandu et al., 2019) and preferentially decoding important terms (Nishimura et al., 2019). Our dataset accelerates this research because pairs of an r-NE and bounding boxes help a model output these terms, considering the entire workflow using the flow graph. 6.2 QA dataset, which requires a model to understand not only flow graphs but also bounding boxes. For example, given an image showing mixing ingredients in a bowl, the question is, “What ingredients are used in it?”. To answ"
2020.lrec-1.527,N19-1423,0,0.0240726,"Missing"
2020.lrec-1.527,D16-1044,0,0.0468733,"texts. Visual grounding is one of the solutions to help computers to understand which objects are aligned with textual descriptions. In the previous studies, they targetted the pair of general texts and visual observations. MSCOCO (Lin et al., 2014), Flickr30k (Plummer et al., 2015), and YouTube-BoundingBox (Real et al., 2017) are typical datasets for such tasks. They reported that annotating bounding boxes with a textual description helps computers to know which objects they have to pay attention to for image captioning (Xu et al., 2015; Cornia et al., 2019), visual question answering (VQA) (Fukui et al., 2016), and some other visual grounding tasks (Huang et al., 2017; Bojanowski et al., 2015; Zhang and Lu, 2018). Compared with such general visual grounding tasks, a dataset with procedural texts is differentiated by an additional goal of understanding the context information, i.e., a model should consider the entire workflow of a procedural text. We call this task contextual visual grounding. In this background, this paper focuses on the domain of cooking recipes and provides a new dataset that has visual grounding annotation of contextual information represented in recipe flow graph (r-FG) (Mori e"
2020.lrec-1.527,L16-1389,1,0.901283,"Missing"
2020.lrec-1.527,D15-1114,0,0.0235546,"experiments showed that the proposed dataset enables us to estimate contextual information described in recipe flow graphs from an image sequence. Keywords: Procedural Text, Bounding Box, Flow Graph, Visual Grounding 1 Introduction Procedural texts are suitable for the target of natural language understanding (NLU) because they are goal-oriented descriptions and we can almost define the understanding of their goals. Some studies have proposed the framework of understanding procedural texts with graphs, which can represent the entire workflow (Mori et al., 2014; Jermsurawong and Habash, 2014; Kiddon et al., 2015). These frameworks would be helpful for real-world systems, such as smart kitchen (Hashimoto et al., 2008) and cooking robot (Bollini et al., 2013), to understand the context of these workflows and execute next actions. Therefore, it is essential to ground visual observations (images or videos) with procedural texts. Visual grounding is one of the solutions to help computers to understand which objects are aligned with textual descriptions. In the previous studies, they targetted the pair of general texts and visual observations. MSCOCO (Lin et al., 2014), Flickr30k (Plummer et al., 2015), and"
2020.lrec-1.527,N18-1144,0,0.0270219,"ple, given an image showing mixing ingredients in a bowl, the question is, “What ingredients are used in it?”. To answer this question correctly, the model must understand the flow of all the ingredients and their visual locations. Multimodal State Tracking State tracking, which detects changes of an object and its identicality in a text, is an essential problem for NLU. Recently, procedural texts are becoming the target for NLU researchers because their understanding requires a model to anticipate the implicit causal effects of actions on entities (Bosselut et al., 2018; Tandon et al., 2018; Mishra et al., 2018; Yagcioglu et al., 2018). Some researchers tried to build a dataset for procedural text understanding (Tandon et al., 2018) for the scientific domain, and other researchers expand them to multimodal version (Yagcioglu et al., 2018) for the cooking area. Some researcher has proposed a dataset for the understanding of procedural texts using a “grid,” which represents changes of an object state using a table format (Tandon et al., 2018; Mishra et al., 2018). Our dataset provides a flow graph of a procedural text, which represents an entire workflow as a rooted DAG, and bounding boxes in an image"
2020.lrec-1.527,mori-etal-2014-flow,1,0.654944,"Missing"
2020.lrec-1.527,P11-2093,1,0.818397,"Missing"
2020.lrec-1.527,W19-8650,1,0.834349,"5; Cornia et al., 2019). This attention mechanism encourages models to know which objects and regions they have to pay attention to when decoding words, and it helps them to generate visually grounded captions. Our dataset provides researchers with pairs of an r-NE and bounding boxes, which leads a model to decode visually grounded words correctly. Moreover, we would like to emphasize that the text part is not a general text but a procedural text. Procedural text generation from an image sequence is a prominent area because it requires a model to consider the context and the output coherency (Nishimura et al., 2019; Chandu et al., 2019). Thus these studies focused on generating grounded captions: incorporating a structure into the model implicitly (Chandu et al., 2019) and preferentially decoding important terms (Nishimura et al., 2019). Our dataset accelerates this research because pairs of an r-NE and bounding boxes help a model output these terms, considering the entire workflow using the flow graph. 6.2 QA dataset, which requires a model to understand not only flow graphs but also bounding boxes. For example, given an image showing mixing ingredients in a bowl, the question is, “What ingredients are"
2020.lrec-1.527,P16-1162,0,0.0229214,"Missing"
2020.lrec-1.527,D18-1006,0,0.0164194,"nding boxes. For example, given an image showing mixing ingredients in a bowl, the question is, “What ingredients are used in it?”. To answer this question correctly, the model must understand the flow of all the ingredients and their visual locations. Multimodal State Tracking State tracking, which detects changes of an object and its identicality in a text, is an essential problem for NLU. Recently, procedural texts are becoming the target for NLU researchers because their understanding requires a model to anticipate the implicit causal effects of actions on entities (Bosselut et al., 2018; Tandon et al., 2018; Mishra et al., 2018; Yagcioglu et al., 2018). Some researchers tried to build a dataset for procedural text understanding (Tandon et al., 2018) for the scientific domain, and other researchers expand them to multimodal version (Yagcioglu et al., 2018) for the cooking area. Some researcher has proposed a dataset for the understanding of procedural texts using a “grid,” which represents changes of an object state using a table format (Tandon et al., 2018; Mishra et al., 2018). Our dataset provides a flow graph of a procedural text, which represents an entire workflow as a rooted DAG, and bound"
2020.lrec-1.527,D18-1166,0,0.0605904,"tion generation is a typical usage of our dataset, where the pairs of a node in the flow graph 4275 Figure 1: An overview of our annotation. Concept tag F T D Q Ac Af Sf St Total Meaning Food Tool Duration Quantity Action by the chef Action by foods State of foods State of tools – Frequency 12.37 3.59 0.73 0.74 13.21 2.67 3.03 0.31 36.65 Table 1: Recipe named entity (r-NE) tags and frequencies per recipe in our r-FG-BB dataset. and bounding boxes help a model understand which region they have to pay attention to at decoding a sentence. One may leverage the pairs for multimodal state tracking (Yagcioglu et al., 2018; Amac et al., 2019) by tracing nodes via arcs in the flow graphs. 2 Recipe Flow Graph Corpus The language part of our r-FG-BB dataset is compatible with the r-FG corpus (Mori et al., 2014). The r-FG corpus consists of cooking recipe texts (or simply “recipes” hereafter) annotated with flow graphs connecting important terms in the texts. Our r-FG-BB dataset is an extension connecting some of the important terms to bounding boxes in the image attached to each step in the text. In this section, we explain cooking recipe texts and flow graphs of the r-FG corpus. 2.1 Cooking Recipe Text A recipe d"
2020.lrec-1.530,L18-1393,1,0.851332,"et al., 2016) by collecting the commented shogi records of Meijin-sen and Jun’i-sen tournament. The game record is a sequence of game states from the initial state to the end of the game. Each comment is mapped to one of the states in the sequence. We also defined shogi named entities (s-NEs) and annotated commentaries. We built an automatic named entity recognition (NER) tool of s-NEs by using the annotated corpus, and the experimental result showed that we could obtain high-quality NER by using our corpus. We also augmented the SGC with modality expressions and event factuality annotation (Matsuyoshi et al., 2018). These labels are annotated by using natural language information. The commentaries are tied up to each state, and we usually treat the pairs of comments and states as if they are correctly mapped. However, the commentaries are sometimes about the past or future states of the game, or outside of the current game. For an accurate evaluation of symbol grounding, we should construct a corpus which shows the relationship between natural language texts and non-text world states. Table 1 shows the list of s-NEs that we defined on (Mori et al., 2016). In this work, we selected Strategy (St), Castle"
2020.lrec-1.530,L16-1225,1,0.732374,"-sen, one of the largest professional shogi tournament and title match, all games are broadcast via the website for a fee1 . These commentaries mainly explain the current game by reasoning the actions, evaluating the states, and predicting the next actions. These commentaries help spectators understand the games. On the other hand, commentators sometimes mention other games such as the players’ previous games. These commentaries are not related to the current games. Tu Po Pi Ps Mc Mn∗ Me St∗ Ca∗ Ev Ee Re Ph Pa Pq Hu Ti Ac Ap Ao Ot 2.3. Shogi Game Corpus We constructed Shogi Game Corpus (SGC) (Mori et al., 2016) by collecting the commented shogi records of Meijin-sen and Jun’i-sen tournament. The game record is a sequence of game states from the initial state to the end of the game. Each comment is mapped to one of the states in the sequence. We also defined shogi named entities (s-NEs) and annotated commentaries. We built an automatic named entity recognition (NER) tool of s-NEs by using the annotated corpus, and the experimental result showed that we could obtain high-quality NER by using our corpus. We also augmented the SGC with modality expressions and event factuality annotation (Matsuyoshi et"
2020.lrec-1.530,Q14-1006,0,0.0152903,"s and those happening in the real world. Our event appearance label set consists of temporal relation, appearance probability, and evidence of the event. Statistics of the annotated corpus and the experimental result show that there exists temporal relation which skillful annotators realize in common. However, it is hard to predict the relationship only by considering the given states. Keywords: game commentary, modality, symbol grounding These days, the interest in the symbol grounding problems becomes larger and larger. A large number of datasets are now available in such as image and text (Young et al., 2014; Chen et al., 2015). These corpora are widely used for description generation (Vinyals et al., 2015; Xu et al., 2015), non-text information retrieval (Ushiku et al., 2017), and so on. Some of these corpora consist of pairs of non-text data and human-writing texts. We usually treat the pairs that the text and non-text data are compatible. However, the assumption is not always true if the corpora are automatically collected. For example, nontext data sometimes reminds humans of some associated things, and they mention to them instead of the exactly given data. To reproduce intelligent systems w"
2020.lrec-1.638,W11-0207,0,0.0739829,"Missing"
2020.lrec-1.638,J96-1002,0,0.0765188,"timation accuracy with gold r-NEs and with automatically recognized r-NEs. The function f (u, v, l) returns a feature vector for an edge, containing information about the nodes u and v that the edge links. The vector comprises the following features: • words in u and v, and their concatenation; • concatenation of the r-NE tags of u and v; • whether u is in the same, a previous or a subsequent sentence as v; Total In initial experiments, we confirmed that each of these five features improves edge detection accuracy. The weight vector Θ is estimated from the training data by a log-linear model (Berger et al., 1996). Given training data consisting of T manually annotated edge-label pairs (ut , vt , lt ), we maximize the following value: T ∑ 1 s(ut , vt , lt ) − ∥Θ∥2 2 t=1 (2) To evaluate the accuracy of flow graph construction, we used 10-fold cross-validation, splitting the data into 270 recipes for training and 30 recipes for test. When we started from the gold standard r-NE tagging, the overall F1 for edge detection was 71.1. When we started instead from the automatic r-NE tagging, the edge detection F1 reduced to 43.3; the main reason for the large decrease is that an edge will always be wrong if the"
2020.lrec-1.638,P06-4020,1,0.623597,"Missing"
2020.lrec-1.638,J17-4005,0,0.0211918,"Missing"
2020.lrec-1.638,N19-1423,0,0.0135175,"Missing"
2020.lrec-1.638,P14-1134,0,0.0253062,"automatic r-NE tagging accuracy. Section 4 describes the flow graph representation, annotation, the parsing algorithm for computing a flow graph, and an evaluation of its accuracy. Section 5 discusses the main findings and proposes directions for future research. 1 The annotated corpus of English recipes is available at https://sites.google.com/view/yy-lab/ resource/english-recipe-flowgraph 5187 2. Related Work There has been much research into representing the semantics of natural language sentences (Banarescu et al., 2013, inter alia) and developing parsers that output such representations (Flanigan et al., 2014, for example). Semantic representations encode the meanings of linguistic units within a sentence, but do not attempt to capture domainspecific constraints or real-world context. In some domains and applications these latter factors may be very important. (For example, in cooking, a mixture can sometimes be beaten and sometimes not, depending on which ingredients have been added to it). For this reason, approaches to processing text describing procedures often do not attempt to construct general semantic representations, but instead construct more specialised domain- and genre-specific repres"
2020.lrec-1.638,D15-1114,0,0.161737,"the socalled ‘smart kitchen’ (Hashimoto et al., 2008), cooking robots (Bollini et al., 2013), etc. In one recent study, Mori et al. (2014) produced flow graph annotations for 266 cooking recipes written in Japanese. That corpus has been used for testing empirical methods for natural language understanding (Maeta et al., 2015) and intelligent search (Yamakata et al., 2013), Similarly, Jermsurawong and Habash (2014) described a corpus of ingredient trees for recipes, and evaluated methods for constructing these automatically. There have been some attempts at unsupervised processing of recipes (Kiddon et al., 2015, inter alia) but the outputs are much less rich than those obtained by supervised methods. This paper concerns a flow graph corpus for recipes in English; the flow graphs are based on the proposals of Mori et al. (2014) in which the graph nodes are ‘recipe named entities’ (r-NEs). The r-NE types cover domain entities such as ingredients; in addition, Mori et al. argue that r-NE types should also cover actions by the cook / chef (which are often expressed as verbs). Unlike the set of NE types commonly used for general text (Sang and Meulder, 2003)—person name, location, organization, etc.—r-NE"
2020.lrec-1.638,W15-2206,1,0.900918,"r graph representation for analysing recipes. More recent studies have created annotated corpora of procedural text, in order to build machine learningbased systems that extract entity and action information. In the domain of cooking recipes, such information has been shown to be useful for the socalled ‘smart kitchen’ (Hashimoto et al., 2008), cooking robots (Bollini et al., 2013), etc. In one recent study, Mori et al. (2014) produced flow graph annotations for 266 cooking recipes written in Japanese. That corpus has been used for testing empirical methods for natural language understanding (Maeta et al., 2015) and intelligent search (Yamakata et al., 2013), Similarly, Jermsurawong and Habash (2014) described a corpus of ingredient trees for recipes, and evaluated methods for constructing these automatically. There have been some attempts at unsupervised processing of recipes (Kiddon et al., 2015, inter alia) but the outputs are much less rich than those obtained by supervised methods. This paper concerns a flow graph corpus for recipes in English; the flow graphs are based on the proposals of Mori et al. (2014) in which the graph nodes are ‘recipe named entities’ (r-NEs). The r-NE types cover domai"
2020.lrec-1.638,C80-1016,0,0.675358,"representations encode the meanings of linguistic units within a sentence, but do not attempt to capture domainspecific constraints or real-world context. In some domains and applications these latter factors may be very important. (For example, in cooking, a mixture can sometimes be beaten and sometimes not, depending on which ingredients have been added to it). For this reason, approaches to processing text describing procedures often do not attempt to construct general semantic representations, but instead construct more specialised domain- and genre-specific representations. For example, Momouchi (1980) proposed representing the meaning of procedural text as a flow graph, and described algorithms to convert text documents to flow graphs. Hamada et al. (2000) adopted a similar graph representation for analysing recipes. More recent studies have created annotated corpora of procedural text, in order to build machine learningbased systems that extract entity and action information. In the domain of cooking recipes, such information has been shown to be useful for the socalled ‘smart kitchen’ (Hashimoto et al., 2008), cooking robots (Bollini et al., 2013), etc. In one recent study, Mori et al. ("
2020.lrec-1.638,mori-etal-2014-flow,1,0.87404,"Missing"
2020.lrec-1.638,W09-1119,0,0.060558,"T Tool D Duration Q Quantity Ac Action by chef Discontinuous Ac2 Ac (English only) Af Action by food Action by tool At (English only) Sf Food state St Tool state Explanation Eatable; also intermediate products Knife, container, etc. Duration of cooking Quantity of food Verb representing a chef’s action Second, non-contiguous part of a single action by chef Verb representing action of a food Verb representing a tool’s action Food’s initial or intermediate state Tool’s initial or intermediate state Table 1: Recipe named entity (r-NE) tags. investigated (Borthwick, 1999; Sang and Meulder, 2003; Ratinov and Roth, 2009), and many general-purpose NER tools have been developed. In this study, we use one such tool, PWNER (Sasada et al., 2015a), which computes probabilities for all possible NE tags based on pointwise prediction, and searches for the best sequence of tags under the tag sequence constraints. The tool is distinctive in being trainable on data that has been only partially annotated. 3. Recipe Named Entities 3.1. Recipe Named Entity Tags In previous work (Yamakata et al., 2017), we created a corpus of 100 recipes written in English, sampled from the Allrecipes UK/Ireland web site2 and annotated for ‘"
2020.lrec-1.638,W03-0419,0,0.243161,"me attempts at unsupervised processing of recipes (Kiddon et al., 2015, inter alia) but the outputs are much less rich than those obtained by supervised methods. This paper concerns a flow graph corpus for recipes in English; the flow graphs are based on the proposals of Mori et al. (2014) in which the graph nodes are ‘recipe named entities’ (r-NEs). The r-NE types cover domain entities such as ingredients; in addition, Mori et al. argue that r-NE types should also cover actions by the cook / chef (which are often expressed as verbs). Unlike the set of NE types commonly used for general text (Sang and Meulder, 2003)—person name, location, organization, etc.—r-NEs are an example of a domain-specific NE definition. Domain-specific NE definitions are widely used in fields such as bioinformatics (Ben Abacha and Zweigenbaum, 2011). A domainspecific NE definition facilitates the development of intelligent applications that process documents in that particular domain. The task of identifying NEs is called ‘named entity recognition’ (NER). NER is usually formulated as a sequence labeling problem, in which each input token is tagged as being inside or outside an NE (and in some approaches, beginning an NE). In th"
2020.lrec-1.638,E99-1023,0,0.0571792,"ssions (Constant et al., 2017). The other is to cover expressions for the actions by automatic cooking tools (e.g. food processors), which are not yet common in Japan, so the tag was not necessary for recipes in Japanese. Table 1 lists the ten r-NE tags that we use for English recipe annotation. Note that this tag set is compatible with the original. Figure 1 shows the annotation that would be given to the recipe step Preheat oven to 180 C / Gas mark 4. The tag suffixes -B and -I (abbreviating Begin and Inside respectively) indicate NE spans according to the IOB2 text chunking representation (Sang and Veenstra, 1999). A tag is assigned to each word or word-sequence designating a single and indivisible object/action/phenomenon in the cooking domain. For example, Gas mark 6 in the example sentence designates the state of the dial of the oven being at 6, so it is annotated as a single r-NE. Therefore, the first word Gas is annotated as St-B and the subsequent words mark and 6 are both annotated as St-I. The word to is annotated O because it is Outside any named entity. 2 5188 http://allrecipes.co.uk/ Preheat oven to 180 Ac-B C / Gas mark 4 Dataset 100-r 200-r Overall . T-B O St-B St-I O St-B St-I St-I O Figu"
C00-1081,P98-1035,0,0.121229,"Missing"
C00-1081,A88-1019,0,0.325437,"Missing"
C00-1081,P96-1025,0,0.0923802,"Missing"
C00-1081,P97-1003,0,0.0632728,") f(t) where f(x) represents the frequency of an event x in the training corpus. The interpolation coeÆcients in the formula (2) are estimated by the deleted interpolation method (Jelinek et al., 1991). 2.3 Selecting Words to be Lexicalized Generally speaking, a word-based n-gram model is better than a POS-based n-gram model in terms of predictive power; however lexicalization of some infrequent words may be harmful because it may cause a data-sparseness problem. In a practical tagger (Kupiec, 1989), only the most frequent 100 words are lexicalized. Also, in a state-of-the-art English parser (Collins, 1997) only the words that occur more than 4 times in training data are lexicalized. For this reason, our parser selects the words to be lexicalized at the time of learning. In the lexicalized models described above (PLL, PP L and PN L ), only the selected words are lexicalized. The selection criterion is parsing accuracy (see section 4) of a held-out corpus, a small part of the learning corpus excluded from parameter estimation. Thus only the words that are predicted to improve the parsing accuracy of the test corpus, or unknown input, are lexicalized. The algorithm is as follows (see Figure 3): 1."
C00-1081,A92-1018,0,0.0282552,"Missing"
C00-1081,J95-2001,0,0.0472713,"Missing"
C00-1081,C96-1058,0,0.149874,"Missing"
C00-1081,W98-1511,0,0.134818,"Missing"
C00-1081,W89-0209,0,0.583224,"Missing"
C00-1081,P98-1083,0,0.143903,"Missing"
C00-1081,H89-2014,0,0.0430351,"ion (MLE) (Merialdo, 1994) as follows: P (wjt+ ) MLE = Pf(f( ht w P (t + ) jt MLE = + ht wii) wii) + f(t+ ; t) f(t) where f(x) represents the frequency of an event x in the training corpus. The interpolation coeÆcients in the formula (2) are estimated by the deleted interpolation method (Jelinek et al., 1991). 2.3 Selecting Words to be Lexicalized Generally speaking, a word-based n-gram model is better than a POS-based n-gram model in terms of predictive power; however lexicalization of some infrequent words may be harmful because it may cause a data-sparseness problem. In a practical tagger (Kupiec, 1989), only the most frequent 100 words are lexicalized. Also, in a state-of-the-art English parser (Collins, 1997) only the words that occur more than 4 times in training data are lexicalized. For this reason, our parser selects the words to be lexicalized at the time of learning. In the lexicalized models described above (PLL, PP L and PN L ), only the selected words are lexicalized. The selection criterion is parsing accuracy (see section 4) of a held-out corpus, a small part of the learning corpus excluded from parameter estimation. Thus only the words that are predicted to improve the parsing"
C00-1081,J94-2001,0,0.0410012,"ossible events are y = 1; 2; : : :; ymax , thus; Py;0 gram = 1=ymax . 2.2 Parameter Estimation Since our model is a hidden Markov model, the parameters of a model can be estimated from a row corpus by EM algorithm (Baum, 1972). With this algorithm, the probability of the row corpus is expected to be maximized regardless of the structure of each sentence. So the obtained model is not always appropriate for a parser. In order to develop a model appropriate for a parser, it is better that the parameters are estimated from a syntactically annotated corpus by a maximum likelihood estimation (MLE) (Merialdo, 1994) as follows: P (wjt+ ) MLE = Pf(f( ht w P (t + ) jt MLE = + ht wii) wii) + f(t+ ; t) f(t) where f(x) represents the frequency of an event x in the training corpus. The interpolation coeÆcients in the formula (2) are estimated by the deleted interpolation method (Jelinek et al., 1991). 2.3 Selecting Words to be Lexicalized Generally speaking, a word-based n-gram model is better than a POS-based n-gram model in terms of predictive power; however lexicalization of some infrequent words may be harmful because it may cause a data-sparseness problem. In a practical tagger (Kupiec, 1989), only the mo"
C00-1081,P98-2148,1,0.90454,"Missing"
C00-1081,P99-1033,0,0.154928,"Missing"
C00-1081,C98-1035,0,\N,Missing
C00-1081,C98-1080,0,\N,Missing
C00-1081,C98-2143,1,\N,Missing
C02-1157,P01-1017,0,0.0401559,"Missing"
C02-1157,P98-1035,0,0.0736324,"Missing"
C02-1157,P97-1003,0,0.0214292,"ba and Jelinek, 2000), proposed as a language model for speech recognition, is also based on a CFG. On the other hand, an SLM for Japanese (Mori et al., 2000) is based on a Markov model by introducing a limit on language structures caused by our human memory limitations (Yngve, 1960; Miller, 1956). We introduced the same limitation into our language model and our parser is also based on a Markov model. In the last decade, the importance of the lexicon has come into focus in the area of stochastic parsers. Nowadays, many state-of-the-art parsers are based on lexicalized models (Charniak, 1997; Collins, 1997). In these papers, they reported signi cant improvement in parsing accuracy by lexicalization. Our model is also lexicalized, the lexicalization is limited to grammatical function words because of the sparseness of data at the step of next word prediction. The greatest di erence between our parser and many state-of-the-art parsers is that our parser is based on a generative language model, which works as a language model of a speech recognizer. Therefore, a speech recognizer equipped with our parser as its language model should be useful for a spoken language understanding system. The greatest"
C02-1157,W98-1511,0,0.0266765,"ediction. The greatest di erence between our parser and many state-of-the-art parsers is that our parser is based on a generative language model, which works as a language model of a speech recognizer. Therefore, a speech recognizer equipped with our parser as its language model should be useful for a spoken language understanding system. The greatest advantage of our model over other structured language models is the ablity to refer to a variable part of the structured history by using ACTs. There have been several attempts at Japanese parsers (Kurohashi and Nagao, 1994; Haruno et al., 1998; Fujio and Matsumoto, 1998; Kudo and Matsumoto, 2000). These Japanese parsers have all been based on a unique phrasal unit called a bunsetsu, a concatenation of one or more content words followed by some grammatical function words. Unlike these parsers, our model describes dependencies between words. Thus our parser can more easily be extended to other languages. In addition, since almost all pasers in other languages than Japanese output relationships between words, the output of our parser can be used by post-parser language processing systems proposed for many other languages (such as a word-level structural alignme"
C02-1157,W89-0209,0,0.152585,"Missing"
C02-1157,P98-1083,0,0.0171919,"step of next word prediction. The greatest di erence between our parser and many state-of-the-art parsers is that our parser is based on a generative language model, which works as a language model of a speech recognizer. Therefore, a speech recognizer equipped with our parser as its language model should be useful for a spoken language understanding system. The greatest advantage of our model over other structured language models is the ablity to refer to a variable part of the structured history by using ACTs. There have been several attempts at Japanese parsers (Kurohashi and Nagao, 1994; Haruno et al., 1998; Fujio and Matsumoto, 1998; Kudo and Matsumoto, 2000). These Japanese parsers have all been based on a unique phrasal unit called a bunsetsu, a concatenation of one or more content words followed by some grammatical function words. Unlike these parsers, our model describes dependencies between words. Thus our parser can more easily be extended to other languages. In addition, since almost all pasers in other languages than Japanese output relationships between words, the output of our parser can be used by post-parser language processing systems proposed for many other languages (such as a wo"
C02-1157,W00-1303,0,0.0142356,"rence between our parser and many state-of-the-art parsers is that our parser is based on a generative language model, which works as a language model of a speech recognizer. Therefore, a speech recognizer equipped with our parser as its language model should be useful for a spoken language understanding system. The greatest advantage of our model over other structured language models is the ablity to refer to a variable part of the structured history by using ACTs. There have been several attempts at Japanese parsers (Kurohashi and Nagao, 1994; Haruno et al., 1998; Fujio and Matsumoto, 1998; Kudo and Matsumoto, 2000). These Japanese parsers have all been based on a unique phrasal unit called a bunsetsu, a concatenation of one or more content words followed by some grammatical function words. Unlike these parsers, our model describes dependencies between words. Thus our parser can more easily be extended to other languages. In addition, since almost all pasers in other languages than Japanese output relationships between words, the output of our parser can be used by post-parser language processing systems proposed for many other languages (such as a word-level structural alignment of sentences in differen"
C02-1157,J94-4001,0,0.0105321,"e sparseness of data at the step of next word prediction. The greatest di erence between our parser and many state-of-the-art parsers is that our parser is based on a generative language model, which works as a language model of a speech recognizer. Therefore, a speech recognizer equipped with our parser as its language model should be useful for a spoken language understanding system. The greatest advantage of our model over other structured language models is the ablity to refer to a variable part of the structured history by using ACTs. There have been several attempts at Japanese parsers (Kurohashi and Nagao, 1994; Haruno et al., 1998; Fujio and Matsumoto, 1998; Kudo and Matsumoto, 2000). These Japanese parsers have all been based on a unique phrasal unit called a bunsetsu, a concatenation of one or more content words followed by some grammatical function words. Unlike these parsers, our model describes dependencies between words. Thus our parser can more easily be extended to other languages. In addition, since almost all pasers in other languages than Japanese output relationships between words, the output of our parser can be used by post-parser language processing systems proposed for many other la"
C02-1157,C00-1081,1,0.919682,"ch is indispensable to spoken language understanding, is a clear advantage of SLMs over word n-gram models. With an SLM as a language model, a speech recognizer is able to directly output a recognition result with its syntactic structure after being given a sequence of acoustic signals. The early SLMs refer to only a limited and xed part of the histories for each step of word and structure prediction in order to avoid a datasparseness problem. For example, in an English model (Chelba and Jelinek, 2000) the next word is predicted from the two right-most exposed heads. Also in a Japanese model (Mori et al., 2000) the next word is predicted from 1) all exposed heads depending on the next word and 2) the words depending on those exposed heads. One of the natural improvements in predictive power for an SLM can be achieved by adding some exibility to the history reference mechanism. For a linear history, which is referred to by using word n-gram models, we can use a context tree (Ron et al., 1996) as a exible history reference mechanism. In an n-gram model with a context tree, the length of each n-gram is increased selectively according to an estimate of the resulting improvement in predictive quality. Th"
C02-1157,P92-1017,0,0.0884949,"Missing"
C02-1157,C98-1035,0,\N,Missing
C02-1157,C98-1080,0,\N,Missing
C08-1113,N06-1019,0,0.0211435,"sks. 10 Although the order in which the candidate tags appear has not been standardized in the PTB corpus, we assume that annotators might order the candidate tags with their conﬁdence. 902 Ex.1 Ex.2 P APA P APA mrg 94.39 73.10 95.08 76.70 random 94.27 71.58 94.98 74.27 ﬁrst 94.26 72.65 94.97 75.28 frequent 94.27 71.68 94.97 74.32 discarded 94.19 71.91 94.98 75.16 Table 5: The average POS tagging performance over 5 trials. Our model is interpreted as one of the CRFs with hidden variables (Quattoni et al., 2004). There are previous work which handles hidden variables in discriminative parsers (Clark and Curran, 2006; Petrov and Klein, 2008). In their methods, the objective functions are also formulated as same as equation (3). For interactive annotation, Culotta et al. (2006) proposed corrective feedback that effectively reduces user operations utilizing partial annotations. Although they assume that the users correct entire label structures so that the CRFs are trained as usual, our proposed method extends their system when the users cannot annotate all of the labels in a sentence. 7 Conclusions and Future Work We are proposing a parameter estimation method for CRFs incorporating partial or ambiguous an"
C08-1113,W04-3230,1,0.42517,"es for non-segmented languages such as Japanese or Chinese. For example, the correct segmentation of the Japanese phrase “ΓইΓই” (incised wound or abrasion) is shown by the lowest boxes segmented by the solid lines in Figure 1. However, there are several overlapping segmentation candidates, which are shown by the other boxes, and possible segmentation by the dashed lines. Thus, the decisions on the word segmentation require considering the context, so simple dictionary lookup approach is not appropriate. Therefore statistical methods have been successfully used for JWS tasks. Previous work (Kudo et al., 2004) showed CRFs outperform generative Markov models and discriminative history-based methods in JWS. In practice, a statistical word segment analyzer tends to perform worse for text from different domains, so that additional annotations for each target domain are required. A major cause of errors is the occurrence of unknown words. For example, if “Γই” (abrasion) is an unknown word, the system may accept the word sequence of “Γ ইΓই” as “Γই” (incised wound), “ Γ” (ﬁle), and “ই” (injury) by mistake. On one hand, lists of new terms in the target domain are often available in the forms of tech"
C08-1113,W03-1025,0,0.0161797,"lowing sentence from the PTB corpus includes an ambiguous annotation for the POS tag of “pending”: That/DT suit/NN is/VBZ pending/VBG|JJ ./. , where words are paired with their part-of-speech tag by a forward slash (“/”).2 Uncertainty concerning the proper POS tag of “pending” is represented by the disjunctive POS tag (“VBG and JJ”) as indicated by a vertical bar. The existence of the ambiguous annotations is due to the task deﬁnition itself, the procedure man1 The boundary policies of some words are different even among linguists. In addition, the boundary agreement is even lower in Chinese (Luo, 2003). 2 These POS tags used here are DT:determiner, NN:common noun, VBZ:present tense 3rd person singular verb, VBG:gerund or present participle verb, JJ:adjective, NNS:plural noun, RBR:comparative adverb, IN:preposition or subordinating conjunction, and RB:adverb. 898 frequency 15 10 7 4 word data more pending than POS tags NN|NNS JJR|RBR JJ|VBG IN|RB Table 1: Words in the PTB with ambiguous POSs. ual for the annotators, or the inadequate knowledge of the annotators. Ideally, the annotations should be disambiguated by a skilled annotator for the training data. However, even the PTB corpus, whose"
C08-1113,J93-2004,0,0.0394081,"nd properly incorporates partial annotations. 5.2 Part-of-speech Tagging Task In this section, we show the results of the POS tagging experiments to assess the proposed method using ambiguous annotations. 9 We selected word occurrences in a batch mode since each training of the CRFs takes too much time for interactive use. 901 ambiguous sentences (training) unique sentences (training) unique sentences (test) Ex.1 Ex.2 118 1,480 2,960 11,840 Table 4: Training and test data for POS tagging. As mentioned in Section 2.2, there are words which have two or more candidate POS tags in the PTB corpus (Marcus et al., 1993). In this experiment, we used 118 sentences in which some words (82 distinct words) are annotated with ambiguous POS tags, and these sentences are called the POS ambiguous sentences. On the other hand, we call sentences in which the POS tags of these terms are uniquely annotated as the POS unique sentences. The goal of this experiment is to effectively improve the tagging performance using both these POS ambiguous sentences and the POS unique sentences as the training data. We assume that the amount of training data is not sufﬁcient to ignore the POS ambiguous sentences, or that the POS ambigu"
C08-1113,C04-1081,0,0.209878,". Then the supervised structured output problem can be deﬁned as learning a map X → Y . In the Japanese word segmentation task, x can represent a given sequence of character boundaries and y is a sequence of the corresponding labels, which specify whether the current position is a word boundary.3 In the POS tagging task, x represents a word sequence and y is a corresponding POS tag sequence. An incomplete annotation, then, is deﬁned as a sequence of subset of the label set instead of a sequence of labels. Let L=(L1 , L2 , · · · , LT ) be a sequence of label subsets for an observed sequence 3 Peng et al. (2004) deﬁned the word segmentation problem as labeling each character as whether or not the previous character boundary of the current character is a word boundary. However, we employ our problem formulation since it is redundant to assign the ﬁrst character of a sentence as the word boundary in their formulation. x, where Lt ∈ 2Y − {∅}. The partial annotation at position s is where Ls is a singleton and the rest Lt=s is Y . For example, if a sentence with 6 character boundaries (7 characters) is partially annotated using the KWIC UI described in Section 2.1, a word annotation where its boundary b"
C08-1113,P92-1017,0,0.172527,"Missing"
C08-1113,N03-1028,0,0.0208949,"lizes the unknown ys out. Then the maximum likelihood estimator for this model can be obtained by maximizing the log likelihood function: LL(θ) = = N   n=1 N  ln P„ (YL(n) |x (n) ) n=1 ln Z„,x(n) ,Y L(n) − ln Z„,x(n) ,Y (3)  . This modeling naturally embraces label ambiguities in the incomplete annotation.4 Unfortunately, equation (3) is not a concave function5 so that there are local maxima in the objective function. Although this non-concavity prevents efﬁcient global maximization of equation (3), it still allows us to incorporate incomplete annotations using gradient ascent iterations (Sha and Pereira, 2003). Gradient ascent methods require the partial derivative of equation (3): ⎛ N ∂ LL(θ) ⎝  = P„ (y|YL(n) , x(n) )Φ(x(n) , y) ∂θ n=1 y∈Y (n) L ⎞  P„ (y|x(n) )Φ(x(n) , y)⎠ , (4) − y∈Y where P„ (y|YL , x) = e„·Φ(x,y) Z„,x,YL (5) is a conditional probability that is normalized over YL . Equations (3) and (4) include the summations of all of the label sequences in Y or YL . It is not practical to enumerate and evaluate all of the label conﬁgurations explicitly, since the number of all of the possible label sequences is exponential on the number of positions t with |Lt |> 1. However, under the Mark"
C08-1113,H05-1010,0,0.0100293,"ll of the labels in a sentence. 7 Conclusions and Future Work We are proposing a parameter estimation method for CRFs incorporating partial or ambiguous annotations of structured data. The empirical results suggest that the proposed method reduces the domain adaptation costs, and improves the prediction performance for the linguistic phenomena that are sometimes difﬁcult for people to label. The proposed method is applicable to other structured output tasks in NLP, such as syntactic parsing, information extraction, and so on. However, there are some NLP tasks, such as the word alignment task (Taskar et al., 2005), in which it is not possible to efﬁciently calculate the sum score of all of the possible label conﬁgurations. Recently, Verbeek and Triggs (2008) independently proposed a parameter estimation method for CRFs using partially labeled images. Although the objective function in their formulation is equivalent to equation (3), they used Loopy Belief Propagation to approximate the sum score for their application (scene segmentation). Their results imply these approximation methods can be used for such applications that cannot use dynamic programming techniques. Acknowledgments We would like to tha"
C12-1072,J93-2003,0,0.0417248,"Missing"
C12-1072,lee-etal-2002-continuous,0,0.0227209,"ransformed, the frequencies of pronunciations for each word entry are counted. We define the frequencies divided by the frequency of the word as the in-class probability of the pronunciation. Let #(x ) be the number of CL word x that appears in the original sentences and #(y|x ) be the number of pronunciations y given to word x ; then the in-class probability, Pc (y|x ), is written as #(y|x ) #(y|x ) . (2) Pc (y|x ) = =P #(x ) y #(y|x ) 3.3 Linguistic corpora to transform The transformation method previously mentioned, of course, requires large linguistic corpora to transform. A former study (Lee et al., 2002) adopted 75 months of newspaper articles for a corpus, which is typical in studies on language models. Newspaper articles are relatively formal and in consistent style; therefore, they are suitable for recognizing speech in written articles, while not for spoken sentences including expressions that are characteristic of spoken language. One candidate for corpora in spoken language is the academic presentation speech corpora included in the Corpus of Spontaneous Japanese (CSJ) (Maekawa, 2003). This corpus consists of 1187 Phoneme− sequence transducer Original sentence a n a t a |n o |... N−best"
C12-1072,I08-7018,0,0.136868,"pt a corpus filtering method (Misu and Kawahara, 2006) in the Yahoo! Q&A corpus to build LMs. The major disadvantage of Web corpora is that some sentences are too inconsistent or not even in the form of sentences, e.g., Internet slang and ASCII arts. Speech recognition does not require these sentences and they are need to be excluded from corpora for training LMs. Corpus filtering is based on perplexity; we choose sentences with small perplexity on an LM from a set of sentence examples. These sentence examples were blog articles in the Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008) core data. Words were segmented and pronunciations were estimated in BCCWJ core data these were manually checked by humans. Blog articles in the BCCWJ core data contained sentences that were close to those in spoken language including informal words and expressions. 4 Experiment Our experiment evaluated the recognition accuracy of ASR. Dialect utterances were recognized as CL sentences and compared to referential CL sentences. We collected utterances in the CL and Kansai dialects. People from the Kansai area (Osaka, Hyogo, Nara and Shiga Prefectures in this experiment) read these sentences in"
C12-1072,P09-1086,0,0.0154892,"e, but effective case is limited; classification would not work well if vocabulary dominates difference of target dialects and these dialects have similar phonological characteristics. Instead of studying acoustic aspects of dialects containing the problems above, some studies focused linguistic aspects. Zhang (1998) described dialect machine translation (MT) between dialects in the Chinese language. Since dialect sentences were only represented in sound and had not been written down, his translations were between pinyin representations of two dialects, which is similar to those in our study. Munteanu et al. (2009), related to the correction of ASR results, tried to correct ASR results in the lecture domain by using a transformation model trained from correct sentences and the corresponding outputs. The scoring for each rule was based on how much the word error rate (WER) could be reduced by applying the rules. These studies still had problems. Zhang (1998) created translation dictionaries manually, and dealing with various dialects required the same process for each dialect. Munteanu et al. (2009) assumed that ASR results were correct; if much vocabulary specific to a target domain were not covered, e."
C12-1072,neubig-mori-2010-word,1,0.856652,"he Yahoo! Q&A corpus mentioned in Section 3.2. 4.1 Conditions Here we describe the training data for the phoneme-sequence transducers and LMs. Table 1 summarizes the size of corpora. Each LM had a common vocabulary size of 10,000. This experiment adopted the parallel corpus (National Institute for Japanese Language and Linguistics, 2008) of the Kansai area (Osaka, Kyoto and Hyogo Prefectures). Each dialect sentence in this corpus was represented as pronunciation while each CL sentence was in plain text. We segmented CL sentences into words and estimated pronunciations of the words with KyTea (Neubig and Mori, 2010) so that the two kinds of sentences would have the same format in pronunciation. We transformed the pronunciation of the Yahoo! Q&A corpus into that of the Kansai dialect to train the LMs. We chose 23,600 out of 335,685 questions in the category of daily life with the filtering method mentioned in Section 3.3, which has approximately the same number of words as the BCCWJ core data. One of at most the five-best dialect pronunciations was randomly chosen in the transformation, with the probability of their normalized likelihoods, and determined the probability of each pronunciation by using Equa"
C12-1072,P98-2238,0,0.0775168,"sifying dialects and selecting LMs is effective only if the vocabulary of target dialects are almost the same, but actually, dialect vocabulary is rather likely to differ between dialects (Wolfram, 2009, p. 144). The strategy of classifying dialects and next selecting LMs is possible, of course, but effective case is limited; classification would not work well if vocabulary dominates difference of target dialects and these dialects have similar phonological characteristics. Instead of studying acoustic aspects of dialects containing the problems above, some studies focused linguistic aspects. Zhang (1998) described dialect machine translation (MT) between dialects in the Chinese language. Since dialect sentences were only represented in sound and had not been written down, his translations were between pinyin representations of two dialects, which is similar to those in our study. Munteanu et al. (2009), related to the correction of ASR results, tried to correct ASR results in the lecture domain by using a transformation model trained from correct sentences and the corresponding outputs. The scoring for each rule was based on how much the word error rate (WER) could be reduced by applying the"
C12-1072,C98-2233,0,\N,Missing
C12-1183,W11-2008,1,0.643275,"ond to but also vague and complex user requests related to, for example, tourist guides or news briefings. This type of application can be achieved through document retrieval in a corresponding domain. For example, we can turn to tourist guidebooks or relevant Wikipedia entries for information on the tourist domain (Misu and Kawahara, 2010). An intelligent dialogue system can be created by restricting the domain and using the knowledge from that domain (Kawahara, 2009). An interactive news navigator that generates dialogues based on news article archives has been developed along this concept (Yoshino et al., 2011). The automatic speech recognition (ASR) module for spoken dialogue systems (SDSs) needs an appropriate language model (LM) adapted to the task domain and style. Even an ASR system with a very large vocabulary cannot cover all proper nouns or named entities (NEs), which are critical in information retrieval. Ideally, an LM should be trained with a large-scale matched corpus, but in many cases this is not realistic. Therefore, two approaches are commonly adopted. The first involves mixing document texts of the target domain with a dialogue corpus of spoken-style expressions. The other involves"
C96-2202,H92-1030,0,\N,Missing
C96-2202,H92-1001,0,\N,Missing
C96-2202,E95-1020,0,\N,Missing
C98-2143,P97-1003,0,0.0406129,"in almost all of the recent practical applications in that it describes only relations between sequential elements. Some linguistic phenomena, however, are better described by assuming relations between separated elements. And modeling this kind of phenomena, the accuracies of various application axe generally augmented. As for English, there have been researches in which a stochastic context-free grammar (SCFG) (Fujisaki et al., 1989) is used for model description. Recently some researchers have pointed out the importa~lce of the lexicon and proposed lexicMized models (Jelinek et al., 1994; Collins, 1997). In these models, every headword is propagated up through the derivation tree such that every parent receives a headword from tile head-child. This kind of speciaLization may, however, be excessive if tile criterion is predictive power of the model. Research aimed at estimating the best specialization level for 2-grarn model (Mori et al., 1997) shows a class-based model is more predictive than a word-based 2-gram model, a completely lexicaiized model, comparing cross entropy of a POS-based 2-grain model, a word-based 2-gram model aztd a class-based 2-gram model, estimated from information the"
C98-2143,W89-0209,0,0.447453,"s of the alphabet (n-gram) on a corpus containing a large number of sentences of a language. This is the same model as 0 This work is done when the auther was at Kyoto Univ. 898 used in almost all of the recent practical applications in that it describes only relations between sequential elements. Some linguistic phenomena, however, are better described by assuming relations between separated elements. And modeling this kind of phenomena, the accuracies of various application axe generally augmented. As for English, there have been researches in which a stochastic context-free grammar (SCFG) (Fujisaki et al., 1989) is used for model description. Recently some researchers have pointed out the importa~lce of the lexicon and proposed lexicMized models (Jelinek et al., 1994; Collins, 1997). In these models, every headword is propagated up through the derivation tree such that every parent receives a headword from tile head-child. This kind of speciaLization may, however, be excessive if tile criterion is predictive power of the model. Research aimed at estimating the best specialization level for 2-grarn model (Mori et al., 1997) shows a class-based model is more predictive than a word-based 2-gram model, a"
C98-2143,W97-1003,0,0.024236,"Missing"
C98-2143,H94-1052,0,0.0137414,"t Kyoto Univ. 898 used in almost all of the recent practical applications in that it describes only relations between sequential elements. Some linguistic phenomena, however, are better described by assuming relations between separated elements. And modeling this kind of phenomena, the accuracies of various application axe generally augmented. As for English, there have been researches in which a stochastic context-free grammar (SCFG) (Fujisaki et al., 1989) is used for model description. Recently some researchers have pointed out the importa~lce of the lexicon and proposed lexicMized models (Jelinek et al., 1994; Collins, 1997). In these models, every headword is propagated up through the derivation tree such that every parent receives a headword from tile head-child. This kind of speciaLization may, however, be excessive if tile criterion is predictive power of the model. Research aimed at estimating the best specialization level for 2-grarn model (Mori et al., 1997) shows a class-based model is more predictive than a word-based 2-gram model, a completely lexicaiized model, comparing cross entropy of a POS-based 2-grain model, a word-based 2-gram model aztd a class-based 2-gram model, estimated from"
C98-2143,J92-4003,0,\N,Missing
D12-1077,W05-0909,0,0.0281214,"dition is true, and 0 otherwise. An example of this is given in Figure 2 (b). To calculate an accuracy measure for ordering F 0 , we ﬁrst calculate the maximum loss for the sentence, which is equal to the total number of non-equal rank comparisons in the sentence5 F J−1 ∑ Lt (F 0 ) , max Lt (F˜ 0 ) F˜ 0 which will take a value between 0 (when F 0 has maximal loss), and 1 (when F 0 matches one of the oracle orderings). In Figure 2 (b), Lt (F 0 ) = 2 and max Lt (F˜ 0 ) = 8, so At (F 0 ) = 0.75. J ∑ 4.3 Chunk Fragmentation Another measure that has been used in evaluation of translation accuracy (Banerjee and Lavie, 2005) and pre-ordering accuracy (Talbot et al., 2011) is chunk fragmentation. This measure is based on the number of chunks that the sentence needs to be broken into to reproduce the correct ordering, with a motivation that the number of continuous chunks is equal to the number of times the reader will have to jump to a diﬀerent position in the reordered sentence to read it in the target order. One way to measure the number of continuous chunks is considering 0 whether each word pair fj0 and fj+1 is discon0 tinuous (the rank of fj+1 is not equal to or one greater than fj0 ) 0 discont(fj0 , fj+1 )="
D12-1077,P10-2033,0,0.013484,"ansforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero and Uszkoreit (2011) learn a reordering model through a three-step process of bilingual grammar induction, training a monolingual p"
D12-1077,J07-2003,0,0.86214,"ng framework results in signiﬁcant gains in translation accuracy over standard phrasebased SMT and previously proposed unsupervised syntax induction methods. 1 Introduction Finding the appropriate word ordering in the target language is one of the most diﬃcult problems for statistical machine translation (SMT), particularly for language pairs with widely divergent syntax. As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al., 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or preordering (Xia and McCord, 2004). In particular, systems that use sourcelanguage syntax allow for the handling of longdistance reordering without large increases in The ﬁrst author is now aﬃliated with the Nara Institute of Science and Technology. decoding time. However, these require a good syntactic parser, which is not available for many languages. In recent work, DeNero and Uszkoreit (2011) suggest that unsupervised grammar induction can be used to create source-sentence parse structure for use in translation as a part of a pre-ord"
D12-1077,P11-2031,0,0.00445512,"xperiments Our experiments test the reordering and translation accuracy of translation systems using the proposed method. As reordering metrics, we use Kendall’s τ and chunk fragmentation (Talbot et al., 2011) comparing the system F 0 and oracle F 0 calculated with manually created alignments. As translation metrics, we use BLEU (Papineni et al., 2002), as well as RIBES (Isozaki et al., 2010a), which is similar to Kendall’s τ , but evaluated on the target sentence E instead of the reordered sentence F 0 . All scores are the average of three training runs to control for randomness in training (Clark et al., 2011). For translation, we use Moses (Koehn et al., 2007) with lexicalized reordering (Koehn et al., 2005) in all experiments. We test three types orig 3-step 3-step+φpos 3-step+φcf g lader lader+φpos lader+φcf g Chunk 61.22 63.51 64.28 65.76 73.19 73.97 75.06 en-ja τ BLEU 73.46 21.87 72.55 21.45 72.11 21.45 75.32 21.67 78.44 23.11 79.24 23.32 80.53 23.36 RIBES 68.25 67.66 67.44 68.47 69.86 69.78 70.89 Chunk 66.42 67.17 67.56 67.23 75.14 75.49 75.14 ja-en τ BLEU 72.99 18.34 73.01 17.78 74.21 18.18 74.06 18.18 79.14 19.54 78.79 19.89 77.80 19.35 RIBES 65.36 64.42 64.65 64.93 66.93 67.24 66.12 Table"
D12-1077,P05-1066,0,0.768146,"in the order of E. Translation then transforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero and Uszkoreit (2011) learn a reordering model through a three-step process of bilingual gram"
D12-1077,W02-1001,0,0.0148034,"ions by selecting the derivation with the largest model score. From an implementation point of view, this can be done by ﬁnding the derivation that minimizes L(Dk |Fk , Ak ) − αS(Dk |Fk , w), where α is a constant small enough to ensure that the eﬀect of the loss will always be greater than the eﬀect of the score. Finally, if the model parse D˙ k has a loss that ˆ k , we is greater than that of the oracle parse D update the weights to increase the score of the oracle parse and decrease the score of the model parse. Any criterion for weight updates may be used, such as the averaged perceptron (Collins, 2002) and MIRA (Crammer et al., 2006), but we opted to use Pegasos (Shalev-Shwartz et al., 2007) as it allows for the introduction of regularization and relatively stable learning. To perform this full process, given a source sentence Fk , alignment Ak , and model weights w we need to be able to eﬃciently calculate scores, calculate losses, and create parse forests for derivations Dk , the details of which will be explained in the following sections. 5.2 Scoring Derivation Trees First, we must consider how to eﬃciently assign scores S(D|F, w) to a derivation or forest during parsing. The most stand"
D12-1077,D11-1018,0,0.622387,"les the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al., 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or preordering (Xia and McCord, 2004). In particular, systems that use sourcelanguage syntax allow for the handling of longdistance reordering without large increases in The ﬁrst author is now aﬃliated with the Nara Institute of Science and Technology. decoding time. However, these require a good syntactic parser, which is not available for many languages. In recent work, DeNero and Uszkoreit (2011) suggest that unsupervised grammar induction can be used to create source-sentence parse structure for use in translation as a part of a pre-ordering based translation system. In this work, we present a method for inducing a parser for SMT by training a discriminative model to maximize reordering accuracy while treating the parse tree as a latent variable. As a learning framework, we use online large-margin methods to train the model to directly minimize two measures of reordering accuracy. We propose a variety of features, and demonstrate that learning can succeed when no linguistic informati"
D12-1077,N10-1128,0,0.0575155,"ring ﬁrst deterministically transforms F into F 0 , which contains the same words as F but is in the order of E. Translation then transforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero"
D12-1077,I11-1087,1,0.815752,"n, 2004). RM-train RM-test TM/LM Tune Test sent. 602 555 329k 1166 1160 word (ja) 14.5k 11.2k 6.08M 26.8k 28.5k word (en) 14.3k 10.4k 5.91M 24.3k 26.7k Table 1: The number of sentences and words for training and testing the reordering model (RM), translation model (TM), and language model (LM). except φpos and φcf g . In addition, we test systems with φpos and φcf g added. For English, we use the Stanford parser (Klein and Manning, 2003) for both POS tagging and CFG parsing. For Japanese, we use the KyTea tagger (Neubig et al., 2011) for POS tagging,8 and the EDA word-based dependency parser (Flannery et al., 2011) with simple manual head-rules to convert a dependency parse to a CFG parse. 6.1 Eﬀect of Pre-ordering of pre-ordering: original order with F 0 ← F (orig), pre-orderings learned using the 3-step process of DeNero and Uszkoreit (2011) (3step), and the proposed model with latent derivations (lader).7 Except when stated otherwise, lader was trained to minimize chunk fragmentation loss with a cube pruning stack pop limit of 50, and the regularization constant of 10−3 (chosen through cross-validation). We test our systems on Japanese-English and English-Japanese translation using data from the Kyot"
D12-1077,C10-1043,0,0.357752,"ure 1). Reordering ﬁrst deterministically transforms F into F 0 , which contains the same words as F but is in the order of E. Translation then transforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our a"
D12-1077,P09-1104,0,0.0189689,"urthermore, we assume that the score S(D|F ) is the weighted sum of a number of feature functions deﬁned over D and F ∑ S(D|F, w) = wi φi (D, F ) i where φi is the ith feature function, and wi is its corresponding weight in weight vector w. Given this model, we must next consider how to learn the weights w. As the ﬁnal goal of our model is to produce good reorderings F 0 , it is natural to attempt to learn weights that will allow us to produce these high-quality reorderings. 3 BTGs cannot reproduce all possible reorderings, but can handle most reorderings occurring in natural translated text (Haghighi et al., 2009). 845 Figure 2: An example of (a) the ranking function r(fj ), (b) loss according to Kendall’s τ , (c) loss according to chunk fragmentation. 4 Evaluating Reorderings Before we explain the learning algorithm, we must know how to distinguish whether the F 0 produced by the model is good or bad. This section explains how to calculate oracle reorderings, and assign each F 0 a loss and an accuracy according to how well it reproduces the oracle. 4.1 Calculating Oracle Orderings In order to calculate reordering quality, we ﬁrst deﬁne a ranking function r(fj |F, A), which indicates the relative posit"
D12-1077,D10-1092,0,0.110239,"Missing"
D12-1077,W10-1736,0,0.679774,"ing a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero and Uszkoreit (2011) learn a reordering model through a three-step process of bilingual grammar induction, training a monolingual parser to reproduce the"
D12-1077,D11-1017,0,0.0374907,"cketing transduction grammar (BTG, Wu (1997)) framework. BTGs represent a binary tree derivation D over the source sentence F as shown in Figure 1. Each non-terminal node can either be a straight (str) or inverted (inv) production, and terminals (term) span a nonempty substring f .2 The ordering of the sentence is determined by the tree structure and the non-terminal labels str and inv, and can be built bottom-up. Each subtree represents a source substring f and its reordered counterpart f 0 . For each terminal node, no reordering occurs and f is equal to f 0 . 1 The semi-supervised method of Katz-Brown et al. (2011) also optimizes reordering accuracy, but requires manually annotated parses as seed data. 2 In the original BTG framework used in translation, terminals produce a bilingual substring pair f /e, but as we are only interested in reordering the source F , we simplify the model by removing the target substring e. For each non-terminal node spanning f with its left child spanning f 1 and its right child spanning f 2 , if the non-terminal symbol is str, the reordered strings will be concatenated in order as f 0 = f 01 f 02 , and if the non-terminal symbol is inv, the reordered strings will be concat"
D12-1077,I11-1005,0,0.255321,"Missing"
D12-1077,P03-1054,0,0.00645291,"dering (chunk, τ ) and translation (BLEU, RIBES) results for each system. Bold numbers indicate no signiﬁcant diﬀerence from the best system (bootstrap resampling with p > 0.05) (Koehn, 2004). RM-train RM-test TM/LM Tune Test sent. 602 555 329k 1166 1160 word (ja) 14.5k 11.2k 6.08M 26.8k 28.5k word (en) 14.3k 10.4k 5.91M 24.3k 26.7k Table 1: The number of sentences and words for training and testing the reordering model (RM), translation model (TM), and language model (LM). except φpos and φcf g . In addition, we test systems with φpos and φcf g added. For English, we use the Stanford parser (Klein and Manning, 2003) for both POS tagging and CFG parsing. For Japanese, we use the KyTea tagger (Neubig et al., 2011) for POS tagging,8 and the EDA word-based dependency parser (Flannery et al., 2011) with simple manual head-rules to convert a dependency parse to a CFG parse. 6.1 Eﬀect of Pre-ordering of pre-ordering: original order with F 0 ← F (orig), pre-orderings learned using the 3-step process of DeNero and Uszkoreit (2011) (3step), and the proposed model with latent derivations (lader).7 Except when stated otherwise, lader was trained to minimize chunk fragmentation loss with a cube pruning stack pop limi"
D12-1077,N03-1017,0,0.0461607,"012. 2012 Association for Computational Linguistics Figure 1: An example with a source sentence F reordered into target order F 0 , and its corresponding target sentence E. D is one of the BTG derivations that can produce this ordering. the pre-ordering approach to machine translation (Xia and McCord, 2004), which performs translation as a two step process of reordering and translation (Figure 1). Reordering ﬁrst deterministically transforms F into F 0 , which contains the same words as F but is in the order of E. Translation then transforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for"
D12-1077,2005.iwslt-1.8,0,0.165383,"ored over the parse tree. Using this model in the pre-ordering framework results in signiﬁcant gains in translation accuracy over standard phrasebased SMT and previously proposed unsupervised syntax induction methods. 1 Introduction Finding the appropriate word ordering in the target language is one of the most diﬃcult problems for statistical machine translation (SMT), particularly for language pairs with widely divergent syntax. As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al., 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or preordering (Xia and McCord, 2004). In particular, systems that use sourcelanguage syntax allow for the handling of longdistance reordering without large increases in The ﬁrst author is now aﬃliated with the Nara Institute of Science and Technology. decoding time. However, these require a good syntactic parser, which is not available for many languages. In recent work, DeNero and Uszkoreit (2011) suggest that unsupervised grammar induction can be used to create source-sentence parse s"
D12-1077,P07-2045,0,0.00429164,"ranslation accuracy of translation systems using the proposed method. As reordering metrics, we use Kendall’s τ and chunk fragmentation (Talbot et al., 2011) comparing the system F 0 and oracle F 0 calculated with manually created alignments. As translation metrics, we use BLEU (Papineni et al., 2002), as well as RIBES (Isozaki et al., 2010a), which is similar to Kendall’s τ , but evaluated on the target sentence E instead of the reordered sentence F 0 . All scores are the average of three training runs to control for randomness in training (Clark et al., 2011). For translation, we use Moses (Koehn et al., 2007) with lexicalized reordering (Koehn et al., 2005) in all experiments. We test three types orig 3-step 3-step+φpos 3-step+φcf g lader lader+φpos lader+φcf g Chunk 61.22 63.51 64.28 65.76 73.19 73.97 75.06 en-ja τ BLEU 73.46 21.87 72.55 21.45 72.11 21.45 75.32 21.67 78.44 23.11 79.24 23.32 80.53 23.36 RIBES 68.25 67.66 67.44 68.47 69.86 69.78 70.89 Chunk 66.42 67.17 67.56 67.23 75.14 75.49 75.14 ja-en τ BLEU 72.99 18.34 73.01 17.78 74.21 18.18 74.06 18.18 79.14 19.54 78.79 19.89 77.80 19.35 RIBES 65.36 64.42 64.65 64.93 66.93 67.24 66.12 Table 2: Reordering (chunk, τ ) and translation (BLEU, RIB"
D12-1077,W04-3250,0,0.117398,"Missing"
D12-1077,P07-1091,0,0.20119,"translation (Figure 1). Reordering ﬁrst deterministically transforms F into F 0 , which contains the same words as F but is in the order of E. Translation then transforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being si"
D12-1077,P06-1096,0,0.0852397,"Missing"
D12-1077,P11-2093,1,0.714814,"niﬁcant diﬀerence from the best system (bootstrap resampling with p > 0.05) (Koehn, 2004). RM-train RM-test TM/LM Tune Test sent. 602 555 329k 1166 1160 word (ja) 14.5k 11.2k 6.08M 26.8k 28.5k word (en) 14.3k 10.4k 5.91M 24.3k 26.7k Table 1: The number of sentences and words for training and testing the reordering model (RM), translation model (TM), and language model (LM). except φpos and φcf g . In addition, we test systems with φpos and φcf g added. For English, we use the Stanford parser (Klein and Manning, 2003) for both POS tagging and CFG parsing. For Japanese, we use the KyTea tagger (Neubig et al., 2011) for POS tagging,8 and the EDA word-based dependency parser (Flannery et al., 2011) with simple manual head-rules to convert a dependency parse to a CFG parse. 6.1 Eﬀect of Pre-ordering of pre-ordering: original order with F 0 ← F (orig), pre-orderings learned using the 3-step process of DeNero and Uszkoreit (2011) (3step), and the proposed model with latent derivations (lader).7 Except when stated otherwise, lader was trained to minimize chunk fragmentation loss with a cube pruning stack pop limit of 50, and the regularization constant of 10−3 (chosen through cross-validation). We test our sy"
D12-1077,E99-1010,0,0.0604002,"term), while l and r are the leftmost and rightmost indices of the span that d covers. c and c + 1 are the rightmost index of the left child and leftmost index of the right child for non-terminal nodes. All features are intersected with the node label s, so each feature described below corresponds to three diﬀerent features (or two for features applicable to only non-terminal nodes). • φlex : Identities of words in positions fl , fr , fc , fc+1 , fl−1 , fr+1 , fl fr , and fc fc+1 . • φclass : Same as φlex , but with words abstracted to classes. We use the 50 classes automatically generated by Och (1999)’s method that are calculated during alignment in standard SMT systems. • φbalance : For non-terminals, features indicating whether the length of the left span 848 (c − l + 1) is lesser than, equal to, or greater than the length of the right span (r − c). • φtable : Features, bucketed by length, that indicate whether “fl . . . fr ” appears as a contiguous phrase in the SMT training data, as well as the log frequency of the number of times the phrase appears total and the number of times it appears as a contiguous phrase (DeNero and Uszkoreit, 2011). Phrase length is limited to 8, and phrases o"
D12-1077,P02-1040,0,0.101341,"easonable burden in terms of time and memory. To overcome this problem, we note that this setting is nearly identical to translation using synchronous CFGs with an integrated bigram LM, and thus we can employ cube-pruning to reduce our search space (Chiang, 2007). 6 Experiments Our experiments test the reordering and translation accuracy of translation systems using the proposed method. As reordering metrics, we use Kendall’s τ and chunk fragmentation (Talbot et al., 2011) comparing the system F 0 and oracle F 0 calculated with manually created alignments. As translation metrics, we use BLEU (Papineni et al., 2002), as well as RIBES (Isozaki et al., 2010a), which is similar to Kendall’s τ , but evaluated on the target sentence E instead of the reordered sentence F 0 . All scores are the average of three training runs to control for randomness in training (Clark et al., 2011). For translation, we use Moses (Koehn et al., 2007) with lexicalized reordering (Koehn et al., 2005) in all experiments. We test three types orig 3-step 3-step+φpos 3-step+φcf g lader lader+φpos lader+φcf g Chunk 61.22 63.51 64.28 65.76 73.19 73.97 75.06 en-ja τ BLEU 73.46 21.87 72.55 21.45 72.11 21.45 75.32 21.67 78.44 23.11 79.24"
D12-1077,2007.tmi-papers.21,0,0.0861613,"works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero and Uszkoreit (2011) learn a reordering model through a three-step process of bilingual grammar induction, training a monolingual parser to reproduce the induced trees, and training 844 a reordering model that selects a reordering based on this parse structure. In contrast, our method trains the model in a single step, treating the parse structure as a latent vari"
D12-1077,2011.mtsummit-papers.36,0,0.0181648,"s for systems trained to optimize chunk fragmentation (Lc ) or Kendall’s τ (Lt ). that spanned constituent boundaries (as long as the phrase frequency was high). Finally, as Section 6.2 shows in detail, the ability of lader to maximize reordering accuracy directly allows for improved reordering and translation results. It can also be seen that incorporating POS tags or parse trees improves accuracy of both lader and 3-step, particularly for EnglishJapanese, where syntax has proven useful for pre-ordering, and less so for Japanese-English, where syntactic pre-ordering has been less successful (Sudoh et al., 2011b). We also tested Moses’s implementation of hierarchical phrase-based SMT (Chiang, 2007), which achieved BLEU scores of 23.21 and 19.30 for English-Japanese and Japanese-English respectively, approximately matching lader in accuracy, but with a signiﬁcant decrease in decoding speed. Further, when pre-ordering with lader and hierarchical phrase-based SMT were combined, BLEU scores rose to 23.29 and 19.69, indicating that the two techniques can be combined for further accuracy improvements. 6.2 Eﬀect of Training Loss Table 3 shows results when one of three losses is optimized during training: c"
D12-1077,W11-2102,0,0.294296,"d fj2 are assigned the same rank. We can now deﬁne measures of reordering accuracy for F 0 by how well it arranges the words in order of ascending rank. It should be noted that as we allow ties in rank, there are multiple possible F 0 where all words are in strictly ascending order, which we will call oracle orderings. 4.2 The ﬁrst measure of reordering accuracy that we will consider is Kendall’s τ (Kendall, 1938), a measure of pairwise rank correlation which has been proposed for evaluating translation reordering accuracy (Isozaki et al., 2010a; Birch et al., 2010) and pre-ordering accuracy (Talbot et al., 2011). The fundamental idea behind the measure lies in comparisons between each pair of elements fj01 and fj02 of the reordered sentence, where j1 < j2 . Because j1 < j2 , fj01 comes before fj02 in the reordered sentence, the ranks should be r(fj01 ) ≤ r(fj02 ) in order to produce the correct ordering. Based on this criterion, we ﬁrst deﬁne a loss Lt (F 0 ) that will be higher for orderings that are further from the oracle. Speciﬁcally, we take the sum of all pairwise orderings that do not follow the expected order Lt (F ) = J−1 ∑ J ∑ where δ(·) is an indicator function that is 1 when its condition"
D12-1077,D09-1105,0,0.607314,"ic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero and Uszkoreit (2011) learn a reordering model through a three-step process of bilingual grammar induction, training a monolingual parser to reproduce the induced trees, and training 844 a reordering model that selects a reordering based on this parse structure. In contrast, our method trains the model in a single step, treating the parse structure as a latent variable in a discriminative r"
D12-1077,D07-1080,1,0.843185,"1, which corresponds to the total number of comparisons made in calculating the loss6 Ac (F 0 ) = 1 − Lc (F 0 ) . J +1 In Figure 2 (c), Lc (F 0 ) = 3 and J + 1 = 6, so Ac (F 0 ) = 0.5. 5 Learning a BTG Parser for Reordering Now that we have a deﬁnition of loss over reorderings produced by the model, we have a clear learning objective: we would like to ﬁnd reorderings F 0 with low loss. The learning algorithm we use to achieve this goal is motivated by discriminative training for machine translation systems (Liang et al., 2006), and extended to use large-margin training in an online framework (Watanabe et al., 2007). 5.1 Learning Algorithm Learning uses the general framework of largemargin online structured prediction (Crammer et al., 2006), which makes several passes through the data, ﬁnding a derivation with high model score (the model parse) and a derivation with 6 It should be noted that for sentences of length one or sentences with tied ranks, the maximum loss may be less than J + 1, but for simplicity we use this approximation. 847 minimal loss (the oracle parse), and updating w if these two parses diverge (Figure 3). In order to create both of these parses eﬃciently, we ﬁrst create a parse forest"
D12-1077,J97-3002,0,0.73298,"ization, including features such as those that utilize the existence of a span in the phrase table. Our work is also unique in that we show that it is possible to directly optimize several measures of reordering accuracy, which proves important for achieving good translations.1 3 Training a Reordering Model with Latent Derivations In this section, we provide a basic overview of the proposed method for learning a reordering model with latent derivations using online discriminative learning. 3.1 Space of Reorderings The model we present here is based on the bracketing transduction grammar (BTG, Wu (1997)) framework. BTGs represent a binary tree derivation D over the source sentence F as shown in Figure 1. Each non-terminal node can either be a straight (str) or inverted (inv) production, and terminals (term) span a nonempty substring f .2 The ordering of the sentence is determined by the tree structure and the non-terminal labels str and inv, and can be built bottom-up. Each subtree represents a source substring f and its reordered counterpart f 0 . For each terminal node, no reordering occurs and f is equal to f 0 . 1 The semi-supervised method of Katz-Brown et al. (2011) also optimizes reor"
D12-1077,C04-1073,0,0.932492,"sebased SMT and previously proposed unsupervised syntax induction methods. 1 Introduction Finding the appropriate word ordering in the target language is one of the most diﬃcult problems for statistical machine translation (SMT), particularly for language pairs with widely divergent syntax. As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al., 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or preordering (Xia and McCord, 2004). In particular, systems that use sourcelanguage syntax allow for the handling of longdistance reordering without large increases in The ﬁrst author is now aﬃliated with the Nara Institute of Science and Technology. decoding time. However, these require a good syntactic parser, which is not available for many languages. In recent work, DeNero and Uszkoreit (2011) suggest that unsupervised grammar induction can be used to create source-sentence parse structure for use in translation as a part of a pre-ordering based translation system. In this work, we present a method for inducing a parser for"
D12-1077,N09-1028,0,0.450117,"anslation then transforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve mention for being similar to our approach. First, DeNero and Uszkoreit (2011) learn a reordering model through a three-step process of bilingual grammar induction, tr"
D12-1077,P01-1067,0,0.229152,"in translation accuracy over standard phrasebased SMT and previously proposed unsupervised syntax induction methods. 1 Introduction Finding the appropriate word ordering in the target language is one of the most diﬃcult problems for statistical machine translation (SMT), particularly for language pairs with widely divergent syntax. As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al., 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or preordering (Xia and McCord, 2004). In particular, systems that use sourcelanguage syntax allow for the handling of longdistance reordering without large increases in The ﬁrst author is now aﬃliated with the Nara Institute of Science and Technology. decoding time. However, these require a good syntactic parser, which is not available for many languages. In recent work, DeNero and Uszkoreit (2011) suggest that unsupervised grammar induction can be used to create source-sentence parse structure for use in translation as a part of a pre-ordering based translation system. In this work, we pre"
D12-1077,W07-0401,0,0.0103136,"ss of reordering and translation (Figure 1). Reordering ﬁrst deterministically transforms F into F 0 , which contains the same words as F but is in the order of E. Translation then transforms F 0 into E using a method such as phrase-based SMT (Koehn et al., 2003), which can produce accurate translations when only local reordering is required. This general framework has been widely studied, with the majority of works relying on a syntactic parser being available in the source language. Reordering rules are deﬁned over this parse either through machine learning techniques (Xia and McCord, 2004; Zhang et al., 2007; Li et al., 2007; Genzel, 2010; Dyer and Resnik, 2010; Khalilov and Sima’an, 2011) or linguistically motivated manual rules (Collins et al., 2005; Xu et al., 2009; Carpuat et al., 2010; Isozaki et al., 2010b). However, as building a parser for each source language is a resourceintensive undertaking, there has also been some interest in developing reordering rules without the use of a parser (Rottmann and Vogel, 2007; Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Visweswariah et al., 2011), and we will follow this thread of research in this paper. In particular, two methods deserve men"
D12-1077,W06-3119,0,0.0728907,"as well as the log frequency of the number of times the phrase appears total and the number of times it appears as a contiguous phrase (DeNero and Uszkoreit, 2011). Phrase length is limited to 8, and phrases of frequency one are removed. • φpos : Same as φlex , but with words abstracted to language-dependent POS tags. • φcf g : Features indicating the label of the spans fl . . . fr , fl . . . fc , and fc+1 . . . fr in a supervised parse tree, and the intersection of the three labels. When spans do not correspond to a span in the supervised parse tree, we indicate “no span” with the label “X” (Zollmann and Venugopal, 2006). Most of these features can be calculated from only a parallel corpus, but φpos requires a POS tagger and φcf g requires a full syntactic parser in the source language. As it is preferable to have a method that is applicable in languages where these tools are not available, we perform experiments both with and without the features that require linguistic analysis tools. 5.3 Finding Losses for Derivation Trees The above features φ and their corresponding weights w are all that are needed to calculate scores of derivation trees at test time. However, during training, it is also necessary to ﬁnd"
D12-1077,D11-1045,0,\N,Missing
D13-1021,2010.iwslt-papers.7,0,0.33004,"data (in case of sample-wise noise, we assume the noise is in the beginning). This assumption derives a constraint between signal and noise parts that helps to avoid a welter of transliteration and non-transliteration parts. It also has a shortcoming that it is generally noise t h エ noise e sp e ッ t c チ ン グ h i n sp g マ sp ス m ク a s t noiseB t noiseB noise k s s t noiseB t noiseB s s s t signal t signal Figure 2: Example of many-to-many alignment with partial noise in the beginning and end. “noise” stands for the noise symbol and “sp” stands for a white space. s 3.3 Constrained Gibbs sampling Finch and Sumita (2010) used a blocked Gibbs sampling algorithm with forward-filtering backwardsampling (FFBS) (Mochihashi et al., 2009). We extend their algorithm for our noise-aware model using a state-based calculation over the three states: non-transliteration part in the beginning (noiseB), transliteration part (signal), non-transliteration part in the end (noiseE). Figure 3 illustrates our FFBS steps. At first in the forward filtering, we begin with transition to noiseB and signal. The calculation of forward probabilities itself is almost the same as Finch and Sumita (2010) except for state transition constrai"
D13-1021,P09-1012,0,0.0328726,"nt between signal and noise parts that helps to avoid a welter of transliteration and non-transliteration parts. It also has a shortcoming that it is generally noise t h エ noise e sp e ッ t c チ ン グ h i n sp g マ sp ス m ク a s t noiseB t noiseB noise k s s t noiseB t noiseB s s s t signal t signal Figure 2: Example of many-to-many alignment with partial noise in the beginning and end. “noise” stands for the noise symbol and “sp” stands for a white space. s 3.3 Constrained Gibbs sampling Finch and Sumita (2010) used a blocked Gibbs sampling algorithm with forward-filtering backwardsampling (FFBS) (Mochihashi et al., 2009). We extend their algorithm for our noise-aware model using a state-based calculation over the three states: non-transliteration part in the beginning (noiseB), transliteration part (signal), non-transliteration part in the end (noiseE). Figure 3 illustrates our FFBS steps. At first in the forward filtering, we begin with transition to noiseB and signal. The calculation of forward probabilities itself is almost the same as Finch and Sumita (2010) except for state transition constraints: from noiseB to signal, from signal to noiseE. The backward-sampling traverses a path by probabilitybased sam"
D13-1021,P02-1040,0,0.0872961,"Missing"
D13-1021,P12-1049,0,0.282575,"ration in patent domain using patent bilingual corpora. 1 Introduction Transliteration is used for providing translations for source language words that have no appropriate counterparts in target language, such as some technical terms and named entities. Statistical machine transliteration (Knight and Graehl, 1998) is a technology to solve it in a statistical manner. Bilingual dictionaries can be used to train its model, but many of their entries are actually translation but not transliteration. Such non-transliteration pairs hurt the transliteration model and should be eliminated beforehand. Sajjad et al. (2012) proposed a method to identify such non-transliteration pairs, and applied it successfully to noisy word pairs obtained from automatic word alignment on bilingual corpora. It enables the statistical machine transliteration to be bootstrapped from bilingual corpora. This approach is beneficial because it does not require carefullydeveloped bilingual transliteration dictionaries and it can learn domain-specific transliteration patterns This paper proposes a novel transliteration mining method for such partial transliterations. The method uses a noise-aware character alignment model that distingu"
D13-1021,W10-2402,0,\N,Missing
D13-1021,J98-4003,0,\N,Missing
D15-1140,J92-4003,0,0.190917,"at logs user behavior (such as typing and selection of word candidates) (Section 4), • a method for improving word segmentation by using these logs (Section 5). To the best of our knowledge, this is the first paper proposing a method for using IM logs to successfully improve WS. 2 Related Work The main focus of this paper is WS. Corpus-based, or empirical, methods were proposed in the early 90’s (Nagata, 1994). Then (Mori and Kurata, 2005) extended it by lexicalizing the states like many researches in that era, grouping the wordPOS pairs into clusters inspired by the class-based n-gram model (Brown et al., 1992), and making the history length variable like a POS tagger in English (Ron et al., 1996). In parallel, there were attempts at solving Chinese WS in a similar way (Sproat and Chang, 1996). WS or the joint task of WS and POS tagging can be seen as a sequence labeling problem. So conditional random fields (CRFs) (Peng et al., 2004; Lafferty et al., 2001) have been applied to this task and showed better performance than POS-based Markov models (Kudo et al., 2004). The training time of sequencebased methods tends to be long, especially when we use partially annotated data. Thus a simple method base"
D15-1140,P00-1031,0,0.281357,"s extension was adopted in Chinese WS to make use of socalled natural annotations (Yang and Vozila, 2014; Jiang et al., 2013). In that work, tags in hyper-texts were regarded as annotations and used to improve WS performance. The IM logs used in this paper are also classified as natural annotations, but contain much more noise. In addition, we need an IM that is specifically designed to collect logs as natural annotations. Server design is the most important factor in capturing information from IM logs. The most popular IM servers are based on statistical language modeling (Mori et al., 1999; Chen and Lee, 2000; Maeta and Mori, 2012). Their parameters are trained from manually segmented sentences whose words are annotated with phoneme sequences, and from sentences automatically annotated with NLP tools which are also based on machine learning models trained on the annotated sentences. Thus normal IM servers are not capable of presenting out-of-vocabulary (OOV) words (which provide large amounts of information on word boundaries) as conversion candidates. To make our IM server capable of presenting OOV words, we extend a statistical IM server based on (Mori et al., 2006), and ensure that it is comput"
D15-1140,P13-1075,0,0.167513,"ecome increasingly aware of the importance of language resources (Neubig and Mori, 2010; Mori and Neubig, 2014). So Mori and Oda (2009) proposed to incorpolate dictionaries for human into a WS system with a different word definition. CRFs were also extended to enable training from partially annotated sentences (Tsuboi et al., 2008). When using partially annotated sentences for WS training data, word boundary information exists only between some character pairs and is absent for others. This extension was adopted in Chinese WS to make use of socalled natural annotations (Yang and Vozila, 2014; Jiang et al., 2013). In that work, tags in hyper-texts were regarded as annotations and used to improve WS performance. The IM logs used in this paper are also classified as natural annotations, but contain much more noise. In addition, we need an IM that is specifically designed to collect logs as natural annotations. Server design is the most important factor in capturing information from IM logs. The most popular IM servers are based on statistical language modeling (Mori et al., 1999; Chen and Lee, 2000; Maeta and Mori, 2012). Their parameters are trained from manually segmented sentences whose words are ann"
D15-1140,D14-1011,0,0.0129072,"lable training data often differ from domains where there is a high demand for NLP, which causes a severe degradation in WS performance. Examples include ma* This work was done when the first author was at Kyoto University. Shinsuke Mori ACCMS, Kyoto University Yoshida Honmachi, Sakyo-ku, Kyoto, Japan forest@i.kyoto-u.ac.jp chine translation of patents, text mining of medical texts, and marketing on the micro-blog site Twitter1 . Some papers have reported low accuracy on WS or the joint task of WS and part-of-speech (POS) tagging of Japanese or Chinese in these domains (Mori and Neubig, 2014; Kaji and Kitsuregawa, 2014; Liu et al., 2014) To cope with this problem, we propose a way to collect information from people as they type Japanese or Chinese on computers. These languages use far more characters than the number of keys on a keyboard, so users use software called an input method (IM) to type text in these languages. Unlike written texts in these languages, which lack word boundary information, text entered with an IM can provide word boundary information that can used by NLP systems. As we show in this paper, logs collected from IMs are a valuable source of word boundary information. An IM consists of a"
D15-1140,D15-1277,1,0.763267,"-gram probabilities by dividing word n-gram frequencies by word (n − 1)gram frequencies. For a detailed explanation and a mathematical proof of this method, please refer to (Mori and Takuma, 2004). 3.2.2 Pseudo-Stochastically Segmented Corpora The computational costs (in terms of both time and space) for calculating an n-gram model from an SSC are very high2 , so it is not a practical technique for implementing an IM engine. In order to reduce the computational costs we approximate an SSC using a deterministically tagged corpus, which is called a pseudo-stochastically segmented corpus (pSSC) (Kameko et al., 2015). The following is the method for producing a pSSC from an SSC. • For i = 1 to nr − 1 1. output a character xi , 2. generate a random number 0 ≤ p &lt; 1, 3. output a word boundary if p &lt; Pi or output nothing otherwise. Now we have a corpus in the same format as a standard segmented corpus with variable (nonconstant) segmentation. 2 This is because an SSC has many words and word fragments. Additionally, word n-gram frequencies must be calculated using floating point numbers instead of integers. 1. generate a random number 0 ≤ p &lt; 1, 2. annotate wi with its∑ j-th phoneme sequence y i,j , where j−1"
D15-1140,W04-3230,0,0.0145915,"alizing the states like many researches in that era, grouping the wordPOS pairs into clusters inspired by the class-based n-gram model (Brown et al., 1992), and making the history length variable like a POS tagger in English (Ron et al., 1996). In parallel, there were attempts at solving Chinese WS in a similar way (Sproat and Chang, 1996). WS or the joint task of WS and POS tagging can be seen as a sequence labeling problem. So conditional random fields (CRFs) (Peng et al., 2004; Lafferty et al., 2001) have been applied to this task and showed better performance than POS-based Markov models (Kudo et al., 2004). The training time of sequencebased methods tends to be long, especially when we use partially annotated data. Thus a simple method based on pointwise classification has been shown to be as accurate as sequence-based methods and fast enough to make active learning practically possible (Neubig et al., 2011). Since the pointwise method decides whether there is a word boundary or not between two characters without referring to other word boundary decisions in the same sentence, it is straightforward to train the model from partially annotated sentences. We adopt this WS system for our experiment"
D15-1140,D14-1093,0,0.0189118,"ffer from domains where there is a high demand for NLP, which causes a severe degradation in WS performance. Examples include ma* This work was done when the first author was at Kyoto University. Shinsuke Mori ACCMS, Kyoto University Yoshida Honmachi, Sakyo-ku, Kyoto, Japan forest@i.kyoto-u.ac.jp chine translation of patents, text mining of medical texts, and marketing on the micro-blog site Twitter1 . Some papers have reported low accuracy on WS or the joint task of WS and part-of-speech (POS) tagging of Japanese or Chinese in these domains (Mori and Neubig, 2014; Kaji and Kitsuregawa, 2014; Liu et al., 2014) To cope with this problem, we propose a way to collect information from people as they type Japanese or Chinese on computers. These languages use far more characters than the number of keys on a keyboard, so users use software called an input method (IM) to type text in these languages. Unlike written texts in these languages, which lack word boundary information, text entered with an IM can provide word boundary information that can used by NLP systems. As we show in this paper, logs collected from IMs are a valuable source of word boundary information. An IM consists of a client (front-end)"
D15-1140,I08-7018,0,0.0300037,"The reason why we use SVM for word segmentation is that the accuracy is generally higher than that based on LR. It was so in the experiments of this paper. The F-measure of LR on TWI-test was 91.30 (Recall = 89.50, Precision = 93.17), There are two test corpora: one is the general domain corpus from which we built the baseline WS, and the other is the same domain that the IM logs were collected from, Twitter. 6.1 Corpora The annotated corpus we used to build the baseline word segmenter is the manually annotated part (core data) of the Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008), plus newspaper articles and daily conversation sentences. We also used a 234,652-word dictionary (UniDic) provided with the BCCWJ. A small portion of the BCCWJ core data is reserved for testing. In addition, we manually segmented sentences randomly obtained from Twitter8 during the same period as the log collection for the test corpus. Table 2 shows the details of these corpora. which is lower than that of SVM (see Table 4). To make an SSC, however, we use an LR model because we need word boundary probabilities. 8 We extracted body text from 1,592 tweets excluding mentions, hash tags, URLs,"
D15-1140,W12-4801,1,0.852021,"ted in Chinese WS to make use of socalled natural annotations (Yang and Vozila, 2014; Jiang et al., 2013). In that work, tags in hyper-texts were regarded as annotations and used to improve WS performance. The IM logs used in this paper are also classified as natural annotations, but contain much more noise. In addition, we need an IM that is specifically designed to collect logs as natural annotations. Server design is the most important factor in capturing information from IM logs. The most popular IM servers are based on statistical language modeling (Mori et al., 1999; Chen and Lee, 2000; Maeta and Mori, 2012). Their parameters are trained from manually segmented sentences whose words are annotated with phoneme sequences, and from sentences automatically annotated with NLP tools which are also based on machine learning models trained on the annotated sentences. Thus normal IM servers are not capable of presenting out-of-vocabulary (OOV) words (which provide large amounts of information on word boundaries) as conversion candidates. To make our IM server capable of presenting OOV words, we extend a statistical IM server based on (Mori et al., 2006), and ensure that it is computationally efficient eno"
D15-1140,mori-neubig-2014-language,1,0.872752,"the domains of the available training data often differ from domains where there is a high demand for NLP, which causes a severe degradation in WS performance. Examples include ma* This work was done when the first author was at Kyoto University. Shinsuke Mori ACCMS, Kyoto University Yoshida Honmachi, Sakyo-ku, Kyoto, Japan forest@i.kyoto-u.ac.jp chine translation of patents, text mining of medical texts, and marketing on the micro-blog site Twitter1 . Some papers have reported low accuracy on WS or the joint task of WS and part-of-speech (POS) tagging of Japanese or Chinese in these domains (Mori and Neubig, 2014; Kaji and Kitsuregawa, 2014; Liu et al., 2014) To cope with this problem, we propose a way to collect information from people as they type Japanese or Chinese on computers. These languages use far more characters than the number of keys on a keyboard, so users use software called an input method (IM) to type text in these languages. Unlike written texts in these languages, which lack word boundary information, text entered with an IM can provide word boundary information that can used by NLP systems. As we show in this paper, logs collected from IMs are a valuable source of word boundary info"
D15-1140,P06-1092,1,0.759025,"modeling (Mori et al., 1999; Chen and Lee, 2000; Maeta and Mori, 2012). Their parameters are trained from manually segmented sentences whose words are annotated with phoneme sequences, and from sentences automatically annotated with NLP tools which are also based on machine learning models trained on the annotated sentences. Thus normal IM servers are not capable of presenting out-of-vocabulary (OOV) words (which provide large amounts of information on word boundaries) as conversion candidates. To make our IM server capable of presenting OOV words, we extend a statistical IM server based on (Mori et al., 2006), and ensure that it is computationally efficient enough for practical use by the public. The target domain in our experiments is Twitter, a site where users post short messages called tweets. Since tweets are an immediate and powerful reflection of public attitudes and social trends, there have been numerous attempts at extracting information from them. Examples include information analysis of disasters (Sakai et al., 2010), estimation of depressive tendencies (Tsugawa et al., 2013), speech diarization (Higashinaka et al., 2011), and many others. These works require preprocessing of tweets wi"
D15-1140,C94-1032,0,0.0942494,"inguistics. sion of our IM. The three main contributions of this paper are: • an IM server that proposes word candidates which are not included in the vocabulary (Section 3), • a publicly usable IM that logs user behavior (such as typing and selection of word candidates) (Section 4), • a method for improving word segmentation by using these logs (Section 5). To the best of our knowledge, this is the first paper proposing a method for using IM logs to successfully improve WS. 2 Related Work The main focus of this paper is WS. Corpus-based, or empirical, methods were proposed in the early 90’s (Nagata, 1994). Then (Mori and Kurata, 2005) extended it by lexicalizing the states like many researches in that era, grouping the wordPOS pairs into clusters inspired by the class-based n-gram model (Brown et al., 1992), and making the history length variable like a POS tagger in English (Ron et al., 1996). In parallel, there were attempts at solving Chinese WS in a similar way (Sproat and Chang, 1996). WS or the joint task of WS and POS tagging can be seen as a sequence labeling problem. So conditional random fields (CRFs) (Peng et al., 2004; Lafferty et al., 2001) have been applied to this task and showe"
D15-1140,neubig-mori-2010-word,1,0.855479,"thod based on pointwise classification has been shown to be as accurate as sequence-based methods and fast enough to make active learning practically possible (Neubig et al., 2011). Since the pointwise method decides whether there is a word boundary or not between two characters without referring to other word boundary decisions in the same sentence, it is straightforward to train the model from partially annotated sentences. We adopt this WS system for our experiments. Along with the evolution of models, the NLP community has become increasingly aware of the importance of language resources (Neubig and Mori, 2010; Mori and Neubig, 2014). So Mori and Oda (2009) proposed to incorpolate dictionaries for human into a WS system with a different word definition. CRFs were also extended to enable training from partially annotated sentences (Tsuboi et al., 2008). When using partially annotated sentences for WS training data, word boundary information exists only between some character pairs and is absent for others. This extension was adopted in Chinese WS to make use of socalled natural annotations (Yang and Vozila, 2014; Jiang et al., 2013). In that work, tags in hyper-texts were regarded as annotations and"
D15-1140,P11-2093,1,0.899551,"imilar way (Sproat and Chang, 1996). WS or the joint task of WS and POS tagging can be seen as a sequence labeling problem. So conditional random fields (CRFs) (Peng et al., 2004; Lafferty et al., 2001) have been applied to this task and showed better performance than POS-based Markov models (Kudo et al., 2004). The training time of sequencebased methods tends to be long, especially when we use partially annotated data. Thus a simple method based on pointwise classification has been shown to be as accurate as sequence-based methods and fast enough to make active learning practically possible (Neubig et al., 2011). Since the pointwise method decides whether there is a word boundary or not between two characters without referring to other word boundary decisions in the same sentence, it is straightforward to train the model from partially annotated sentences. We adopt this WS system for our experiments. Along with the evolution of models, the NLP community has become increasingly aware of the importance of language resources (Neubig and Mori, 2010; Mori and Neubig, 2014). So Mori and Oda (2009) proposed to incorpolate dictionaries for human into a WS system with a different word definition. CRFs were al"
D15-1140,C04-1081,0,0.0304669,"Corpus-based, or empirical, methods were proposed in the early 90’s (Nagata, 1994). Then (Mori and Kurata, 2005) extended it by lexicalizing the states like many researches in that era, grouping the wordPOS pairs into clusters inspired by the class-based n-gram model (Brown et al., 1992), and making the history length variable like a POS tagger in English (Ron et al., 1996). In parallel, there were attempts at solving Chinese WS in a similar way (Sproat and Chang, 1996). WS or the joint task of WS and POS tagging can be seen as a sequence labeling problem. So conditional random fields (CRFs) (Peng et al., 2004; Lafferty et al., 2001) have been applied to this task and showed better performance than POS-based Markov models (Kudo et al., 2004). The training time of sequencebased methods tends to be long, especially when we use partially annotated data. Thus a simple method based on pointwise classification has been shown to be as accurate as sequence-based methods and fast enough to make active learning practically possible (Neubig et al., 2011). Since the pointwise method decides whether there is a word boundary or not between two characters without referring to other word boundary decisions in the"
D15-1140,J96-3004,0,0.145419,"owledge, this is the first paper proposing a method for using IM logs to successfully improve WS. 2 Related Work The main focus of this paper is WS. Corpus-based, or empirical, methods were proposed in the early 90’s (Nagata, 1994). Then (Mori and Kurata, 2005) extended it by lexicalizing the states like many researches in that era, grouping the wordPOS pairs into clusters inspired by the class-based n-gram model (Brown et al., 1992), and making the history length variable like a POS tagger in English (Ron et al., 1996). In parallel, there were attempts at solving Chinese WS in a similar way (Sproat and Chang, 1996). WS or the joint task of WS and POS tagging can be seen as a sequence labeling problem. So conditional random fields (CRFs) (Peng et al., 2004; Lafferty et al., 2001) have been applied to this task and showed better performance than POS-based Markov models (Kudo et al., 2004). The training time of sequencebased methods tends to be long, especially when we use partially annotated data. Thus a simple method based on pointwise classification has been shown to be as accurate as sequence-based methods and fast enough to make active learning practically possible (Neubig et al., 2011). Since the poi"
D15-1140,C08-1113,1,0.925087,"ry or not between two characters without referring to other word boundary decisions in the same sentence, it is straightforward to train the model from partially annotated sentences. We adopt this WS system for our experiments. Along with the evolution of models, the NLP community has become increasingly aware of the importance of language resources (Neubig and Mori, 2010; Mori and Neubig, 2014). So Mori and Oda (2009) proposed to incorpolate dictionaries for human into a WS system with a different word definition. CRFs were also extended to enable training from partially annotated sentences (Tsuboi et al., 2008). When using partially annotated sentences for WS training data, word boundary information exists only between some character pairs and is absent for others. This extension was adopted in Chinese WS to make use of socalled natural annotations (Yang and Vozila, 2014; Jiang et al., 2013). In that work, tags in hyper-texts were regarded as annotations and used to improve WS performance. The IM logs used in this paper are also classified as natural annotations, but contain much more noise. In addition, we need an IM that is specifically designed to collect logs as natural annotations. Server desig"
D15-1140,D14-1010,0,0.242042,"the NLP community has become increasingly aware of the importance of language resources (Neubig and Mori, 2010; Mori and Neubig, 2014). So Mori and Oda (2009) proposed to incorpolate dictionaries for human into a WS system with a different word definition. CRFs were also extended to enable training from partially annotated sentences (Tsuboi et al., 2008). When using partially annotated sentences for WS training data, word boundary information exists only between some character pairs and is absent for others. This extension was adopted in Chinese WS to make use of socalled natural annotations (Yang and Vozila, 2014; Jiang et al., 2013). In that work, tags in hyper-texts were regarded as annotations and used to improve WS performance. The IM logs used in this paper are also classified as natural annotations, but contain much more noise. In addition, we need an IM that is specifically designed to collect logs as natural annotations. Server design is the most important factor in capturing information from IM logs. The most popular IM servers are based on statistical language modeling (Mori et al., 1999; Chen and Lee, 2000; Maeta and Mori, 2012). Their parameters are trained from manually segmented sentence"
D15-1277,P13-1075,0,0.0916695,"tag system, in which there is no constraint between neighboring tags. For Japanese WS, our preliminary experiments showed that the combination of the BI tag system with SVMs is slightly better than the BIES tag system with CRFs. This is another reason why we used the former in this paper. Our extension of word segmentation is, however, applicable to the BIES/CRFs combination as well. The method we describe in this paper is unsupervised and requires a small amount of annotated data to tune the hyperparameter. From this viewpoint, the approach based on natural annotation (Yang and Vozila, 2014; Jiang et al., 2013; Liu et al., 2014) may come to readers’ mind. In these studies, tags in hyper-texts were regarded as partial annotations and used to improve WS performance using CRFs trainable from such data (Tsuboi et al., 2008). Mori and Nagao (1996) proposed a method for extracting new words from a large amount of raw text. Murawaki and Kuro2301 hashi (2008) proposed an online method in a similar setting. In contrast to these studies, this paper proposes to use other modalities, game states as the first trial, than languages. 7 Conclusion We have described an unsupervised method for improving word segment"
D15-1277,D14-1093,0,0.0538287,"there is no constraint between neighboring tags. For Japanese WS, our preliminary experiments showed that the combination of the BI tag system with SVMs is slightly better than the BIES tag system with CRFs. This is another reason why we used the former in this paper. Our extension of word segmentation is, however, applicable to the BIES/CRFs combination as well. The method we describe in this paper is unsupervised and requires a small amount of annotated data to tune the hyperparameter. From this viewpoint, the approach based on natural annotation (Yang and Vozila, 2014; Jiang et al., 2013; Liu et al., 2014) may come to readers’ mind. In these studies, tags in hyper-texts were regarded as partial annotations and used to improve WS performance using CRFs trainable from such data (Tsuboi et al., 2008). Mori and Nagao (1996) proposed a method for extracting new words from a large amount of raw text. Murawaki and Kuro2301 hashi (2008) proposed an online method in a similar setting. In contrast to these studies, this paper proposes to use other modalities, game states as the first trial, than languages. 7 Conclusion We have described an unsupervised method for improving word segmentation based on symb"
D15-1277,P15-1167,0,0.0358304,"Missing"
D15-1277,I08-7018,0,0.112746,"didate as the score of the candidate. After that, we get the summation of, the average of, or the maximum in the scores of the same candidate over the whole dataset. Finally we select the top R percent of word candidates in descending order of the value of sum, ave, or max and add them to the WS dictionary and retrain the model. 5 Evaluation We conducted word segmentation experiments in the following settings. 5.1 Corpora The annotated corpus we used to build the baseline word segmenter is the manually annotated part (core data) of the Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008), plus newspaper articles and daily conversation sentences. We also used a 234,652-word dictionary (UniDic) provided with the BCCWJ. A small portion of the BCCWJ core data is reserved for testing. In addition, we manually segmented sentences randomly obtained from Shogi commentaries. We divided these sentences into two parts: a development set and a test set. Table 1 shows the details of these corpora. To make a pSSC, we prepared 33,151 pairs of a Shogi position and a commentary sentence. The 2300 Table 2: WS accuracy on BCCWJ. Recall Prec. F-meas. Baseline 98.99 99.06 99.03 + Sym.Gro. 99.03 9"
D15-1277,C96-2202,1,0.413116,"is another reason why we used the former in this paper. Our extension of word segmentation is, however, applicable to the BIES/CRFs combination as well. The method we describe in this paper is unsupervised and requires a small amount of annotated data to tune the hyperparameter. From this viewpoint, the approach based on natural annotation (Yang and Vozila, 2014; Jiang et al., 2013; Liu et al., 2014) may come to readers’ mind. In these studies, tags in hyper-texts were regarded as partial annotations and used to improve WS performance using CRFs trainable from such data (Tsuboi et al., 2008). Mori and Nagao (1996) proposed a method for extracting new words from a large amount of raw text. Murawaki and Kuro2301 hashi (2008) proposed an online method in a similar setting. In contrast to these studies, this paper proposes to use other modalities, game states as the first trial, than languages. 7 Conclusion We have described an unsupervised method for improving word segmentation based on symbol grounding results. To extract word candidates from raw sentences, we first segment sentences stochastically, and then match the word candidate sequences with game states that are described by the sentences. Finally,"
D15-1277,D08-1045,0,0.0363732,"Missing"
D15-1277,C94-1032,0,0.126072,"s valuable as the annotation additions. From a close look at the comparison of the recall and the precision, we see that the improvement in the recall is higher than that of the precision. This result shows that the symbol grounding successfully acquired new words with a few erroneous words. As the final remark, the result on the general domain (Table 2) shows that our framework does not cause a severe performance degradation in the general domain. 6 Related Work The NLP task we focus on in this paper is word segmentation. One of the first empirical methods was based on a hidden Markov model (Nagata, 1994). In parallel, there were attempts at solving Chinese word segmentation in a similar way (Sproat and Chang, 1996). These methods take words as the modeling unit. Recently, Neubig et al. (2011) have presented a method for directly deciding whether there is a word boundary or not at each point between characters. For Chinese word segmentation, there are some attempts at tagging characters with BIES tags (Xue, 2003) by a sequence labeller such as CRFs (Lafferty et al., 2001), where B, I, E, and S means the beginning of a word, intermediate of a word, the end of a word, and a single character word"
D15-1277,P11-2093,1,0.65013,"rpus Cr (hereafter referred to as the character sequence xn1 r ) and word boundary probabilities of the form Pi , which is the probability that a word boundary exists between two characters xi and xi+1 . These probabilities are estimated by a model based on logistic regression (LR) (Fan et al., 2008) trained on a manually segmented corpus by referring to the surrounding characters1 . Since there are word boundaries before the first character and after the last character of the corpus, P0 = Pnr = 1. The expected frequency of a word 1 In the experiment we used the same features as those used in Neubig et al., (2011). . 2298 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2298–2303, c Lisbon, Portugal, 17-21 September 2015. 2015 Association for Computational Linguistics. Figure 1: Overview of our method. w in an SSC {∏ is calculated as } follows: fr (w) = ∑ k−1 j=1 (1 − Pi+j ) Pi+k , where O = i∈O Pi {i |xi+k i+1 = w} is the set of all the occurrences of the string matching with w2 . 2.2 Pseudo-Stochastically Segmented Corpora The computational cost (in terms of both time and space) for calculating the expected frequencies in an SSC is very high3 , so it is no"
D15-1277,Q13-1003,0,0.054047,"oximation errors decrease to 0 when m → ∞. 3 Symbol Grounding As the target of symbol grounding, we use states (piece positions) of a Shogi game and commen2 For a detailed explanation and a mathematical proof of this method, please refer to Mori and Takuma (2004) . 3 This is because an SSC has many words and word fragments. Additionally, word 1-gram frequencies must be calculated using floating point numbers instead of integers. taries associated with them. We should note, however, that our framework is general and applicable to different types of combinations such as image/description pairs (Regneri et al., 2013). 3.1 Game Commentary The Japanese language is one of the languages without clear word boundaries and we need an automatic WS as the first step of NLP. In Shogi, there are many professional players and many commentaries about game states are available. 3.2 Grounding Words We build a symbol grounding model using a Shogi commentary dataset. We use a set of pairs of a Shogi state Si and a commentary sentence Ci as the training set. A Shogi state Si is converted into a feature vector f(Si ). We generate m (in our experiment, m = 4) pSSC Ci′ from Ci . Ci′ contains m corpora of the same text body bu"
D15-1277,J96-3004,0,0.442213,"sion, we see that the improvement in the recall is higher than that of the precision. This result shows that the symbol grounding successfully acquired new words with a few erroneous words. As the final remark, the result on the general domain (Table 2) shows that our framework does not cause a severe performance degradation in the general domain. 6 Related Work The NLP task we focus on in this paper is word segmentation. One of the first empirical methods was based on a hidden Markov model (Nagata, 1994). In parallel, there were attempts at solving Chinese word segmentation in a similar way (Sproat and Chang, 1996). These methods take words as the modeling unit. Recently, Neubig et al. (2011) have presented a method for directly deciding whether there is a word boundary or not at each point between characters. For Chinese word segmentation, there are some attempts at tagging characters with BIES tags (Xue, 2003) by a sequence labeller such as CRFs (Lafferty et al., 2001), where B, I, E, and S means the beginning of a word, intermediate of a word, the end of a word, and a single character word, respectively. The pointwise WS can be seen as character tagging with the BI tag system, in which there is no co"
D15-1277,C08-1113,1,0.785905,"ystem with CRFs. This is another reason why we used the former in this paper. Our extension of word segmentation is, however, applicable to the BIES/CRFs combination as well. The method we describe in this paper is unsupervised and requires a small amount of annotated data to tune the hyperparameter. From this viewpoint, the approach based on natural annotation (Yang and Vozila, 2014; Jiang et al., 2013; Liu et al., 2014) may come to readers’ mind. In these studies, tags in hyper-texts were regarded as partial annotations and used to improve WS performance using CRFs trainable from such data (Tsuboi et al., 2008). Mori and Nagao (1996) proposed a method for extracting new words from a large amount of raw text. Murawaki and Kuro2301 hashi (2008) proposed an online method in a similar setting. In contrast to these studies, this paper proposes to use other modalities, game states as the first trial, than languages. 7 Conclusion We have described an unsupervised method for improving word segmentation based on symbol grounding results. To extract word candidates from raw sentences, we first segment sentences stochastically, and then match the word candidate sequences with game states that are described by"
D15-1277,O03-4002,0,0.0575001,"egradation in the general domain. 6 Related Work The NLP task we focus on in this paper is word segmentation. One of the first empirical methods was based on a hidden Markov model (Nagata, 1994). In parallel, there were attempts at solving Chinese word segmentation in a similar way (Sproat and Chang, 1996). These methods take words as the modeling unit. Recently, Neubig et al. (2011) have presented a method for directly deciding whether there is a word boundary or not at each point between characters. For Chinese word segmentation, there are some attempts at tagging characters with BIES tags (Xue, 2003) by a sequence labeller such as CRFs (Lafferty et al., 2001), where B, I, E, and S means the beginning of a word, intermediate of a word, the end of a word, and a single character word, respectively. The pointwise WS can be seen as character tagging with the BI tag system, in which there is no constraint between neighboring tags. For Japanese WS, our preliminary experiments showed that the combination of the BI tag system with SVMs is slightly better than the BIES tag system with CRFs. This is another reason why we used the former in this paper. Our extension of word segmentation is, however,"
D15-1277,D14-1010,0,0.0945302,"er tagging with the BI tag system, in which there is no constraint between neighboring tags. For Japanese WS, our preliminary experiments showed that the combination of the BI tag system with SVMs is slightly better than the BIES tag system with CRFs. This is another reason why we used the former in this paper. Our extension of word segmentation is, however, applicable to the BIES/CRFs combination as well. The method we describe in this paper is unsupervised and requires a small amount of annotated data to tune the hyperparameter. From this viewpoint, the approach based on natural annotation (Yang and Vozila, 2014; Jiang et al., 2013; Liu et al., 2014) may come to readers’ mind. In these studies, tags in hyper-texts were regarded as partial annotations and used to improve WS performance using CRFs trainable from such data (Tsuboi et al., 2008). Mori and Nagao (1996) proposed a method for extracting new words from a large amount of raw text. Murawaki and Kuro2301 hashi (2008) proposed an online method in a similar setting. In contrast to these studies, this paper proposes to use other modalities, game states as the first trial, than languages. 7 Conclusion We have described an unsupervised method for im"
D15-1277,D11-1041,0,\N,Missing
I11-1087,J96-1002,0,0.0526627,"Missing"
I11-1087,W06-1615,0,0.0740221,"total size of the partial annotation pool produced by using all rules was 248,148 dependencies out of 1,010,648 annotation candidates (not counting the last word of sentences, which has no dependency). The baseline case only used the EHJ-train with no partial annotations from the 5 Related Work There has been a significant amount of work on how to utilize in-domain data to improve the accuracy of parsing. The majority of this work has focused on using unlabeled data in combination with self-training (Roark and Bacchiani, 2003; McClosky et al., 2006) or other semi-supervised learning methods (Blitzer et al., 2006; Nivre et al., 2007; Suzuki et al., 2009). Roark and Bacchiani (2003) also present work on supervised domain adaptation, although this focuses on the utilization of an already-existing indomain corpus. There has also been some work on efficient annotation of data for parsing (Tang et al., 2002; Osborne and Baldridge, 2004; Sassano and Kurohashi, 2010). Most previous work focuses on picking efficient sentences to annotate for parsing, but Sassano and Kurohashi (2010) also present a method for using partially annotated data with deterministic dependency parsers, which can be trivially estimated"
I11-1087,W06-2920,0,0.415876,"eature vector φ = hφ1 , φ2 , . . . , φm i is a vector of non-negative values calculated from features on pairs (x, j), with corresponding weights given by the parameter vector θ = hθ1 , θ2 , . . . , θm i. We estimate θ from sentences annotated with dependencies. It should be noted that the probability p(di ) depends only on i, j, and the inputs w, t, which ensures that it is estimated independently for each wi . Because paˆ rameter estimation does not involve computing d, 2 Pointwise estimation for dependency parsing This work follows the standard setting of recent work on dependency parsing (Buchholz and Marsi, 2006). Given as input a sequence of words, w = hw1 , w2 , . . . , wn i, the goal is to output a dependency tree d = hd1 , d2 , . . . , dn i, where di ≡ j when the head of wi is wj .1 We assume that di = 0 for some word wi in a sentence, which indicates that wi is the head of the sentence. we do not apply the maximum spanning tree algorithm in training. 2.1 A Pointwise MST Parser 2.2 Features The parsing model we pursue in this paper is McDonald et al. (2005)’s edge-factored model. A score, σ(di ), is assigned to each edge (i.e. dependency) di , and parsing finds a dependency tree, ˆ that maximizes"
I11-1087,W01-0521,0,0.0265859,"s trained on fully annotated data. 1 Introduction Parsing is one of the fundamental building blocks of natural language processing, with applications ranging from machine translation (Yamada and Knight, 2001) to information extraction (Miyao et al., 2009). However, while statistical parsers achieve higher and higher accuracies on in-domain text, the creation of data to train these parsers is labor-intensive, which becomes a bottleneck for smaller languages. In addition, it is also a well known fact that accuracy plummets when tested on sentences of a different domain than the training corpus (Gildea, 2001; Petrov et al., 2010), and that in-domain data can be annotated to make up for this weakness. In this paper, we propose a maximum spanning tree (MST) parser that helps ameliorate these problems by allowing for the efficient development of training data. This is done through a combination of an efficient corpus annotation strategy, and a novel parsing method. For corpus construction, we use partial annotation, which allows an 776 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 776–784, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP by the"
I11-1087,W07-1522,0,0.0314663,"ormed, out of all possible annotations to have annotators 2 We take a language-independent approach that does not make any assumptions about the unit of tokenization or the meaning of tags used. 778 ID 01 02 03 04 05 06 07 phrase-based dependency corpus (fully annotated) head phrase 02 党内/noun の/part. ? 07 議論/noun は /part. 04 「 /symbol 保守/noun ? 05 二/noun 党/suff. 論/noun は /part. ? 06 よろし /adj. く/infl. な/adj. い/infl. 。/symbol 」/symbol と /part. ? 07 い/verb う/infl. ? – もの/noun だ /aux. 。/symbol Figure 2: An example of phrase-based dependency annotation for a sentence. the NAIST Text Corpus (NTC) (Iida et al., 2007) to create a small partially-annotated target domain corpus. The NTC consists of newspaper articles from the Mainichi Shimbun.3 Figure 2 shows an example sentence from this corpus annotated with phrase dependencies. To aid the construction of conversion rules, we chose three broad categories of words - content words, function words, and punctuation symbols - that provide clues to the structure of a phrase. Before we explain our rules, we will give a short explanation of these three categories. We defined content words as nouns, verbs, adjectives, interjections, prenominal adjectives, suffixes,"
I11-1087,W02-2016,0,0.511521,"ave no labels because almost all nouns are connected to a verb with a case marker and many important labels are obvious. The words are not annotated with POS tags, so we used a Japanese POS tagger, KyTea (Neubig et al., 2011), trained on about 40k sentences from the BCCWJ (Maekawa, 2008). For the general domain experiments we compared the following systems, using projective parsing algorithms for training because of the assumptions about Japanese parsing outlined in Section 2.1. Theoretically the training time of our method is proportional to the number of annotated dependencies. In line with Kudo and Matsumoto (2002), we make two assumptions about Japanese dependency parsing. First, because Japanese is a headfinal language we assume that every word except the final one in a sentence depends on one of the words located to its right. Second, we assume that all dependencies are projective, in other words that edges in the dependency tree do not cross each other. These assumptions limit the number of candidate heads for a word, reducing the training time. Because all parsers were trained with projective algorithms, the first assumption is most likely the main reason for the difference in training times betwee"
I11-1087,N04-1012,0,0.0282352,"nificant amount of work on how to utilize in-domain data to improve the accuracy of parsing. The majority of this work has focused on using unlabeled data in combination with self-training (Roark and Bacchiani, 2003; McClosky et al., 2006) or other semi-supervised learning methods (Blitzer et al., 2006; Nivre et al., 2007; Suzuki et al., 2009). Roark and Bacchiani (2003) also present work on supervised domain adaptation, although this focuses on the utilization of an already-existing indomain corpus. There has also been some work on efficient annotation of data for parsing (Tang et al., 2002; Osborne and Baldridge, 2004; Sassano and Kurohashi, 2010). Most previous work focuses on picking efficient sentences to annotate for parsing, but Sassano and Kurohashi (2010) also present a method for using partially annotated data with deterministic dependency parsers, which can be trivially estimated from partially annotated data. 782 Parsing Accuracy on NKN-test 0.900 Dependency Accuracy Dependency Accuracy 0.970 0.965 0.960 0.955 Malt MST PW 0.950 0 40000 80000 0.890 0.880 0.870 0.860 0.850 0.840 120000 baseline LAST PAREN FFS CF INFLECT FUNCT all Dependency Conversion Rule Training Set Size (Dependencies) Figure 5:"
I11-1087,I08-7018,0,0.0315213,"nually and all the words are annotated with their heads manually. The Japanese data provided by the CoNLL organizers (Buchholz and Marsi, 2006) are the result of an automatic conversion from phrase (bunsetsu) dependencies. For a more appropriate evaluation we have prepared a word-based dependency data set. The dependencies have no labels because almost all nouns are connected to a verb with a case marker and many important labels are obvious. The words are not annotated with POS tags, so we used a Japanese POS tagger, KyTea (Neubig et al., 2011), trained on about 40k sentences from the BCCWJ (Maekawa, 2008). For the general domain experiments we compared the following systems, using projective parsing algorithms for training because of the assumptions about Japanese parsing outlined in Section 2.1. Theoretically the training time of our method is proportional to the number of annotated dependencies. In line with Kudo and Matsumoto (2002), we make two assumptions about Japanese dependency parsing. First, because Japanese is a headfinal language we assume that every word except the final one in a sentence depends on one of the words located to its right. Second, we assume that all dependencies are"
I11-1087,D10-1069,0,0.0304919,"ully annotated data. 1 Introduction Parsing is one of the fundamental building blocks of natural language processing, with applications ranging from machine translation (Yamada and Knight, 2001) to information extraction (Miyao et al., 2009). However, while statistical parsers achieve higher and higher accuracies on in-domain text, the creation of data to train these parsers is labor-intensive, which becomes a bottleneck for smaller languages. In addition, it is also a well known fact that accuracy plummets when tested on sentences of a different domain than the training corpus (Gildea, 2001; Petrov et al., 2010), and that in-domain data can be annotated to make up for this weakness. In this paper, we propose a maximum spanning tree (MST) parser that helps ameliorate these problems by allowing for the efficient development of training data. This is done through a combination of an efficient corpus annotation strategy, and a novel parsing method. For corpus construction, we use partial annotation, which allows an 776 Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 776–784, c Chiang Mai, Thailand, November 8 – 13, 2011. 2011 AFNLP by the maximum spanning tree"
I11-1087,P06-1043,0,0.0492846,"measured the results in the same way as the individual rules. The total size of the partial annotation pool produced by using all rules was 248,148 dependencies out of 1,010,648 annotation candidates (not counting the last word of sentences, which has no dependency). The baseline case only used the EHJ-train with no partial annotations from the 5 Related Work There has been a significant amount of work on how to utilize in-domain data to improve the accuracy of parsing. The majority of this work has focused on using unlabeled data in combination with self-training (Roark and Bacchiani, 2003; McClosky et al., 2006) or other semi-supervised learning methods (Blitzer et al., 2006; Nivre et al., 2007; Suzuki et al., 2009). Roark and Bacchiani (2003) also present work on supervised domain adaptation, although this focuses on the utilization of an already-existing indomain corpus. There has also been some work on efficient annotation of data for parsing (Tang et al., 2002; Osborne and Baldridge, 2004; Sassano and Kurohashi, 2010). Most previous work focuses on picking efficient sentences to annotate for parsing, but Sassano and Kurohashi (2010) also present a method for using partially annotated data with de"
I11-1087,N03-1027,0,0.0339771,"word-based dependencies and measured the results in the same way as the individual rules. The total size of the partial annotation pool produced by using all rules was 248,148 dependencies out of 1,010,648 annotation candidates (not counting the last word of sentences, which has no dependency). The baseline case only used the EHJ-train with no partial annotations from the 5 Related Work There has been a significant amount of work on how to utilize in-domain data to improve the accuracy of parsing. The majority of this work has focused on using unlabeled data in combination with self-training (Roark and Bacchiani, 2003; McClosky et al., 2006) or other semi-supervised learning methods (Blitzer et al., 2006; Nivre et al., 2007; Suzuki et al., 2009). Roark and Bacchiani (2003) also present work on supervised domain adaptation, although this focuses on the utilization of an already-existing indomain corpus. There has also been some work on efficient annotation of data for parsing (Tang et al., 2002; Osborne and Baldridge, 2004; Sassano and Kurohashi, 2010). Most previous work focuses on picking efficient sentences to annotate for parsing, but Sassano and Kurohashi (2010) also present a method for using partiall"
I11-1087,H05-1066,0,0.196071,"Missing"
I11-1087,P10-1037,0,0.259285,", Yusuke Miyao2 , Graham Neubig1 , Shinsuke Mori1 1 Graduate School of Informatics, Kyoto University Yoshida Honmachi, Sakyo-ku, Kyoto, Japan 2 National Institute of Informatics 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo, Japan flannery@ar.media.kyoto-u.ac.jp, yusuke@nii.ac.jp, neubig@ar.media.kyoto-u.ac.jp, forest@i.kyoto-u.ac.jp Abstract annotator to skip annotation of unnecessary edges, focusing their efforts only on the ones that will provide the maximal gains in accuracy. While partial annotation has been shown to be an effective annotation strategy for a number of tasks (Tsuboi et al., 2008; Sassano and Kurohashi, 2010; Neubig and Mori, 2010), traditional MST parsers such as that of McDonald et al. (2005) cannot be learned from partially annotated data. The reason for this is that they use structural prediction methods that must be learned from fully annotated sentences. However, a number of recent works (Liang et al., 2008; Neubig et al., 2011) have found that it is possible to ignore structure and still achieve competitive accuracy on tasks such as part-of-speech (POS) tagging. Similarly, recent work on dependency parsing (Spreyer and Kuhn, 2009; Spreyer et al., 2010) has shown that training constraints c"
I11-1087,W09-1104,0,0.127786,"on strategy for a number of tasks (Tsuboi et al., 2008; Sassano and Kurohashi, 2010; Neubig and Mori, 2010), traditional MST parsers such as that of McDonald et al. (2005) cannot be learned from partially annotated data. The reason for this is that they use structural prediction methods that must be learned from fully annotated sentences. However, a number of recent works (Liang et al., 2008; Neubig et al., 2011) have found that it is possible to ignore structure and still achieve competitive accuracy on tasks such as part-of-speech (POS) tagging. Similarly, recent work on dependency parsing (Spreyer and Kuhn, 2009; Spreyer et al., 2010) has shown that training constraints can be relaxed to allow MST parsers to be trained from partially annotated sentences, with only a small reduction in parsing accuracy. In this approach the scoring function used to evaluate potential dependency trees is modified so that it does not penalize trees consistent with the partial annotations used for training. Our formulation of an MST parser is based on an even stronger independence assumption, namely that the score of each edge is independent of the other edges in the dependency tree. While this does have the potential to"
I11-1087,2008.amta-papers.15,0,0.050818,"Missing"
I11-1087,spreyer-etal-2010-training,0,0.34034,"of tasks (Tsuboi et al., 2008; Sassano and Kurohashi, 2010; Neubig and Mori, 2010), traditional MST parsers such as that of McDonald et al. (2005) cannot be learned from partially annotated data. The reason for this is that they use structural prediction methods that must be learned from fully annotated sentences. However, a number of recent works (Liang et al., 2008; Neubig et al., 2011) have found that it is possible to ignore structure and still achieve competitive accuracy on tasks such as part-of-speech (POS) tagging. Similarly, recent work on dependency parsing (Spreyer and Kuhn, 2009; Spreyer et al., 2010) has shown that training constraints can be relaxed to allow MST parsers to be trained from partially annotated sentences, with only a small reduction in parsing accuracy. In this approach the scoring function used to evaluate potential dependency trees is modified so that it does not penalize trees consistent with the partial annotations used for training. Our formulation of an MST parser is based on an even stronger independence assumption, namely that the score of each edge is independent of the other edges in the dependency tree. While this does have the potential to decrease accuracy, it"
I11-1087,neubig-mori-2010-word,1,0.85591,"ig1 , Shinsuke Mori1 1 Graduate School of Informatics, Kyoto University Yoshida Honmachi, Sakyo-ku, Kyoto, Japan 2 National Institute of Informatics 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo, Japan flannery@ar.media.kyoto-u.ac.jp, yusuke@nii.ac.jp, neubig@ar.media.kyoto-u.ac.jp, forest@i.kyoto-u.ac.jp Abstract annotator to skip annotation of unnecessary edges, focusing their efforts only on the ones that will provide the maximal gains in accuracy. While partial annotation has been shown to be an effective annotation strategy for a number of tasks (Tsuboi et al., 2008; Sassano and Kurohashi, 2010; Neubig and Mori, 2010), traditional MST parsers such as that of McDonald et al. (2005) cannot be learned from partially annotated data. The reason for this is that they use structural prediction methods that must be learned from fully annotated sentences. However, a number of recent works (Liang et al., 2008; Neubig et al., 2011) have found that it is possible to ignore structure and still achieve competitive accuracy on tasks such as part-of-speech (POS) tagging. Similarly, recent work on dependency parsing (Spreyer and Kuhn, 2009; Spreyer et al., 2010) has shown that training constraints can be relaxed to allow M"
I11-1087,D09-1058,0,0.0158008,"produced by using all rules was 248,148 dependencies out of 1,010,648 annotation candidates (not counting the last word of sentences, which has no dependency). The baseline case only used the EHJ-train with no partial annotations from the 5 Related Work There has been a significant amount of work on how to utilize in-domain data to improve the accuracy of parsing. The majority of this work has focused on using unlabeled data in combination with self-training (Roark and Bacchiani, 2003; McClosky et al., 2006) or other semi-supervised learning methods (Blitzer et al., 2006; Nivre et al., 2007; Suzuki et al., 2009). Roark and Bacchiani (2003) also present work on supervised domain adaptation, although this focuses on the utilization of an already-existing indomain corpus. There has also been some work on efficient annotation of data for parsing (Tang et al., 2002; Osborne and Baldridge, 2004; Sassano and Kurohashi, 2010). Most previous work focuses on picking efficient sentences to annotate for parsing, but Sassano and Kurohashi (2010) also present a method for using partially annotated data with deterministic dependency parsers, which can be trivially estimated from partially annotated data. 782 Parsin"
I11-1087,P11-2093,1,0.923583,"otator to skip annotation of unnecessary edges, focusing their efforts only on the ones that will provide the maximal gains in accuracy. While partial annotation has been shown to be an effective annotation strategy for a number of tasks (Tsuboi et al., 2008; Sassano and Kurohashi, 2010; Neubig and Mori, 2010), traditional MST parsers such as that of McDonald et al. (2005) cannot be learned from partially annotated data. The reason for this is that they use structural prediction methods that must be learned from fully annotated sentences. However, a number of recent works (Liang et al., 2008; Neubig et al., 2011) have found that it is possible to ignore structure and still achieve competitive accuracy on tasks such as part-of-speech (POS) tagging. Similarly, recent work on dependency parsing (Spreyer and Kuhn, 2009; Spreyer et al., 2010) has shown that training constraints can be relaxed to allow MST parsers to be trained from partially annotated sentences, with only a small reduction in parsing accuracy. In this approach the scoring function used to evaluate potential dependency trees is modified so that it does not penalize trees consistent with the partial annotations used for training. Our formula"
I11-1087,P02-1016,0,0.19976,"here has been a significant amount of work on how to utilize in-domain data to improve the accuracy of parsing. The majority of this work has focused on using unlabeled data in combination with self-training (Roark and Bacchiani, 2003; McClosky et al., 2006) or other semi-supervised learning methods (Blitzer et al., 2006; Nivre et al., 2007; Suzuki et al., 2009). Roark and Bacchiani (2003) also present work on supervised domain adaptation, although this focuses on the utilization of an already-existing indomain corpus. There has also been some work on efficient annotation of data for parsing (Tang et al., 2002; Osborne and Baldridge, 2004; Sassano and Kurohashi, 2010). Most previous work focuses on picking efficient sentences to annotate for parsing, but Sassano and Kurohashi (2010) also present a method for using partially annotated data with deterministic dependency parsers, which can be trivially estimated from partially annotated data. 782 Parsing Accuracy on NKN-test 0.900 Dependency Accuracy Dependency Accuracy 0.970 0.965 0.960 0.955 Malt MST PW 0.950 0 40000 80000 0.890 0.880 0.870 0.860 0.850 0.840 120000 baseline LAST PAREN FFS CF INFLECT FUNCT all Dependency Conversion Rule Training Set"
I11-1087,C04-1010,0,0.012227,"otations used for training. Our formulation of an MST parser is based on an even stronger independence assumption, namely that the score of each edge is independent of the other edges in the dependency tree. While this does have the potential to decrease accuracy, it has a number of advantages such as the ability to use partially annotated data, faster speed, and simple implementation. We perform an evaluation of the proposed method on a Japanese dependency parsing task. First, we compare the proposed method to both a traditional MST parser (McDonald et al., 2005), and a deterministic parser (Nivre and Scholz, 2004). We find that despite the lack of structure in our prediction method, the proposed method is still able to achieve accuracy similar to that of We introduce a maximum spanning tree (MST) dependency parser that can be trained from partially annotated corpora, allowing for effective use of available linguistic resources and reduction of the costs of preparing new training data. This is especially important for domain adaptation in a real-world situation. We use a pointwise approach where each edge in the dependency tree for a sentence is estimated independently. Experiments on Japanese dependenc"
I11-1087,C08-1113,1,0.837066,"ora Daniel Flannery1 , Yusuke Miyao2 , Graham Neubig1 , Shinsuke Mori1 1 Graduate School of Informatics, Kyoto University Yoshida Honmachi, Sakyo-ku, Kyoto, Japan 2 National Institute of Informatics 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo, Japan flannery@ar.media.kyoto-u.ac.jp, yusuke@nii.ac.jp, neubig@ar.media.kyoto-u.ac.jp, forest@i.kyoto-u.ac.jp Abstract annotator to skip annotation of unnecessary edges, focusing their efforts only on the ones that will provide the maximal gains in accuracy. While partial annotation has been shown to be an effective annotation strategy for a number of tasks (Tsuboi et al., 2008; Sassano and Kurohashi, 2010; Neubig and Mori, 2010), traditional MST parsers such as that of McDonald et al. (2005) cannot be learned from partially annotated data. The reason for this is that they use structural prediction methods that must be learned from fully annotated sentences. However, a number of recent works (Liang et al., 2008; Neubig et al., 2011) have found that it is possible to ignore structure and still achieve competitive accuracy on tasks such as part-of-speech (POS) tagging. Similarly, recent work on dependency parsing (Spreyer and Kuhn, 2009; Spreyer et al., 2010) has show"
I11-1087,nivre-etal-2006-maltparser,0,0.360234,"d, reducing the training time. Because all parsers were trained with projective algorithms, the first assumption is most likely the main reason for the difference in training times between PW and MST. For other languages where possible heads can be located both to the left and right of a word, we expect training times to increase. Our pointwise approach can be extended to handle these languages by changing the constraint on heads from j > i to j 6= i for all di = j. This is an important direction for future work now that we have confirmed that this approach is effective for Japanese. 1. Malt: Nivre et al. (2006)’s MaltParser, using Nivre’s arc-eager algorithm and the option for strict root handling. 2. MST: McDonald et al. (2005)’s MST Parser, using k-best parse size with k=5. 3. PW: Our system, where pointwise estimation is used to estimate dependencies. Stochastic gradient descent training was used to train log-linear models. We performed a second experiment in the general domain to measure the impact of the training corpus size on parsing accuracy. To make smaller training corpora, we set a fixed number of dependency annotations and then sequentially selected sentences from EHJ-train until the des"
I11-1087,P01-1067,0,0.118633,"ources and reduction of the costs of preparing new training data. This is especially important for domain adaptation in a real-world situation. We use a pointwise approach where each edge in the dependency tree for a sentence is estimated independently. Experiments on Japanese dependency parsing show that this approach allows for rapid training and achieves accuracy comparable to state-ofthe-art dependency parsers trained on fully annotated data. 1 Introduction Parsing is one of the fundamental building blocks of natural language processing, with applications ranging from machine translation (Yamada and Knight, 2001) to information extraction (Miyao et al., 2009). However, while statistical parsers achieve higher and higher accuracies on in-domain text, the creation of data to train these parsers is labor-intensive, which becomes a bottleneck for smaller languages. In addition, it is also a well known fact that accuracy plummets when tested on sentences of a different domain than the training corpus (Gildea, 2001; Petrov et al., 2010), and that in-domain data can be annotated to make up for this weakness. In this paper, we propose a maximum spanning tree (MST) parser that helps ameliorate these problems b"
I11-1087,D07-1096,0,\N,Missing
I13-1126,neubig-mori-2010-word,1,0.931736,"ly Annotated Corpora Koichiro Yoshino, Shinsuke Mori, Tatsuya Kawahara School of Informatics, Kyoto University Yoshida-Honmachi, Sakyo-ku, Kyoto 606-8501, Japan yoshino@ar.media.kyoto-u.ac.jp Abstract in target domain is not available in realistic cases, and it is difficult to apply the current supervised approaches to a new domain. When annotating only the domain-specific area, the use of a partially annotated corpus (Tsuboi et al., 2008; Sassano and Kurohashi, 2010) that allows incomplete annotations improves accuracy efficiently and reduce the number of annotations. The pointwise approach (Neubig and Mori, 2010) enables efficient use of such incomplete language resources in word segmentation tasks and requires only partial annotations for the relevant tasks and lower layer annotations on which they depend. We design a new P-A structure analysis method that enables us to directly estimate semantic role labels by referring to a model that is trained from a corpus that includes only partially annotated tag information without word dependencies. We present a novel scheme of predicate argument structure analysis that can be trained from partially annotated corpora. In order to allow partial annotation, th"
I13-1126,P11-2093,1,0.867501,"ted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al. (2011) report that a comparable accuracy to a CRF-based sequential labeling method can be achieved without referring to the estimated labels for unlabeled words. They call this method a pointwise approach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring to a model that is trained from a corpus. It"
I13-1126,J05-1004,0,0.0429399,"ain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was"
I13-1126,J08-2006,0,0.0262757,"ls (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanabe et al., 2010). However, this pre-annotation incurs high annotation costs which prevent us from adapting the analyzer to new domains. Having training data that are representative of a domain is essential for constructing a robust semantic role labeler (Pradhan et al., 2008) because the important information structures are specific to each domain (R.Grishman, 2003). Fully annotated corpus 2 Predicate argument structure analysis In this section, we give a brief explanation of PA structure and its problems. Then, we describe the typical method of structural prediction for this task based on supervised machine learning. 2.1 Predicate-argument (P-A) structure A predicate-argument (P-A) structure is a relationship between a verbal expression and its arguments, such as the subject, the direct object, and the indirect object. Predicate P in a document D has arguments A1"
I13-1126,D09-1151,0,0.0211451,"ostly and difficult for untrained annotators. This difficulty interferes with efficient language resource preparation and reduces domain portability. However, the accuracy of P-A structure analysis increases in accordance with the data size. This indicates that we can realize an improvement just by easily preparing more training data for the target domain document. 2.2 Typical solution The typical solution divides the P-A structure prediction into two problems: semantic role labeling (SRL) (Johansson and Nugues, 2008; Bj¨orkelund et al., 2009) and zero-anaphora resolution (Iida et al., 2007a; Sasano and Kurohashi, 2009). The typical approach requires three preprocessing steps: word segmentation, POS tagging, and dependency parsing. After the preprocessing, the task of SRL improves assigning semantic role labels to the edges in word dependencies. A semantic role labeler performs two tasks: predicate sense estimation, and SRL. Zeroanaphora resolution is treated as an independent problem from the SRL task in the previous research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is a gap in a sentence that has an anaphoric function (Iida et al., 2007a). Some semantic relationships exi"
I13-1126,I11-1085,0,0.314177,"ble 2 and 3. Evaluations that are classified with the existing depend and zero property are given in Table 2. Classifiers used in “w.o. feat. (3)” do not refer to case existence features (the binary feature (3) in Table 1). We can see that case frames play a large role in improving the labeling accuracy. This depend and zero property is based on the dependency, which cannot be referred to in the pointwise approach. As an alternative, we used sentence boundaries for the tag classification and Table 3 shows the result. The bottom “cf.” rows in Tables 2 and 3 are the result of the previous work (Sasano and Kurohashi, 2011) for comparison1 . In the comparison, the accuracies of our work are comparable to the accuracies of the previous work. By comparing the total F mea6 Conclusion We presented a novel scheme of P-A structure analysis based on the pointwise approach that makes it possible to use partially annotated corpora. This paper can be seen as an extension of the pointwise approach to a higher NLP layer that allows us to concentrate annotation work on the focused task. The results indicated that our scheme reduces the cost of constructing language resource and makes it easy to adapt the P-A structure analyz"
I13-1126,C08-1097,0,0.331007,"o the type of the predicate. This predicate and semantic case behavior strongly affects the SRL task. The oracle of the case existence is used for SRL features. For example, the predicate “bet” in Figure 5 contains information indicating that the predicate has two kinds of argument: “subject, zero” and “direct object depend.” We assume that the case existence for each predicate can be estimated with case frames (Kawahara and Kurohashi, 2006). A case frame is a set of a predicate and its potential arguments. It is known that the case frames contribute to the P-A structure analysis performance (Sasano et al., 2008). 5 Evaluations We conducted three experiments to evaluate the proposed method: SRL, corpus size discrimination, and domain adaptation. 4.2 SRL and zero-anaphora resolution The second step is SRL that includes zeroanaphora resolution. We handle the problem with a direct approach for SRL that is redefined as a binary classification problem for the pair of an argument candidate and a predicate. Labeled pairs of argument (arg) and predicate (pred) are used as positive training example and unlabeled pairs are used as negative training example. In the example of Figure 5, the pair of “fate” and “pa"
I13-1126,P10-1037,0,0.0270079,"ach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring to a model that is trained from a corpus. It includes only partially annotated POS tags but not with dependency information for the following reasons. Automatic estimation of POS tags achieves high accuracy in domain adaptation cases, and the annotation cost is small (Neubig et al., 2011), but the accuracy for dependency parsing (Flannery et al., 2011; Sassano and Kurohashi, 2010) is not sufficiently high. However, handcraft annotation cost of dependency is so high, and it disturbs rapid preparation of annotation data. We show an example of a partially annotated corpus in Figure 2. The annotation of “reach” is incomplete, and the information that can be referred to by an analyzer is the fully annotated word boundaries, POS tags, and partially annotated P-A tags. Word boundaries and POS tags are output by 2.3 Open problems in P-A structure analysis Existing approaches require full annotation of word boundaries, POS tags, and word dependencies to use them as features. Mo"
I13-1126,D07-1002,0,0.0609882,"novel scheme of predicate argument structure analysis that can be trained from partially annotated corpora. In order to allow partial annotation, this semantic role labeler does not require word dependency information. The advantage of partial annotation is that it allows for smooth domain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Ha"
I13-1126,W08-2121,0,0.0352448,"Missing"
I13-1126,C12-1161,0,0.0232894,"Missing"
I13-1126,C08-1113,1,0.850905,"fill in the words that are semantically omitted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al. (2011) report that a comparable accuracy to a CRF-based sequential labeling method can be achieved without referring to the estimated labels for unlabeled words. They call this method a pointwise approach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring"
I13-1126,D09-1082,0,0.0288546,"analysis that can be trained from partially annotated corpora. In order to allow partial annotation, this semantic role labeler does not require word dependency information. The advantage of partial annotation is that it allows for smooth domain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous app"
I13-1126,P10-2018,0,0.279139,", 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanabe et al., 2010). However, this pre-annotation incurs high annotation costs which prevent us from adapting the analyzer to new domains. Having training data that are representative of a domain is essential for constructing a robust semantic role labeler (Pradhan et al., 2008) because the important information structures are specific to each domain (R.Grishman, 2003). Fully annotated corpus 2 Predicate argument structure analysis In this section, we give a brief explanation of PA structure and its problems. Then, we describe the typical method of structural prediction for this task based on supervised machine"
I13-1126,W11-2008,1,0.843432,"corpora. In order to allow partial annotation, this semantic role labeler does not require word dependency information. The advantage of partial annotation is that it allows for smooth domain adaptation of training data and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotati"
I13-1126,C12-1183,1,0.890997,"Missing"
I13-1126,P98-1013,0,0.0247373,"and improves the adaptability to a variety of domains. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanab"
I13-1126,W09-1206,0,0.0577077,"Missing"
I13-1126,I11-1087,1,0.84542,"ethod a pointwise approach. Even with the pointwise assumption, we can estimate labels as accurately as sequential labeling just by referring to the appropriate features. We design a P-A structure analyzer that directly estimates the semantic role labels by referring to a model that is trained from a corpus. It includes only partially annotated POS tags but not with dependency information for the following reasons. Automatic estimation of POS tags achieves high accuracy in domain adaptation cases, and the annotation cost is small (Neubig et al., 2011), but the accuracy for dependency parsing (Flannery et al., 2011; Sassano and Kurohashi, 2010) is not sufficiently high. However, handcraft annotation cost of dependency is so high, and it disturbs rapid preparation of annotation data. We show an example of a partially annotated corpus in Figure 2. The annotation of “reach” is incomplete, and the information that can be referred to by an analyzer is the fully annotated word boundaries, POS tags, and partially annotated P-A tags. Word boundaries and POS tags are output by 2.3 Open problems in P-A structure analysis Existing approaches require full annotation of word boundaries, POS tags, and word dependenci"
I13-1126,E09-1026,0,0.0472369,"Missing"
I13-1126,J95-2003,0,0.221772,"a positive example Y, and pairs of “fate” and other candidates are negative examples N. The features used for classification are listed in Table 1. We use simple n-gram features based on words and POS tags. The pairwise features are POS pairs located at positions from -2 to +2, and pairs of the predicate and the argument candidates. The distance between the argument candidate and the predicate is used as a feature. We used the number of predicates between the predicate and the argument candidate as this feature. Binary features (1) and (2) are based on a previous study on “Centering” theory (Grosz et al., 1995). In this theory, subjects are frequently omitted, and the first candidate tends to be a subject. By contrast, objects are not omitted, and the last candidate tends to be an object. To apply the theory to a pointwise approach, we define features that are independent of syntactic structure. Finally, the result of the processing described above is used as a binary feature (3). Table 1: Features of SRL: wp is a predicate, wa is an argument candidate, ti is the POS tag of wi . type word 1-gram word 2-gram word 3-gram POS 1-gram POS 2-gram POS 3-gram pairwise distance binary feature wp−3 ,wp−2 ,wp−"
I13-1126,W09-1201,0,0.0244114,"Missing"
I13-1126,I11-1023,0,0.101367,"ious research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is a gap in a sentence that has an anaphoric function (Iida et al., 2007a). Some semantic relationships exist in which there is no dependency relationship between their arguments and predicates; this is called zero anaphora. The task of P-A structure analysis goes beyond the syntactic problem and comes down to a semantic problem to fill in the words that are semantically omitted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al. (2011) report that a comp"
I13-1126,P11-1081,0,0.172638,"he SRL task in the previous research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is a gap in a sentence that has an anaphoric function (Iida et al., 2007a). Some semantic relationships exist in which there is no dependency relationship between their arguments and predicates; this is called zero anaphora. The task of P-A structure analysis goes beyond the syntactic problem and comes down to a semantic problem to fill in the words that are semantically omitted. Various special approaches can be applied after SRL to solve this problem (Sasano and Kurohashi, 2009; Iida and Poesio, 2011; Hayashibe et al., 2011). Some approaches adopt a Salience Reference List (Nariyama, 2002) based on the 1-best argument decision model. 3 Partial annotation for P-A structures Partial annotation allows annotators to focus on efficient examples in the target domain document, and to maximize the cost-effectiveness of annotation. For automatic word segmentation and POS tagging, the scheme allows partial annotation of corpus (Tsuboi et al., 2008; Neubig and Mori, 2010; Neubig et al., 2011) and achieves high accuracy and domain portability though annotation of domain-specific areas. Neubig et al."
I13-1126,W07-1522,0,0.250021,"ins. 1 Introduction The predicate-argument (P-A) structure is one of the most fundamental and important representations in linguistics (Fillmore, 1968). Many applications use P-A structure as a component, for example, QA systems (Shen and Lapata, 2007), text mining systems (Wang and Zhang, 2009), and a spoken dialogue systems (Yoshino et al., 2011). P-A structure analysis is regarded as a task of semantic role labeling (SRL). A semantic role represents a meaning of the components in P-A structure (i.e. Propbank (Palmer et al., 2005), FrameNet (Baker et al., 1998), and NAIST Text Corpus (NTC) (Iida et al., 2007b)). Traditional P-A structure analyzers estimate the semantic role labels for an input sentence by referring to a model trained on data annotated with not only semantic role labels but also dependency labels (Surdeanu et al., 2008; Hajiˇc et al., 2009). Most of the previous approaches to P-A structure analysis assume full annotation for P-A structures and the lower layer labels: word boundaries, parts of speech (POS), and dependencies. Given a corpus fully annotated with them, the structural prediction approach was shown to be effective (Watanabe et al., 2010). However, this pre-annotation in"
I13-1126,D08-1008,0,0.0130355,"re analyzer, we need to annotate the entire document. To make it worse, these kinds of annotations are costly and difficult for untrained annotators. This difficulty interferes with efficient language resource preparation and reduces domain portability. However, the accuracy of P-A structure analysis increases in accordance with the data size. This indicates that we can realize an improvement just by easily preparing more training data for the target domain document. 2.2 Typical solution The typical solution divides the P-A structure prediction into two problems: semantic role labeling (SRL) (Johansson and Nugues, 2008; Bj¨orkelund et al., 2009) and zero-anaphora resolution (Iida et al., 2007a; Sasano and Kurohashi, 2009). The typical approach requires three preprocessing steps: word segmentation, POS tagging, and dependency parsing. After the preprocessing, the task of SRL improves assigning semantic role labels to the edges in word dependencies. A semantic role labeler performs two tasks: predicate sense estimation, and SRL. Zeroanaphora resolution is treated as an independent problem from the SRL task in the previous research. The zero-anaphora problem is caused by the ellipsis of shared words, and it is"
I13-1126,N06-1023,0,0.0254209,"es that are clearly annotated. 4.1 Case existence detection The first step in the proposed sequential analysis is case existence estimation. The given semantic cases differ according to the type of the predicate. This predicate and semantic case behavior strongly affects the SRL task. The oracle of the case existence is used for SRL features. For example, the predicate “bet” in Figure 5 contains information indicating that the predicate has two kinds of argument: “subject, zero” and “direct object depend.” We assume that the case existence for each predicate can be estimated with case frames (Kawahara and Kurohashi, 2006). A case frame is a set of a predicate and its potential arguments. It is known that the case frames contribute to the P-A structure analysis performance (Sasano et al., 2008). 5 Evaluations We conducted three experiments to evaluate the proposed method: SRL, corpus size discrimination, and domain adaptation. 4.2 SRL and zero-anaphora resolution The second step is SRL that includes zeroanaphora resolution. We handle the problem with a direct approach for SRL that is redefined as a binary classification problem for the pair of an argument candidate and a predicate. Labeled pairs of argument (ar"
I13-1126,kawahara-etal-2002-construction,0,0.0449111,"Missing"
I13-1126,N07-1070,0,\N,Missing
I13-1126,C98-1013,0,\N,Missing
I13-1126,2002.tmi-papers.15,0,\N,Missing
I17-1033,C16-1005,0,0.013223,"omatic caption generation have reported great results both in images (Xu et al., 2015; Karpathy and Fei-Fei, 2015; Johnson et al., 2016) and short video clips (Li et al., 2015; Donahue et al., 2015; Shetty and Laaksonen, 2016) by using convolutional neural network (CNN), recurrent neural network, and LSTM. (Venugopalan et al., 2015) improved the accuracy with a sequence to sequence model (Sutskever et al., 2014). In addi326 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 326–335, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP tion, (Laokulrat et al., 2016; Guo et al., 2016) also improved the accuracy of automatic caption generation by introducing an LSTM equipped with an attention mechanism. One of the features of these end-to-end models is that they directly generate sentences from videos without determining content words such as subjects and predicates. Common datasets (Lin et al., 2014; Chen and Dolan, 2011; Torabi et al., 2015; Rohrbach et al., 2015) made research on automatic caption generation popular. Table 1: Definition of r-NE tags. r-NE tag meaning F Food T Tool D Duration Q Quantity Ac Action by the chef Af Action by foods Sf State"
I17-1033,P11-1020,0,0.0131114,"sequence to sequence model (Sutskever et al., 2014). In addi326 Proceedings of the The 8th International Joint Conference on Natural Language Processing, pages 326–335, c Taipei, Taiwan, November 27 – December 1, 2017 2017 AFNLP tion, (Laokulrat et al., 2016; Guo et al., 2016) also improved the accuracy of automatic caption generation by introducing an LSTM equipped with an attention mechanism. One of the features of these end-to-end models is that they directly generate sentences from videos without determining content words such as subjects and predicates. Common datasets (Lin et al., 2014; Chen and Dolan, 2011; Torabi et al., 2015; Rohrbach et al., 2015) made research on automatic caption generation popular. Table 1: Definition of r-NE tags. r-NE tag meaning F Food T Tool D Duration Q Quantity Ac Action by the chef Af Action by foods Sf State of foods St State of tools Before the above end-to-end models succeeded, many researchers concentrated models generating sentences via content words or intermediate states (Guadarrama et al., 2013; Rohrbach et al., 2013). As an advantage of the technique of using intermediate states, object recognition or motion recognition model can be diverted as it is. Thus"
I17-1033,mori-etal-2014-flow,1,0.844436,"recipe/video pairs available for various researches. For example, the KUSK Dataset (Hashimoto et al., 2014), which we use in the experiments, contains recipes and their cooking videos. Note that the lengths of these cooking videos are about 20 minutes or more, which are much longer than video clips used in automatic video captioning researches. And also note that the texts are kinds of summaries mentioning only the necessary objects and actions to complete a certain mission. Such texts are intrinsically different from scene descriptions in automatic video (or image) captioning researches. in (Mori et al., 2014), whose types are listed in Table 1. There are eight r-NE tag types, but our CV part recognizes only foods (F) and tools (T). We use the notation “チンゲン 菜/F” (“qing-geng-cai/F”) to indicate that “チンゲン 菜” is an r-NE and its type is food (F)1 . 3.2 As we mentioned in Section 1, there is no large amount of video/sentence pairs available for our problem. But instead, in some cases, large textonly corpus is available in the domain. The corpus will allow us to train a generative model of the instruction sentences. 3.2.2 Named Entity Recognizer In order to develop a useful generative model we must loc"
I17-1033,P11-2093,1,0.80797,"s process is the r-NE sequence and the scores of the r-NEs. And the output is the recipe sentence candidate that maximizes the score for the given partial frame sequence (Figure 2 D). For the sentence candidate generation we use an LSTM language model. It outputs a sentence and its likelihood. Different from the ordinary LSTM, it takes a set of r-NEs as the input, but not a sequence. In addition, it is trained on the corpus in which r-NEs are recognized and replaced with rNE tags as summarized in Figure 4. The first step of its training is preprocessing, in which we conduct word segmentation (Neubig et al., 2011) (not necessary for English or some other languages) and r-NE recognition (Sasada et al., 2015) for each recipe sentence in the recipe corpus (Figure 4 A). Then we filter out sentences containing r-NEs other than Ac, F and T and delete Ac tags for the reasons below: is the sentence corresponding to it. The generation probability of a sentence is calculated by the following formula: PLSTM (r(e)|e) = Nd ∏ P (dk |d1 , d2 , ..., dk−1 ; e), k=1 where r(e) = d1 , d2 , ..., dNd is a word string and Nd is the length of the word string. And P (dk |d1 , d2 , ..., dk−1 ; e) denotes the generation probabi"
I17-1033,P02-1040,0,0.105163,"t if if you like and serve”) in the result. This sort of errors are caused by the LSTM language model. We may need a language model incorporating grammatical structures (Chelba and Jelinek, 2000). Despite the errors mentioned above, our method 5.1.5 Evaluation Metrics We generated a recipe for each of 16 cooking videos corresponding to seven recipes in KUSK Dataset. As we mentioned in Section 3 they are excluded from the training data. In order to investigate the effectiveness of P ({e})−l , we compared the results of the models with and without it. The evaluation metrics is BLEU (N = 1 ∼ 4) (Papineni et al., 2002) taking the original humanwritten recipes as the reference. The cooking actions in the KUSK Dataset video part were performed with following these recipes. Unlike BLEU calculation in MT, we treat the entire recipe, a sequence of sentences, as the unit instead of a single sentence. This is because one can describe the same actions in various ways with different number of sentences. An example pair is “cut onions and potatoes.” and “cut onions. then cut potatoes.” 5.2 Results and Discussion Since our task is quite novel and existing end-toend video captioning methods do not obviously work becaus"
L16-1105,C96-1058,0,0.0139411,"nt performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data are usually larger than those for DP especially in domain adaptation situations. In this paper we"
L16-1105,P12-1110,0,0.0171401,"In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data are usually larger than those for DP especially in domain adaptation situations. In this paper we assume that we want accurate DP results of raw texts in a new target domain and the method is language resource addition to each step because it is the easiest and sometimes most effective method for improving the accuracy. We p"
L16-1105,P10-1001,0,0.0130875,"lications. DP is, however, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data are usually larger than"
L16-1105,W02-2016,0,0.049668,"and to choose a suitable language resource addition strategy for the parsing accuracy improvement. Keywords: language resource addition, part-of-speech tagging, dependency parsing 1. Introduction For languages without clear word boundary natural language processing (NLP) , such as word segmentation (WS), part-of-speech (POS) tagging (PT), and dependency parsing (DP) is essential technology for applications such as machine translation or information extraction (Matsumoto et al., 2000; Kudo et al., 2004; Kurohashi et al., 1994; Neubig et al., 2011; Kurohashi and Nagao, 1994; Mori et al., 2000; Kudo and Matsumoto, 2002; Flannery et al., 2012). WS and PT are now sufficiently accurate and widely used in various applications. DP is, however, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchho"
L16-1105,W04-3230,0,0.0734595,"he parsing accuracy. So we conclude that it is important to check out the characteristics of the target domain and to choose a suitable language resource addition strategy for the parsing accuracy improvement. Keywords: language resource addition, part-of-speech tagging, dependency parsing 1. Introduction For languages without clear word boundary natural language processing (NLP) , such as word segmentation (WS), part-of-speech (POS) tagging (PT), and dependency parsing (DP) is essential technology for applications such as machine translation or information extraction (Matsumoto et al., 2000; Kudo et al., 2004; Kurohashi et al., 1994; Neubig et al., 2011; Kurohashi and Nagao, 1994; Mori et al., 2000; Kudo and Matsumoto, 2002; Flannery et al., 2012). WS and PT are now sufficiently accurate and widely used in various applications. DP is, however, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does"
L16-1105,I08-7018,0,0.165425,"istic than joint approaches. Actually for WS and PT available training data are usually larger than those for DP especially in domain adaptation situations. In this paper we assume that we want accurate DP results of raw texts in a new target domain and the method is language resource addition to each step because it is the easiest and sometimes most effective method for improving the accuracy. We propose several variations of language resource addition strategies and compare them in DP accuracy. In the experiments, we use core data of Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008) which has six sub-domains (Yahoo!Answers, white paper, Yahoo!Blog, book, magazine, and newspaper). We select white paper and Yahoo!Blog as target domains to investigate language resource addition strategies. The reason is that two domains have the lowest DP accuracies and the causes are different. At WS and PT steps, the possible language resources are word dictionaries and fully annotated corpora. At DP step, the language resource is fully annotated corpora. In the following sections, we briefly explain WS, PT, DP, and language resources for them. Then we experimentally compare the performan"
L16-1105,E06-1011,0,0.0668819,"012). WS and PT are now sufficiently accurate and widely used in various applications. DP is, however, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches."
L16-1105,H05-1066,0,0.0709613,"Missing"
L16-1105,W06-2932,0,0.0188762,"ly used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data are usually larger than those for DP especially in domain ada"
L16-1105,mori-neubig-2014-language,1,0.847877,"and fully annotated corpora. At DP step, the language resource is fully annotated corpora. In the following sections, we briefly explain WS, PT, DP, and language resources for them. Then we experimentally compare the performances in accuracy of DP from raw texts under various settings. Finally we discuss the strategies from the viewpoints of efficiency and cost. 2. Word Segmentation WS is the first step, which takes an unsegmented text as the input and segments it into a sequence of words. We adopt one of the state-of-art methods, pointwise method (Neubig and Mori, 2010; Neubig et al., 2011; Mori and Neubig, 2014). This method is capable of utilizing various types of language resources and thus useful in domain adaptation situations. 2.1. Method The pointwise word segmenter takes a sequence of characters x = x1 x2 · · · xn as input. Then it makes a classification at every point between two characters (decision point). Each classification is binary indicating whether there is a word boundary (Y) or not (N) as shown in Figure 2. Normally SVM (Fan et al., 2008) is used for classification referring to the features described in Table 1. They are derived from surrounding characters x = xi−m+1 xi−m+2 · · · xi"
L16-1105,C00-1081,1,0.450511,"f the target domain and to choose a suitable language resource addition strategy for the parsing accuracy improvement. Keywords: language resource addition, part-of-speech tagging, dependency parsing 1. Introduction For languages without clear word boundary natural language processing (NLP) , such as word segmentation (WS), part-of-speech (POS) tagging (PT), and dependency parsing (DP) is essential technology for applications such as machine translation or information extraction (Matsumoto et al., 2000; Kudo et al., 2004; Kurohashi et al., 1994; Neubig et al., 2011; Kurohashi and Nagao, 1994; Mori et al., 2000; Kudo and Matsumoto, 2002; Flannery et al., 2012). WS and PT are now sufficiently accurate and widely used in various applications. DP is, however, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languag"
L16-1105,mori-etal-2014-japanese,1,0.829802,"he dependency relationships among all its words. Thus it implies that the sentence is divided into words but it does not need POSs for the words. 5. Strategy Comparison In order to obtain knowledge of language resource addition strategy, we measured the contributions to the parsing accuracy of language resource additions to the sub-steps. In this section, we first describe the settings of experiments, then evaluate their results, and finally discuss the strategies. 5.1. Language Resources For the experiments, we used a part of BCCWJ (Maekawa, 2008) annotated with dependency trees provided by (Mori et al., 2014). Thus the sentences are divided into words annotated with POS tags and tree structures. BCCWJ has six sub-domains (Yahoo!Answers, white paper, Yahoo!Blog, book, magazine, and newspaper). We divided each of them into a training and test part (Table 4). We also use a dictionary, UniDic (Den et al., 2007), containing 234,653 wordPOS pairs. We separated inflectional endings from the stems. 5.2. Evaluation Criteria The PT evaluation criterion is the same as morphological analysis F-measure (Nagata, 1994). Let MREF be the num#Words/#Sentences 20.49 40.42 16.99 23.53 17.02 22.13 19.69 47.52 18.15 23"
L16-1105,C94-1032,0,0.161186,"nts, we used a part of BCCWJ (Maekawa, 2008) annotated with dependency trees provided by (Mori et al., 2014). Thus the sentences are divided into words annotated with POS tags and tree structures. BCCWJ has six sub-domains (Yahoo!Answers, white paper, Yahoo!Blog, book, magazine, and newspaper). We divided each of them into a training and test part (Table 4). We also use a dictionary, UniDic (Den et al., 2007), containing 234,653 wordPOS pairs. We separated inflectional endings from the stems. 5.2. Evaluation Criteria The PT evaluation criterion is the same as morphological analysis F-measure (Nagata, 1994). Let MREF be the num#Words/#Sentences 20.49 40.42 16.99 23.53 17.02 22.13 19.69 47.52 18.15 23.08 14.98 24.99 ber of word-POS pairs in the correct sentences, MSY S be the number of word-POS pairs in the output sentences, and MCOR be the number of the word-POS pairs in both of the correct sentences and the output sentences, then the precision P and the recall R are defined as follows: P = MCOR /MREF , R = MCOR /MSY S . The total evaluation criterion is F-measure, the harmonic mean of the precision and the recall. For WS evaluation, we only compare words ignoring POSs. For DP evaluation we coun"
L16-1105,neubig-mori-2010-word,1,0.832847,"ble language resources are word dictionaries and fully annotated corpora. At DP step, the language resource is fully annotated corpora. In the following sections, we briefly explain WS, PT, DP, and language resources for them. Then we experimentally compare the performances in accuracy of DP from raw texts under various settings. Finally we discuss the strategies from the viewpoints of efficiency and cost. 2. Word Segmentation WS is the first step, which takes an unsegmented text as the input and segments it into a sequence of words. We adopt one of the state-of-art methods, pointwise method (Neubig and Mori, 2010; Neubig et al., 2011; Mori and Neubig, 2014). This method is capable of utilizing various types of language resources and thus useful in domain adaptation situations. 2.1. Method The pointwise word segmenter takes a sequence of characters x = x1 x2 · · · xn as input. Then it makes a classification at every point between two characters (decision point). Each classification is binary indicating whether there is a word boundary (Y) or not (N) as shown in Figure 2. Normally SVM (Fan et al., 2008) is used for classification referring to the features described in Table 1. They are derived from surr"
L16-1105,P11-2093,1,0.894468,"is important to check out the characteristics of the target domain and to choose a suitable language resource addition strategy for the parsing accuracy improvement. Keywords: language resource addition, part-of-speech tagging, dependency parsing 1. Introduction For languages without clear word boundary natural language processing (NLP) , such as word segmentation (WS), part-of-speech (POS) tagging (PT), and dependency parsing (DP) is essential technology for applications such as machine translation or information extraction (Matsumoto et al., 2000; Kudo et al., 2004; Kurohashi et al., 1994; Neubig et al., 2011; Kurohashi and Nagao, 1994; Mori et al., 2000; Kudo and Matsumoto, 2002; Flannery et al., 2012). WS and PT are now sufficiently accurate and widely used in various applications. DP is, however, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words"
L16-1105,P05-1013,0,0.0273606,"idely used in various applications. DP is, however, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data"
L16-1105,C04-1010,0,0.0403105,". Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data are usually larger than those for DP especially in domain adaptation situations. In this paper we assume that we want accur"
L16-1105,P99-1033,0,0.131822,"er, not so widely used as WS and PT because of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data are usually larger than those for DP e"
L16-1105,P06-2089,0,0.0186552,"cause of its insufficient performance. Recently there are many attempts at using sentence structure such as tree-based machine translation, language generation, etc. Thus the accuracy of a dependency parser is getting more and more important. In this paper, we discuss DP from raw sentences in Japanese. Although Japanese does not have clear word boundary, we take words as the DP unit similar to NLP in other languages such as English (Buchholz and Marsi, 2006; McDonald and Pereira, 2006; McDonald et al., 2005; Nivre and Nilsson, 2005; Koo and Collins, 2010; Oflazer, 1999; McDonald et al., 2006; Sagae and Lavie, 2006; Eisner, 1996; Nivre and Scholz, 2004), and we adopt a threestep pipeline method consisting of a word segmenter, a POS tagger, and a dependency parser (Figure 1). Although some researchers have proposed joint approaches (Hatori et al., 2012), the pipeline method has advantages that it can utilize various types of language resources easily and it is easy to analyze the effects of each step. So we can say the pipeline method is more realistic than joint approaches. Actually for WS and PT available training data are usually larger than those for DP especially in domain adaptation situations. In"
L16-1105,W06-2920,0,\N,Missing
L16-1214,C00-1004,0,0.059558,"Missing"
L16-1214,C12-1028,0,0.0600281,"Missing"
L16-1214,N13-1122,0,0.19724,"in the list since the automatically-generated mappings were by no means perfect. 2.4. Annotation Guidelines Ling et al. (2015) pointed out that lack of annotation guidelines posed a serious problem in the task of wikification. To keep annotation consistent, we adopt the following policies. Any topics. Unlike many previous studies, we do not limit the scope of wikification to named entities. All mentions of both common and proper noun phrases are to be tagged as long as they have corresponding Wikipedia articles. Exhaustive annotation. While several previous studies (Mihalcea and Csomai, 2007; Guo et al., 2013), as well as Wikipedia itself, focus on “important” concepts, we tag as many mentions as possible. It is impossible to determine importance in an objective way. Note again that unlike in Kulkarni et al. (2009), no NILs are covered. Prefer longer mentions. Mention “日本国” (State of Japan), for example, is to be linked to entity “日本” (Japan) and should not be divided into “日本” (Japan, entity identical with the mention) and “国” (state, mapped to a synonymous entity “国家”). Sometimes a pair of mention candidates do not nest within one another but simply overlap. For example, “舞台芸術作品” (performing art"
L16-1214,P14-1036,0,0.0343776,"Missing"
L16-1214,W04-3230,0,0.0720858,"i, Japanese employs scriptio continua, or a writing system in which words are not delimited by white space. For this reason, word segmentation is widely used as a prerequisite for most NLP tasks, and wikification could be another such task. However, the pipeline architecture often suffers from error propagation. Indeed, our motivation for Japanese wikification comes not only from the above-mentioned applications but from the lexical bottleneck problem in word segmentation. While decades of research in Japanese word segmentation has achieved a reasonable level of accuracy in benchmark corpora (Kudo et al., 2004), it is still prone to errors when it comes to real-world texts. One of the key problems is socalled unknown words, or the lack of lexical knowledge. In essence, in order to reliably identify words in text, the segmenter needs to know them in advance, by representing them directly as dictionary items (Kurohashi et al., 1994; Asahara and Matsumoto, 2000; Kudo et al., 2004) or indirectly as corpus-induced features (Neubig et al., 2011). Although lexical knowledge has been maintained by experts, it is impractical to adapt it to web-scale texts by hand (Murawaki and Kurohashi, 2008). Recognizing p"
L16-1214,Q15-1023,0,0.0288798,"trie, and then each of the candidates was mapped 3 http://dumps.wikimedia.org/jawiki/ to potential entities. Since the na¨ıve enumeration gave too many candidates, we applied a simple filtering rule: a mention candidate whose pre-computed LinkProb was below a threshold was dropped. LinkProb will be defined later in Table 3. We asked annotators to choose the best mention-entity pair from the candidate list (or discard all if appropriate). They were allowed to add mention-entity pairs not in the list since the automatically-generated mappings were by no means perfect. 2.4. Annotation Guidelines Ling et al. (2015) pointed out that lack of annotation guidelines posed a serious problem in the task of wikification. To keep annotation consistent, we adopt the following policies. Any topics. Unlike many previous studies, we do not limit the scope of wikification to named entities. All mentions of both common and proper noun phrases are to be tagged as long as they have corresponding Wikipedia articles. Exhaustive annotation. While several previous studies (Mihalcea and Csomai, 2007; Guo et al., 2013), as well as Wikipedia itself, focus on “important” concepts, we tag as many mentions as possible. It is impo"
L16-1214,mori-etal-2014-japanese,1,0.858082,"two mentions, “尾道” (Onomichi, a place name) and “しまなみ海道” (Shimanami Kaid¯o, a common alias for an expressway). Entity disambiguation is the task of linking each mention to a Wikipedia article, which is called an entity. The title of a Wikipedia article is used as the entity name because each Wikipedia article has a unique title. In the above example, The main corpora we work on are subsets of the Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa et al., 2014). In BCCWJ, sentences are segmented into words and each word is annotated with a POS tag and pronunciation. In addition, Mori et al. (2014) augmented them with gold-standard dependency relations. Figure 1(c) depicts our annotation for wikification. The sentence is segmented into POS-tagged words. Each word is given an ID and its parent word ID (PID). What we add is marked with the dotted rounded rectangle. We adopt the BIO labeling scheme, where B, I, and O stand for beginning, inside, and outside, respectively. For efficiency, O is not marked. A B and zero or more successive I’s represent a mention while a character sequence right after the B tag indicates a corresponding entity. We assume that a mention does not subdivide a wor"
L16-1214,D08-1045,1,0.809376,"acy in benchmark corpora (Kudo et al., 2004), it is still prone to errors when it comes to real-world texts. One of the key problems is socalled unknown words, or the lack of lexical knowledge. In essence, in order to reliably identify words in text, the segmenter needs to know them in advance, by representing them directly as dictionary items (Kurohashi et al., 1994; Asahara and Matsumoto, 2000; Kudo et al., 2004) or indirectly as corpus-induced features (Neubig et al., 2011). Although lexical knowledge has been maintained by experts, it is impractical to adapt it to web-scale texts by hand (Murawaki and Kurohashi, 2008). Recognizing product names, for example, is important for downstream applications, but they are too large in number and undergo rapid transition. In light of this, one might think that Wikipedia is a promising source of lexical knowledge. However, Wikipedia, as it is, cannot be used as a word dictionary due to segmentation mismatch. Every designer of the word segmentation task needs to define her own segmentation standard because it is left unspecified by Japanese orthography. External lexical resources like Wikipedia are full of compounds and thus incompatible with the standard. What is wors"
L16-1214,P11-2093,1,0.836554,"l bottleneck problem in word segmentation. While decades of research in Japanese word segmentation has achieved a reasonable level of accuracy in benchmark corpora (Kudo et al., 2004), it is still prone to errors when it comes to real-world texts. One of the key problems is socalled unknown words, or the lack of lexical knowledge. In essence, in order to reliably identify words in text, the segmenter needs to know them in advance, by representing them directly as dictionary items (Kurohashi et al., 1994; Asahara and Matsumoto, 2000; Kudo et al., 2004) or indirectly as corpus-induced features (Neubig et al., 2011). Although lexical knowledge has been maintained by experts, it is impractical to adapt it to web-scale texts by hand (Murawaki and Kurohashi, 2008). Recognizing product names, for example, is important for downstream applications, but they are too large in number and undergo rapid transition. In light of this, one might think that Wikipedia is a promising source of lexical knowledge. However, Wikipedia, as it is, cannot be used as a word dictionary due to segmentation mismatch. Every designer of the word segmentation task needs to define her own segmentation standard because it is left unspec"
L16-1214,D12-1113,0,0.0307795,"d investigate its performance on these corpora. Keywords: corpus annotation, wikification, word segmentation 1. Introduction Wikification is the task of detecting concept mentions in text and disambiguating them into their corresponding Wikipedia articles. It was originally introduced as an information retrieval task (Mihalcea and Csomai, 2007; Ferragina and Scaiella, 2010), and then has found a wide range of NLP applications including measuring semantic relatedness between text fragments (Gabrilovich and Markovitch, 2007), text classification (Chang et al., 2008), and coreference resolution (Ratinov and Roth, 2012). In this paper, we present new Japanese corpora for wikification. A major difference from previous studies on English lies in the fact that like Chinese and Thai, Japanese employs scriptio continua, or a writing system in which words are not delimited by white space. For this reason, word segmentation is widely used as a prerequisite for most NLP tasks, and wikification could be another such task. However, the pipeline architecture often suffers from error propagation. Indeed, our motivation for Japanese wikification comes not only from the above-mentioned applications but from the lexical bo"
L16-1214,E09-1100,0,0.0318497,"terms, specialized meanings are overrepresented in Wikipedia. For example, “声明” means statement in ordinary speech but Wikipedia only has an article for Buddhist chant. High coverage of nouns and noun compounds might be achieved with an amalgam of the encyclopedia and a dictionary. Although we focused on Japanese, we believe that the key ideas presented in this paper are applicable to other languages with scriptiones continuae. It is well known that Chinese also suffers from the problematic notion of word (Xia, 2000). While the Chinese language community has explored character-level analysis (Zhao, 2009), it is likely that longer units like mentions are also useful. Word segmentation and wikification might help each other because mention boundaries coincide with word boundaries. Similarly, the presence of a mention indicates that only its head word is modified from outside. A corpus with the multiple layers of annotation like ours enables us to explore this research direction. 5. Conclusion In this paper, we reported the details of annotated corpora for Japanese wikification. We specified annotation policies, annotated corpora for wikification, and tested them with a baseline wikifier. The ma"
L16-1225,den-etal-2008-proper,0,0.0178113,"s, we decided to incorporate verbal expressions including copula verbs followed by an adjective. These include passive forms and causative forms. In the BIO system, there are 2J + 1 tags, where J is the number of the NE types. For shogi NE we defined J = 21 types and the annotation work is to choose one among 43 (= 2 × 21 + 1) tags for each word. We prepared an annotation tool shown in Figure 3. We first segmented sentences automatically with a tool KyTea1 (Neubig and Mori, 2010; Neubig et al., 2011), trained on the general domain corpus, BCCWJ (Maekawa et al., 2010) and a dictionary, UniDic (Den et al., 2008) containing 212,900 words. We then supplied the results to the tool. Finally an annotator corrected word boundaries and added BIO tags for words using the tool shown in Figure 3. Pushing a “＋” button connects the words to form a single word and pushing a “▲” button separates a word into two words. A BIO tag is annotated to each word by selecting one among those in the pull-down menu. 1 http://www.phontron.com/kytea/ (accessed on 2016 Feb. 19). 1417 Figure 3: Annotation tool for word segmentation and BIO tags (the depenency part is not used). Type manu. auto. #Matches #States #Sent. #NEs #Words"
L16-1225,D15-1021,0,0.13057,"rounding 1. Introduction In recent years there has been a surge of interest in the generation of natural language annotations to describe digital recordings of the real world. A notable example is sentence generation from images (Ushiku et al., 2011; Yang et al., 2011). In such studies the natural language annotations are often provided by human workers on Amazon Mechanical Turk, and thus are often somewhat artificial. Since Hashimoto et al. (2014) recorded cooking videos of recipes spontaneously posted to an Internet site (Mori et al., 2014b), there have been many other image/video datasets (Ferraro et al., 2015) published. These attempts at connecting language expressions to real world objects such as images are often called symbol grounding (Harnad, 1990), an exciting new area in natural language processing. However, images, videos, and many other forms of media have ambiguities that make symbol grounding difficult. In this task we propose to use a well-defined “real world,” that is game states, to concentrate on language ambiguities. The game we focus on is shogi (Japanese chess) (Leggett, 2009). We collected 742,286 commentary sentences in Japanese and then defined domain-specific named entities ("
L16-1225,D15-1277,1,0.761706,"ng characteristics: • The commentaries are spontaneously given by professional players or writers. • Each commentary has a corresponding game state in a real match. Figure 1: Starting setup of shogi (left: normal depiction, right: chess-like depiction). • The game states do not have any ambiguity. Typical usages of our corpus include automatic commentary generation, detection of domain specific expressions, and their classification referring to game states (in the real world). There has in the past been an attempt at predicting characteristic words given a game state to generate a commentary (Kameko et al., 2015b). In this study, however, they only predict words (e.g. “king’s”) and do not identify concepts (e.g. “king’s gambit”), nor concept types (e.g. strategy). With our corpus we can try generation using automatically generated templates (Reiter, 1995; Mori et al., 2014a) or deep learning with our NEs in place of dialog acts (Wen et al., 2015). 2. Game and Commentary In this section we briefly explain shogi and its commentaries. For detailed explaination of shogi, please refer to (Leggett, 2009). 1415 3. Shogi Commentary Expressions Commentaries contain many domain specific expressions (words or m"
L16-1225,D15-1015,0,0.117727,"Missing"
L16-1225,maekawa-etal-2010-design,0,0.0289174,"). 3.7. Actions Unlike the general NE definitions, we decided to incorporate verbal expressions including copula verbs followed by an adjective. These include passive forms and causative forms. In the BIO system, there are 2J + 1 tags, where J is the number of the NE types. For shogi NE we defined J = 21 types and the annotation work is to choose one among 43 (= 2 × 21 + 1) tags for each word. We prepared an annotation tool shown in Figure 3. We first segmented sentences automatically with a tool KyTea1 (Neubig and Mori, 2010; Neubig et al., 2011), trained on the general domain corpus, BCCWJ (Maekawa et al., 2010) and a dictionary, UniDic (Den et al., 2008) containing 212,900 words. We then supplied the results to the tool. Finally an annotator corrected word boundaries and added BIO tags for words using the tool shown in Figure 3. Pushing a “＋” button connects the words to form a single word and pushing a “▲” button separates a word into two words. A BIO tag is annotated to each word by selecting one among those in the pull-down menu. 1 http://www.phontron.com/kytea/ (accessed on 2016 Feb. 19). 1417 Figure 3: Annotation tool for word segmentation and BIO tags (the depenency part is not used). Type man"
L16-1225,W03-0430,0,0.0408632,"ther improvement in word segmentation on game commentaries by referring to the game states (Kameko et al., 2015a). So we can say that an accurate word segmenter for shogi commentaries is now available. 5.2. Named Entity Recognition We also conducted shogi NE recognition. We trained a BIO2-based NE recognizer (Sasada et al., 2015) and tested it. The corpus specifications are shown in Table 2. The precision and recall are 0.913 and 0.789, respectively. The F-measure is 0.847, which is comparable to the general domain case (around 0.9) trained from about 10,000 sentences (Sang and Meulder, 2003; McCallum and Li, 2003). These results suggest that an NE recognizer is ready to be used to detect shogi NEs in raw commentaries for various applications. 5.3. Symbol Grounding One of the most interesting research directions is symbol grounding. Contrary to images or videos (Regneri et al., 2013), game states do not cause recognition problems and we can concentrate on the ambiguities on the language side. Another interesting aspect of symbol grounding to game states is that we can connect natural language expressions to computer analysis and predictions. 5.4. Others The NE recognition and/or symbol grounding results"
L16-1225,mori-neubig-2014-language,1,0.852837,"65 7,161 9,470 7 NA 386 NA 1,777 57,281 7,922 — 27,025 1,339,500 36,589 1,931,751 Table 2: Corpus specifications for word segmentation and NE recognition experiments. Training BCCWJ BCCWJ + Shogi Precision 0.872 0.983 Recall 0.907 0.983 F-measure 0.889 0.983 Table 3: Word segmentation accuracies. In this section we show their results and describe other potential applications. 5.1. Word Segmentation Our corpus has word boundary information. We therefore first tested word segmentation performance. It is well known that an annotated corpus in the target domain improves the performance very well (Mori and Neubig, 2014). Thus in addition to the baseline (see Subsection 4.1.), we trained another model using our corpus additionally. Table 2 shows the experimental settings. The results are shown in Table 3. The performance of the baseline word segmenter is very bad. Our corpus, however, improves the performance drastically. We can realize a further improvement in word segmentation on game commentaries by referring to the game states (Kameko et al., 2015a). So we can say that an accurate word segmenter for shogi commentaries is now available. 5.2. Named Entity Recognition We also conducted shogi NE recognition."
L16-1225,W14-4418,1,0.890694,"d to the real world. Keywords: game commentary, named entity, symbol grounding 1. Introduction In recent years there has been a surge of interest in the generation of natural language annotations to describe digital recordings of the real world. A notable example is sentence generation from images (Ushiku et al., 2011; Yang et al., 2011). In such studies the natural language annotations are often provided by human workers on Amazon Mechanical Turk, and thus are often somewhat artificial. Since Hashimoto et al. (2014) recorded cooking videos of recipes spontaneously posted to an Internet site (Mori et al., 2014b), there have been many other image/video datasets (Ferraro et al., 2015) published. These attempts at connecting language expressions to real world objects such as images are often called symbol grounding (Harnad, 1990), an exciting new area in natural language processing. However, images, videos, and many other forms of media have ambiguities that make symbol grounding difficult. In this task we propose to use a well-defined “real world,” that is game states, to concentrate on language ambiguities. The game we focus on is shogi (Japanese chess) (Leggett, 2009). We collected 742,286 commenta"
L16-1225,mori-etal-2014-flow,1,0.893921,"Missing"
L16-1225,neubig-mori-2010-word,1,0.834625,"crete expressions, like “10 minutes,” this includes abstract ones such as “長時間” (long time). 3.7. Actions Unlike the general NE definitions, we decided to incorporate verbal expressions including copula verbs followed by an adjective. These include passive forms and causative forms. In the BIO system, there are 2J + 1 tags, where J is the number of the NE types. For shogi NE we defined J = 21 types and the annotation work is to choose one among 43 (= 2 × 21 + 1) tags for each word. We prepared an annotation tool shown in Figure 3. We first segmented sentences automatically with a tool KyTea1 (Neubig and Mori, 2010; Neubig et al., 2011), trained on the general domain corpus, BCCWJ (Maekawa et al., 2010) and a dictionary, UniDic (Den et al., 2008) containing 212,900 words. We then supplied the results to the tool. Finally an annotator corrected word boundaries and added BIO tags for words using the tool shown in Figure 3. Pushing a “＋” button connects the words to form a single word and pushing a “▲” button separates a word into two words. A BIO tag is annotated to each word by selecting one among those in the pull-down menu. 1 http://www.phontron.com/kytea/ (accessed on 2016 Feb. 19). 1417 Figure 3: Ann"
L16-1225,P11-2093,1,0.797173,"“10 minutes,” this includes abstract ones such as “長時間” (long time). 3.7. Actions Unlike the general NE definitions, we decided to incorporate verbal expressions including copula verbs followed by an adjective. These include passive forms and causative forms. In the BIO system, there are 2J + 1 tags, where J is the number of the NE types. For shogi NE we defined J = 21 types and the annotation work is to choose one among 43 (= 2 × 21 + 1) tags for each word. We prepared an annotation tool shown in Figure 3. We first segmented sentences automatically with a tool KyTea1 (Neubig and Mori, 2010; Neubig et al., 2011), trained on the general domain corpus, BCCWJ (Maekawa et al., 2010) and a dictionary, UniDic (Den et al., 2008) containing 212,900 words. We then supplied the results to the tool. Finally an annotator corrected word boundaries and added BIO tags for words using the tool shown in Figure 3. Pushing a “＋” button connects the words to form a single word and pushing a “▲” button separates a word into two words. A BIO tag is annotated to each word by selecting one among those in the pull-down menu. 1 http://www.phontron.com/kytea/ (accessed on 2016 Feb. 19). 1417 Figure 3: Annotation tool for word"
L16-1225,Q13-1003,0,0.0341371,"trained a BIO2-based NE recognizer (Sasada et al., 2015) and tested it. The corpus specifications are shown in Table 2. The precision and recall are 0.913 and 0.789, respectively. The F-measure is 0.847, which is comparable to the general domain case (around 0.9) trained from about 10,000 sentences (Sang and Meulder, 2003; McCallum and Li, 2003). These results suggest that an NE recognizer is ready to be used to detect shogi NEs in raw commentaries for various applications. 5.3. Symbol Grounding One of the most interesting research directions is symbol grounding. Contrary to images or videos (Regneri et al., 2013), game states do not cause recognition problems and we can concentrate on the ambiguities on the language side. Another interesting aspect of symbol grounding to game states is that we can connect natural language expressions to computer analysis and predictions. 5.4. Others The NE recognition and/or symbol grounding results allow for various applications. Firstly we can improve automatic commentary generation (Kaneko, 2012). Kameko et al. (2015b) proposed a method for finding characteristic words for game states and used them to generate commentaries automatically. With our corpus, one can tr"
L16-1225,W03-0419,0,0.807406,"(path) is used to denote bishop’s diagonal lines and rook’s orthogonal lines. There are special expressions to denote relative positions of a piece like “腹” (belly) meaning the side squares of a piece. Pq: Piece quantity. Usually it is a pair of a number and a counter word. This also includes expressions such as “切れ ” (lack of) and “豊富” (abundant). 4. Game Commentary Corpus In this section we briefly explain our annotation framework, show some statistics for our corpus, and describe the corpus availability. 4.1. Annotation Framework As the notation for shogi NEs, we adopt the BIO tag system (Sang and Meulder, 2003). B, I, and O stand for begin, intermediate, and other, respectively. Each word is annotated with O, indicating that the word is not any NE, or a combination of BI tag and an NE type tag such as Hu-B, which indicates that the word is the beginning (B) of a player name (Hu). The following is the correct annotation for the commentary in Figure 2. 広瀬/Hu-B は /O 対/O ゴ /St-B キゲン /St-I 中/St-I 飛車/St-I の/O 超速/St-B ▲/St-I ３七/St-I 銀/St-I 戦法/St-I を /O 採用/Ac し /O た/O 。/O 3.6. Describing Events Outside the Board Commentators sometimes refer to issues outside of the board but related to the match. They can b"
L16-1225,W04-1221,0,0.244304,"xpressions to real world objects such as images are often called symbol grounding (Harnad, 1990), an exciting new area in natural language processing. However, images, videos, and many other forms of media have ambiguities that make symbol grounding difficult. In this task we propose to use a well-defined “real world,” that is game states, to concentrate on language ambiguities. The game we focus on is shogi (Japanese chess) (Leggett, 2009). We collected 742,286 commentary sentences in Japanese and then defined domain-specific named entities (NEs), similar to previous work on bio-medical NEs (Settles, 2004; Tateisi et al., 2002) or recipe NEs (Mori et al., 2014b). For example, “central rook” is a shogi strategy expression similar to “king’s gambit” in chess. We finally annotated NEs for 2,508 sentences to form our game commentary corpus, which has the following distinguishing characteristics: • The commentaries are spontaneously given by professional players or writers. • Each commentary has a corresponding game state in a real match. Figure 1: Starting setup of shogi (left: normal depiction, right: chess-like depiction). • The game states do not have any ambiguity. Typical usages of our corpus"
L16-1225,D15-1199,0,0.0215308,"ic commentary generation, detection of domain specific expressions, and their classification referring to game states (in the real world). There has in the past been an attempt at predicting characteristic words given a game state to generate a commentary (Kameko et al., 2015b). In this study, however, they only predict words (e.g. “king’s”) and do not identify concepts (e.g. “king’s gambit”), nor concept types (e.g. strategy). With our corpus we can try generation using automatically generated templates (Reiter, 1995; Mori et al., 2014a) or deep learning with our NEs in place of dialog acts (Wen et al., 2015). 2. Game and Commentary In this section we briefly explain shogi and its commentaries. For detailed explaination of shogi, please refer to (Leggett, 2009). 1415 3. Shogi Commentary Expressions Commentaries contain many domain specific expressions (words or multi-word expressions), which can be categorized into groups in a similar way to the general domain or bio-medical NEs. All players are familiar with these expressions (e.g. King’s gambit, Ruy Lopez, etc. in chess) and category names (e.g. opening). To facilitate various studies, we created detailed definitions of shogi NEs and annotated N"
L16-1225,D11-1041,0,0.399437,"Missing"
L16-1261,W08-1301,0,0.258594,"Missing"
L16-1261,de-marneffe-etal-2014-universal,0,0.14179,"Missing"
L16-1261,den-etal-2008-proper,0,0.0441224,"Missing"
L16-1261,N06-1023,0,0.0301,"ersal part-of-speech (POS) tags (UPOS) (Petrov et al., 2012). In our research, we attempt to port the UD annotation scheme to the Japanese language. The traditional annotation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to"
L16-1261,W02-2016,1,0.600528,"al., 2014) and Google universal part-of-speech (POS) tags (UPOS) (Petrov et al., 2012). In our research, we attempt to port the UD annotation scheme to the Japanese language. The traditional annotation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge"
L16-1261,W04-3230,1,0.799406,"Missing"
L16-1261,maekawa-etal-2000-spontaneous,0,0.265949,"Missing"
L16-1261,mori-etal-2014-japanese,1,0.826748,"apanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not segmented into word"
L16-1261,P11-2093,1,0.783083,"e adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not segmented into words or morphemes by white space in its orthography. Thus, we have several word unit standards that can be found in corpus annotation schemata or in the outputs of morphological analyzers (Kudo et al., 2004; Neubig et al., 2011). NINJAL1 proposed several word unit standards for Japanese corpus linguistics, such as the minimum word unit (Maekawa et al., 2000). Since 2002, the Institute has maintained a morphological information annotated lexicon, UniDic (Den et al., 2008), and has proposed three types of word unit standards: Short Unit Word (SUW): SUW is a minimal language unit that has a morphological function. SUW almost always corresponds to an entry in traditional Japanese dictionaries. Middle Unit Word (MUW): MUW is based on the rightbranching compound word construction and on phonological constructions, such as"
L16-1261,petrov-etal-2012-universal,0,0.0821258,". Keywords: typed dependencies, Short Unit Word, multiword expression, UniDic 1. Introduction 2. The Universal Dependencies (UD) project has been developing cross-linguistically consistent treebank annotation for various languages in recent years. The goal of the project is to facilitate multilingual parser development, cross-lingual learning, and parsing research from a language typology perspective (Nivre, 2015). The annotation scheme is based on (universal) Stanford dependencies (de Marneffe and Manning, 2008; de Marneffe et al., 2014) and Google universal part-of-speech (POS) tags (UPOS) (Petrov et al., 2012). In our research, we attempt to port the UD annotation scheme to the Japanese language. The traditional annotation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a m"
L16-1261,W13-4913,1,0.86233,"(10) 太郎 . NOUN . Taro . cop は . ADP . -TOPIC . 学生 . . NOUN . student . だ . AUX . COPULA . ‘Taro is a student.’ 5. Corpus It is reasonable to obtain Japanese UD corpora by converting existent linguistic resources; however, a direct conversion from the major Japanese corpora such as the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) is not simple since they lack syntactic information (unlabeled) and the structure is not suitable to recover constituents (bunsetsu chunk-based dependency trees). Therefore, we first constructed conversion rules for use with Japanese constituent treebank (Tanaka and Nagata, 2013) 1655 for the Mainichi Shimbun Newspaper. The treebank was initially built by converting the Kyoto University Text Corpus and was manually annotated. The treebank has clause level annotations with syntactic function labels, e.g., syntactic role and clause type, and coordination construction, which are required for UD annotation. The treebank is composed of complete binary trees, and can be easily converted to dependency tree by adapting the head percolation rules and dependency type rules for each partial tree. The UD corpus is composed of 10,000 sentences, and it contains 267,631 tokens. The"
L16-1261,P15-2039,1,0.532985,"ve been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not segmented into words or morphemes by white sp"
L16-1261,uchimoto-den-2008-word,0,0.0247262,"tation schemes for the Japanese language have been uniquely developed and are markedly different from other schemes, such as Penn Treebank-style annotation. Japanese syntactic parsing trees are usually represented as unlabeled dependency structures between bunsetsu chunks (base phrase units), as found in the Kyoto University Text Corpus (Kurohashi and Nagao, 2003) and the outputs of syntactic parsers (Kudo and Matsumoto, 2002; Kawahara and Kurohashi, 2006). Therefore, we must devise a method to construct word-based dependency structures that match the characteristics of the Japanese language (Uchimoto and Den, 2008; Mori et al., 2014; Tanaka and Nagata, 2015) and are able to derive the syntactic information required to assign relation types to dependencies. We describe the conversion from the Japanese POS tagset to the UPOS tagset, the adaptation of the UD annotation for Japanese syntax, and the attempt to build a UD corpus by converting the existing resources. We also address the remaining issues that may emerge when applying the UD scheme to other languages. Word unit The definition of a word unit is indispensable in UD annotation, which is not a trivial question for Japanese, since a sentence is not"
L16-1737,J93-2003,0,0.0509369,"h animation episode has a different animation director. training set. This result shows that the constructed dialect resource increases the accuracy of Kana Kanji conversion, and it is also useful for applications of NLP. 4.3. Other Possible Applications There are some possible applications improved by the proposed dialect data in this paper. Text to speech (TTS) includes some modules that require dataset for the adaptation (Nagano et al., 2005), pronunciation estimation or F0 estimation, and it is one of the most major area that requires parallel speech data. Statistical machine translation (Brown et al., 1993) is also an application that requires parallel data of texts and speeches. The machine translation between the common language and dialect intermediates in conversion of systems for common language to systems for dialect. Parallel corpora of several dialects benefit who constructs a system that assumes mixed dialect as an input, and it also realizes to estimate the proportion of affected dialect of the user (Hirayama et al., 2015). This technology can be applied for other types properties that affect the speaking style of people, for example, jobs or hobbies. This work indicates the importance"
L16-1737,C12-1072,1,0.915866,"corpora also have transcription in Katakana character and translation in common language (Tokyo dialect) for each speech. The corpora preserve pure Japanese dialect, however, the recording setting is not suitable for spoken language processing (noisy, not closed talk). The lack of dialect data is also a problem of NLP. Collecting large scale text data becomes easier by the buildup of Web, however, it is still difficult to collect large scale dialect data from Web. We tackled this problem with a conversion of common language resources on Web to dialects based on machine translation techniques (Hirayama et al., 2012). We trained Weighted Finite State Transducer (WFST) that converts common language sentences to dialect pronunciation sequences by using a small parallel corpus of common language in Japanese and Kansai dialect (dialect spoken in Kansai area in Japan) extracted from the database of (National Institute for Japanese Language and Linguistics, 2001 2008). The trained WFST generates large scale simulated dialect corpus to be used for the training of NLP and SLP applications. Kyushu Figure 1: Locations of areas where dialects are spoken. parallel corpora. The location of each area is shown in Figure"
L16-1737,N06-1030,0,0.0244222,"on (ASR) and Kana Kanji conversion (KKC) system are improved by adapting the system with the data. Keywords: Speech, Transcription, Dialect, Japanese 1. Introduction speech processing. Texts and their read speeches are necessary for natural and spoken language processing (NLP and SLP). Tireless efforts of data collection of speech data and their transcriptions from the early stage of NLP and SLP researches drastically improved accuracies of a variety of NLP and SLP tasks. However, we still do not have enough resources for some minor languages, and it causes less accuracies in minor languages (Kominek and Black, 2006). Especially, we do not have enough speech data of dialects. The lack of dialect speech data disturbs the use of NLP and SLP applications of dialect speakers. For example, it is very difficult to recognize dialect speeches accurately by using a model trained in common language. Automatic speech recognition (ASR) system is now generally used in public services, for example, taking minutes of national congresses and city councils (Akita et al., 2009). Such applications are expected to be used for not only current formal situations but also more casual situations, for example, taking minutes of c"
L16-1737,I08-7018,0,0.0331148,"people from various region, thus, the major dialect spoken in Hokkaido is common language. • Okinawa has different building history from other areas, and the dialect is greatly different from the common language. 3.1. Recording Procedure The recording procedure of proposed dialect corpora consists of following four steps. 2.2. ASR system in Japanese Language One of the state-of-the-art ASR system in Japanese is Julius decoder (Lee et al., 2001)1 . Julius packages deep neural network based acoustic model and language model trained from Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008)2 . The language model supports to recognize Japanese common language utterances, however, it does not support any dialect speech. The language model is easily updated by adding a training text data, and we tried to update the language model by adding simulated dialect text generated from the WFST based converter (Hirayama et al., 2012). 3. Parallel Dialect Corpora We selected one common language (Tokyo dialect) and four dialects (Kansai, Kyushu, Tohoku, and San-yo) to construct 1 2 Tokyo 1. We randomly selected 100 sentences of common language to be read by common language and dialect speaker"
L16-1737,mori-etal-2014-japanese,1,0.893068,"Missing"
L16-1737,P11-2093,1,0.694453,"f the corpora. We request you to cite this paper and the project of JSPS KAKENHI Grant No.24220006 when you publish anything that uses this resource. The resource is provided on the project web page7 . corpora. 9. Bibliographical References 5. Discussion for Annotation There are some discussions for annotation of the collected corpora. Word segments, accents, and the phoneme set are the points it should be updated in future. 5.1. Word Segment The original texts from BCCWJ (= common language) have word segmentation annotations. The translated dialect texts are automatically segmented by KyTea (Neubig et al., 2011)6 . We plan to annotate the word segments of dialects that can be aligned to the original text of common language, however, we still need discussion for annotation standard of word segmentation of dialects. 5.2. Accent Accents are characteristics of dialect speech in Japanese. This information will benefit to use the corpora in speech synthesis area (Nagano et al., 2005). 5.3. Phoneme Set In the first version of the corpora, we annotated phonemes with in the phoneme set defined in JNAS. However, JNAS is a common language speech corpus and the phoneme set has some mismatches to real dialect spe"
L18-1287,W16-5406,1,0.730532,"D Japanese-GSD, UD JapanesePUD, and UD Japanese-Modern (Omura et al., 2017). Table 1 presents the current status of UD Japanese resources. Below, we describe these resources briefly. UD Japanese-BCCWJ is UD data based on the ‘Balanced Corpus of Contemporary Written Japanese’ (hereafter BCCWJ) (Maekawa et al., 2014). The BCCWJ defines 1 million word-scale core data samples in which the morphological information is manually annotated with three layers of word delimitations: Short Unit Word (SUW), Long Unit Word (LUW), and bunsetsu. The BCCWJ has several syntactic annotations. The BCCWJ-DepPara (Asahara and Matsumoto, 2016) is a bunsetsu-based syntactic dependency and coordinate structure annotation. The BCCWJ-PAS (Ueda et al., 2015) is a predicate-argument relation annotation with the NAIST Text Corpus annotation schema (Iida et al., 2007). We maintain conversion rules based on these annotations. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013) which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu, namely base phrase, based dependency treebank with its own word delimitation schema"
L18-1287,W07-1522,1,0.718422,"ced Corpus of Contemporary Written Japanese’ (hereafter BCCWJ) (Maekawa et al., 2014). The BCCWJ defines 1 million word-scale core data samples in which the morphological information is manually annotated with three layers of word delimitations: Short Unit Word (SUW), Long Unit Word (LUW), and bunsetsu. The BCCWJ has several syntactic annotations. The BCCWJ-DepPara (Asahara and Matsumoto, 2016) is a bunsetsu-based syntactic dependency and coordinate structure annotation. The BCCWJ-PAS (Ueda et al., 2015) is a predicate-argument relation annotation with the NAIST Text Corpus annotation schema (Iida et al., 2007). We maintain conversion rules based on these annotations. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013) which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu, namely base phrase, based dependency treebank with its own word delimitation schema and POS tagset. The NTT Japanese Phrase Structure Treebank is a phrase structure-based treebank. The word delimitation and POS are adapted to the UniDic SUW standard. The data is still in version 1.0 schema as of February"
L18-1287,C00-1060,1,0.238943,"version 1.0 schema as of February 2018. We are now modifying UD Japanese KTC from version 1.0 schema to version 2.0. UD Japanese-GSD (formerly known as UD Japanese) consists of sentences from Wikipedia. The version 2.0 of this annotated corpus was provided for the CoNLL 2017 Shared Task (Zeman et al., 2017). In the release of version 2.0, the sentences have been automatically split into words by IBM’s word segmenter. The segmentation errors were removed by adding lexicons specific to the data. In addition, the dependencies are automatically resolved using the bunsetsu-level dependency parser (Kanayama et al., 2000) with the attachment rules for functional words defined in UD Japanese (Tanaka et al., 2016). Complex sentences with parenthesis were removed to avoid parsing errors. In the version 2.1 released in November 2017, manual annotations were merged with the semi-automatic annotations to reduce remaining errors. UD Japanese-PUD was created in the same manner as UD Japanese-GSD, with the goal of maintaining consistency with UD Japanese-GSD. Since it is a parallel corpus with other languages, no sentences were removed from the corpus, including the ones containing parenthesis. UD Japanese-Modern (Omur"
L18-1287,P13-2017,0,0.1339,"Missing"
L18-1287,W13-4913,1,0.80844,"information is manually annotated with three layers of word delimitations: Short Unit Word (SUW), Long Unit Word (LUW), and bunsetsu. The BCCWJ has several syntactic annotations. The BCCWJ-DepPara (Asahara and Matsumoto, 2016) is a bunsetsu-based syntactic dependency and coordinate structure annotation. The BCCWJ-PAS (Ueda et al., 2015) is a predicate-argument relation annotation with the NAIST Text Corpus annotation schema (Iida et al., 2007). We maintain conversion rules based on these annotations. UD Japanese-KTC (Tanaka et al., 2016) is based on the NTT Japanese Phrase Structure Treebank (Tanaka and Nagata, 2013) which contains the same original text as the Kyoto Text Corpus (KTC) (Kurohashi and Nagao, 2003). KTC is a bunsetsu, namely base phrase, based dependency treebank with its own word delimitation schema and POS tagset. The NTT Japanese Phrase Structure Treebank is a phrase structure-based treebank. The word delimitation and POS are adapted to the UniDic SUW standard. The data is still in version 1.0 schema as of February 2018. We are now modifying UD Japanese KTC from version 1.0 schema to version 2.0. UD Japanese-GSD (formerly known as UD Japanese) consists of sentences from Wikipedia. The ver"
L18-1287,uchimoto-den-2008-word,0,0.0154352,"d on UniDic word boundary definition. The definition contains three layers: SUW, LUW, and bunsetsu. SUW can be produced by the morphological analyser MeCab.1 with UniDic2 LUW and bunsetsu can be produced by the pre-trained chunker Comainu.3 NINJAL4 defined five sorts of word unit definitions by operationalism. The most fine-grained unit is NINJAL Minimum Unit Word. SUW (Short Unit Word: 短単位) is constructively defined by the NINJAL Minimum Unit Word (最小単位). MUW (Middle Unit Word: 中単位) is a basic unit where a sound may change at the beginning or the ending of a word and/or an accent may change (Uchimoto and Den, 2008). The Middle Unit Word defines voiced compound (“rendaku”) (van de Weijer et al., 2005). 1825 1 taku910.github.io/mecab/ unidic.ninjal.ac.jp/ 3 osdn.net/projects/comainu/ 4 National Institute for Japanese Language and Linguistics. 2 Short Unit Word (SUW) advcl root iobj name punct iobj name 中国 . PROPN . China . . ・ . PUNCT . . . 北京 . PROPN . Beijing . . punct case 大 . NOUN . univ. . . obj aux に . ADP . -IOBJ . . 留学 . VERB . . . compound し . AUX . . study . abroad . 、 . PUNCT . . . 帰国 . VERB . return . to Japan . case 後 . NOUN . after . . case に . ADP . -IOBJ . . 双子 . NOUN . twins . . を. ADP ."
L18-1287,K17-3001,1,0.858266,"Missing"
L18-1393,D15-1021,0,0.031655,"t can be used to train a computer to identify words and phrases that signal factuality and to determine events with the said factuality, paving the way for grounding possible and counterfactual states. Keywords: game commentary, modality, factuality, symbol grounding 1. Introduction The field of natural language processing (NLP) has experienced a resurgence of interest in the symbol grounding problem (Harnad, 1990). An increasing number of datasets available align natural language expressions with real world objects in the form of images and videos (Hashimoto et al., 2014; Mori et al., 2014b; Ferraro et al., 2015), and systems built on top of such datasets typically perform image/videoto-text generation (Ushiku et al., 2011; Yang et al., 2011). These systems are, however, more akin to great apes than to humans in the sense that “[t]heir lives are lived entirely in the present” (Donald, 1991). While there is no evidence that nonhuman animals communicate past episodes and planned future events, human language is abundant with them (Szagun, 1978). It is even suggested that the faculty of language has a close connection to the ability to image the future (Suddendorf and Corballis, 1997). Here we argue that"
L18-1393,D15-1015,0,0.0685031,"Missing"
L18-1393,W14-4418,1,0.934846,"2 factuality tags. It can be used to train a computer to identify words and phrases that signal factuality and to determine events with the said factuality, paving the way for grounding possible and counterfactual states. Keywords: game commentary, modality, factuality, symbol grounding 1. Introduction The field of natural language processing (NLP) has experienced a resurgence of interest in the symbol grounding problem (Harnad, 1990). An increasing number of datasets available align natural language expressions with real world objects in the form of images and videos (Hashimoto et al., 2014; Mori et al., 2014b; Ferraro et al., 2015), and systems built on top of such datasets typically perform image/videoto-text generation (Ushiku et al., 2011; Yang et al., 2011). These systems are, however, more akin to great apes than to humans in the sense that “[t]heir lives are lived entirely in the present” (Donald, 1991). While there is no evidence that nonhuman animals communicate past episodes and planned future events, human language is abundant with them (Szagun, 1978). It is even suggested that the faculty of language has a close connection to the ability to image the future (Suddendorf and Corballis, 1"
L18-1393,mori-etal-2014-flow,1,0.90276,"Missing"
L18-1393,L16-1225,1,0.912084,". Unlike typical image captions, human comments on shogi games are full of references to past and future moves as we will see in Subsection 2.2. Yet, thanks to the well-definedness of the world, many of such references can be grounded in a game tree. Although ambiguities inherent in natural language remain a challenging problem, modern game-tree search algorithms (Tsuruoka et al., 2002) help distinguish realistic states from unrealistic ones. For this reason, we have collected shogi commentaries together with the corresponding board states and have been developing a game commentary generator (Mori et al., 2016; Kameko et al., 2015). Figure 1: Starting setup of shogi (left: normal depiction, right: chess-like depiction). A human commentator usually expresses to shogi fans the degree of confidence on the future move he is describing, which reflects his evaluation of the game-tree. Since confidence is expressed through a wide variety of words and phrases, which we call modality expressions, identifying such expressions and binding the factual statuses to events are necessary steps toward automatic generation of humanlike commentaries. To this end, we annotate a shogi corpus for a commentator’s confide"
L18-1393,W03-0419,0,0.108355,"think white will useFNr anaguma castle.) FNs Possibly not the case that P. <PS−> △９四歩は指しFNs づらいかもしれません (Maybe it is hard to takeFNs Px9d.) 5. Annotated Corpus We explain our annotation process and show some statistics on our annotated corpus. We also report preliminary experiments on modality expression detection and event factuality analysis using it. 5.1. Annotation Process In annotation process, we annotated the SGC corpus with modality expressions, event classes and factuality in this order. Because a modality expression can be made of more than one word, we adopt the IOB2 tagging style (Sang and Meulder, 2003) for our modality expression layer. The 2478 Tag MEy MEa ME0 MEm MEn MEp MEf MEh Freq. 21 103 105 7 140 370 32 66 Precision 0.00 0.63 0.63 1.00 0.75 0.91 0.92 0.69 Recall 0.00 0.68 0.60 0.14 0.71 0.92 0.34 0.47 F-measure 0.00 0.65 0.62 0.25 0.73 0.92 0.50 0.56 features. The second module searches for the best tag sequence by using conditional random fields referring to the tag-confidence pairs. Tables 4 and 5 show the results of modality expression detection and event factuality analysis, respectively. In the tables, “Freq.” indicates the number of a target tag in the test data. From Table 4,"
L18-1393,suzuki-etal-2012-detecting,1,0.82058,"that the event is probable. “防い (prevent)” is a verb used as a modality expression while in EX 4 it is used a main verb and can be seen as an event mention. This counterfactive verb makes it explicit that the event “跳ね (attack)” did not happen. In EX 5, “ば (if)” is a conjunctive particle that leads to a conditional construction. Factuality of event mentions in the hypothetical construction is absolutely uncertain. In the first layer of our annotation scheme, we mark up modality expressions as described above. 3.1. POS There have been several studies of detecting Japanese modality expressions (Suzuki et al., 2012; Izumi et al., 2013) (Kamioka et al., 2015). However, they focus on auxiliary verbs and functional multi-word expressions. Modal adverbs and conjunctive particles are largely out of scope of these studies. By contrast, we target all types of modality expressions for mark-up regardless of their parts-of-speech. 2476 Layer String POS NE Modality Event class Factuality 先手 black N Tu-B O は 美濃 囲い が 崩れ て い る TOP Mino castle NOM break have PP P N N P V P V Sf O Ca-B Ca-I O Ao-B O O O O O O O MEn-B O O O EVe EVe EVf FNc FPc の で because P Aux O O O O 、 飛車 交換 は 後手 の 得 rook change TOP white ’s good Pnc"
L18-1393,D15-1199,0,0.0215458,". 6.2. Automatic Commentary Generation With our corpus, we can improve automatic commentary generation (Kaneko, 2012; Kameko et al., 2015). The previous work proposed a two-step approach where identification of characteristic words for the given game state is followed by language model-based generation. With consideration for event factuality in addition to characteristic words, the generator is expected to choose appropriate modality expressions. We can try generation using automatically generated templates (Reiter, 1995; Mori et al., 2014a) or deep learning with NEs in place of dialog acts (Wen et al., 2015). 4 2 This is a title match called “Meijinsen,” which causes longer text than a usual match. 3 http://www.ar.media.kyoto-u.ac.jp/tool/ PWNER/home.html The game records and the commentary sentences are distributed in the website: http://www.meijinsen.jp (in Japanese) for a fee. We provide a helper script to download the records and the text at https://github.com/hkmk/ shogi-comment-tools. 2479 6.3. Game State Retrieval We can also create a system for game state search by natural language queries. A previous study proposed search for game states by piece positions (Ganguly et al., 2014). NE reco"
L18-1393,D11-1041,0,0.0869221,"Missing"
L18-1393,W15-1606,0,0.0191354,"is a verb used as a modality expression while in EX 4 it is used a main verb and can be seen as an event mention. This counterfactive verb makes it explicit that the event “跳ね (attack)” did not happen. In EX 5, “ば (if)” is a conjunctive particle that leads to a conditional construction. Factuality of event mentions in the hypothetical construction is absolutely uncertain. In the first layer of our annotation scheme, we mark up modality expressions as described above. 3.1. POS There have been several studies of detecting Japanese modality expressions (Suzuki et al., 2012; Izumi et al., 2013) (Kamioka et al., 2015). However, they focus on auxiliary verbs and functional multi-word expressions. Modal adverbs and conjunctive particles are largely out of scope of these studies. By contrast, we target all types of modality expressions for mark-up regardless of their parts-of-speech. 2476 Layer String POS NE Modality Event class Factuality 先手 black N Tu-B O は 美濃 囲い が 崩れ て い る TOP Mino castle NOM break have PP P N N P V P V Sf O Ca-B Ca-I O Ao-B O O O O O O O MEn-B O O O EVe EVe EVf FNc FPc の で because P Aux O O O O 、 飛車 交換 は 後手 の 得 rook change TOP white ’s good Pnc N N P N P N O Mn-B Mn-I O Tu-B O Ee-B O O O"
mori-etal-2014-flow,D11-1041,0,\N,Missing
mori-etal-2014-flow,C04-1033,0,\N,Missing
mori-etal-2014-flow,C08-1113,1,\N,Missing
mori-etal-2014-flow,C80-1016,0,\N,Missing
mori-etal-2014-flow,I13-1126,1,\N,Missing
mori-etal-2014-flow,Q13-1003,0,\N,Missing
mori-etal-2014-flow,P13-1006,0,\N,Missing
mori-etal-2014-flow,W03-0430,0,\N,Missing
mori-etal-2014-flow,mori-etal-2014-japanese,1,\N,Missing
mori-etal-2014-flow,mori-neubig-2014-language,1,\N,Missing
mori-etal-2014-flow,tateisi-etal-2014-annotation,0,\N,Missing
mori-etal-2014-flow,neubig-mori-2010-word,1,\N,Missing
mori-etal-2014-flow,maekawa-etal-2010-design,0,\N,Missing
mori-etal-2014-flow,M98-1001,0,\N,Missing
mori-etal-2014-flow,P11-2093,1,\N,Missing
mori-etal-2014-japanese,J93-2004,0,\N,Missing
mori-etal-2014-japanese,W06-2920,0,\N,Missing
mori-etal-2014-japanese,J11-1007,0,\N,Missing
mori-etal-2014-japanese,C00-1081,1,\N,Missing
mori-etal-2014-japanese,H05-1066,0,\N,Missing
mori-etal-2014-japanese,P06-1092,1,\N,Missing
mori-etal-2014-japanese,I11-1087,1,\N,Missing
mori-etal-2014-japanese,I11-1136,0,\N,Missing
mori-etal-2014-japanese,neubig-mori-2010-word,1,\N,Missing
mori-etal-2014-japanese,maekawa-etal-2010-design,1,\N,Missing
mori-etal-2014-japanese,P11-2093,1,\N,Missing
mori-neubig-2014-language,W04-3236,0,\N,Missing
mori-neubig-2014-language,W04-3230,0,\N,Missing
mori-neubig-2014-language,C04-1067,0,\N,Missing
mori-neubig-2014-language,C94-1032,0,\N,Missing
mori-neubig-2014-language,C96-2202,1,\N,Missing
mori-neubig-2014-language,C08-1113,1,\N,Missing
mori-neubig-2014-language,P09-1117,0,\N,Missing
mori-neubig-2014-language,P02-1064,0,\N,Missing
mori-neubig-2014-language,I13-1018,0,\N,Missing
mori-neubig-2014-language,P09-1058,0,\N,Missing
mori-neubig-2014-language,mori-etal-2014-flow,1,\N,Missing
mori-neubig-2014-language,I08-7018,0,\N,Missing
mori-neubig-2014-language,neubig-mori-2010-word,1,\N,Missing
mori-neubig-2014-language,P11-2093,1,\N,Missing
neubig-mori-2010-word,den-etal-2008-proper,0,\N,Missing
neubig-mori-2010-word,W07-1516,0,\N,Missing
neubig-mori-2010-word,C08-1113,1,\N,Missing
neubig-mori-2010-word,I08-7018,0,\N,Missing
P06-1092,J90-2002,0,0.545659,"Missing"
P06-1092,C90-2036,0,0.0943256,"Missing"
P06-1092,J03-3001,0,0.0165604,"rovement augments the accuracies of all NLP systems based on a noisy channel model. Recently the main research focus of LM is shifting to the adaptation method, how to capture the characteristics of words and expressions in a target domain. The standard adaptation method is to prepare a corpus in the application domain, count the frequencies of words and word sequences, and manually annotate new words with their input signal sequences to be added to the vocabulary. It is now easy to gather machine-readable sentences in various domains because of the ease of publication and access via the Web (Kilgarriff and Grefenstette, 2003). In addition, traditional machinereadable forms of medical reports or business reports are also available. When we need to develop an NLP system in various domains, there is a huge but unannotated corpus. For languages, such as Japanese and Chinese, in which the words are not delimited by whitespace, one encounters a word identification problem before counting the frequencies of words and word sequences. To solve this problem one must have a good word segmenter in the domain of the corpus. The only robust and reliable word segmenter in the domain is, however, a word segmenter based on the sta"
P06-1092,C94-1032,0,0.310778,"Missing"
P06-1092,W96-0205,0,0.0493395,"Missing"
P11-1064,N10-1028,0,0.636111,"tributions, and thus the parameters for the Pitman-Yor process will be different for each distribution. Further, as ll and lr must be smaller than l, Pt,l no longer contains itself as a base measure, and is thus not deficient. An example of the actual discount values learned in one of the experiments described in Section 7 is shown in Figure 2. It can be seen that, as expected, the discounts for short phrases are lower than 636 4.2 Implementation Previous research has used a variety of sampling methods to learn Bayesian phrase based alignment models (DeNero et al., 2008; Blunsom et al., 2009; Blunsom and Cohn, 2010). All of these techniques are applicable to the proposed model, but we choose to apply the sentence-based blocked sampling of Blunsom and Cohn (2010), which has desirable convergence properties compared to sampling single alignments. As exhaustive sampling is too slow for practical purpose, we adopt the beam search algorithm of Saers et al. (2009), and use a probability beam, trimming spans where the probability is at least 1010 times smaller than that of the best hypothesis in the bucket. One important implementation detail that is different from previous models is the management of phrase co"
P11-1064,P09-1088,0,0.778629,"nts. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one important change: ITG symbols and phrase pairs are generated in the opposite order. In traditional ITG models, the branches of a biparse tree are generated from a nonterminal distribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-based divide and conquer strategy to genera"
P11-1064,J93-2003,0,0.0978707,"Missing"
P11-1064,W10-1703,0,0.0131603,"he proposed method on translation tasks from four languages, French, German, Spanish, and Japanese, into English. 638 TM (en) TM (other) LM (en) Tune (en ) Tune (other) Test (en) Test (other) de-en 1.80M 1.85M 52.7M 49.8k 47.2k 65.6k 62.7k es-en 1.62M 1.82M 52.7M 49.8k 52.6k 65.6k 68.1k fr-en 1.35M 1.56M 52.7M 49.8k 55.4k 65.6k 72.6k ja-en 2.38M 2.78M 44.7M 68.9k 80.4k 40.4k 48.7k Table 1: The number of words in each corpus for TM and LM training, tuning, and testing. 7.1 Experimental Setup The data for French, German, and Spanish are from the 2010 Workshop on Statistical Machine Translation (Callison-Burch et al., 2010). We use the news commentary corpus for training the TM, and the news commentary and Europarl corpora for training the LM. For Japanese, we use data from the NTCIR patent translation task (Fujii et al., 2008). We use the first 100k sentences of the parallel corpus for the TM, and the whole parallel corpus for the LM. Details of both corpora can be found in Table 1. Corpora are tokenized, lower-cased, and sentences of over 40 words on either side are removed for TM training. For both tasks, we perform weight tuning and testing on specified development and test sets. We compare the accuracy of o"
P11-1064,W07-0403,0,0.436106,"able that is consistent with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one important change: ITG symbols and phrase pairs are generated in the opposite order. In traditional ITG models, the branches of a biparse tree are generated from a nonterminal distribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-"
P11-1064,J07-2003,0,0.350869,"a fraction of the size of most heuristic extraction methods. Finally, we varied the size of the parallel corpus for the Japanese-English task from 50k to 400k senFor future work, we plan to refine HLEN to use a more appropriate model of phrase length than the uniform distribution, particularly by attempting to bias against phrase pairs where one of the two phrases is much longer than the other. In addition, we will test probabilities learned using the proposed model with an ITG-based decoder. We will also examine the applicability of the proposed model in the context of hierarchical phrases (Chiang, 2007), or in alignment using syntactic structure (Galley et al., 2006). It is also worth examining the plausibility of variational inference as proposed by Cohen et al. (2010) in the alignment context. Acknowledgments This work was performed while the first author was supported by the JSPS Research Fellowship for Young Scientists. References Figure 4: The effect of corpus size on the accuracy (a) and phrase table size (b) for each method (Japanese-English). tences and measured the effect of corpus size on translation accuracy. From the results in Figure 4 (a), it can be seen that at all corpus size"
P11-1064,N10-1081,0,0.293077,"rates from the symbol distribution Px , then from the phrase distribution Pt , while HIER generates directly from Pt , which falls back to divide-and-conquer based on Px when necessary. It can be seen that while Pt in FLAT only generates minimal phrases, Pt in HIER generates (and thus memorizes) phrases at all levels of granularity. 4.1 Length-based Parameter Tuning There are still two problems with HIER, one theoretical, and one practical. Theoretically, HIER contains itself as its base measure, and stochastic process models that include themselves as base measures are deficient, as noted in Cohen et al. (2010). Practically, while the Pitman-Yor process in HIER shares the parameters s and d over all phrase pairs in the model, long phrase pairs are much more sparse those of long phrases. In particular, phrase pairs of length up to six (for example, |e |= 3, |f |= 3) are given discounts of nearly zero while larger phrases are more heavily discounted. We conjecture that this is related to the observation by Koehn et al. (2003) that using phrases where max(|e|, |f |) ≤ 3 cause significant improvements in BLEU score, while using larger phrases results in diminishing returns. Figure 2: Learned discount va"
P11-1064,P05-1066,0,0.0803727,"Missing"
P11-1064,P08-2007,0,0.0326897,"Fi). We decompose this posterior probability using Bayes law into the corpus likelihood and parameter prior probabilities Wong (2002), DeNero et al. (2008), inter alia), and in particular a number of recent works (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009) have used the formalism of inversion transduction grammars (ITGs) (Wu, 1997) to learn phrase alignments. By slightly limit reordering of words, ITGs make it possible to exactly calculate probabilities of phrasal alignments in polynomial time, which is a computationally hard problem when arbitrary reordering is allowed (DeNero and Klein, 2008). The traditional flat ITG generative probability for a particular phrase (or sentence) pair Pf lat (he, f i; θx , θt ) is parameterized by a phrase table θt and a symbol distribution θx . We use the following generative story as a representative of the flat ITG model. 1. Generate symbol x from the multinomial distribution Px (x; θx ). x can take the values TERM, REG , or INV . 2. According to the x take the following actions. (a) If x = TERM, generate a phrase pair from the phrase table Pt (he, f i; θt ). (b) If x = REG, a regular ITG rule, generate phrase pairs he1 , f1 i and he2 , f2 i from"
P11-1064,P10-1147,0,0.261523,"the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size. 1 Introduction The training of translation models for phrasebased statistical machine translation (SMT) systems (Koehn et al., 2003) takes unaligned bilingual training data as input, and outputs a scored table of phrase pairs. This phrase table is traditionally generated by going through a pipeline of two steps, first generating word (or minimal phrase) alignments, then extracting a phrase table that is consistent with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one importan"
P11-1064,W06-3105,0,0.0185751,"lso for phrases that, while not directly included in the model, are composed of two high probability child phrases. It should be noted that while for FLAT and HIER Pt can be used directly, as HLEN learns separate models for each length, we must combine these probabilities into a single value. We do this by setting Pt (he, f i) = Pt,l (he, f i)c(l)/ L ∑ c(˜l) ˜ l=1 for every phrase pair, where l = |e |+ |f |and c(l) is the number of phrases of length l in the sample. We call this model-based extraction method MOD. 5.3 Sample Combination As has been noted in previous works, (Koehn et al., 2003; DeNero et al., 2006) exhaustive phrase extraction tends to out-perform approaches that use syntax or generative models to limit phrase boundaries. DeNero et al. (2006) state that this is because generative models choose only a single phrase segmentation, and thus throw away many good phrase pairs that are in conflict with this segmentation. Luckily, in the Bayesian framework it is simple to overcome this problem by combining phrase tables from multiple samples. This is equivalent to approximating the integral over various parameter configurations in Equation (1). In MOD, we do this by taking the average of the jo"
P11-1064,D08-1033,0,0.563293,"Missing"
P11-1064,P06-1121,0,0.17041,"ds. Finally, we varied the size of the parallel corpus for the Japanese-English task from 50k to 400k senFor future work, we plan to refine HLEN to use a more appropriate model of phrase length than the uniform distribution, particularly by attempting to bias against phrase pairs where one of the two phrases is much longer than the other. In addition, we will test probabilities learned using the proposed model with an ITG-based decoder. We will also examine the applicability of the proposed model in the context of hierarchical phrases (Chiang, 2007), or in alignment using syntactic structure (Galley et al., 2006). It is also worth examining the plausibility of variational inference as proposed by Cohen et al. (2010) in the alignment context. Acknowledgments This work was performed while the first author was supported by the JSPS Research Fellowship for Young Scientists. References Figure 4: The effect of corpus size on the accuracy (a) and phrase table size (b) for each method (Japanese-English). tences and measured the effect of corpus size on translation accuracy. From the results in Figure 4 (a), it can be seen that at all corpus sizes, the results from all three methods are comparable, with insign"
P11-1064,D07-1103,0,0.0694819,"mentation. Luckily, in the Bayesian framework it is simple to overcome this problem by combining phrase tables from multiple samples. This is equivalent to approximating the integral over various parameter configurations in Equation (1). In MOD, we do this by taking the average of the joint probability and span probability features, and re-calculating the conditional probabilities from the averaged joint probabilities. 6 Related Work In addition to the previously mentioned phrase alignment techniques, there has also been a significant body of work on phrase extraction (Moore and Quirk (2007), Johnson et al. (2007a), inter alia). DeNero and Klein (2010) presented the first work on joint phrase alignment and extraction at multiple levels. While they take a supervised approach based on discriminative methods, we present a fully unsupervised generative model. A generative probabilistic model where longer units are built through the binary combination of shorter units was proposed by de Marcken (1996) for monolingual word segmentation using the minimum description length (MDL) framework. Our work differs in that it uses Bayesian techniques instead of MDL, and works on two languages, not one. Adaptor gramma"
P11-1064,P07-2045,0,0.00525629,"Missing"
P11-1064,N03-1017,0,0.562956,"not only by terminal, but also non-terminal symbols. This allows for a completely probabilistic model that is able to create a phrase table that achieves competitive accuracy on phrase-based machine translation tasks directly from unaligned sentence pairs. Experiments on several language pairs demonstrate that the proposed model matches the accuracy of traditional two-step word alignment/phrase extraction approach while reducing the phrase table to a fraction of the original size. 1 Introduction The training of translation models for phrasebased statistical machine translation (SMT) systems (Koehn et al., 2003) takes unaligned bilingual training data as input, and outputs a scored table of phrase pairs. This phrase table is traditionally generated by going through a pipeline of two steps, first generating word (or minimal phrase) alignments, then extracting a phrase table that is consistent with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieve"
P11-1064,2005.iwslt-1.8,0,0.00647738,"tokenized, lower-cased, and sentences of over 40 words on either side are removed for TM training. For both tasks, we perform weight tuning and testing on specified development and test sets. We compare the accuracy of our proposed method of joint phrase alignment and extraction using the FLAT, HIER and HLEN models, with a baseline of using word alignments from GIZA ++ and heuristic phrase extraction. Decoding is performed using Moses (Koehn and others, 2007) using the phrase tables learned by each method under consideration, as well as standard bidirectional lexical reordering probabilities (Koehn et al., 2005). Maximum phrase length is limited to 7 in all models, and for the LM we use an interpolated Kneser-Ney 5-gram model. For GIZA ++, we use the standard training regimen up to Model 4, and combine alignments with grow-diag-final-and. For the proposed models, we train for 100 iterations, and use the final sample acquired at the end of the training process for our experiments using a single sample6 . In addition, 6 For most models, while likelihood continued to increase gradually for all 100 iterations, BLEU score gains plateaued after 5-10 iterations, likely due to the strong prior information Al"
P11-1064,N06-1014,0,0.0794575,"f |; λ) 1 M0 (he, f i) =(Pm1 (f |e)Puni (e)Pm1 (e|f )Puni (f )) 2 . Ppois is the Poisson distribution with the average length parameter λ. As long phrases lead to sparsity, we set λ to a relatively small value to allow us to bias against overly long phrases4 . Pm1 is the word-based Model 1 (Brown et al., 1993) probability of one phrase given the other, which incorporates word-based alignment information as prior knowledge in the phrase translation probability. We take the geometric mean5 of the Model 1 probabilities in both directions to encourage alignments that are supported by both models (Liang et al., 2006). It should be noted that while Model 1 probabilities are used, they are only soft constraints, compared with the hard constraint of choosing a single word alignment used in most previous phrase extraction approaches. For Pbu , if g is the non-null phrase in e and f , we calculate the probability as follows: Pbu (he, f i) = Puni (g)Ppois (|g|; λ)/2. Note that Pbu is divided by 2 as the probability is considering null alignments in both directions. 4 Hierarchical ITG Model While in FLAT only minimal phrases were memorized by the model, as DeNero et al. (2008) note We choose 10−2 , 10−3 , or 10−"
P11-1064,W02-1018,0,0.126279,"Missing"
P11-1064,W07-0715,0,0.0636315,"n conflict with this segmentation. Luckily, in the Bayesian framework it is simple to overcome this problem by combining phrase tables from multiple samples. This is equivalent to approximating the integral over various parameter configurations in Equation (1). In MOD, we do this by taking the average of the joint probability and span probability features, and re-calculating the conditional probabilities from the averaged joint probabilities. 6 Related Work In addition to the previously mentioned phrase alignment techniques, there has also been a significant body of work on phrase extraction (Moore and Quirk (2007), Johnson et al. (2007a), inter alia). DeNero and Klein (2010) presented the first work on joint phrase alignment and extraction at multiple levels. While they take a supervised approach based on discriminative methods, we present a fully unsupervised generative model. A generative probabilistic model where longer units are built through the binary combination of shorter units was proposed by de Marcken (1996) for monolingual word segmentation using the minimum description length (MDL) framework. Our work differs in that it uses Bayesian techniques instead of MDL, and works on two languages, n"
P11-1064,W99-0604,0,0.0831392,"on which value gives the best performance on the development set. 5 The probabilities of the geometric mean do not add to one, but we found empirically that even when left unnormalized, this provided much better results than the using the arithmetic mean, which is more theoretically correct. 3 and we confirm in the experiments in Section 7, using only minimal phrases leads to inferior translation results for phrase-based SMT. Because of this, previous research has combined FLAT with heuristic phrase extraction, which exhaustively combines all adjacent phrases permitted by the word alignments (Och et al., 1999). We propose an alternative, fully statistical approach that directly models phrases at multiple granularities, which we will refer to as HIER. By doing so, we are able to do away with heuristic phrase extraction, creating a fully probabilistic model for phrase probabilities that still yields competitive results. Similarly to FLAT, HIER assigns a probability Phier (he, f i; θx , θt ) to phrase pairs, and is parameterized by a phrase table θt and a symbol distribution θx . The main difference from the generative story of the traditional ITG model is that symbols and phrase pairs are generated i"
P11-1064,W09-3804,0,0.435467,"be seen that, as expected, the discounts for short phrases are lower than 636 4.2 Implementation Previous research has used a variety of sampling methods to learn Bayesian phrase based alignment models (DeNero et al., 2008; Blunsom et al., 2009; Blunsom and Cohn, 2010). All of these techniques are applicable to the proposed model, but we choose to apply the sentence-based blocked sampling of Blunsom and Cohn (2010), which has desirable convergence properties compared to sampling single alignments. As exhaustive sampling is too slow for practical purpose, we adopt the beam search algorithm of Saers et al. (2009), and use a probability beam, trimming spans where the probability is at least 1010 times smaller than that of the best hypothesis in the bucket. One important implementation detail that is different from previous models is the management of phrase counts. As a phrase pair ta may have been generated from two smaller component phrases tb and tc , when a sample containing ta is removed from the distribution, it may also be necessary to decrement the counts of tb and tc as well. The Chinese Restaurant Process representation of Pt (Teh, 2006) lends itself to a natural and easily implementable solu"
P11-1064,P06-1124,0,0.832206,"tribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-based divide and conquer strategy to generate phrase pairs that do not exist (or are given low probability) in the phrase distribution. We combine this model with the Bayesian nonparametric Pitman-Yor process (Pitman and Yor, 1997; Teh, 2006), realizing ITG-based divide and conquer through a novel formulation where the Pitman-Yor process uses two copies of itself as a 632 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 632–641, c Portland, Oregon, June 19-24, 2011. 2011 Association for Computational Linguistics base measure. As a result of this modeling strategy, phrases of multiple granularities are generated, and thus memorized, by the Pitman-Yor process. This makes it possible to directly use probabilities of the phrase model as a replacement for the phrase table generated by heuri"
P11-1064,J97-3002,0,0.466135,"le values of the hidden parameters: ∫ P (e|f , hE, Fi) = P (e|f , θ)P (θ|hE, Fi). (1) θ If θ takes the form of a scored phrase table, we can use traditional methods for phrase-based SMT to find P (e|f , θ) and concentrate on creating a model for P (θ|hE, Fi). We decompose this posterior probability using Bayes law into the corpus likelihood and parameter prior probabilities Wong (2002), DeNero et al. (2008), inter alia), and in particular a number of recent works (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009) have used the formalism of inversion transduction grammars (ITGs) (Wu, 1997) to learn phrase alignments. By slightly limit reordering of words, ITGs make it possible to exactly calculate probabilities of phrasal alignments in polynomial time, which is a computationally hard problem when arbitrary reordering is allowed (DeNero and Klein, 2008). The traditional flat ITG generative probability for a particular phrase (or sentence) pair Pf lat (he, f i; θx , θt ) is parameterized by a phrase table θt and a symbol distribution θx . We use the following generative story as a representative of the flat ITG model. 1. Generate symbol x from the multinomial distribution Px (x;"
P11-1064,P08-1012,0,0.360881,"t with these alignments. However, as DeNero and Klein (2010) note, this two step approach results in word alignments that are not optimal for the final task of generating In this paper, we propose the first unsupervised approach to joint alignment and extraction of phrases at multiple granularities. This is achieved by constructing a generative model that includes phrases at many levels of granularity, from minimal phrases all the way up to full sentences. The model is similar to previously proposed phrase alignment models based on inversion transduction grammars (ITGs) (Cherry and Lin, 2007; Zhang et al., 2008; Blunsom et al., 2009), with one important change: ITG symbols and phrase pairs are generated in the opposite order. In traditional ITG models, the branches of a biparse tree are generated from a nonterminal distribution, and each leaf is generated by a word or phrase pair distribution. As a result, only minimal phrases are directly included in the model, while larger phrases must be generated by heuristic extraction methods. In the proposed model, at each branch in the tree, we first attempt to generate a phrase pair from the phrase pair distribution, falling back to ITG-based divide and con"
P11-2093,C00-1004,0,0.0226465,"text as input, and outputs a string of morphemes annotated with parts of speech (POSs). As MA is the first step in Japanese NLP, its accuracy directly affects the accuracy of NLP systems as a whole. In addition, with the proliferation of text in various domains, there is increasing need for methods that are both robust and adaptable to out-of-domain data (Escudero et al., 2000). Previous approaches have used structured predictors such as hidden Markov models (HMMs) or conditional random fields (CRFs), which consider the interactions between neighboring words and parts of speech (Nagata, 1994; Asahara and Matsumoto, 2000; Kudo et al., 2004). However, while structure does provide valuable information, Liang et al. (2008) have shown that gains provided by structured prediction can be largely recovered by using a richer feature set. This approach has also been called “pointwise” prediction, as it makes a single independent decision at each point (Neubig and Mori, 2010). While Liang et al. (2008) focus on the speed benefits of pointwise prediction, we demonstrate that it also allows for more robust and adaptable MA. We find experimental evidence that pointwise MA can exceed the accuracy of a state-of-the-art stru"
P11-2093,P07-1007,0,0.00818117,"cribed in the following section. 3 Domain Adaptation for Morphological Analysis NLP is now being used in domains such as medical text and legal documents, and it is necessary that MA be easily adaptable to these areas. In a domain adaptation situation, we have at our disposal both annotated general domain data, and unannotated target domain data. We would like to annotate the target domain data efficiently to achieve a maximal gain in accuracy for a minimal amount of work. Active learning has been used as a way to pick data that is useful to annotate in this scenario for several applications (Chan and Ng, 2007; Rai et al., 2010) so we adopt an active-learning-based approach here. When adapting sequence-based prediction methods, most active learning approaches have focused on picking full sentences that are valuable to annotate (Ringger et al., 2007; Settles and Craven, 2008). However, even within sentences, there are generally a few points of interest surrounded by large segments that are well covered by already annotated data. Partial annotation provides a solution to this problem (Tsuboi et al., 2008; Sassano and Kurohashi, 2010). In partial annotation, data that will not contribute to the improv"
P11-2093,W00-1322,0,0.101669,"Missing"
P11-2093,P09-1058,0,0.00709397,"e annotated. In a realistic domain adaptation scenario, we find that a combination of pointwise prediction, partial annotation, and active learning allows for easy adaptation. 2 Japanese Morphological Analysis Japanese MA takes an unsegmented string of characters xI1 as input, segments it into morphemes wJ1 , and annotates each morpheme with a part of speech tJ1 . This can be formulated as a two-step process of first segmenting words, then estimating POSs (Ng and Low, 2004), or as a single joint process of finding a morpheme/POS string from unsegmented text (Kudo et al., 2004; Nakagawa, 2004; Kruengkrai et al., 2009). In this section we describe an existing joint sequence-based method for Japanese MA, as well as our proposed two-step pointwise method. 2.1 Joint Sequence-Based MA Japanese MA has traditionally used sequence based models, finding a maximal POS sequence for enType Character n-gram Char. Type n-gram WS Only POS Only Figure 1: Joint MA (a) performs maximization over the entire sequence, while two-step MA (b) maximizes the 4 boundary and 4 POS tags independently. Type Unigram Bigram Feature Strings tj , tj wj , c(wj ), tj c(wj ) tj−1 tj , tj−1 tj wj−1 , tj−1 tj wj , tj−1 tj wj−1 wj Table 1: Feat"
P11-2093,W04-3230,0,0.778036,"string of morphemes annotated with parts of speech (POSs). As MA is the first step in Japanese NLP, its accuracy directly affects the accuracy of NLP systems as a whole. In addition, with the proliferation of text in various domains, there is increasing need for methods that are both robust and adaptable to out-of-domain data (Escudero et al., 2000). Previous approaches have used structured predictors such as hidden Markov models (HMMs) or conditional random fields (CRFs), which consider the interactions between neighboring words and parts of speech (Nagata, 1994; Asahara and Matsumoto, 2000; Kudo et al., 2004). However, while structure does provide valuable information, Liang et al. (2008) have shown that gains provided by structured prediction can be largely recovered by using a richer feature set. This approach has also been called “pointwise” prediction, as it makes a single independent decision at each point (Neubig and Mori, 2010). While Liang et al. (2008) focus on the speed benefits of pointwise prediction, we demonstrate that it also allows for more robust and adaptable MA. We find experimental evidence that pointwise MA can exceed the accuracy of a state-of-the-art structured approach (Kud"
P11-2093,I08-7018,0,0.014986,"y annotated data has been presented by Tsuboi et al. (2008). However, when using partial annotation, CRFs’ already slow training time becomes slower still, as they must be trained over every sequence that has at least one annotated point. Training time is important in an active learning situation, as an annotator must wait while the model is being re-trained. 4 Experiments In order to test the effectiveness of pointwise MA, we did an experiment measuring accuracy both on in-domain data, and in a domain-adaptation situation. We used the Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008), specifying the whitepaper, news, and books sections as our general domain corpus, and the web text section as our target domain corpus (Table 3). As a representative of joint sequence-based MA described in 2.1, we used MeCab (Kudo, 2006), an open source implementation of Kudo et al. (2004)’s CRF-based method (we will call this JOINT). For the pointwise two-step method, we trained logistic regression models with the LIBLINEAR toolkit (Fan et al., 2008) using the features described in Section 2.2 (2- LR). In addition, we trained a CRF-based model with the CRFSuite toolkit (Okazaki, 2007) using"
P11-2093,C94-1032,0,0.0284615,"g of Japanese text as input, and outputs a string of morphemes annotated with parts of speech (POSs). As MA is the first step in Japanese NLP, its accuracy directly affects the accuracy of NLP systems as a whole. In addition, with the proliferation of text in various domains, there is increasing need for methods that are both robust and adaptable to out-of-domain data (Escudero et al., 2000). Previous approaches have used structured predictors such as hidden Markov models (HMMs) or conditional random fields (CRFs), which consider the interactions between neighboring words and parts of speech (Nagata, 1994; Asahara and Matsumoto, 2000; Kudo et al., 2004). However, while structure does provide valuable information, Liang et al. (2008) have shown that gains provided by structured prediction can be largely recovered by using a richer feature set. This approach has also been called “pointwise” prediction, as it makes a single independent decision at each point (Neubig and Mori, 2010). While Liang et al. (2008) focus on the speed benefits of pointwise prediction, we demonstrate that it also allows for more robust and adaptable MA. We find experimental evidence that pointwise MA can exceed the accura"
P11-2093,C04-1067,0,0.00975807,"ular sentence are annotated. In a realistic domain adaptation scenario, we find that a combination of pointwise prediction, partial annotation, and active learning allows for easy adaptation. 2 Japanese Morphological Analysis Japanese MA takes an unsegmented string of characters xI1 as input, segments it into morphemes wJ1 , and annotates each morpheme with a part of speech tJ1 . This can be formulated as a two-step process of first segmenting words, then estimating POSs (Ng and Low, 2004), or as a single joint process of finding a morpheme/POS string from unsegmented text (Kudo et al., 2004; Nakagawa, 2004; Kruengkrai et al., 2009). In this section we describe an existing joint sequence-based method for Japanese MA, as well as our proposed two-step pointwise method. 2.1 Joint Sequence-Based MA Japanese MA has traditionally used sequence based models, finding a maximal POS sequence for enType Character n-gram Char. Type n-gram WS Only POS Only Figure 1: Joint MA (a) performs maximization over the entire sequence, while two-step MA (b) maximizes the 4 boundary and 4 POS tags independently. Type Unigram Bigram Feature Strings tj , tj wj , c(wj ), tj c(wj ) tj−1 tj , tj−1 tj wj−1 , tj−1 tj wj , tj−"
P11-2093,neubig-mori-2010-word,1,0.450813,"(Escudero et al., 2000). Previous approaches have used structured predictors such as hidden Markov models (HMMs) or conditional random fields (CRFs), which consider the interactions between neighboring words and parts of speech (Nagata, 1994; Asahara and Matsumoto, 2000; Kudo et al., 2004). However, while structure does provide valuable information, Liang et al. (2008) have shown that gains provided by structured prediction can be largely recovered by using a richer feature set. This approach has also been called “pointwise” prediction, as it makes a single independent decision at each point (Neubig and Mori, 2010). While Liang et al. (2008) focus on the speed benefits of pointwise prediction, we demonstrate that it also allows for more robust and adaptable MA. We find experimental evidence that pointwise MA can exceed the accuracy of a state-of-the-art structured approach (Kudo et al., 2004) on in-domain data, and is significantly more robust to out-of-domain data. We also show that pointwise MA can be adapted to new domains with minimal effort through the combination of active learning and partial annotation (Tsuboi et al., 2008), where only informative parts of a particular sentence are annotated. In"
P11-2093,W04-3236,0,0.0194173,"h the combination of active learning and partial annotation (Tsuboi et al., 2008), where only informative parts of a particular sentence are annotated. In a realistic domain adaptation scenario, we find that a combination of pointwise prediction, partial annotation, and active learning allows for easy adaptation. 2 Japanese Morphological Analysis Japanese MA takes an unsegmented string of characters xI1 as input, segments it into morphemes wJ1 , and annotates each morpheme with a part of speech tJ1 . This can be formulated as a two-step process of first segmenting words, then estimating POSs (Ng and Low, 2004), or as a single joint process of finding a morpheme/POS string from unsegmented text (Kudo et al., 2004; Nakagawa, 2004; Kruengkrai et al., 2009). In this section we describe an existing joint sequence-based method for Japanese MA, as well as our proposed two-step pointwise method. 2.1 Joint Sequence-Based MA Japanese MA has traditionally used sequence based models, finding a maximal POS sequence for enType Character n-gram Char. Type n-gram WS Only POS Only Figure 1: Joint MA (a) performs maximization over the entire sequence, while two-step MA (b) maximizes the 4 boundary and 4 POS tags ind"
P11-2093,C04-1081,0,0.0439892,"ry as features (Table 2). Specifically dictionary features for word segmentation ls and rs are active if a string of length s included in the dictionary is present directly to the left or right of the present word boundary, and is is active if the present word boundary is included in a dictionary word of length s. Dictionary feature djk for POS estimation indicates whether the current word wj occurs as a dictionary entry with tag tk . Previous work using this two-stage approach has used sequence-based prediction methods, such as maximum entropy Markov models (MEMMs) or CRFs (Ng and Low, 2004; Peng et al., 2004). However, as Liang et al. (2008) note, and we confirm, sequence-based predictors are often not necessary when an appropriately rich feature set is used. One important difference between our formulation and that of Liang et al. (2008) and all other previous methods is that we rely only on features that are directly calculable from the surface string, without using estimated information such as word boundaries or neighboring POS tags2 . This allows for training from sentences that are partially annotated as described in the following section. 3 Domain Adaptation for Morphological Analysis NLP i"
P11-2093,W10-0104,0,0.0352595,"Missing"
P11-2093,W07-1516,0,0.0171938,"n situation, we have at our disposal both annotated general domain data, and unannotated target domain data. We would like to annotate the target domain data efficiently to achieve a maximal gain in accuracy for a minimal amount of work. Active learning has been used as a way to pick data that is useful to annotate in this scenario for several applications (Chan and Ng, 2007; Rai et al., 2010) so we adopt an active-learning-based approach here. When adapting sequence-based prediction methods, most active learning approaches have focused on picking full sentences that are valuable to annotate (Ringger et al., 2007; Settles and Craven, 2008). However, even within sentences, there are generally a few points of interest surrounded by large segments that are well covered by already annotated data. Partial annotation provides a solution to this problem (Tsuboi et al., 2008; Sassano and Kurohashi, 2010). In partial annotation, data that will not contribute to the improvement of the classifier is left untagged. For example, if there is a single difficult word in a long sentence, only the word boundaries and POS of the difficult word will be tagged. “Dif2 Dictionary features are active if the string exists, re"
P11-2093,P10-1037,0,0.0291745,"ick data that is useful to annotate in this scenario for several applications (Chan and Ng, 2007; Rai et al., 2010) so we adopt an active-learning-based approach here. When adapting sequence-based prediction methods, most active learning approaches have focused on picking full sentences that are valuable to annotate (Ringger et al., 2007; Settles and Craven, 2008). However, even within sentences, there are generally a few points of interest surrounded by large segments that are well covered by already annotated data. Partial annotation provides a solution to this problem (Tsuboi et al., 2008; Sassano and Kurohashi, 2010). In partial annotation, data that will not contribute to the improvement of the classifier is left untagged. For example, if there is a single difficult word in a long sentence, only the word boundaries and POS of the difficult word will be tagged. “Dif2 Dictionary features are active if the string exists, regardless of whether it is treated as a single word in wJ1 , and thus can be calculated without the word segmentation result. Type General Target Train 782k 153k Test 87.5k 17.3k Table 3: General and target domain corpus sizes in words. ficult” words can be selected using active learning a"
P11-2093,P02-1064,0,0.0990311,"(xr xr+1 xr+2 ) ls , rs , is wj , c(wj ), djk Table 2: Features for the two-step model. xl and xr indicate the characters to the left and right of the word boundary or word wj in question. ls , rs , and is represent the left, right, and inside dictionary features, while djk indicates that tag k exists in the dictionary for word j. 2.2 2-Step Pointwise MA In our research, we take a two-step approach, first segmenting character sequence xI1 into the word sequence wJ1 with the highest probability, then tagging each word with parts of speech tJ1 . This approach is shown in Figure 1 (b). We follow Sassano (2002) in formulating word segmentation as a binary classification problem, estimating boundary tags bI−1 1 . Tag bi = 1 indicates that a word boundary exists between characters xi and xi+1 , while bi = 0 indicates that a word boundary does not exist. POS estimation can also be formulated as a multi-class classification problem, where we choose one tag tj for each word wj . These two classification problems can be solved by tools in the standard machine learning toolbox such as logistic regression (LR), support vector machines (SVMs), or conditional random fields (CRFs). We use information about the"
P11-2093,D08-1112,0,0.0215178,"t our disposal both annotated general domain data, and unannotated target domain data. We would like to annotate the target domain data efficiently to achieve a maximal gain in accuracy for a minimal amount of work. Active learning has been used as a way to pick data that is useful to annotate in this scenario for several applications (Chan and Ng, 2007; Rai et al., 2010) so we adopt an active-learning-based approach here. When adapting sequence-based prediction methods, most active learning approaches have focused on picking full sentences that are valuable to annotate (Ringger et al., 2007; Settles and Craven, 2008). However, even within sentences, there are generally a few points of interest surrounded by large segments that are well covered by already annotated data. Partial annotation provides a solution to this problem (Tsuboi et al., 2008; Sassano and Kurohashi, 2010). In partial annotation, data that will not contribute to the improvement of the classifier is left untagged. For example, if there is a single difficult word in a long sentence, only the word boundaries and POS of the difficult word will be tagged. “Dif2 Dictionary features are active if the string exists, regardless of whether it is t"
P11-2093,C08-1113,1,0.943702,"” prediction, as it makes a single independent decision at each point (Neubig and Mori, 2010). While Liang et al. (2008) focus on the speed benefits of pointwise prediction, we demonstrate that it also allows for more robust and adaptable MA. We find experimental evidence that pointwise MA can exceed the accuracy of a state-of-the-art structured approach (Kudo et al., 2004) on in-domain data, and is significantly more robust to out-of-domain data. We also show that pointwise MA can be adapted to new domains with minimal effort through the combination of active learning and partial annotation (Tsuboi et al., 2008), where only informative parts of a particular sentence are annotated. In a realistic domain adaptation scenario, we find that a combination of pointwise prediction, partial annotation, and active learning allows for easy adaptation. 2 Japanese Morphological Analysis Japanese MA takes an unsegmented string of characters xI1 as input, segments it into morphemes wJ1 , and annotates each morpheme with a part of speech tJ1 . This can be formulated as a two-step process of first segmenting words, then estimating POSs (Ng and Low, 2004), or as a single joint process of finding a morpheme/POS string"
P12-1018,P02-1051,0,0.0205265,"ey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumer"
P12-1018,I08-1033,0,0.0173092,"ed by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word"
P12-1018,N10-1028,0,0.511558,"r)I(as,S,u,U )I(aS,t,U,v ) s≤S≤t u≤U ≤v + X X Px (inv)I(as,S,U,v )I(aS,t,u,U ) s≤S≤t u≤U ≤v where Px (str) and Px (inv) are the probability of straight and inverted ITG productions. While the exact calculation of these probabilities can be performed in O(n6 ) time, where n is the 2 Pt can be specified according to Bayesian statistics as described by Neubig et al. (2011). 168 length of the sentence, this is impractical for all but the shortest sentences. Thus it is necessary to use methods to reduce the search space such as beamsearch based chart parsing (Saers et al., 2009) or slice sampling (Blunsom and Cohn, 2010).3 In this section we propose the use of a look-ahead probability to increase the efficiency of this chart parsing. Taking the example of Saers et al. (2009), spans are pushed onto a different queue based on their size, and queues are processed in ascending order of size. Agendas can further be trimmed based on a histogram beam (Saers et al., 2009) or probability beam (Neubig et al., 2011) compared to the best hypothesis a ˆ. In other words, we have a queue discipline based on the inside probability, and all spans ak where I(ak ) &lt; cI(ˆ a) are pruned. c is a constant describing the width of th"
P12-1018,P09-1088,0,0.0977356,"normalize or split the sentence into morpheme streams (Corston-Oliver and Gamon, 2004). 167 enough information to allow for effective alignment with its corresponding elements in eI1 . While this is often the case in word-based models, for characterbased models this assumption breaks down, as there is often no clear correspondence between characters. 3.2 Many-to-Many Alignment On the other hand, in recent years, there have been advances in many-to-many alignment techniques that are able to align multi-element chunks on both sides of the translation (Marcu and Wong, 2002; DeNero et al., 2008; Blunsom et al., 2009; Neubig et al., 2011). Many-to-many methods can be expected to achieve superior results on character-based alignment, as the aligner can use information about substrings, which may correspond to letters, morphemes, words, or short phrases. Here, we focus on the model presented by Neubig et al. (2011), which uses Bayesian inference in the phrasal inversion transduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the process of biparsing, which we explain more i"
P12-1018,W07-0735,0,0.0131682,"is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of wor"
P12-1018,J93-2003,0,0.0971778,"ir. We represent our target and source sentences as eI1 and f J1 . ei and fj represent single elements of the target and source sentences respectively. These may be words in word-based alignment models or single characters in character-based alignment models.1 We define our alignment as aK 1 , where each element is a span ak = hs, t, u, vi indicating that the target string es , . . . , et and source string fu , . . . , fv are aligned to each-other. 3.1 One-to-Many Alignment The most well-known and widely-used models for bitext alignment are for one-to-many alignment, including the IBM models (Brown et al., 1993) and HMM alignment model (Vogel et al., 1996). These models are by nature directional, attempting to find the alignments that maximize the conditional probability of the target sentence P (eI1 |f J1 , aK 1 ). For computational reasons, the IBM models are restricted to aligning each word on the target side to a single word on the source side. In the formalism presented above, this means that each ei must be included in at most one span, and for each span u = v. Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al., 2"
P12-1018,2002.tmi-papers.3,0,0.0215762,"in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods f"
P12-1018,W08-0336,0,0.0274774,"Missing"
P12-1018,D09-1075,0,0.0227118,"ion (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach is attractive conceptual"
P12-1018,P06-3003,0,0.165382,"ter-based) Model 1 probability, which can be efficiently calculated using the dynamic programming algorithm described by Brown et al. (1993). However, for reasons previously stated in Section 3, these methods are less satisfactory when performing character-based alignment, as the amount of information contained in a character does not allow for proper alignment. 5.2 Substring Co-occurrence Priors Instead, we propose a method for using raw substring co-occurrence statistics to bias alignments towards substrings that often co-occur in the entire training corpus. This is similar to the method of Cromieres (2006), but instead of using these cooccurrence statistics as a heuristic alignment criterion, we incorporate them as a prior probability in a statistical model that can take into account mutual exclusivity of overlapping substrings in a sentence. We define this prior probability using three counts over substrings c(e), c(f ), and c(e, f ). c(e) and c(f ) count the total number of sentences in which the substrings e and f occur respectively. c(e, f ) is a count of the total number of sentences in which the substring e occurs on the target side, and f occurs on the source side. We perform the calcula"
P12-1018,D08-1033,0,0.0307241,"Missing"
P12-1018,W11-2107,0,0.014441,"riments, although it does indicate that we must have access to tokenized data for the development set. 7 171 6.2 Quantitative Evaluation Table 2 presents a quantitative analysis of the translation results for each of the proposed methods. As previous research has shown that it is more difficult to translate into morphologically rich languages than into English (Koehn, 2005), we perform experiments translating in both directions for all language pairs. We evaluate translation quality using BLEU score (Papineni et al., 2002), both on the word and character level (with n = 4), as well as METEOR (Denkowski and Lavie, 2011) on the word level. It can be seen that character-based translation with all of the proposed alignment improvements greatly exceeds character-based translation using one-to-many alignment, confirming that substringbased information is necessary for accurate alignments. When compared with word-based translation, character-based translation achieves better, comparable, or inferior results on character-based BLEU, comparable or inferior results on METEOR, and inferior results on word-based BLEU. The differences between the evaluation metrics are due to the fact that character-based translation of"
P12-1018,H05-1085,0,0.0216227,"ollection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine"
P12-1018,P09-1104,0,0.122759,"when co-occurrence counts are used. More importantly, they allow for more aggressive beam pruning, increasing sampling speed from 1.3 sent/s to 2.5 sent/s for Finnish, and 6.8 sent/s to 11.6 sent/s for Japanese. 7 Conclusion and Future Directions This paper demonstrated that character-based translation can act as a unified framework for handling difficult problems in translation: morphology, compound words, transliteration, and segmentation. One future challenge includes scaling training up to longer sentences, which can likely be achieved through methods such as the heuristic span pruning of Haghighi et al. (2009) or sentence splitting of Vilar et al. (2007). Monolingual data could also be used to improve estimates of our substring-based prior. In addition, error analysis showed that wordbased translation performed better than characterbased translation on reordering and lexical choice, indicating that improved decoding (or pre-ordering) and language modeling tailored to character-based translation will likely greatly improve accuracy. Finally, we plan to explore the middle ground between word-based and character based translation, allowing for the flexibility of character-based translation, while usin"
P12-1018,N07-1018,0,0.0294521,"ng, 2003), and tic-tac-toe pruning for wordbased ITGs (Zhang and Gildea, 2005). As the calculation of the actual outside probability O(ak ) is just as expensive as parsing itself, it is necessary to approximate this with heuristic function O∗ that can be calculated efficiently. Here we propose a heuristic function that is designed specifically for phrasal ITGs and is computable with worst-case complexity of n2 , compared with the n3 amortized time of the tic-tac-toe pruning 3 Applying beam-search before sampling will sample from an improper distribution, although Metropolis-in-Gibbs sampling (Johnson et al., 2007) can be used to compensate. However, we found that this had no significant effect on results, so we omit the Metropolis-in-Gibbs step for experiments. algorithm described by (Zhang et al., 2008a). During the calculation of the phrase generation probabilities Pt , we save the best inside probability I ∗ for each monolingual span. Ie∗ (s, t) = max If∗ (u, v) = max {˜ a=h˜ s,t˜,˜ u,˜ v i;˜ s=s,t˜=t} Pt (˜ a) {˜ a=h˜ s,t˜,˜ u,˜ v i;˜ u=u,˜ v =v} Pt (˜ a) For each language independently, we calculate forward probabilities α and backward probabilities β. For example, αe (s) is the maximum probabilit"
P12-1018,N03-1016,0,0.0120405,"is unwise to ignore competing hypotheses during beam pruning. Particularly, the alignment “les/1960s” competes with the high-probability alignment “les/the,” so intuitively should be a good candidate for pruning. However its probability is only slightly higher than “ann´ees/1960s,” which has no competing hypotheses and thus should not be trimmed. In order to take into account competing hypotheses, we can use for our queue discipline not only the inside probability I(ak ), but also the outside probability O(ak ), the probability of generating all spans other than ak , as in A* search for CFGs (Klein and Manning, 2003), and tic-tac-toe pruning for wordbased ITGs (Zhang and Gildea, 2005). As the calculation of the actual outside probability O(ak ) is just as expensive as parsing itself, it is necessary to approximate this with heuristic function O∗ that can be calculated efficiently. Here we propose a heuristic function that is designed specifically for phrasal ITGs and is computable with worst-case complexity of n2 , compared with the n3 amortized time of the tic-tac-toe pruning 3 Applying beam-search before sampling will sample from an improper distribution, although Metropolis-in-Gibbs sampling (Johnson e"
P12-1018,N03-1017,0,0.0487988,"n et al., 1993) and HMM alignment model (Vogel et al., 1996). These models are by nature directional, attempting to find the alignments that maximize the conditional probability of the target sentence P (eI1 |f J1 , aK 1 ). For computational reasons, the IBM models are restricted to aligning each word on the target side to a single word on the source side. In the formalism presented above, this means that each ei must be included in at most one span, and for each span u = v. Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al., 2003). However, in order for one-to-many alignment methods to be effective, each fj must contain 1 Some previous work has also performed alignment using morphological analyzers to normalize or split the sentence into morpheme streams (Corston-Oliver and Gamon, 2004). 167 enough information to allow for effective alignment with its corresponding elements in eI1 . While this is often the case in word-based models, for characterbased models this assumption breaks down, as there is often no clear correspondence between characters. 3.2 Many-to-Many Alignment On the other hand, in recent years, there hav"
P12-1018,W04-3250,0,0.0751149,"35.45 en-fi 13.22 / 58.50 / 27.03 13.12 / 59.27 / 27.09 04.58 / 35.09 / 11.76 12.14 / 59.02 / 25.31 en-fr 32.19 / 69.20 / 52.39 31.66 / 69.61 / 51.98 10.31 / 42.84 / 25.06 27.74 / 67.44 / 48.56 en-ja 20.79 / 27.01 / 38.41 20.26 / 28.34 / 38.34 01.48 / 00.72 / 06.67 17.90 / 28.46 / 35.71 Table 2: Translation results in word-based BLEU, character-based BLEU, and METEOR for the GIZA++ and phrasal ITG models for word and character-based translation, with bold numbers indicating a statistically insignificant difference from the best system according to the bootstrap resampling method at p = 0.05 (Koehn, 2004). source and target were 100 characters or less,6 the total size of which is shown in Table 1. In characterbased translation, white spaces between words were treated as any other character and not given any special treatment. Evaluation was performed on tokenized and lower-cased data. For alignment, we use the GIZA++ implementation of one-to-many alignment7 and the pialign implementation of the phrasal ITG models8 modified with the proposed improvements. For GIZA++, we used the default settings for word-based alignment, but used the HMM model for character-based alignment to allow for alignmen"
P12-1018,2005.mtsummit-papers.11,0,0.090289,"ed enhancements to the model. Finally, we perform a qualitative analysis, which finds that character-based translation can handle unsegmented text, conjugation, and proper names in a unified framework with no additional processing. 2 Related Work on Data Sparsity in SMT As traditional SMT systems treat all words as single tokens without considering their internal structure, major problems of data sparsity occur for less frequent tokens. In fact, it has been shown that there is a direct negative correlation between vocabulary 166 size (and thus sparsity) of a language and translation accuracy (Koehn, 2005). Sparsity causes trouble for alignment models, both in the form of incorrectly aligned uncommon words, and in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regu"
P12-1018,N03-2016,0,0.0319786,"logical analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), alth"
P12-1018,N04-4015,0,0.0188944,"f garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named en"
P12-1018,P11-1140,0,0.0221195,"e segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and K"
P12-1018,W02-1018,0,0.0382455,"alignment using morphological analyzers to normalize or split the sentence into morpheme streams (Corston-Oliver and Gamon, 2004). 167 enough information to allow for effective alignment with its corresponding elements in eI1 . While this is often the case in word-based models, for characterbased models this assumption breaks down, as there is often no clear correspondence between characters. 3.2 Many-to-Many Alignment On the other hand, in recent years, there have been advances in many-to-many alignment techniques that are able to align multi-element chunks on both sides of the translation (Marcu and Wong, 2002; DeNero et al., 2008; Blunsom et al., 2009; Neubig et al., 2011). Many-to-many methods can be expected to achieve superior results on character-based alignment, as the aligner can use information about substrings, which may correspond to letters, morphemes, words, or short phrases. Here, we focus on the model presented by Neubig et al. (2011), which uses Bayesian inference in the phrasal inversion transduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the pr"
P12-1018,P11-1090,0,0.014234,"nsduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the process of biparsing, which we explain more in the following section. Phrasal ITGs are ITGs that allow for non-terminals that can emit phrase pairs with multiple elements on both the source and target sides. It should be noted that there are other many-to-many alignment methods that have been used for simultaneously discovering morphological boundaries over multiple languages (Snyder and Barzilay, 2008; Naradowsky and Toutanova, 2011), but these have generally been applied to single words or short phrases, and it is not immediately clear that they will scale to aligning full sentences. 4 Look-Ahead Biparsing In this work, we experiment with the alignment method of Neubig et al. (2011), which can achieve competitive accuracy with a much smaller phrase table than traditional methods. This is important in the character-based translation context, as we would like to use phrases that contain large numbers of characters without creating a phrase table so large that it cannot be used in actual decoding. In this framework, trainin"
P12-1018,P11-1064,1,0.701097,"of traditional word-based systems using only character strings. We draw upon recent advances in many-to-many alignment, which allows for the automatic choice of the length of units to be aligned. As these units may be at the character, subword, word, or multi-word phrase level, we conjecture that this will allow for better character alignments than one-to-many alignment techniques, and will allow for better translation of uncommon words than traditional word-based models by breaking down words into their component parts. We also propose two improvements to the manyto-many alignment method of Neubig et al. (2011). One barrier to applying many-to-many alignment models to character strings is training cost. In the inversion transduction grammar (ITG) framework (Wu, 1997), which is widely used in many-to-many alignment, search is cumbersome for longer sentences, a problem that is further exacerbated when using characters instead of words as the basic unit. As a step towards overcoming this difficulty, we increase the efficiency of the beam-search technique of Saers et al. (2009) by augmenting it with look-ahead probabilities in the spirit of A* search. Secondly, we describe a method to seed the search pr"
P12-1018,C10-1092,0,0.0075172,"1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach is attractive conceptually, previous research"
P12-1018,C00-2162,0,0.113372,"d uncommon words, and in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophistica"
P12-1018,J03-1002,0,0.00795056,"traditional SMT systems treat all words as single tokens without considering their internal structure, major problems of data sparsity occur for less frequent tokens. In fact, it has been shown that there is a direct negative correlation between vocabulary 166 size (and thus sparsity) of a language and translation accuracy (Koehn, 2005). Sparsity causes trouble for alignment models, both in the form of incorrectly aligned uncommon words, and in the form of garbage collection, where uncommon words in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more diffi"
P12-1018,P02-1040,0,0.101074,"atmt.org/moses/ 11 We chose this set-up to minimize the effect of tuning criterion on our experiments, although it does indicate that we must have access to tokenized data for the development set. 7 171 6.2 Quantitative Evaluation Table 2 presents a quantitative analysis of the translation results for each of the proposed methods. As previous research has shown that it is more difficult to translate into morphologically rich languages than into English (Koehn, 2005), we perform experiments translating in both directions for all language pairs. We evaluate translation quality using BLEU score (Papineni et al., 2002), both on the word and character level (with n = 4), as well as METEOR (Denkowski and Lavie, 2011) on the word level. It can be seen that character-based translation with all of the proposed alignment improvements greatly exceeds character-based translation using one-to-many alignment, confirming that substringbased information is necessary for accurate alignments. When compared with word-based translation, character-based translation achieves better, comparable, or inferior results on character-based BLEU, comparable or inferior results on METEOR, and inferior results on word-based BLEU. The"
P12-1018,W09-3804,0,0.613151,"els by breaking down words into their component parts. We also propose two improvements to the manyto-many alignment method of Neubig et al. (2011). One barrier to applying many-to-many alignment models to character strings is training cost. In the inversion transduction grammar (ITG) framework (Wu, 1997), which is widely used in many-to-many alignment, search is cumbersome for longer sentences, a problem that is further exacerbated when using characters instead of words as the basic unit. As a step towards overcoming this difficulty, we increase the efficiency of the beam-search technique of Saers et al. (2009) by augmenting it with look-ahead probabilities in the spirit of A* search. Secondly, we describe a method to seed the search process using counts of all substring pairs in the corpus to bias the phrase alignment model. We do this by defining prior probabilities based on these substring counts within the Bayesian phrasal ITG framework. An evaluation on four language pairs with differing morphological properties shows that for distant language pairs, character-based SMT can achieve translation accuracy comparable to word-based systems. In addition, we perform ablation studies, showing that thes"
P12-1018,P08-1084,0,0.0198035,"n the phrasal inversion transduction grammar (ITG, Wu (1997)) framework. ITGs are a variety of synchronous context free grammar (SCFG) that allows for many-to-many alignment to be achieved in polynomial time through the process of biparsing, which we explain more in the following section. Phrasal ITGs are ITGs that allow for non-terminals that can emit phrase pairs with multiple elements on both the source and target sides. It should be noted that there are other many-to-many alignment methods that have been used for simultaneously discovering morphological boundaries over multiple languages (Snyder and Barzilay, 2008; Naradowsky and Toutanova, 2011), but these have generally been applied to single words or short phrases, and it is not immediately clear that they will scale to aligning full sentences. 4 Look-Ahead Biparsing In this work, we experiment with the alignment method of Neubig et al. (2011), which can achieve competitive accuracy with a much smaller phrase table than traditional methods. This is important in the character-based translation context, as we would like to use phrases that contain large numbers of characters without creating a phrase table so large that it cannot be used in actual dec"
P12-1018,P11-1024,0,0.0120071,"oblem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt wi"
P12-1018,P06-1122,0,0.012896,"s in one language are incorrectly aligned to large segments of the sentence in the other language (Och and Ney, 2003). Unknown words are also a problem during the translation process, and the default approach is to map them as-is into the target sentence. This is a major problem in agglutinative languages such as Finnish or compounding languages such as German. Previous works have attempted to handle morphology, decompounding and regularization through lemmatization, morphological analysis, or unsupervised techniques (Nießen and Ney, 2000; Brown, 2002; Lee, 2004; Goldwater and McClosky, 2005; Talbot and Osborne, 2006; Mermer and Akın, 2010; Macherey et al., 2011). It has also been noted that it is more difficult to translate into morphologically rich languages, and methods for modeling target-side morphology have attracted interest in recent years (Bojar, 2007; Subotin, 2011). Another source of data sparsity that occurs in all languages is proper names, which have been handled by using cognates or transliteration to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliter"
P12-1018,2009.eamt-1.3,0,0.0804142,"for languages with explicit word The first author is now affiliated with the Nara Institute of Science and Technology. These difficulties occur because we are translating sequences of words as our basic unit. On the other hand, Vilar et al. (2007) examine the possibility of instead treating each sentence as sequences of characters to be translated. This method is attractive, as it is theoretically able to handle all sparsity phenomena in a single unified framework, but has only been shown feasible between similar language pairs such as Spanish-Catalan (Vilar et al., 2007), Swedish-Norwegian (Tiedemann, 2009), and ThaiLao (Sornlertlamvanich et al., 2008), which have a strong co-occurrence between single characters. As Vilar et al. (2007) state and we confirm, accurate translations cannot be achieved when applying traditional translation techniques to character-based translation for less similar language pairs. In this paper, we propose improvements to the alignment process tailored to character-based machine translation, and demonstrate that it is, in fact, possible to achieve translation accuracies that ap165 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,"
P12-1018,W07-0705,0,0.459683,"d eI1 is assumed to be a word in the source and target languages. However, the definition of a “word” is often problematic. The most obvious example of this lies in languages that do not separate words with white space such as Chinese, Japanese, or Thai, in which the choice of a segmentation standard has a large effect on translation accuracy (Chang et al., 2008). Even for languages with explicit word The first author is now affiliated with the Nara Institute of Science and Technology. These difficulties occur because we are translating sequences of words as our basic unit. On the other hand, Vilar et al. (2007) examine the possibility of instead treating each sentence as sequences of characters to be translated. This method is attractive, as it is theoretically able to handle all sparsity phenomena in a single unified framework, but has only been shown feasible between similar language pairs such as Spanish-Catalan (Vilar et al., 2007), Swedish-Norwegian (Tiedemann, 2009), and ThaiLao (Sornlertlamvanich et al., 2008), which have a strong co-occurrence between single characters. As Vilar et al. (2007) state and we confirm, accurate translations cannot be achieved when applying traditional translation"
P12-1018,C96-2141,0,0.510173,"ces as eI1 and f J1 . ei and fj represent single elements of the target and source sentences respectively. These may be words in word-based alignment models or single characters in character-based alignment models.1 We define our alignment as aK 1 , where each element is a span ak = hs, t, u, vi indicating that the target string es , . . . , et and source string fu , . . . , fv are aligned to each-other. 3.1 One-to-Many Alignment The most well-known and widely-used models for bitext alignment are for one-to-many alignment, including the IBM models (Brown et al., 1993) and HMM alignment model (Vogel et al., 1996). These models are by nature directional, attempting to find the alignments that maximize the conditional probability of the target sentence P (eI1 |f J1 , aK 1 ). For computational reasons, the IBM models are restricted to aligning each word on the target side to a single word on the source side. In the formalism presented above, this means that each ei must be included in at most one span, and for each span u = v. Traditionally, these models are run in both directions and combined using heuristics to create many-to-many alignments (Koehn et al., 2003). However, in order for one-to-many align"
P12-1018,J97-3002,0,0.511044,"th of units to be aligned. As these units may be at the character, subword, word, or multi-word phrase level, we conjecture that this will allow for better character alignments than one-to-many alignment techniques, and will allow for better translation of uncommon words than traditional word-based models by breaking down words into their component parts. We also propose two improvements to the manyto-many alignment method of Neubig et al. (2011). One barrier to applying many-to-many alignment models to character strings is training cost. In the inversion transduction grammar (ITG) framework (Wu, 1997), which is widely used in many-to-many alignment, search is cumbersome for longer sentences, a problem that is further exacerbated when using characters instead of words as the basic unit. As a step towards overcoming this difficulty, we increase the efficiency of the beam-search technique of Saers et al. (2009) by augmenting it with look-ahead probabilities in the spirit of A* search. Secondly, we describe a method to seed the search process using counts of all substring pairs in the corpus to bias the phrase alignment model. We do this by defining prior probabilities based on these substring"
P12-1018,P05-1059,0,0.00986268,"arly, the alignment “les/1960s” competes with the high-probability alignment “les/the,” so intuitively should be a good candidate for pruning. However its probability is only slightly higher than “ann´ees/1960s,” which has no competing hypotheses and thus should not be trimmed. In order to take into account competing hypotheses, we can use for our queue discipline not only the inside probability I(ak ), but also the outside probability O(ak ), the probability of generating all spans other than ak , as in A* search for CFGs (Klein and Manning, 2003), and tic-tac-toe pruning for wordbased ITGs (Zhang and Gildea, 2005). As the calculation of the actual outside probability O(ak ) is just as expensive as parsing itself, it is necessary to approximate this with heuristic function O∗ that can be calculated efficiently. Here we propose a heuristic function that is designed specifically for phrasal ITGs and is computable with worst-case complexity of n2 , compared with the n3 amortized time of the tic-tac-toe pruning 3 Applying beam-search before sampling will sample from an improper distribution, although Metropolis-in-Gibbs sampling (Johnson et al., 2007) can be used to compensate. However, we found that this h"
P12-1018,P08-1012,0,0.710838,"n to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach"
P12-1018,W08-0335,0,0.0813058,"n to improve translation (Knight and Graehl, 1998; Kondrak et al., 2003; Finch and Sumita, 2007), and more sophisticated methods for named entity translation that combine translation and transliteration have also been proposed (Al-Onaizan and Knight, 2002). Choosing word units is also essential for creating good translation results for languages that do not explicitly mark word boundaries, such as Chinese, Japanese, and Thai. A number of works have dealt with this word segmentation problem in translation, mainly focusing on Chinese-to-English translation (Bai et al., 2008; Chang et al., 2008; Zhang et al., 2008b; Chung and Gildea, 2009; Nguyen et al., 2010), although these works generally assume that a word segmentation exists in one language (English) and attempt to optimize the word segmentation in the other language (Chinese). We have enumerated these related works to demonstrate the myriad of data sparsity problems and proposed solutions. Character-based translation has the potential to handle all of the phenomena in the previously mentioned research in a single unified framework, requiring no language specific tools such as morphological analyzers or word segmenters. However, while the approach"
P12-1018,corston-oliver-gamon-2004-normalizing,0,\N,Missing
P12-1018,P10-3006,0,\N,Missing
P12-1018,I08-8003,0,\N,Missing
P12-1018,J98-4003,0,\N,Missing
P16-2039,D15-1277,1,0.916517,"referring to the real world. Because of the lack of datasets consisting of sentences annotated with the general NE tags such as names of people, organizations, and times (Sang and Meulder, 2003), with accompanying real world data, we take game states as the counterpart of the language and the NE tag set specialized for game commentaries such as defense formations and opening names (Mori et al., 2016). Similar to bio-medical NEs (Settles, 2004; Tateisi et al., 2002), these NEs are useful for applications in the game domain. Our method could be used to improve automatic game commentary systems (Kameko et al., 2015b; Chen et al., 2010) or to build a state search method that uses natural language queries instead of state notations (Ganguly et al., 2014). In addition to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et"
P16-2039,D15-1293,0,0.0126694,"t al. (2015) extend word2vec (Mikolov et al., 2013a; Mikolov et al., 2013b) to incorporate visual information for acquiring multimodal representations. Word embedding methods including word2vec are often used for various NLP tasks instead of one hot representations, and were shown to improve the performance of NLP systems. Word embeddings are mappings from a word to a low-dimensional real vectors that represents word meanings and relations between words. Word2vec is a method for acquiring word embeddings from a neural network which solves a pseudo-supervised task to predict surrounding words. Kiela and Clark (2015) extend word2vec to incorporate bag-of-audio-words (BoAW). Gupta et al. (2015) have shown that word embeddings contain much information for predicting attributes. Herbelot and Vecchi (2015) proposed a method for predicting general quantifiers such as some for predicate-subject pairs. Similar to this paper Kameko et al. (2015a) proposed a method for word segmentation using game states and DNNs. The main differences between their method and ours is that i) they use game states to build a term dictionary for word segmentation, but our method directly incorporates a game state to improve NER, and"
P16-2039,D15-1015,0,0.0294169,"Missing"
P16-2039,D15-1021,0,0.0154234,"our experiments, we took Japanese chess as the example. The dataset consists of pairs of a game state and commentary sentences about it annotated with gamespecific NE tags. We conducted NER experiments and showed that referring to the real world improves the NER accuracy. 1 Introduction In recent years there has been a surge of interest in relating natural language to the real world. And more and more language resources accompanied by nonlinguistic data are becoming available. Typical examples are image descriptions (Yang et al., 2011; Ushiku et al., 2011) and video (Hashimoto et al., 2014). Ferraro et al. (2015) summarized many other image and video datasets. These datasets allow us to attempt the task of connecting language expressions to the real world, which is called symbol grounding (Harnad, 1990). Bruni et al. (2014) proposed methods for acquiring multimodal representations by applying SVD to distributional semantics and bag-of-visual-words (BoVW). Ngiam et al. (2011) proposed unsupervised multimodal learning based on deep restricted boltzmann machines (RBMs). In the field of natural language processing (NLP) research, ∗ This work was done when the first author was at Ehime University. 236 Proc"
P16-2039,D15-1002,0,0.0667347,"Missing"
P16-2039,N15-1016,0,0.0136891,"nformation, which increases its accuracy. 2 proposed a deep learning method for learning multimodal representations by solving pseudosupervised tasks to predict the input’s object label, such as ’boat,’ given textual and visual attributebased representations for the object. Their objective function is the weighted sum of the autoencoding error and the classification error. Though their model is for supervised learning, Multimodal representations are learned In their experiments, the acquired multimodal representations were used for evaluating the word similarity task and word clustering task. Lazaridou et al. (2015) extend word2vec (Mikolov et al., 2013a; Mikolov et al., 2013b) to incorporate visual information for acquiring multimodal representations. Word embedding methods including word2vec are often used for various NLP tasks instead of one hot representations, and were shown to improve the performance of NLP systems. Word embeddings are mappings from a word to a low-dimensional real vectors that represents word meanings and relations between words. Word2vec is a method for acquiring word embeddings from a neural network which solves a pseudo-supervised task to predict surrounding words. Kiela and Cl"
P16-2039,W03-0426,0,0.0707334,"r advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et al., 2013b; Pennington et al., 2014; Mikolov et al., 2013a), part-of-speech tagging (Tsuboi, 2014), parsing (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013a), parsing (Socher et al., 2013a), NER (Hammerton, 2003) , sentiment analysis (Socher et al., 2013b) and machine translation (Neubig et al., 2015). First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked autoencoder to a text-based deep neural network for NER. We first train the stacked auto-encoder only from the real world information, then the entire deep neural network from sentences annotate"
P16-2039,W15-0110,0,0.0232074,"Missing"
P16-2039,W03-0430,0,0.132001,"Missing"
P16-2039,D15-1003,0,0.0146668,"word2vec are often used for various NLP tasks instead of one hot representations, and were shown to improve the performance of NLP systems. Word embeddings are mappings from a word to a low-dimensional real vectors that represents word meanings and relations between words. Word2vec is a method for acquiring word embeddings from a neural network which solves a pseudo-supervised task to predict surrounding words. Kiela and Clark (2015) extend word2vec to incorporate bag-of-audio-words (BoAW). Gupta et al. (2015) have shown that word embeddings contain much information for predicting attributes. Herbelot and Vecchi (2015) proposed a method for predicting general quantifiers such as some for predicate-subject pairs. Similar to this paper Kameko et al. (2015a) proposed a method for word segmentation using game states and DNNs. The main differences between their method and ours is that i) they use game states to build a term dictionary for word segmentation, but our method directly incorporates a game state to improve NER, and ii) they used manually developed features to extract game states while we automatically acquire game states by using pre-training. Related Work There are several lines of multimodal learnin"
P16-2039,D12-1110,0,0.0492347,"l., 2014). In addition to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et al., 2013b; Pennington et al., 2014; Mikolov et al., 2013a), part-of-speech tagging (Tsuboi, 2014), parsing (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013a), parsing (Socher et al., 2013a), NER (Hammerton, 2003) , sentiment analysis (Socher et al., 2013b) and machine translation (Neubig et al., 2015). First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked autoencoder to a text-based deep neural network for NER. We first train the stacked auto-encoder only from the real"
P16-2039,L16-1225,1,0.885271,"n based on visual similarity. Ramisa et al. (2015) describe a method for predicting a preposition referring to positions in the image. In this paper, we propose a method for enhancing a named entity (NE) recognizer referring to the real world. Because of the lack of datasets consisting of sentences annotated with the general NE tags such as names of people, organizations, and times (Sang and Meulder, 2003), with accompanying real world data, we take game states as the counterpart of the language and the NE tag set specialized for game commentaries such as defense formations and opening names (Mori et al., 2016). Similar to bio-medical NEs (Settles, 2004; Tateisi et al., 2002), these NEs are useful for applications in the game domain. Our method could be used to improve automatic game commentary systems (Kameko et al., 2015b; Chen et al., 2010) or to build a state search method that uses natural language queries instead of state notations (Ganguly et al., 2014). In addition to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real w"
P16-2039,W15-5003,0,0.0283913,"which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et al., 2013b; Pennington et al., 2014; Mikolov et al., 2013a), part-of-speech tagging (Tsuboi, 2014), parsing (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013a), parsing (Socher et al., 2013a), NER (Hammerton, 2003) , sentiment analysis (Socher et al., 2013b) and machine translation (Neubig et al., 2015). First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked autoencoder to a text-based deep neural network for NER. We first train the stacked auto-encoder only from the real world information, then the entire deep neural network from sentences annotated with NEs and accompanied by real world information. In our experiments, we took Japanese"
P16-2039,P13-1045,0,0.0176659,"n to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et al., 2013b; Pennington et al., 2014; Mikolov et al., 2013a), part-of-speech tagging (Tsuboi, 2014), parsing (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013a), parsing (Socher et al., 2013a), NER (Hammerton, 2003) , sentiment analysis (Socher et al., 2013b) and machine translation (Neubig et al., 2015). First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked autoencoder to a text-based deep neural network for NER. We first train the stacked auto-encoder only from the real world information, th"
P16-2039,D13-1170,0,0.0047811,"n to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et al., 2013b; Pennington et al., 2014; Mikolov et al., 2013a), part-of-speech tagging (Tsuboi, 2014), parsing (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013a), parsing (Socher et al., 2013a), NER (Hammerton, 2003) , sentiment analysis (Socher et al., 2013b) and machine translation (Neubig et al., 2015). First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked autoencoder to a text-based deep neural network for NER. We first train the stacked auto-encoder only from the real world information, th"
P16-2039,D14-1162,0,0.0758897,"., 2010) or to build a state search method that uses natural language queries instead of state notations (Ganguly et al., 2014). In addition to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et al., 2013b; Pennington et al., 2014; Mikolov et al., 2013a), part-of-speech tagging (Tsuboi, 2014), parsing (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013a), parsing (Socher et al., 2013a), NER (Hammerton, 2003) , sentiment analysis (Socher et al., 2013b) and machine translation (Neubig et al., 2015). First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked au"
P16-2039,D15-1022,0,0.0408236,"Missing"
P16-2039,C08-1113,1,0.86041,"Missing"
P16-2039,D14-1101,0,0.0184126,"ries instead of state notations (Ganguly et al., 2014). In addition to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition (NER), we propose to use deep neural networks (DNNs), which have been reported to be successful in various NLP tasks such as word embedding (Bengio et al., 2003; Mikolov et al., 2013b; Pennington et al., 2014; Mikolov et al., 2013a), part-of-speech tagging (Tsuboi, 2014), parsing (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013a), parsing (Socher et al., 2013a), NER (Hammerton, 2003) , sentiment analysis (Socher et al., 2013b) and machine translation (Neubig et al., 2015). First we build a normal NE recognizer by referring only to the text information based on DNN. Each unit of its output layer corresponds to a BIO tag for In this paper, we propose a method for referring to the real world to improve named entity recognition (NER) specialized for a domain. Our method adds a stacked autoencoder to a text-based deep neural network for NER. We first"
P16-2039,W04-1221,0,0.0349875,"5) describe a method for predicting a preposition referring to positions in the image. In this paper, we propose a method for enhancing a named entity (NE) recognizer referring to the real world. Because of the lack of datasets consisting of sentences annotated with the general NE tags such as names of people, organizations, and times (Sang and Meulder, 2003), with accompanying real world data, we take game states as the counterpart of the language and the NE tag set specialized for game commentaries such as defense formations and opening names (Mori et al., 2016). Similar to bio-medical NEs (Settles, 2004; Tateisi et al., 2002), these NEs are useful for applications in the game domain. Our method could be used to improve automatic game commentary systems (Kameko et al., 2015b; Chen et al., 2010) or to build a state search method that uses natural language queries instead of state notations (Ganguly et al., 2014). In addition to these interesting applications, game states have another advantage for NLP research. They are much easier to recognize than images and video, which allows us to concentrate on the NLP problem. In order to incorporate the real world, i.e. game states, into NE recognition"
P16-2039,P14-1068,0,0.0191255,"al. (2011) and Srivastava and Salakhutdinov (2012) proposed unsupervised learning methods based on deep RBMs for learning multimodal representations in hidden layers. Providing paired information such as text-image pairs or audio-video pairs to RBMs, shared representations are learned in their hidden layers. Ngiam et al. (2011) also used deep auto-encoders for learning RBMs. After acquiring multimodal representations, they can be used as inputs for other supervised learning tasks, such as speech recognition and image retrieval, where standard linear classifiers are used for solving the tasks. Silberer and Lapata (2014) 3 Game Commentary Corpus The game we chose for the experiments is Japanese chess, called shogi in Japanese. It is a two-player board game with professional players. The board has 9×9 squares and games are played with 40 pieces of 14 different types. Unlike chess, players can reuse captured pieces. In computer science terms, it is a deterministic perfect informa237 Tag Hu Tu Po Pi Ps Mc Pa Pq Re Ph St Ca Me Mn Ee Ev Ti Ac Ap Ao Ot Meaning Human Turn Position Piece Piece specifier Move compliment Piece attribute Piece quantity Region Phase Strategy Castle Move eval. Move name Eval. element Eval"
P16-2039,D11-1041,0,\N,Missing
P16-2039,W03-0419,0,\N,Missing
P98-2148,J92-4003,0,0.0297894,"in the present paper attest, word-class relation is dependent on language model. In this paper, taking Japanese as the object language, we propose two complete stochastic language models using dependency between bugsetsu, a sequence of one or more content words followed by zero, one or more function words, and evaluate their predictive power by cross entropy. Since the number of sorts of b u n s e t s u is enormous, considering it as a symbol to be predicted would surely invoke the datasparseness problem. To cope with this problem we use the concept of class proposed for a word n-gram model (Brown et al., 1992). Each bunsetsu is represented by the class calculated from the POS of its last content word and that of its last function word. The relation between bunsetsu, called dependency, is described by a stochastic context-free grammar (Fu, 1974) on the classes. From the class of a bunsetsu, the content word sequence and the function word sequence are independently predicted by word n-gram models equipped with unknown word models (Mori and Yamaji, 1997). The above model assumes that the syntactic behavior of each bunsetsu depends only on POS. The POS system invented by grammarians may not always be t"
P98-2148,P97-1003,0,0.0403373,"d in almost all of the recent practicM applications in that it describes only relations between sequential elements. Some linguistic phenomena, however, axe better described by assuming relations between sepaxated elements. And modeling this kind of phenomena, the accuracies of various application axe generally augmented. As for English, there have been researches in which a stochastic context-free grammar (SCFG) (Fujisaki et ~1., 1989) is used for model description. Recently some researchers have pointed out the importance of the lexicon and proposed lexicalized models (Jelinek et al., 1994; Collins, 1997). In these models, every headword is propagated up through the derivation tree such that every parent receives a headword from the head-child. This kind of specialization may, however, be excessive if the criterion is predictive power of the model. Research ~ m e d at estimating the best specialization level for 2-gram model (Mori et aL, 1997) shows a class-based model is more predictive than a word-based 2-gram model, a completely lexicalized model, comparing cross entropy of a POS-based 2-graxa model, a word-based 2-gram model and a class-based 2-graxa model, estimated from information theor"
P98-2148,W89-0209,0,0.595279,"Missing"
P98-2148,W97-1003,0,0.0235135,"Missing"
P98-2148,H94-1052,0,0.0149636,"Sakyo Kyoto, Japan used in almost all of the recent practicM applications in that it describes only relations between sequential elements. Some linguistic phenomena, however, axe better described by assuming relations between sepaxated elements. And modeling this kind of phenomena, the accuracies of various application axe generally augmented. As for English, there have been researches in which a stochastic context-free grammar (SCFG) (Fujisaki et ~1., 1989) is used for model description. Recently some researchers have pointed out the importance of the lexicon and proposed lexicalized models (Jelinek et al., 1994; Collins, 1997). In these models, every headword is propagated up through the derivation tree such that every parent receives a headword from the head-child. This kind of specialization may, however, be excessive if the criterion is predictive power of the model. Research ~ m e d at estimating the best specialization level for 2-gram model (Mori et aL, 1997) shows a class-based model is more predictive than a word-based 2-gram model, a completely lexicalized model, comparing cross entropy of a POS-based 2-graxa model, a word-based 2-gram model and a class-based 2-graxa model, estimated from i"
W11-2008,D07-1002,0,0.10912,"Missing"
W11-2008,2009.eamt-1.30,0,0.0218093,"Missing"
W11-2008,P08-1028,0,0.0367914,"Missing"
W11-2008,P98-2127,0,0.00882207,"ts is defined based on the co-occurrence statistics in the corpus. The measure for predicate is defined based on distributional analysis of arguments. 4.2 Relevance measure of arguments The relevance of argument words (=nouns) wi and wj is defined as simarg (wi , wj ) = {C(wi , wj )}2 . C(wi ) × C(wj ) (6) Here, wi is in the original query, and relaxed (ignored) in the partial matching, and wj of the best relevance score is retrieved for response generation. In the example of Fig. 2, wi is “Ichiro” and wj is “Lopez”. 4.3 Relevance measure of predicates Distributional analysis (Z.Harris, 1951; Lin, 1998) has been used to define similarity of words, assuming that similar words have similar contexts. In this paper, we use the distribution of arguments which have a modification relation to predicates (Fig. 3) frequency 28 Ichiro 12 single 20 Lopez 31 homer Agent Object Agent Object frequency 3 Ichiro 1 single 2 Lopez 4 homer hit Agent 1. Exact Matching of P-A templates. 2. Partial Matching using significance measure for query relaxation and relevance score for candidate selection. 3. Back-off to “Bag-of-Words” (BOW) model with significance measure for disambiguation. Object Agent Object Figure 4"
W11-2008,D09-1082,0,0.0528628,"Missing"
W11-2008,P05-1026,0,0.0234721,"s been studied to handle large-scale texts such as web, but most of the conventional systems adopt a “bag-ofwords” model, and naive statistical matching often generates irrelevant responses which have nothing to do with the user’s requests. Our proposed scheme solves this problem by using information extraction based on semantic parsing from web texts, without constructing an RDB. We adopt the predicateargument (P-A) structure generated by a parser as a baseline, but every P-A structure is not useful for information extraction and retrieval(Y.Kiyota et al., 2002; M.O.Dzikovska et al., 2003; S.Harabagiu et al., 2005). In fact, the useful information structure is dependent on domains. Conventionally, the templates for information extraction were hand-crafted (R.Grishman, 2003), but this heuristic process is so costly that it cannot be applied to a variety of domains on the web. In this paper, therefore, we pro59 Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 59–66, c Portland, Oregon, June 17-18, 2011. 2011 Association for Computational Linguistics SYSTEM PROCESS DIALOGUE USER BACK END SYSTEM Ichiro(agent), home-run(object), hit User:"
W11-2008,P10-1097,0,0.0216602,"Missing"
W11-2008,I08-2110,0,0.0658194,"Missing"
W11-2008,C02-1084,0,0.0823079,"Missing"
W11-2008,H94-1010,0,\N,Missing
W11-2008,N06-1023,0,\N,Missing
W11-2008,C98-2122,0,\N,Missing
W11-2008,D09-1098,0,\N,Missing
W11-3502,P06-1029,0,0.0725051,"Missing"
W11-3502,W04-3230,0,0.0730085,"Missing"
W11-3502,I08-7018,0,0.0632957,"(x(i) , y ∗ ) − f (x(i) , y (i) )) for k ∈ K do (i+1) wk i+ 1 2 = sign(wk (i+ 1 ) 2 ) max{|wk In the case of online FOBOS, FOBOS is viewed as an extension of the stochastic gradient decent and the subgradient method. FOBOS alternates between two phases. The first step processes the (sub)gradient descent, the second step processes the regularization term in a manner similar to projected gradients. The first step of FOBOS is as follows: 1 ∇f (x, y) = (5) − j j k (i) (i) Ψk (x, yj−1 , yj )). (9) k 5.1 Settings As the data set, we used the balanced corpus of contemporary written Japanese (BCCWJ) (Maekawa, 2008). The corpus contains several different data set, and we used humanannotated data sets in our experiments. The human-annotated part of the BCCWJ consists of four parts, referred to as OC, OW, PN and PB. Each data set is summarized in Table 1. In addition, we constructed a data set (referred to as ALL) that is the concatenation of OC, OW, PN and PB. The baseline method we used herein is a language model based generative model. The language model is the linear sum of logarithm of a (i+ 12 ) |− ληt , 0}, (7) where sign is a function which returns 1 if the argument is greater than 0 and otherwise"
W11-3502,C94-1032,0,0.295458,"Missing"
W12-4801,J92-4003,0,0.541416,"escribes the context and it is larger in size than the word-pronunciation model. We focus on how to improve the language model for KKC. An n-gram model is generally used for many tasks. In KKC, considering the need for the conversion speed and the size of the language model, bi-gram models are often used. However, bi-gram models can not refer to a long history. A tri-gram model, which is also popular for many tasks, can refer a longer history but the size of tri-gram models is larger than that of bi-gram models. There have been many attempts at improving language models. A class n-gram model (Brown et al., 1992; Kneser and Ney, 1993; Mori et al., 1998), which groups words of similar behavior into a single class, and a phrase n-gram model (Deligne and Bimbot, 1995; Ries et al., 1996; Mori et al., 1997) which replaces some word sequences by single tokens, are known to be practical in speech recognition community. In this paper, we propose a method to construct a smaller, more accurate language model for KKC. It is often thought that accurate models are larger and that small models are less accurate. However, we successfully built a smaller, more accurate language model. This is done by combining phras"
W12-4801,P00-1031,0,0.87622,"has over 6,000 characters, which is much larger than the number of keys in a keyboard. It is impossible to map each Japanese character to a key. So an alternate input method for Japanese characters is needed. This is done by inputting a pronunciation sequence and converting it to an output sequence of words. Here, the input sequence of pronunciation is a sequence of kana characters and the output sequence of words is a mixture of kana and kanji characters. So this conversion is called Kana-Kanji Conversion (KKC). The noisy channel model approach has been successfully applied to input methods (Chen and Lee, 2000; Mori et al., 1999). In KKC, a word sequence is predicted from a pronunciation sequence. The system is composed of two modules: a language model, which measures the likelihood of a word sequence in the language and a word-pronunciation model, which describes a relationship between a word sequence and a pronunciation sequence. Thus, the conversion accuracy of KKC depends on the language model and the word-pronunciation model. The language model is, however, more important since it describes the context and it is larger in size than the word-pronunciation model. We focus on how to improve the l"
W12-4801,I08-7018,0,0.162887,"), where x 0 i is the character sequence corresponding to γi . 10 usage training test #sentences 53,424 6,350 #words 1,258,805 137,642 #chars 1,813,135 201,477 Table 1: Corpora. 5 Experiments In order to test the effectiveness of combining the phrase and class methods, we constructed phrase class bi-gram using our method and compared the conversion accuracy and the model size of our model to other language models. In this section we show the experimental results and discuss them. 5.1 Experimental Settings We used the core corpus of the Balanced Corpus of Contemporary Written Japanese (BCCWJ) (Maekawa, 2008) for the experiments. The BCCWJ is composed of two corpora, the BCCWJCORE corpus and the BCCWJ-NON-CORE corpus, and we used the BCCWJ-CORE. A sentence of the BCCWJ-CORE corpus is a sequence of pairs of a word and its pronunciation as shown in Figure 1. The word segmentation and pronunciation tagging were done manually. We split the BCCWJ-CORE into two parts: one is for training language models and the other is for the test of them. Table 1 shows the specifications of the corpora. We constructed language models and a vocabulary from the training corpus of the BCCWJ. The vocabulary was construct"
W12-4802,P00-1031,0,0.620355,"n order to input Japanese texts, it is common to use input methods called Kana-Kanji conversion, which convert Hiragana characters into Kanji or mixed characters. Since there are no spaces between words, most of Japanese input methods process texts sentence by sentence. Chinese language has nearly the same problem. There are more than 10,000 Hanzi characters in Chinese and Pinyin input methods are used to convert Roman characters into Chinese characters. In these days, statistical models are used for such input methods to achieve high accuracy and automate parameter tuning (Mori et al., 1999; Chen and Lee, 2000). The statistical models are trained before actual conversion from corpora in each language. Sentences in these corpora are segmented word by word and annotated to specify the words’ pronunciation, whether manually or automatically. Most of the models treat a word as an atomic unit; that means, they distinguish all words completely even if they share some characters in their strings. In this paper, we call such approaches word-based models. However, such word-based models suffer from unknown words in principle, because they cannot convert or even enumerate a word in the candidate list when the"
W12-4802,D09-1111,0,0.0146787,"rd n-gram model to address unknown word problem (Mori et al., 2006; Gao et al., 2002). However, character n-gram model does not exploit rich information of joint n-gram of word and its pronunciation. Moreover, it is not straightforward to extend character n-gram model to character-based joint n-gram model without recent development in alignment techniques we use (Jiampojamarn et al., 2007; Kubo et al., 2011). 16 Figure 1: An Ensemble Model of Word-based and Character-based Models Recently, discriminative models are introduced to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher order n-gram because of their large model size and long training time. Spelling correction is commonly incorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the manner of statistical machine translation (SMT), aut"
W12-4802,I08-8003,0,0.0147555,"d to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher order n-gram because of their large model size and long training time. Spelling correction is commonly incorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the manner of statistical machine translation (SMT), automatic alignment is applied to estimate character alignment between source and target strings (Jiampojamarn et al., 2007; Kubo et al., 2011). Hatori and Suzuki (2011) solved Japanese pronunciation inference combining word-based and character-based features within SMT-style framework to handle unknown words. Neubig et al. (2012) proposed character-based SMT to incorporate word segmentation and handle sparsity. They solved different problems using similar solutions. 3 An Ensemble Model of Word-based and Character-based Models"
W12-4802,I11-1014,0,0.324955,"ncorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the manner of statistical machine translation (SMT), automatic alignment is applied to estimate character alignment between source and target strings (Jiampojamarn et al., 2007; Kubo et al., 2011). Hatori and Suzuki (2011) solved Japanese pronunciation inference combining word-based and character-based features within SMT-style framework to handle unknown words. Neubig et al. (2012) proposed character-based SMT to incorporate word segmentation and handle sparsity. They solved different problems using similar solutions. 3 An Ensemble Model of Word-based and Character-based Models We propose an ensemble model as a combination of word-based and character-based models. Figure 1 shows the training process for our model. The left side shows word-based model, while the right side shows character-based model. The diffe"
W12-4802,P08-1103,0,0.0550113,"as a back-off model for word n-gram model to address unknown word problem (Mori et al., 2006; Gao et al., 2002). However, character n-gram model does not exploit rich information of joint n-gram of word and its pronunciation. Moreover, it is not straightforward to extend character n-gram model to character-based joint n-gram model without recent development in alignment techniques we use (Jiampojamarn et al., 2007; Kubo et al., 2011). 16 Figure 1: An Ensemble Model of Word-based and Character-based Models Recently, discriminative models are introduced to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher order n-gram because of their large model size and long training time. Spelling correction is commonly incorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the manner of statistical mach"
W12-4802,N07-1047,0,0.0318928,"is remained as a future work. In this paper, we focus on models for standard annotated corpora to keep the study reproducible and comparable with other works. In noisy channel model, character n-gram is used as a back-off model for word n-gram model to address unknown word problem (Mori et al., 2006; Gao et al., 2002). However, character n-gram model does not exploit rich information of joint n-gram of word and its pronunciation. Moreover, it is not straightforward to extend character n-gram model to character-based joint n-gram model without recent development in alignment techniques we use (Jiampojamarn et al., 2007; Kubo et al., 2011). 16 Figure 1: An Ensemble Model of Word-based and Character-based Models Recently, discriminative models are introduced to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher order n-gram because of their large model size and long training time. Spelling correction is commonly incorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang e"
W12-4802,P04-1021,0,0.555463,"oduces related work, section 3 proposes the models, section 4 describes experimental results, and section 5 summarizes this paper and future work. 2 Related Work There is a limited number of studies specialized in statistical models for input methods. However, closely related tasks such as machine transliteration, letter-to-phoneme conversion, language modeling, or machine translation share similar problems and solutions with input methods. Early models for input methods adopt noisy channel model (Mori et al., 1999; Chen and Lee, 2000), which are less accurate than joint source channel model (Li et al., 2004). Conventionally, noisy channel model is used to divide joint model into conditional model and language model so that language model can be trained from large raw data such as crawled websites. Joint source channel model can also be combined such large raw data, though it is remained as a future work. In this paper, we focus on models for standard annotated corpora to keep the study reproducible and comparable with other works. In noisy channel model, character n-gram is used as a back-off model for word n-gram model to address unknown word problem (Mori et al., 2006; Gao et al., 2002). Howeve"
W12-4802,I08-7018,0,0.0687307,"Missing"
W12-4802,P06-1092,1,0.834347,"joint source channel model (Li et al., 2004). Conventionally, noisy channel model is used to divide joint model into conditional model and language model so that language model can be trained from large raw data such as crawled websites. Joint source channel model can also be combined such large raw data, though it is remained as a future work. In this paper, we focus on models for standard annotated corpora to keep the study reproducible and comparable with other works. In noisy channel model, character n-gram is used as a back-off model for word n-gram model to address unknown word problem (Mori et al., 2006; Gao et al., 2002). However, character n-gram model does not exploit rich information of joint n-gram of word and its pronunciation. Moreover, it is not straightforward to extend character n-gram model to character-based joint n-gram model without recent development in alignment techniques we use (Jiampojamarn et al., 2007; Kubo et al., 2011). 16 Figure 1: An Ensemble Model of Word-based and Character-based Models Recently, discriminative models are introduced to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher orde"
W12-4802,P12-1018,1,0.814994,"ames into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the manner of statistical machine translation (SMT), automatic alignment is applied to estimate character alignment between source and target strings (Jiampojamarn et al., 2007; Kubo et al., 2011). Hatori and Suzuki (2011) solved Japanese pronunciation inference combining word-based and character-based features within SMT-style framework to handle unknown words. Neubig et al. (2012) proposed character-based SMT to incorporate word segmentation and handle sparsity. They solved different problems using similar solutions. 3 An Ensemble Model of Word-based and Character-based Models We propose an ensemble model as a combination of word-based and character-based models. Figure 1 shows the training process for our model. The left side shows word-based model, while the right side shows character-based model. The difference between word-based model and character-based model is that later has an alignment step to produce character-aligned corpus by an automatic alignment tool. Th"
W12-4802,P00-1073,0,0.0407692,"one smoothing Precision 0.931 0.929 0.929 0.925 0.798 Recall 0.932 0.930 0.931 0.927 0.819 ACC 0.361 0.338 0.343 0.322 0.174 Table 6: Smoothing Methods Pruning Threshold 1e-4 1e-5 1e-6 1e-7 1e-8 F-score 0.808 0.877 0.914 0.936 0.942 1-gram size 345416 345416 345416 345416 345416 2-gram size 2232 27450 222883 1200021 5286912 3-gram size 144 3345 72087 833593 4146260 File size 15MB 15MB 17MB 34MB 98MB Table 7: Pruning Effect 4.8 Pruning Effect In practical input methods, model size is important because the memory in a device is limited. In order to reduce model size, we applied entropy pruning (Stolcke, 2000) to word-based model. Table 7 shows the result of F-score, N-gram size and file size in the SRILM binary format for various thresholds. In this experiment, all data in BCCWJ including automatically annotated one is used to confirm the effectiveness of big data. The result shows practical tradeoff between model size and accuracy; more larger model might improve accuracy in the future. 4.9 Error Analysis Figure 6 shows some examples of output from the ensemble model and the word-based model, and correct output. There are some typical cases where the ensemble model outperforms the word-based mode"
W12-4802,D12-1056,0,0.0171979,"htforward to extend character n-gram model to character-based joint n-gram model without recent development in alignment techniques we use (Jiampojamarn et al., 2007; Kubo et al., 2011). 16 Figure 1: An Ensemble Model of Word-based and Character-based Models Recently, discriminative models are introduced to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher order n-gram because of their large model size and long training time. Spelling correction is commonly incorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the manner of statistical machine translation (SMT), automatic alignment is applied to estimate character alignment between source and target strings (Jiampojamarn et al., 2007; Kubo et al., 2011). Hatori and Suzuki (2011) solved Japanese pronunciation inference combining word-b"
W12-4802,W11-3502,1,0.905228,"haracter n-gram is used as a back-off model for word n-gram model to address unknown word problem (Mori et al., 2006; Gao et al., 2002). However, character n-gram model does not exploit rich information of joint n-gram of word and its pronunciation. Moreover, it is not straightforward to extend character n-gram model to character-based joint n-gram model without recent development in alignment techniques we use (Jiampojamarn et al., 2007; Kubo et al., 2011). 16 Figure 1: An Ensemble Model of Word-based and Character-based Models Recently, discriminative models are introduced to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher order n-gram because of their large model size and long training time. Spelling correction is commonly incorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the"
W12-4802,W12-4401,0,0.0127386,"., 2007; Kubo et al., 2011). 16 Figure 1: An Ensemble Model of Word-based and Character-based Models Recently, discriminative models are introduced to input methods (Tokunaga et al., 2011; Jiampojamarn et al., 2008; Cherry and Suzuki, 2009), but they are impractical for higher order n-gram because of their large model size and long training time. Spelling correction is commonly incorporated with Chinese input methods (Zheng et al., 2011; Suzuki and Gao, 2012). Machine transliteration is a similar task to input method, which translates proper names into foreign languages based on their sounds (Zhang et al., 2012). Machine transliteration is formulated as monotonic machine translation that is purely based on characters rather than words (Finch and Sumita, 2008). According to the manner of statistical machine translation (SMT), automatic alignment is applied to estimate character alignment between source and target strings (Jiampojamarn et al., 2007; Kubo et al., 2011). Hatori and Suzuki (2011) solved Japanese pronunciation inference combining word-based and character-based features within SMT-style framework to handle unknown words. Neubig et al. (2012) proposed character-based SMT to incorporate word"
W13-4504,corvey-etal-2012-foundations,0,0.139573,"risis-related information (Munro, 2010), gather survivor lists from evacuation sites and enter them into a central database (Google Japan, 2011), or even annotate data for the creation of specialized information extraction systems (Neubig et al., 2011). Given the large amount of work required in these collaborative efforts, it is common for as many as hundreds of volunteers to be involved in any single task. On the other hand, examinations of the types of information provided on social networks after crises have shown that the number of possible information extraction tasks is large (20-30 by Corvey et al. (2012)’s classification). Information requirements also vary greatly from situation to situation, with the direction of the wind being important during the Oklahoma wildfires, and radiation measurements being important after the nuclear meltdown following the Great East Japan Earthquake (Vieweg et al., 2010; Doan et al., 2012). While a large number of volunteers may be mobilized for a single task, scaling this approach to tens or hundreds of disparate tasks has not proven This research proposes a framework for efficient information extraction and filtering in situations where 1) extreme reliability"
W13-4504,2010.amta-workshop.1,0,0.0374699,"rbird et al., 2012). However, distinguishing useful information (e.g. “there is water at the evacuation center in Sendai high school”) from unreliable or non-actionable information (e.g. “just arrived at the evacuation center, so tired...”) takes a large amount of human effort. Luckily, however, the effort of good-willed internet users is one thing that is often plentiful in times of crisis. There have been many success stories where volunteers have banded together to turn natural language data into machine-readable format (Starbird and Stamberger, 2010), translate crisis-related information (Munro, 2010), gather survivor lists from evacuation sites and enter them into a central database (Google Japan, 2011), or even annotate data for the creation of specialized information extraction systems (Neubig et al., 2011). Given the large amount of work required in these collaborative efforts, it is common for as many as hundreds of volunteers to be involved in any single task. On the other hand, examinations of the types of information provided on social networks after crises have shown that the number of possible information extraction tasks is large (20-30 by Corvey et al. (2012)’s classification)."
W13-4504,I11-1108,1,0.90347,"he evacuation center, so tired...”) takes a large amount of human effort. Luckily, however, the effort of good-willed internet users is one thing that is often plentiful in times of crisis. There have been many success stories where volunteers have banded together to turn natural language data into machine-readable format (Starbird and Stamberger, 2010), translate crisis-related information (Munro, 2010), gather survivor lists from evacuation sites and enter them into a central database (Google Japan, 2011), or even annotate data for the creation of specialized information extraction systems (Neubig et al., 2011). Given the large amount of work required in these collaborative efforts, it is common for as many as hundreds of volunteers to be involved in any single task. On the other hand, examinations of the types of information provided on social networks after crises have shown that the number of possible information extraction tasks is large (20-30 by Corvey et al. (2012)’s classification). Information requirements also vary greatly from situation to situation, with the direction of the wind being important during the Oklahoma wildfires, and radiation measurements being important after the nuclear m"
W13-4504,D11-1136,0,0.0239071,"s(Di ) = log P (ui = 1|Di ) − log P (ui = 0|Di ) which allows us to define each weight λn as λn = log c(ϕn , u∗ = 1) − log c(ϕn , u∗ = 0). However, zero counts for either positive or negative labels will cause the log odds to be negative or positive infinity, so in many cases, the counts are augmented with a pseudo-count α for smoothing (Mackay and Petoy, 1995): λn = log(c(ϕn , u∗ = 1) + α) − log(c(ϕn , u∗ = 0) + α). (4) It should also be noted that while standard classifiers are trained using the document labels U, it is also possible to directly label the features ϕn (Melville et al., 2009; Settles, 2011). In this case, let l(ϕn , u∗ = 1) be a function that is 1 if feature ϕn is labeled positive, and 0 otherwise. We further augment Equation (4) with a pseudo-count β in the case of labeled features (3) n=1 In the case of s(Di ) ≥ 0, Di is classified as a positive example, and in the case of s(Di ) &lt; 0, Di is classified as a negative example. In order to learn the weights λ = (λ1 , λ2 , . . . , λK ), a corpus of documents D is annotated with labels U ∗ , and a classifier such as support vector machines (SVMs) or naive Bayes classifiers is used to train the weight values (Joachims, 1998). In this"
W14-4418,P13-1006,0,0.0256878,"the chef by the computer vision (CV) technologies etc. and suggests the chef the next action to be taken or a good way of doing it in a casual manner. In this application, the text generation module make a sentence from a subtree speciﬁed by the process supervision module. There are some other interesting applications: a help system for internet users to write good sentences, machine translation of a recipe in a diﬀerent language represented as a ﬂow graph, or automatic recipe generation from a cooking video based on CV and NLP researches such as (Regneri et al., 2013; Yamakata et al., 2013; Yu and Siskind, 2013). Table 4 shows the result. The generated texts contain 14.5 sentences in average. The answers to Q1 tell that there are many grammatical errors. We need some mechanism that selects more appropriate skeletons. The number of ambiguous wordings, however, is very low. The reason is that the important words are given along with the subtrees. The average of the answer to Q3 is 3.05. This result says that the dish will be partly the same as the original recipe. There is a room for improvement. Finally, let us take a look at the correlation of the result of three Qs with BLEU. The numbers of grammati"
W14-4418,mori-etal-2014-flow,1,0.854735,"sequence of subtrees that are suitable for a sentence. Finally it converts subtrees into natural language sentences. In this paper we describe a method for generating a procedural text given its ﬂow graph representation. Our main idea is to automatically collect sentence skeletons from real texts by replacing the important word sequences with their type labels to form a skeleton pool. The experimental results showed that our method is feasible and has a potential to generate natural sentences. 1 2 Introduction Recipe Flow Graph Corpus The input of our LNG system is the meaning representation (Mori et al., 2014) for cooking instructions in a recipe. A recipe consists of three parts: a title, an ingredient list, and sentences describing cooking instructions (see Figure 1). The meaning of the instruction sentences is represented by a directed acyclic graph (DAG) with a root (the ﬁnal dish) as shown in Figure 2. Its vertices have a pair of an important word sequence in the recipe and its type called a recipe named entity (NE)1 . And its arcs denote relationships between them. The arcs are also classiﬁed into some types. In this paper, however, we do not use arc types for text generation, because we want"
W14-4418,P11-2093,1,0.780421,"ﬂow graph, we choose the following algorithm. Skeleton Pool Compilation Before the run time, we ﬁrst prepare a skeleton pool. A skeleton pool is a collection of skeleton sentences, or skeletons for short, and a skeleton is a sentence in which NEs have been replaced with NE tags. The skeletons are similar to the so-called templates and the main diﬀerence is that the skeletons are automatically converted from real sentences. The following is the process to prepare a skeleton pool. 1. Crawl cooking procedural sentences from recipe sites. 2. Segment sentences into words by a word segmenter KyTea (Neubig et al., 2011). Then recognize recipe NEs by an NE recognizer PWNER (Mori et al., 2012). 3. Replace the NE instances in the sentences with NE tags. 1. search for an Ac vertex by the depth ﬁrst search (DFS), 2. each time it ﬁnds an Ac, return the largest subtree which has an Ac as its root and contains only unvisited vertices. 3. set the visited-mark to the vertices contained in the returned subtree, 4. go back to 1 unless all the vertices are marked as visited. In DFS, we choose a child vertex randomly because a recipe ﬂow graph is unordered. 119 Table 1: Corpus speciﬁcations. Usage #Recipes #Sent. #NEs #Wo"
W14-4418,P02-1040,0,0.0986745,"teps. 1. Collect skeletons from the pool whose NE key matches the NE tag sequence speciﬁed by the subtree3 . 2. Select the skeleton that maximize a scoring function among collected ones. As the ﬁrst trial we use the frequency of skeletons in the pool as the scoring function. 3. Replace each NE in the skeleton with the word sequence of the corresponding NE in the subtree. 4 Evaluation 4.3 We conducted experiments generating texts from ﬂow graphs. In this section, we report the coverage and the sentence quality. 4.1 To measure the quality of generated texts, we ﬁrst calculated the BLEU (N = 4) (Papineni et al., 2002) with taking the original recipe texts as the references. The unit in our case is a sequence of sentences for a dish. Table 2 shows the average BLEU for all the test set. The result says that the more sentences we use for the skeleton pool compilation, the better the generated sentences become. The absolute BLEU score, however, does not tell much about the quality of generated texts. As it is well known, we can sometimes change the instruction order in dish preparation. Therefore we conducted a subjective evaluation in addition. We asked four evaluators to read 10 texts generated from 10 ﬂow g"
W14-4418,Q13-1003,0,\N,Missing
W15-2202,mori-etal-2014-japanese,1,0.864665,"Missing"
W15-2202,P11-2093,1,0.904681,"Missing"
W15-2202,nivre-etal-2006-maltparser,0,0.0507612,"with the smallest unit that the parser uses for training. In the extreme case this is as small as a single dependency between two words. This fine-grained annotation unit is a natural fit for active learning, where we seek to find training examples with the greatest training value. However, fine-grained units are cognitively more difficult for a human annotator because less context is available. Thus, we must balance the granularity of annotations against the difficulty of processing them. 3 MST Parsing Currently, the two major types of data-driven dependency parsers are shift-reduce parsers (Nivre et al., 2006) and graph-based parsers (McDonald et al., 2005). Shift-reduce parsers perform parsing deterministically (so their time complexity can be as fast as linear in the size of the input). Graph-based dependency parsers treat parsing as 3.2 Pointwise MST Parsing To enable the use of partial annotation in active learning, we use a pointwise MST parser (Flannery et al., 2011) that predicts each word’s head independently. It uses only simple features based 12 on surface forms and part-of-speech (POS) tags of words, and first-order features between pairs of head and dependent words. Higher-order feature"
W15-2202,I11-1087,1,0.959819,"sults for simulations only because of the high cost of annotation work. We use active learning to perform domain adaptation for a Japanese dependency parsing task, and measure the actual time required for manual annotation of training data to better frame the results of our experiments. This kind of evaluation is crucial for assessing the effectiveness of active learning in practice. Previous work on active learning for structured prediction tasks like parsing (Hwa, 2004) often assumes that the training data must be fully annotated. But recent work on dependency parsing (Spreyer et al., 2010; Flannery et al., 2011) has shown that models trained from partially annotated data (where only part of the tree structure is annotated) can achieve competitive performance. However, deciding which portion of the tree structure to annotate remains a difficult problem. The machine learning-based approaches that dominate natural language processing research require massive amounts of labeled training data. Active learning has the potential to substantially reduce the human effort needed to prepare this data by allowing annotators to focus on only the most informative training examples. This paper shows that active lea"
W15-2202,P10-1037,0,0.307866,"Missing"
W15-2202,J04-3001,0,0.697854,"Olsson, 2009), but most of it is concerned only with the single-domain case. Additionally, work on active learning commonly reports results for simulations only because of the high cost of annotation work. We use active learning to perform domain adaptation for a Japanese dependency parsing task, and measure the actual time required for manual annotation of training data to better frame the results of our experiments. This kind of evaluation is crucial for assessing the effectiveness of active learning in practice. Previous work on active learning for structured prediction tasks like parsing (Hwa, 2004) often assumes that the training data must be fully annotated. But recent work on dependency parsing (Spreyer et al., 2010; Flannery et al., 2011) has shown that models trained from partially annotated data (where only part of the tree structure is annotated) can achieve competitive performance. However, deciding which portion of the tree structure to annotate remains a difficult problem. The machine learning-based approaches that dominate natural language processing research require massive amounts of labeled training data. Active learning has the potential to substantially reduce the human e"
W15-2202,spreyer-etal-2010-training,0,0.246591,"Missing"
W15-2202,I08-7018,0,0.0335407,"are still common when using active learning because the cost of annotation is very high. However, recently there is increased interest in measuring the true costs of annotation work when doing active learning (Settles et al., 2008). For a more realistic evaluation of active learning for parsing, we also measured annotation time for the 2-stage strategy. We trained a model on EHJ-train plus NKN-train and used this model and the 2-stage strategy to select dependencies to be annotated by a human annotator. The pool is 747 blog sentences5 from the Balanced Corpus of Contemporary Written Japanese (Maekawa, 2008). We selected 2k dependencies in a single iteration so the annotator did not need to wait while the model was retrained after each batch of annotations. While real annotation times are not constant, this simplification is justified because we expect the annotation strategy (partial or full) to have a larger effect on the overall annotation speed than the dependencies that are selected. A single annotator performed annotations for one hour each using the 2-stage strategy with both partial annotation and full annotation, alternating strategies every fifteen minutes. Sentences with more than fort"
W15-2202,P02-1016,0,0.510575,"d to random selection. We found that partial annotation delivers better indomain performance for the same amount of human effort than full annotation. 1 2 Related Work Most previous work on active learning for parsing (Hwa, 2004; Sassano and Kurohashi, 2010) studies the single-domain case, where the initial labeled data set and the pool of unlabeled data share the same domain. An important difference from previous work is that we focus on domain adaptation, so we assume that the initial labeled data and annotation pool come from different domains. Previous work on active learning for parsing (Tang et al., 2002; Hwa, 2004) has focused on selecting sentences to be fully annotated. Sassano and Kurohashi (2010) showed that smaller units like phrases (bunsetsu) could also be used in an active learning scenario for a Japanese dependency parser. Their work included results for partially Introduction Active learning is a promising approach for domain adaptation because it offers a way to reduce the amount of data needed to train classifiers, minimizing the amount of difficult in-domain annotation. This type of annotation requires annotators to have both domain knowledge plus familiarity with * This work wa"
W15-2202,J11-1007,0,0.0178287,"un, part., verb verb, NULL, NULL The second word, the case marker は (subj.), has two grammatically possible heads: the verbs つなが (leads) and 歓迎 (welcomes). In the partial annotation framework, only this word needs to be annotated. Table 1: An example of full annotation (di full) and partial annotation (di part.) for a sentence. Features for the dependency between the case marker は (subj.) and the verb 歓迎 (welcomes) are also shown. the search for a directed maximum spanning tree (MST). We adopt the latter type in this paper because its accuracy is slightly higher especially for long sentences (McDonald and Nivre, 2011). annotated sentences, but did not use entropy-based query strategies (Tang et al., 2002; Hwa, 2004) designed for selecting whole sentences because of the difficulty of applying them. We use an even smaller unit, words, and show how entropy-based measures can be successfully applied to their selection. Mirroshandel and Nasr (2011) also investigated selection of units smaller than sentences for a graph-based parser in the single-domain setting. Their query strategy used an entropy-based measure calculated from n-best lists, which are computationally expensive and require modification of the par"
W15-2202,E06-1011,0,0.338431,"Missing"
W15-2202,H05-1066,0,0.222911,"Missing"
W15-2202,W11-2917,0,0.183854,"Features for the dependency between the case marker は (subj.) and the verb 歓迎 (welcomes) are also shown. the search for a directed maximum spanning tree (MST). We adopt the latter type in this paper because its accuracy is slightly higher especially for long sentences (McDonald and Nivre, 2011). annotated sentences, but did not use entropy-based query strategies (Tang et al., 2002; Hwa, 2004) designed for selecting whole sentences because of the difficulty of applying them. We use an even smaller unit, words, and show how entropy-based measures can be successfully applied to their selection. Mirroshandel and Nasr (2011) also investigated selection of units smaller than sentences for a graph-based parser in the single-domain setting. Their query strategy used an entropy-based measure calculated from n-best lists, which are computationally expensive and require modification of the parser’s edge scoring function to produce. In contrast, our query strategy is a simpler one that does not require n-best lists. All of the work discussed here reports results for simulations only. This is common practice in active learning research because large-scale annotation is prohibitively expensive. Some recent work on active"
W15-2202,D10-1069,0,\N,Missing
W15-2206,C04-1035,0,0.0445974,"Missing"
W15-2206,mori-etal-2014-flow,1,0.877863,"pt functioning as clues for the structure. As a representative of procedural texts, we selected cooking recipes, because there are many available resources not only in the NLP area but in the computer vision (CV) area. For example, the TACoS dataset (Regneri et al., 2013), is a collection of short videos recording fundamental actions in cooking with descriptions written by Amazon Mechanical Turk. Another example, the KUSK dataset (Hashimoto et al., 2014), contains 40 videos recording entire executions (20 recipes by two persons). The recipes in the KUSK dataset are taken from the r-FG corpus (Mori et al., 2014), in which each recipe text is annotated with its “meaning.” We tested our framework on recipe texts manually annotated with word boundary information, concepts, and a flow graph. We compare a naive application of an MST dependency parser and our extension for flow graph estimation. We also measure the accuracy at each step with the gold input assuming the perfect preceding steps. Finally we evaluate the full automatic process of building a flow graph from a raw text. Our result can be a solid baseline for future improvement in the procedural text understanding problem. 2 From the NLP viewpoin"
W15-2206,P10-1001,0,0.0104772,"u is left to v and -1 otherwise, Here the symbol ∧ indicates the combination of individual features. Next we simply concatenate the label l with each feature to construct feature vectors of labeled arcs. For example, we extracts a feature “concept tag of u ∧ concept tag of v.” Then, this type of feature becomes “l ∧ concept tag of u ∧ concept tag of v.” by concatenating the label l. The same concatenation of a label is done on the other features. So-called higher order features which refer to the neighboring vertices in the DAG are common in work on dependency parsing (McDonald et al., 2006; Koo and Collins, 2010), but we do not use these kinds of features because we only have 200 recipes annotated with DAGs9 . This number is much smaller than roughly 40,000 sentences of the Wall Street Journal which are commonly used to train dependency parsers (Marcus et al., 1994). F2: Whether u and v are in the same sentence, 8 Evaluation F3: Whether u and v are in the same step, We evaluated our framework on the r-FG corpus described in Table 1. We executed 10-fold cross validation for more reliable results. DAG estimation accuracy is measured by the F-measure of labeled arcs, which is the harmonic mean of precisi"
W15-2206,P11-2093,1,0.731042,"e relationship between “heat” and “add.” Celery etc. should be added not to the initial cold Dutch oven without oil but to the hot Dutch oven with oil, which is the implicit result of the action “heat.” 4 5 Word Segmentation Some languages such as Japanese or Chinese, have no obvious word boundary like whitespace in English. The first step of our framework is WS. For many European languages this process is almost obvious and instead of WS we only need to decompose some special words like “isn’t” to “is” + “not” in English or “du” to “de” + “le” in French. For WS we adopt the pointwise method (Neubig et al., 2011) because of its flexibility for language resource addition.3 This characteristics is suitable especially for domain adaptation. Below we explain pointwise WS briefly and our method to improve its accuracy for user generated recipes. Overview of Procedural Text Understanding Our framework of procedural text understanding consists of the following three processes combined in the cascaded manner. 1. Word segmentation (WS) 2. Concept identification (CI) 3. Flow graph estimation 3 An implementation and the default model for the general domain are available from http://www.phontron. com/kytea/ (acce"
W15-2206,I08-7018,0,0.00907816,"s of a word sequence and a concept type) as the input. The output of an MST parser is a tree, but not a DAG. So we add our arc addition module for a fair comparison. As the implementation, we modified a Japanese dependency parser (Flannery et al., 2012) that uses the logistic regression as the scoring function. 8.2.1 Settings of Word Segmentation and Concept Identification We built an automatic word segmenter and an automatic concept identifier in the following way. WS: The word segmenter (see Section 5) is trained on the following corpora. 1. Balanced Corpus of Contemporary Written Japanese (Maekawa, 2008) containing fully segmented 53,899 sentences from newspaper articles, books, magazines, whitepapers, Web logs, and Web QAs. 2. The partially segmented sentences derived from 208 recipes in the r-FG corpus and additional 208 recipes annotated with concept types. In the experiment, we excluded the test part in 10fold cross validation. Thus we built 10 models in total. 3. Partially annotated 1,651 sentences crawled from another recipe Web site10 . Proposed This combines the spanning tree estimation (Subsection 7.1) and the arc addition (Subsection 7.2) in the cascaded manner. Different from the B"
W15-2206,C04-1157,0,0.0236287,"ith the gold input assuming the perfect preceding steps. Finally we evaluate the full automatic process of building a flow graph from a raw text. Our result can be a solid baseline for future improvement in the procedural text understanding problem. 2 From the NLP viewpoint, the major problems we are solving are 1) dependency parsing (Buchholz and Marsi, 2006) among concepts only, 2) predicate-argument structure analysis (Taira et al., 2010; Yoshino et al., 2013), 3) semantic parsing (Wong and Mooney, 2007; Zettlemoyer and Collins, 2005), and 4) coreference, anaphora, and ellipsis resolution (Nielsen, 2004; Fern´andez et al., 2004). For dependency parsing we resolve the target of modifiers such as quantities, durations, timing clauses. For predicate-argument structure analysis, we figure out which action is applied to what object with what tools, even if it is stated in passive form or just by a past participle. For semantic parsing we resolve the relationships between concepts. For coreference, anaphora, and ellipsis resolution, our DAG constructor links an action to another action that takes the result of the former action or an abstract expression to a concrete intermediate product. Our meth"
W15-2206,H94-1020,0,0.0820112,"concept tag of v.” Then, this type of feature becomes “l ∧ concept tag of u ∧ concept tag of v.” by concatenating the label l. The same concatenation of a label is done on the other features. So-called higher order features which refer to the neighboring vertices in the DAG are common in work on dependency parsing (McDonald et al., 2006; Koo and Collins, 2010), but we do not use these kinds of features because we only have 200 recipes annotated with DAGs9 . This number is much smaller than roughly 40,000 sentences of the Wall Street Journal which are commonly used to train dependency parsers (Marcus et al., 1994). F2: Whether u and v are in the same sentence, 8 Evaluation F3: Whether u and v are in the same step, We evaluated our framework on the r-FG corpus described in Table 1. We executed 10-fold cross validation for more reliable results. DAG estimation accuracy is measured by the F-measure of labeled arcs, which is the harmonic mean of precision and recall. Let Nsys , Nref , and Nint be the number of the estimated arcs, the gold standard arcs, and their intersection, respectively. Then precision = Nint /Nsys , recall = Nint /Nref , and F-measure = 2Nint /(Nref + Nsys ). 7.3 Features The feature f"
W15-2206,H05-1066,0,0.122311,"Missing"
W15-2206,Q13-1003,0,0.0741727,"Missing"
W15-2206,W06-2932,0,0.018652,"th sign, which is +1 if u is left to v and -1 otherwise, Here the symbol ∧ indicates the combination of individual features. Next we simply concatenate the label l with each feature to construct feature vectors of labeled arcs. For example, we extracts a feature “concept tag of u ∧ concept tag of v.” Then, this type of feature becomes “l ∧ concept tag of u ∧ concept tag of v.” by concatenating the label l. The same concatenation of a label is done on the other features. So-called higher order features which refer to the neighboring vertices in the DAG are common in work on dependency parsing (McDonald et al., 2006; Koo and Collins, 2010), but we do not use these kinds of features because we only have 200 recipes annotated with DAGs9 . This number is much smaller than roughly 40,000 sentences of the Wall Street Journal which are commonly used to train dependency parsers (Marcus et al., 1994). F2: Whether u and v are in the same sentence, 8 Evaluation F3: Whether u and v are in the same step, We evaluated our framework on the r-FG corpus described in Table 1. We executed 10-fold cross validation for more reliable results. DAG estimation accuracy is measured by the F-measure of labeled arcs, which is the"
W15-2206,J94-2001,0,0.420304,"t al. (2000) proposed treebased representation of cooking instruction texts (recipes) from the application point of view. These approaches used rule-based methods, but they, along with the current success of the machine learning approach, inspired us to conceive that the procedural text understanding can be a tractable problem for the current NLP. In our framework the procedural text understanding problem is decomposed into three processes. The first process is the well-known WS. There have been many researches reporting high accuracies in various languages based on the corpus-based approach (Merialdo, 1994; Neubig The understanding of procedural texts may allow a more sophisticated combination of NLP an CV. Recently there have been some attempts at aligning videos and natural language descriptions 51 1. 両手 鍋T で 油F を 熱Ac する 。 ( In a Dutch ovenT , heatAc oilF . ) セロリF と 緑 玉ねぎ F と ニンニクF を 加え Ac る 。 ( AddAc celeryF , green onionsF , and garlicF . ) １ 分 ほど D 炒めAc る 。 ( CookAc for about 1 minuteD . ) 2. ブ イヨン F と 水F と マカロニF と 胡椒F を 加え Ac て 、 パスタF が 柔らか Sf く な Af る まで 煮Ac る 。 ( AddAc brothF , the waterF , macaroniF , and pepperF , and simmerAc until the pastaF isAf tenderSf . ) 3. 刻Ac ん だ セージ F を まぶAc"
W15-2206,C80-1016,0,0.752767,"ding Tetsuro Sasada Shinsuke Mori Hirokuni Maeta∗ ACCMS, Kyoto University ACCMS, Kyoto University Cybozu, Inc. 2-7-1 Nihombashi, Chuo-ku, Yoshida Honmachi, Sakyo-ku, Yoshida Honmachi, Sakyo-ku, Tokyo, Japan Kyoto, Japan Kyoto, Japan hirokuni.maeta@gmail.com sasada@ar.media.kyoto-u.ac.jp Abstract forest@i.kyoto-u.ac.jp series of sub-problems: word identification, partof-speech tagging, parsing, semantic analysis, and so on. Contrary to this design, in this paper, we propose a concise framework of NLU focusing on procedural texts. There have been a few attempts at procedural text understanding. Momouchi (1980) tried to convert various procedural texts into so-called PT-chart on the background of automatic programming. Hamada et al. (2000) proposed a method for interpreting cooking instruction texts (recipes) to schedule two or more recipes. Although their definition of understanding was not clear and their approach was based on domain specific heuristic rules, these pioneer works inspired us to tackle a major problem of NLP, text understanding. As the meaning representation of a procedural text we adopt a flow graph. Its vertices are important concepts consisting of word sequences denoting material"
W15-2206,mori-neubig-2014-language,1,0.838842,"n conditional random fields (CRFs). In this paper we use an NER which allows a partially annotated corpus as a training data as well as a normal fully annotated corpus (Mori et al., 2012).4 In the training step this NER estimates the parameters of a classifier based on logistic regression (Fan et al., 2008) from sentences fully (or partially) annotated with NEs (concepts). The features are word n-grams surrounding the word in the focus wi , Table 5 lists the features. 5.2 Domain Adaptation As the WS adaptation to recipes, we convert the rFG corpus into partially segmented sentences following (Mori and Neubig, 2014). In the corpus only r-NEs are segmented into words. That is to say, only both edges of the r-NEs and the inside of the r-NEs are annotated with word boundary information. If the r-NE in focus is ホットドッグ composed of two words, then the partially segmented sentences are ex.) 各|ホ-ッ-ト |ド -ッ-グ |に チ リ 、…, ex.) |ホ-ッ-ト |ド -ッ-グ |を ア ル ミ…, 4 CRFs are also trainable from a partially annotated corpus (Tsuboi et al., 2008). Recently Sasada et al. (2015) have proposed a hybrid method and reported a higher accuracy than CRFs. We may use it for further improvement. where the symbols “|,” “-,” and “ ” mean wor"
W15-2206,P10-2030,0,0.0137006,"oncepts, and a flow graph. We compare a naive application of an MST dependency parser and our extension for flow graph estimation. We also measure the accuracy at each step with the gold input assuming the perfect preceding steps. Finally we evaluate the full automatic process of building a flow graph from a raw text. Our result can be a solid baseline for future improvement in the procedural text understanding problem. 2 From the NLP viewpoint, the major problems we are solving are 1) dependency parsing (Buchholz and Marsi, 2006) among concepts only, 2) predicate-argument structure analysis (Taira et al., 2010; Yoshino et al., 2013), 3) semantic parsing (Wong and Mooney, 2007; Zettlemoyer and Collins, 2005), and 4) coreference, anaphora, and ellipsis resolution (Nielsen, 2004; Fern´andez et al., 2004). For dependency parsing we resolve the target of modifiers such as quantities, durations, timing clauses. For predicate-argument structure analysis, we figure out which action is applied to what object with what tools, even if it is stated in passive form or just by a past participle. For semantic parsing we resolve the relationships between concepts. For coreference, anaphora, and ellipsis resolution"
W15-2206,C08-1113,1,0.540555,"ng the word in the focus wi , Table 5 lists the features. 5.2 Domain Adaptation As the WS adaptation to recipes, we convert the rFG corpus into partially segmented sentences following (Mori and Neubig, 2014). In the corpus only r-NEs are segmented into words. That is to say, only both edges of the r-NEs and the inside of the r-NEs are annotated with word boundary information. If the r-NE in focus is ホットドッグ composed of two words, then the partially segmented sentences are ex.) 各|ホ-ッ-ト |ド -ッ-グ |に チ リ 、…, ex.) |ホ-ッ-ト |ド -ッ-グ |を ア ル ミ…, 4 CRFs are also trainable from a partially annotated corpus (Tsuboi et al., 2008). Recently Sasada et al. (2015) have proposed a hybrid method and reported a higher accuracy than CRFs. We may use it for further improvement. where the symbols “|,” “-,” and “ ” mean word boundary, no word boundary, and no information, 54 At run-time, given a word sequence, the classifier enumerates all possible BIO2 tags ti for each word wi with their probabilities as follows: 1: PLR (ti |w− , wi , w+ ), 3: where w− and w+ are the word sequences preceding it and following it, respectively. Then this NER searches for the tag sequence of the highest probability satisfying the tag sequence cons"
W15-2206,P07-1121,0,0.0274234,"MST dependency parser and our extension for flow graph estimation. We also measure the accuracy at each step with the gold input assuming the perfect preceding steps. Finally we evaluate the full automatic process of building a flow graph from a raw text. Our result can be a solid baseline for future improvement in the procedural text understanding problem. 2 From the NLP viewpoint, the major problems we are solving are 1) dependency parsing (Buchholz and Marsi, 2006) among concepts only, 2) predicate-argument structure analysis (Taira et al., 2010; Yoshino et al., 2013), 3) semantic parsing (Wong and Mooney, 2007; Zettlemoyer and Collins, 2005), and 4) coreference, anaphora, and ellipsis resolution (Nielsen, 2004; Fern´andez et al., 2004). For dependency parsing we resolve the target of modifiers such as quantities, durations, timing clauses. For predicate-argument structure analysis, we figure out which action is applied to what object with what tools, even if it is stated in passive form or just by a past participle. For semantic parsing we resolve the relationships between concepts. For coreference, anaphora, and ellipsis resolution, our DAG constructor links an action to another action that takes"
W15-2206,I13-1126,1,0.823582,"graph. We compare a naive application of an MST dependency parser and our extension for flow graph estimation. We also measure the accuracy at each step with the gold input assuming the perfect preceding steps. Finally we evaluate the full automatic process of building a flow graph from a raw text. Our result can be a solid baseline for future improvement in the procedural text understanding problem. 2 From the NLP viewpoint, the major problems we are solving are 1) dependency parsing (Buchholz and Marsi, 2006) among concepts only, 2) predicate-argument structure analysis (Taira et al., 2010; Yoshino et al., 2013), 3) semantic parsing (Wong and Mooney, 2007; Zettlemoyer and Collins, 2005), and 4) coreference, anaphora, and ellipsis resolution (Nielsen, 2004; Fern´andez et al., 2004). For dependency parsing we resolve the target of modifiers such as quantities, durations, timing clauses. For predicate-argument structure analysis, we figure out which action is applied to what object with what tools, even if it is stated in passive form or just by a past participle. For semantic parsing we resolve the relationships between concepts. For coreference, anaphora, and ellipsis resolution, our DAG constructor l"
W15-2206,W06-2920,0,\N,Missing
W15-2206,J96-1002,0,\N,Missing
W15-2206,W03-0419,0,\N,Missing
W15-2206,M98-1001,0,\N,Missing
W19-8650,N18-1016,0,0.0387281,"Missing"
W19-8650,D15-1166,0,0.0255732,"g dataset for the embedding space. Then we calculate their average K 1 ∑ rk , K k=1 r¯ n = (1) and concatenate it to the image embedding vector for the photo to have un = (ˆ v n , r¯ n ). Encoding (iii): We provide the enhanced image embedding vector to a biLSTM on = biLSTM(un ). (2) Decoding (iv): We provide an LSTM with the output of the encoder on as the initial vector. It decodes repeatedly outputting a token in the vocabulary including period, beginning of step (⟨step⟩), and its ending (⟨/step⟩) to form a step consisting of multiple sentences. We also use the general attention mechanism (Luong et al., 2015), which helps the model to generate important terms by recieving feedback from retrieved step embedding vectors. Based on a hidden vector ht at decoding t-th token and the series of retrieved step embedding vectors R, we calculate the attention weight of kth step atk at t-th token decoding as follows: Procedural Text Generation Figure 2 shows an overview of our method. (i) We pre-train the joint embedding model using image/text pairs. Then, given a photo sequence, our method repeats the following procedures for each photo: (ii) retrieve the top K nearest steps to the photo in the embedding spa"
W19-8650,W14-2407,0,0.0301935,"ods, tools, and 409 Proceedings of The 12th International Conference on Natural Language Generation, pages 409–414, c Tokyo, Japan, 28 Oct - 1 Nov, 2019. 2019 Association for Computational Linguistics actions in the recipe case. The result showed that the proposed method verbalizes them more correctly. Some qualitative analyses also suggested that the proposed method generates a suitable procedural text for a given photo sequence. 2 a step and an image. In our preliminary experiment, the original networks did not achieve a good performance because there are many omissions in procedural texts (Malmaud et al., 2014). To solve this problem, we propose to insert a bi-directional LSTM (biLSTM) to the textual encoder to refer to the preceding and following steps in addition to the current one. Related Work Some researchers have been tackling problems to generate a procedural text from various inputs. In cooking domain, Salvador et al. (2019) tried to generate a recipe from an image of a complete dish. Bosselut et al. (2018) and Kiddon et al. assumed a title and ingredients as the input. It may be, however, almost impossible to generate a good recipe due to lack of information on mesomorphic states of ingredi"
W19-8650,W14-4418,1,0.898394,"Missing"
W19-8650,mori-etal-2014-flow,1,0.856981,"olve this problem, we propose to insert a bi-directional LSTM (biLSTM) to the textual encoder to refer to the preceding and following steps in addition to the current one. Related Work Some researchers have been tackling problems to generate a procedural text from various inputs. In cooking domain, Salvador et al. (2019) tried to generate a recipe from an image of a complete dish. Bosselut et al. (2018) and Kiddon et al. assumed a title and ingredients as the input. It may be, however, almost impossible to generate a good recipe due to lack of information on mesomorphic states of ingredients. Mori et al. (2014a) generated a procedural text from a meaning representation taking intermediate states into account. Close look at these studies suggests the importance of the information on intermediate processes for a procedural text generator to be practical. Thus we assume a photo sequence as the input. Since authors of multimedia procedural texts at least take a photo at each important step, this setting is realistic. Sharing the input and output media the most similar task may be the visual storytelling (Huang et al., 2016). Liu et al. (2017) proposed a joint embedding model for image and text to inter"
Y17-1052,N15-1132,0,0.0265948,"Missing"
Y17-1052,D07-1109,0,0.0463327,"which each sense of every word is provided with definition sentences. Lesk’s method counts the overlapping words that are between the words used in the definition sentence and words that are surrounding the target word in the test sentence. Finally, the sense with the largest overlapping is selected. However, a knowledge based method generally cannot make use of the distribution of senses, resulting in low precision. There are various unsupervised learning methods (Yarowsky, 1995; Izquierdo-Bevi´a et al., 2006; Zhong and Ng, 2009). Recently, methods using a generative model have been studied (Boyd-Graber et al., 2007; Tanigaki et al., 2013; Tanigaki et al., 2015; Komiya et al., 2015). These methods have higher precision than knowledge based methods, in general, and can be expected to improve in the future. However, current unsupervised learning methods have the problem that the sense assigned to a word is a concept, because such a method essentially uses the following heuristic: “If the context surrounding the sense a is similar to the context surrounding the sense b, then a is similar to b.” In general, a and b are ambiguous, so we must measure the distance between a and b to use this heuristic. In the c"
Y17-1052,D14-1110,0,0.0650827,"Missing"
Y17-1052,C08-2011,0,0.0322881,"Missing"
Y17-1052,Y15-1005,1,0.416586,"sk’s method counts the overlapping words that are between the words used in the definition sentence and words that are surrounding the target word in the test sentence. Finally, the sense with the largest overlapping is selected. However, a knowledge based method generally cannot make use of the distribution of senses, resulting in low precision. There are various unsupervised learning methods (Yarowsky, 1995; Izquierdo-Bevi´a et al., 2006; Zhong and Ng, 2009). Recently, methods using a generative model have been studied (Boyd-Graber et al., 2007; Tanigaki et al., 2013; Tanigaki et al., 2015; Komiya et al., 2015). These methods have higher precision than knowledge based methods, in general, and can be expected to improve in the future. However, current unsupervised learning methods have the problem that the sense assigned to a word is a concept, because such a method essentially uses the following heuristic: “If the context surrounding the sense a is similar to the context surrounding the sense b, then a is similar to b.” In general, a and b are ambiguous, so we must measure the distance between a and b to use this heuristic. In the case which a and b are concepts, we can measure that distance. Howeve"
Y17-1052,S10-1094,0,0.0314686,"utation (PACLIC 31), pages 392–399 Cebu City, Philippines, November 16-18, 2017 c Copyright 2017 Hiroyuki Shinnou, Kanako Komiya, Minoru Sasaki and Shinsuke Mori 2 Related Work The availability of a supervised learning method for all-words WSD typically requires specifying the domain. Some systems using a supervised learning method have used all-words WSD tasks of SemEval07 (Navigli et al., 2007), but these systems have a problem with scalability. All-words WSD methods not using a supervised learning method are divided into two types: knowledge based methods and unsupervised learning methods (Kulkarni et al., 2010). Lesk’s method (Lesk, 1986), a well known classical knowledge based method uses a dictionary in which each sense of every word is provided with definition sentences. Lesk’s method counts the overlapping words that are between the words used in the definition sentence and words that are surrounding the target word in the test sentence. Finally, the sense with the largest overlapping is selected. However, a knowledge based method generally cannot make use of the distribution of senses, resulting in low precision. There are various unsupervised learning methods (Yarowsky, 1995; Izquierdo-Bevi´a"
Y17-1052,D14-1113,0,0.0194449,"Missing"
Y17-1052,neubig-mori-2010-word,1,0.789731,"Missing"
Y17-1052,P11-2093,1,0.770145,"g time (Navigli, 2009). However, a sense in many allwords WSD systems is defined as a concept, resulting in coarse granularity. Furthermore, the target language is generally English. Japanese all-words WSD has not been achieved, preventing easy access to it. Given this background, we created a Japanese all-words WSD system called KyWSD1 . KyWSD is 1 The substance of KyWSD is a model built using the Kyoto Text Analysis ToolKit (KyTea)2 , a learning system. By executing KyTea using this model, KyWSD accepts plain Japanese text, segments it into words, and assigns a sense to each segmented word (Neubig et al., 2011). Briefly KyTea is a system learning a morphological analysis model. We build KyWSD using KyTea because all-words WSD can be regarded as a kind of morphological analysis. Therefore, KyTea contains a mechanism for learning a model to adapt to a target domain. The ability to use this mechanism provides KyWSD with high adaptability. For example, adding training data to KyWSD, senses to all words, but a target sense. Thus, KyWSD is an appropriate system for domain adaptation. As seen above, KyWSD provides great value as new use of KyTea. We evaluated KyWSD using a Japanese dictionary task in Sense"
Y17-1052,P13-1087,0,0.0243832,"word is provided with definition sentences. Lesk’s method counts the overlapping words that are between the words used in the definition sentence and words that are surrounding the target word in the test sentence. Finally, the sense with the largest overlapping is selected. However, a knowledge based method generally cannot make use of the distribution of senses, resulting in low precision. There are various unsupervised learning methods (Yarowsky, 1995; Izquierdo-Bevi´a et al., 2006; Zhong and Ng, 2009). Recently, methods using a generative model have been studied (Boyd-Graber et al., 2007; Tanigaki et al., 2013; Tanigaki et al., 2015; Komiya et al., 2015). These methods have higher precision than knowledge based methods, in general, and can be expected to improve in the future. However, current unsupervised learning methods have the problem that the sense assigned to a word is a concept, because such a method essentially uses the following heuristic: “If the context surrounding the sense a is similar to the context surrounding the sense b, then a is similar to b.” In general, a and b are ambiguous, so we must measure the distance between a and b to use this heuristic. In the case which a and b are c"
Y17-1052,P95-1026,0,0.588205,"g methods (Kulkarni et al., 2010). Lesk’s method (Lesk, 1986), a well known classical knowledge based method uses a dictionary in which each sense of every word is provided with definition sentences. Lesk’s method counts the overlapping words that are between the words used in the definition sentence and words that are surrounding the target word in the test sentence. Finally, the sense with the largest overlapping is selected. However, a knowledge based method generally cannot make use of the distribution of senses, resulting in low precision. There are various unsupervised learning methods (Yarowsky, 1995; Izquierdo-Bevi´a et al., 2006; Zhong and Ng, 2009). Recently, methods using a generative model have been studied (Boyd-Graber et al., 2007; Tanigaki et al., 2013; Tanigaki et al., 2015; Komiya et al., 2015). These methods have higher precision than knowledge based methods, in general, and can be expected to improve in the future. However, current unsupervised learning methods have the problem that the sense assigned to a word is a concept, because such a method essentially uses the following heuristic: “If the context surrounding the sense a is similar to the context surrounding the sense b,"
Y17-1052,S01-1008,0,\N,Missing
