2021.findings-emnlp.303,Do {UD} Trees Match Mention Spans in Coreference Annotations?,2021,-1,-1,2,0,227,martin popel,Findings of the Association for Computational Linguistics: EMNLP 2021,0,"One can find dozens of data resources for various languages in which coreference - a relation between two or more expressions that refer to the same real-world entity - is manually annotated. One could also assume that such expressions usually constitute syntactically meaningful units; however, mention spans have been annotated simply by delimiting token intervals in most coreference projects, i.e., independently of any syntactic representation. We argue that it could be advantageous to make syntactic and coreference annotations convergent in the long term. We present a pilot empirical study focused on matches and mismatches between hand-annotated linear mention spans and automatically parsed syntactic trees that follow Universal Dependencies conventions. The study covers 9 datasets for 8 different languages."
2020.cl-3.3,Sentence Meaning Representations Across Languages: What Can We Learn from Existing Frameworks?,2020,-1,-1,1,1,7153,zdenvek vzabokrtsky,Computational Linguistics,0,"This article gives an overview of how sentence meaning is represented in eleven deep-syntactic frameworks, ranging from those based on linguistic theories elaborated for decades to rather lightweight NLP-motivated approaches. We outline the most important characteristics of each framework and then discuss how particular language phenomena are treated across those frameworks, while trying to shed light on commonalities as well as differences."
W19-8508,Attempting to separate inflection and derivation using vector space representations,2019,-1,-1,2,0.594348,14784,rudolf rosa,Proceedings of the Second International Workshop on Resources and Tools for Derivational Morphology,0,None
W19-8510,{D}eri{N}et 2.0: Towards an All-in-One Word-Formation Resource,2019,-1,-1,2,0,23382,jonavs vidra,Proceedings of the Second International Workshop on Resources and Tools for Derivational Morphology,0,None
W19-8511,Building a Morphological Network for {P}ersian on Top of a Morpheme-Segmented Lexicon,2019,-1,-1,3,0,23384,hamid haghdoost,Proceedings of the Second International Workshop on Resources and Tools for Derivational Morphology,0,None
W19-8512,Universal Derivations Kickoff: A Collection of Harmonized Derivational Resources for Eleven Languages,2019,-1,-1,2,0,23383,lukavs kyjanek,Proceedings of the Second International Workshop on Resources and Tools for Derivational Morphology,0,None
R19-1007,Supervised Morphological Segmentation Using Rich Annotated Lexicon,2019,0,0,2,0,11026,ebrahim ansari,Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019),0,"Morphological segmentation of words is the process of dividing a word into smaller units called morphemes; it is tricky especially when a morphologically rich or polysynthetic language is under question. In this work, we designed and evaluated several Recurrent Neural Network (RNN) based models as well as various other machine learning based approaches for the morphological segmentation task. We trained our models using annotated segmentation lexicons. To evaluate the effect of the training data size on our models, we decided to create a large hand-annotated morphologically segmented corpus of Persian words, which is, to the best of our knowledge, the first and the only segmentation lexicon for the Persian language. In the experimental phase, using the hand-annotated Persian lexicon and two smaller similar lexicons for Czech and Finnish languages, we evaluated the effect of the training data size, different hyper-parameters settings as well as different RNN-based models."
L18-1291,Semi-Automatic Construction of Word-Formation Networks (for {P}olish and {S}panish),2018,0,0,3,0,18010,mateusz lango,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1551,{S}ume{C}zech: Large {C}zech News-Based Summarization Dataset,2018,0,1,4,0,228,milan straka,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1584,Using Adversarial Examples in Natural Language Processing,2018,-1,-1,3,0,30136,petr bvelohlavek,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-7615,Error Analysis of Cross-lingual Tagging and Parsing,2017,-1,-1,2,0.696695,14784,rudolf rosa,Proceedings of the 16th International Workshop on Treebanks and Linguistic Theories,0,None
W17-1508,Projection-based Coreference Resolution Using Deep Syntax,2017,0,2,3,0.888889,3253,michal novak,Proceedings of the 2nd Workshop on Coreference Resolution Beyond {O}nto{N}otes ({CORBON} 2017),0,"The paper describes the system for coreference resolution in German and Russian, trained exclusively on coreference relations project ed through a parallel corpus from English. The resolver operates on the level of deep syntax and makes use of multiple specialized models. It achieves 32 and 22 points in terms of CoNLL score for Russian and German, respectively. Analysis of the evaluation results show that the resolver for Russian is able to preserve 66{\%} of the English resolver{'}s quality in terms of CoNLL score. The system was submitted to the Closed track of the CORBON 2017 Shared task."
W17-1226,"{S}lavic Forest, {N}orwegian Wood",2017,0,0,4,0.696695,14784,rudolf rosa,"Proceedings of the Fourth Workshop on {NLP} for Similar Languages, Varieties and Dialects ({V}ar{D}ial)",0,"We once had a corp, or should we say, it once had us They showed us its tags, isn{'}t it great, unified tags They asked us to parse and they told us to use everything So we looked around and we noticed there was near nothing We took other langs, bitext aligned: words one-to-one We played for two weeks, and then they said, here is the test The parser kept training till morning, just until deadline So we had to wait and hope what we get would be just fine And, when we awoke, the results were done, we saw we{'}d won So, we wrote this paper, isn{'}t it good, Norwegian wood."
W17-0412,{U}dapi: Universal {API} for {U}niversal {D}ependencies,2017,3,3,2,0.674603,227,martin popel,Proceedings of the {N}o{D}a{L}i{D}a 2017 Workshop on Universal Dependencies ({UDW} 2017),0,None
Y16-2018,Planting Trees in the Desert: Delexicalized Tagging and Parsing Combined,2016,14,0,4,0,5828,daniel zeman,"Proceedings of the 30th Pacific Asia Conference on Language, Information and Computation: Oral Papers",0,None
L16-1015,If You {E}ven Don{'}t Have a Bit of {B}ible: Learning Delexicalized {POS} Taggers,2016,17,2,3,0,13611,zhiwei yu,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Part-of-speech (POS) induction is one of the most popular tasks in research on unsupervised NLP. Various unsupervised and semi-supervised methods have been proposed to tag an unseen language. However, many of them require some partial understanding of the target language because they rely on dictionaries or parallel corpora such as the Bible. In this paper, we propose a different method named delexicalized tagging, for which we only need a raw corpus of the target language. We transfer tagging models trained on annotated corpora of one or more resource-rich languages. We employ language-independent features such as word length, frequency, neighborhood entropy, character classes (alphabetic vs. numeric vs. punctuation) etc. We demonstrate that such features can, to certain extent, serve as predictors of the part of speech, represented by the universal POS tag."
L16-1208,Merging Data Resources for Inflectional and Derivational Morphology in {C}zech,2016,0,4,1,1,7153,zdenvek vzabokrtsky,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"The paper deals with merging two complementary resources of morphological data previously existing for Czech, namely the inflectional dictionary MorfFlex CZ and the recently developed lexical network DeriNet. The MorfFlex CZ dictionary has been used by a morphological analyzer capable of analyzing/generating several million Czech word forms according to the rules of Czech inflection. The DeriNet network contains several hundred thousand Czech lemmas interconnected with links corresponding to derivational relations (relations between base words and words derived from them). After summarizing basic characteristics of both resources, the process of merging is described, focusing on both rather technical aspects (growth of the data, measuring the quality of newly added derivational relations) and linguistic issues (treating lexical homonymy and vowel/consonant alternations). The resulting resource contains 970 thousand lemmas connected with 715 thousand derivational relations and is publicly available on the web under the CC-BY-NC-SA license. The data were incorporated in the MorphoDiTa library version 2.0 (which provides morphological analysis, generation, tagging and lemmatization for Czech) and can be browsed and searched by two web tools (DeriNet Viewer and DeriNet Search tool)."
W15-2209,{MSTP}arser Model Interpolation for Multi-Source Delexicalized Transfer,2015,18,2,2,0.789474,14784,rudolf rosa,Proceedings of the 14th International Conference on Parsing Technologies,0,"We introduce interpolation of trained MSTParser models as a resource combination method for multi-source delexicalized parser transfer. We present both an unweighted method, as well as a variant in which each source model is weighted by the similarity of the source language to the target language. Evaluation on the HamleDT treebank collection shows that the weighted model interpolation performs comparably to weighted parse tree combination method, while being computationally much less demanding."
P15-2040,{KL}cpos3 - a Language Similarity Measure for Delexicalized Parser Transfer,2015,25,15,2,0.789474,14784,rudolf rosa,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),0,"We present KLcpos3 , a language similarity measure based on Kullback-Leibler divergence of coarse part-of-speech tag trigram distributions in tagged corpora. It has been designed for multilingual delexicalized parsing, both for source treebank selection in single-source parser transfer, and for source treebank weighting in multi-source transfer. In the selection task, KLcpos3 identifies the best source treebank in 8 out of 18 cases. In the weighting task, it brings 4.5% UAS absolute, compared to unweighted parse tree combination."
sevcikova-zabokrtsky-2014-word,Word-Formation Network for {C}zech,2014,14,6,2,1,21978,magda vsevvcikova,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In the present paper, we describe the development of the lexical network DeriNet, which captures core word-formation relations on the set of around 266 thousand Czech lexemes. The network is currently limited to derivational relations because derivation is the most frequent and most productive word-formation process in Czech. This limitation is reflected in the architecture of the network: each lexeme is allowed to be linked up with just a single base word; composition as well as combined processes (composition with derivation) are thus not included. After a brief summarization of theoretical descriptions of Czech derivation and the state of the art of NLP approaches to Czech derivation, we discuss the linguistic background of the network and introduce the formal structure of the network and the semi-automatic annotation procedure. The network was initialized with a set of lexemes whose existence was supported by corpus evidence. Derivational links were created using three sources of information: links delivered by a tool for morphological analysis, links based on an automatically discovered set of derivation rules, and on a grammar-based set of rules. Finally, we propose some research topics which could profit from the existence of such lexical network."
rosa-etal-2014-hamledt,{H}amle{DT} 2.0: Thirty Dependency Treebanks Stanfordized,2014,30,20,6,0.789474,14784,rudolf rosa,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"We present HamleDT 2.0 (HArmonized Multi-LanguagE Dependency Treebank). HamleDT 2.0 is a collection of 30 existing treebanks harmonized into a common annotation style, the Prague Dependencies, and further transformed into Stanford Dependencies, a treebank annotation style that became popular in recent years. We use the newest basic Universal Stanford Dependencies, without added language-specific subtypes. We describe both of the annotation styles, including adjustments that were necessary to make, and provide details about the conversion process. We also discuss the differences between the two styles, evaluating their advantages and disadvantages, and note the effects of the differences on the conversion. We regard the stanfordization as generally successful, although we admit several shortcomings, especially in the distinction between direct and indirect objects, that have to be addressed in future. We release part of HamleDT 2.0 freely; we are not allowed to redistribute the whole dataset, but we do provide the conversion pipeline."
C14-1003,Cross-lingual Coreference Resolution of Pronouns,2014,31,8,2,1,3253,michal novak,"Proceedings of {COLING} 2014, the 25th International Conference on Computational Linguistics: Technical Papers",0,"This work is, to our knowledge, a first attempt at a machine learning approach to cross-lingual coreference resolution, i.e. coreference resolution (CR) performed on a bitext. Focusing on CR of English pronouns, we leverage language differences and enrich the feature set of a standard monolingual CR system for English with features extracted from the Czech side of the bitext. Our work also includes a supervised pronoun aligner that outperforms a GIZA baseline in terms of both intrinsic evaluation and evaluation on CR. The final cross-lingual CR system has successfully outperformed both a monolingual CR and a cross-lingual projection system."
W13-3307,Translation of {``}It{''} in a Deep Syntax Framework,2013,14,14,3,1,3253,michal novak,Proceedings of the Workshop on Discourse in Machine Translation,0,"We present a novel approach to the translation of the English personal pronoun it to Czech. We conduct a linguistic analysis on how the distinct categories of it are usually mapped to their Czech counterparts. Armed with these observations, we design a discriminative translation model of it, which is then integrated into the TectoMT deep syntax MT framework. Features in the model take advantage of rich syntactic annotation TectoMT is based on, external tools for anaphoricity resolution, lexical co-occurrence frequencies measured on a large parallel corpus and gold coreference annotation. Even though the new model for it exhibits no improvement in terms of BLEU, manual evaluation shows that it outperforms the original solution in 8.5% sentences containing it."
W13-2805,Improvements to Syntax-based Machine Translation using Ensemble Dependency Parsers,2013,23,3,2,1,29993,nathan green,Proceedings of the Second Workshop on Hybrid Approaches to Translation,0,"Dependency parsers are almost ubiquitously evaluated on their accuracy scores, these scores say nothing of the complexity and usefulness of the resulting structures. The structures may have more complexity due to their coordination structure or attachment rules. As dependency parses are basic structures in which other systems are built upon, it would seem more reasonable to judge these parsers down the NLP pipeline. We show results from 7 individual parsers, including dependency and constituent parsers, and 3 ensemble parsing techniques with their overall effect on a Machine Translation system, Treex, for English to Czech translation. We show that parsersxe2x80x99 UAS scores are more correlated to the NIST evaluation metric than to the BLEU Metric, however we see increases in both metrics."
P13-1051,Coordination Structures in Dependency Treebanks,2013,31,22,5,1,227,martin popel,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"Paratactic syntactic structures are notoriously difficult to represent in dependency formalisms. This has painful consequences such as high frequency of parsing errors related to coordination. In other words, coordination is a pending problem in dependency analysis of natural languages. This paper tries to shed some light on this area by bringing a systematizing view of various formal means developed for encoding coordination structures. We introduce a novel taxonomy of such approaches and apply it to treebanks across a typologically diverse range of 26 languages. In addition, empirical observations on convertibility between selected styles of representations are shown too."
I13-1142,Two Case Studies on Translating Pronouns in a Deep Syntax Framework,2013,10,4,2,1,3253,michal novak,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,We focus on improving the translation of the English pronoun it and English reflexive pronouns in an English-Czech syntaxbased machine translation framework. Our evaluation both from intrinsic and extrinsic perspective shows that adding specialized syntactic and coreference-related features leads to an improvement in translation quality.
W12-5611,Morphological Processing for {E}nglish-{T}amil Statistical Machine Translation,2012,15,15,3,0,42069,loganathan ramasamy,Proceedings of the Workshop on Machine Translation and Parsing in {I}ndian Languages,0,"Various experiments from literature suggest that in statistical machine translation (SMT), applying either pre-processing or post-processing to morphologically rich languages leads to better translation quality. In this work, we focus on the English-Tamil language pair. We implement suffix-separation rules for both of the languages and evaluate the impact of this preprocessing on translation quality of the phrase-based as well as hierarchical model in terms of BLEU score and a small manual evaluation. The results confirm that our simple suffix-based morphological processing helps to obtain better translation performance. A by-product of our efforts is a new parallel corpus of 190k sentence pairs gathered from the web."
W12-3903,The Study of Effect of Length in Morphological Segmentation of Agglutinative Languages,2012,21,1,2,0,42069,loganathan ramasamy,Proceedings of the First Workshop on Multilingual Modeling,0,"Morph length is one of the indicative feature that helps learning the morphology of languages, in particular agglutinative languages. In this paper, we introduce a simple unsupervised model for morphological segmentation and study how the knowledge of morph length affect the performance of the segmentation task under the Bayesian framework. The model is based on (Goldwater et al., 2006) unigram word segmentation model and assumes a simple prior distribution over morph length. We experiment this model on two highly related and agglutinative languages namely Tamil and Telugu, and compare our results with the state of the art Morfessor system. We show that, knowledge of morph length has a positive impact and provides competitive results in terms of overall performance."
W12-3410,Using an {SVM} Ensemble System for Improved {T}amil Dependency Parsing,2012,19,4,3,1,29993,nathan green,Proceedings of the {ACL} 2012 Joint Workshop on Statistical Parsing and Semantic Processing of Morphologically Rich Languages,0,"Dependency parsing has been shown to improve NLP systems in certain languages and in many cases helps achieve state of the art results in NLP applications, in particular applications for free word order languages. Morphologically rich languages are often short on training data or require much higher amounts of training data due to the increased size of their lexicon. This paper examines a new approach for addressing morphologically rich languages with little training data to start. Using Tamil as our test language, we create 9 dependency parse models with a limited amount of training data. Using these models we train an SVM classifier using only the model agreements as features. We use this SVM classifier on an edge by edge decision to form an ensemble parse tree. Using only model agreements as features allows this method to remain language independent and applicable to a wide range of morphologically rich languages. We show a statistically significant 5.44% improvement over the average dependency model and a statistically significant 0.52% improvement over the best individual system."
W12-3132,Formemes in {E}nglish-{C}zech Deep Syntactic {MT},2012,20,10,2,0,2976,ondvrej duvsek,Proceedings of the Seventh Workshop on Statistical Machine Translation,0,"One of the most notable recent improvements of the TectoMT English-to-Czech translation is a systematic and theoretically supported revision of formemes---the annotation of morpho-syntactic features of content words in deep dependency syntactic structures based on the Prague tectogrammatics theory. Our modifications aim at reducing data sparsity, increasing consistency across languages and widening the usage area of this markup. Formemes can be used not only in MT, but in various other NLP tasks."
W12-1911,Unsupervised Dependency Parsing using Reducibility and Fertility features,2012,4,1,2,1,9478,david marevcek,Proceedings of the {NAACL}-{HLT} Workshop on the Induction of Linguistic Structure,0,"This paper describes a system for unsupervised dependency parsing based on Gibbs sampling algorithm. The novel approach introduces a fertility model and reducibility model, which assumes that dependent words can be removed from a sentence without violating its syntactic correctness."
W12-0503,Hybrid Combination of Constituency and Dependency Trees into an Ensemble Dependency Parser,2012,22,12,2,1,29993,nathan green,Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data,0,"Dependency parsing has made many advancements in recent years, in particular for English. There are a few dependency parsers that achieve comparable accuracy scores with each other but with very different types of errors. This paper examines creating a new dependency structure through ensemble learning using a hybrid of the outputs of various parsers. We combine all tree outputs into a weighted edge graph, using 4 weighting mechanisms. The weighted edge graph is the input into our ensemble system and is a hybrid of very different parsing techniques (constituent parsers, transition-based dependency parsers, and a graph-based parser). From this graph we take a maximum spanning tree. We examine the new dependency structure in terms of accuracy and errors on individual part-of-speech values.n n The results indicate that using a greater number of more varied parsers will improve accuracy results. The combined ensemble system, using 5 parsers based on 3 different parsing techniques, achieves an accuracy score of 92.58%, beating all single parsers on the Wall Street Journal section 23 test set. Additionally, the ensemble system reduces the average relative error on selected POS tags by 9.82%."
majlis-zabokrtsky-2012-language,Language Richness of the Web,2012,3,17,2,0,42252,martin majlivs,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We have built a corpus containing texts in 106 languages from texts available on the Internet and on Wikipedia. The W2C Web Corpus contains 54.7{\textasciitilde}GB of text and the W2C Wiki Corpus contains 8.5{\textasciitilde}GB of text. The W2C Web Corpus contains more than 100{\textasciitilde}MB of text available for 75 languages. At least 10{\textasciitilde}MB of text is available for 100 languages. These corpora are a unique data source for linguists, since they outclass all published works both in the size of the material collected and the number of languages covered. This language data resource can be of use particularly to researchers specialized in multilingual technologies development. We also developed software that greatly simplifies the creation of a new text corpus for a given language, using text materials freely available on the Internet. Special attention was given to components for filtering and de-duplication that allow to keep the material quality very high."
zeman-etal-2012-hamledt,{H}amle{DT}: To Parse or Not to Parse?,2012,24,34,6,0.267857,5828,daniel zeman,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We propose HamleDT â HArmonized Multi-LanguagE Dependency Treebank. HamleDT is a compilation of existing dependency treebanks (or dependency conversions of other treebanks), transformed so that they all conform to the same annotation style. While the license terms prevent us from directly redistributing the corpora, most of them are easily acquirable for research purposes. What we provide instead is the software that normalizes tree structures in the data obtained by the user from their original providers."
ramasamy-zabokrtsky-2012-prague,{P}rague Dependency Style Treebank for {T}amil,2012,12,9,2,0,42069,loganathan ramasamy,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Annotated corpora such as treebanks are important for the development of parsers, language applications as well as understanding of the language itself. Only very few languages possess these scarce resources. In this paper, we describe our efforts in syntactically annotating a small corpora (600 sentences) of Tamil language. Our annotation is similar to Prague Dependency Treebank (PDT) and consists of annotation at 2 levels or layers: (i) morphological layer (m-layer) and (ii) analytical layer (a-layer). For both the layers, we introduce annotation schemes i.e. positional tagging for m-layer and dependency relations for a-layers. Finally, we discuss some of the issues in treebank development for Tamil."
hajic-etal-2012-announcing,Announcing {P}rague {C}zech-{E}nglish {D}ependency {T}reebank 2.0,2012,5,27,16,0,17503,jan hajivc,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"We introduce a substantial update of the Prague Czech-English Dependency Treebank, a parallel corpus manually annotated at the deep syntactic layer of linguistic representation. The English part consists of the Wall Street Journal (WSJ) section of the Penn Treebank. The Czech part was translated from the English source sentence by sentence. This paper gives a high level overview of the underlying linguistic theory (the so-called tectogrammatical annotation) with some details of the most important features like valency annotation, ellipsis reconstruction or coreference."
bojar-etal-2012-joy,The Joy of Parallelism with {C}z{E}ng 1.0,2012,15,34,2,0.403226,292,ondvrej bojar,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"CzEng 1.0 is an updated release of our Czech-English parallel corpus, freely available for non-commercial research or educational purposes. In this release, we approximately doubled the corpus size, reaching 15 million sentence pairs (about 200 million tokens per language). More importantly, we carefully filtered the data to reduce the amount of non-matching sentence pairs. CzEng 1.0 is automatically aligned at the level of sentences as well as words. We provide not only the plain text representation, but also automatic morphological tags, surface syntactic as well as deep syntactic dependency parse trees and automatic co-reference links in both English and Czech. This paper describes key properties of the released resource including the distribution of text domains, the corpus data formats, and a toolkit to handle the provided rich annotation. We also summarize the procedure of the rich annotation (incl. co-reference resolution) and of the automatic filtering. Finally, we provide some suggestions on exploiting such an automatically annotated sentence-parallel corpus."
D12-1028,Exploiting Reducibility in Unsupervised Dependency Parsing,2012,15,9,2,1,9478,david marevcek,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,0,The possibility of deleting a word from a sentence without violating its syntactic correctness belongs to traditionally known manifestations of syntactic dependency. We introduce a novel unsupervised parsing approach that is based on a new n-gram reducibility measure. We perform experiments across 18 languages available in CoNLL data and we show that our approach achieves better accuracy for the majority of the languages then previously reported results.
C12-1015,{P}rague {D}ependency {T}reebank 2.5 {--} a Revisited Version of {PDT} 2.0,2012,15,11,7,0,17929,eduard bejvcek,Proceedings of {COLING} 2012,0,"We present the Prague Dependency Treebank 2.5, the newest version of PDT and the first to be released under a free license. We show the benefits of PDT 2.5 in comparison to other state-of-the-art treebanks. We present the new features of the 2.5 release, how they were obtained and how reliably they are annotated. We also show how they can be used in queries and how they are visualised with tools released alongside the treebank."
W11-3901,{G}ibbs Sampling with Treeness Constraint in Unsupervised Dependency Parsing,2011,14,0,2,1,9478,david marevcek,Proceedings of Workshop on Robust Unsupervised and Semisupervised Methods in Natural Language Processing,0,"This paper presents a work in progress on the task of unsupervised parsing, following the main stream approach of optimizing the overall probability of the corpus. We evaluate a sequence of experiments for Czech with various modifications of corpus initiation, of dependency edge probability model and of sampling procedure, stressing especially the treeness constraint. The best configuration is then applied to 19 languages from CoNLL-2006 and CoNLL-2007 shared tasks. Our best achieved results are comparable to the state of the art in dependency parsing and outperform the previously published results for many languages."
W11-2153,Influence of Parser Choice on Dependency-Based {MT},2011,18,9,4,1,227,martin popel,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,Accuracy of dependency parsers is one of the key factors limiting the quality of dependency-based machine translation. This paper deals with the influence of various dependency parsing approaches (and also different training data size) on the overall performance of an English-to-Czech dependency-based statistical translation system implemented in the Treex framework. We also study the relationship between parsing accuracy in terms of unlabeled attachment score and machine translation quality in terms of BLEU.
W10-1730,Maximum Entropy Translation Model in Dependency-Based {MT} Framework,2010,18,13,1,1,7153,zdenvek vzabokrtsky,Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and {M}etrics{MATR},0,"Maximum Entropy Principle has been used successfully in various NLP tasks. In this paper we propose a forward translation model consisting of a set of maximum entropy classifiers: a separate classifier is trained for each (sufficiently frequent) source-side lemma. In this way the estimates of translation probabilities can be sensitive to a large number of features derived from the source sentence (including non-local features, features making use of sentence syntactic structure, etc.). When integrated into English-to-Czech dependency-based translation scenario implemented in the TectoMT framework, the new translation model significantly outperforms the baseline model (MLE) in terms of BLEU. The performance is further boosted in a configuration inspired by Hidden Tree Markov Models which combines the maximum entropy translation model with the target-language dependency tree model."
bojar-etal-2010-evaluating,Evaluating Utility of Data Sources in a Large Parallel {C}zech-{E}nglish Corpus {C}z{E}ng 0.9,2010,3,2,3,0.625,292,ondvrej bojar,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"CzEng 0.9 is the third release of a large parallel corpus of Czech and English. For the current release, CzEng was extended by significant amount of texts from various types of sources, including parallel web pages, electronically available books and subtitles. This paper describes and evaluates filtering techniques employed in the process in order to avoid misaligned or otherwise damaged parallel sentences in the collection. We estimate the precision and recall of two sets of filters. The first set was used to process the data before their inclusion into CzEng. The filters from the second set were newly created to improve the filtering process for future releases of CzEng. Given the overall amount and variance of sources of the data, our experiments illustrate the utility of parallel data sources with respect to extractable parallel segments. As a similar behaviour can be expected for other language pairs, our results can be interpreted as guidelines indicating which sources should other researchers exploit first."
C10-3003,Annotation Tool for Discourse in {PDT},2010,6,4,3,0,16889,jivri mirovsky,Coling 2010: Demonstrations,0,"We present a tool for annotation of sexc2xad mantic interxc2xadsentential discourse relaxc2xad tions on the tectogrammatical layer of the Prague Dependency Treebank (PDT). We present the way of helping the annotators by several useful features implemented in the annotation tool, such as a possibility to combine surface and deep syntactic representation of senxc2xad tences during the annotation, a possibilixc2xad ty to define, display and connect arbixc2xad trary groups of nodes, a clausexc2xadbased compact depiction of trees, etc. For studying differences among parallel anxc2xad notations, the tool offers a simultaneous depiction of parallel annotations of the data."
W09-3939,Comparison of Classification and Ranking Approaches to Pronominal Anaphora Resolution in {C}zech,2009,21,10,3,0,46825,giang ngáy,Proceedings of the {SIGDIAL} 2009 Conference,0,"In this paper we compare two Machine Learning approaches to the task of pronominal anaphora resolution: a conventional classification system based on C5.0 decision trees, and a novel perceptron-based ranker. We use coreference links annotated in the Prague Dependency Treebank 2.0 for training and evaluation purposes. The perceptron system achieves f-score 79.43% on recognizing coreference of personal and possessive pronouns, which clearly outperforms the classifier and which is the best result reported on this data set so far."
W09-3538,{C}zech Named Entity Corpus and {SVM}-based Recognizer,2009,12,25,2,0,46882,jana kravalova,Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration ({NEWS} 2009),0,"This paper deals with recognition of named entities in Czech texts. We present a recently released corpus of Czech sentences with manually annotated named entities, in which a rich two-level classification scheme was used. There are around 6000 sentences in the corpus with roughly 33000 marked named entity instances. We use the data for training and evaluating a named entity recognizer based on Support Vector Machine classification technique. The presented recognizer outperforms the results previously reported for NE recognition in Czech."
W09-0422,{E}nglish-{C}zech {MT} in 2008,2009,15,13,7,0.952381,292,ondvrej bojar,Proceedings of the Fourth Workshop on Statistical Machine Translation,0,We describe two systems for English-to-Czech machine translation that took part in the WMT09 translation task. One of the systems is a tuned phrase-based system and the other one is based on a linguistically motivated analysis-transfer-synthesis approach.
P09-2037,Hidden {M}arkov Tree Model in Dependency-based Machine Translation,2009,11,15,1,1,7153,zdenvek vzabokrtsky,Proceedings of the {ACL}-{IJCNLP} 2009 Conference Short Papers,0,"We would like to draw attention to Hidden Markov Tree Models (HMTM), which are to our knowledge still unexploited in the field of Computational Linguistics, in spite of highly successful Hidden Markov (Chain) Models. In dependency trees, the independence assumptions made by HMTM correspond to the intuition of linguistic dependency. Therefore we suggest to use HMTM and tree-modified Viterbi algorithm for tasks interpretable as labeling nodes of dependency trees. In particular, we show that the transfer phase in a Machine Translation system based on tectogrammatical dependency trees can be seen as a task suitable for HMTM. When using the HMTM approach for the English-Czech translation, we reach a moderate improvement over the baseline."
W08-0325,{T}ecto{MT}: Highly Modular {MT} System with Tectogrammatics Used as Transfer Layer,2008,9,74,1,1,7153,zdenvek vzabokrtsky,Proceedings of the Third Workshop on Statistical Machine Translation,0,We present a new Englishxe2x86x92Czech machine translation system combining linguistically motivated layers of language description (as defined in the Prague Dependency Treebank annotation scenario) with statistical NLP approaches.
bojar-etal-2008-czeng,{C}z{E}ng 0.7: Parallel Corpus with Community-Supplied Translations,2008,5,8,3,0.952381,292,ondvrej bojar,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"This paper describes CzEng 0.7, a new release of Czech-English parallel corpus freely available for research and educational purposes. We provide basic statistics of the corpus and focus on data produced by a community of volunteers. Anonymous contributors manually correct the output of a machine translation (MT) system, generating on average 2000 sentences a month, 70{\%} of which are indeed correct translations. We compare the utility of community-supplied and of professionally translated training data for a baseline English-to-Czech MT system."
2008.eamt-1.16,Automatic alignment of {C}zech and {E}nglish deep syntactic dependency trees,2008,13,8,2,1,9478,david marevcek,Proceedings of the 12th Annual conference of the European Association for Machine Translation,0,"In this paper, we focus on alignment of Czech and English tectogrammatical dependency trees. The alignment of deep syntactic de- pendency trees can be used for training transfer models for machine translation systems based on analysis-transfer-synthesis architecture. The results of our experiments show that shifting the alignment task from the word layer to the tectogrammatical layer both (a) increases the inter- annotator agreement on the task and (b) allows to construct a feature- based algorithm which uses sentence structure and which outperforms the GIZA aligner in terms of f-measure on aligned tectogrammatical node pairs."
lopatkova-etal-2006-valency,Valency Lexicon of {C}zech Verbs: Alternation-Based Model,2006,7,8,2,0,17429,marketa lopatkova,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"The main objective of this paper is to introduce an alternation-based model of valency lexicon of Czech verbs VALLEX. Alternations describe regular changes in valency structure of verbs -- they are seen as transformations taking one lexical unit and return a modified lexical unit as a result. We characterize and exemplify Âsyntactically-basedÂ and Âsemantically-based'Â alternations and their effects on verb argument structure. The alternation-based model allows to distinguish a minimal form of lexicon, which provides compact characterization of valency structure of Czech verbs, and an expanded form of lexicon useful for some applications."
W05-1518,Improving Parsing Accuracy by Combining Diverse Dependency Parsers,2005,15,61,2,0.267857,5828,daniel zeman,Proceedings of the Ninth International Workshop on Parsing Technology,0,"This paper explores the possibilities of improving parsing results by combining outputs of several parsers. To some extent, we are porting the ideas of Henderson and Brill (1999) to the world of dependency structures. We differ from them in exploring context features more deeply. All our experiments were conducted on Czech but the method is language-independent. We were able to significantly improve over the best parsing result for the given setting, known so far. Moreover, our experiments show that even parsers far below the state of the art can contribute to the total improvement."
W04-2711,Valency Frames of {C}zech Verbs in {VALLEX} 1.0,2004,6,10,1,1,7153,zdenvek vzabokrtsky,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,None
zabokrtsky-etal-2002-machine,A Machine Learning Approach to Automatic Functor Assignment in the {P}rague Dependency Treebank,2002,5,10,1,1,7153,zdenvek vzabokrtsky,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"The aim of this paper is to describe and evaluate a system that automates a part of the transition from analytical to tectogrammatical tree structures within the Prague Dependency Treebank. In particular, it assigns functors to autosemantic words. The system is based on the machine learning approach of decision tree induction. The resulting software tool is incorporated into the annotation process and significantly reduces the manual annotation effort during the transition from analytical tree structures to the tectogrammatical tree structures, which consumes a huge amount of time of linguistic experts."
