W19-3104,Bottom-Up Unranked Tree-to-Graph Transducers for Translation into Semantic Graphs,2019,0,0,4,0,10077,johanna bjorklund,Proceedings of the 14th International Conference on Finite-State Methods and Natural Language Processing,0,"We propose a formal model for translating unranked syntactic trees, such as dependency trees, into semantic graphs. These tree-to-graph transducers can serve as a formal basis of transition systems for semantic parsing which recently have been shown to perform very well, yet hitherto lack formalization. Our model features {``}extended{''} rules and an arc-factored normal form, comes with an efficient translation algorithm, and can be equipped with weights in a straightforward manner."
J19-2005,Ordered Tree Decomposition for {HRG} Rule Extraction,2019,25,0,2,0,3945,daniel gildea,Computational Linguistics,0,"We present algorithms for extracting Hyperedge Replacement Grammar (HRG) rules from a graph along with a vertex order. Our algorithms are based on finding a tree decomposition of smallest width, relative to the vertex order, and then extracting one rule for each node in this structure. The assumption of a fixed order for the vertices of the input graph makes it possible to solve the problem in polynomial time, in contrast to the fact that the problem of finding optimal tree decompositions for a graph is NP-hard. We also present polynomial-time algorithms for parsing based on our HRGs, where the input is a vertex sequence and the output is a graph structure. The intended application of our algorithms is grammar extraction and parsing for semantic representation of natural language. We apply our algorithms to data annotated with Abstract Meaning Representations and report on the characteristics of the resulting grammars."
P18-1171,Sequence-to-sequence Models for Cache Transition Systems,2018,0,6,4,0,24422,xiaochang peng,Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"In this paper, we present a sequence-to-sequence based approach for mapping natural language sentences to AMR semantic graphs. We transform the sequence to graph mapping problem to a word sequence to transition action sequence problem using a special transition system called a cache transition system. To address the sparsity issue of neural AMR parsing, we feed feature embeddings from the transition state to provide relevant local information for each decoder state. We present a monotonic hard attention model for the transition framework to handle the strictly left-to-right alignment between each transition state and the current buffer input focus. We evaluate our neural transition model on the AMR parsing task, and our parser outperforms other sequence-to-sequence approaches and achieves competitive results in comparison with the best-performing models."
J18-3004,On the Complexity of {CCG} Parsing,2018,28,0,2,0,12072,marco kuhlmann,Computational Linguistics,0,"We study the parsing complexity of Combinatory Categorial Grammar (CCG) in the formalism of Vijay-Shanker and Weir (1994). As our main result, we prove that any parsing algorithm for this formalism will take in the worst case exponential time when the size of the grammar, and not only the length of the input sentence, is included in the analysis. This sets the formalism of Vijay-Shanker and Weir (1994) apart from weakly equivalent formalisms such as Tree Adjoining Grammar, for which parsing can be performed in time polynomial in the combined size of grammar and input sentence. Our results contribute to a refined understanding of the class of mildly context-sensitive grammars, and inform the search for new, mildly context-sensitive versions of CCG."
J18-1004,Cache Transition Systems for Graph Parsing,2018,-1,-1,2,0,3945,daniel gildea,Computational Linguistics,0,"Motivated by the task of semantic parsing, we describe a transition system that generalizes standard transition-based dependency parsing techniques to generate a graph rather than a tree. Our system includes a cache with fixed size m, and we characterize the relationship between the parameter m and the class of graphs that can be produced through the graph-theoretic concept of tree decomposition. We find empirically that small cache sizes cover a high percentage of sentences in existing semantic corpora."
J18-1005,Weighted {DAG} Automata for Semantic Graphs,2018,-1,-1,5,0,3180,david chiang,Computational Linguistics,0,"Graphs have a variety of uses in natural language processing, particularly as representations of linguistic meaning. A deficit in this area of research is a formal framework for creating, combining, and using models involving graphs that parallels the frameworks of finite automata for strings and finite tree automata for trees. A possible starting point for such a framework is the formalism of directed acyclic graph (DAG) automata, defined by Kamimura and Slutzki and extended by Quernheim and Knight. In this article, we study the latter in depth, demonstrating several new results, including a practical recognition algorithm that can be used for inference and learning with models defined on DAG automata. We also propose an extension to graphs with unbounded node degree and show that our results carry over to the extended formalism."
E17-1051,An Incremental Parser for {A}bstract {M}eaning {R}epresentation,2017,15,45,3,0,982,marco damonte,"Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",0,"Abstract Meaning Representation (AMR) is a semantic representation for natural language that embeds annotations related to traditional tasks such as named entity recognition, semantic role labeling, word sense disambiguation and co-reference resolution. We describe a transition-based parser for AMR that parses sentences left-to-right, in linear time. We further propose a test-suite that assesses specific subtasks that are helpful in comparing AMR parsers, and show that our parser is competitive with the state of the art on the LDC2015E86 dataset and that it outperforms state-of-the-art parsers for recovering named entities and handling polarity."
J16-2002,Synchronous Context-Free Grammars and Optimal Parsing Strategies,2016,37,0,2,0,3945,daniel gildea,Computational Linguistics,0,"The complexity of parsing with synchronous context-free grammars is polynomial in the sentence length for a fixed grammar, but the degree of the polynomial depends on the grammar. Specifically, the degree depends on the length of rules, the permutations represented by the rules, and the parsing strategy adopted to decompose the recognition of a rule into smaller steps. We address the problem of finding the best parsing strategy for a rule, in terms of space and time complexity. We show that it is NP-hard to find the binary strategy with the lowest space complexity. We also show that any algorithm for finding the strategy with the lowest time complexity would imply improved approximation algorithms for finding the treewidth of general graphs."
J15-2002,Lexicalization and Generative Power in {CCG},2015,20,8,3,0.677447,12072,marco kuhlmann,Computational Linguistics,0,"The weak equivalence of Combinatory Categorial Grammar CCG and Tree-Adjoining Grammar TAG is a central result of the literature on mildly context-sensitive grammar formalisms. However, the categorial formalism for which this equivalence has been established differs significantly from the versions of CCG that are in use today. In particular, it allows restriction of combinatory rules on a per grammar basis, whereas modern CCG assumes a universal set of rules, isolating all cross-linguistic variation in the lexicon. In this article we investigate the formal significance of this difference. Our main result is that lexicalized versions of the classical CCG formalism are strictly less powerful than TAG."
Q14-1010,A Tabular Method for Dynamic Oracles in Transition-Based Parsing,2014,13,22,3,0,3457,yoav goldberg,Transactions of the Association for Computational Linguistics,0,"We develop parsing oracles for two transition-based dependency parsers, including the arc-standard parser, solving a problem that was left open in (Goldberg and Nivre, 2013). We experimentally show that using these oracles during training yields superior parsing accuracies on many languages."
Q14-1032,A New Parsing Algorithm for {C}ombinatory {C}ategorial {G}rammar,2014,21,5,2,0.767203,12072,marco kuhlmann,Transactions of the Association for Computational Linguistics,0,"We present a polynomial-time parsing algorithm for CCG, based on a new decomposition of derivations into small, shareable parts. Our algorithm has the same asymptotic complexity, O(n6), as a previous algorithm by Vijay-Shanker and Weir (1993), but is easier to understand, implement, and prove correct."
D14-1099,A Polynomial-Time Dynamic Oracle for Non-Projective Dependency Parsing,2014,17,15,3,0.701509,2685,carlos gomezrodriguez,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"The introduction of dynamic oracles has considerably improved the accuracy of greedy transition-based dependency parsers, without sacrificing parsing efficiency. However, this enhancement is limited to projective parsing, and dynamic oracles have not yet been implemented for parsers supporting non-projectivity. In this paper we introduce the first such oracle, for a non-projective parser based on Attardixe2x80x99s parser. We show that training with this oracle improves parsing accuracy over a conventional (static) oracle on a wide range of datasets."
Q13-1022,Efficient Parsing for Head-Split Dependency Trees,2013,15,6,1,1,24529,giorgio satta,Transactions of the Association for Computational Linguistics,0,"Head splitting techniques have been successfully exploited to improve the asymptotic runtime of parsing algorithms for projective dependency trees, under the arc-factored model. In this article we extend these techniques to a class of non-projective dependency trees, called well-nested dependency trees with block-degree at most 2, which has been previously investigated in the literature. We define a structural property that allows head splitting for these trees, and present two algorithms that improve over the runtime of existing algorithms at no significant loss in coverage."
P13-1014,A Transition-Based Dependency Parser Using a Dynamic Parsing Strategy,2013,21,21,2,0,39079,francesco sartorio,Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a novel transition-based, greedy dependency parser which implements a flexible mix of bottom-up and top-down strategies. The new strategy allows the parser to postpone difficult decisions until the relevant information becomes available. The novel parser has a 12% error reduction in unlabeled attachment score over an arc-eager parser, with a slow-down factor of 2.8."
N13-1052,Approximate {PCFG} Parsing Using Tensor Decomposition,2013,22,14,2,0.384615,3318,shay cohen,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We provide an approximation algorithm for PCFG parsing, which asymptotically improves time complexity with respect to the input grammar size, and prove upper bounds on the approximation quality. We test our algorithm on two treebanks, and get significant improvements in parsing speed."
P12-2058,Heuristic Cube Pruning in Linear Time,2012,12,1,2,0,40042,andrea gesmundo,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"We propose a novel heuristic algorithm for Cube Pruning running in linear time in the beam size. Empirically, we show a gain in running time of a standard machine translation system, at a small loss in accuracy."
J12-3006,{T}ree-{A}djoining {G}rammars Are Not Closed Under Strong Lexicalization,2012,6,4,2,1,12072,marco kuhlmann,Computational Linguistics,0,"A lexicalized tree-adjoining grammar is a tree-adjoining grammar where each elementary tree contains some overt lexical item. Such grammars are being used to give lexical accounts of syntactic phenomena, where an elementary tree defines the domain of locality of the syntactic and semantic dependencies of its lexical items. It has been claimed in the literature that for every tree-adjoining grammar, one can construct a strongly equivalent lexicalized version. We show that such a procedure does not exist: Tree-adjoining grammars are not closed under strong lexicalization."
W11-2919,Prefix Probabilities for Linear Context-Free Rewriting Systems,2011,33,1,2,0,5269,markjan nederhof,Proceedings of the 12th International Conference on Parsing Technologies,0,"We present a novel method for the computation of prefix probabilities for linear context-free rewriting systems. Our approach streamlines previous procedures to compute prefix probabilities for context-free grammars, synchronous context-free grammars and tree adjoining grammars. In addition, the methodology is general enough to be used for a wider range of problems involving, for example, several prefixes."
P11-1046,Optimal Head-Driven Parsing Complexity for Linear Context-Free Rewriting Systems,2011,25,6,5,0,44662,pierluigi crescenzi,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,We study the problem of finding the best head-driven parsing strategy for Linear Context-Free Rewriting System productions. A head-driven strategy must begin with a specified righthand-side nonterminal (the head) and add the remaining nonterminals one at a time in any order. We show that it is NP-hard to find the best head-driven strategy in terms of either the time or space complexity of parsing.
P11-1047,Prefix Probability for Probabilistic Synchronous Context-Free Grammars,2011,19,4,2,0,5269,markjan nederhof,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We present a method for the computation of prefix probabilities for synchronous context-free grammars. Our framework is fairly general and relies on the combination of a simple, novel grammar transformation and standard techniques to bring grammars into normal forms."
P11-1068,Dynamic Programming Algorithms for Transition-Based Dependency Parsers,2011,20,52,3,1,12072,marco kuhlmann,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We develop a general dynamic programming technique for the tabulation of transition-based dependency parsers, and apply it to obtain novel, polynomial-time algorithms for parsing with the arc-standard and arc-eager models. We also show how to reverse our technique to obtain new transition-based dependency parsers from existing tabular methods. Additionally, we provide a detailed discussion of the conditions under which the feature models commonly used in transition-based parsing can be integrated into our algorithms."
J11-4009,Splittability of Bilexical Context-Free Grammars is Undecidable,2011,10,0,2,0,5269,markjan nederhof,Computational Linguistics,0,"Bilexical context-free grammars (2-LCFGs) have proved to be accurate models for statistical natural language parsing. Existing dynamic programming algorithms used to parse sentences under these models have running time of O(xc3xa2xcbx86xc2xa3wxc3xa2xcbx86xc2xa34), where w is the input string.n n A 2-LCFG is splittable if the left arguments of a lexical head are always independent of the right arguments, and vice versa. When a 2-LCFGs is splittable, parsing time can be asymptotically improved to O(xc3xa2xcbx86xc2xa3wxc3xa2xcbx86xc2xa33). Testing this property is therefore of central interest to parsing efficiency. In this article, however, we show the negative result that splittability of 2-LCFGs is undecidable."
D11-1112,Computation of Infix Probabilities for Probabilistic Context-Free Grammars,2011,25,8,2,0,5269,markjan nederhof,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"The notion of infix probability has been introduced in the literature as a generalization of the notion of prefix (or initial substring) probability, motivated by applications in speech recognition and word error correction. For the case where a probabilistic context-free grammar is used as language model, methods for the computation of infix probabilities have been presented in the literature, based on various simplifying assumptions. Here we present a solution that applies to the problem in its full generality."
D11-1114,Exact Inference for Generative Probabilistic Non-Projective Dependency Parsing,2011,33,17,3,0.384615,3318,shay cohen,Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,0,"We describe a generative model for non-projective dependency parsing based on a simplified version of a transition system that has recently appeared in the literature. We then develop a dynamic programming parsing algorithm for our model, and derive an inside-outside algorithm that can be used for unsupervised learning of non-projective dependency trees."
W10-2503,Parsing and Translation Algorithms Based on Weighted Extended Tree Transducers,2010,20,3,2,0.740741,29499,andreas maletti,Proceedings of the 2010 Workshop on Applications of Tree Automata in Natural Language Processing,0,This paper proposes a uniform framework for the development of parsing and translation algorithms for weighted extended (top-down) tree transducers and input strings. The asymptotic time complexity of these algorithms can be improved in practice by exploiting an algorithm for rule factorization in the above transducers.
P10-1054,Optimal Rank Reduction for Linear Context-Free Rewriting Systems with Fan-Out Two,2010,13,9,2,0,250,benoit sagot,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,Linear Context-Free Rewriting Systems (LCFRSs) are a grammar formalism capable of modeling discontinuous phrases. Many parsing applications use LCFRSs where the fan-out (a measure of the discontinuity of phrases) does not exceed 2. We present an efficient algorithm for optimal reduction of the length of production right-hand side in LCFRSs with fan-out at most 2. This results in asymptotical running time improvement for known parsing algorithms for this class.
P10-1055,The Importance of Rule Restrictions in {CCG},2010,17,4,3,1,12072,marco kuhlmann,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,1,"Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and cross-linguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this 'pure' form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG."
N10-1035,Efficient Parsing of Well-Nested Linear Context-Free Rewriting Systems,2010,22,31,3,1,2685,carlos gomezrodriguez,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,The use of well-nested linear context-free rewriting systems has been empirically motivated for modeling of the syntax of languages with discontinuous constituents or relatively free word order. We present a chart-based parsing algorithm that asymptotically improves the known running time upper bound for this class of rewriting systems. Our result is obtained through a linear space construction of a binary normal form for the grammar at hand.
J10-3006,"Complexity, Parsing, and Factorization of Tree-Local Multi-Component {T}ree-{A}djoining {G}rammar",2010,35,3,2,0.833333,46380,rebecca nesson,Computational Linguistics,0,"Tree-Local Multi-Component Tree-Adjoining Grammar (TL-MCTAG) is an appealing formalism for natural language representation because it arguably allows the encapsulation of the appropriate domain of locality within its elementary structures. Its multicomponent structure allows modeling of lexical items that may ultimately have elements far apart in a sentence, such as quantifiers and wh-words. When used as the base formalism for a synchronous grammar, its flexibility allows it to express both the close relationships and the divergent structure necessary to capture the links between the syntax and semantics of a single language or the syntax of two different languages. Its limited expressivity provides constraints on movement and, we posit, may have generated additional popularity based on a misconception about its parsing complexity.n n Although TL-MCTAG was shown to be equivalent in expressivity to TAG when it was first introduced, the complexity of TL-MCTAG is still not well understood. This article offers a thorough examination of the problem of TL-MCTAG recognition, showing that even highly restricted forms of TL-MCTAG are NP-complete to recognize. However, in spite of the provable difficulty of the recognition problem, we offer several algorithms that can substantially improve processing efficiency. First, we present a parsing algorithm that improves on the baseline parsing method and runs in polynomial time when both the fan-out and rank of the input grammar are bounded. Second, we offer an optimal, efficient algorithm for factorizing a grammar to produce a strongly equivalent TL-MCTAG grammar with the rank of the grammar minimized."
W09-3801,Parsing Algorithms based on Tree Automata,2009,29,12,2,0.740741,29499,andreas maletti,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"We investigate several algorithms related to the parsing problem for weighted automata, under the assumption that the input is a string rather than a tree. This assumption is motivated by several natural language processing applications. We provide algorithms for the computation of parse-forests, best tree probability, inside probability (called partition function), and prefix probability. Our algorithms are obtained by extending to weighted tree automata the Bar-Hillel technique, as defined for context-free grammars."
W09-3810,Synchronous Rewriting in Treebanks,2009,11,4,3,0,5576,laura kallmeyer,Proceedings of the 11th International Conference on Parsing Technologies ({IWPT}{'}09),0,"Several formalisms have been proposed for modeling trees with discontinuous phrases. Some of these formalisms allow for synchronous rewriting. However, it is unclear whether synchronous rewriting is a necessary feature. This is an important question, since synchronous rewriting greatly increases parsing complexity. We present a characterization of recursive synchronous rewriting in constituent tree-banks with discontinuous annotation. An empirical investigation reveals that synchronous rewriting is actually a necessary feature. Furthermore, we transfer this property to grammars extracted from tree-banks."
P09-1111,An Optimal-Time Binarization Algorithm for Linear Context-Free Rewriting Systems with Fan-Out Two,2009,13,11,2,1,2685,carlos gomezrodriguez,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"Linear context-free rewriting systems (LCFRSs) are grammar formalisms with the capability of modeling discontinuous constituents. Many applications use LCFRSs where the fan-out (a measure of the discontinuity of phrases) is not allowed to be greater than 2. We present an efficient algorithm for transforming LCFRS with fan-out at most 2 into a binary form, whenever this is possible. This results in asymptotical run-time improvement for known parsing algorithms for this class."
P09-1112,A Polynomial-Time Parsing Algorithm for {TT}-{MCTAG},2009,15,8,2,0,5576,laura kallmeyer,Proceedings of the Joint Conference of the 47th Annual Meeting of the {ACL} and the 4th International Joint Conference on Natural Language Processing of the {AFNLP},1,"This paper investigates the class of Tree-Tuple MCTAG with Shared Nodes, TT-MCTAG for short, an extension of Tree Adjoining Grammars that has been proposed for natural language processing, in particular for dealing with discontinuities and word order variation in languages such as German. It has been shown that the universal recognition problem for this formalism is NP-hard, but so far it was not known whether the class of languages generated by TT-MCTAG is included in PTIME. We provide a positive answer to this question, using a new characterization of TT-MCTAG."
N09-1061,Optimal Reduction of Rule Length in Linear Context-Free Rewriting Systems,2009,17,28,3,1,2685,carlos gomezrodriguez,Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Linear Context-free Rewriting Systems (LCFRS) is an expressive grammar formalism with applications in syntax-based machine translation. The parsing complexity of an LCFRS is exponential in both the rank of a production, defined as the number of nonterminals on its right-hand side, and a measure for the discontinuity of a phrase, called fan-out. In this paper, we present an algorithm that transforms an LCFRS into a strongly equivalent form in which all productions have rank at most 2, and has minimal fan-out. Our results generalize previous work on Synchronous Context-Free Grammar, and are particularly relevant for machine translation from or to languages that require syntactic analyses with discontinuous constituents."
E09-1055,Treebank Grammar Techniques for Non-Projective Dependency Parsing,2009,20,43,2,1,12072,marco kuhlmann,Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009),0,"An open problem in dependency parsing is the accurate and efficient treatment of non-projective structures. We propose to attack this problem using chart-parsing algorithms developed for mildly context-sensitive grammar formalisms. In this paper, we provide two key tools for this approach. First, we show how to reduce non-projective dependency parsing to parsing with Linear Context-Free Rewriting Systems (LCFRS), by presenting a technique for extracting LCFRS from dependency treebanks. For efficient parsing, the extracted grammars need to be transformed in order to minimize the number of nonterminal symbols per production. Our second contribution is an algorithm that computes this transformation for a large, empirically relevant class of grammars."
P08-1069,Optimal $k$-arization of Synchronous {T}ree-{A}djoining {G}rammar,2008,16,10,2,0.833333,46380,rebecca nesson,Proceedings of ACL-08: HLT,1,"Synchronous Tree-Adjoining Grammar (STAG) is a promising formalism for syntaxaware machine translation and simultaneous computation of natural-language syntax and semantics. Current research in both of these areas is actively pursuing its incorporation. However, STAG parsing is known to be NP-hard due to the potential for intertwined correspondences between the linked nonterminal symbols in the elementary structures. Given a particular grammar, the polynomial degree of efficient STAG parsing algorithms depends directly on the rank of the grammar: the maximum number of correspondences that appear within a single elementary structure. In this paper we present a compile-time algorithm for transforming a STAG into a strongly-equivalent STAG that optimally minimizes the rank, k, across the grammar. The algorithm performs inO(|G| |Y|xc2xb7L 3 ) time where LG is the maximum number of links in any single synchronous tree pair in the grammar and Y is the set of synchronous tree pairs ofG."
bosco-etal-2008-comparing,Comparing {I}talian parsers on a common Treebank: the {EVALITA} experience,2008,27,14,8,0,17906,cristina bosco,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"The EVALITA 2007 Parsing Task has been the first contest among parsing systems for Italian. It is the first attempt to compare the approaches and the results of the existing parsing systems specific for this language using a common treebank annotated using both a dependency and a constituency-based format. The development data set for this parsing competition was taken from the Turin University Treebank, which is annotated both in dependency and constituency format. The evaluation metrics were those standardly applied in CoNLL and PARSEVAL. The results of the parsing results are very promising and higher than the state-of-the-art for dependency parsing of Italian. An analysis of such results is provided, which takes into account other experiences in treebank-driven parsing for Italian and for other Romance languages (in particular, the CoNLL X {\&} 2007 shared tasks for dependency parsing). It focuses on the characteristics of data sets, i.e. type of annotation and size, parsing paradigms and approaches applied also to languages other than Italian."
W07-2216,On the Complexity of Non-Projective Data-Driven Dependency Parsing,2007,36,83,2,0,10634,ryan mcdonald,Proceedings of the Tenth International Conference on Parsing Technologies,0,"In this paper we investigate several non-projective parsing algorithms for dependency parsing, providing novel polynomial time solutions under the assumption that each dependency decision is independent of all the others, called here the edge-factored model. We also investigate algorithms for non-projective parsing that account for nonlocal information, and present several hardness results. This suggests that it is unlikely that exact non-projective dependency parsing is tractable for any model richer than the edge-factored model."
P07-1096,Guided Learning for Bidirectional Sequence Classification,2007,15,136,2,0,6930,libin shen,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"In this paper, we propose guided learning, a new learning framework for bidirectional sequence classification. The tasks of learning the order of inference and training the local classifier are dynamically incorporated into a single Perceptron like learning algorithm. We apply this novel learning algorithm to POS tagging. It obtains an error rate of 2.67% on the standard PTB test set, which represents 3.3% relative error reduction over the previous best result on the same data set, while using fewer features."
P06-2036,Factoring Synchronous Grammars by Sorting,2006,9,13,2,0,3945,daniel gildea,Proceedings of the {COLING}/{ACL} 2006 Main Conference Poster Sessions,0,"Synchronous Context-Free Grammars (SCFGs) have been successfully exploited as translation models in machine translation applications. When parsing with an SCFG, computational complexity grows exponentially with the length of the rules, in the worst case. In this paper we examine the problem of factorizing each rule of an input SCFG to a generatively equivalent set of rules, each having the smallest possible length. Our algorithm works in time O(n log n), for each rule of length n. This improves upon previous results and solves an open problem about recognizing permutations that can be factored."
N06-1043,Cross-Entropy and Estimation of Probabilistic Context-Free Grammars,2006,-1,-1,2,1,43089,anna corazza,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,None
N06-1044,Estimation of Consistent Probabilistic Context-free Grammars,2006,14,12,2,0,5269,markjan nederhof,"Proceedings of the Human Language Technology Conference of the {NAACL}, Main Conference",0,"We consider several empirical estimators for probabilistic context-free grammars, and show that the estimated grammars have the so-called consistency property, under the most general conditions. Our estimators include the widely applied expectation maximization method, used to estimate probabilistic context-free grammars on the basis of unannotated corpora. This solves a problem left open in the literature, since for this method the consistency property has been shown only under restrictive assumptions on the rules of the source grammar."
H05-1101,Some Computational Complexity Results for Synchronous Context-Free Grammars,2005,23,50,1,1,24529,giorgio satta,Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,0,"This paper investigates some computational problems associated with probabilistic translation models that have recently been adopted in the literature on machine translation. These models can be viewed as pairs of probabilistic context-free grammars working in a 'synchronous' way. Two hardness results for the class NP are reported, along with an exponential time lower-bound for certain classes of algorithms that are currently used in the literature."
P04-1069,Probabilistic Parsing Strategies,2004,26,5,2,0.51649,5269,markjan nederhof,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,We present new results on the relation between context-free parsing strategies and their probabilistic counter-parts. We provide a necessary condition and a sufficient condition for the probabilistic extension of parsing strategies. These results generalize existing results in the literature that were obtained by considering parsing strategies in isolation.
P04-1070,An Alternative Method of Training Probabilistic {LR} Parsers,2004,26,3,2,0.51649,5269,markjan nederhof,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"We discuss existing approaches to train LR parsers, which have been used for statistical resolution of structural ambiguity. These approaches are nonoptimal, in the sense that a collection of probability distributions cannot be obtained. In particular, some probability distributions expressible in terms of a context-free grammar cannot be expressed in terms of the LR parser constructed from that grammar, under the restrictions of the existing approaches to training of LR parsers. We present an alternative way of training that is provably optimal, and that allows all probability distributions expressible in the context-free grammar to be carried over to the LR parser. We also demonstrate empirically that this kind of training can be effectively applied on a large treebank."
P04-1084,Generalized Multitext Grammars,2004,16,55,2,0,47407,dan melamed,Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics ({ACL}-04),1,"Generalized Multitext Grammar (GMTG) is a synchronous grammar formalism that is weakly equivalent to Linear Context-Free Rewriting Systems (LCFRS), but retains much of the notational and intuitive simplicity of Context-Free Grammar (CFG). GMTG allows both synchronous and independent rewriting. Such flexibility facilitates more perspicuous modeling of parallel text than what is possible with other synchronous formalisms. This paper investigates the generative capacity of GMTG, proves that each component grammar of a GMTG retains its generative power, and proposes a generalization of Chomsky Normal Form, which is necessary for synchronous CKY-style parsing."
C04-1011,{K}ullback-{L}eibler Distance between Probabilistic Context-Free Grammars and Probabilistic Finite Automata,2004,18,10,2,0.51649,5269,markjan nederhof,{COLING} 2004: Proceedings of the 20th International Conference on Computational Linguistics,0,"We consider the problem of computing the Kullback-Leibler distance, also called the relative entropy, between a probabilistic context-free grammar and a probabilistic finite automaton. We show that there is a closed-form (analytical) solution for one part of the Kullback-Leibler distance, viz. the cross-entropy. We discuss several applications of the result to the problem of distributional approximation of probabilistic context-free grammars by means of probabilistic finite automata."
W03-3016,Probabilistic Parsing as Intersection,2003,0,38,2,0.54737,5269,markjan nederhof,Proceedings of the Eighth International Conference on Parsing Technologies,0,"We show that a well-known algorithm to compute the intersection of a context-fre language and a regular language can be extended to apply to a probabilistic context-free grammar and a probabilistic finite automaton, provided the two probabilistic models are combined through multiplication. The result is a probabilistic context-free grammar that contains joint information about the original grammar and automaton."
W03-3020,Partially Ordered Multiset Context-free Grammars and Free-word-order Parsing,2003,10,5,2,0.54737,5269,markjan nederhof,Proceedings of the Eighth International Conference on Parsing Technologies,0,"We present a new formalism, partially ordered multiset context-free grammars (poms-CFG), along with an Earley-style parsing algorithm. The formalism, which can be thought of as a generalization of context-free grammars with partially ordered right-hand sides, is of interest in its own right, and also as infrastructure for obtaining tighter complexity bounds for more expressive context-free formalisms intended to express free or multiple word-order, such as ID/LP grammars. We reduce ID/LP grammars to poms-grammars, thereby getting finer-grained bounds on the parsing complexity of ID/LP grammars. We argue that in practice, the width of attested ID/LP grammars is small, yielding effectively polynomial time complexity for ID/LP grammar parsing."
P02-1015,Parsing non-recursive {CFG}s,2002,5,13,2,0.588876,5269,markjan nederhof,Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,1,"We consider the problem of parsing non-recursive context-free grammars, i.e., context-free grammars that generate finite languages. In natural language processing, this problem arises in several areas of application, including natural language generation, speech recognition and machine translation. We present two tabular algorithms for parsing of non-recursive context-free grammars, and show that they perform well in practical settings, despite the fact that this problem is PSPACE-complete."
W00-2011,A faster parsing algorithm for {L}exicalized {T}ree-{A}djoining {G}rammars,2000,20,12,2,0.666667,4433,jason eisner,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,"This paper points out some computational inefficiencies of standard TAG parsing algorithms when applied to LTAGs. We propose a novel algorithm with an asymptotic improvement, from to , where is the input length and are grammar constants that are independent of vocabulary size."
A00-2036,Left-To-Right Parsing and Bilexical Context-Free Grammars,2000,27,4,2,0.654762,5269,markjan nederhof,1st Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"We compare the asymptotic time complexity of left-to-right and bidirectional parsing techniques for bilexical context-free grammars, a grammar formalism that is an abstraction of language models used in several state-of-the-art real-world parsers. We provide evidence that left-to-right parsing cannot be realised within acceptable time-bounds if the so called correct-prefix property is to be ensured. Our evidence is based on complexity results for the representation of regular languages."
2000.iwpt-1.4,Parsing Techniques for Lexicalized Context-Free Grammars,2000,-1,-1,1,1,24529,giorgio satta,Proceedings of the Sixth International Workshop on Parsing Technologies,0,
P99-1059,Efficient Parsing for Bilexical Context-Free Grammars and Head Automaton Grammars,1999,21,129,2,0.666667,4433,jason eisner,Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,1,"Several recent stochastic parsers use bilexical grammars, where each word type idiosyncratically prefers particular complements with particular head words. We present O(n4) parsing algorithms for two bilexical formalisms, improving the prior upper bounds of O(n5). For a common special case that was known to allow O(n3) parsing (Eisner, 1997), we present an O(n3) algorithm with an improved grammar constant."
W98-0130,Prefix probabilities for linear indexed grammars,1998,2,0,3,0.757576,5269,markjan nederhof,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
P98-2157,Prefix Probabilities from Stochastic Free Adjoining Grammars,1998,9,5,3,0.757576,5269,markjan nederhof,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"Language models for speech recognition typically use a probability model of the form Pr(an/a1, a2, .... an-1 Stochastic grammars, on the other hand, are typically used to assign structure to utterances. A language model of the above form is constructed from such grammars by computing the prefix probability xe2x88x91wexcfx83* Pr(a1 ...anw), where w represents all possible terminations of the prefix a1 ... an. The main result in this paper is an algorithm to compute such prefix probabilities given a stochastic Tree Adjoining Grammar (TAG). The algorithm achieves the required computation in O(n 6) time. The probability of sub-derivations that do not derive any words in the prefix, but contribute structurally to its derivation, are precomputed to achieve termination. This algorithm enables existing corpus-based estimation techniques for stochastic TAGs to be used for language modelling."
P98-2192,Restrictions on Tree Adjoining Languages,1998,11,9,1,1,24529,giorgio satta,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 2",0,"Several methods are known for parsing languages generated by Tree Adjoining Grammars (TAGs) in O(n6) worst case running time. In this paper we investigate which restrictions on TAGs and TAG derivations are needed in order to lower this O(n6) time complexity, without introducing large runtime constants, and without losing any of the generative power needed to capture the syntactic constructions in natural language that can be handled by unrestricted TAGs. In particular, we describe an algorithm for parsing a strict subcalss of TAG in O(n5), and attempt to show that this subclass retains enough generative power to make it useful in the general case."
J98-2006,{O}ptimality {T}heory and the Generative Complexity of Constraint Violability,1998,16,97,2,0,2215,robert frank,Computational Linguistics,0,"It has been argued that rule-based phonological descriptions can uniformaly be expressed as mappings carried out by finite-state transducers, and therefore fall within the class of rational relations. If this property of generative capacity is an empirically correct characterization of phonological mappings, it should hold of any sufficiently restrictive theory of phonology, whether it utilizes constraints or rewrite rules. In this paper, we investigate the conditions under which the phonological descriptions that are possible within the view of constraint interaction embodied in Optimality Theory (Prince and Smolensky 1993) remain within the class of rational relations. We show that this is true when GEN is itself a rational relation, and each of the constraints distinguishes among finitely many regular sets of candidates."
J98-1007,Book Reviews: Parsing with Principles and Classes of Information,1998,-1,-1,1,1,24529,giorgio satta,Computational Linguistics,0,None
C98-2152,Prefix Probabilities from Stochastic {T}ree {A}djoining {G}rammars,1998,8,2,3,0.757576,5269,markjan nederhof,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"Language models for speech recognition typically use a probability model of the form Pr(a_n | a_1, a_2, ..., a_{n-1}). Stochastic grammars, on the other hand, are typically used to assign structure to utterances. A language model of the above form is constructed from such grammars by computing the prefix probability Sum_{w in Sigma*} Pr(a_1 ... a_n w), where w represents all possible terminations of the prefix a_1 ... a_n. The main result in this paper is an algorithm to compute such prefix probabilities given a stochastic Tree Adjoining Grammar (TAG). The algorithm achieves the required computation in O(n^6) time. The probability of subderivations that do not derive any words in the prefix, but contribute structurally to its derivation, are precomputed to achieve termination. This algorithm enables existing corpus-based estimation techniques for stochastic TAGs to be used for language modelling."
C98-2187,Restrictions on Tree Adjoining Languages,1998,11,9,1,1,24529,giorgio satta,{COLING} 1998 Volume 2: The 17th International Conference on Computational Linguistics,0,"Several methods are known for parsing languages generated by Tree Adjoining Grammars (TAGs) in O(n6) worst case running time. In this paper we investigate which restrictions on TAGs and TAG derivations are needed in order to lower this O(n6) time complexity, without introducing large runtime constants, and without losing any of the generative power needed to capture the syntactic constructions in natural language that can be handled by unrestricted TAGs. In particular, we describe an algorithm for parsing a strict subcalss of TAG in O(n5), and attempt to show that this subclass retains enough generative power to make it useful in the general case."
P97-1057,String Transformation Learning,1997,8,10,1,1,24529,giorgio satta,35th Annual Meeting of the Association for Computational Linguistics and 8th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,1,"String transformation systems have been introduced in (Brill, 1995) and have several applications in natural language processing. In this work we consider the computational problem of automatically learning from a given corpus the set of transformations presenting the best evidence. We introduce an original data structure and efficient algorithms that learn some families of transformations that are relevant for part-of-speech tagging and phonological rule systems. We also show that the same learning problem becomes NP-hard in cases of an unbounded use of don't care symbols in a transformation."
P96-1016,Synchronous Models of Language,1996,18,16,2,0,1354,owen rambow,34th Annual Meeting of the Association for Computational Linguistics,1,"In synchronous rewriting, the productions of two rewriting systems are paired and applied synchronously in the derivation of a pair of strings. We present a new synchronous rewriting system and argue that it can handle certain phenomena that are not covered by existing synchronous systems. We also prove some interesting formal/computational properties of our system."
P96-1032,Efficient Tabular {LR} Parsing,1996,19,10,2,1,5269,markjan nederhof,34th Annual Meeting of the Association for Computational Linguistics,1,"We give a new treatment of tabular LR parsing, which is an alternative to Tomita's generalized LR algorithm. The advantage is twofold. Firstly, our treatment is conceptually more attractive because it uses simpler concepts, such as grammar transformations and standard tabulation techniques also know as chart parsing. Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced."
P94-1029,An Extended Theory of Head-Driven Parsing,1994,13,8,2,1,5269,markjan nederhof,32nd Annual Meeting of the Association for Computational Linguistics,1,"We show that more head-driven parsing algorithms can be formulated than those occurring in the existing literature. These algorithms are inspired by a family of left-to-right parsing algorithms from a recent publication. We further introduce a more advanced notion of head-driven parsing which allows more detailed specification of the processing order of non-head elements in the right-hand side. We develop a parsing algorithm for this strategy, based on LR parsing techniques."
J94-2002,{T}ree-{A}djoining {G}rammar Parsing and {B}oolean Matrix Multiplication,1994,14,34,1,1,24529,giorgio satta,Computational Linguistics,0,"The computational problem of parsing a sentence in a tree-adjoining language is investigated. An interesting relation is studied between this problem and the well-known computational problem of Boolean matrix multiplication: it is shown that any algorithm for the solution of the former problem can easily be converted into an algorithm for the solution of the latter problem. This result bears on at least two important computational issues. First, we realize that a straightforward method that improves the known upper bound for tree-adjoining grammar parsing is hard to find. Second, we understand which features of the tree-adjoining grammar parsing problem are responsible for the claimed difficulty."
P92-1012,Recognition of Linear Context-Free Rewriting Systems,1992,9,33,1,1,24529,giorgio satta,30th Annual Meeting of the Association for Computational Linguistics,1,"The class of linear context-free rewriting systems has been introduced as a generalization of a class of grammar formalisms known as mildly context-sensitive. The recognition problem for linear context-free rewriting languages is studied at length here, presenting evidence that, even in some restricted cases, it cannot be solved efficiently. This entails the existence of a gap between, for example, tree adjoining languages and the subclass of linear context-free rewriting languages that generalizes the former class; such a gap is attributed to crossing configurations. A few other interesting consequences of the main result are discussed, that concern the recognition problem for linear context-free rewriting languages."
J92-3011,Book Reviews: Generalized {LR} Parsing,1992,-1,-1,1,1,24529,giorgio satta,Computational Linguistics,0,None
E91-1006,Bidirectional Parsing of {L}exicalized {T}ree {A}djoining {G}rammars,1991,10,17,2,0,14633,alberto lavelli,Fifth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper a bidirectional parser for Lexicalized Tree Adjoining Grammars will be presented. The algorithm takes advantage of a peculiar characteristic of Lexicalized TAGs, i.e. that each elementary tree is associated with a lexical item, called its anchor. The algorithm employs a mixed strategy: it works bottom-up from the lexical anchors and then expands (partial) analyses making top-down predictions. Even if such an algorithm does not improve the worst-case time bounds of already known TAGs parsing methods, it could be relevant from the perspective of linguistic information processing, because it employs lexical information in a more direct way."
1991.iwpt-1.24,Stochastic Context-Free Grammars for Island-Driven Probabilistic Parsing,1991,-1,-1,4,1,43089,anna corazza,Proceedings of the Second International Workshop on Parsing Technologies,0,In automatic speech recognition the use of language models improves performance. Stochastic language models fit rather well the uncertainty created by the acoustic pattern matching. These models are used to score \textit{theories} corresponding to partial interpretations of sentences. Algorithms have been developed to compute probabilities for theories that grow in a strictly left-to-right fashion. In this paper we consider new relations to compute probabilities of partial interpretations of sentences. We introduce theories containing a gap corresponding to an uninterpreted signal segment. Algorithms can be easily obtained from these relations. Computational complexity of these algorithms is also derived.
C90-3022,A Computational Approach to Binding Theory,1990,6,7,3,0,57582,alessandra giorgi,{COLING} 1990 Volume 3: Papers presented to the 13th International Conference on Computational Linguistics,0,"This paper is a first step towards a computational account of Binding Theory (BT). Two algorithms that compute, respectively, Principle A and B have been provided. Particular attention has been devoted to possible interactions of BT with other modules of the linguistic theory, such as those ruling argumental chains. Finally, the computational complexity of the algorithms has been studied."
W89-0205,Head-Driven Bidirectional Parsing: A Tabular Method,1989,0,20,1,1,24529,giorgio satta,Proceedings of the First International Workshop on Parsing Technologies,0,
