2020.lrec-1.388,Modelling Etymology in {LMF}/{TEI}: The Grande Dicion{\\'a}rio Houaiss da L{\\'\\i}ngua Portuguesa Dictionary as a Use Case,2020,-1,-1,2,0,17440,fahad khan,Proceedings of the 12th Language Resources and Evaluation Conference,0,"In this article we will introduce two of the new parts of the new multi-part version of the Lexical Markup Framework (LMF) ISO standard, namely part 3 of the standard (ISO 24613-3), which deals with etymological and diachronic data, and Part 4 (ISO 24613-4), which consists of a TEI serialisation of all of the prior parts of the model. We will demonstrate the use of both standards by describing the LMF encoding of a small number of examples taken from a sample conversion of the reference Portuguese dictionary \textit{Grande Dicion{\'a}rio Houaiss da L{\'\i}ngua Portuguesa}, part of a broader experiment comprising the analysis of different, heterogeneously encoded, Portuguese lexical resources. We present the examples in the Unified Modelling Language (UML) and also in a couple of cases in TEI."
2020.lrec-1.569,Establishing a New State-of-the-Art for {F}rench Named Entity Recognition,2020,-1,-1,4,0,17806,pedro suarez,Proceedings of the 12th Language Resources and Evaluation Conference,0,"The French TreeBank developed at the University Paris 7 is the main source of morphosyntactic and syntactic annotations for French. However, it does not include explicit information related to named entities, which are among the most useful information for several natural language processing tasks and applications. Moreover, no large-scale French corpus with named entity annotations contain referential information, which complement the type and the span of each mention with an indication of the entity it refers to. We have manually annotated the French TreeBank with such information, after an automatic pre-annotation step. We sketch the underlying annotation guidelines and we provide a few figures about the resulting annotations."
2020.jeptalnrecital-taln.5,Les mod{\\`e}les de langue contextuels Camembert pour le fran{\\c{c}}ais : impact de la taille et de l{'}h{\\'e}t{\\'e}rog{\\'e}n{\\'e}it{\\'e} des donn{\\'e}es d{'}entrainement ({C} {AMEM} {BERT} Contextual Language Models for {F}rench: Impact of Training Data Size and Heterogeneity ),2020,-1,-1,5,0,17824,louis martin,"Actes de la 6e conf{\\'e}rence conjointe Journ{\\'e}es d'{\\'E}tudes sur la Parole (JEP, 33e {\\'e}dition), Traitement Automatique des Langues Naturelles (TALN, 27e {\\'e}dition), Rencontre des {\\'E}tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R{\\'E}CITAL, 22e {\\'e}dition). Volume 2 : Traitement Automatique des Langues Naturelles",0,"Les mod{\`e}les de langue neuronaux contextuels sont d{\'e}sormais omnipr{\'e}sents en traitement automatique des langues. Jusqu{'}{\`a} r{\'e}cemment, la plupart des mod{\`e}les disponibles ont {\'e}t{\'e} entra{\^\i}n{\'e}s soit sur des donn{\'e}es en anglais, soit sur la concat{\'e}nation de donn{\'e}es dans plusieurs langues. L{'}utilisation pratique de ces mod{\`e}les {---} dans toutes les langues sauf l{'}anglais {---} {\'e}tait donc limit{\'e}e. La sortie r{\'e}cente de plusieurs mod{\`e}les monolingues fond{\'e}s sur BERT (Devlin et al., 2019), notamment pour le fran{\c{c}}ais, a d{\'e}montr{\'e} l{'}int{\'e}r{\^e}t de ces mod{\`e}les en am{\'e}liorant l{'}{\'e}tat de l{'}art pour toutes les t{\^a}ches {\'e}valu{\'e}es. Dans cet article, {\`a} partir d{'}exp{\'e}riences men{\'e}es sur CamemBERT (Martin et al., 2019), nous montrons que l{'}utilisation de donn{\'e}es {\`a} haute variabilit{\'e} est pr{\'e}f{\'e}rable {\`a} des donn{\'e}es plus uniformes. De fa{\c{c}}on plus surprenante, nous montrons que l{'}utilisation d{'}un ensemble relativement petit de donn{\'e}es issues du web (4Go) donne des r{\'e}sultats aussi bons que ceux obtenus {\`a} partir d{'}ensembles de donn{\'e}es plus grands de deux ordres de grandeurs (138Go)."
2020.acl-main.156,A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages,2020,-1,-1,2,0,17806,pedro suarez,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCAR-based and Wikipedia-based ELMo embeddings for these languages on the part-of-speech tagging and parsing tasks. We show that, despite the noise in the Common-Crawl-based OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the cross-lingual benefit of multilingual embedding architectures."
2020.acl-main.645,{C}amem{BERT}: a Tasty {F}rench Language Model,2020,-1,-1,5,0,17824,louis martin,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models {--}in all languages except English{--} very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks."
W17-7006,{TBX} in {ODD}: Schema-agnostic specification and documentation for {T}erm{B}ase e{X}change,2017,-1,-1,2,0,31294,stefan pernes,"Proceedings of Language, Ontology, Terminology and Knowledge Structures Workshop ({LOTKS} 2017)",0,None
L16-1304,{T}erm{ITH}-Eval: a {F}rench Standard-Based Resource for Keyphrase Extraction Evaluation,2016,9,1,3,0,35031,adrien bougouin,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Keyphrase extraction is the task of finding phrases that represent the important content of a document. The main aim of keyphrase extraction is to propose textual units that represent the most important topics developed in a document. The output keyphrases of automatic keyphrase extraction methods for test documents are typically evaluated by comparing them to manually assigned reference keyphrases. Each output keyphrase is considered correct if it matches one of the reference keyphrases. However, the choice of the appropriate textual unit (keyphrase) for a topic is sometimes subjective and evaluating by exact matching underestimates the performance. This paper presents a dataset of evaluation scores assigned to automatically extracted keyphrases by human evaluators. Along with the reference keyphrases, the manual evaluations can be used to validate new evaluation measures. Indeed, an evaluation measure that is highly correlated to the manual evaluation is appropriate for the evaluation of automatic keyphrase extraction methods."
R15-1003,Automatic Construction of a {TMF} Terminological Database using a Transducer Cascade,2015,12,1,3,0,37333,chihebeddine ammar,Proceedings of the International Conference Recent Advances in Natural Language Processing,0,"The automatic development of terminological databases, especially in a standardized format, has a crucial aspect for multiple applications related to technical and scientific knowledge that requires semantic and terminological descriptions covering multiple domains. In this context, we have, in this paper, two challenges: the first is the automatic extraction of terms in order to build a terminological database, and the second challenge is their normalization into a standardized format. To deal with these challenges, we propose an approach based on a cascade of transducers performed using CasSys tool of the Unitex linguistic platform that benefits from both: the success of the rule-based approach for the extraction of terms, and the performance of the TMF standard for the representation of terms. We have tested and evaluated our approach on an Arabic scientific and technical corpus for the Elevator domain and the results are very encouraging."
J14-1008,Book Review: Natural Language Processing for Historical Texts by {M}ichael Piotrowski,2014,-1,-1,1,1,17441,laurent romary,Computational Linguistics,0,None
E12-2003,Collaborative Machine Translation Service for Scientific texts,2012,5,4,3,0,23604,patrik lambert,Proceedings of the Demonstrations at the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"French researchers are required to frequently translate into French the description of their work published in English. At the same time, the need for French people to access articles in English, or to international researchers to access theses or papers in French, is incorrectly resolved via the use of generic translation tools. We propose the demonstration of an end-to-end tool integrated in the HAL open archive for enabling efficient translation for scientific texts. This tool can give translation suggestions adapted to the scientific domain, improving by more than 10 points the BLEU score of a generic system. It also provides a post-edition service which captures user post-editing data that can be used to incrementally improve the translations engines. Thus it is helpful for users which need to translate or to access scientific texts."
S10-1055,{HUMB}: Automatic Key Term Extraction from Scientific Articles in {GROBID},2010,10,13,2,0,43561,patrice lopez,Proceedings of the 5th International Workshop on Semantic Evaluation,0,"The Semeval task 5 was an opportunity for experimenting with the key term extraction module of GROBID, a system for extracting and generating bibliographical information from technical and scientific documents. The tool first uses GROBID's facilities for analyzing the structure of scientific articles, resulting in a first set of structural features. A second set of features captures content properties based on phraseness, informativeness and keywordness measures. Two knowledge bases, GRISP and Wikipedia, are then exploited for producing a last set of lexical/semantic features. Bagged decision trees appeared to be the most efficient machine learning algorithm for generating a list of ranked key term candidates. Finally a post ranking was realized based on statistics of cousage of keywords in HAL, a large Open Access publication repository."
pustejovsky-etal-2010-iso,{ISO}-{T}ime{ML}: An International Standard for Semantic Annotation,2010,8,113,4,0,993,james pustejovsky,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"In this paper, we present ISO-TimeML, a revised and interoperable version of the temporal markup language, TimeML. We describe the changes and enrichments made, while framing the effort in a more general methodology of semantic annotation. In particular, we assume a principled distinction between the annotation of an expression and the representation which that annotation denotes. This involves not only the specification of an annotation language for a particular phenomenon, but also the development of a meta-model that allows one to interpret the syntactic expressions of the specification semantically."
cruz-lara-etal-2010-mlif,{MLIF} : A Metamodel to Represent and Exchange Multilingual Textual Information,2010,2,4,3,0,39029,samuel cruzlara,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The fast evolution of language technology has produced pressing needs in standardization. The multiplicity of language resources representation levels and the specialization of these representations make difficult the interaction between linguistic resources and components manipulating these resources. In this paper, we describe the MultiLingual Information Framework (MLIF â ISO CD 24616). MLIF is a metamodel which allows the representation and the exchange of multilingual textual information. This generic metamodel is designed to provide a common platform for all the tools developed around the existing multilingual data exchange formats. This platform provides, on the one hand, a set of generic data categories for various application domains, and on the other hand, strategies for the interoperability with existing standards. The objective is to reach a better convergence between heterogeneous standardisation activities that are taking place in the domain of data modeling (XML; W3C), text management (TEI; TEIC), multilingual information (TMX-LISA; XLIFF-OASIS) and multimedia (SMILText; W3C). This is a work in progress within ISO-TC37 in order to define a new ISO standard."
bunt-etal-2010-towards,Towards an {ISO} Standard for Dialogue Act Annotation,2010,22,96,10,0.167249,16745,harry bunt,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"This paper describes an ISO project which aims at developing a standard for annotating spoken and multimodal dialogue with semantic information concerning the communicative functions of utterances, the kind of semantic content they address, and their relations with what was said and done earlier in the dialogue. The project, ISO 24617-2 ''``Semantic annotation framework, Part 2: Dialogue acts'''', is currently at DIS stage. The proposed annotation schema distinguishes 9 orthogonal dimensions, allowing each functional segment in dialogue to have a function in each of these dimensions, thus accounting for the multifunctionality that utterances in dialogue often have. A number of core communicative functions is defined in the form of ISO data categories, available at http://semantic-annotation.uvt.nl/dialogue-acts/iso-datcats.pdf; they are divided into ''``dimension-specific'''' functions, which can be used only in a particular dimension, such as Turn Accept in the Turn Management dimension, and ''``general-purpose'''' functions, which can be used in any dimension, such as Inform and Request. An XML-based annotation language, ''``DiAML'''' is defined, with an abstract syntax, a semantics, and a concrete syntax."
lopez-romary-2010-grisp,{GRISP}: A Massive Multilingual Terminological Database for Scientific and Technical Domains,2010,20,10,2,0,43561,patrice lopez,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"The development of a multilingual terminology is a very long and costly process. We present the creation of a multilingual terminological database called GRISP covering multiple technical and scientific fields from various open resources. A crucial aspect is the merging of the different resources which is based in our proposal on the definition of a sound conceptual model, different domain mapping and the use of structural constraints and machine learning techniques for controlling the fusion process. The result is a massive terminological database of several millions terms, concepts, semantic relations and definitions. The accuracy of the concept merging between several resources have been evaluated following several methods. This resource has allowed us to improve significantly the mean average precision of an information retrieval system applied to a large collection of multilingual and multidomain patent documents. New specialized terminologies, not specifically created for text processing applications, can be aggregated and merged to GRISP with minimal manual efforts."
broeder-etal-2008-foundation,Foundation of a Component-based Flexible Registry for Language Resources and Technology,2008,0,7,5,0.566224,18402,daan broeder,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"Within the CLARIN e-science infrastructure project it is foreseen to develop a component-based registry for metadata for Language Resources and Language Technology. With this registry it is hoped to overcome the problems of the current available systems with respect to inflexible fixed schema, unsuitable terminology and interoperability problems. The registry will address interoperability needs by refering to a shared vocabulary registered in data category registries as they are suggested by ISO."
kemps-snijders-etal-2006-api,An {API} for accessing the Data Category Registry,2006,0,4,3,0,35127,marc kempssnijders,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,Central Ontologies are increasingly important to manage interoperability between different types of language resources. This was the reason for ISO to set up a new committee ISO TC37/SC4 taking care of language resource management issues. Central to the work of this committee is the definition of a framework for a central registry of data categories that are important in the domain of language resources. This paper describes an application programming interface that was designed to request services from this data category registry. The DCR is operational and the described API has already been tested from a lexicon application.
wittenburg-etal-2006-foundations,Foundations of Modern Language Resource Archives,2006,0,1,5,0.436508,39140,peter wittenburg,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"A number of serious reasons will convince an increasing amount of researchers to store their relevant material in centers which we will call ``language resource archives''. They combine the duty of taking care of long-term preservation as well as the task to give access to their material to different user groups. Access here is meant in the sense that an active interaction with the data will be made possible to support the integration of new data, new versions or commentaries of all sorts. Modern Language Resource Archives will have to adhere to a number of basic principles to fulfill all requirements and they will have to be involved in federations to create joint language resource domains making it even simpler for the researchers to access the data. This paper makes an attempt to formulate the essential pillars language resource archives have to adhere to."
offenga-etal-2006-metadata,Metadata Profile in the {ISO} Data Category Registry,2006,0,2,5,0,50169,freddy offenga,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Metadata descriptions of language resources become an increasing necessity since the shear amount of language resources is increasing rapidly and especially since we are now creating infrastuctures to access these resources via the web through integrated domains of language resource archives. Yet, the metadata frameworks offered for the domain of language resources (IMDI and OLAC), although mature, are not as widely accepted as necessary. The lack of confidence in the stability and persistence of the concepts and formats introduced by these metadata sets seems to be one argument for people to not invest the time needed for metadata creation. The introduction of these concepts into an ISO standardization process may convince contributors to make use of the terminology. The availability of the ISO Data Category Registry that includes a metadata profile will also offer the opportunity for researchers to construct their own metadata set tailored to the needs of the project at hand, but nevertheless supporting interoperability."
ide-romary-2006-representing,Representing Linguistic Corpora and Their Annotations,2006,5,49,2,0,16303,nancy ide,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"A Linguistic Annotation Framework (LAF) is being developed within the International Standards Organization Technical Committee 37 Sub-committee on Language Resource Management (ISO TC37 SC4). LAF is intended to provide a standardized means to represent linguistic data and its annotations that is defined broadly enough to accommodate all types of linguistic annotations, and at the same time provide means to represent precise and potentially complex linguistic information. The general principles informing the design of LAF have been previously reported (Ide and Romary, 2003; Ide and Romary, 2004a). This paper describes some of the more technical aspects of the LAF design that have been addressed in the process of finalizing the specifications for the standard."
le-etal-2006-lexicalized,A {L}exicalized {T}ree-{A}djoining {G}rammar for {V}ietnamese,2006,11,4,3,0,50510,phuong le,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper, we present the first sizable grammar built for Vietnamese using LTAG, developed over the past two years, named vnLTAG. This grammar aims at modelling written language and is general enough to be both application- and domain-independent. It can be used for the morpho-syntactic tagging and syntactic parsing of Vietnamese texts, as well as text generation. We then present a robust parsing scheme using vnLTAG and a parser for the grammar. We finish with an evaluation using a test suite."
W04-2104,Standards going concrete : from {LMF} to Morphalou,2004,7,59,1,1,17441,laurent romary,Proceedings of the Workshop on Enhancing and Using Electronic Dictionaries,0,Lexical resources are key components for applications related to human language technology. Various models of lexical resources have been designed and implemented during the last twenty years and the scientific community has now gained enough experience to design a common standard at an international level. This paper thus describes the ongoing activity within ISO/TC 37/SC 4 on LMF (Lexical Markup Framework) and shows how it can be concretely implemented for the design of an on-line morphological resource for French in the Morphalou project.
W04-1814,Construction of Grammar Based Term Extraction Model for {J}apanese,2004,0,0,4,0,17433,koichi takeuchi,Proceedings of {C}ompu{T}erm 2004: 3rd International Workshop on Computational Terminology,0,None
W04-0608,An Extensible Framework for Efficient Document Management using {RDF} and {OWL},2004,7,2,3,0,51681,erica meena,Proceeedings of the Workshop on {NLP} and {XML} ({NLPXML}-2004): {RDF}/{RDFS} and {OWL} in Language Technology,0,"In this paper, we describe an integrated approach towards dealing with various semantic and structural issues associated with document management. We provide motivations for using XML, RDF and OWL in building a seamless architecture to serve not only as a document exchange service but also to enable higher level services such as annotations, metadata access and querying. The key idea is to manifest differential treatments for the actual document structure, semantic content of the document and ontological document organization. The deployment of this architecture in the PROTEUS project provides an industrial setting for evaluation and further specification."
salmon-alt-romary-2004-towards,Towards a Reference Annotation Framework,2004,7,11,2,0,50134,susanne salmonalt,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper discusses the main characteristics of a possible unified framework for specifying annotation schemes dedicated to the task of reference identification and linking on linguistic corpora. Built upon the foundation principles of the Linguistic Annotation Framework, the model (RAF, Reference Annotation Framework) is based on the combination of a simple meta-model (expressing markables and links between them) and a selection of data categories representing the information actually attached to each component of the meta-model. Based on the observation of existing practices we show how this model can be used in a variety of practical and theoretical configurations."
nguyen-etal-2004-developping,Developping Tools and Building Linguistic Resources for {V}ietnamese Morpho-syntactic Processing,2004,4,7,3,0,5484,thanh nguyen,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"Vietnamese is spoken by about 80 millions people around the world, yet very few concrete works on this language have been noticed in Natural Language Processing (NLP) until now. The fundamental problems in automatic analysis of Vietnamese, such as part-ofspeech (POS) tagging, parsing, etc. are extremely difficult due to the lack of formal linguistic knowledge on one hand, and the specificities of isolating languages on the other hand. In this paper we present our efforts to develop a set of tools permitting the construction and management of language resources for Vietnamese in a normalized framework, whose aim is to be largely distributed and usable for research purposes in NLP. We first define a tagset by constructing Vietnamese morpho-syntactic descriptors that fit in a model compatible with MULTEXT 1 , so as to account for possible multilingual applications as well as the reusability of defined tagsets. We then implement a system undertaking the tasks of word segmentation and POS tagging. Our system ensures a representation format of linguistic resources that is currently considered in the framework of ISO TC37 SC4 2 . Finally we attempt to construct a formal syntactic description of nominal groups using the Tree Adjoining Grammar (TAG) formalism."
popescu-belis-etal-2004-online,Online Evaluation of Coreference Resolution,2004,13,13,4,0,6978,andrei popescubelis,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"This paper presents the design of an online evaluation service for coreference resolution in texts. We argue that coreference, as an equivalence relation between referring expressions (RE) in texts, should be properly distinguished from anaphora and has therefore to be evaluated separately. The annotation model for coreference is based on links between REs. The program presented in this article compares two such annotations, which may be the output of coreference resolution tools or of human judgement. In order to evaluate the agreement between the two annotations, the evaluator first converts the input annotation format into a pivot format, then abstracts equivalence classes from the links and provides five scores representing in different ways the similarity between the two partitions: MUC, B3, Kappa, Core-discourse-entity, and Mutual-information. Although we consider that the identification of REs (i.e. the elements of the partition) should not be part of coreference resolution properly speaking, we propose several solutions for the frequent case when the input files do not agree on the elements of the text to consider as REs."
landragin-etal-2004-multimodal,Multimodal Meaning Representation for Generic Dialogue Systems Architectures,2004,8,12,4,0,16608,frederic landragin,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"An unified language for the communicative acts between agents is essential for the design of multi-agents architectures. Whatever the type of interaction (linguistic, multimodal, including particular aspects such as force feedback), whatever the type of application (command dialogue, request dialogue, database querying), the concepts are common and we need a generic meta-model. In order to tend towards task-independent systems, we need to clarify the modules parameterization procedures. In this paper, we focus on the characteristics of a meta-model designed to represent meaning in linguistic and multimodal applications. This meta-model is called MMIL for MultiModal Interface Language, and has first been specified in the framework of the IST MIAMM European project. What we want to test here is how relevant is MMIL for a completely different context (a different task, a different interaction type, a different linguistic domain). We detail the exploitation of MMIL in the framework of the IST OZONE European project, and we draw the conclusions on the role of MMIL in the parameterization of task-independent dialogue managers."
devillers-etal-2004-french,The {F}rench {MEDIA}/{EVALDA} Project: the Evaluation of the Understanding Capability of Spoken Language Dialogue Systems,2004,9,30,12,0,39952,laurence devillers,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,The aim of the MEDIA project is to design and test a methodology for the evaluat ion of context-dependent and independent spoken dialogue systems. We propose an evaluation paradigm based on the use of test suites from real-world corpora and a common semantic representation and common metrics. This paradigm should allow us to diagnose the context-sensitive understanding capability of dialogue system s. This paradigm will be used within an evaluation campaign involving several si tes all of which will carry out the task of querying information from a database .
broeder-etal-2004-large,A Large Metadata Domain of Language Resources,2004,0,7,3,0.625,18402,daan broeder,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The INTERA and ECHO projects were partly intended to create a critical mass of open and linked metadata descriptions of language resources, helping researchers to understand the benefits of an increased visibility of language resources in the Internet and motivating them to participate. The work was based on the new IMDI version 3.0.3 which is a result of experiences with the earlier versions and new requirements coming from the involved partners. While in INTERA major data centers in Europe are participating, the ECHO project focuses on resources that can be seen as part of cultural heritage. Currently, 27 institutions and projects are active with the goal of having a large browsable and searchable domain by the summer of 2004. Experience shows that the creation of high quality metadata is not trivial and asks for a considerable amount of effort and skills, since manual work alone is too time consumin (Less)"
ide-romary-2004-registry,A Registry of Standard Data Categories for Linguistic Annotation,2004,2,45,2,0,16303,nancy ide,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this paper we describe the most recent work within ISO TC37/SC 4, and in particular the development of a Data Category Registry (DCR) component of the Linguistic Annotation Framework. The DCR will contain a formally defined set of linguistic categories in common use within the language engineering community for reference and use in linguistically annotated resources. We outline the first proposals for creation and management of the DCR, as a solicitation for input from the community."
romary-etal-2004-experiments,Experiments on Building Language Resources for Multi-Modal Dialogue Systems,2004,12,0,1,1,17441,laurent romary,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"The paper presents the experiments made to adapt and to synchronise the linguistic resources of the French language processing modules integrated in the MIAMM prototype, designed to handle multi-modal human-machine interactions. These experiments allowed us to identify a methodology for adapting multilingual resources for a dialogue system. In the paper, we describe the iterative joint process used to build linguistic resources for the two cooperative modules: speech recognition for speech modality and syntactic/semantic parsing."
lee-etal-2004-towards,Towards an International Standard on Feature Structure Representation,2004,22,18,3,0.517352,18931,kiyong lee,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,This paper describes the preliminary results of a joint initiative of the TEI (Text Encoding Initiative) Consortium and the ISO Committee TC 37SC 4 (language Resource management) to provide a standard for the representation and interchange of feature structures.
bunt-romary-2004-standardization,Standardization in Multimodal Content Representation: Some Methodological Issues,2004,10,13,2,0.167249,16745,harry bunt,Proceedings of the Fourth International Conference on Language Resources and Evaluation ({LREC}{'}04),0,"In this paper we discuss some basic methodological considerations of the activities undertaken in the ACL-SIGSEM Working Group on the Representation of Multimodal Semantic Information. This independent expert group was founded on the instigation of the Interna- tional Organization for Standardisation ISO for investigating the possibilities to develop well-founded guidelines for the representation and annotation of semantic information in interactive multimodal contexts, with the aim to support the interoperability and reuse of multimodal and language resources."
2004.jeptalnrecital-long.31,La {FREEBANK} : vers une base libre de corpus annot{\\'e}s,2004,-1,-1,3,0,50134,susanne salmonalt,Actes de la 11{\\`e}me conf{\\'e}rence sur le Traitement Automatique des Langues Naturelles. Articles longs,0,"Les corpus fran{\c{c}}ais librement accessibles annot{\'e}s {\`a} d{'}autres niveaux linguistiques que morpho-syntaxique sont insuffisants {\`a} la fois quantitativement et qualitativement. Partant de ce constat, la FREEBANK {--} construite sur la base d{'}outils d{'}analyse automatique dont la sortie est r{\'e}vis{\'e}e manuellement {--} se veut une base de corpus du fran{\c{c}}ais annot{\'e}s {\`a} plusieurs niveaux (structurel, morphologique, syntaxique, cor{\'e}f{\'e}rentiel) et {\`a} diff{\'e}rents degr{\'e}s de finesse linguistique qui soit libre d{'}acc{\`e}s, cod{\'e}e selon des sch{\'e}mas normalis{\'e}s, int{\'e}grant des ressources existantes et ouverte {\`a} l{'}enrichissement progressif."
W03-1901,Outline of the International Standard Linguistic Annotation Framework,2003,8,39,2,0.187743,16303,nancy ide,Proceedings of the {ACL} 2003 Workshop on Linguistic Annotation: Getting the Model Right,0,"This paper describes the outline of a linguistic annotation framework under development by ISO TC37 SC WG1-1. This international standard provides an architecture for the creation, annotation, and manipulation of linguistic resources and processing software. The goal is to provide maximum flexibility for encoders and annotators, while at the same time enabling interchange and re-use of annotated linguistic resources. We describe here the outline of the standard for the purposes of enabling annotators to begin to explore how their schemes may map into the framework."
W03-0804,International Standard for a Linguistic Annotation Framework,2003,7,89,2,0.187743,16303,nancy ide,Proceedings of the {HLT}-{NAACL} 2003 Workshop on Software Engineering and Architecture of Language Technology Systems ({SEALTS}),0,"This paper describes the outline of a linguistic annotation framework under development by ISO TC37 SC WG1-1. This international standard will provide an architecture for the creation, annotation, and manipulation of linguistic resources and processing software. The outline described here results from a meeting of approximately 20 experts in the field, who determined the principles and fundamental structure of the framework. The goal is to provide maximum flexibility for encoders and annotators, while at the same time enabling interchange and re-use of annotated linguistic resources."
2003.mtsummit-papers.45,{SYSTRAN} new generation: the {XML} translation workflow,2003,2,3,3,0,13889,jean senellart,Proceedings of Machine Translation Summit IX: Papers,0,"Customization of Machine Translation (MT) is a prerequisite for corporations to adopt the technology. It is therefore important but nonetheless challenging. Ongoing implementation proves that XML is an excellent exchange device between MT modules that efficiently enables interaction between the user and the processes to reach highly granulated structure-based customization. Accomplished through an innovative approach called the SYSTRAN Translation Stylesheet, this method is coherent with the current evolution of the {``}authoring process{''}. As a natural progression, the next stage in the customization process is the integration of MT in a multilingual tool kit designed for the {``}authoring process{''}."
todirascu-etal-2002-towards,Towards Reusable {NLP} Components,2002,5,2,3,0,15684,amalia todirascu,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,We propose a methodology for transforming NLP modules into reusable components that can be integrated it into a distributed and open architecture. We illustrate the methodology by showing the adaptations needed to transform an LTAG parser into a bundle of parsing and lexical services
broeder-etal-2002-lrep,{LREP}: A Language Repository Exchange Protocol,2002,3,0,4,0.625,18402,daan broeder,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,The recent increase in the number and complexity of the language resources available on the Internet is followed by a similar increase of available tools for linguistic analysis. Ideally the user does not need to be confronted with the question in how to match tools with resources. If resource repositories and tool repositories offer adequate metadata information and a suitable exchange protocol is developed this matching process could be performed (semi-) automatically.
ide-romary-2002-standards,Standards for Language Resources,2002,0,50,2,0.084813,16303,nancy ide,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper presents an abstract data model for linguistic annotations and its implementation using XML, RDF and related standards; and to outline the work of a newly formed committee of the International Standards Organization (ISO), ISO/TC 37/SC 4 Language Resource Management, which will use this work as its starting point. The primary motive for presenting the latter is to solicit the participation of members of the research community to contribute to the work of the committee."
P01-1040,A Common Framework for Syntactic Annotation,2001,7,30,2,0.113084,16303,nancy ide,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"It is widely recognized that the proliferation of annotation schemes runs counter to the need to re-use language resources, and that standards for linguistic annotation are becoming increasingly mandatory. To answer this need, we have developed a representation framework comprised of an abstract model for a variety of different annotation types (e.g., morpho-syntactic tagging, syntactic annotation, co-reference annotation, etc.), which can be instantiated in different ways depending on the annotator s approach and goals. In this paper we provide an overview of our representation framework and demonstrate its applicability to syntactic annotation. We show how the framework can contribute to comparative evaluation and merging of parser output and diverse syntactic annotation schemes."
ide-etal-2000-xces,{XCES}: An {XML}-based Encoding Standard for Linguistic Corpora,2000,8,130,3,0.166443,16303,nancy ide,Proceedings of the Second International Conference on Language Resources and Evaluation ({LREC}{'}00),0,"The Corpus Encoding Standard (CES) is a part of the EAGLES Guidelines developed by the Expert Advisory Group on Language Engineering Standards (EAGLES) that provides a set of encoding standards for corpus-based work in natural language processing applications. We have instantiated the CES as an XML application called XCES, based on the same data architecture comprised of a primary encoded text and standoff annotation in separate documents. Conversion to XML enables use of some of the more powerful mechanisms provided in the XML framework, including the XSLT Transformation Language, XML Schemas, and support for interrescue reference together with an extensive path syntax for pointers. In this paper, we describe the differences between the CES and XCES DTDs and demonstrate how XML mechanisms can be used to select from and manipulate annotated corpora encoded according to XCES specifications. We also provide a general overview of XML and the XML mechanisms that are most relevant to language engineering research and applications."
P98-1044,Veins Theory: A Model of Global Discourse Cohesion and Coherence,1998,24,82,3,0,14259,dan cristea,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"In this paper, we propose a generalization of Centering Theory (CT) (Grosz, Joshi, Weinstein (1995)) called Veins Theory (VT), which extends the applicability of centering rules from local to global discourse. A key facet of the theory involves the identification of xc2xabveinsxc2xbb over discourse structure trees such as those defined in RST, which delimit domains of referential accessibility for each unit in a discourse. Once identified, reference chains can be extended across segment boundaries, thus enabling the application of CT over the entire discourse. We describe the processes by which veins are defined over discourse structure trees and how CT can be applied to global discourse by using these chains. We also define a discourse xc2xabsmoothnessxc2xbb index which can be used to compare different discourse structures and interpretations, and show how VT can be used to abstract a span of text in the context of the whole discourse. Finally, we validate our theory by analyzing examples from corpora of English, French, and Romanian."
C98-1044,Veins Theory: A Model of Global Discourse Cohesion and Coherence,1998,24,82,3,0,14259,dan cristea,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"In this paper, we propose a generalization of Centering Theory (CT) (Grosz, Joshi, Weinstein (1995)) called Veins Theory (VT), which extends the applicability of centering rules from local to global discourse. A key facet of the theory involves the identification of xc2xabveinsxc2xbb over discourse structure trees such as those defined in RST, which delimit domains of referential accessibility for each unit in a discourse. Once identified, reference chains can be extended across segment boundaries, thus enabling the application of CT over the entire discourse. We describe the processes by which veins are defined over discourse structure trees and how CT can be applied to global discourse by using these chains. We also define a discourse xc2xabsmoothnessxc2xbb index which can be used to compare different discourse structures and interpretations, and show how VT can be used to abstract a span of text in the context of the whole discourse. Finally, we validate our theory by analyzing examples from corpora of English, French, and Romanian."
W97-1413,"Constraints on the Use of Language, Gesture and Speech for Multimodal Dialogues",1997,9,2,2,0,46601,bertrand gaiffe,Referring Phenomena in a Multimedia Context and their Computational Treatment,0,"In the domain of natural language understanding and more precisely man-machine dialogue design, there are usually two trends of research which seem to be rather differentiated. On the one hand, many studies have tackled the problem of interpreting spatial references expressed in verbal utterances, focusing in particular on the different geometric or functionnal constraints which are bound to the existance of a 'source' (or site) element in relation to which a 'target' is being situated. Such studies are usually based upon fine grained linguistic descriptions for different languages (Vandeloise, 1986). On the other hand, the problem raised by the integration of a gestural mode within classical NL interfaces has yielded some specific research about the association of demonstrative or deictic Nps together with designations, as initited by Bolt some two decades ago (cf. Thorisson et alii, 1992; Bellalem and Romary, 1995). Our aim in this paper is to show that the different phenomena described in the context of spatial reference or multimodal interaction should not necessarily be considered as two independant issues, but should rather be analysed in a unified way to account for the fact that they are both based on linguistic and perceptual data."
