2021.sigmorphon-1.23,Finite-state Model of Shupamem Reduplication,2021,-1,-1,3,0,1352,magdalena markowska,"Proceedings of the 18th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"Shupamem, a language of Western Cameroon, is a tonal language which also exhibits the morpho-phonological process of full reduplication. This creates two challenges for finite-state model of its morpho-syntax and morphophonology: how to manage the full reduplication and the autosegmental nature of lexical tone. Dolatian and Heinz (2020) explain how 2-way finite-state transducers can model full reduplication without an exponential increase in states, and finite-state transducers with multiple tapes have been used to model autosegmental tiers, including tone (Wiebe, 1992; Dolatian and Rawski, 2020a). Here we synthesize 2-way finite-state transducers and multitape transducers, resulting in a finite-state formalism that subsumes both, to account for the full reduplicative processes in Shupamem which also affect tone."
2020.lrec-1.167,Email Classification Incorporating Social Networks and Thread Structure,2020,-1,-1,2,1,16938,sakhar alkhereyf,Proceedings of the 12th Language Resources and Evaluation Conference,0,"Existing methods for different document classification tasks in the context of social networks typically only capture the semantics of texts, while ignoring the users who exchange the text and the network they form. However, some work has shown that incorporating the social network information in addition to information from language is effective for various NLP applications including sentiment analysis, inferring user attributes, and predicting inter-personal relations. In this paper, we present an empirical study of email classification into {``}Business{''} and {``}Personal{''} categories. We represent the email communication using various graph structures. As features, we use both the textual information from the email content and social network information from the communication graphs. We also model the thread structure for emails. We focus on detecting personal emails, and we evaluate our methods on two corpora, only one of which we train on. The experimental results reveal that incorporating social network information improves over the performance of an approach based on textual information only. The results also show that considering the thread structure of emails improves the performance further. Furthermore, our approach improves over a state-of-the-art baseline which uses node embeddings based on both lexical and social network information."
2020.acl-main.701,"To Test Machine Comprehension, Start by Defining Comprehension",2020,64,0,4,0,23085,jesse dunietz,Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,1,"Many tasks aim to measure machine reading comprehension (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key contributions. First, we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehension{---}a {``}Template of Understanding{''}{---}for a widely useful class of texts, namely short narratives. We then conduct an experiment that strongly suggests existing systems are not up to the task of narrative understanding as we define it."
W19-4615,"Morphologically Annotated Corpora for Seven {A}rabic Dialects: Taizi, Sanaani, Najdi, Jordanian, Syrian, Iraqi and {M}oroccan",2019,0,0,9,1,24089,faisal alshargi,Proceedings of the Fourth Arabic Natural Language Processing Workshop,0,"We present a collection of morphologically annotated corpora for seven Arabic dialects: Taizi Yemeni, Sanaani Yemeni, Najdi, Jordanian, Syrian, Iraqi and Moroccan Arabic. The corpora collectively cover over 200,000 words, and are all manually annotated in a common set of standards for orthography, diacritized lemmas, tokenization, morphological units and English glosses. These corpora will be publicly available to serve as benchmarks for training and evaluating systems for Arabic dialect morphological analysis and disambiguation."
N19-1075,Syntax-aware Neural Semantic Role Labeling with Supertags,2019,26,1,5,0.815603,3374,jungo kasai,"Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",0,"We introduce a new syntax-aware model for dependency-based semantic role labeling that outperforms syntax-agnostic models for English and Spanish. We use a BiLSTM to tag the text with supertags extracted from dependency parses, and we feed these supertags, along with words and parts of speech, into a deep highway BiLSTM for semantic role labeling. Our model combines the strengths of earlier models that performed SRL on the basis of a full dependency parse with more recent models that use no syntactic information at all. Our local and non-ensemble model achieves state-of-the-art performance on the CoNLL 09 English and Spanish datasets. SRL models benefit from syntactic information, and we show that supertagging is a simple, powerful, and robust way to incorporate syntax into a neural SRL system."
W18-5808,Automatically Tailoring Unsupervised Morphological Segmentation to the Language,2018,0,0,2,1,8324,ramy eskander,"Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,"Morphological segmentation is beneficial for several natural language processing tasks dealing with large vocabularies. Unsupervised methods for morphological segmentation are essential for handling a diverse set of languages, including low-resource languages. Eskander et al. (2016) introduced a Language Independent Morphological Segmenter (LIMS) using Adaptor Grammars (AG) based on the best-on-average performing AG configuration. However, while LIMS worked best on average and outperforms other state-of-the-art unsupervised morphological segmentation approaches, it did not provide the optimal AG configuration for five out of the six languages. We propose two language-independent classifiers that enable the selection of the optimal or nearly-optimal configuration for the morphological segmentation of unseen languages."
N18-1096,Author Commitment and Social Power: Automatic Belief Tagging to Infer the Social Context of Interactions,2018,30,2,3,0.977676,90,vinodkumar prabhakaran,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"Understanding how social power structures affect the way we interact with one another is of great interest to social scientists who want to answer fundamental questions about human behavior, as well as to computer scientists who want to build automatic methods to infer the social contexts of interactions. In this paper, we employ advancements in extra-propositional semantics extraction within NLP to study how author commitment reflects the social context of an interactions. Specifically, we investigate whether the level of commitment expressed by individuals in an organizational interaction reflects the hierarchical power structures they are part of. We find that subordinates use significantly more instances of non-commitment than superiors. More importantly, we also find that subordinates attribute propositions to other agents more often than superiors do {---} an aspect that has not been studied before. Finally, we show that enriching lexical features with commitment labels captures important distinctions in social meanings."
N18-1107,End-to-End Graph-Based {TAG} Parsing with Neural Networks,2018,29,0,5,1,3374,jungo kasai,"Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",0,"We present a graph-based Tree Adjoining Grammar (TAG) parser that uses BiLSTMs, highway connections, and character-level CNNs. Our best end-to-end parser, which jointly performs supertagging, POS tagging, and parsing, outperforms the previously reported best results by more than 2.2 LAS and UAS points. The graph-based parsing architecture allows for global inference and rich feature representations for TAG parsing, alleviating the fundamental trade-off between transition-based and graph-based parsing systems. We also demonstrate that the proposed parser achieves state-of-the-art performance in the downstream tasks of Parsing Evaluation using Textual Entailments (PETE) and Unbounded Dependency Recovery. This provides further support for the claim that TAG is a viable formalism for problems that require rich structural analysis of sentences."
L18-1535,The {MADAR} {A}rabic Dialect Corpus and Lexicon,2018,0,9,5,0,516,houda bouamor,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
L18-1574,Unified Guidelines and Resources for {A}rabic Dialect Orthography,2018,-1,-1,4,0,517,nizar habash,Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018),0,None
W17-6213,Linguistically Rich Vector Representations of Supertags for {TAG} Parsing,2017,14,0,6,0.833333,4415,dan friedman,Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms,0,None
W17-6214,{TAG} Parser Evaluation using Textual Entailments,2017,16,1,4,0,29439,pauli xu,Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms,0,None
W17-4202,Predicting User Views in Online News,2017,3,1,2,0.5,416,daniel hardt,Proceedings of the 2017 {EMNLP} Workshop: Natural Language Processing meets Journalism,0,"We analyze user viewing behavior on an online news site. We collect data from 64,000 news articles, and use text features to predict frequency of user views. We compare predictiveness of the headline and {``}teaser{''} (viewed before clicking) and the body (viewed after clicking). Both are predictive of clicking behavior, with the full article text being most predictive."
W17-2408,"Work Hard, Play Hard: Email Classification on the Avocado and {E}nron Corpora",2017,6,2,2,1,16938,sakhar alkhereyf,Proceedings of {T}ext{G}raphs-11: the Workshop on Graph-based Methods for Natural Language Processing,0,"In this paper, we present an empirical study of email classification into two main categories {``}Business{''} and {``}Personal{''}. We train on the Enron email corpus, and test on the Enron and Avocado email corpora. We show that information from the email exchange networks improves the performance of classification. We represent the email exchange networks as social networks with graph structures. For this classification task, we extract social networks features from the graphs in addition to lexical features from email content and we compare the performance of SVM and Extra-Trees classifiers using these features. Combining graph features with lexical features improves the performance on both classifiers. We also provide manually annotated sets of the Avocado and Enron email corpora as a supplementary contribution."
D17-1180,{TAG} Parsing with Neural Networks and Vector Representations of Supertags,2017,22,9,4,1,3374,jungo kasai,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,0,"We present supertagging-based models for Tree Adjoining Grammar parsing that use neural network architectures and dense vector representation of supertags (elementary trees) to achieve state-of-the-art performance in unlabeled and labeled attachment scores. The shift-reduce parsing model eschews lexical information entirely, and uses only the 1-best supertags to parse a sentence, providing further support for the claim that supertagging is {``}almost parsing.{''} We demonstrate that the embedding vector representations the parser induces for supertags possess linguistically interpretable structure, supporting analogies between grammatical structures like those familiar from recent work in distributional semantics. This dense representation of supertags overcomes the drawbacks for statistical models of TAG as compared to CCG parsing, raising the possibility that TAG is a viable alternative for NLP tasks that require the assignment of richer structural descriptions to sentences."
W16-5003,Detecting Level of Belief in {C}hinese and {S}panish,2016,-1,-1,3,0,33539,juan colomer,Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics ({E}x{P}ro{M}),0,"There has been extensive work on detecting the level of committed belief (also known as {``}factuality{''}) that an author is expressing towards the propositions in his or her utterances. Previous work on English has revealed that this can be done as a sequence tagging task. In this paper, we investigate the same task for Chinese and Spanish, two very different languages from English and from each other."
W16-3309,Revisiting Supertagging and Parsing: How to Use Supertags in Transition-Based Parsing,2016,1,0,4,0,33762,wonchang chung,Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms ({TAG}+12),0,We discuss the use of supertags derived from a TAG in transition-based parsing. We show some initial experimental results which suggest that using a representation of a supertag in terms of its structural and linguistic dimensions outperforms the use of atomic supertags.
W16-3311,Hyperedge Replacement and Nonprojective Dependency Structures,2016,15,2,2,1,33764,daniel bauer,Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms ({TAG}+12),0,None
W16-2011,The {C}olumbia {U}niversity - {N}ew {Y}ork {U}niversity {A}bu {D}habi {SIGMORPHON} 2016 Morphological Reinflection Shared Task Submission,2016,-1,-1,4,0,14288,dima taji,"Proceedings of the 14th {SIGMORPHON} Workshop on Computational Research in Phonetics, Phonology, and Morphology",0,None
L16-1207,Morphologically Annotated Corpora and Morphological Analyzers for {M}oroccan and Sanaani Yemeni {A}rabic,2016,12,9,5,1,24089,faisal alshargi,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"We present new language resources for Moroccan and Sanaani Yemeni Arabic. The resources include corpora for each dialect which have been morphologically annotated, and morphological analyzers for each dialect which are derived from these corpora. These are the first sets of resources for Moroccan and Yemeni Arabic. The resources will be made available to the public."
L16-1322,"A Corpus of {W}ikipedia Discussions: Over the Years, with Topic, Power and Gender Labels",2016,13,3,2,1,90,vinodkumar prabhakaran,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"In order to gain a deep understanding of how social context manifests in interactions, we need data that represents interactions from a large community of people over a long period of time, capturing different aspects of social context. In this paper, we present a large corpus of Wikipedia Talk page discussions that are collected from a broad range of topics, containing discussions that happened over a period of 15 years. The dataset contains 166,322 discussion threads, across 1236 articles/topics that span 15 different topic categories or domains. The dataset also captures whether the post is made by an registered user or not, and whether he/she was an administrator at the time of making the post. It also captures the Wikipedia age of editors in terms of number of months spent as an editor, as well as their gender. This corpus will be a valuable resource to investigate a variety of computational sociolinguistics research questions regarding online social interactions."
L16-1640,{SPLIT}: Smart Preprocessing (Quasi) Language Independent Tool,2016,0,4,5,0.526316,32076,mohamed albadrashiny,Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16),0,"Text preprocessing is an important and necessary task for all NLP applications. A simple variation in any preprocessing step may drastically affect the final results. Moreover replicability and comparability, as much as feasible, is one of the goals of our scientific enterprise, thus building systems that can ensure the consistency in our various pipelines would contribute significantly to our goals. The problem has become quite pronounced with the abundance of NLP tools becoming more and more available yet with different levels of specifications. In this paper, we present a dynamic unified preprocessing framework and tool, SPLIT, that is highly configurable based on user requirements which serves as a preprocessing tool for several tools at once. SPLIT aims to standardize the implementations of the most important preprocessing steps by allowing for a unified API that could be exchanged across different researchers to ensure complete transparency in replication. The user is able to select the required preprocessing tasks among a long list of preprocessing steps. The user is also able to specify the order of execution which in turn affects the final preprocessing output."
C16-1043,Incrementally Learning a Dependency Parser to Support Language Documentation in Field Linguistics,2016,12,1,3,1,17200,morgan ulinski,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We present experiments in incrementally learning a dependency parser. The parser will be used in the WordsEye Linguistics Tools (WELT) (Ulinski et al., 2014) which supports field linguists documenting a language{'}s syntax and semantics. Our goal is to make syntactic annotation faster for field linguists. We have created a new parallel corpus of descriptions of spatial relations and motion events, based on pictures and video clips used by field linguists for elicitation of language from native speaker informants. We collected descriptions for each picture and video from native speakers in English, Spanish, German, and Egyptian Arabic. We compare the performance of MSTParser (McDonald et al., 2006) and MaltParser (Nivre et al., 2006) when trained on small amounts of this data. We find that MaltParser achieves the best performance. We also present the results of experiments using the parser to assist with annotation. We find that even when the parser is trained on a single sentence from the corpus, annotation time significantly decreases."
C16-1086,Extending the Use of {A}daptor {G}rammars for Unsupervised Morphological Segmentation of Unseen Languages,2016,12,0,2,1,8324,ramy eskander,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"We investigate using Adaptor Grammars for unsupervised morphological segmentation. Using six development languages, we investigate in detail different grammars, the use of morphological knowledge from outside sources, and the use of a cascaded architecture. Using cross-validation on our development languages, we propose a system which is language-independent. We show that it outperforms two state-of-the-art systems on 5 out of 6 languages."
C16-1207,Automatically Processing Tweets from Gang-Involved Youth: Towards Detecting Loss and Aggression,2016,19,10,6,0,10565,terra blevins,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Violence is a serious problems for cities like Chicago and has been exacerbated by the use of social media by gang-involved youths for taunting rival gangs. We present a corpus of tweets from a young and powerful female gang member and her communicators, which we have annotated with discourse intention, using a deep read to understand how and what triggered conversations to escalate into aggression. We use this corpus to develop a part-of-speech tagger and phrase table for the variant of English that is used and a classifier for identifying tweets that express grieving and aggression."
C16-1326,Creating Resources for Dialectal {A}rabic from a Single Annotation: A Case Study on {E}gyptian and {L}evantine,2016,28,4,3,1,8324,ramy eskander,"Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",0,"Arabic dialects present a special problem for natural language processing because there are few resources, they have no standard orthography, and have not been studied much. However, as more and more written dialectal Arabic is found in social media, NLP for Arabic dialects becomes an important goal. We present a methodology for creating a morphological analyzer and a morphological tagger for dialectal Arabic, and we illustrate it on Egyptian and Levantine Arabic. To our knowledge, these are the first analyzer and tagger for Levantine."
W15-3206,{DIWAN}: A Dialectal Word Annotation Tool for {A}rabic,2015,8,10,2,1,24089,faisal alshargi,Proceedings of the Second Workshop on {A}rabic Natural Language Processing,0,"This paper presents DIWAN, an annotation interface for Arabic dialectal texts. While the Arabic dialects differ in many respects from each other and from Modern Standard Arabic, they also have much in common. To facilitate annotation and to make it as efficient as possible, it is therefore not advisable to treat each Arabic dialect as a separate language, unrelated to the other variants of Arabic. Instead, we make analyses from other variants available to the annotator, who then can choose to use them or not."
W15-1304,Committed Belief Tagging on the Factbank and {LU} Corpora: A Comparative Study,2015,13,5,4,0,37059,gregory werner,Proceedings of the Second Workshop on Extra-Propositional Aspects of Meaning in Computational Semantics ({E}x{P}ro{M} 2015),0,"Level of committed belief is a modality in natural language, it expresses a speak-er/writers belief in a proposition. Initial work exploring this phenomenon in the literature both from a linguistic and computational modeling perspective shows that it is a challenging phenomenon to capture, yet of great interest to several downstream NLP applications. In this work, we focus on identifying relevant features to the task of determining the level of committed belief tagging in two corpora specifically annotated for the phenomenon: the LU corpus and the FactBank corpus. We perform a thorough analysis comparing tagging schemes, infrastructure machinery, feature sets, preprocessing schemes and data genres and their impact on performance in both corpora. Our best results are an F1 score of 75.7 on the FactBank corpus and 72.9 on the smaller LU corpus."
W15-0704,Validating Literary Theories Using Automatic Social Network Extraction,2015,19,5,4,0,22726,prashant jayannavar,Proceedings of the Fourth Workshop on Computational Linguistics for Literature,0,"In this paper, we investigate whether longstanding literary theories about nineteenthcentury British novels can be verified using computational techniques. Elson et al. (2010) previously introduced the task of computationally validating such theories, extracting conversational networks from literary texts. Revisiting their work, we conduct a closer reading of the theories themselves, present a revised and expanded set of hypotheses based on a divergent interpretation of the theories, and widen the scope of networks for validating this expanded set of hypotheses."
S15-1009,A New Dataset and Evaluation for Belief/Factuality,2015,15,5,4,1,90,vinodkumar prabhakaran,Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics,0,"The terms xe2x80x9cbeliefxe2x80x9d and xe2x80x9cfactualityxe2x80x9d both refer to the intention of the writer to present the propositional content of an utterance as firmly believed by the writer, not firmly believed, or having some other status. This paper presents an ongoing annotation effort and an associated evaluation."
P15-5003,"Sentiment and Belief: How to Think about, Represent, and Annotate Private States",2015,22,3,1,1,1354,owen rambow,Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing: Tutorial Abstracts,0,"Over the last ten years, there has been an explosion in interest in sentiment analysis, with many interesting and impressive results. For example, the first twenty publications on Google Scholar returned for the Query xe2x80x9csentiment analysisxe2x80x9d all date from 2003 or later, and have a total citation count of 12,140. The total number of publications is in the thousands. Partly, this interest is driven by the immediate commercial applications of sentiment analysis. Sentiment is a xe2x80x9cprivate statexe2x80x9d (Wiebe, 1990). However, it is not the only private state that has received attention in the computational literature; others include belief and intention. In this tutorial, we propose to provide a deeper understanding of what a private state is. We will concentrate on sentiment and belief. We will provide background that will allow the tutorial participants to understand the notion of a private state as a cognitive phenomenon, which can be manifested linguistically in communication in various ways. We will explain the formalization in terms of a triple of state, source, and target. We will discuss how to model the source and the target. We will then explain in some detail the annotations that have been made. The issue of annotation is crucial for private states: while the MPQA corpus (Wiebe et al., 2005; Wilson, 2007) has been around for some time, most research using it does not make use of many of its features. We believe this is because the MPQA annotation is quite complex and requires a deeper understanding of the phenomenon of xe2x80x9cprivate statexe2x80x9d, which is what the annotation is getting at. Furthermore, there are currently several efforts underway of creating new versions of annotations, which we will also present. The larger goal of this tutorial is to allow the tutorial participants to gain a deeper understanding of the role of private states in human communication, and to encourage them to use this deeper understanding in their computational work. The immediate goal of this tutorial is to allow the participants to make more complete use of available annotated resources. We propose to achieve these goals by concentrating on annotated corpora, since this will allow participants to both understand the underlying content (achieving the larger goal) and the technical details of the annotations (achieving the immediate goal)."
D15-1304,{SLSA}: A Sentiment Lexicon for {S}tandard {A}rabic,2015,16,22,2,1,8324,ramy eskander,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,0,"Sentiment analysis has been a major area of interest, for which the existence of highquality resources is crucial. In Arabic, there is a reasonable number of sentiment lexicons but with major deficiencies. The paper presents a large-scale Standard Arabic Sentiment Lexicon (SLSA) that is publicly available for free and avoids the deficiencies in the current resources. SLSA has the highest up-to-date reported coverage. The construction of SLSA is based on linking the lexicon of AraMorph with SentiWordNet along with a few heuristics and powerful back-off. SLSA shows a relative improvement of 37.8% over a state-of-theart lexicon when tested for accuracy. It also outperforms it by an absolute 3.5% of F1-score when tested for sentiment analysis."
W14-5816,Light verb constructions with {`}do{'} and {`}be{'} in {H}indi: A {TAG} analysis,2014,16,2,2,0,640,ashwini vaidya,Proceedings of Workshop on Lexical and Grammatical Resources for Language Processing,0,"In this paper we present a Lexicalized Feature-based Tree-Adjoining Grammar analysis for a type of nominal predicate that occurs in combination with the light verbs xe2x80x9cdoxe2x80x9d and xe2x80x9cbexe2x80x9d (Hindi kar and ho respectively). Light verb constructions are a challenge for computational grammars because they are a highly productive predicational strategy in Hindi. Such nominals have been discussed in the literature (Mohanan, 1997; Ahmed and Butt, 2011; Bhatt et al., 2013), but this work is a first attempt at a Tree-Adjoining Grammar (TAG) representation. We look at three possibilities for the design of elementary trees in TAG and explore one option in depth using Hindi data. In this analysis, the nominal is represented with all the arguments of the light verb construction, while the light verb adjoins into its elementary tree."
W14-3901,Foreign Words and the Automatic Processing of {A}rabic Social Media Text Written in {R}oman Script,2014,24,12,4,1,8324,ramy eskander,Proceedings of the First Workshop on Computational Approaches to Code Switching,0,"Arabic on social media has all the properties of any language on social media that make it tough for natural language processing, plus some specific problems. These include diglossia, the use of an alternative alphabet (Roman), and code switching with foreign languages. In this paper, we present a system which can process Arabic written in Roman alphabet (xe2x80x9cArabizixe2x80x9d). It identifies whether each word is a foreign word or one of another four categories (Arabic, name, punctuation, sound), and transliterates Arabic words and names into the Arabic alphabet. We obtain an overall system performance of 83.8% on an unseen test set."
W14-3612,Transliteration of {A}rabizi into {A}rabic Orthography: Developing a Parallel Annotated {A}rabizi-{A}rabic Script {SMS}/Chat Corpus,2014,24,16,10,0.126317,17656,ann bies,Proceedings of the {EMNLP} 2014 Workshop on {A}rabic Natural Language Processing ({ANLP}),0,"This paper describes the process of creating a novel resource, a parallel Arabizi-Arabic script corpus of SMS/Chat data. The language used in social media expresses many differences from other written genres: its vocabulary is informal with intentional deviations from standard orthography such as repeated letters for emphasis; typos and nonstandard abbreviations are common; and nonlinguistic content is written out, such as laughter, sound representations, and emoticons. This situation is exacerbated in the case of Arabic social media for two reasons. First, Arabic dialects, commonly used in social media, are quite different from Modern Standard Arabic phonologically, morphologically and lexically, and most importantly, they lack standard orthographies. Second, Arabic speakers in social media as well as discussion forums, SMS messaging and online chat often use a non-standard romanization called Arabizi. In the context of natural language processing of social media Arabic, transliterating from Arabizi of various dialects to Arabic script is a necessary step, since many of the existing state-of-the-art resources for Arabic dialect processing expect Arabic script input. The corpus described in this paper is expected to support Arabic NLP by providing this resource."
W14-3008,Using Frame Semantics in Natural Language Processing,2014,11,0,3,0.8315,37109,apoorv agarwal,Proceedings of Frame Semantics in {NLP}: A Workshop in Honor of Chuck {F}illmore (1929-2014),0,"We summarize our experience using FrameNet in two rather different projects in natural language processing (NLP). We conclude that NLP can benefit from FrameNet in different ways, but we sketch some problems that need to be overcome."
W14-2710,Power of Confidence: How Poll Scores Impact Topic Dynamics in Political Debates,2014,-1,-1,3,1,90,vinodkumar prabhakaran,Proceedings of the Joint Workshop on Social Dynamics and Personal Attributes in Social Media,0,None
W14-2514,Power of Confidence: How Poll Scores Impact Topic Dynamics in Political Debates,2014,-1,-1,3,1,90,vinodkumar prabhakaran,Proceedings of the {ACL} 2014 Workshop on Language Technologies and Computational Social Science,0,None
W14-2518,Using Simple {NLP} Tools to Trace the Globalization of the Art World,2014,10,0,3,1,26618,mohamed altantawy,Proceedings of the {ACL} 2014 Workshop on Language Technologies and Computational Social Science,0,"We introduce a novel task, that of associating relative time with cities in text. We show that the task can be performed using NLP tools and techniques. The task is deployed on a large corpus of data to study a specific phenomenon, namely the temporal dimension of contemporary arts globalization over the first decade of the 21 st century."
W14-2202,Documenting Endangered Languages with the {W}ords{E}ye Linguistics Tool,2014,13,3,6,1,17200,morgan ulinski,Proceedings of the 2014 Workshop on the Use of Computational Methods in the Study of Endangered Languages,0,"In this paper, we describe how field linguists can use the WordsEye Linguistics Tool (WELT) to study endangered languages. WELT is a tool under development for eliciting endangered language data and formally documenting a language, based on WordsEye (Coyne and Sproat, 2001), a text-to-scene generation tool that produces 3D scenes from text input. First, a linguist uses WELT to create elicitation materials and collect language data. Next, he or she uses WELT to formally document the language. Finally, the formal models are used to create a textto-scene system that takes input in the endangered language and generates a picture representing its meaning."
W14-1604,Automatic Transliteration of {R}omanized Dialectal {A}rabic,2014,22,20,4,0.526316,32076,mohamed albadrashiny,Proceedings of the Eighteenth Conference on Computational Natural Language Learning,0,"In this paper, we address the problem of converting Dialectal Arabic (DA) text that is written in the Latin script (called Arabizi) into Arabic script following the CODA convention for DA orthography. The presented system uses a finite state transducer trained at the character level to generate all possible transliterations for the input Arabizi words. We then filter the generated list using a DA morphological analyzer. After that we pick the best choice for each input word using a language model. We achieve an accuracy of 69.4% on an unseen test set compared to 63.1% using a system which represents a previously proposed approach."
P14-5009,{WELT}: Using Graphics Generation in Linguistic Fieldwork,2014,12,0,5,1,17200,morgan ulinski,Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,0,"We describe the WordsEye Linguistics tool (WELT), a novel tool for the documentation and preservation of endangered languages. WELT is based on WordsEye (Coyne and Sproat, 2001), a text-toscene tool that automatically generates 3D scenes from written input. WELT has two modes of operation. In the first mode, English input automatically generates a picture which can be used to elicit a description in the target language. In the second mode, the linguist formally documents the grammar of an endangered language, thereby creating a system that takes input in the endangered language and generates a picture according to the grammar; the picture can then be used to verify the grammar with native speakers. We will demonstrate WELTxe2x80x99s use on scenarios involving Arrernte and Nahuatl."
P14-2056,Predicting Power Relations between Participants in Written Dialog from a Single Thread,2014,17,12,2,1,90,vinodkumar prabhakaran,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,We introduce the problem of predicting who has power over whom in pairs of people based on a single written dialog. We propose a new set of structural features. We build a supervised learning system to predict the direction of power; our new features significantly improve the results over using previously proposed features.
P14-1127,Unsupervised Morphology-Based Vocabulary Expansion,2014,29,8,4,0,3273,mohammad rasooli,Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),1,"We present a novel way of generating unseen words, which is useful for certain applications such as automatic speech recognition or optical character recognition in low-resource languages. We test our vocabulary generator on seven low-resource languages by measuring the decrease in out-of-vocabulary word rate on a held-out test set. The languages we study have very different morphological properties; we show how our results differ depending on the morphological complexity of the language. In our best result (on Assamese), our approach can predict 29% of the token-based out-of-vocabulary with a small amount of unlabeled training data."
pasha-etal-2014-madamira,"{MADAMIRA}: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of {A}rabic",2014,14,279,8,1,35353,arfath pasha,Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14),0,"In this paper, we present MADAMIRA, a system for morphological analysis and disambiguation of Arabic that combines some of the best aspects of two previously commonly used systems for Arabic processing, MADA (Habash and Rambow, 2005; Habash et al., 2009; Habash et al., 2013) and AMIRA (Diab et al., 2007). MADAMIRA improves upon the two systems with a more streamlined Java implementation that is more robust, portable, extensible, and is faster than its ancestors by more than an order of magnitude. We also discuss an online demo (see http://nlp.ldeo.columbia.edu/madamira/) that highlights these aspects."
E14-1023,Frame Semantic Tree Kernels for Social Network Extraction from Text,2014,23,17,5,0.8315,37109,apoorv agarwal,Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"In this paper, we present work on extracting social networks from unstructured text. We introduce novel features derived from semantic annotations based on FrameNet. We also introduce novel semantic tree kernels that help us improve the performance of the best reported system on social event detection and classification by a statistically significant margin. We show results for combining the models for the two aforementioned subtasks into the overall task of social network extraction. We show that a combination of features from all three levels of abstractions (lexical, syntactic and semantic) are required to achieve the best performing system."
D14-1157,Staying on Topic: An Indicator of Power in Political Debates,2014,18,9,3,1,90,vinodkumar prabhakaran,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We study the topic dynamics of interactions in political debates using the 2012 Republican presidential primary debates as data. We show that the tendency of candidates to shift topics changes over the course of the election campaign, and that it is correlated with their relative power. We also show that our topic shift features help predict candidatesxe2x80x99 relative rankings."
D14-1211,Gender and Power: How Gender and Gender Environment Affect Manifestations of Power,2014,28,11,3,1,90,vinodkumar prabhakaran,Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP}),0,"We investigate the interaction of power, gender, and language use in the Enron email corpus. We present a freely available extension to the Enron corpus, with the gender of senders of 87% messages reliably identified. Using this data, we test two specific hypotheses drawn from the sociolinguistic literature pertaining to gender and power: women managers use face-saving communicative strategies, and women use language more explicitly than men to create and maintain social relations. We introduce the notion of xe2x80x9cgender environmentxe2x80x9d to the computational study of written conversations; we interpret this notion as the gender makeup of an email thread, and show that some manifestations of power differ significantly between gender environments. Finally, we show the utility of gender information in the problem of automatically predicting the direction of power between pairs of participants in email interactions."
W13-4910,{SPMRL}{`}13 Shared Task System: The {CADIM} {A}rabic Dependency Parser,2013,18,3,3,0.909091,34833,yuval marton,Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,0,We describe the submission from the Columbia Arabic & Dialect Modeling group (CADIM) for the Shared Task at the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRLxe2x80x992013). We participate in the Arabic Dependency parsing task for predicted POS tags and features. Our system is based on Marton et al. (2013).
N13-1044,Morphological Analysis and Disambiguation for Dialectal {A}rabic,2013,36,78,3,0,517,nizar habash,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"The many differences between Dialectal Arabic and Modern Standard Arabic (MSA) pose a challenge to the majority of Arabic natural language processing tools, which are designed for MSA. In this paper, we retarget an existing state-of-the-art MSA morphological tagger to Egyptian Arabic (ARZ). Our evaluation demonstrates that our ARZ morphology tagger outperforms its MSA variant on ARZ input in terms of accuracy in part-of-speech tagging, diacritization, lemmatization and tokenization; and in terms of utility for ARZ-toEnglish statistical machine translation."
N13-1066,Processing Spontaneous Orthography,2013,32,24,3,1,8324,ramy eskander,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"In cases in which there is no standard orthography for a language or language variant, written texts will display a variety of orthographic choices. This is problematic for natural language processing (NLP) because it creates spurious data sparseness. We study the transformation of spontaneously spelled Egyptian Arabic into a conventionalized orthography which we have previously proposed for NLP purposes. We show that a two-stage process can reduce divergences from this standard by 69%, making subsequent processing of Egyptian Arabic easier."
N13-1099,Improving the Quality of Minority Class Identification in Dialog Act Tagging,2013,15,6,3,0,41617,adinoyi omuya,Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,"We present a method of improving the performance of dialog act tagging in identifying minority classes by using per-class feature optimization and a method of choosing the class based not on confidence, but on a cascade of classifiers. We show that it gives a minority class F-measure error reduction of 22.8%, while also reducing the error for other classes and the overall error by about 10%."
J13-1008,Dependency Parsing of {M}odern {S}tandard {A}rabic with Lexical and Inflectional Features,2013,38,30,3,0.909091,34833,yuval marton,Computational Linguistics,0,"We explore the contribution of lexical and inflectional morphology features to dependency parsing of Arabic, a morphologically rich language with complex agreement patterns. Using controlled experiments, we contrast the contribution of different part-of-speech POS tag sets and morphological features in two input conditions: machine-predicted condition in which POS tags and morphological feature values are automatically assigned, and gold condition in which their true values are known. We find that more informative fine-grained tag sets are useful in the gold condition, but may be detrimental in the predicted condition, where they are outperformed by simpler but more accurately predicted tag sets. We identify a set of features definiteness, person, number, gender, and undiacritized lemma that improve parsing quality in the predicted condition, whereas other features are more useful in gold. We are the first to show that functional features for gender and number e.g., broken plurals, and optionally the related rationality humanness feature, are more helpful for parsing than form-based gender and number. We finally show that parsing quality in the predicted condition can dramatically improve by training in a combined goldpredicted condition. We experimented with two transition-based parsers, MaltParser and Easy-First Parser. Our findings are robust across parsers, models, and input conditions. This suggests that the contribution of the linguistic knowledge in the tag sets and features we identified goes beyond particular experimental settings, and may be informative for other parsers and morphologically rich languages."
I13-2004,{DIRA}: Dialectal {A}rabic Information Retrieval Assistant,2013,12,4,6,1,35353,arfath pasha,The Companion Volume of the Proceedings of {IJCNLP} 2013: System Demonstrations,0,"DIRA is a query expansion tool that generates search terms in Standard Arabic and/or its dialects when provided with queries in English or Standard Arabic. The retrieval of dialectal Arabic text has recently become necessary due to the increase of dialectal content on social media. DIRA addresses the challenges of retrieving information in Arabic dialects, which have significant linguistic differences from Standard Arabic. To our knowledge, DIRA is the only tool in existence that automatically generates dialect search terms with relevant morphological variations from English or Standard Arabic query terms."
I13-2009,{SINNET}: Social Interaction Network Extractor from Text,2013,11,27,4,0.972222,37109,apoorv agarwal,The Companion Volume of the Proceedings of {IJCNLP} 2013: System Demonstrations,0,In this paper we present a demo of our system: Social Interaction Network Extractor from Text (SINNET). SINNET is able to extract a social network from unstructured text. Nodes in the network are people and links are social events.
I13-1025,Written Dialog and Social Power: Manifestations of Different Types of Power in Dialog Behavior,2013,24,14,2,1,90,vinodkumar prabhakaran,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"Dialog behavior is affected by power relations among the discourse participants. We show that four different types of power relations (hierarchical power, situational power, influence, and power over communication) affect written dialog behavior in different ways. We also present a system that can identify power relations given a written dialog."
I13-1171,Automatic Extraction of Social Networks from Literary Text: A Case Study on Alice in Wonderland,2013,35,27,3,0.972222,37109,apoorv agarwal,Proceedings of the Sixth International Joint Conference on Natural Language Processing,0,"In this paper we present results for two tasks: social event detection and social network extraction from a literary text, Alice in Wonderland. For the first task, our system trained on a news corpus using tree kernels and support vector machines beats the baseline systems by a statistically significant margin. Using this system we extract a social network from Alice in Wonderland. We show that while we achieve an F-measure of about 61% on social event detection, our extracted unweighted network is not statistically distinguishable from the un-weighted gold network according to popularly used network measures."
D13-1105,Automatic Extraction of Morphological Lexicons from Morphologically Annotated Corpora,2013,28,20,3,1,8324,ramy eskander,Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,0,"We present a method for automatically learning inflectional classes and associated lemmas from morphologically annotated corpora. The method consists of a core languageindependent algorithm, which can be optimized for specific languages. The method is demonstrated on Egyptian Arabic and German, two morphologically rich languages. Our best method for Egyptian Arabic provides an error reduction of 55.6% over a simple baseline; our best method for German achieves a 66.7% error reduction."
W12-4619,Creating a {T}ree {A}djoining {G}rammar from a Multilayer Treebank,2012,12,3,2,1,40828,rajesh bhatt,Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms ({TAG}+11),0,We propose a method for the extraction of a Tree Adjoining Grammar (TAG) from a dependency treebank which has some representative examples annotated with phrase structures. We show that the resulting TAG along with corresponding dependency structure can be used to convert a dependency treebank to a TAG-based phrase structure treebank.
W12-3807,Statistical Modality Tagging from Rule-based Annotations and Crowdsourcing,2012,19,15,7,1,90,vinodkumar prabhakaran,Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics,0,We explore training an automatic modality tagger. Modality is the attitude that a speaker might have toward an event or state. One of the main hurdles for training a linguistic tagger is gathering training data. This is particularly problematic for training a tagger for modality because modality triggers are sparse for the overwhelming majority of sentences. We investigate an approach to automatically training a modality tagger where we first gathered sentences based on a high-recall simple rule-based modality tagger and then provided these sentences to Mechanical Turk annotators for further annotation. We used the resulting set of training data to train a precise modality tagger using a multi-class SVM that delivers good performance.
W12-2513,Social Network Analysis of Alice in Wonderland,2012,15,45,4,1,37109,apoorv agarwal,Proceedings of the {NAACL}-{HLT} 2012 Workshop on Computational Linguistics for Literature,0,"We present a network analysis of a literary text, Alice in Wonderland. We build novel types of networks in which links between characters are different types of social events. We show that analyzing networks based on these social events gives us insight into the roles of characters in the story. Also, static network analysis has limitations which be- come apparent from our analysis. We propose the use of dynamic network analysis to over- come these limitations. tify these limitations, few have done so with a strict and specific rubric for categorizing interactions. In this paper, we annotate Lewis Carroll's Alice in Wonderland using a well-defined annotation scheme which we have previously developed on newswire text Agarwal et al. (2010). It is well suited to deal with the aforementioned limitations. We show that using different types of networks can be useful by al- lowing us to provide a model for determining point- of-view. We also show that social networks allow characters to be categorized into roles based on how they function in the text, but that this approach is limited when using static social networks. We then build and visualize dynamic networks and show that static networks can distort the importance of char- acters. By using dynamic networks, we can build a fuller picture of how each character works in a liter- ary text. Our paper uses an annotation scheme that is well- defined and has been used in previous computational models that extract social events from news articles (Agarwal and Rambow, 2010). This computational model may be adapted to extract these events from literary texts. However, the focus of this paper is not to adapt the previously proposed computational model to a new domain or genre, but to first demon- strate the usefulness of this annotation scheme for the analysis of literary texts, and the social networks derived from it. All results reported in this paper are based on hand annotation of the text. Further- more, we are investigating a single text, so that we do cannot draw conclusions about the usefulness of our methods for validating theories of literature. We summarize the contributions of this paper: xe2x80xa2 We manually extract a social network from Al-"
W12-2105,Detecting Influencers in Written Online Conversations,2012,12,21,5,0,20407,or biran,Proceedings of the Second Workshop on Language in Social Media,0,"It has long been established that there is a correlation between the dialog behavior of a participant and how influential he or she is perceived to be by other discourse participants. In this paper we explore the characteristics of communication that make someone an opinion leader and develop a machine learning based approach for the automatic identification of discourse participants that are likely to be influencers in online communication. Our approach relies on identification of three types of conversational behavior: persuasion, agreement/disagreement, and dialog patterns."
S12-1026,Unsupervised Induction of a Syntax-Semantics Lexicon Using Iterative Refinement,2012,15,5,2,0,31649,hagen furstenau,"*{SEM} 2012: The First Joint Conference on Lexical and Computational Semantics {--} Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation ({S}em{E}val 2012)",0,"We present a method for learning syntax-semantics mappings for verbs from unannotated corpora. We learn linkings, i. e., mappings from the syntactic arguments and adjuncts of a verb to its semantic roles. By learning such linkings, we do not need to model individual semantic roles independently of one another, and we can exploit the relation between different mappings for the same verb, or between mappings for different verbs. We present an evaluation on a standard test set for semantic role labeling."
P12-2032,A Comprehensive Gold Standard for the {E}nron Organizational Hierarchy,2012,11,20,4,1,37109,apoorv agarwal,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),0,"Many researchers have attempted to predict the Enron corporate hierarchy from the data. This work, however, has been hampered by a lack of data. We present a new, large, and freely available gold-standard hierarchy. Using our new gold standard, we show that a simple lower bound for social network-based systems outperforms an upper bound on the approach taken by current NLP systems."
N12-1057,Predicting Overt Display of Power in Written Dialogs,2012,12,26,2,1,90,vinodkumar prabhakaran,Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies,0,We analyze overt displays of power (ODPs) in written dialogs. We present an email corpus with utterances annotated for ODP and present a supervised learning system to predict it. We obtain a best cross validation F-measure of 65.8 using gold dialog act features and 55.6 without using them.
habash-etal-2012-conventional,Conventional Orthography for Dialectal {A}rabic,2012,16,76,3,0,517,nizar habash,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Dialectal Arabic (DA) refers to the day-to-day vernaculars spoken in the Arab world. DA lives side-by-side with the official language, Modern Standard Arabic (MSA). DA differs from MSA on all levels of linguistic representation, from phonology and morphology to lexicon and syntax. Unlike MSA, DA has no standard orthography since there are no Arabic dialect academies, nor is there a large edited body of dialectal literature that follows the same spelling standard. In this paper, we present CODA, a conventional orthography for dialectal Arabic; it is designed primarily for the purpose of developing computational models of Arabic dialects. We explain the design principles of CODA and provide a detailed description of its guidelines as applied to Egyptian Arabic."
prabhakaran-etal-2012-annotations,Annotations for Power Relations on Email Threads,2012,13,5,3,1,90,vinodkumar prabhakaran,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"Social relations like power and influence are difficult concepts to define, but are easily recognizable when expressed. In this paper, we describe a multi-layer annotation scheme for social power relations that are recognizable from online written interactions. We introduce a typology of four types of power relations between dialog participants: hierarchical power, situational power, influence and control of communication. We also present a corpus of Enron emails comprising of 122 threaded conversations, manually annotated with instances of these power relations between participants. Our annotations also capture attempts at exercise of power or influence and whether those attempts were successful or not. In addition, we also capture utterance level annotations for overt display of power. We describe the annotation definitions using two example email threads from our corpus illustrating each type of power relation. We also present detailed instructions given to the annotators and provide various statistics on annotations in the corpus."
bauer-etal-2012-dependency,The Dependency-Parsed {F}rame{N}et Corpus,2012,14,7,3,1,33764,daniel bauer,Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12),0,"When training semantic role labeling systems, the syntax of example sentences is of particular importance. Unfortunately, for the FrameNet annotated sentences, there is no standard parsed version. The integration of the automatic parse of an annotated sentence with its semantic annotation, while conceptually straightforward, is complex in practice. We present a standard dataset that is publicly available and that can be used in future research. This dataset contains parser-generated dependency structures (with POS tags and lemmas) for all FrameNet 1.5 sentences, with nodes automatically associated with FrameNet annotations."
C12-1138,Who{'}s (Really) the Boss? Perception of Situational Power in Written Interactions,2012,29,9,2,1,90,vinodkumar prabhakaran,Proceedings of {COLING} 2012,0,We study the perception of situational power in written dialogs in the context of organizational emails and contrast it to the power attributed by organizational hierarchy. We analyze various correlates of the perception of power in the dialog structure and language use by participants in the dialog. We also present an SVM-based machine learning system using dialog structure and lexical features to predict persons with situational power in a given communication thread.
W11-4416,Fast Yet Rich Morphological Analysis,2011,19,12,3,1,26618,mohamed altantawy,Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Processing,0,"Implementations of models of morphologically rich languages such as Arabic typically achieve speed and small memory footprint at the cost of abandoning linguistically abstract and elegant representations. We present a solution to modeling rich morphologies that is both fast and based on linguistically rich representations. In our approach, we convert a linguistically complex and abstract implementation of Arabic verbs in finite-state machinery into a simple precompiled tabular representation."
W11-2127,Fuzzy Syntactic Reordering for Phrase-based Statistical Machine Translation,2011,26,8,3,0.784314,3933,jacob andreas,Proceedings of the Sixth Workshop on Statistical Machine Translation,0,"The quality of Arabic-English statistical machine translation often suffers as a result of standard phrase-based SMT systems' inability to perform long-range re-orderings, specifically those needed to translate VSO-ordered Arabic sentences. This problem is further exacerbated by the low performance of Arabic parsers on subject and subject span detection. In this paper, we present two parse fuzzification techniques which allow the translation system to select among a range of possible S--V re-orderings. With this approach, we demonstrate a 0.3-point improvement in BLEU score (69% of the maximum possible using gold parses), and a corresponding improvement in the percentage of syntactically well-formed subjects under a manual evaluation."
W11-0905,{V}ig{N}et: Grounding Language in Graphics using Frame Semantics,2011,19,20,3,0.952381,24826,bob coyne,Proceedings of the {ACL} 2011 Workshop on Relational Models of Semantics,0,"This paper introduces Vignette Semantics, a lexical semantic theory based on Frame Semantics that represents conceptual and graphical relations. We also describe a lexical resource that implements this theory, VigNet, and its application in text-to-scene generation."
W11-0705,Sentiment Analysis of {T}witter Data,2011,15,883,4,1,37109,apoorv agarwal,Proceedings of the Workshop on Language in Social Media ({LSM} 2011),0,"We examine sentiment analysis on Twitter data. The contributions of this paper are: (1) We introduce POS-specific prior polarity features. (2) We explore the use of a tree kernel to obviate the need for tedious feature engineering. The new features (in conjunction with previously proposed features) and the tree kernel perform approximately at the same level, both outperforming the state-of-the-art baseline."
P11-1159,Improving {A}rabic Dependency Parsing with Form-based and Functional Morphological Features,2011,25,12,3,0.909091,34833,yuval marton,Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,1,"We explore the contribution of morphological features -- both lexical and inflectional -- to dependency parsing of Arabic, a morphologically rich language. Using controlled experiments, we find that definiteness, person, number, gender, and the undiacritzed lemma are most helpful for parsing on automatically tagged input. We further contrast the contribution of form-based and functional features, and show that functional gender and number (e.g., broken plurals) and the related rationality feature improve over form-based features. It is the first time functional morphological features are used for Arabic NLP."
I11-1138,"Linguistic Phenomena, Analyses, and Representations: Understanding Conversion between Treebanks",2011,12,9,2,1,40828,rajesh bhatt,Proceedings of 5th International Joint Conference on Natural Language Processing,0,"Treebanks are valuable resources for natural language processing (NLP). There is much work in NLP which converts treebanks from one representation (e.g., phrase structure) to another (e.g., dependency) before applying machine learning. This paper provides a framework in which to think about the question of when such a conversion is possible."
W10-1803,Annotation Scheme for Social Network Extraction from Text,2010,11,13,2,1,37109,apoorv agarwal,Proceedings of the Fourth Linguistic Annotation Workshop,0,"We are interested in extracting social networks from text. We present a novel annotation scheme for a new type of event, called social event, in which two people participate such that at least one of them is cognizant of the other. We compare our scheme in detail to the ACE scheme. We perform a detailed analysis of interannotator agreement, which shows that our annotations are reliable."
W10-1402,Improving {A}rabic Dependency Parsing with Lexical and Inflectional Morphological Features,2010,19,34,3,0.784314,34833,yuval marton,Proceedings of the {NAACL} {HLT} 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,0,"We explore the contribution of different lexical and inflectional morphological features to dependency parsing of Arabic, a morphologically rich language. We experiment with all leading POS tagsets for Arabic, and introduce a few new sets. We show that training the parser using a simple regular expressive extension of an impoverished POS tagset with high prediction accuracy does better than using a highly informative POS tagset with only medium prediction accuracy, although the latter performs best on gold input. Using controlled experiments, we find that definiteness (or determiner presence), the so-called phi-features (person, number, gender), and undi-acritzed lemma are most helpful for Arabic parsing on predicted input, while case and state are most helpful on gold."
N10-1049,The Simple Truth about Dependency and Phrase Structure Representations: An Opinion Piece,2010,7,27,1,1,1354,owen rambow,Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics,0,"There are many misconceptions about dependency representations and phrase structure representations for syntax. They are partly due to terminological confusion, partly due to a lack of meta-scientific clarity about the roles of representations and linguistic theories. This opinion piece argues for a simple but clear view of syntactic representation."
altantawy-etal-2010-morphological,Morphological Analysis and Generation of {A}rabic Nouns: A Morphemic Functional Approach,2010,15,25,3,1,26618,mohamed altantawy,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"MAGEAD is a morphological analyzer and generator for Modern Standard Arabic (MSA) and its dialects. We introduced MAGEAD in previous work with an implementation of MSA and Levantine Arabic verbs. In this paper, we port that system to MSA nominals (nouns and adjectives), which are far more complex to model than verbs. Our system is a functional morphological analyzer and generator, i.e., it analyzes to and generates from a representation consisting of a lexeme and linguistic feature-value pairs, where the features are syntactically (and perhaps semantically) meaningful, rather than just morphologically. A detailed evaluation of the current implementation comparing it to a commonly used morphological analyzer shows that it has good morphological coverage with precision and recall scores in the 90s. An error analysis reveals that the majority of recall and precision errors are problems in the gold standard or a result of the discrepancy between different models of form-based/functional morphology."
bhatia-etal-2010-empty,Empty Categories in a {H}indi Treebank,2010,8,9,5,0,11651,archna bhatia,Proceedings of the Seventh International Conference on Language Resources and Evaluation ({LREC}'10),0,"We are in the process of creating a multi-representational and multi-layered treebank for Hindi/Urdu (Palmer et al., 2009), which has three main layers: dependency structure, predicate-argument structure (PropBank), and phrase structure. This paper discusses an important issue in treebank design which is often neglected: the use of empty categories (ECs). All three levels of representation make use of ECs. We make a high-level distinction between two types of ECs, trace and silent, on the basis of whether they are postulated to mark displacement or not. Each type is further refined into several subtypes based on the underlying linguistic phenomena which the ECs are introduced to handle. This paper discusses the stages at which we add ECs to the Hindi/Urdu treebank and why. We investigate methodically the different types of ECs and their role in our syntactic and semantic representations. We also examine our decisions whether or not to coindex each type of ECs with other elements in the representation."
D10-1100,Automatic Detection and Classification of Social Events,2010,29,29,2,1,37109,apoorv agarwal,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"In this paper we introduce the new task of social event extraction from text. We distinguish two broad types of social events depending on whether only one or both parties are aware of the social contact. We annotate part of Automatic Content Extraction (ACE) data, and perform experiments using Support Vector Machines with Kernel methods. We use a combination of structures derived from phrase structure trees and dependency trees. A characteristic of our events (which distinguishes them from ACE events) is that the participating entities can be spread far across the parse trees. We use syntactic and semantic insights to devise a new structure derived from dependency trees and show that this plays a role in achieving the best performing system for both social event detection and classification tasks. We also use three data sampling approaches to solve the problem of data skewness. Sampling methods improve the F1-measure for the task of relation detection by over 20% absolute over the baseline."
D10-1112,Word-Based Dialect Identification with Georeferenced Rules,2010,11,7,2,0,263,yves scherrer,Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,0,"We present a novel approach for (written) dialect identification based on the discriminative potential of entire words. We generate Swiss German dialect words from a Standard German lexicon with the help of hand-crafted phonetic/graphemic rules that are associated with occurrence maps extracted from a linguistic atlas created through extensive empirical fieldwork. In comparison with a character-n-gram approach to dialect identification, our model is more robust to individual spelling differences, which are frequently encountered in non-standardized dialect writing. Moreover, it covers the whole Swiss German dialect continuum, which trained models struggle to achieve due to sparsity of training data."
C10-2117,Automatic Committed Belief Tagging,2010,23,33,2,1,90,vinodkumar prabhakaran,Coling 2010: Posters,0,"We go beyond simple propositional meaning extraction and present experiments in determining which propositions in text the author believes. We show that deep syntactic parsing helps for this task. Our best feature combination achieves an F-measure of 64%, a relative reduction in F-measure error of 21% over not using syntactic features."
W09-3953,Contrasting the Interaction Structure of an Email and a Telephone Corpus: A Machine Learning Approach to Annotation of Dialogue Function Units,2009,26,15,3,0,34691,jun hu,Proceedings of the {SIGDIAL} 2009 Conference,0,"We present a dialogue annotation scheme for both spoken and written interaction, and use it in a telephone transaction corpus and an email corpus. We train classifiers, comparing regular SVM and structured SVM against a heuristic baseline. We provide a novel application of structured SVM to predicting relations between instance pairs."
W09-3012,Committed Belief Annotation and Tagging,2009,12,45,4,0.133333,7377,mona diab,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"We present a preliminary pilot study of belief annotation and automatic tagging. Our objective is to explore semantic meaning beyond surface propositions. We aim to model people's cognitive states, namely their beliefs as expressed through linguistic means. We model the strength of their beliefs and their (the human) degree of commitment to their utterance. We explore only the perspective of the author of a text. We classify predicates into one of three possibilities: committed belief, non committed belief, or not applicable. We proceed to manually annotate data to that end, then we build a supervised framework to test the feasibility of automatically predicting these belief states. Even though the data is relatively small, we show that automatic prediction of a belief class is a feasible task. Using syntactic features, we are able to obtain significant improvements over a simple baseline of 23% F-measure absolute points. The best performing automatic tagging condition is where we use POS tag, word type feature AlphaNumeric, and shallow syntactic chunk information CHUNK. Our best overall performance is 53.97% F-measure."
W09-3036,A Multi-Representational and Multi-Layered Treebank for {H}indi/{U}rdu,2009,11,89,4,1,40828,rajesh bhatt,Proceedings of the Third Linguistic Annotation Workshop ({LAW} {III}),0,"This paper describes the simultaneous development of dependency structure and phrase structure treebanks for Hindi and Urdu, as well as a PropBank. The dependency structure and the PropBank are manually annotated, and then the phrase structure treebank is produced automatically. To ensure successful conversion the development of the guidelines for all three representations are carefully coordinated."
N09-2047,{MICA}: A Probabilistic Dependency Parser Based on Tree Insertion Grammars (Application Note),2009,16,20,4,0.360579,4704,srinivas bangalore,"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers",0,"MICA is a dependency parser which returns deep dependency representations, is fast, has state-of-the-art performance, and is freely available."
W08-2318,Is Coordination Quantification?,2008,15,0,2,0,47313,kevin lerman,Proceedings of the Ninth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+9),0,"We explore the semantics of conjunction using a neo-Davidsonian semantics expressed in a synchronous grammar. We propose to model conjunction as quantification over the set of conjoined entities, and discuss problems that arise in this approach when we have conjoined quantified noun phrases."
P08-2030,"{A}rabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking",2008,7,128,2,0.681818,39729,ryan roth,"Proceedings of ACL-08: HLT, Short Papers",0,"We investigate the tasks of general morphological tagging, diacritization, and lemmatization for Arabic. We show that for all tasks we consider, both modeling the lexeme explicitly, and retuning the weights of individual classifiers for the specific task, improve the performance."
farber-etal-2008-improving,Improving {NER} in {A}rabic Using a Morphological Tagger,2008,10,28,4,0,48017,benjamin farber,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We discuss a named entity recognition system for Arabic, and show how we incorporated the information provided by MADA, a full morphological tagger which uses a morphological analyzer. Surprisingly, the relevant features used are the capitalization of the English gloss chosen by the tagger, and the fact that an analysis is returned (that a word is not OOV to the morphological analyzer). The use of the tagger also improves over a third system which just uses a morphological analyzer, yielding a 14{\textbackslash}{\%} reduction in error over the baseline. We conduct a thorough error analysis to identify sources of success and failure among the variations, and show that by combining the systems in simple ways we can significantly influence the precision-recall trade-off."
ramos-etal-2008-using,Using Semantically Annotated Corpora to Build Collocation Resources,2008,9,12,2,0,46267,margarita ramos,Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08),0,"We present an experiment in extracting collocations from the FrameNet corpus, specifically, support verbs such as direct in Environmentalists directed strong criticism at world leaders. Support verbs do not contribute meaning of their own and the meaning of the construction is provided by the noun; the recognition of support verbs is thus useful in text understanding. Having access to a list of support verbs is also useful in applications that can benefit from paraphrasing, such as generation (where paraphrasing can provide variety). This paper starts with a brief presentation of the notion of lexical function in Meaning-Text Theory, where they fall under the notion of lexical function, and then discusses how relevant information is encoded in the FrameNet corpus. We describe the resource extracted from the FrameNet corpus."
P07-1105,Grammar Approximation by Representative Sublanguage: A New Model for Language Learning,2007,14,9,2,0,1561,smaranda muresan,Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,1,"We propose a new language learning model that learns a syntactic-semantic grammar from a small number of natural language strings annotated with their semantics, along with basic assumptions about natural language syntax. We show that the search space for grammar induction is a complete grammar lattice, which guarantees the uniqueness of the learned grammar."
N07-2014,{A}rabic Diacritization through Full Morphological Tagging,2007,9,101,2,0.341678,517,nizar habash,"Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers",0,We present a diacritization system for written Arabic which is based on a lexical resource. It combines a tagger and a lexeme language model. It improves on the best results reported in the literature.
N07-1054,Building and Refining Rhetorical-Semantic Relation Models,2007,20,29,3,0,45820,sasha blairgoldensohn,Human Language Technologies 2007: The Conference of the North {A}merican Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,0,"We report results of experiments which build and refine models of rhetoricalsemantic relations such as Cause and Contrast. We adopt the approach of Marcu and Echihabi (2002), using a small set of patterns to build relation models, and extend their work by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing. Using human-annotated and automatically-extracted test sets, we find that each of these techniques results in improved relation classification accuracy."
D07-1116,Determining Case in {A}rabic: Learning Complex Linguistic Behavior Requires Complex Linguistic Features,2007,9,27,3,0.341678,517,nizar habash,Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({EMNLP}-{C}o{NLL}),0,"This paper discusses automatic determination of case in Arabic. This task is a major source of errors in full diacritization of Arabic. We use a gold-standard syntactic tree, and obtain an error rate of about 4.2%, with a machine learning based system outperforming a system using hand-written rules. A careful error analysis suggests that when we account for annotation errors in the gold standard, the error rate drops to 0.8%, with the hand-written rules outperforming the machine learning-based system."
2007.mtsummit-papers.39,Semi-automatic error analysis for large-scale statistical machine translation,2007,-1,-1,2,0,3723,katrin kirchhoff,Proceedings of Machine Translation Summit XI: Papers,0,None
W06-1501,The Hidden {TAG} Model: Synchronous Grammars for Parsing Resource-Poor Languages,2006,14,4,2,0,3180,david chiang,Proceedings of the Eighth International Workshop on Tree Adjoining Grammar and Related Formalisms,0,"This paper discusses a novel probabilistic synchronous TAG formalism, synchronous Tree Substitution Grammar with sister adjunction (TSGSA). We use it to parse a language for which there is no training data, by leveraging off a second, related language for which there is abundant training data. The grammar for the resource-rich side is automatically extracted from a treebank; the grammar on the resource-poor side and the synchronization are created by handwritten rules. Our approach thus represents a combination of grammar-based and empirical natural language processing. We discuss the approach using the example of Levantine Arabic and Standard Arabic."
W06-1503,The Metagrammar Goes Multilingual: A Cross-Linguistic Look at the V2-Phenomenon,2006,8,9,2,1,49777,alexandra kinyon,Proceedings of the Eighth International Workshop on Tree Adjoining Grammar and Related Formalisms,0,"We present an initial investigation into the use of a metagrammar for explicitly sharing abstract grammatical specifications among languages. We define a single class hierarchy for a metagrammar which allows us to automatically generate grammars for different languages from a single compact metagrammar hierarchy. We use as our linguistic example the verb-second phenomenon, which shows considerable variation while retaining a basic property, namely the fact that the verb can appear in one of two positions in the clause."
P06-1086,{MAGEAD}: A Morphological Analyzer and Generator for the {A}rabic Dialects,2006,16,94,2,0.464801,517,nizar habash,Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,1,"We present MAGEAD, a morphological analyzer and generator for the Arabic language family. Our work is novel in that it explicitly addresses the need for processing the morphology of the dialects. MAGEAD performs an on-line analysis to or generation from a rootpatternfeatures representation, it has separate phonological and orthographic representations, and it allows for combining morphemes from different dialects. We present a detailed evaluation of MAGEAD."
maamouri-etal-2006-developing,Developing and Using a Pilot Dialectal {A}rabic Treebank,2006,12,33,6,0.247954,34888,mohamed maamouri,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"In this paper, we describe the methodological procedures and issues that emerged from the development of a pilot Levantine Arabic Treebank (LATB) at the Linguistic Data Consortium (LDC) and its use at the Johns Hopkins University (JHU) Center for Language and Speech Processing workshop on Parsing Arabic Dialects (PAD). This pilot, consisting of morphological and syntactic annotation of approximately 26,000 words of Levantine Arabic conversational telephone speech, was developed under severe time constraints; hence the LDC team drew on their experience in treebanking Modern Standard Arabic (MSA) text. The resulting Levantine dialect treebanked corpus was used by the PAD team to develop and evaluate parsers for Levantine dialect texts. The parsers were trained on MSA resources and adapted using dialect-MSA lexical resources (some developed especially for this task) and existing linguistic knowledge about syntactic differences between MSA and dialect. The use of the LATB for development and evaluation of syntactic parsers allowed the PAD team to provide feedbasck to the LDC treebank developers. In this paper, we describe the creation of resources for this corpus, as well as transformations on the corpus to eliminate speech effects and lessen the gap between our pre-existing MSA resources and the new dialectal corpus"
passonneau-etal-2006-inter,Inter-annotator Agreement on a Multilingual Semantic Annotation Task,2006,15,40,3,0,721,rebecca passonneau,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"Six sites participated in the Interlingual Annotation of Multilingual Text Corpora (IAMTC) project (Dorr et al., 2004; Farwell et al., 2004; Mitamura et al., 2004). Parsed versions of English translations of news articles in Arabic, French, Hindi, Japanese, Korean and Spanish were annotated by up to ten annotators. Their task was to match open-class lexical items (nouns, verbs, adjectives, adverbs) to one or more concepts taken from the Omega ontology (Philpot et al., 2003), and to identify theta roles for verb arguments. The annotated corpus is intended to be a resource for meaning-based approaches to machine translation. Here we discuss inter-annotator agreement for the corpus. The annotation task is characterized by annotators freedom to select multiple concepts or roles per lexical item. As a result, the annotation categories are sets, the number of which is bounded only by the number of distinct annotator-lexical item pairs. We use a reliability metric designed to handle partial agreement between sets. The best results pertain to the part of the ontology derived from WordNet. We examine change over the course of the project, differences among annotators, and differences across parts of speech. Our results suggest a strong learning effect early in the project."
rambow-etal-2006-parallel,Parallel Syntactic Annotation of Multiple Languages,2006,12,10,1,1,1354,owen rambow,Proceedings of the Fifth International Conference on Language Resources and Evaluation ({LREC}{'}06),0,"This paper describes an effort to investigate the incrementally deepening development of an interlingua notation, validated by human annotation of texts in English plus six languages. We begin with deep syntactic annotation, and in this paper present a series of annotation manuals for six different languages at the deep-syntactic level of representation. Many syntactic differences between languages are removed in the proposed syntactic annotation, making them useful resources for multilingual NLP projects with semantic components."
E06-1047,Parsing {A}rabic Dialects,2006,30,81,4,0,3180,david chiang,11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,"The Arabic language is a collection of spoken dialects with important phonological, morphological, lexical, and syntactic differences, along with a standard written language, Modern Standard Arabic (MSA). Since the spoken dialects are not officially written, it is very costly to obtain adequate corpora to use for training dialect NLP tools such as parsers. In this paper, we address the problem of parsing transcribed spoken Levantine Arabic (LA).We do not assume the existence of any annotated LA corpus (except for development and testing), nor of a parallel corpus LAMSA. Instead, we use explicit knowledge about the relation between LA and MSA."
W05-0703,Morphological Analysis and Generation for {A}rabic Dialects,2005,14,50,2,0.464801,517,nizar habash,Proceedings of the {ACL} Workshop on Computational Approaches to {S}emitic Languages,0,"We present Magead, a morphological analyzer and generator for the Arabic language family. Our work is novel in that it explicitly addresses the need for processing the morphology of the dialects. Magead provides an analysis to a rootpattern representation, it has separate phonological and orthographic representations, and it allows for combining morphemes from different dialects."
P05-1071,"{A}rabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop",2005,8,354,2,0.464801,517,nizar habash,Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics ({ACL}{'}05),1,"We present an approach to using a morphological analyzer for tokenizing and morphologically tagging (including part-of-speech tagging) Arabic words in one process. We learn classifiers for individual morphological features, as well as ways of using these classifiers to choose among entries from the output of the analyzer. We obtain accuracy rates on all tasks in the high nineties."
W04-3308,{S}uper{T}agging and Full Parsing,2004,17,19,2,1,5812,alexis nasr,Proceedings of the 7th International Workshop on Tree Adjoining Grammar and Related Formalisms,0,"We investigate an approach to parsing in which lexical information is used only in a first phase, supertagging, in which lexical syntactic properties are determined without building structure. In the second phase, the best parse tree is determined without using lexical information. We investigate different probabilistic models for adjunction, and we show that, assuming hypothetically perfect performance in the first phase, the error rate on dependency arc attachment can be reduced to 2.3% using a full chart parser. This is an improvement of about 50% over previously reported results using a simple heuristic parser."
W04-2709,Interlingual Annotation of Multilingual Text Corpora,2004,14,20,10,0,50484,stephen helmreich,Proceedings of the Workshop Frontiers in Corpus Annotation at {HLT}-{NAACL} 2004,0,"This paper describes a multi-site project to annotate six sizable bilingual parallel corpora for interlingual content. After presenting the background and objectives of the effort, we will go on to describe the data set that is being annotated, the interlingua representation language used, an interface environment that supports the annotation task and the annotation process itself. We will then present a preliminary version of our evaluation methodology and conclude with a summary of the current status of the project along with a number of issues which have arisen."
W04-1503,A Simple String-Rewriting Formalism for Dependency Grammar,2004,-1,-1,2,1,5812,alexis nasr,Proceedings of the Workshop on Recent Advances in Dependency Grammar,0,None
N04-4027,Summarizing Email Threads,2004,7,85,1,1,1354,owen rambow,Proceedings of {HLT}-{NAACL} 2004: Short Papers,0,"Summarizing threads of email is different from summarizing other types of written communication as it has an inherent dialog structure. We present initial research which shows that sentence extraction techniques can work for email threads as well, but profit from email-specific features. In addition, the presentation of the summary should take into account the dialogic structure of email communication."
reeder-etal-2004-interlingual,Interlingual annotation for {MT} development,2004,16,7,10,0,46657,florence reeder,Proceedings of the 6th Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"MT systems that use only superficial representations, including the current generation of statistical MT systems, have been successful and useful. However, they will experience a plateau in quality, much like other {``}silver bullet{''} approaches to MT. We pursue work on the development of interlingual representations for use in symbolic or hybrid MT systems. In this paper, we describe the creation of an interlingua and the development of a corpus of semantically annotated text, to be validated in six languages and evaluated in several ways. We have established a distributed, well-functioning research methodology, designed a preliminary interlingua notation, created annotation manuals and tools, developed a test collection in six languages with associated English translations, annotated some 150 translations, and designed and applied various annotation metrics. We describe the data sets being annotated and the interlingual (IL) representation language which uses two ontologies and a systematic theta-role list. We present the annotation tools built and outline the annotation process. Following this, we describe our evaluation methodology and conclude with a summary of issues that have arisen."
W03-2417,The {M}eta{G}rammar: a cross-framework and cross-language test-suite generation tool,2003,0,5,2,1,49777,alexandra kinyon,Proceedings of 4th International Workshop on Linguistically Interpreted Corpora ({LINC}-03) at {EACL} 2003,0,None
W03-1006,Use of Deep Linguistic Features for the Recognition and Labeling of Semantic Arguments,2003,14,76,2,1,15412,john chen,Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,0,"We use deep linguistic features to predict semantic roles on syntactic arguments, and show that these perform considerably better than surface-oriented features. We also show that predicting labels from a lightweight parser that generates deep syntactic features performs comparably to using a full parser that generates only surface syntactic features."
W02-2214,Context-Free Parsing of a {T}ree {A}djoining {G}rammar Using Finite-State Machines,2002,15,3,2,1,5812,alexis nasr,Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+6),0,None
W02-2235,Cross-serial dependencies in {T}agalog,2002,6,7,2,0,52773,anna maclachlan,Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+6),0,None
W02-2236,Reranking an n-gram supertagger,2002,21,15,4,1,15412,john chen,Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+6),0,"As shown by Srinivas (1997), standard n-gram modeling may be used to perform supertag disambiguation with accuracy that is adequate for partial parsing, but in general not sufficient for full parsing. A serious problem is that n-gram modeling usually considers a very small, fixed context and does not perform well with large tag sets, such as those generated by automatic grammar extraction (Xia, 1999; Chen and Vijay-Shanker, 2000; Chiang, 2000). As an alternative, Chen, Bangalore and Vijay-Shanker (1999) introduce class-based supertagging. An example of class tagging is n-best trigram-based supertagging, which assigns to each word the top n most likely supertags as determined by an n-gram supertagging model. Class-based supertagging can be performed much more accurately than supertagging with only a small increase in ambiguity. In a second phase, the most likely candidate from the class is chosen. In this paper, we investigate an approach to such a choice based on reranking a set of candidate supertags and their confidence scores. RankBoost (Freund et al., 1998) is the boosting algorithm that we use in order to learn to rerank outputs. It also has been used with good effect in reranking outputs of a statistical parser (Collins, 2000) and ranking sentence plans (Walker, Rambow and Rogati, 2001). RankBoost may learn to correct biases that are inherent in n-gram modeling which lead to systematic errors in supertagging (cf. (van Halteren, 1996)). RankBoost can also use a variety of local and long distance features more easily than n-gram-based approaches (cf. (Chen, Bangalore and Vijay-Shanker, 1999)) because it makes sparse data less of an issue. The outline of this paper is as follows. First, we develop the background and motivations behind the task of reranking the output of an n-best trigram supertagger. Second, we introduce RankBoost as the approach that we adopt in order to train the reranker. Third, we perform an initial set of experiments where the reranker is trained with different feature subsets. Fourth, we perform an in-depth analysis of several reranking models. Fifth, after pointing out causes that at times render the reranker ineffective, we develop and test some new models that attempt to sidestep these limitations. Lastly, after some significance testing results, we state our conclusions and remark on potential future directions."
rambow-etal-2002-dependency,A Dependency Treebank for {E}nglish,2002,10,32,1,1,1354,owen rambow,Proceedings of the Third International Conference on Language Resources and Evaluation ({LREC}{'}02),0,"This paper presents the syntactic annotation level of a project aimed at providing a small dialog corpus with multiple levels of annotation. The syntactic annotation is based on dependency syntax. We outline the reasons for choosing dependency, and show the syntactic annotation for some constructions. We finish by describing the current state of the project."
C02-2026,Creating a Finite-State Parser with Application Semantics,2002,7,10,1,1,1354,owen rambow,{COLING} 2002: The 17th International Conference on Computational Linguistics: Project Notes,0,"Parsli is a finite-state (FS) parser which can be tailored to the lexicon, syntax, and semantics of a particular application using a hand-editable declarative lexicon. The lexicon is defined in terms of a lexicalized Tree Adjoining Grammar, which is subsequently mapped to a FS representation. This approach gives the application designer better and easier control over the natural language understanding component than using an off-the-shelf parser. We present results using Parsli on an application that creates 3D-images from typed input."
C02-1138,Towards Automatic Generation of Natural Language Generation Systems,2002,17,27,3,1,15412,john chen,{COLING} 2002: The 19th International Conference on Computational Linguistics,0,"Systems that interact with the user via natural language are in their infancy. As these systems mature and become more complex, it would be desirable for a system developer if there were an automatic method for creating natural language generation components that can produce quality output efficiently. We conduct experiments that show that this goal appears to be realizable. In particular we discuss a natural language generation system that is composed of SPoT, a trainable sentence planner, and FER-GUS, a stochastic surface, realizer. We show how these stochastic NLG components can be made to work together, that they can be ported to new domains with apparent ease, and that such NLG components can be integrated in a real-time dialog system."
W01-0801,Corpus-Based Methods in Natural Language Generation: {F}riends or Foe? (invited talk),2001,0,1,1,1,1354,owen rambow,Proceedings of the {ACL} 2001 Eighth {E}uropean Workshop on Natural Language Generation ({EWNLG}),0,None
W01-0520,Impact of Quality and Quantity of Corpora on Stochastic Generation,2001,0,11,3,0.95501,4704,srinivas bangalore,Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing,0,None
P01-1038,Generation of {VP} Ellipsis: A Corpus-Based Approach,2001,10,6,2,0.5,416,daniel hardt,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"We present conditions under which verb phrases are elided based on a corpus of positive and negative examples. Factor that affect verb phrase ellipsis include: the distance between antecedent and ellipsis site, the syntactic relation between antecedent and ellipsis site, and the presence or absence of adjuncts. Building on these results, we examine where in the generation architecture a trainable algorithm for VP ellipsis should be located. We show that the best performance is achieved when the trainable module is located after the realizer and has access to surface-oriented features (error rate of 7.5%)."
P01-1056,Evaluating a Trainable Sentence Planner for a Spoken Dialogue System,2001,15,18,1,1,1354,owen rambow,Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,1,"Techniques for automatically training modules of a natural language generator have recently been proposed, but a fundamental concern is whether the quality of utterances produced with trainable components can compete with hand-crafted template-based or rule-based approaches. In this paper We experimentally evaluate a trainable sentence planner for a spoken dialogue system by eliciting subjective human judgments. In order to perform an exhaustive comparison, we also evaluate a hand-crafted template-based generation component, two rule-based sentence planners, and two baseline sentence planners. We show that the trainable sentence planner performs better than the rule-based systems and the baselines, and as well as the hand-crafted system."
N01-1003,{SP}o{T}: A Trainable Sentence Planner,2001,13,101,2,0,6000,marilyn walker,Second Meeting of the North {A}merican Chapter of the Association for Computational Linguistics,0,"Sentence planning is a set of inter-related but distinct tasks, one of which is sentence scoping, i.e. the choice of syntactic structure for elementary speech acts and the decision of how to combine them into one or more sentences. In this paper, we present SPoT, a sentence planner, and a new methodology for automatically training SPoT on the basis of feedback provided by human judges. We reconceptualize the task into two distinct phases. First, a very simple, randomized sentence-plan-generator (SPG) generates a potentially large list of possible sentence plans for a given text-plan input. Second, the sentence-plan-ranker (SPR) ranks the list of output sentence plans, and then selects the top-ranked plan. The SPR uses ranking rules automatically learned from training data. We show that the trained SPR learns to select a sentence plan whose rating on average is only 5% worse than the top human-ranked sentence plan."
J01-1004,{D}-Tree Substitution Grammars,2001,40,38,1,1,1354,owen rambow,Computational Linguistics,0,"There is considerable interest among computational linguists in lexicalized grammatical frame-works; lexicalized tree adjoining grammar (LTAG) is one widely studied example. In this paper, we investigate how derivations in LTAG can be viewed not as manipulations of trees but as manipulations of tree descriptions. Changing the way the lexicalized formalism is viewed raises questions as to the desirability of certain aspects of the formalism. We present a new formalism, d-tree substitution grammar (DSG). Derivations in DSG involve the composition of d-trees, special kinds of tree descriptions. Trees are read off from derived d-trees. We show how the DSG formalism, which is designed to inherit many of the characterestics of LTAG, can be used to express a variety of linguistic analyses not available in LTAG."
H01-1055,Natural Language Generation in Dialog Systems,2001,18,35,1,1,1354,owen rambow,Proceedings of the First International Conference on Human Language Technology Research,0,"Recent advances in Automatic Speech Recognition technology have put the goal of naturally sounding dialog systems within reach. However, the improved speech recognition has brought to light a new problem: as dialog systems understand more of what the user tells them, they need to be more sophisticated at responding to the user. The issue of system response to users has been extensively studied by the natural language generation community, though rarely in the context of dialog systems. We show how research in generation can be adapted to dialog systems, and how the high cost of hand-crafting knowledge-based generation systems can be overcome by employing machine learning techniques."
W00-2004,"Using {TAG}s, a Tree Model, and a Language Model for Generation",2000,4,41,2,0.95501,4704,srinivas bangalore,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,None
W00-2013,The {S}ino-{K}orean light verb construction and lexical argument structure,2000,6,11,2,0,31427,chunghye han,Proceedings of the Fifth International Workshop on Tree Adjoining Grammar and Related Frameworks ({TAG}+5),0,None
W00-1401,Evaluation Metrics for Generation,2000,11,138,2,0.95501,4704,srinivas bangalore,{INLG}{'}2000 Proceedings of the First International Conference on Natural Language Generation,0,"Certain generation applications may profit from the use of stochastic methods. In developing stochastic methods, it is crucial to be able to quickly assess the relative merits of different approaches or models. In this paper, we present several types of intrinsic (system internal) metrics which we have used for baseline quantitative assessment. This quantitative assessment should then be augmented to a fuller evaluation that examines qualitative aspects. To this end, we describe an experiment that tests correlation between the quantitative metrics and human qualitative judgment. The experiment confirms that intrinsic metrics cannot replace human evaluation, but some correlate significantly with human judgments of quality and understandability and can be used for evaluation during development."
P00-1059,Corpus-Based Lexical Choice in Natural Language Generation,2000,7,73,2,0.95501,4704,srinivas bangalore,Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,1,"Choosing the best lexeme to realize a meaning in natural language generation is a hard task. We investigate different tree-based stochastic models for lexical choice. Because of the difficulty of obtaining a sense-tagged corpus, we generalize the notion of synonymy. We show that a tree-based model can achieve a word-bag based accuracy of 90%, representing an improvement over the baseline."
C00-1007,Exploiting a Probabilistic Hierarchical Model for Generation,2000,12,183,2,0.95501,4704,srinivas bangalore,{COLING} 2000 Volume 1: The 18th International Conference on Computational Linguistics,0,"Previous stochastic approaches to generation do not include a tree-based representation of syntax. While this may be adequate or even advantageous for some applications, other applications profit from using as much syntactic knowledge as is available, leaving to a stochastic model only those issues that are not determined by the grammar. We present initial results showing that a tree-based model derived from a tree-annotated corpus improves on a tree model derived from an unannotated corpus, and that a tree-based stochastic model with a hand-crafted grammar outperforms both."
A00-1009,A Framework for {MT} and Multilingual {NLG} Systems Based on Uniform Lexico-Structural Processing,2000,10,19,4,1,51615,benoit lavoie,Sixth Applied Natural Language Processing Conference,0,"In this paper we describe an implemented framework for developing monolingual or multilingual natural language generation (NLG) applications and machine translation (MT) applications. The framework demonstrates a uniform approach to generation and transfer based on declarative lexico-structural transformations of dependency structures of syntactic or conceptual levels (uniform lexico-structural processing). We describe how this framework has been used in practical NLG and MT applications, and report the lessons learned."
han-etal-2000-handling,Handling structural divergences and recovering dropped arguments in a {K}orean/{E}nglish machine translation system,2000,10,34,4,0,31427,chunghye han,Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper describes an approach for handling structural divergences and recovering dropped arguments in an implemented Korean to English machine translation system. The approach relies on canonical predicate-argument structures (or dependency structures), which provide a suitable pivot representation for the handling of structural divergences and the recovery of dropped arguments. It can also be converted to and from the interface representations of many off-the-shelf parsers and generators."
W98-1409,A New Approach to Expert System Explanations,1998,12,22,3,0,847,regina barzilay,Natural Language Generation,0,"Abstract : Expert systems were one of the first applications to emerge from initial research in artificial intelligence, and the explanation of expert system reasoning was one of the first applications of natural language generation. This is because the need for explanations is obvious, and generation from a knowledge-based application such as reasoning should be relatively straightforward. However, while explanation has been universally acknowledged as a desirable functionality in expert systems, natural language generation has not taken a central place in contemporary expert system development. For example, a popular text book about expert systems such as (Giarratano and Riley, 1994) stresses twice in the introduction the importance of explanation, but provides no further mention of explanation in the remaining 600 pages. (The book is based on the popular CLIPS framework.) In this paper, we present a new approach to enhancing an expert system with an explanation facility. The approach comprises both software components and a methodology for assembling the components. The methodology is minimally intrusive into existing expert system development practice. This paper is structured as follows. In Section 2, we discuss previous work and identify shortcomings. We present our analysis of knowledge types in Section 3. Section 4 presents the Security Assistant and its explanation facility. Finally, we sketch a general methodology for explainable expert system engineering in Section 5."
W98-0135,Wh-islands in {TAG} and related formalisms,1998,1,2,1,1,1354,owen rambow,Proceedings of the Fourth International Workshop on Tree Adjoining Grammars and Related Frameworks ({TAG}+4),0,None
P98-1106,"Pseudo-Projectivity, A Polynomially Parsable Non-Projective Dependency Grammar",1998,13,74,3,0,14272,sylvain kahane,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,None
P98-1118,A Framework for Customizable Generation of Hypertext Presentations,1998,9,3,2,1,51615,benoit lavoie,"36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1",1,"In this paper, we present a framework, PRESENTOR, for the development and customization of hypertext presentation generators. PRESENTOR offers intuitive and powerful declarative languages specifying the presentation at different levels: macro-planning, micro-planning, realization, and formatting. PRESSENTOR is implemented and is portable cross-platform and cross-domain. It has been used with success in several application domains including weather forecasting, object modeling, system description and requirements summarization."
C98-1102,Pseudo-Projectivity: A Polynomially Parsable Non-Projective Dependency Grammar,1998,13,74,3,0,14272,sylvain kahane,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,None
C98-1114,A Framework for Customizable Generation of Hypertext Presentations,1998,9,3,2,1,51615,benoit lavoie,{COLING} 1998 Volume 1: The 17th International Conference on Computational Linguistics,0,"In this paper, we present a framework, PRESENTOR, for the development and customization of hypertext presentation generators. PRESENTOR offers intuitive and powerful declarative languages specifying the presentation at different levels: macro-planning, micro-planning, realization, and formatting. PRESSENTOR is implemented and is portable cross-platform and cross-domain. It has been used with success in several application domains including weather forecasting, object modeling, system description and requirements summarization."
palmer-etal-1998-rapid,Rapid prototyping of domain-apecific machine translation systems,1998,9,14,2,0,4859,martha palmer,Proceedings of the Third Conference of the Association for Machine Translation in the Americas: Technical Papers,0,"This paper reports on an experiment in assembling a domain-specific machine translation prototype system from off-the-shelf components. The design goals of this experiment were to reuse existing components, to use machine-learning techniques for parser specialization and for transfer lexicon extraction, and to use an expressive, lexicalized formalism for the transfer component."
A97-1037,Customizable Descriptions of Object-Oriented Models,1997,10,23,2,1,51615,benoit lavoie,Fifth Conference on Applied Natural Language Processing,0,"With the emergence of object-oriented technology and user-centered software engineering paradigms, the requirements analysis phase has changed in two important ways: it has become an iterative activity, and it has become more closely linked to the design phase of software engineering (Davis, 1993). A requirements analyst builds a formal object-oriented (OO) domain model. A user (domain expert) validates the domain model. The domain model undergoes subsequent evolution (modi cation or adjustment) by a (perhaps di erent) analyst. Finally, the domain model is passed to the designer (system analyst), who re nes the model into a OO design model used as the basis for implementation. Thus, we can see that the OO models form the basis of many important ows of information in OO software engineering methodologies. How can this information best be communicated? It is widely believed that graphical representations are easy to learn and use, both for modeling and for communication among the engineers and domain experts who together develop the OO domain model. This belief is re ected by the large number of graphical OO modeling tools currently in research labs and on the market. However, this belief is not accurate, as some recent empirical studies show. For example, Kim (1990) simulated a modeling task with experienced analysts and a validation task with sophisticated users not familiar with the particular graphical language. Both user groups showed semantic error rates between 25% and 70% for the separately scored areas of entities, attributes, and relations. Relations were particularly troublesome to both analysts and users. Petre (1995) compares diagrams with textual representations of nested conditional structures (which can be compared to OO modeling in the complexity of the paths through the system). She nds that the intrinsic di culty of the graphics mode was the strongest e ect observed (p.35). We therefore conclude that graphics, in order to assure maximum communicative e ciency, needs to be complemented by an alternate view of the data. We claim that the alternate view should be provided by an explanation tool that represents the data in the form of a uent English text. This paper presents such a tool, the ModelExplainer, or ModEx for short, and focuses on the customizability of the system. Automatically generating natural-language descriptions of software models and speci cations is not a new idea. The rst such system was Swartout's GIST Paraphraser (Swartout, 1982). More recent projects include the paraphraser in ARIES (Johnson et al., 1992); the GEMA dataow diagram describer (Scott and de Souza, 1989); and Gulla's paraphraser for the PPP system (Gulla, 1993). ModEx certainly belongs in the tradition of these speci cation paraphrasers, but the combination of features that we will describe in the next section (and in particular the customizability) is, to our knowledge, unique."
1997.mtsummit-workshop.12,Enriching lexical transfer with cross-linguistic semantic features or how to do interlingua without interlingua,1997,7,12,2,1,5812,alexis nasr,AMTA/SIG-IL First Workshop on Interlinguas,0,"In this paper, we propose an alternative to interlingua which can capture the analyses and generalizations that interlinguas can express, but which uses cross-linguistic semantic features rather than a separate level of representation. This alternative we call lexico-structural transfer. Lexico-structural transfer relies on the expressive power of a lexicalized syntactic representation (or xe2x80x9clexicalized grammarxe2x80x9d for short). In a lexicalized grammar, lexemes are associated with syntactic structure; in the transfer lexicon, we do not simply relate words (or context-free rewrite rules) from one language to words (or context-free rewrite rules) from another language. Instead, we relate lexemes along with relevant syntactic structure (essentially, their syntactic projection along with syntactic and lexical-semantic features). Several different lexicalized grammar formalisms have been proposed in the past, including notably Tree Adjoining Grammar (Joshi, 1987), Lexical-Functional Grammar (Kaplan and Bresnan, 1982) and various dependency grammars. We will present our work using a transfer formalism based on a dependency grammar, namely Melxe2x80x99cukxe2x80x99s Meaning Text Theory (MTT) (Melxe2x80x99cuk, 1988), specifically the xe2x80x9cDeep Syntactic Levelxe2x80x9d. This level of representation is similar in crucial respects to the derivation structures of TAG (Rambow and Joshi, 1996) and to the f-structure of LFG. There are two main reasons why we may want to investigate an alternative to the use of an interlingua:"
W96-0503,The {M}odel{E}xplainer,1996,-1,-1,2,1,51615,benoit lavoie,Eighth International Natural Language Generation Workshop (Posters and Demonstrations),0,None
P96-1016,Synchronous Models of Language,1996,18,16,1,1,1354,owen rambow,34th Annual Meeting of the Association for Computational Linguistics,1,"In synchronous rewriting, the productions of two rewriting systems are paired and applied synchronously in the derivation of a pair of strings. We present a new synchronous rewriting system and argue that it can handle certain phenomena that are not covered by existing synchronous systems. We also prove some interesting formal/computational properties of our system."
P95-1021,{D}-Tree Grammars,1995,18,95,1,1,1354,owen rambow,33rd Annual Meeting of the Association for Computational Linguistics,1,"DTG are designed to share some of the advantages of TAG while overcoming some of its limitations. DTG involve two composition operations called subsertion and sister-adjunction. The most distinctive feature of DTG is that, unlike TAG, there is complete uniformity in the way that the two DTG operations relate lexical items: subsertion always corresponds to complementation and sister-adjunction to modification. Furthermore, DTG, unlike TAG, can provide a uniform analysis for wh-movement in English and Kashmiri, despite the fact that the wh element in Kashmiri appears in sentence-second position, and not sentence-initial position as in English."
1995.iwpt-1.6,Parsing Non-Immediate Dominance Relations,1995,-1,-1,2,1,46850,tilman becker,Proceedings of the Fourth International Workshop on Parsing Technologies,0,"We present a new technique for parsing grammar formalisms that express non-immediate dominance relations by {`}dominance-links{'}. Dominance links have been introduced in various formalisms such as extensions to CFG and TAG in order to capture long-distance dependencies in free-word order languages (Becker et al., 1991; Rambow, 1994). We show how the addition of {`}link counters{'} to standard parsing algorithms such as CKY- and Earley-based methods for TAG results in a polynomial time complexity algorithm for parsing lexicalized V-TAG, a multi-component version of TAGs defined in (Rambow, 1994). A variant of this method has previously been applied to context-free grammar based formalisms such as UVG-DL."
1995.iwpt-1.30,Parsing {D}-Tree Grammars,1995,0,11,3,0,12137,vijayshanker,Proceedings of the Fourth International Workshop on Parsing Technologies,0,
W94-0320,The Role of Cognitive Modeling in Communicative Intentions,1994,17,0,1,1,1354,owen rambow,Proceedings of the Seventh International Workshop on Natural Language Generation,0,"A discourse planner for (task-oriented) dialogue must be able to make choices about whether relevant, but optional information (for example, the satellites in an RST-based planner) should be communicated. We claim that effective text planners must explicitly model aspects of the Hearer's cognitive state, such as what the hearer is attending to and what inferences the hearer can draw, in order to make these choices. We argue that a mere representation of the Hearer's knowledge is inadequate. We support this claim by (1) an analysis of naturally occurring dialogue, and (2) by simulating the generation of discourses in a situation in which we can vary the cognitive parameters of the hearer. Our results show that modeling cognitive state can lead to more effective discourses (measured with respect to a simple task)."
P94-1036,Multiset-Valued Linear Index Grammars: Imposing Dominance Constraints on Derivations,1994,19,18,1,1,1354,owen rambow,32nd Annual Meeting of the Association for Computational Linguistics,1,"This paper defines multiset-valued linear index grammar and unordered vector grammar with dominance links. The former models certain uses of multiset-valued feature structures in unification-based formalisms, while the latter is motivated by word order variation and by quasi-trees, a generalization of trees. The two formalisms are weakly equivalent, and an important subset is at most context-sensitive and polynomially parsable."
W93-0227,Rhetoric as Knowledge,1993,-1,-1,1,1,1354,owen rambow,Intentionality and Structure in Discourse Relations,0,None
A92-1006,Applied Text Generation,1992,20,70,1,1,1354,owen rambow,Third Conference on Applied Natural Language Processing,0,None
E91-1005,Long-Distance Scrambling and {T}ree {A}djoining {G}rammars,1991,10,74,3,1,46850,tilman becker,Fifth Conference of the {E}uropean Chapter of the Association for Computational Linguistics,0,None
W90-0112,Domain Communication Knowledge,1990,9,21,1,1,1354,owen rambow,Proceedings of the Fifth International Workshop on Natural Language Generation,0,None
